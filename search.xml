<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ä¸è¿ç»­MRCå®éªŒ</title>
      <link href="/2022/01/10/%E4%B8%8D%E8%BF%9E%E7%BB%ADMRC%E5%AE%9E%E9%AA%8C/"/>
      <url>/2022/01/10/%E4%B8%8D%E8%BF%9E%E7%BB%ADMRC%E5%AE%9E%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="ä¸è¿ç»­MRCå®éªŒ"><a href="#ä¸è¿ç»­MRCå®éªŒ" class="headerlink" title="ä¸è¿ç»­MRCå®éªŒ"></a>ä¸è¿ç»­MRCå®éªŒ</h1><h2 id="ç¯å¢ƒé…ç½®"><a href="#ç¯å¢ƒé…ç½®" class="headerlink" title="ç¯å¢ƒé…ç½®"></a>ç¯å¢ƒé…ç½®</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda create -n drop python=3.7</span><br><span class="line">pip3 install torch torchvision torchaudio</span><br><span class="line">pip3 install transformers</span><br></pre></td></tr></table></figure><h2 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h2><blockquote><p>æ•°æ®é›†ï¼šDROP <a href="https://huggingface.co/datasets/drop">https://huggingface.co/datasets/drop</a></p><p>æ•°æ®é¢„å¤„ç†ï¼šå‚è€ƒNAQAnetï¼Œå°†æ–‡æ¡£ä¸­çš„word numè½¬ä¸ºint numï¼Œè½¬æ¢ç›®å‰åªæ”¯æŒæ•´æ•°ã€‚</p><p>NAQAnet ä¸­å¯¹æ•°å­—çš„å¤„ç†å¯ä»¥å€Ÿé‰´ã€‚</p><p>TDEERä¸­ å¯¹spançš„æå–æ€è·¯å¯ä»¥å€Ÿé‰´ï¼Œç‰¹åˆ«æ˜¯ In the second stage å¯¹ start å’Œ end çš„åˆ†ç±»é¢„æµ‹ã€‚</p></blockquote><h2 id="ä»£ç ç»“æ„"><a href="#ä»£ç ç»“æ„" class="headerlink" title="ä»£ç ç»“æ„"></a>ä»£ç ç»“æ„</h2><h3 id="tool"><a href="#tool" class="headerlink" title="tool"></a>tool</h3><h4 id="log"><a href="#log" class="headerlink" title="log"></a>log</h4><blockquote><p>åŠ å…¥ emitï¼Œprintä¸ä¼šå—åˆ° tqdm è¿›åº¦è¡¨çš„å½±å“ã€‚</p><p>ä½¿ç”¨åå‡½æ•°ä¹Ÿå¯ä»¥é‡å†™loggerï¼Œä½†æ˜¯å®šåˆ¶åŒ–ç¨‹åº¦ä¸é«˜ï¼Œè¿™é‡Œä½¿ç”¨è‡ªå®šä¹‰çš„get_loggerç±»ï¼Œä»Šååœ¨å…¶ä»–é¡¹ç›®ä¸­ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚</p></blockquote><h3 id="dataset-readers"><a href="#dataset-readers" class="headerlink" title="dataset_readers"></a>dataset_readers</h3><p>è¸©å‘è®°å½•ï¼š</p><ol><li>tokenizer</li></ol><blockquote><p>ä½¿ç”¨ Transformers çš„ tokenizeråˆ†è¯å¹¶åšembeddingï¼Œå½“padding=â€™max_lengthâ€™æ—¶ï¼Œpaddingæ‰ä¼šè¡¥å……åˆ°æŒ‡å®šé•¿åº¦ã€‚</p><p>åœ¨ä½¿ç”¨tokenizerçš„æ—¶å€™ä¹Ÿå¯ä»¥æŒ‡å®šå‚æ•°ï¼Œreturn_tensors=â€™ptâ€™,è¿™æ ·å°±ä¸ç”¨æ‰‹åŠ¨å°†listè½¬tensoräº†ã€‚</p><p>tokenizer(sent, max_length=max_length, padding=â€™max_lengthâ€™, truncation=True)</p></blockquote><ol><li>tensor</li></ol><blockquote><p>torch.stack() æ¯æ¬¡éƒ½åœ¨<strong>æ–°çš„</strong>æŒ‡å®šçš„ç»´åº¦ä¸Šè¿›è¡Œæ‹¼æ¥ï¼Œè¿­ä»£ä½¿ç”¨çš„æ—¶å€™éœ€è¦æ³¨æ„ã€‚</p><p>torch.cat() åœ¨å·²æœ‰çš„ç»´åº¦ä¸Šè¿æ¥ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿æ¥åä¸ä¼šæ‰©å……ç»´åº¦ï¼Œéœ€è¦æ‰‹åŠ¨çš„reshapeã€‚</p></blockquote><ol><li>TensorDataset</li></ol><blockquote><p>TensorDataset å¯ä»¥å°†tensoråºåˆ—åŒ–ä¿å­˜ï¼Œé¿å…å¤šæ¬¡é‡å¤é¢„å¤„ç†ï¼ŒåŒæ ·ä½¿ç”¨torch.save()ä¿å­˜ï¼Œå½“ç„¶ï¼Œlistï¼Œdictï¼Œéƒ½å¯ä»¥ä½¿ç”¨torch.save()ä¿å­˜ï¼Œæ–¹ä¾¿ä¸‹æ¬¡åœ¨è¯¥èŠ‚ç‚¹ç»§ç»­æ“ä½œã€‚</p><p>torch.save({â€œdatasetâ€: TensorDataset, â€œexamplesâ€: _examples}, temp_file_path)</p></blockquote><ol><li>ä½ç½®åŒ¹é…</li></ol><blockquote><p>æœ€å¼€å§‹ä½¿ç”¨spacyï¼Œç®€å•çš„ä½¿ç”¨ç©ºæ ¼åˆ†è¯ï¼Œå¹¶æŸ¥æ‰¾ç­”æ¡ˆ span çš„ä½ç½®ï¼Œä½†åœ¨åé¢ä½¿ç”¨transformersçš„tokenizeråšembeddingçš„æ—¶å€™æ„è¯†åˆ°ï¼Œæ‹†è¯æ–¹å¼ä¸åŒï¼Œé¢„å¤„ç†é˜¶æ®µç”Ÿæˆçš„answer spanä¹Ÿä¼šæœ‰åå·®ï¼Œæ‰€ä»¥ä¸€è‡´ä½¿ç”¨tokenizeråˆ†è¯ã€‚</p><p>é™¤äº†eval_examplesä¸­çš„spanæ˜¯ä»¥charä¸ºå•ä½ï¼Œå…¶ä½™spanéƒ½æ˜¯ä»¥wordä¸ºå•ä½ã€‚</p></blockquote><p><strong>æ•°æ®é›†å°è£…æ ¼å¼ï¼š</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">_dataset = TensorDataset(</span><br><span class="line">    torch.tensor(passage_text_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(passage_text_attention_mask, dtype=torch.long),</span><br><span class="line">    torch.tensor(question_text_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(question_text_attention_mask, dtype=torch.long),</span><br><span class="line">    torch.tensor(start_indices_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(start_indices_attention_mask, dtype=torch.long),</span><br><span class="line">    torch.tensor(end_indices_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(end_indices_attention_mask, dtype=torch.long),</span><br><span class="line">    torch.tensor(counts_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(count_attention_mask, dtype=torch.long),</span><br><span class="line">    torch.tensor(id_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(id_attention_mask, dtype=torch.long)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>æŸ¥é˜…DROPç›¸å…³è®ºæ–‡ ç¡®å®šå¯¹ä¸åŒanser_typeçš„å¤„ç†æ–¹å¼</p><p><a href="https://paperswithcode.com/sota/question-answering-on-drop-test">https://paperswithcode.com/sota/question-answering-on-drop-test</a></p><p><a href="https://paperswithcode.com/dataset/drop">https://paperswithcode.com/dataset/drop</a></p><h2 id="æ’è¡Œæ¦œ"><a href="#æ’è¡Œæ¦œ" class="headerlink" title="æ’è¡Œæ¦œ"></a>æ’è¡Œæ¦œ</h2><p>DROPæ•°æ®é›†æ€§èƒ½æ’è¡Œæ¦œï¼š<a href="https://paperswithcode.com/sota/question-answering-on-drop-test">https://paperswithcode.com/sota/question-answering-on-drop-test</a></p><p>paperswithcodeä¸DROPç›¸å…³è®ºæ–‡ï¼š<a href="https://paperswithcode.com/dataset/drop">https://paperswithcode.com/dataset/drop</a></p><h2 id="æ–°å·¥å…·"><a href="#æ–°å·¥å…·" class="headerlink" title="æ–°å·¥å…·"></a>æ–°å·¥å…·</h2><p>Adapter Transformers</p><p>ä»‹ç»ï¼š<a href="https://zhuanlan.zhihu.com/p/373424011">https://zhuanlan.zhihu.com/p/373424011</a></p><p>æºç ï¼š<a href="https://github.com/Adapter-Hub/adapter-transformers">https://github.com/Adapter-Hub/adapter-transformers</a></p><p>é¢„è®­ç»ƒæ¨¡å‹ï¼š<a href="https://huggingface.co/AdapterHub/bert-base-uncased-pf-drop">https://huggingface.co/AdapterHub/bert-base-uncased-pf-drop</a></p><h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h2><ol><li><strong>TASE</strong>-(paper) - A Simple and Effective Model for Answering Multi-span Questions <strong>EMNLP 2020</strong></li></ol><p>â€‹        GitHubï¼š<a href="https://github.com/llamazing/numnet_plus">https://github.com/llamazing/numnet_plus</a></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20220110113838.png" alt="image-20220110113838743"></p><ol><li><strong>MTMSN</strong>-(paper) - A Multi-Type Multi-Span Network for Reading Comprehension that Requires Discrete Reasoning <strong>EMNLP 2019</strong></li></ol><p>â€‹        GitHubï¼š<a href="https://github.com/huminghao16/MTMSN">https://github.com/huminghao16/MTMSN</a></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20220110113857.png" alt="image-20220110113857713"></p><ol><li><strong>MetaQA</strong>-(paper) - MetaQA: Combining Expert Agents for Multi-Skill Question Answering <strong>Submitted on 3 Dec 2021</strong>æ¯”è¾ƒæ–° ä¸” <strong>ä»£ç ç»“æ„ç±»ä¼¼</strong></li></ol><p>â€‹        GitHubï¼š <a href="https://github.com/ukplab/metaqa">https://github.com/ukplab/metaqa</a></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20220110102212.png" alt="image-20220110102212928" style="zoom: 25%;" /></p><ol><li><p><strong>NAQANet</strong> <strong>æ€§èƒ½è¾ƒä½</strong> ä½†ä»£ç å®ç°å¯å‚è€ƒ</p><p>GitHubï¼š<a href="https://github.com/francescomontagna/NAQANet-PyTorch">https://github.com/francescomontagna/NAQANet-PyTorch</a></p><p>åŸå§‹æ•°æ®ä½¿ç”¨çš„æ˜¯ drop_dataset_train_standardized.json å’Œ drop_dataset_dev_standardized.json</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> è½¯ä»¶å¼€å‘&amp;æ¨¡å‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> Drop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç®—æ³•ç¬”è®°ï¼ˆæ›´æ–°ä¸­ï¼‰</title>
      <link href="/2022/01/04/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"/>
      <url>/2022/01/04/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="ç®—æ³•ç¬”è®°"><a href="#ç®—æ³•ç¬”è®°" class="headerlink" title="ç®—æ³•ç¬”è®°"></a>ç®—æ³•ç¬”è®°</h1><p>è®°å½•åˆ·é¢˜è¿‡ç¨‹ä¸­é‡åˆ°çš„é‡è¦çŸ¥è¯†ç‚¹å’Œæ–°çŸ¥è¯†ï¼</p><h2 id="Pythonä¸“é¢˜"><a href="#Pythonä¸“é¢˜" class="headerlink" title="Pythonä¸“é¢˜"></a>Pythonä¸“é¢˜</h2><h3 id="defaultdict"><a href="#defaultdict" class="headerlink" title="defaultdict"></a>defaultdict</h3><p>defaultdictçš„ä½œç”¨æ˜¯åœ¨äºï¼Œå½“å­—å…¸é‡Œçš„keyä¸å­˜åœ¨ä½†è¢«æŸ¥æ‰¾æ—¶ï¼Œè¿”å›çš„ä¸æ˜¯keyErrorè€Œæ˜¯ä¸€ä¸ªé»˜è®¤å€¼ã€‚</p><h3 id="bisectæ¨¡å—"><a href="#bisectæ¨¡å—" class="headerlink" title="bisectæ¨¡å—"></a>bisectæ¨¡å—</h3><blockquote><p>ç§‘æ™®ç¯èŠ‚ï¼šè¿™ä¸ªæ¨¡å—å«åš bisect å› ä¸ºå…¶ä½¿ç”¨äº†åŸºæœ¬çš„äºŒåˆ†ï¼ˆbisectionï¼‰ç®—æ³•ã€‚</p></blockquote><p>ä¸€æ—¦å†³å®šä½¿ç”¨äºŒåˆ†æœç´¢æ—¶ï¼Œç«‹é©¬è¦æƒ³åˆ°ä½¿ç”¨è¿™ä¸ªæ¨¡å—ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import bisect</span><br><span class="line"> </span><br><span class="line">x_insert_point = bisect.bisect_left(L,x)ã€€ã€€#åœ¨Lä¸­æŸ¥æ‰¾xï¼Œxå­˜åœ¨æ—¶è¿”å›xå·¦ä¾§çš„ä½ç½®ï¼Œxä¸å­˜åœ¨è¿”å›åº”è¯¥æ’å…¥çš„ä½ç½®</span><br><span class="line">x_insert_point = bisect.bisect_right(L,x)  #åœ¨Lä¸­æŸ¥æ‰¾xï¼Œxå­˜åœ¨æ—¶è¿”å›xå³ä¾§çš„ä½ç½®ï¼Œxä¸å­˜åœ¨è¿”å›åº”è¯¥æ’å…¥çš„ä½ç½®</span><br><span class="line">x_insort_left = bisect.insort_left(L,x)  #å°†xæ’å…¥åˆ°åˆ—è¡¨Lä¸­ï¼Œxå­˜åœ¨æ—¶æ’å…¥åœ¨å·¦ä¾§</span><br><span class="line">x_insort_rigth = bisect.insort_right(L,x) #å°†xæ’å…¥åˆ°åˆ—è¡¨Lä¸­ï¼Œxå­˜åœ¨æ—¶æ’å…¥åœ¨å³ä¾§ã€€ã€€ã€€ã€€</span><br></pre></td></tr></table></figure><h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentences = [&quot;i like dog&quot;, &quot;i love coffee&quot;, &quot;i hate milk&quot;]</span><br></pre></td></tr></table></figure><p>â€œ â€œ.join(sentences) å°†åˆ—è¡¨æ‹¼æ¥æˆä¸€ä¸ªå¥å­ â€˜i like dog i love coffee i hate milkâ€™</p><h3 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h3><h4 id="numpy-random-choice"><a href="#numpy-random-choice" class="headerlink" title="numpy.random.choice"></a>numpy.random.choice</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">numpy.random.choice(a, size=None, replace=True, p=None)</span><br><span class="line"></span><br><span class="line">#ä»a(åªè¦æ˜¯ndarrayéƒ½å¯ä»¥ï¼Œä½†å¿…é¡»æ˜¯ä¸€ç»´çš„)ä¸­éšæœºæŠ½å–æ•°å­—ï¼Œå¹¶ç»„æˆæŒ‡å®šå¤§å°(size)çš„æ•°ç»„</span><br><span class="line">#replace:Trueè¡¨ç¤ºå¯ä»¥å–ç›¸åŒæ•°å­—ï¼ŒFalseè¡¨ç¤ºä¸å¯ä»¥å–ç›¸åŒæ•°å­—</span><br><span class="line">#æ•°ç»„pï¼šä¸æ•°ç»„aç›¸å¯¹åº”ï¼Œè¡¨ç¤ºå–æ•°ç»„aä¸­æ¯ä¸ªå…ƒç´ çš„æ¦‚ç‡ï¼Œé»˜è®¤ä¸ºé€‰å–æ¯ä¸ªå…ƒç´ çš„æ¦‚ç‡ç›¸åŒã€‚</span><br></pre></td></tr></table></figure><h4 id="np-eye-nums"><a href="#np-eye-nums" class="headerlink" title="np.eye(nums)"></a>np.eye(nums)</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">np.eye(3)</span><br><span class="line"></span><br><span class="line">Out[22]: </span><br><span class="line">array([[1., 0., 0.],</span><br><span class="line">       [0., 1., 0.],</span><br><span class="line">       [0., 0., 1.]])</span><br></pre></td></tr></table></figure><ul><li>å–æœ€å†…å±‚æŒ‡å®šä½ç½®å…ƒç´ </li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">np.eye(3)[0,1]</span><br><span class="line"></span><br><span class="line">Out[23]: 0.0</span><br><span class="line"># è¡¨ç¤ºå–0è¡Œçš„ç¬¬äºŒä¸ªå…ƒç´ </span><br></pre></td></tr></table></figure><ul><li>åµŒå¥—åˆ—è¡¨å–æŒ‡å®šä½ç½®å‘é‡</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.eye(3)[[0,1]]</span><br><span class="line"></span><br><span class="line">Out[24]: </span><br><span class="line">array([[1., 0., 0.],</span><br><span class="line">       [0., 1., 0.]])</span><br></pre></td></tr></table></figure><h3 id="ord-å‡½æ•°"><a href="#ord-å‡½æ•°" class="headerlink" title="ord()å‡½æ•°"></a>ord()å‡½æ•°</h3><p>è¿”å›å€¼æ˜¯å¯¹åº”çš„åè¿›åˆ¶æ•´æ•°ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ord(&#x27;a&#x27;)</span><br><span class="line">97</span><br></pre></td></tr></table></figure><h3 id="åˆ—è¡¨"><a href="#åˆ—è¡¨" class="headerlink" title="åˆ—è¡¨"></a>åˆ—è¡¨</h3><p>åˆ—è¡¨çš„å¤åˆ¶</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new = old[:]</span><br></pre></td></tr></table></figure><h3 id="clså’Œself"><a href="#clså’Œself" class="headerlink" title="clså’Œself"></a>clså’Œself</h3><p><strong>selfå’Œclsçš„åŒºåˆ«</strong></p><ul><li>selfè¡¨ç¤ºä¸€ä¸ªå…·ä½“çš„å®ä¾‹æœ¬èº«ã€‚éœ€è¦å®ä¾‹åŒ–ä¹‹åæ‰èƒ½è°ƒç”¨ã€‚</li><li>clsè¡¨ç¤ºè¿™ä¸ªç±»æœ¬èº«ï¼Œç›´æ¥ç±»å¯¹è±¡è°ƒç”¨ã€ç±»æ–¹æ³•.æ–¹æ³•åã€‘/å®ä¾‹åŒ–åè°ƒç”¨å‡å¯ã€‚</li></ul><h2 id="C-ä¸“é¢˜"><a href="#C-ä¸“é¢˜" class="headerlink" title="C++ä¸“é¢˜"></a>C++ä¸“é¢˜</h2><h3 id="STL"><a href="#STL" class="headerlink" title="STL"></a>STL</h3><h4 id="è¿­ä»£å™¨"><a href="#è¿­ä»£å™¨" class="headerlink" title="è¿­ä»£å™¨"></a>è¿­ä»£å™¨</h4><ul><li><strong>c.begin()</strong> è¿”å›ä¸€ä¸ªè¿­ä»£å™¨ï¼Œå®ƒæŒ‡å‘å®¹å™¨cçš„ç¬¬ä¸€ä¸ªå…ƒç´ </li><li><strong>c.end()</strong> è¿”å›ä¸€ä¸ªè¿­ä»£å™¨ï¼Œå®ƒæŒ‡å‘å®¹å™¨cçš„æœ€åä¸€ä¸ªå…ƒç´ çš„ä¸‹ä¸€ä¸ªä½ç½®</li><li><strong>c.rbegin()</strong> è¿”å›ä¸€ä¸ªé€†åºè¿­ä»£å™¨ï¼Œå®ƒæŒ‡å‘å®¹å™¨cçš„æœ€åä¸€ä¸ªå…ƒç´ </li><li><strong>c.rend()</strong> è¿”å›ä¸€ä¸ªé€†åºè¿­ä»£å™¨ï¼Œå®ƒæŒ‡å‘å®¹å™¨cçš„ç¬¬ä¸€ä¸ªå…ƒç´ å‰é¢çš„ä½ç½®</li></ul><h4 id="vector"><a href="#vector" class="headerlink" title="vector"></a>vector</h4><ul><li><strong>vectoræ’åºï¼š</strong><code>sort(nums.begin(),nums.end());</code></li></ul><p>å‡åºï¼š<code>sort(vec.begin(), vec.end(), less&lt;int&gt;());</code></p><p>é™åºï¼š<code>sort(vec.begin(), vec.end(), greater&lt;int&gt;());</code></p><ul><li><p><strong>vectoræ•°ç»„çš„é•¿åº¦ï¼š</strong><code>vector.length;</code> æˆ–è€… <code>vector.size();</code></p></li><li><p>åˆå§‹åŒ–vector</p><p><code>vector&lt;bool&gt; a(b.size(),false);</code></p><p><code>vector&lt;string&gt;  honor&#123;&quot;Gold Medal&quot;,&quot;Silver Medal&quot;,&quot;Bronze Medal&quot;&#125;;</code></p></li><li><p>åè½¬</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reverse(num.begin(),num.end());</span><br></pre></td></tr></table></figure><ul><li>åˆ é™¤ erase()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num.erase(num.begin()+i*2+1-i);</span><br><span class="line">// å€¼å¾—æ³¨æ„çš„æ˜¯ åˆ é™¤å æ•°ç»„çš„é•¿åº¦ä¼šå‘ç”Ÿå˜åŒ–</span><br><span class="line">num.erase(num.end()-1);</span><br></pre></td></tr></table></figure><ul><li>æ’å…¥ insert()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//æ’å…¥å…ƒç´ iåˆ°æŒ‡å®šä½ç½®</span><br><span class="line">p.insert(p.begin(),i);</span><br></pre></td></tr></table></figure><ul><li>æŸ¥æ‰¾ find()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// æŸ¥æ‰¾å…ƒç´ iæ˜¯å¦åœ¨pä¸­å‡ºç° (æ³¨æ„è¿”å›çš„æ˜¯è¿­ä»£å™¨)</span><br><span class="line">vector&lt;int&gt;::iterator it = find(p.begin(),p.end(),i);</span><br><span class="line">if (it==p.end())</span><br><span class="line">//ä¸å­˜åœ¨</span><br></pre></td></tr></table></figure><ul><li>ä¸‹æ ‡ distance()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//itä¸ºè¿­ä»£å™¨ è®¡ç®—itæŒ‡å‘å…ƒç´ çš„ä¸‹æ ‡index</span><br><span class="line">int dis = distance(p.begin(), it);</span><br></pre></td></tr></table></figure><h4 id="setå’Œunordered-set"><a href="#setå’Œunordered-set" class="headerlink" title="setå’Œunordered_set"></a>setå’Œunordered_set</h4><ul><li><strong>setå’Œunordered_set</strong>ï¼šå…¶ä¸­unordered_setå¯¹å…ƒç´ ä¸è¿›è¡Œæ’åº</li></ul><p><strong>find(key)ï¼š</strong>æŸ¥æ‰¾ä»¥å€¼ä¸º key çš„å…ƒç´ ï¼Œå¦‚æœæ‰¾åˆ°ï¼Œåˆ™è¿”å›ä¸€ä¸ªæŒ‡å‘è¯¥å…ƒç´ çš„æ­£å‘è¿­ä»£å™¨ï¼›åä¹‹ï¼Œåˆ™è¿”å›ä¸€ä¸ªæŒ‡å‘å®¹å™¨ä¸­æœ€åä¸€ä¸ªå…ƒç´ ä¹‹åä½ç½®çš„è¿­ä»£å™¨ï¼ˆå¦‚end() æ–¹æ³•è¿”å›çš„è¿­ä»£å™¨ï¼‰ã€‚</p><p><strong>count(key)ï¼š</strong>åœ¨å®¹å™¨ä¸­æŸ¥æ‰¾å€¼ä¸º key çš„å…ƒç´ çš„ä¸ªæ•°ã€‚</p><h4 id="mapå’Œunordered-map"><a href="#mapå’Œunordered-map" class="headerlink" title="mapå’Œunordered_map"></a>mapå’Œunordered_map</h4><p>mapæ˜¯æœ‰åºçš„ï¼Œçº¢é»‘æ ‘å®ç°ã€‚</p><p>unordered_mapæ˜¯æ— åºçš„ï¼Œå†…éƒ¨å®ç°äº†ä¸€ä¸ªå“ˆå¸Œè¡¨ã€‚</p><p>map int åˆå§‹å€¼ 0ï¼›</p><p><strong>èµ‹å€¼ï¼š</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">order_list.insert(pair&lt;char, int&gt;(score[i], i));</span><br></pre></td></tr></table></figure><p><strong>ç»Ÿè®¡ï¼š</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//åˆ¤æ–­ order_list ä¸­æ˜¯å¦å‡ºç°è¿‡ x</span><br><span class="line">order_list.count(x)</span><br></pre></td></tr></table></figure><p><strong>éå†ï¼š</strong></p><p>æ–¹æ³•ä¸€ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">unordered_map&lt;string, int&gt; cnt;</span><br><span class="line">// &amp; å¼•ç”¨</span><br><span class="line">for (auto &amp; [key,val] : cnt) &#123;</span><br><span class="line">            if (key.substr(0, prefix.size()) == prefix) &#123;</span><br><span class="line">                res += val;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>æ–¹æ³•äºŒï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">std::map&lt;int, TaskInfo*&gt;::iterator iter;</span><br><span class="line">for (iter=maps.begin(); iter!=maps.end(); iter++)</span><br><span class="line">   &#123;</span><br><span class="line">       printf(&quot;%d, %s&quot;, iter-&gt;first, iter-&gt;second);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="advance-å‡½æ•°"><a href="#advance-å‡½æ•°" class="headerlink" title="advance()å‡½æ•°"></a>advance()å‡½æ•°</h4><p>advance() å‡½æ•°ç”¨äºå°†è¿­ä»£å™¨å‰è¿›ï¼ˆæˆ–è€…åé€€ï¼‰æŒ‡å®šé•¿åº¦çš„è·ç¦»ï¼Œå…¶è¯­æ³•æ ¼å¼å¦‚ä¸‹ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">template &lt;class InputIterator, class Distance&gt;</span><br><span class="line">    void advance (InputIterator&amp; it, Distance n);</span><br><span class="line">    </span><br><span class="line">ä¸¾ä¾‹ï¼š</span><br><span class="line">list&lt;int&gt; lst(nums.begin(), nums.end());</span><br><span class="line">        for (int i = 0;i&lt;this-&gt;back.size();i++)</span><br><span class="line">            &#123;</span><br><span class="line">                // ä½¿ç”¨listçš„è¿­ä»£å™¨</span><br><span class="line">                auto it = lst.begin();</span><br><span class="line">                // é€‰æ‹©éšæœºæ•°</span><br><span class="line">                int j = rand()%(lst.size());</span><br><span class="line">                cout&lt;&lt;j;</span><br><span class="line">                // å°†è¿­ä»£å™¨å‘åç§»åŠ¨jä½</span><br><span class="line">                advance(it,j);</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><h4 id="string"><a href="#string" class="headerlink" title="string"></a>string</h4><ul><li>åˆå§‹åŒ–</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">string sgood=&quot;abs&quot;;</span><br><span class="line">string sgood_rev(sgood.rbegin(), sgood.rend());</span><br></pre></td></tr></table></figure><ul><li>åè½¬</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reverse(ans.begin(), ans.end());</span><br><span class="line">æˆ–è€…</span><br><span class="line">string sgood=&quot;abs&quot;;</span><br><span class="line">string sgood_rev(sgood.rbegin(), sgood.rend());</span><br></pre></td></tr></table></figure><h4 id="array"><a href="#array" class="headerlink" title="array"></a>array</h4><p>åˆå§‹åŒ–</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">std::array&lt;int, 5&gt; arr = &#123;1, 2, 3, 4, 5&#125;;</span><br><span class="line">std::array&lt;double, 100&gt; data &#123;&#125;; //åˆå§‹åŒ–ä¸º0.0</span><br><span class="line"></span><br><span class="line">values.fill(3.1415926); //é€šè¿‡è°ƒç”¨æ•°ç»„å¯¹è±¡çš„æˆå‘˜å‡½æ•° fill()ï¼Œå¯ä»¥å°†æ‰€æœ‰å…ƒç´ è®¾æˆç»™å®šå€¼ã€‚</span><br></pre></td></tr></table></figure><ul><li>ç©ºæ ¼åˆ†å‰²å­—ç¬¦ä¸²ï¼Œä½¿ç”¨stringstream</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">int main()&#123;</span><br><span class="line">    //ç”¨äºå­˜æ”¾åˆ†å‰²åçš„å­—ç¬¦ä¸² </span><br><span class="line">    vector&lt;string&gt; res;</span><br><span class="line">    //å¾…åˆ†å‰²çš„å­—ç¬¦ä¸²ï¼Œå«æœ‰å¾ˆå¤šç©ºæ ¼ </span><br><span class="line">    string word=&quot;   Hello, I want   to learn C++!   &quot;;</span><br><span class="line">    //æš‚å­˜ä»wordä¸­è¯»å–çš„å­—ç¬¦ä¸² </span><br><span class="line">    string result;</span><br><span class="line">    //å°†å­—ç¬¦ä¸²è¯»åˆ°inputä¸­ </span><br><span class="line">    stringstream input(word);</span><br><span class="line">    //ä¾æ¬¡è¾“å‡ºåˆ°resultä¸­ï¼Œå¹¶å­˜å…¥resä¸­ </span><br><span class="line">    while(input&gt;&gt;result)</span><br><span class="line">        res.push_back(result);</span><br><span class="line">    //è¾“å‡ºres </span><br><span class="line">    for(int i=0;i&lt;res.size();i++)&#123;</span><br><span class="line">        cout&lt;&lt;res[i]&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>å­—ç¬¦ä¸²éå†</li></ul><blockquote><p>for (char ch: s)</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">unordered_map&lt;char, int&gt; c;</span><br><span class="line">for (char ch: s) &#123;</span><br><span class="line">       ++c[ch];</span><br><span class="line">     &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>isalnum(char c ) åˆ¤æ–­æ˜¯å¦æ˜¯å­—æ¯æˆ–æ•°å­—</li><li>isalpha() åˆ¤æ–­æ˜¯å¦æ˜¯å­—æ¯</li><li>isdigit() åˆ¤æ–­æ˜¯å¦æ˜¯æ•°å­—</li><li>tolower() è½¬å°å†™ ï¼›touper() è½¬å¤§å†™</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tolower(a);</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">string ans;</span><br><span class="line">for(char c : s)&#123;</span><br><span class="line">      ans += tolower(c);</span><br><span class="line">   &#125;</span><br><span class="line">return ans;</span><br></pre></td></tr></table></figure><h4 id="ä¼˜å…ˆé˜Ÿåˆ—-priority-queue"><a href="#ä¼˜å…ˆé˜Ÿåˆ—-priority-queue" class="headerlink" title="ä¼˜å…ˆé˜Ÿåˆ— priority_queue"></a>ä¼˜å…ˆé˜Ÿåˆ— priority_queue</h4><ol><li>å®šä¹‰ <code>priority_queue&lt;Type, Container, Functional&gt;</code></li></ol><blockquote><p>STLé‡Œé¢é»˜è®¤ç”¨çš„æ˜¯vector</p><p><a href="https://blog.csdn.net/weixin_36888577/article/details/79937886">å¼•ç”¨</a></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">priority_queue&lt;pii, vector&lt;pii&gt;, greater&lt;pii&gt;&gt; pq;</span><br></pre></td></tr></table></figure><ol><li>æ–¹æ³•</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pq.empty() </span><br><span class="line">pq.top()</span><br><span class="line">pq.emplace()</span><br><span class="line">pq.pop()</span><br></pre></td></tr></table></figure><h4 id="pair"><a href="#pair" class="headerlink" title="pair"></a>pair</h4><p>é…åˆvectorä½¿ç”¨</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;pair&lt;int, int&gt;&gt; arr;</span><br></pre></td></tr></table></figure><ul><li>make_pair(1,2)</li></ul><h3 id="è¯­æ³•"><a href="#è¯­æ³•" class="headerlink" title="è¯­æ³•"></a>è¯­æ³•</h3><h4 id="1-åˆ¤æ–­å¤§å°å†™"><a href="#1-åˆ¤æ–­å¤§å°å†™" class="headerlink" title="1.åˆ¤æ–­å¤§å°å†™"></a>1.åˆ¤æ–­å¤§å°å†™</h4><p><code>islower(&#39;a&#39;)</code></p><p><code>isupper(word[1])</code></p><h4 id="2-å¼‚æˆ–"><a href="#2-å¼‚æˆ–" class="headerlink" title="2. å¼‚æˆ–"></a>2. å¼‚æˆ–</h4><p><code>^</code>è¿ç®—ç¬¦</p><h4 id="3-å¼•ç”¨-amp"><a href="#3-å¼•ç”¨-amp" class="headerlink" title="3.å¼•ç”¨ &amp;"></a>3.å¼•ç”¨ &amp;</h4><p>ç”¨ char <strong>&amp;c</strong> å¯ä»¥ä¿®æ”¹åŸå˜é‡çš„å†…å®¹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for(char &amp;c : s)&#123;</span><br><span class="line">    c =  tolower(c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-æŠŠæ•°å­—å­—ç¬¦ä¸²è½¬æ¢æˆintè¾“å‡º"><a href="#4-æŠŠæ•°å­—å­—ç¬¦ä¸²è½¬æ¢æˆintè¾“å‡º" class="headerlink" title="4.æŠŠæ•°å­—å­—ç¬¦ä¸²è½¬æ¢æˆintè¾“å‡º"></a>4.æŠŠæ•°å­—å­—ç¬¦ä¸²è½¬æ¢æˆintè¾“å‡º</h4><ul><li><p><strong>atoi()</strong>çš„å‚æ•°æ˜¯ const char<em> ,å› æ­¤å¯¹äºä¸€ä¸ªå­—ç¬¦ä¸²stræˆ‘ä»¬å¿…é¡»è°ƒç”¨ c_str()çš„æ–¹æ³•æŠŠè¿™ä¸ªstringè½¬æ¢æˆ const char</em> ç±»å‹çš„,</p></li><li><p><strong>stoi()</strong>çš„å‚æ•°æ˜¯const string*,ä¸éœ€è¦è½¬åŒ–ä¸º const char*</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">string date = &quot;2019-01-09&quot;</span><br><span class="line">int year = stoi(date.substr(0, 4));</span><br></pre></td></tr></table></figure><h4 id="5-æ•°å­—èŒƒå›´"><a href="#5-æ•°å­—èŒƒå›´" class="headerlink" title="5.æ•°å­—èŒƒå›´"></a>5.æ•°å­—èŒƒå›´</h4><ul><li>int</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INT_MAX</span><br></pre></td></tr></table></figure><h4 id="6-ä½è¿ç®—"><a href="#6-ä½è¿ç®—" class="headerlink" title="6.ä½è¿ç®—"></a>6.ä½è¿ç®—</h4><p>å·¦ç§»ä¹˜2</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">step &lt;&lt;= 1; //æ­¥é•¿ * 2</span><br><span class="line">n &gt;&gt;= 1;  //æ€»æ•° / 2</span><br></pre></td></tr></table></figure><h2 id="ç®—æ³•"><a href="#ç®—æ³•" class="headerlink" title="ç®—æ³•"></a>ç®—æ³•</h2><h3 id="äºŒåˆ†"><a href="#äºŒåˆ†" class="headerlink" title="äºŒåˆ†"></a>äºŒåˆ†</h3><ul><li>æ‰¾ä¸­é—´ä½ç½® é å³çš„å…ƒç´ </li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mid = left + (right - left + 1)/2;</span><br><span class="line">ä¸</span><br><span class="line">mid = (left+right+1)/2;  ä¸€è‡´</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p><strong>upper_bound( begin,end,num)</strong>ï¼šä»æ•°ç»„çš„beginä½ç½®åˆ°end-1ä½ç½®äºŒåˆ†æŸ¥æ‰¾ç¬¬ä¸€ä¸ª<strong>å¤§äº</strong>numçš„æ•°å­—ï¼Œæ‰¾åˆ°è¿”å›è¯¥æ•°å­—çš„åœ°å€ï¼Œä¸å­˜åœ¨åˆ™è¿”å›endã€‚</p><p>é€šè¿‡è¿”å›çš„åœ°å€å‡å»èµ·å§‹åœ°å€begin,å¾—åˆ°æ‰¾åˆ°æ•°å­—åœ¨æ•°ç»„ä¸­çš„ä¸‹æ ‡ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int pos = upper_bound(times.begin(), times.end(), t) - times.begin() - 1;</span><br><span class="line">// - 1 è¡¨ç¤ºtåº”è¯¥æ’å…¥çš„ä½ç½®</span><br><span class="line">// ä¸å‡1 ä»£è¡¨è¾¹ç•Œä¸‹æ ‡</span><br><span class="line">// å› ä¸ºè¿”å›çš„åœ°å€æ˜¯ ç¬¬ä¸€ä¸ª å¤§äºt çš„ä¸‹æ ‡</span><br></pre></td></tr></table></figure></li><li><p><strong>lower_bound( begin,end,num)</strong>ï¼šä»æ•°ç»„çš„beginä½ç½®åˆ°end-1ä½ç½®äºŒåˆ†æŸ¥æ‰¾ç¬¬ä¸€ä¸ª<strong>å¤§äºæˆ–ç­‰äº</strong>numçš„æ•°å­—ï¼Œæ‰¾åˆ°è¿”å›è¯¥æ•°å­—çš„åœ°å€ï¼Œä¸å­˜åœ¨åˆ™è¿”å›endã€‚</p><p>é€šè¿‡è¿”å›çš„åœ°å€å‡å»èµ·å§‹åœ°å€begin,å¾—åˆ°æ‰¾åˆ°æ•°å­—åœ¨æ•°ç»„ä¸­çš„ä¸‹æ ‡ã€‚</p></li><li><p>æ‰‹å†™å®ç°</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">int left = 0, right = times.size() - 1;</span><br><span class="line">//times æ•°ç»„ä¸¥æ ¼é€’å¢</span><br><span class="line">        while (left &lt; right) &#123;</span><br><span class="line">            int i = left + (right - left +1 ) / 2;</span><br><span class="line">            if (times[i] == t) </span><br><span class="line">                return tops[i];</span><br><span class="line">            else if (times[i] &lt; t)</span><br><span class="line">                left = i ;</span><br><span class="line">            else </span><br><span class="line">                right = i - 1;</span><br><span class="line">        &#125;</span><br><span class="line">        return tops[left];</span><br></pre></td></tr></table></figure><h3 id="å­—å…¸æ ‘"><a href="#å­—å…¸æ ‘" class="headerlink" title="å­—å…¸æ ‘"></a>å­—å…¸æ ‘</h3><blockquote><p>å­—å…¸æ ‘ä¸­ çˆ¶ç»“ç‚¹çš„å­©å­èŠ‚ç‚¹çš„ä¸ªæ•°ç­‰äºå­—ç¬¦é›†çš„å¤§å°ã€‚</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># å­—å…¸æ ‘</span><br><span class="line">class TreeNode:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.children = [None] * 26 # å­©å­èŠ‚ç‚¹çš„æ•°é‡</span><br><span class="line">        self.isEnd = False</span><br><span class="line"></span><br><span class="line">    def insert(self, word: str) -&gt; None:</span><br><span class="line">        node = self</span><br><span class="line">        for ch in word:</span><br><span class="line">            num = ord(ch)-ord(&#x27;a&#x27;) # asscii </span><br><span class="line">            if not node.children[num]: # å­©å­èŠ‚ç‚¹å¯¹åº”ä½ç½®ä¸ºç©º è¯´æ˜æ­¤å¤„æ²¡æœ‰å…ƒç´  æ‰§è¡Œæ’å…¥</span><br><span class="line">                node.children= TreeNode()</span><br><span class="line">            # æ’å…¥å®Œæˆ æˆ–è€… æ­¤å¤„å·²æœ‰å…ƒç´  è¿›å…¥ä¸‹ä¸€å±‚</span><br><span class="line">            node = node.children[num]</span><br><span class="line">        node.isEnd =True # æ’å…¥å®Œæˆ è®¾ç½®ä¸ºå¶å­ç»“ç‚¹</span><br></pre></td></tr></table></figure><h3 id="2çš„å¹‚"><a href="#2çš„å¹‚" class="headerlink" title="2çš„å¹‚"></a>2çš„å¹‚</h3><blockquote><p>ä¸€ä¸ªæ•°æ˜¯2çš„å¹‚ï¼Œå½“ä¸”ä»…å½“næ˜¯æ­£æ•´æ•°ï¼Œå¹¶ä¸”nçš„äºŒè¿›åˆ¶è¡¨ç¤ºä¸­åªåŒ…å«1ä¸ª1ã€‚</p><p>é‚£ä¹ˆå¦‚ä½•è®¡ç®—å‘¢ï¼Œæœ‰ä»¥ä¸‹ä¸¤ä¸ªç»“è®ºã€‚</p></blockquote><ol><li><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211028163510.png" alt="image-20211028163510268"></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># nå’Œn-1åšä¸è¿ç®— å¦‚æœç»“æœä¸º0 åˆ™nä¸º2çš„å¹‚</span><br><span class="line">n &amp; (n - 1) == 0 </span><br></pre></td></tr></table></figure><ol><li><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211028163553.png" alt="image-20211028163553103"></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># nå’Œ-nåšä¸è¿ç®— ç»“æœä¸ºnæœ¬èº« åˆ™nä¸º2çš„å¹‚</span><br><span class="line">n &amp; (-n) == n </span><br></pre></td></tr></table></figure><h3 id="Fisher-Yates-æ´—ç‰Œç®—æ³•"><a href="#Fisher-Yates-æ´—ç‰Œç®—æ³•" class="headerlink" title="Fisher-Yates æ´—ç‰Œç®—æ³•"></a>Fisher-Yates æ´—ç‰Œç®—æ³•</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// å¾ªç¯næ¬¡</span><br><span class="line">for (int i = 0; i &lt; nums.size(); ++i) &#123;</span><br><span class="line"># åœ¨[i,n)åŒºé—´æŠ½å–éšæœºä¸‹æ ‡j,ä½œä¸ºå¾…äº¤æ¢çš„å…ƒç´ ä¸‹æ ‡</span><br><span class="line">          int j = i + rand() % (nums.size() - i);</span><br><span class="line">          // nums[i,n-1]ä¸ºå¾…ä¹±åºçš„æ•°ç»„ [0,i-1]çš„éƒ¨åˆ†ä¸ºä¹±åºåçš„æ•°ç»„ã€‚</span><br><span class="line">          //äº¤æ¢ i jï¼ŒæŠŠéšæœºæŠ½å–çš„å…ƒç´ jæ”¾åˆ°içš„ä½ç½®ã€‚</span><br><span class="line">          swap(nums[i], nums[j]);</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><h3 id="äºŒå‰æœç´¢æ ‘"><a href="#äºŒå‰æœç´¢æ ‘" class="headerlink" title="äºŒå‰æœç´¢æ ‘"></a>äºŒå‰æœç´¢æ ‘</h3><blockquote><p>å·¦å­æ ‘ä¸¥æ ¼å°äºæ ¹ç»“ç‚¹ å³å­æ ‘ä¸¥æ ¼å¤§äºæ ¹ç»“ç‚¹</p></blockquote><ul><li>è¿­ä»£</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    TreeNode* searchBST(TreeNode* root, int val) &#123;</span><br><span class="line">        //éå†äºŒå‰æœç´¢æ ‘</span><br><span class="line">        // å·¦å­æ ‘ä¸¥æ ¼å°äºæ ¹ç»“ç‚¹ å³å­æ ‘ä¸¥æ ¼å¤§äºæ ¹ç»“ç‚¹</span><br><span class="line">        if (root==nullptr)</span><br><span class="line">            return NULL;</span><br><span class="line">        if (root-&gt;val == val)</span><br><span class="line">            return root;     </span><br><span class="line">        return searchBST(val &lt; root-&gt;val ? root-&gt;left : root-&gt;right, val);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul><li>é€’å½’</li></ul><blockquote><p>é€’å½’æ€§èƒ½å¥½ ç©ºé—´å¤æ‚åº¦ä½</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    TreeNode *searchBST(TreeNode *root, int val) &#123;</span><br><span class="line">        while (root) &#123;</span><br><span class="line">            if (val == root-&gt;val) &#123;</span><br><span class="line">                return root;</span><br><span class="line">            &#125;</span><br><span class="line">            root = val &lt; root-&gt;val ? root-&gt;left : root-&gt;right;</span><br><span class="line">        &#125;</span><br><span class="line">        return nullptr;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="è´ªå¿ƒ"><a href="#è´ªå¿ƒ" class="headerlink" title="è´ªå¿ƒ"></a>è´ªå¿ƒ</h3><ol><li>K æ¬¡å–ååæœ€å¤§åŒ–çš„æ•°ç»„å’Œ</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int largestSumAfterKNegations(vector&lt;int&gt;&amp; nums, int k) &#123;</span><br><span class="line">        int min_abs = 100;</span><br><span class="line">        int sum=0;</span><br><span class="line">        // æ‰¾å‡ºç»å¯¹å€¼æœ€å°çš„æ•°</span><br><span class="line">        for(auto num:nums)&#123;</span><br><span class="line">            if(abs(num)&lt;min_abs)</span><br><span class="line">                min_abs = abs(num);</span><br><span class="line">            sum+=num;</span><br><span class="line">        &#125;</span><br><span class="line">        sort(nums.begin(),nums.end());</span><br><span class="line">        // åˆ¤æ–­è´Ÿæ•°å’Œkçš„æ•°é‡å…³ç³»</span><br><span class="line">        for(int i=0;i&lt;nums.size()&amp;&amp; k;i++,k--)</span><br><span class="line">        &#123;</span><br><span class="line">            if(nums[i]&gt;0)</span><br><span class="line">                break;</span><br><span class="line">            // è´Ÿæ•° åè½¬</span><br><span class="line">            sum+=2*abs(nums[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        // åˆ¤æ–­kçš„å¤§å° å¦‚æœk&gt;0 è¯´æ˜ è´Ÿæ•°æ•°é‡å°äºk æ‰€æœ‰çš„ğŸ“–éƒ½å·²ç»å˜æˆæ­£æ•° åˆ™å¯¹å‰©ä½™æ¬¡æ•° åè½¬ è€ƒè™‘kçš„å¥‡å¶æ€§</span><br><span class="line">        // å¶æ•° ä¸å¤„ç† å¥‡æ•° åè½¬ç»å¯¹å€¼æœ€å°çš„æ•°ä¸ºè´Ÿæ•°</span><br><span class="line">        if(k&gt;0 &amp;&amp; k%2!=0)</span><br><span class="line">        &#123;</span><br><span class="line">            sum -= 2*min_abs;</span><br><span class="line">        &#125;</span><br><span class="line">return sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="å¿«é€Ÿä¹˜"><a href="#å¿«é€Ÿä¹˜" class="headerlink" title="å¿«é€Ÿä¹˜"></a>å¿«é€Ÿä¹˜</h3><p>å¿«é€Ÿå¹‚ ä½¿ç”¨è¿­ä»£å®ç°</p><blockquote><p>æ³¨æ„ è½¬æˆ long long ä¸ç„¶è´Ÿæ•°ä¼šæº¢å‡º int</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    // å¿«é€Ÿå¹‚</span><br><span class="line">    // è¿­ä»£å®ç° å°†nè½¬æˆäºŒè¿›åˆ¶è¡¨ç¤º</span><br><span class="line">    double quickMul(double x,long long N)</span><br><span class="line">    &#123;</span><br><span class="line">        double ans = 1.0;</span><br><span class="line">        // è´¡çŒ®çš„åˆå§‹å€¼ä¸º x</span><br><span class="line">        double x_contribute = x;</span><br><span class="line">        // åœ¨å¯¹ N è¿›è¡ŒäºŒè¿›åˆ¶æ‹†åˆ†çš„åŒæ—¶è®¡ç®—ç­”æ¡ˆ</span><br><span class="line">        while(N&gt;0)</span><br><span class="line">        &#123;</span><br><span class="line">            if(N&amp;1)//æœ€ä½ä½ä¸º1</span><br><span class="line">            &#123;</span><br><span class="line">               ans*=x_contribute; </span><br><span class="line">            &#125;</span><br><span class="line">            // å³ç§»ä¸€ä½</span><br><span class="line">            x_contribute*=x_contribute;</span><br><span class="line">            N=N&gt;&gt;1;</span><br><span class="line">        &#125;</span><br><span class="line">        return ans;</span><br><span class="line">    &#125;</span><br><span class="line">    double myPow(double x, int n) &#123;</span><br><span class="line">        long long N = n;</span><br><span class="line">        return N &gt;= 0 ? quickMul(x, N) : 1.0 / quickMul(x, -N);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="å›¾çš„DFSéå†"><a href="#å›¾çš„DFSéå†" class="headerlink" title="å›¾çš„DFSéå†"></a>å›¾çš„DFSéå†</h3><blockquote><p>ä¾‹å¦‚å²›å±¿æ•°é‡é—®é¢˜</p><ol><li>å²›å±¿æ•°é‡</li></ol></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">private:</span><br><span class="line">    void dfs(vector&lt;vector&lt;char&gt;&gt;&amp; grid, int r, int c) &#123;</span><br><span class="line">        // è¡Œåˆ—èŒƒå›´</span><br><span class="line">        int nr = grid.size();</span><br><span class="line">        int nc = grid[0].size();</span><br><span class="line">        </span><br><span class="line">        //å°†å·²ç»ä¾¿åˆ©è¿‡çš„å²›å±¿æ ‡è®°ä¸º2</span><br><span class="line">        grid[r][c] = &#x27;2&#x27;;</span><br><span class="line">        //åˆ¤æ–­è¾¹ç•Œæƒ…å†µ</span><br><span class="line">        if (r - 1 &gt;= 0 &amp;&amp; grid[r-1][c] == &#x27;1&#x27;) dfs(grid, r - 1, c);</span><br><span class="line">        if (r + 1 &lt; nr &amp;&amp; grid[r+1][c] == &#x27;1&#x27;) dfs(grid, r + 1, c);</span><br><span class="line">        if (c - 1 &gt;= 0 &amp;&amp; grid[r][c-1] == &#x27;1&#x27;) dfs(grid, r, c - 1);</span><br><span class="line">        if (c + 1 &lt; nc &amp;&amp; grid[r][c+1] == &#x27;1&#x27;) dfs(grid, r, c + 1);</span><br><span class="line">    &#125;</span><br><span class="line">public:</span><br><span class="line">    int numIslands(vector&lt;vector&lt;char&gt;&gt;&amp; grid) &#123;</span><br><span class="line">        // dfséå†</span><br><span class="line">        int nr = grid.size();</span><br><span class="line">        if (!nr) return 0;</span><br><span class="line">        int nc = grid[0].size();</span><br><span class="line"></span><br><span class="line">        int num_islands = 0;</span><br><span class="line">        //éå†æ‰€æœ‰ç‚¹ å¯æœç´¢çš„æ¬¡æ•°å°±æ˜¯ç‹¬ç«‹å—çš„æ•°é‡</span><br><span class="line">        for (int r = 0; r &lt; nr; ++r) &#123;</span><br><span class="line">            for (int c = 0; c &lt; nc; ++c) &#123;</span><br><span class="line">                // dfsæœç´¢æœªè®¿é—®è¿‡çš„å²›å±¿</span><br><span class="line">                if (grid[r][c] == &#x27;1&#x27;) &#123;</span><br><span class="line">                    ++num_islands;</span><br><span class="line">                    dfs(grid, r, c);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return num_islands;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul><li>å¯¹äºè¾¹ç•Œæƒ…å†µçš„å¤„ç†</li></ul><blockquote><p>å¯ä»¥ç”¨ <code>direc[4][2] = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;</code> å»éå†å››ä¸ªæ–¹å‘</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">int direc[4][2] = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;;</span><br><span class="line">        for (int i = 0; i &lt; 4; i++) &#123;</span><br><span class="line">            int nx = direc[i][0] + x, ny = direc[i][1] + y;</span><br><span class="line">            if (!(nx &gt;= 0 &amp;&amp; nx &lt; m &amp;&amp; ny &gt;= 0 &amp;&amp; ny &lt; n &amp;&amp; grid[nx][ny] == originalColor)) &#123;</span><br><span class="line">                isBorder = true;</span><br><span class="line">            &#125; else if (!visited[nx][ny]) &#123;</span><br><span class="line">                visited[nx][ny] = true;</span><br><span class="line">                dfs(grid, nx, ny, visited, borders, originalColor);</span><br><span class="line">            &#125;                </span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h3 id="æ»‘åŠ¨æ•°ç»„"><a href="#æ»‘åŠ¨æ•°ç»„" class="headerlink" title="æ»‘åŠ¨æ•°ç»„"></a>æ»‘åŠ¨æ•°ç»„</h3><blockquote><p>æ³¨æ„åŒºé—´èŒƒå›´çš„ä¸‹æ ‡ é—­åŒºé—´ [0,k-1] [k+1,2k-1]</p></blockquote><ol><li>ä¸‰ä¸ªæ— é‡å å­æ•°ç»„çš„æœ€å¤§å’Œ</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; maxSumOfThreeSubarrays(vector&lt;int&gt;&amp; nums, int k) &#123;</span><br><span class="line">        // æ»‘åŠ¨æ•°ç»„è§£å†³ 3ä¸ªæ•°ç»„ä¸é‡å  ç”±ç¬¬ä¸€ä¸ªæ•°ç»„æœ€å¤§å€¼--ç¬¬äºŒä¸ªæ•°ç»„æœ€å¤§å€¼--ç¬¬ä¸‰ä¸ªæ•°ç»„æœ€å¤§å€¼ã€‚</span><br><span class="line">        // è®°å½•æœ€å¤§å€¼æ—¶è®°å½•ä¸‹æ ‡ä½ç½®</span><br><span class="line">        // é•¿åº¦ä¸ºkçš„æ•°ç»„åŒºé—´[0,k-1] [k,2k-1] [2k,3k-1]</span><br><span class="line">        vector&lt;int&gt; ans; //ä¸‹æ ‡</span><br><span class="line">        int sum1 = 0, maxSum1 = 0, maxSum1Idx = 0;</span><br><span class="line">        int sum2 = 0, maxSum12 = 0, maxSum12Idx1 = 0, maxSum12Idx2 = 0;</span><br><span class="line">        int sum3 = 0, maxTotal = 0;</span><br><span class="line">        // æ»‘åŠ¨è®¡ç®—è¿‡ç¨‹</span><br><span class="line">        for(int i=2*k;i&lt;nums.size();i++)&#123;</span><br><span class="line">            // ä»ç¬¬ä¸‰ä¸ªæ•°ç»„èµ·å§‹ä¸‹æ ‡å¼€å§‹</span><br><span class="line">            // è®°å½•å„ä¸ªæ•°ç»„å†…éƒ¨å’Œ</span><br><span class="line">            sum1+=nums[i-2*k];</span><br><span class="line">            sum2+=nums[i-k];</span><br><span class="line">            sum3+=nums[i];</span><br><span class="line">            //è¶…è¶Šç¬¬ä¸‰ä¸ªæ•°ç»„é•¿åº¦ æ›´æ–°æ¯ä¸ªæ•°ç»„æœ€å¤§å€¼</span><br><span class="line">            if(i&gt;=3*k-1)&#123;</span><br><span class="line">                if(sum1&gt;maxSum1)&#123;</span><br><span class="line">                    maxSum1=sum1;</span><br><span class="line">                    maxSum1Idx=i-3*k+1;</span><br><span class="line">                &#125;</span><br><span class="line">                if(maxSum1 + sum2&gt;maxSum12)&#123;</span><br><span class="line">                    maxSum12=maxSum1+sum2;</span><br><span class="line">                    // åŒæ­¥æ›´æ–°</span><br><span class="line">                    maxSum12Idx1 = maxSum1Idx;</span><br><span class="line">                    maxSum12Idx2 = i-2*k+1;</span><br><span class="line">                &#125;</span><br><span class="line">                if(maxSum12 + sum3&gt;maxTotal)&#123;</span><br><span class="line">                    maxTotal = maxSum12 + sum3;</span><br><span class="line">                    ans = &#123;maxSum12Idx1 , maxSum12Idx2 , i-k+1&#125;;</span><br><span class="line">                &#125;</span><br><span class="line">            //å‡æ‰ä¸Šä¸€åŒºé—´æœ€å¼€å§‹çš„å…ƒç´ </span><br><span class="line">            sum1-=nums[i-3*k+1];</span><br><span class="line">            sum2-=nums[i-2*k+1];</span><br><span class="line">            sum3-=nums[i-k+1];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    return ans;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="é—°å¹´"><a href="#é—°å¹´" class="headerlink" title="é—°å¹´"></a>é—°å¹´</h3><p>è®¡ç®—é—°å¹´çš„ç®€å•æ–¹æ³•</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">year-(æœ€è¿‘çš„ä¸Šä¸€ä¸ªé—°å¹´+1)/4</span><br><span class="line"># å¯ä»¥è®¡ç®—å‡ºyearè·ç¦»å¾…è®¡ç®—æ—¥æœŸä¹‹é—´æœ‰å‡ æ¬¡é—°å¹´</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> ç®—æ³• </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>leetcodeæ¯æ—¥ä¸€é¢˜ï¼ˆæ›´æ–°ä¸­ï¼‰</title>
      <link href="/2022/01/04/leetcode%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/"/>
      <url>/2022/01/04/leetcode%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="ç®€å•"><a href="#ç®€å•" class="headerlink" title="ç®€å•"></a>ç®€å•</h1><h2 id="å‰‘æŒ‡-Offer-10-I-æ–æ³¢é‚£å¥‘æ•°åˆ—"><a href="#å‰‘æŒ‡-Offer-10-I-æ–æ³¢é‚£å¥‘æ•°åˆ—" class="headerlink" title="å‰‘æŒ‡ Offer 10- I. æ–æ³¢é‚£å¥‘æ•°åˆ—"></a>å‰‘æŒ‡ Offer 10- I. æ–æ³¢é‚£å¥‘æ•°åˆ—</h2><blockquote><p>ä¸èƒ½ä½¿ç”¨ç®€å•é€’å½’ ä¼šè¶…æ—¶</p><p>ä½¿ç”¨åŠ¨æ€è§„åˆ’æ±‚è§£</p><p>ç”±äº F(n) åªå’Œ F(nâˆ’1) ä¸ F(nâˆ’2) æœ‰å…³ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨ã€Œæ»šåŠ¨æ•°ç»„æ€æƒ³ã€æŠŠç©ºé—´å¤æ‚åº¦ä¼˜åŒ–æˆ O(1)ã€‚</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def fib(self, n: int) -&gt; int:</span><br><span class="line">        # è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œç­”æ¡ˆéœ€è¦å–æ¨¡  1e9+7</span><br><span class="line">        MOD = 10 ** 9 + 7</span><br><span class="line">        if n &lt; 2:</span><br><span class="line">            return n</span><br><span class="line">        else:</span><br><span class="line">            # ä½¿ç”¨æ»šåŠ¨æ•°ç»„å‡å°ç©ºé—´å¤æ‚åº¦</span><br><span class="line">            # f0=0 f1=1</span><br><span class="line">            p = 0</span><br><span class="line">            q = 0</span><br><span class="line">            r = 1</span><br><span class="line">            for i in range(2, n + 1):</span><br><span class="line">                p = q</span><br><span class="line">                q = r</span><br><span class="line">                r = (p + q) % MOD</span><br><span class="line">            return r</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    n = 100</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.fib(n)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="å‰‘æŒ‡-Offer-II-069-å±±å³°æ•°ç»„çš„é¡¶éƒ¨"><a href="#å‰‘æŒ‡-Offer-II-069-å±±å³°æ•°ç»„çš„é¡¶éƒ¨" class="headerlink" title="å‰‘æŒ‡ Offer II 069. å±±å³°æ•°ç»„çš„é¡¶éƒ¨"></a>å‰‘æŒ‡ Offer II 069. å±±å³°æ•°ç»„çš„é¡¶éƒ¨</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def peakIndexInMountainArray(self, arr: List[int]) -&gt; int:</span><br><span class="line">        s_len = len(arr)</span><br><span class="line">        left=0</span><br><span class="line">        right=s_len-2</span><br><span class="line">        ans=1</span><br><span class="line">        while left &lt;= right:</span><br><span class="line">            mid = (left+right)//2</span><br><span class="line">            if arr[mid]&gt;arr[mid+1]:</span><br><span class="line">                ans = mid</span><br><span class="line">                right = mid - 1 </span><br><span class="line">            else:</span><br><span class="line">                left =mid +1</span><br><span class="line">        return ans</span><br></pre></td></tr></table></figure><h2 id="141-ç¯å½¢é“¾è¡¨"><a href="#141-ç¯å½¢é“¾è¡¨" class="headerlink" title="141. ç¯å½¢é“¾è¡¨"></a>141. ç¯å½¢é“¾è¡¨</h2><blockquote><p><strong>STLå®¹å™¨</strong></p><p>setå’Œunordered_setï¼šå…¶ä¸­unordered_setå¯¹å…ƒç´ ä¸è¿›è¡Œæ’åº</p><p>find(key)ï¼šæŸ¥æ‰¾ä»¥å€¼ä¸º key çš„å…ƒç´ ï¼Œå¦‚æœæ‰¾åˆ°ï¼Œåˆ™è¿”å›ä¸€ä¸ªæŒ‡å‘è¯¥å…ƒç´ çš„æ­£å‘è¿­ä»£å™¨ï¼›åä¹‹ï¼Œåˆ™è¿”å›ä¸€ä¸ªæŒ‡å‘å®¹å™¨ä¸­æœ€åä¸€ä¸ªå…ƒç´ ä¹‹åä½ç½®çš„è¿­ä»£å™¨ï¼ˆå¦‚end() æ–¹æ³•è¿”å›çš„è¿­ä»£å™¨ï¼‰ã€‚</p><p>count(key)ï¼šåœ¨å®¹å™¨ä¸­æŸ¥æ‰¾å€¼ä¸º key çš„å…ƒç´ çš„ä¸ªæ•°ã€‚</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition for singly-linked list.</span><br><span class="line"> * struct ListNode &#123;</span><br><span class="line"> *     int val;</span><br><span class="line"> *     ListNode *next;</span><br><span class="line"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span><br><span class="line"> * &#125;;</span><br><span class="line"> */</span><br><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    bool hasCycle(ListNode *head) &#123;</span><br><span class="line">        // éå†é“¾è¡¨ å°†è®¿é—®è¿‡çš„èŠ‚ç‚¹å­˜åˆ°å“ˆå¸Œè¡¨ å¦‚æœèŠ‚ç‚¹è¢«å¤šæ¬¡è®¿é—® åˆ™å­˜åœ¨ç¯    </span><br><span class="line">        set&lt;ListNode*&gt; nodes;</span><br><span class="line">        while(head!=nullptr)</span><br><span class="line">        &#123;</span><br><span class="line">            // å¦‚æœsetä¸­æ‰¾ä¸åˆ°æŒ‡å®šå…ƒç´  è¿”å›nodes.end()</span><br><span class="line">            if(nodes.find(head)!=nodes.end())</span><br><span class="line">                return true;</span><br><span class="line">            // count(head) åœ¨å®¹å™¨ä¸­æŸ¥æ‰¾å€¼ä¸º key çš„å…ƒç´ çš„ä¸ªæ•°ã€‚</span><br><span class="line">            // if (nodes.count(head)) &#123;</span><br><span class="line">            //     return true;</span><br><span class="line">            // &#125;</span><br><span class="line">            nodes.insert(head);</span><br><span class="line">            head=head-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="268-ä¸¢å¤±çš„æ•°å­—"><a href="#268-ä¸¢å¤±çš„æ•°å­—" class="headerlink" title="268. ä¸¢å¤±çš„æ•°å­—"></a>268. ä¸¢å¤±çš„æ•°å­—</h2><blockquote><p>stlä¸­vectorçš„æ’åº<code>sort(nums.begin(), nums.end());</code></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int missingNumber(vector&lt;int&gt;&amp; nums) &#123;</span><br><span class="line">        // å…ˆæ’åº </span><br><span class="line">        sort(nums.begin(), nums.end());</span><br><span class="line">        // for (int v:nums)</span><br><span class="line">        //     cout&lt;&lt;v;</span><br><span class="line">        // éå†å¯¹åº”ä½ç½® ç´¢å¼•ä¸æ•°ç»„å€¼ä¸å¯¹åº” åˆ™è¿”å›è¯¥ç´¢å¼•</span><br><span class="line">        for (int i=0;i&lt;nums.size();i++)&#123;</span><br><span class="line">            if (nums[i]!=i)</span><br><span class="line">                return i;</span><br><span class="line">        &#125;</span><br><span class="line">        return nums.size();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="405-æ•°å­—è½¬æ¢ä¸ºåå…­è¿›åˆ¶æ•°"><a href="#405-æ•°å­—è½¬æ¢ä¸ºåå…­è¿›åˆ¶æ•°" class="headerlink" title="405. æ•°å­—è½¬æ¢ä¸ºåå…­è¿›åˆ¶æ•°"></a>405. æ•°å­—è½¬æ¢ä¸ºåå…­è¿›åˆ¶æ•°</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    </span><br><span class="line">    def toHex(self, num: int) -&gt; str:</span><br><span class="line">        CONV = &quot;0123456789abcdef&quot;</span><br><span class="line">        ans =[]</span><br><span class="line">        # 32ä½äºŒè¿›åˆ¶æ•° è½¬æˆåå…­è¿›åˆ¶ å…±8ä½ 4*8</span><br><span class="line">        for _ in range(8): </span><br><span class="line">            temp = num % 16</span><br><span class="line">            num = num//16</span><br><span class="line">            ans.append(temp)</span><br><span class="line">            if not num:</span><br><span class="line">                break</span><br><span class="line">        # å€’ç€è¾“å‡º</span><br><span class="line">        return &#x27;&#x27;.join(CONV[j] for j in ans[::-1])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="434-å­—ç¬¦ä¸²ä¸­çš„å•è¯æ•°"><a href="#434-å­—ç¬¦ä¸²ä¸­çš„å•è¯æ•°" class="headerlink" title="434. å­—ç¬¦ä¸²ä¸­çš„å•è¯æ•°"></a>434. å­—ç¬¦ä¸²ä¸­çš„å•è¯æ•°</h2><blockquote><p>æ³¨æ„ï¼špythonä¸­split()å‡½æ•°ç”¨æ³•</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a=&quot;     &quot;</span><br><span class="line">a.split() # æŒ‰ç…§ç©ºæ ¼åˆ†å‰² åˆ†å‰²å®Œåˆ é™¤ç©ºå­—ç¬¦ä¸²</span><br><span class="line">a.split() # æŒ‰ç…§ç©ºæ ¼åˆ†å‰² ä½†åªæ˜¯æŒ‰ç…§å•ä¸ªç©ºæ ¼åˆ†å‰² åˆ†å‰²åå­—ç¬¦ä¸²ä¸­ä¼šåŒ…å«ç©ºå­—ç¬¦ä¸²</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def countSegments(self, s: str) -&gt; int:</span><br><span class="line">        ans =0 </span><br><span class="line">        # s=s.strip()</span><br><span class="line">        for i in range(len(s)):</span><br><span class="line">            </span><br><span class="line">            if(s[i]==&quot; &quot; and s[i-1]!=&quot; &quot; and i&gt;0) or (i==(len(s)-1) and s[i]!=&quot; &quot;):</span><br><span class="line">                ans+=1</span><br><span class="line">        return ans </span><br><span class="line">        # return len(s.split())</span><br></pre></td></tr></table></figure><h2 id="496-ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´ -I"><a href="#496-ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´ -I" class="headerlink" title="496. ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´  I"></a>496. ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´  I</h2><blockquote><p>æ—¶é—´å¤æ‚åº¦è¾ƒä½çš„è§£æ³•ï¼Œä½¿ç”¨ å•è°ƒæ ˆ + å“ˆå¸Œè¡¨</p><p>åº”ä¸ºnums2ä¸­æ²¡æœ‰é‡å¤çš„å…ƒç´ ï¼Œæ„é€ ä¸¥æ ¼å•è°ƒé€’å¢çš„æ ˆ å¹¶å°†æ ˆä¸­çš„å€¼ä¸å°äºè‡ªèº«çš„å€¼ å¯¹åº”å…³ç³»å­˜å‚¨åˆ°å“ˆå¸Œè¡¨</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def nextGreaterElement(self, nums1: List[int], nums2: List[int]) -&gt; List[int]:</span><br><span class="line">        res = &#123;&#125;</span><br><span class="line">        stack = []</span><br><span class="line">        for num in reversed(nums2):</span><br><span class="line">            while stack and num &gt;= stack[-1]:</span><br><span class="line">                stack.pop()</span><br><span class="line">            res[num] = stack[-1] if stack else -1</span><br><span class="line">            stack.append(num)</span><br><span class="line">        return [res[num] for num in nums1]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="598-èŒƒå›´æ±‚å’Œ-II"><a href="#598-èŒƒå›´æ±‚å’Œ-II" class="headerlink" title="598. èŒƒå›´æ±‚å’Œ II"></a>598. èŒƒå›´æ±‚å’Œ II</h2><blockquote><p>æ±‚å‡ºåŒºé—´äº¤é›†å³å¯</p><p>ç”¨ä¸ç€æš´åŠ›æ¨¡æ‹Ÿ è€Œä¸”ä¼šè¶…æ—¶</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int maxCount(int m, int n, vector&lt;vector&lt;int&gt;&gt;&amp; ops) &#123;</span><br><span class="line">        // æ±‚è§£ å¯¹äºmxnçš„çŸ©é˜µM æ“ä½œçš„äº¤é›†åŒºé—´ å³ä¸ºæœ€å¤§å€¼åŒºé—´</span><br><span class="line">        int max_a=m,max_b=n;</span><br><span class="line">        for(vector&lt;int&gt;op : ops)</span><br><span class="line">        &#123;</span><br><span class="line">            max_a = min(op[0],max_a);</span><br><span class="line">            max_b=min(op[1],max_b);</span><br><span class="line">        &#125;</span><br><span class="line">        return max_b*max_a;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="700-äºŒå‰æœç´¢æ ‘ä¸­çš„æœç´¢"><a href="#700-äºŒå‰æœç´¢æ ‘ä¸­çš„æœç´¢" class="headerlink" title="700. äºŒå‰æœç´¢æ ‘ä¸­çš„æœç´¢"></a>700. äºŒå‰æœç´¢æ ‘ä¸­çš„æœç´¢</h2><blockquote><p>å·¦å­æ ‘ä¸¥æ ¼å°äºæ ¹ç»“ç‚¹ å³å­æ ‘ä¸¥æ ¼å¤§äºæ ¹ç»“ç‚¹</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    TreeNode* searchBST(TreeNode* root, int val) &#123;</span><br><span class="line">        //éå†äºŒå‰æœç´¢æ ‘</span><br><span class="line">        // å·¦å­æ ‘ä¸¥æ ¼å°äºæ ¹ç»“ç‚¹ å³å­æ ‘ä¸¥æ ¼å¤§äºæ ¹ç»“ç‚¹</span><br><span class="line">        if (root==nullptr)</span><br><span class="line">            return NULL;</span><br><span class="line">        if (root-&gt;val == val)</span><br><span class="line">            return root;     </span><br><span class="line">        return searchBST(val &lt; root-&gt;val ? root-&gt;left : root-&gt;right, val);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="704-äºŒåˆ†æŸ¥æ‰¾"><a href="#704-äºŒåˆ†æŸ¥æ‰¾" class="headerlink" title="704. äºŒåˆ†æŸ¥æ‰¾"></a>704. äºŒåˆ†æŸ¥æ‰¾</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def search(self, nums: List[int], target: int) -&gt; int:</span><br><span class="line">        low, high = 0, len(nums) - 1</span><br><span class="line">        while low &lt;= high:</span><br><span class="line">            # ç¡®ä¿åœ¨åŸæ•°ç»„æ“ä½œ</span><br><span class="line">            mid = (high - low) // 2 + low</span><br><span class="line">            num = nums[mid]</span><br><span class="line">            if num == target:</span><br><span class="line">                return mid</span><br><span class="line">            elif num &gt; target:</span><br><span class="line">                high = mid - 1</span><br><span class="line">            else:</span><br><span class="line">                low = mid + 1</span><br><span class="line">        return -1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    nums = [-1, 0, 3, 5, 9, 12]</span><br><span class="line">    target = 9</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.search(nums, target)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="1221-åˆ†å‰²å¹³è¡¡å­—ç¬¦ä¸²"><a href="#1221-åˆ†å‰²å¹³è¡¡å­—ç¬¦ä¸²" class="headerlink" title="1221. åˆ†å‰²å¹³è¡¡å­—ç¬¦ä¸²"></a>1221. åˆ†å‰²å¹³è¡¡å­—ç¬¦ä¸²</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def balancedStringSplit(self, s: str) -&gt; int:</span><br><span class="line">        s_list = list(s)</span><br><span class="line">        ch = 0</span><br><span class="line">        ans = 0</span><br><span class="line">        # éå†å­—ç¬¦ä¸² ç»Ÿè®¡ä¸¤ç§å­—ç¬¦å‡ºç°æ•°é‡ä¹‹å·® ch=0æ—¶ è¯´æ˜å‰ç¼€å­—ç¬¦ä¸²æ•°é‡ç›¸åŒ æ„æˆå¹³è¡¡å­—ç¬¦ä¸² ans+1</span><br><span class="line">        for i in s_list:</span><br><span class="line">            if i == &#x27;R&#x27;:</span><br><span class="line">                ch += 1</span><br><span class="line">            else:</span><br><span class="line">                ch -= 1</span><br><span class="line">            if ch == 0:</span><br><span class="line">                ans += 1</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    s = &quot;RLRRLLRLRL&quot;</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.balancedStringSplit(s)</span><br><span class="line">    print(b)</span><br></pre></td></tr></table></figure><h3 id="1436-æ—…è¡Œç»ˆç‚¹ç«™"><a href="#1436-æ—…è¡Œç»ˆç‚¹ç«™" class="headerlink" title="1436. æ—…è¡Œç»ˆç‚¹ç«™"></a>1436. æ—…è¡Œç»ˆç‚¹ç«™</h3><blockquote><p>æ³¨æ„ å¦‚æœç”¨ä¸‹é¢çš„åŠæ³• å­—å…¸éœ€è¦éå†ä¸¤é</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def destCity(self, paths: List[List[str]]) -&gt; str:</span><br><span class="line"></span><br><span class="line">        city_dict = dict()</span><br><span class="line">        for i in paths:</span><br><span class="line">            if city_dict.get(i[1]):</span><br><span class="line">                city_dict[i[1]] += 1</span><br><span class="line">            else:</span><br><span class="line">                city_dict[i[1]] = 1</span><br><span class="line">        for i in paths:</span><br><span class="line">            if city_dict.get(i[0]):</span><br><span class="line">                city_dict[i[0]] -= 1</span><br><span class="line">        # è¾“å‡ºå€¼ä¸º1çš„åŸå¸‚</span><br><span class="line">        for k, v in city_dict.items():</span><br><span class="line">            if v == 1:</span><br><span class="line">                return k</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    root = [[&quot;B&quot;, &quot;C&quot;], [&quot;D&quot;, &quot;B&quot;], [&quot;C&quot;, &quot;A&quot;]]</span><br><span class="line">    targetSum = 8</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.destCity(root)</span><br><span class="line">    print(b)</span><br></pre></td></tr></table></figure><h1 id="ä¸€èˆ¬"><a href="#ä¸€èˆ¬" class="headerlink" title="ä¸€èˆ¬"></a>ä¸€èˆ¬</h1><h2 id="é¢è¯•é¢˜-17-14-æœ€å°Kä¸ªæ•°"><a href="#é¢è¯•é¢˜-17-14-æœ€å°Kä¸ªæ•°" class="headerlink" title="é¢è¯•é¢˜ 17.14. æœ€å°Kä¸ªæ•°"></a>é¢è¯•é¢˜ 17.14. æœ€å°Kä¸ªæ•°</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def smallestK(self, arr: List[int], k: int) -&gt; List[int]:</span><br><span class="line">        if k &gt; 0 and k &lt; len(arr):</span><br><span class="line">            arr.sort()</span><br><span class="line">            return arr[0:k]</span><br><span class="line">        else:</span><br><span class="line">            return []</span><br></pre></td></tr></table></figure><blockquote><p>ç”±äº C++ è¯­è¨€ä¸­çš„å †ï¼ˆå³ä¼˜å…ˆé˜Ÿåˆ—ï¼‰ä¸ºå¤§æ ¹å †ï¼Œè€Œ Python è¯­è¨€ä¸­çš„å †ä¸ºå°æ ¹å †ï¼Œå› æ­¤æˆ‘ä»¬è¦å¯¹æ•°ç»„ä¸­æ‰€æœ‰çš„æ•°å–å…¶ç›¸åæ•°ï¼Œæ‰èƒ½ä½¿ç”¨å°æ ¹å †ç»´æŠ¤å‰ k å°å€¼ã€‚ã€</p></blockquote><h1 id="ä¸­ç­‰"><a href="#ä¸­ç­‰" class="headerlink" title="ä¸­ç­‰"></a>ä¸­ç­‰</h1><h2 id="ğŸŒŸ29-ä¸¤æ•°ç›¸é™¤"><a href="#ğŸŒŸ29-ä¸¤æ•°ç›¸é™¤" class="headerlink" title="ğŸŒŸ29. ä¸¤æ•°ç›¸é™¤"></a>ğŸŒŸ29. ä¸¤æ•°ç›¸é™¤</h2><blockquote><p>æœ‰ç‚¹æ²¡æ€è·¯</p></blockquote><p>é¢˜è§£ï¼š</p><ul><li>å¦‚æœæˆ‘ä»¬å°†è¢«é™¤æ•°å’Œé™¤æ•°éƒ½å˜ä¸ºæ­£æ•°ï¼Œé‚£ä¹ˆå¯èƒ½ä¼šå¯¼è‡´æº¢å‡ºã€‚ä¾‹å¦‚å½“è¢«é™¤æ•°ä¸º $-2^{31}$ æ—¶ï¼Œå®ƒçš„ç›¸åæ•° $2^{31}$äº§ç”Ÿäº†æº¢å‡ºã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘å°†è¢«é™¤æ•°å’Œé™¤æ•°éƒ½å˜ä¸ºè´Ÿæ•°ï¼Œè¿™æ ·å°±ä¸ä¼šæœ‰æº¢å‡ºçš„é—®é¢˜ï¼Œåœ¨ç¼–ç æ—¶åªéœ€è¦è€ƒè™‘ 1 ç§æƒ…å†µäº†ã€‚</li><li>ä½¿ç”¨å¿«é€Ÿä¹˜å®ç°ä¹˜æ³•è¿ç®—ã€‚å¿«é€Ÿä¹˜å®é™…ä¸Šæ˜¯é€šè¿‡åŠ æ³•è¿ç®—å®ç°çš„ã€‚</li></ul><p>å®˜æ–¹é¢˜è§£è¿˜æ˜¯æœ‰ç‚¹æ‡µï¼Œæ‰¾åˆ°ä¸€ç¯‡æ€è·¯ç®€å•çš„é¢˜è§£ï¼š</p><ul><li>ä¸¾ä¸ªä¾‹å­ï¼š11 é™¤ä»¥ 3 ã€‚<br>é¦–å…ˆ11æ¯”3å¤§ï¼Œç»“æœè‡³å°‘æ˜¯1ï¼Œ ç„¶åæˆ‘è®©3ç¿»å€ï¼Œå°±æ˜¯6ï¼Œå‘ç°11æ¯”3ç¿»å€åè¿˜è¦å¤§ï¼Œé‚£ä¹ˆç»“æœå°±è‡³å°‘æ˜¯2äº†ï¼Œé‚£æˆ‘è®©è¿™ä¸ª6å†ç¿»å€ï¼Œå¾—12ï¼Œ11ä¸æ¯”12å¤§ï¼Œå“æ­»æˆ‘äº†ï¼Œå·®ç‚¹è®©å°±è®©åˆšæ‰çš„æœ€å°è§£2ä¹Ÿç¿»å€å¾—åˆ°4äº†ã€‚ä½†æ˜¯æˆ‘çŸ¥é“æœ€ç»ˆç»“æœè‚¯å®šåœ¨2å’Œ4ä¹‹é—´ã€‚ä¹Ÿå°±æ˜¯è¯´2å†åŠ ä¸ŠæŸä¸ªæ•°ï¼Œè¿™ä¸ªæ•°æ˜¯å¤šå°‘å‘¢ï¼Ÿæˆ‘è®©11å‡å»åˆšæ‰æœ€åä¸€æ¬¡çš„ç»“æœ6ï¼Œå‰©ä¸‹5ï¼Œæˆ‘ä»¬è®¡ç®—5æ˜¯3çš„å‡ å€ï¼Œä¹Ÿå°±æ˜¯é™¤æ³•ï¼Œçœ‹ï¼Œé€’å½’å‡ºç°äº†ã€‚</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int divide(int dividend, int divisor) &#123;</span><br><span class="line">        if(dividend == 0) return 0;</span><br><span class="line">        if(divisor == 1) return dividend;</span><br><span class="line">        if(divisor == -1)&#123;</span><br><span class="line">            if(dividend&gt;INT_MIN) return -dividend;// åªè¦ä¸æ˜¯æœ€å°çš„é‚£ä¸ªæ•´æ•°ï¼Œéƒ½æ˜¯ç›´æ¥è¿”å›ç›¸åæ•°å°±å¥½å•¦</span><br><span class="line">            return INT_MAX;// æ˜¯æœ€å°çš„é‚£ä¸ªï¼Œé‚£å°±è¿”å›æœ€å¤§çš„æ•´æ•°å•¦</span><br><span class="line">        &#125;</span><br><span class="line">        long a = dividend;</span><br><span class="line">        long b = divisor;</span><br><span class="line">        int sign = 1; </span><br><span class="line">        if((a&gt;0&amp;&amp;b&lt;0) || (a&lt;0&amp;&amp;b&gt;0))&#123;</span><br><span class="line">            sign = -1;</span><br><span class="line">        &#125;</span><br><span class="line">        a = a&gt;0?a:-a;</span><br><span class="line">        b = b&gt;0?b:-b;</span><br><span class="line">        long res = div(a,b);</span><br><span class="line">        if(sign&gt;0)return res&gt;INT_MAX?INT_MAX:res;</span><br><span class="line">        return -res;</span><br><span class="line">    &#125;</span><br><span class="line">    int div(long a, long b)&#123;  // ä¼¼ä¹ç²¾é«“å’Œéš¾ç‚¹å°±åœ¨äºä¸‹é¢è¿™å‡ å¥</span><br><span class="line">        if(a&lt;b) return 0;</span><br><span class="line">        long count = 1;</span><br><span class="line">        long tb = b; // åœ¨åé¢çš„ä»£ç ä¸­ä¸æ›´æ–°b</span><br><span class="line">        while((tb+tb)&lt;=a)&#123;</span><br><span class="line">            count = count + count; // æœ€å°è§£ç¿»å€</span><br><span class="line">            tb = tb+tb; // å½“å‰æµ‹è¯•çš„å€¼ä¹Ÿç¿»å€</span><br><span class="line">        &#125;</span><br><span class="line">        return count + div(a-tb,b);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def divide(self, dividend: int, divisor: int) -&gt; int:</span><br><span class="line">        # è¾¹ç•Œæƒ…å†µ </span><br><span class="line">        INT_MIN = -(2&lt;&lt;30)</span><br><span class="line">        INI_MAX = (2&lt;&lt;30)-1</span><br><span class="line">        # åˆ¤æ–­ç‰¹æ®Šæƒ…å†µ</span><br><span class="line">        # è¢«é™¤æ•°ä¸º0</span><br><span class="line">        if dividend==0:</span><br><span class="line">            return 0</span><br><span class="line">        if divisor==-1:</span><br><span class="line">            # INT_MIN/-1 ä¸º2^31 æ­£æ•°è¶Šç•Œ</span><br><span class="line">            if dividend == INT_MIN:</span><br><span class="line">                return INI_MAX</span><br><span class="line">            return -dividend</span><br><span class="line">        # æ–¹ä¾¿åé¢æ‰¾å€æ•°å…³ç³» è½¬ä¸ºæ­£æ•°è®¡ç®—</span><br><span class="line">        # è®°å½•ç¬¦å·</span><br><span class="line">        sign = -1</span><br><span class="line">        if (dividend&gt;0 and  divisor&gt;0 ) or (dividend&lt;0 and divisor&lt;0):</span><br><span class="line">            sign = 1</span><br><span class="line">        dividend = dividend if dividend&gt;0 else -dividend</span><br><span class="line">        divisor = divisor if divisor&gt;0 else -divisor</span><br><span class="line">        # è®¡ç®—ç»“æœ</span><br><span class="line">        # print(dividend,divisor)</span><br><span class="line">        ans = self.div(dividend,divisor)</span><br><span class="line"></span><br><span class="line">        if sign == 1:</span><br><span class="line">                return ans</span><br><span class="line">        else:</span><br><span class="line">                return -ans</span><br><span class="line"></span><br><span class="line">    def div(self,x,y):</span><br><span class="line">        # åˆ¤æ–­ x/yå¯ä»¥é™¤å‡ è½® ä¸èƒ½ç”¨é™¤å· ç”¨å€æ•°æ¥ä»£æ›¿</span><br><span class="line">        if x&lt;y :</span><br><span class="line">            return 0 </span><br><span class="line">        # x &gt; y xä¸­è‡³å°‘åŒ…å«ä¸€ä¸ªy</span><br><span class="line">        times =1</span><br><span class="line">        ty= y</span><br><span class="line">        while (ty&lt;&lt;1) &lt;= x:</span><br><span class="line">            times += times</span><br><span class="line">            ty = ty&lt;&lt;1</span><br><span class="line">        return times + self.div(x-ty,y)</span><br></pre></td></tr></table></figure><h2 id="36-æœ‰æ•ˆçš„æ•°ç‹¬"><a href="#36-æœ‰æ•ˆçš„æ•°ç‹¬" class="headerlink" title="36. æœ‰æ•ˆçš„æ•°ç‹¬"></a>36. æœ‰æ•ˆçš„æ•°ç‹¬</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def isValidSudoku(self, board: List[List[str]]) -&gt; bool:</span><br><span class="line"></span><br><span class="line">        dict_col = &#123;&#125;</span><br><span class="line">        # å…ˆè¿›è¡Œè¡Œæ£€æµ‹ ç¡®ä¿ä¸å‡ºç°é‡å¤æ•°å­—</span><br><span class="line">        row = self.signal_num(board)</span><br><span class="line">        # print(row)</span><br><span class="line">        if row:</span><br><span class="line">            # å†è¿›è¡Œåˆ—æ£€æµ‹ ç¡®ä¿æ¯ä¸€åˆ—æ•°æ®ä¸åŒ…å«é‡å¤æ•°å­—</span><br><span class="line">            #  çŸ©é˜µè½¬ç½®</span><br><span class="line">            t_board = np.transpose(np.array(board))</span><br><span class="line">            col = self.signal_num(list(t_board))</span><br><span class="line">            # print(col)</span><br><span class="line">            if col:</span><br><span class="line">                # åˆ¤æ–­3x3 åŒºé—´æ˜¯å¦æœ‰é‡å¤æ•°å­—</span><br><span class="line">                # ä½¿ç”¨numpyå®ç°çŸ©é˜µåˆ‡ç‰‡</span><br><span class="line">                np_board = np.transpose(np.array(board))</span><br><span class="line">                # print(np_board)</span><br><span class="line">                for j in range(3):</span><br><span class="line">                    for i in range(3):</span><br><span class="line">                        index_i = i * 3</span><br><span class="line">                        index_j = j * 3</span><br><span class="line">                        new_board = np_board[index_i:index_i + 3, index_j:index_j + 3]</span><br><span class="line">                        # çŸ©é˜µå±•å¼€æˆä¸€çº¬åº¦</span><br><span class="line">                        d1_new_board = new_board.flatten()</span><br><span class="line">                        # print(d1_new_board)</span><br><span class="line">                        if not self.signal_num(list([d1_new_board])):</span><br><span class="line">                            return False</span><br><span class="line">            else:</span><br><span class="line">                return False</span><br><span class="line"></span><br><span class="line">        else:</span><br><span class="line">            return False</span><br><span class="line">        return True</span><br><span class="line"></span><br><span class="line">    def signal_num(self, board_self: List[List[str]]) -&gt; bool:</span><br><span class="line">        for row in board_self:</span><br><span class="line">            dict_row = &#123;&#125;</span><br><span class="line">            for i in row:</span><br><span class="line">                if i != &#x27;.&#x27; and dict_row.get(i):</span><br><span class="line">                    return False</span><br><span class="line">                else:</span><br><span class="line">                    dict_row[i] = i</span><br><span class="line">        return True</span><br></pre></td></tr></table></figure><h2 id="38-å¤–è§‚æ•°åˆ—"><a href="#38-å¤–è§‚æ•°åˆ—" class="headerlink" title="38. å¤–è§‚æ•°åˆ—"></a>38. å¤–è§‚æ•°åˆ—</h2><blockquote><p>å¯ä»¥å½“ä½œåŒæŒ‡é’ˆæ¥åš ä¸€ä¸ªè®°å½•å¼€å§‹ä½ç½® ä¸€ä¸ªè®°å½•ç»“æŸä¸ºæ­¢ ç›¸å‡å³ä¸ºå­—ç¬¦ä¸²é•¿åº¦</p><p>å¾ªç¯æ¬¡æ•°ä¸ç¡®å®šçš„æ—¶å€™è¦ç”¨ <strong>while</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def countAndSay(self, n: int) -&gt; str:</span><br><span class="line">        prev = &quot;1&quot;</span><br><span class="line">        # å¾ªç¯n-1æ¬¡ å› ä¸ºç¬¬ä¸€æ¬¡ä¸ºç¡®å®šçš„&#x27;1&#x27;</span><br><span class="line">        # æ¯æ¬¡å¾ªç¯è§£é‡Š prev</span><br><span class="line">        for i in range(n - 1):</span><br><span class="line">            curr = &quot;&quot;</span><br><span class="line">            pos = 0</span><br><span class="line">            start = 0</span><br><span class="line"></span><br><span class="line">            while pos &lt; len(prev):</span><br><span class="line">                while pos &lt; len(prev) and prev[pos] == prev[start]:</span><br><span class="line">                    pos += 1</span><br><span class="line">                curr += str(pos - start) + prev[start]</span><br><span class="line">                start = pos</span><br><span class="line">            prev = curr</span><br><span class="line"></span><br><span class="line">        return prev</span><br></pre></td></tr></table></figure><h2 id="46-å…¨æ’åˆ—"><a href="#46-å…¨æ’åˆ—" class="headerlink" title="46. å…¨æ’åˆ—"></a>46. å…¨æ’åˆ—</h2><blockquote><p>å›æº¯</p><p>å…¶ä¸­è¦æ³¨æ„ python ä¸­æ•°ç»„æ‹·è´è¦ç”¨ new = old[:]</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import copy</span><br><span class="line">class Solution:</span><br><span class="line">    def permute(self, nums: List[int]) -&gt; List[List[int]]:</span><br><span class="line">        # å›æº¯ç®—æ³•å®ç°</span><br><span class="line">        # å®šä¹‰ä¸€ä¸ªå¸ƒå°”æ•°ç»„ æ ‡è®°æ¯ä¸ªèŠ‚ç‚¹çš„è®¿é—®çŠ¶æ€</span><br><span class="line">        used = [False for i in range(len(nums))]</span><br><span class="line"></span><br><span class="line">        # def</span><br><span class="line">        depth = 0 #éå†å±‚çš„æ·±åº¦</span><br><span class="line">        res=[]</span><br><span class="line">        len_nums = len(nums) </span><br><span class="line">        path=[]</span><br><span class="line">        def dfs(depth,len_nums,path):</span><br><span class="line">            if depth == len_nums:</span><br><span class="line">                # éå†åˆ°æœ€åä¸€å±‚ æ·»åŠ ä¸€ä¸ªæ’åˆ—ç»“æœ</span><br><span class="line">                # ç”¨pathä¼šå‡ºé”™ å¿…é¡»ç”¨ path[:] å®ƒå¤åˆ¶åˆ—è¡¨oldåˆ°new</span><br><span class="line">                res.append(path[:])</span><br><span class="line">            for i in range(len_nums):</span><br><span class="line">                if  used[i]:</span><br><span class="line">                    continue</span><br><span class="line">                else:</span><br><span class="line">                    path.append(nums[i])</span><br><span class="line">                    used[i]=True</span><br><span class="line">                    dfs(depth+1,len_nums,path)</span><br><span class="line">                    path.pop()</span><br><span class="line">                    used[i]=False</span><br><span class="line">        dfs(depth,len_nums,path)</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure><h2 id="47-å…¨æ’åˆ—-II"><a href="#47-å…¨æ’åˆ—-II" class="headerlink" title="47. å…¨æ’åˆ— II"></a>47. å…¨æ’åˆ— II</h2><blockquote><p>å»æ‰é‡å¤æ’åˆ—</p><p>å…ˆå¯¹æ•°ç»„æ’åº é¿å…åŒä¸€ä¸ªæ•°å­—å¤šæ¬¡ä½¿ç”¨</p><p>è¦è§£å†³é‡å¤é—®é¢˜ï¼Œæˆ‘ä»¬åªè¦è®¾å®šä¸€ä¸ªè§„åˆ™ï¼Œä¿è¯åœ¨å¡«ç¬¬ iä¸ªæ•°çš„æ—¶å€™é‡å¤æ•°å­—åªä¼šè¢«å¡«å…¥ä¸€æ¬¡å³å¯ã€‚è€Œåœ¨æœ¬é¢˜è§£ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©å¯¹åŸæ•°ç»„æ’åºï¼Œä¿è¯ç›¸åŒçš„æ•°å­—éƒ½ç›¸é‚»ï¼Œç„¶åæ¯æ¬¡å¡«å…¥çš„æ•°ä¸€å®šæ˜¯è¿™ä¸ªæ•°æ‰€åœ¨é‡å¤æ•°é›†åˆä¸­ã€Œä»å·¦å¾€å³ç¬¬ä¸€ä¸ªæœªè¢«å¡«è¿‡çš„æ•°å­—ã€ï¼Œå³å¦‚ä¸‹çš„åˆ¤æ–­æ¡ä»¶ï¼š</p></blockquote><p>å…³é”®ä»£ç ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if  used[i] or (i &gt; 0 and not used[i - 1] and nums[i] == nums[i - 1]):</span><br><span class="line">                    continue</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import copy</span><br><span class="line">class Solution:</span><br><span class="line">    def permuteUnique(self, nums: List[int]) -&gt; List[List[int]]:</span><br><span class="line"></span><br><span class="line">        # å›æº¯ç®—æ³•å®ç°</span><br><span class="line">        # å®šä¹‰ä¸€ä¸ªå¸ƒå°”æ•°ç»„ æ ‡è®°æ¯ä¸ªèŠ‚ç‚¹çš„è®¿é—®çŠ¶æ€</span><br><span class="line">        used = [False for i in range(len(nums))]</span><br><span class="line">        # å¿…é¡»è¦æ’åº</span><br><span class="line">        nums.sort()</span><br><span class="line">        # def</span><br><span class="line">        depth = 0 #éå†å±‚çš„æ·±åº¦</span><br><span class="line">        res=[]</span><br><span class="line">        len_nums = len(nums) </span><br><span class="line">        path=[]</span><br><span class="line">        def dfs(depth,len_nums,path):</span><br><span class="line">            if depth == len_nums:</span><br><span class="line">                # éå†åˆ°æœ€åä¸€å±‚ æ·»åŠ ä¸€ä¸ªæ’åˆ—ç»“æœ</span><br><span class="line">                # ç”¨pathä¼šå‡ºé”™ å¿…é¡»ç”¨ path[:] å®ƒå¤åˆ¶åˆ—è¡¨oldåˆ°new</span><br><span class="line">                res.append(path[:])</span><br><span class="line">            for i in range(len_nums):</span><br><span class="line">                if  used[i] or (i &gt; 0 and not used[i - 1] and nums[i] == nums[i - 1]):</span><br><span class="line">                # é‡åˆ°ç›¸åŒçš„æ•°å­— åªæœ‰å½“å‰ä¸€ä¸ªç›¸åŒçš„æ•°å­—æ²¡æœ‰è¢«ä½¿ç”¨æ‰å¯ä»¥ </span><br><span class="line">                    continue</span><br><span class="line">                else:</span><br><span class="line">                    path.append(nums[i])</span><br><span class="line">                    used[i]=True</span><br><span class="line">                    dfs(depth+1,len_nums,path)</span><br><span class="line">                    path.pop()</span><br><span class="line">                    used[i]=False</span><br><span class="line">        dfs(depth,len_nums,path)</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure><h2 id="162-å¯»æ‰¾å³°å€¼"><a href="#162-å¯»æ‰¾å³°å€¼" class="headerlink" title="162. å¯»æ‰¾å³°å€¼"></a>162. å¯»æ‰¾å³°å€¼</h2><blockquote><p>æ‰¾å‡ºæœ€å¤§å€¼å³æ»¡è¶³æ¡ä»¶</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def findPeakElement(self, nums: List[int]) -&gt; int:</span><br><span class="line">        max_value = np.max(np.array(nums))</span><br><span class="line"></span><br><span class="line">        return nums.index(int(max_value))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    nums = [1, 2, 3, 1]</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.findPeakElement(nums)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="166-åˆ†æ•°åˆ°å°æ•°"><a href="#166-åˆ†æ•°åˆ°å°æ•°" class="headerlink" title="166. åˆ†æ•°åˆ°å°æ•°"></a>166. åˆ†æ•°åˆ°å°æ•°</h2><blockquote><p>å‚è€ƒäº†ä¸€ä¸ªéå¸¸æ¸…æ™°çš„é¢˜è§£</p></blockquote><ul><li>java</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">    public String fractionToDecimal(int numerator, int denominator) &#123;</span><br><span class="line">        // è½¬ long è®¡ç®—ï¼Œé˜²æ­¢æº¢å‡º</span><br><span class="line">        long a = numerator, b = denominator;</span><br><span class="line">        // å¦‚æœæœ¬èº«èƒ½å¤Ÿæ•´é™¤ï¼Œç›´æ¥è¿”å›è®¡ç®—ç»“æœ</span><br><span class="line">        if (a % b == 0) return String.valueOf(a / b);</span><br><span class="line">        StringBuilder sb = new StringBuilder();</span><br><span class="line">        // å¦‚æœå…¶ä¸€ä¸ºè´Ÿæ•°ï¼Œå…ˆè¿½åŠ è´Ÿå·</span><br><span class="line">        if (a * b &lt; 0) sb.append(&#x27;-&#x27;);</span><br><span class="line">        a = Math.abs(a); b = Math.abs(b);</span><br><span class="line">        // è®¡ç®—å°æ•°ç‚¹å‰çš„ï¼Œéƒ¨åˆ†ï¼Œå¹¶å°†ä½™æ•°èµ‹å€¼ç»™ a</span><br><span class="line">        sb.append(String.valueOf(a / b) + &quot;.&quot;);</span><br><span class="line">        a %= b;</span><br><span class="line">        Map&lt;Long, Integer&gt; map = new HashMap&lt;&gt;();</span><br><span class="line">        while (a != 0) &#123;</span><br><span class="line">            // è®°å½•å½“å‰ä½™æ•°æ‰€åœ¨ç­”æ¡ˆçš„ä½ç½®</span><br><span class="line">            map.put(a, sb.length());</span><br><span class="line">            a *= 10;</span><br><span class="line">            sb.append(a / b);</span><br><span class="line">            a %= b;</span><br><span class="line">            // å¦‚æœå½“å‰ä½™æ•°ä¹‹å‰å‡ºç°è¿‡ï¼Œåˆ™å°† [å‡ºç°ä½ç½® - å½“å‰ä½ç½®] çš„éƒ¨åˆ†æŠ å‡ºæ¥ï¼ˆå¾ªç¯å°æ•°éƒ¨åˆ†ï¼‰</span><br><span class="line">            if (map.containsKey(a)) &#123;</span><br><span class="line">                int u = map.get(a);</span><br><span class="line">                return String.format(&quot;%s(%s)&quot;, sb.substring(0, u), sb.substring(u));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return sb.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>python</p><blockquote><p>pythonæˆªå–å­—ç¬¦ä¸²ä¸€å®šè¦æ£€æŸ¥å†’å·æ˜¯å¦å®Œæ•´</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def fractionToDecimal(self, numerator: int, denominator: int) -&gt; str:</span><br><span class="line">        # åˆ¤æ–­æ˜¯å¦å¯ä»¥æ•´é™¤</span><br><span class="line">        if numerator % denominator == 0:</span><br><span class="line">            return str(numerator // denominator)</span><br><span class="line">        ans = &#x27;&#x27;</span><br><span class="line">        # å¦‚æœä¸èƒ½æ•´é™¤ åˆ¤æ–­ç¬¦å·</span><br><span class="line">        if numerator * denominator &lt; 0:</span><br><span class="line">            ans += &#x27;-&#x27;</span><br><span class="line">            numerator = abs(numerator)</span><br><span class="line">            denominator = abs(denominator)</span><br><span class="line">        # è®¡ç®—æ•´æ•°éƒ¨åˆ†</span><br><span class="line">        ans += str(numerator // denominator)</span><br><span class="line">        # è®¡ç®—å°æ•°éƒ¨åˆ†</span><br><span class="line">        ans += &#x27;.&#x27;</span><br><span class="line">        # å‡ºç°è¿‡çš„å°æ•°ä½å­˜å‚¨</span><br><span class="line">        nums = []</span><br><span class="line">        # å½“å‰ä½™æ•°</span><br><span class="line">        numerator = numerator % denominator</span><br><span class="line">        len_ans = len(ans)</span><br><span class="line">        while numerator != 0:</span><br><span class="line">            nums.append(numerator)</span><br><span class="line">            numerator *= 10</span><br><span class="line">            # å­˜å‚¨æ•°ä½</span><br><span class="line">            ans += str(numerator // denominator)</span><br><span class="line">            numerator %= denominator</span><br><span class="line">            # åˆ¤æ–­å½“å‰ä½™æ•°æ˜¯å¦å‡ºç°è¿‡</span><br><span class="line">            if nums.__contains__(numerator):</span><br><span class="line">                loc = nums.index(numerator)</span><br><span class="line">                end = len_ans + loc</span><br><span class="line">                return ans[0:end] + &#x27;(&#x27; + ans[len_ans + loc:] + &#x27;)&#x27;</span><br><span class="line">        return ans</span><br></pre></td></tr></table></figure><h2 id="187-é‡å¤çš„DNAåºåˆ—"><a href="#187-é‡å¤çš„DNAåºåˆ—" class="headerlink" title="187. é‡å¤çš„DNAåºåˆ—"></a>187. é‡å¤çš„DNAåºåˆ—</h2><blockquote><p>å…³é”®å­—ï¼šå“ˆå¸Œè¡¨</p><p>defaultdictçš„ä½œç”¨æ˜¯åœ¨äºï¼Œå½“å­—å…¸é‡Œçš„keyä¸å­˜åœ¨ä½†è¢«æŸ¥æ‰¾æ—¶ï¼Œè¿”å›çš„ä¸æ˜¯keyErrorè€Œæ˜¯ä¸€ä¸ªé»˜è®¤å€¼</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findRepeatedDnaSequences(self, s: str) -&gt; List[str]:</span><br><span class="line">        ans =[]</span><br><span class="line">        substr=defaultdict(int)</span><br><span class="line">        for i in range(len(s)-10+1):</span><br><span class="line">            temp = s[i:i+10]</span><br><span class="line">            # åˆ‡ç‰‡æ—¶é—´å¤æ‚åº¦ Oï¼ˆNï¼‰</span><br><span class="line">            substr[temp]+=1</span><br><span class="line">            if substr[temp]==2:</span><br><span class="line">                ans.append(temp)</span><br><span class="line">        return ans</span><br></pre></td></tr></table></figure><h2 id="200-å²›å±¿æ•°é‡"><a href="#200-å²›å±¿æ•°é‡" class="headerlink" title="200. å²›å±¿æ•°é‡"></a>200. å²›å±¿æ•°é‡</h2><blockquote><p>å›¾çš„DFSéå†</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">private:</span><br><span class="line">    void dfs(vector&lt;vector&lt;char&gt;&gt;&amp; grid, int r, int c) &#123;</span><br><span class="line">        // è¡Œåˆ—èŒƒå›´</span><br><span class="line">        int nr = grid.size();</span><br><span class="line">        int nc = grid[0].size();</span><br><span class="line">        </span><br><span class="line">        //å°†å·²ç»ä¾¿åˆ©è¿‡çš„å²›å±¿æ ‡è®°ä¸º2</span><br><span class="line">        grid[r][c] = &#x27;2&#x27;;</span><br><span class="line">        //åˆ¤æ–­è¾¹ç•Œæƒ…å†µ</span><br><span class="line">        if (r - 1 &gt;= 0 &amp;&amp; grid[r-1][c] == &#x27;1&#x27;) dfs(grid, r - 1, c);</span><br><span class="line">        if (r + 1 &lt; nr &amp;&amp; grid[r+1][c] == &#x27;1&#x27;) dfs(grid, r + 1, c);</span><br><span class="line">        if (c - 1 &gt;= 0 &amp;&amp; grid[r][c-1] == &#x27;1&#x27;) dfs(grid, r, c - 1);</span><br><span class="line">        if (c + 1 &lt; nc &amp;&amp; grid[r][c+1] == &#x27;1&#x27;) dfs(grid, r, c + 1);</span><br><span class="line">    &#125;</span><br><span class="line">public:</span><br><span class="line">    int numIslands(vector&lt;vector&lt;char&gt;&gt;&amp; grid) &#123;</span><br><span class="line">        // dfséå†</span><br><span class="line">        int nr = grid.size();</span><br><span class="line">        if (!nr) return 0;</span><br><span class="line">        int nc = grid[0].size();</span><br><span class="line"></span><br><span class="line">        int num_islands = 0;</span><br><span class="line">        for (int r = 0; r &lt; nr; ++r) &#123;</span><br><span class="line">            for (int c = 0; c &lt; nc; ++c) &#123;</span><br><span class="line">                // dfsæœç´¢æœªè®¿é—®è¿‡çš„å²›å±¿</span><br><span class="line">                if (grid[r][c] == &#x27;1&#x27;) &#123;</span><br><span class="line">                    ++num_islands;</span><br><span class="line">                    dfs(grid, r, c);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return num_islands;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="211-æ·»åŠ ä¸æœç´¢å•è¯-æ•°æ®ç»“æ„è®¾è®¡"><a href="#211-æ·»åŠ ä¸æœç´¢å•è¯-æ•°æ®ç»“æ„è®¾è®¡" class="headerlink" title="211. æ·»åŠ ä¸æœç´¢å•è¯ - æ•°æ®ç»“æ„è®¾è®¡"></a>211. æ·»åŠ ä¸æœç´¢å•è¯ - æ•°æ®ç»“æ„è®¾è®¡</h2><blockquote><p>å­—å…¸æ ‘ ç¥å¥‡ï¼</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"># å­—å…¸æ ‘</span><br><span class="line">class TreeNode:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.children = [None] * 26</span><br><span class="line">        self.isEnd = False</span><br><span class="line"></span><br><span class="line">    def insert(self, word: str) -&gt; None:</span><br><span class="line">        node = self</span><br><span class="line">        for ch in word:</span><br><span class="line">            num = ord(ch)-ord(&#x27;a&#x27;) # asscii </span><br><span class="line">            if not node.children[num]:</span><br><span class="line">                node.children[num]= TreeNode()</span><br><span class="line">            node = node.children[num]</span><br><span class="line">        node.isEnd =True</span><br><span class="line"></span><br><span class="line">class WordDictionary:</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.trieRoot = TreeNode()</span><br><span class="line"></span><br><span class="line">    def addWord(self, word: str) -&gt; None:</span><br><span class="line">        self.trieRoot.insert(word)</span><br><span class="line"></span><br><span class="line">    def search(self, word: str) -&gt; bool:</span><br><span class="line">        def dfs(index: int, node: TreeNode) -&gt; bool:</span><br><span class="line">            if index == len(word):</span><br><span class="line">                return node.isEnd #æœç´¢åˆ°å¶å­ç»“ç‚¹</span><br><span class="line">            ch = word[index]</span><br><span class="line">            if ch != &#x27;.&#x27;:</span><br><span class="line">                child = node.children[ord(ch) - ord(&#x27;a&#x27;)]</span><br><span class="line">                if child is not None and dfs(index + 1, child):</span><br><span class="line">                    return True</span><br><span class="line">            else:</span><br><span class="line">                for child in node.children: # . å¯ä»¥è¡¨ä»»æ„ä¸€ä¸ªèŠ‚ç‚¹ ä»æ¯ä¸€ä¸ªåˆ†æ”¯ç»§ç»­æœç´¢</span><br><span class="line">                    if child is not None and dfs(index + 1, child):</span><br><span class="line">                        return True</span><br><span class="line">            return False</span><br><span class="line"></span><br><span class="line">        return dfs(0, self.trieRoot)</span><br><span class="line"></span><br><span class="line"># Your WordDictionary object will be instantiated and called as such:</span><br><span class="line"># obj = WordDictionary()</span><br><span class="line"># obj.addWord(word)</span><br><span class="line"># param_2 = obj.search(word)</span><br></pre></td></tr></table></figure><h2 id="223-çŸ©å½¢é¢ç§¯"><a href="#223-çŸ©å½¢é¢ç§¯" class="headerlink" title="223. çŸ©å½¢é¢ç§¯"></a>223. çŸ©å½¢é¢ç§¯</h2><blockquote><p>å­¦åˆ°ä¸€æ‹› å…ˆå‡ååŠ  é¿å…æº¢å‡º</p><p>é‡å éƒ¨åˆ†å¯ä»¥æ±‚æŠ•å½±çš„äº¤é›†</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def computeArea(self, ax1: int, ay1: int, ax2: int, ay2: int, bx1: int, by1: int, bx2: int, by2: int) -&gt; int:</span><br><span class="line">        # è®¡ç®—é‡å é¢ç§¯è¾¹ç•Œ</span><br><span class="line">        bothx1 = max(ax1,bx1)</span><br><span class="line">        bothx2 = min(ax2,bx2)</span><br><span class="line"></span><br><span class="line">        bothy1 = max(ay1,by1)</span><br><span class="line">        bothy2 = min(ay2,by2)</span><br><span class="line">        # è®¡ç®—é‡å é¢ç§¯</span><br><span class="line">        both_area = 0</span><br><span class="line">        if bothx1&lt;bothx2 and bothy1&lt;bothy2:</span><br><span class="line">            both_area = abs(bothx2-bothx1)*abs(bothy2-bothy1)</span><br><span class="line"></span><br><span class="line">        # å…ˆå‡ååŠ  é¿å…æº¢å‡º</span><br><span class="line">        return abs(ax1-ax2)*abs(ay1-ay2) - both_area + abs(bx1-bx2)*abs(by1-by2)</span><br><span class="line">        </span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="230-äºŒå‰æœç´¢æ ‘ä¸­ç¬¬Kå°çš„å…ƒç´ "><a href="#230-äºŒå‰æœç´¢æ ‘ä¸­ç¬¬Kå°çš„å…ƒç´ " class="headerlink" title="230. äºŒå‰æœç´¢æ ‘ä¸­ç¬¬Kå°çš„å…ƒç´ "></a>230. äºŒå‰æœç´¢æ ‘ä¸­ç¬¬Kå°çš„å…ƒç´ </h2><blockquote><p>äºŒå‰æœç´¢æ ‘æ€§è´¨ï¼š</p><p>å·¦å­æ ‘å°äºæ ¹èŠ‚ç‚¹ å³å­æ ‘å¤§äºæ ¹èŠ‚ç‚¹ã€‚</p><p>äºŒå‰æœç´¢æ ‘çš„ä¸­åºéå†æ˜¯æœ‰åºçš„ã€‚</p></blockquote><ul><li>pop()å‡½æ•°é»˜è®¤popæœ€åä¸€ä¸ªå…ƒç´ </li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># Definition for a binary tree node.</span><br><span class="line"># class TreeNode:</span><br><span class="line">#     def __init__(self, val=0, left=None, right=None):</span><br><span class="line">#         self.val = val</span><br><span class="line">#         self.left = left</span><br><span class="line">#         self.right = right</span><br><span class="line">class Solution:</span><br><span class="line">    def kthSmallest(self, root: TreeNode, k: int) -&gt; int:</span><br><span class="line">        stack = []</span><br><span class="line">        # å·¦æ ¹å³</span><br><span class="line">        while root or stack:</span><br><span class="line">            while root:</span><br><span class="line">                # ä¸€ç›´éå†åˆ°å·¦å­æ ‘å¶å­èŠ‚ç‚¹ å³ä¸ºæœ€å°å€¼ </span><br><span class="line">                stack.append(root)</span><br><span class="line">                root = root.left</span><br><span class="line">            root = stack.pop()</span><br><span class="line">            k -= 1 # å‡ºæ ˆçš„æ¬¡åºä¸ºæœ€å°å€¼æ¬¡åº</span><br><span class="line">            if k == 0:</span><br><span class="line">                return root.val</span><br><span class="line">            root = root.right</span><br><span class="line">            </span><br></pre></td></tr></table></figure><h2 id="240-æœç´¢äºŒç»´çŸ©é˜µ-II"><a href="#240-æœç´¢äºŒç»´çŸ©é˜µ-II" class="headerlink" title="240. æœç´¢äºŒç»´çŸ©é˜µ II"></a>240. æœç´¢äºŒç»´çŸ©é˜µ II</h2><blockquote><p>ä¸¤ç§è§£æ³• ä»å³ä¸Šè§’æœç´¢è¿˜æ˜¯æ¯”è¾ƒå·§å¦™çš„ï¼</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def searchMatrix(self, matrix: List[List[int]], target: int) -&gt; bool:</span><br><span class="line">        # # å…ˆè¡Œæœç´¢ æ‰¾åˆ°æœ€æ¥è¿‘target çš„å€¼</span><br><span class="line">        # ans_row=[]</span><br><span class="line">        # for row in matrix:</span><br><span class="line">        #     for i in row:</span><br><span class="line">        #         if i == target:</span><br><span class="line">        #             return True</span><br><span class="line">        #         elif i &gt; target:</span><br><span class="line">        #             break</span><br><span class="line">        #         else:</span><br><span class="line">        #             ans_row = matrix.index(row)</span><br><span class="line">        # print(ans_row)</span><br><span class="line">        # return 0 </span><br><span class="line">        # è§£æ³•2 å³ä¸Šè§’æœç´¢ å¤§äºtargetè¯´æ˜å½“å‰åˆ—å…¨éƒ¨å¤§äº å‘å·¦ç§»åŠ¨ å°äºï¼Œè¯´æ˜å½“å‰è¡Œå…¨éƒ¨å°äº å‘ä¸‹ç§»åŠ¨ï¼ˆå› ä¸ºåœ¨æœ€å³ä¸Šè§’ï¼‰</span><br><span class="line">        m,n=len(matrix),len(matrix[0])</span><br><span class="line">        x,y=0,n-1</span><br><span class="line">        while x&lt;m and y&gt;=0 :</span><br><span class="line">            if matrix[x][y]==target:</span><br><span class="line">                return True</span><br><span class="line">            elif matrix[x][y] &gt;target:</span><br><span class="line">                y-=1</span><br><span class="line">            elif matrix[x][y]&lt;target:</span><br><span class="line">                x+=1</span><br><span class="line">        return False</span><br></pre></td></tr></table></figure><h2 id="319-ç¯æ³¡å¼€å…³"><a href="#319-ç¯æ³¡å¼€å…³" class="headerlink" title="319. ç¯æ³¡å¼€å…³"></a>319. ç¯æ³¡å¼€å…³</h2><blockquote><p>è„‘ç­‹æ€¥è½¬å¼¯ é™ç»´æ‰“å‡»</p><p>å¦‚æœæˆ‘ä»¬å°†æ‰€æœ‰çš„ç¯æ³¡ä»å·¦åˆ°å³ä¾æ¬¡ç¼–å·ä¸º1,2,3â€¦n ä¼šå‘ç°ç¬¬iæ¬¡åªå¯¹içš„å€æ•°è¿›è¡Œåˆ‡æ¢çŠ¶æ€</p><p>ç¯æ³¡åˆå§‹çŠ¶æ€æ˜¯ç­çš„ï¼Œå¶æ•°æ¬¡åˆ‡æ¢ä¹Ÿæ˜¯ç­çš„ å¥‡æ•°æ¬¡åˆ‡æ¢å˜äº®ï¼Œæ‰€ä»¥æ±‚kçš„çº¦æ•°ä¸ªæ•°å³å¯</p><p>ä½†ç›®çš„æ˜¯åˆ¤æ–­å¥‡å¶æ€§ï¼Œæ‰€ä»¥åªç”¨åˆ¤æ–­kæ˜¯ä¸æ˜¯å®Œå…¨å¹³æ–¹æ•°ï¼Œå¦‚æœæ˜¯ä¸€å®šå­˜åœ¨ k=x*x å³çº¦æ•°ä¸ªæ•°ä¸ºå¥‡æ•°ä¸ª</p><p>åˆ¤æ–­1,2,3â€¦nä¸­æœ‰å‡ ä¸ªå®Œå…¨å¹³æ–¹æ•°ï¼Œå¯¹nå¼€æ ¹å·å³å¯</p></blockquote><ul><li>sqrt(n + 0.5); sqrtæ˜¯æµ®ç‚¹æ•°è¿ç®—ï¼Œå¼ºåˆ¶ç±»å‹è½¬æ¢ä¸ºintä¼šå‘ä¸‹å–æ•´ï¼Œå› æ­¤å¢åŠ 0.5ä¿è¯ç²¾åº¦ã€‚</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int bulbSwitch(int n) &#123;</span><br><span class="line">        return sqrt(n + 0.5);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="ğŸŒŸ430-æ‰å¹³åŒ–å¤šçº§åŒå‘é“¾è¡¨"><a href="#ğŸŒŸ430-æ‰å¹³åŒ–å¤šçº§åŒå‘é“¾è¡¨" class="headerlink" title="ğŸŒŸ430. æ‰å¹³åŒ–å¤šçº§åŒå‘é“¾è¡¨"></a>ğŸŒŸ430. æ‰å¹³åŒ–å¤šçº§åŒå‘é“¾è¡¨</h2><blockquote><p>å‚è€ƒçš„é¢˜è§£ å†çœ‹çœ‹</p></blockquote><h2 id="447-å›æ—‹é•–çš„æ•°é‡"><a href="#447-å›æ—‹é•–çš„æ•°é‡" class="headerlink" title="447. å›æ—‹é•–çš„æ•°é‡"></a>447. å›æ—‹é•–çš„æ•°é‡</h2><blockquote><ul><li>hash_points = defaultdict(int)</li></ul><p>defaultdictï¼Œå½“å­—å…¸é‡Œçš„keyä¸å­˜åœ¨ä½†è¢«æŸ¥æ‰¾æ—¶ï¼Œè¿”å›çš„ä¸æ˜¯keyErrorè€Œæ˜¯ä¸€ä¸ªå·¥å‚å‡½æ•°çš„é»˜è®¤å€¼ï¼Œæ¯”å¦‚listå¯¹åº”[ ]ï¼Œstrå¯¹åº”çš„æ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œsetå¯¹åº”set( )ï¼Œintå¯¹åº”0</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from collections import defaultdict</span><br><span class="line">from math import sqrt</span><br><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def numberOfBoomerangs(self, points: List[List[int]]) -&gt; int:</span><br><span class="line">        ans = 0</span><br><span class="line">        for p in points:</span><br><span class="line">            # defaultdictï¼Œå½“å­—å…¸é‡Œçš„keyä¸å­˜åœ¨ä½†è¢«æŸ¥æ‰¾æ—¶ï¼Œè¿”å›çš„ä¸æ˜¯keyErrorè€Œæ˜¯ä¸€ä¸ªå·¥å‚å‡½æ•°çš„é»˜è®¤å€¼ï¼Œæ¯”å¦‚listå¯¹åº”[ ]ï¼Œstrå¯¹åº”çš„æ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œsetå¯¹åº”set( )ï¼Œintå¯¹åº”0</span><br><span class="line">            hash_points = defaultdict(int)</span><br><span class="line">            # ä½¿ç”¨å“ˆå¸Œè¡¨å­˜å‚¨åˆ°è¯¥ç‚¹è·ç¦»ç›¸ç­‰çš„pointä¸ªæ•°</span><br><span class="line">            for temp_q in points:</span><br><span class="line">                dis = sqrt(pow((p[0] - temp_q[0]), 2) + pow((p[1] - temp_q[1]), 2))</span><br><span class="line">                hash_points[dis] += 1</span><br><span class="line">            for v in hash_points.values():</span><br><span class="line">                # å…¨æ’åˆ—</span><br><span class="line">                ans += v * (v - 1)</span><br><span class="line"></span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    points = [[0, 0], [1, 0], [2, 0]]</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.numberOfBoomerangs(points)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="437-è·¯å¾„æ€»å’Œ-III"><a href="#437-è·¯å¾„æ€»å’Œ-III" class="headerlink" title="437. è·¯å¾„æ€»å’Œ III"></a>437. è·¯å¾„æ€»å’Œ III</h2><blockquote><p>æ³¨æ„èŠ‚ç‚¹æ­£è´Ÿæ€§ ä¸€å®šè¦éå†åˆ°æœ€å</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># Definition for a binary tree node.</span><br><span class="line"># class TreeNode:</span><br><span class="line">#     def __init__(self, val=0, left=None, right=None):</span><br><span class="line">#         self.val = val</span><br><span class="line">#         self.left = left</span><br><span class="line">#         self.right = right</span><br><span class="line">class Solution:</span><br><span class="line">    def pathSum(self, root: TreeNode, targetSum: int) -&gt; int:</span><br><span class="line">        # åˆ¤æ–­å½“å‰èŠ‚ç‚¹çš„è·¯å¾„æ•°é‡</span><br><span class="line">        def get_sum(node, target):</span><br><span class="line">            # é‡‡ç”¨é€’å½’çš„æ€è·¯ éå†å·¦å­æ ‘å’Œå³å­æ ‘</span><br><span class="line">            temp_ans=0</span><br><span class="line">            if node is None:</span><br><span class="line">                return 0</span><br><span class="line">            if node.val == target:</span><br><span class="line">                temp_ans+=1</span><br><span class="line">                # return temp_ans</span><br><span class="line">                # ä¸èƒ½ç›´æ¥return å› ä¸ºèŠ‚ç‚¹æœ‰å¯èƒ½ä¸ºè´Ÿæ•°</span><br><span class="line">            temp_ans+=get_sum(node.left, target - node.val)</span><br><span class="line">            temp_ans+=get_sum(node.right, target - node.val)</span><br><span class="line">            return temp_ans</span><br><span class="line">        if root is None:</span><br><span class="line">            return 0</span><br><span class="line">        # å¯»æ‰¾å½“å‰èŠ‚ç‚¹è·¯å¾„æ•°é‡</span><br><span class="line">        ans = get_sum(root, targetSum)</span><br><span class="line">        # å¯»æ‰¾å½“å‰èŠ‚ç‚¹å­æ ‘çš„è·¯å¾„æ•°é‡</span><br><span class="line">        ans +=self.pathSum(root.left,targetSum)</span><br><span class="line">        ans +=self.pathSum(root.right,targetSum)</span><br><span class="line">        return ans</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="524-é€šè¿‡åˆ é™¤å­—æ¯åŒ¹é…åˆ°å­—å…¸é‡Œæœ€é•¿å•è¯"><a href="#524-é€šè¿‡åˆ é™¤å­—æ¯åŒ¹é…åˆ°å­—å…¸é‡Œæœ€é•¿å•è¯" class="headerlink" title="524. é€šè¿‡åˆ é™¤å­—æ¯åŒ¹é…åˆ°å­—å…¸é‡Œæœ€é•¿å•è¯"></a>524. é€šè¿‡åˆ é™¤å­—æ¯åŒ¹é…åˆ°å­—å…¸é‡Œæœ€é•¿å•è¯</h2><blockquote><p>åŒ¹é…ä¸¤ä¸ªå­—ç¬¦ä¸² å¯ä»¥ä½¿ç”¨åŒæŒ‡é’ˆçš„æ–¹æ³•</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def findLongestWord(self, s: str, dictionary: List[str]) -&gt; str:</span><br><span class="line">        # ä½¿ç”¨åŒæŒ‡é’ˆå®ç°å­—ç¬¦ä¸²åŒ¹é…</span><br><span class="line">        ans = &#x27;&#x27;</span><br><span class="line">        # å¾ªç¯åŒ¹é…å­—å…¸ä¸­çš„å­—ç¬¦ä¸²</span><br><span class="line">        for word in dictionary:</span><br><span class="line">            # åŒæŒ‡é’ˆ</span><br><span class="line">            i, j = 0, 0</span><br><span class="line">            while i &lt; len(word) and j &lt; len(s):</span><br><span class="line">                # åœ¨å­—ç¬¦ä¸²sä¸­å¯»æ‰¾word ä¹Ÿå°±æ˜¯è¯´wordä¸­çš„æ¯ä¸ªå­—æ¯éƒ½è¦åœ¨sä¸­æŒ‰é¡ºåºå‡ºç°</span><br><span class="line">                if word[i] == s[j]:</span><br><span class="line">                    i += 1</span><br><span class="line">                j += 1</span><br><span class="line">            if i == len(word):</span><br><span class="line">                # åŒ¹é…æˆåŠŸ ç»´æŠ¤æœ€é•¿å­—ä¸² é•¿åº¦ç›¸åŒ è¿”å›é•¿åº¦æœ€é•¿ä¸” å­—å…¸åº æœ€å°çš„å­—ç¬¦ä¸²</span><br><span class="line">                if (len(word) &gt; len(ans)) or (len(word) == len(ans) and word &lt; ans):</span><br><span class="line">                    ans = word</span><br><span class="line"></span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    s = &quot;abpcplea&quot;</span><br><span class="line">    dictionary = [&quot;ale&quot;, &quot;apple&quot;, &quot;monkey&quot;, &quot;plea&quot;]</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.findLongestWord(s,dictionary)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="583-ä¸¤ä¸ªå­—ç¬¦ä¸²çš„åˆ é™¤æ“ä½œ"><a href="#583-ä¸¤ä¸ªå­—ç¬¦ä¸²çš„åˆ é™¤æ“ä½œ" class="headerlink" title="583. ä¸¤ä¸ªå­—ç¬¦ä¸²çš„åˆ é™¤æ“ä½œ"></a>583. ä¸¤ä¸ªå­—ç¬¦ä¸²çš„åˆ é™¤æ“ä½œ</h2><blockquote><p>å€¼å¾—æ³¨æ„çš„æ˜¯ text[0:i-1]å¯¹åº”çš„dpæ•°ç»„ä½ç½®ä¸ºdp[i-1][j]</p><p>text æ•°ç»„å¯¹åº”çš„å­—ç¬¦ä¸‹æ ‡ä»1å¼€å§‹</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def minDistance(self, word1: str, word2: str) -&gt; int:</span><br><span class="line">        m, n = len(word1), len(word2)</span><br><span class="line">        # dp[i][j] è¡¨ç¤ºword1[0:i] å’Œ word[0:j] çš„æœ€å¤§å…¬å…±å­åºåˆ—é•¿åº¦</span><br><span class="line">        dp = [[0] * (n + 1) for _ in range(m + 1)]</span><br><span class="line">        # print(dp)</span><br><span class="line">        for i in range(1, m + 1):</span><br><span class="line">            for j in range(1, n + 1):</span><br><span class="line">                # å½“å‰ä½ç½®å­—ç¬¦ä¸²ç›¸åŒ</span><br><span class="line">                if word1[i - 1] == word2[j - 1]:</span><br><span class="line">                    dp[i][j] = dp[i - 1][j - 1] + 1</span><br><span class="line">                else:</span><br><span class="line">                    # å½“å‰ä½ç½®å­—ç¬¦ä¸²ä¸ç›¸åŒ å–å½“å‰ä½ç½®  dp[i - 1][j] å’Œ dp[i][j - 1] çš„æœ€å¤§å€¼</span><br><span class="line">                    # è‹¥text1[i-1] != text2[j-1]ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸¤ä¸ªå­—ç¬¦ä¸²çš„æœ€åä¸€ä½ä¸ç›¸ç­‰ï¼Œé‚£ä¹ˆå­—ç¬¦ä¸²text1çš„[1,i]åŒºé—´å’Œå­—ç¬¦ä¸²text2çš„[1,j]åŒºé—´çš„æœ€é•¿å…¬å…±å­åºåˆ—é•¿åº¦æ— æ³•å»¶é•¿ï¼Œå› æ­¤f[i][j]å°±ä¼šç»§æ‰¿f[i-1][j]ä¸f[i][j-1]ä¸­çš„è¾ƒå¤§å€¼</span><br><span class="line">                    # å€¼å¾—æ³¨æ„çš„æ˜¯ text[0:i-1]å¯¹åº”çš„dpæ•°ç»„ä½ç½®ä¸ºdp[i-1][j]</span><br><span class="line">                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])</span><br><span class="line"></span><br><span class="line">        lcs = dp[m][n]</span><br><span class="line">        return m - lcs + n - lcs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    word1 = &quot;sea&quot;</span><br><span class="line">    word2 = &quot;eata&quot;</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.minDistance(word1, word2)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="638-å¤§ç¤¼åŒ…"><a href="#638-å¤§ç¤¼åŒ…" class="headerlink" title="638. å¤§ç¤¼åŒ…"></a>638. å¤§ç¤¼åŒ…</h2><blockquote><p>ä½¿ç”¨äº† lru_cache å‚æ•°å¿…é¡»å¯ä»¥ä½¿ç”¨hashå€¼ä½œä¸ºç´¢å¼•</p><ul><li><p>å¯å“ˆå¸Œçš„å…ƒç´ ï¼šintã€floatã€strã€tupleã€è‡ªå®šä¹‰çš„ç±»çš„å®ä¾‹å¯¹è±¡</p></li><li><p>ä¸å¯å“ˆå¸Œçš„å…ƒç´ ï¼šlistã€setã€dict</p></li></ul></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line">class Solution:</span><br><span class="line">    def shoppingOffers(self, price: List[int], special: List[List[int]], needs: List[int]) -&gt; int:</span><br><span class="line">        # ä»·æ ¼ price</span><br><span class="line">        # å¤§ç¤¼åŒ…ç§ç±» special</span><br><span class="line">        # æ€»éœ€æ±‚ need</span><br><span class="line"></span><br><span class="line">        # 1. è¿‡æ»¤æ‰ ä¸ä¼˜æƒ çš„å¤§ç¤¼åŒ…ç»„åˆ</span><br><span class="line">        filter_sp=[]</span><br><span class="line">        for sp in special:</span><br><span class="line">            temp_sp=[]</span><br><span class="line">            for i in range(len(sp)-1):</span><br><span class="line">                temp_sp.append(sp[i]*price[i])</span><br><span class="line">            if sum(temp_sp)&gt;sp[-1]: # æ¯”ç›´æ¥è´­ä¹°ä¾¿å®œ</span><br><span class="line">                filter_sp.append(sp)</span><br><span class="line">        # 2.è®¡ç®—æœ€ä¼˜ç»„åˆ</span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        # ç¼“å­˜ åŠ é€Ÿé‡å¤è®¡ç®—</span><br><span class="line">        def dfs(cur_needs):</span><br><span class="line">            # ä¸è´­ä¹°ä»»ä½•å¤§ç¤¼åŒ…ï¼ŒåŸä»·è´­ä¹°è´­ç‰©æ¸…å•ä¸­çš„æ‰€æœ‰ç‰©å“</span><br><span class="line">            min_price = sum(need * price[i] for i, need in enumerate(cur_needs))</span><br><span class="line">            for sp in filter_sp:</span><br><span class="line">                # å¤§ç¤¼åŒ…ä»·æ ¼  </span><br><span class="line">                sp_price =sp[-1]</span><br><span class="line">                # å½“å‰éœ€æ±‚ä¸º cur_needs å‰©ä½™éœ€æ±‚ä¸º next_needs</span><br><span class="line">                next_needs=[]</span><br><span class="line">                for good_index in range(len(price)):</span><br><span class="line">                    if sp[good_index]&gt;cur_needs[good_index]:</span><br><span class="line">                        # ä¸èƒ½è´­ä¹°è¶…è¿‡éœ€æ±‚çš„å•†å“</span><br><span class="line">                        break</span><br><span class="line">                    next_needs.append(cur_needs[good_index]-sp[good_index])</span><br><span class="line">                if len(next_needs)==len(cur_needs): #å¤§ç¤¼åŒ…å¯ä»¥è´­ä¹° æ²¡æœ‰è¶…å‡ºæ•°é‡é™åˆ¶</span><br><span class="line">                    # æ¯”è¾ƒæœ€ä¼˜ä»·æ ¼</span><br><span class="line">                    min_price=min(min_price,sp_price+dfs(tuple(next_needs)))</span><br><span class="line">            return min_price</span><br><span class="line"></span><br><span class="line">        return dfs(tuple(needs))</span><br><span class="line">        # å› ä¸ºä½¿ç”¨äº† lru_cache è€Œlistä¸èƒ½hash æ‰€ä»¥å¿…é¡»è½¬æ¢ä¸ºtuple</span><br></pre></td></tr></table></figure><h2 id="673-æœ€é•¿é€’å¢å­åºåˆ—çš„ä¸ªæ•°"><a href="#673-æœ€é•¿é€’å¢å­åºåˆ—çš„ä¸ªæ•°" class="headerlink" title="673. æœ€é•¿é€’å¢å­åºåˆ—çš„ä¸ªæ•°"></a>673. æœ€é•¿é€’å¢å­åºåˆ—çš„ä¸ªæ•°</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line"></span><br><span class="line">    def findNumberOfLIS(self, nums: List[int]) -&gt; int:</span><br><span class="line"></span><br><span class="line">        # ä½¿ç”¨åŠ¨æ€è§„åˆ’ dp æ•°ç»„å­˜å½“å‰ä½ç½®æœ€é•¿å­åºåˆ—é•¿åº¦</span><br><span class="line">        # cnt æ•°ç»„å­˜æ”¾å½“å‰ä½ç½®æœ€é•¿å­åºåˆ—æ•°é‡</span><br><span class="line">        # çŠ¶æ€è½¬ç§»æ–¹ç¨‹ dp[i] = max(dp[j]) + 1) ä¸”num[j]&lt;num[i]</span><br><span class="line">        max_len = 0</span><br><span class="line">        ans = 0</span><br><span class="line">        dp = [0] * len(nums)</span><br><span class="line">        cnt = [0] * len(nums)</span><br><span class="line">        # éå†æ•°ç»„</span><br><span class="line">        for i, value in enumerate(nums):</span><br><span class="line">            dp[i] = 1</span><br><span class="line">            cnt[i] = 1</span><br><span class="line">            # å¯»æ‰¾å½“å‰ä½ç½®çš„æœ€é•¿å­åºåˆ—</span><br><span class="line">            # å¾€å†å²æœ€é•¿å­åºåˆ—ä¸­åŠ å…¥nums[i]</span><br><span class="line">            # ç›¸åº”çš„dp[i]+1 cnt[i]æ ¹æ®å†å²cnt[j]æ›´æ–°</span><br><span class="line"></span><br><span class="line">            for j in range(i):</span><br><span class="line">                if value &gt; nums[j]:</span><br><span class="line">                    if dp[j] + 1 &gt; dp[i]:</span><br><span class="line">                        dp[i] = dp[j] + 1</span><br><span class="line">                        cnt[i] = cnt[j]</span><br><span class="line">                    elif dp[j] + 1 == dp[i]:</span><br><span class="line">                        cnt[i] += cnt[j]</span><br><span class="line">            if dp[i] &gt; max_len:</span><br><span class="line">                # æ›´æ–°æ•°æ®</span><br><span class="line">                max_len = dp[i]</span><br><span class="line">                ans = cnt[i]</span><br><span class="line">            elif dp[i] == max_len:</span><br><span class="line">                # ç­”æ¡ˆä¸ºå¤šæœ‰æ»¡è¶³ dp[i] == max_len çš„cnt[i]ä¹‹å’Œ</span><br><span class="line">                ans += cnt[i]</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    board = [1, 3, 5, 4, 7]</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.findNumberOfLIS(board)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="678-æœ‰æ•ˆçš„æ‹¬å·å­—ç¬¦ä¸²"><a href="#678-æœ‰æ•ˆçš„æ‹¬å·å­—ç¬¦ä¸²" class="headerlink" title="678. æœ‰æ•ˆçš„æ‹¬å·å­—ç¬¦ä¸²"></a>678. æœ‰æ•ˆçš„æ‹¬å·å­—ç¬¦ä¸²</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def checkValidString(self, s: str) -&gt; bool:</span><br><span class="line">        # å †æ ˆæ¨¡æ‹Ÿå®ç°</span><br><span class="line">        left_stack = []</span><br><span class="line">        star_stack = []</span><br><span class="line">        for index, ch in enumerate(s):</span><br><span class="line">            # é‡åˆ°å·¦æ‹¬å· å’Œ æ˜Ÿå· åˆ†åˆ«å…¥æ ˆ</span><br><span class="line">            # å­˜å‚¨ä¸‹æ ‡ æ–¹ä¾¿æ¯”è¾ƒ</span><br><span class="line">            if ch == &#x27;(&#x27;:</span><br><span class="line">                left_stack.append(index)</span><br><span class="line">            elif ch == &quot;*&quot;:</span><br><span class="line">                star_stack.append(index)</span><br><span class="line">            # é‡åˆ°å³æ‹¬å·åŒ¹é…</span><br><span class="line">            elif ch == &#x27;)&#x27;:</span><br><span class="line">                # å› ä¸ºæ˜Ÿå·å¯ä»¥ä»»æ„åŒ¹é… æ‰€ä»¥ä¼˜å…ˆåŒ¹é…å·¦æ‹¬å·</span><br><span class="line">                if left_stack:</span><br><span class="line">                    left_stack.pop()</span><br><span class="line">                # å·¦æ‹¬å·ä¸è¶³çš„æƒ…å†µä¸‹ä½¿ç”¨æ˜Ÿå·åŒ¹é…</span><br><span class="line">                elif star_stack:</span><br><span class="line">                    star_stack.pop()</span><br><span class="line">                # éƒ½ä¸èƒ½åŒ¹é…åˆ™ä¸æ»¡è¶³æœ‰æ•ˆçš„æ‹¬å·å­—ç¬¦ä¸²</span><br><span class="line">                else:</span><br><span class="line">                    return False</span><br><span class="line"></span><br><span class="line">        # éå†å¯»æ‰¾å³æ‹¬å·ç»“æŸå åŒ¹é…å·¦æ‹¬å·å’Œæ˜Ÿå·</span><br><span class="line">        # åŒ¹é…æ—¶å¿…é¡»æ˜¯å³ä¾§çš„æ˜Ÿå·å’Œå·¦ä¾§çš„å·¦æ‹¬å·çš„åŒ¹é…</span><br><span class="line"></span><br><span class="line">        while left_stack:</span><br><span class="line">            # æ˜Ÿå·æ¶ˆè€—å®Œäº†</span><br><span class="line">            if not star_stack:</span><br><span class="line">                return False</span><br><span class="line">            # å³ä¾§æ˜Ÿå·æ¶ˆè€—å®Œäº†</span><br><span class="line">            elif left_stack[-1] &gt; star_stack[-1]:</span><br><span class="line">                return False</span><br><span class="line">            else:</span><br><span class="line">                left_stack.pop()</span><br><span class="line">                star_stack.pop()</span><br><span class="line">        return True</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    str = &quot;()()()((((()((()(()())(()))(())))((()((()())*(((())()))(()((())(((((((())()*)())((())*))))*)())()))&quot;</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.checkValidString(str)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="725-åˆ†éš”é“¾è¡¨"><a href="#725-åˆ†éš”é“¾è¡¨" class="headerlink" title="725. åˆ†éš”é“¾è¡¨"></a>725. åˆ†éš”é“¾è¡¨</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># Definition for singly-linked list.</span><br><span class="line"># class ListNode:</span><br><span class="line">#     def __init__(self, val=0, next=None):</span><br><span class="line">#         self.val = val</span><br><span class="line">#         self.next = next</span><br><span class="line">class Solution:</span><br><span class="line">    def splitListToParts(self, head: ListNode, k: int) -&gt; List[ListNode]:</span><br><span class="line">        print(head)</span><br><span class="line">        cur, l = head, 0</span><br><span class="line">        # è®¡ç®—é“¾è¡¨é•¿åº¦</span><br><span class="line">        while cur:</span><br><span class="line">            l += 1</span><br><span class="line">            cur = cur.next</span><br><span class="line">        # å‡åˆ† æ±‚ä½™</span><br><span class="line">        each, remain = l // k, l % k</span><br><span class="line">        cur, ans, idx = head, [None] * k, 0</span><br><span class="line">        while cur:</span><br><span class="line">            ans[idx] = cur</span><br><span class="line">            # ä½¿ç”¨lastæ–­å¼€é“¾è¡¨ last.next = None</span><br><span class="line">            last = None</span><br><span class="line">            # idx &lt; remainæ§åˆ¶å·¦ä¾§æ•°é“¾è¡¨äºå³ä¾§é“¾è¡¨</span><br><span class="line">            for i in range(each + (idx &lt; remain)):</span><br><span class="line">                last = cur</span><br><span class="line">                cur = cur.next</span><br><span class="line">            idx += 1</span><br><span class="line">            last.next = None</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="1218-æœ€é•¿å®šå·®å­åºåˆ—"><a href="#1218-æœ€é•¿å®šå·®å­åºåˆ—" class="headerlink" title="1218. æœ€é•¿å®šå·®å­åºåˆ—"></a>1218. æœ€é•¿å®šå·®å­åºåˆ—</h2><blockquote><p>åŠ¨æ€è§„åˆ’å®ç°</p><p>ä»å·¦åˆ°å³éå†ï¼Œè®¡ç®—ä»¥arr[i]ä¸ºç»“å°¾çš„æœ€é•¿çš„ç­‰å·®å­åºåˆ—çš„é•¿åº¦ã€‚</p></blockquote><p>å­¦åˆ°ä¸€æ‹›ï¼Œvectorçš„éå† é™¤äº†ä½¿ç”¨è¿­ä»£å™¨<code>for (vector&lt;int&gt;::iterator it=arr.begin();it!=arr.end();it++)</code>    ,è¿˜å¯ä»¥ç®€å†™<code>for (int v: arr)</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int longestSubsequence(vector&lt;int&gt;&amp; arr, int difference) &#123;</span><br><span class="line">            // åŠ¨æ€è§„åˆ’ </span><br><span class="line">            // unordered_mapå­˜å‚¨dpå€¼</span><br><span class="line">            unordered_map&lt;int, int&gt; dp;</span><br><span class="line">            int ans =0;</span><br><span class="line">            for (vector&lt;int&gt;::iterator it=arr.begin();it!=arr.end();it++)</span><br><span class="line">            &#123;</span><br><span class="line">                dp[*it]=dp[*it-difference]+1;</span><br><span class="line">                // ä»¥å½“å‰æ•°å€¼ä¸ºç»“å°¾çš„ç­‰å·®åºåˆ—é•¿åº¦</span><br><span class="line">                ans = max(ans,dp[*it]);</span><br><span class="line">            &#125;</span><br><span class="line">            return ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="1894-æ‰¾åˆ°éœ€è¦è¡¥å……ç²‰ç¬”çš„å­¦ç”Ÿç¼–å·"><a href="#1894-æ‰¾åˆ°éœ€è¦è¡¥å……ç²‰ç¬”çš„å­¦ç”Ÿç¼–å·" class="headerlink" title="1894. æ‰¾åˆ°éœ€è¦è¡¥å……ç²‰ç¬”çš„å­¦ç”Ÿç¼–å·"></a>1894. æ‰¾åˆ°éœ€è¦è¡¥å……ç²‰ç¬”çš„å­¦ç”Ÿç¼–å·</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def chalkReplacer(self, chalk: List[int], k: int) -&gt; int:</span><br><span class="line">        # åˆ¤æ–­ç¬¬å‡ è½®éœ€è¦è¡¥å……ç²‰ç¬”</span><br><span class="line">        signal_loop = sum(chalk)</span><br><span class="line">        if (k % signal_loop) == 0:</span><br><span class="line">            return 0</span><br><span class="line">        else:</span><br><span class="line">            chalk_loop = k // signal_loop</span><br><span class="line">            k -= chalk_loop * signal_loop</span><br><span class="line">            # æ‰¾å‡ºç²‰ç¬”ä¸è¶³çš„ä¸‹æ ‡</span><br><span class="line">            # é‡æ•´æ•°ç»„ è®¡ç®—å½“å‰ä½ç½®éœ€è¦ç´¯è®¡æ¶ˆè€—ç²‰ç¬”æ•°é‡</span><br><span class="line">            for i in range(len(chalk)):</span><br><span class="line">                if chalk[i] &gt; k:</span><br><span class="line">                    return i</span><br><span class="line">                else:</span><br><span class="line">                    k -= chalk[i]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    chalk = [3, 4, 1, 2]</span><br><span class="line">    k = 25</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.chalkReplacer(chalk, k)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="å›°éš¾"><a href="#å›°éš¾" class="headerlink" title="å›°éš¾"></a>å›°éš¾</h1><h2 id="68-æ–‡æœ¬å·¦å³å¯¹é½"><a href="#68-æ–‡æœ¬å·¦å³å¯¹é½" class="headerlink" title="68. æ–‡æœ¬å·¦å³å¯¹é½"></a>68. æ–‡æœ¬å·¦å³å¯¹é½</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def fullJustify(self, words: List[str], maxWidth: int) -&gt; List[str]:</span><br><span class="line">        # ä½¿å¾—æ¯è¡Œå•è¯æ¥è¿‘maxWidth</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        æ¯ä¸ªå•è¯ä¹‹é—´è‡³å°‘æœ‰ä¸€ä¸ªç©ºæ ¼</span><br><span class="line">        ç‰¹æ®Šæƒ…å†µï¼š</span><br><span class="line">        1.å•è¯æ•°å¤§äº1æ—¶ å·¦ä¾§ç©ºæ ¼æ•°å¤šäºå³ä¾§</span><br><span class="line">        2.å½“å‰è¡Œåªæœ‰ä¸€ä¸ªå•è¯æ—¶ å±…å·¦å¯¹é½ ç©ºæ ¼è¡¥å……é•¿åº¦</span><br><span class="line">        3.æœ€åä¸€è¡Œ å±…å·¦å¯¹é½ æ¯ä¸ªå•è¯ä¹‹é—´1ä¸ªç©ºæ ¼ æœ«å°¾ç©ºæ ¼è¡¥å……é•¿åº¦</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        totalLineWords = []</span><br><span class="line">        signalLineWord = []</span><br><span class="line"></span><br><span class="line">        for temp_len in words:</span><br><span class="line">            if len(temp_len) + self.get_sum(signalLineWord) + len(signalLineWord) &lt;= maxWidth:</span><br><span class="line">                signalLineWord.append(temp_len)</span><br><span class="line">                # print(signalLineWord)</span><br><span class="line">            else:</span><br><span class="line">                totalLineWords.append(signalLineWord)</span><br><span class="line">                signalLineWord = [temp_len]</span><br><span class="line">        totalLineWords.append(signalLineWord)</span><br><span class="line">        ans = self.put_blank(totalLineWords, maxWidth)</span><br><span class="line">        print(ans)</span><br><span class="line">        for lens in ans:</span><br><span class="line">            print(len(lens))</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line">    # å¾—åˆ°å•è¯æ€»é•¿åº¦</span><br><span class="line">    def get_sum(self, word_lsits: List[str]):</span><br><span class="line">        # ç»Ÿè®¡æ¯ä¸ªå•è¯é•¿åº¦</span><br><span class="line">        word_len = [len(i) for i in word_lsits]</span><br><span class="line">        return sum(word_len)</span><br><span class="line"></span><br><span class="line">    # å¡«å……ç©ºæ ¼</span><br><span class="line">    def put_blank(self, totalLineWords: List[List[str]], maxWidth: int):</span><br><span class="line">        # print(totalLineWords[:-1])</span><br><span class="line">        ans = []</span><br><span class="line">        for line in totalLineWords[:-1]:</span><br><span class="line">            if len(line) == 1:</span><br><span class="line">                ans.append(line[0] + self.insert_blank(maxWidth - len(line[0])))</span><br><span class="line">            else:</span><br><span class="line">                # è®¡ç®—å¹³å‡å¯æ’å…¥ç©ºæ ¼</span><br><span class="line">                temp_sum_word = self.get_sum(line)</span><br><span class="line">                mean_blank = int((maxWidth - temp_sum_word) / (len(line) - 1))</span><br><span class="line">                # è®¡ç®—ä»å·¦åˆ°å³çš„ç©ºæ ¼æ•°</span><br><span class="line">                mod_blank = (maxWidth - temp_sum_word) % (len(line) - 1)</span><br><span class="line">                # print(temp_sum_word)</span><br><span class="line">                # print(temp_blank, mod_blank)</span><br><span class="line">                # å¡«å……ç©ºæ ¼</span><br><span class="line">                temp_str = &#x27;&#x27;</span><br><span class="line">                temp_word_line = line[:-1]</span><br><span class="line">                # mean</span><br><span class="line">                for word_index in range(len(line[:-1])):</span><br><span class="line">                    temp_word_line[word_index] = line[:-1][word_index] + self.insert_blank(mean_blank)</span><br><span class="line">                # mod</span><br><span class="line">                for index in range(mod_blank):</span><br><span class="line">                    temp_word_line[index] += &#x27; &#x27;</span><br><span class="line">                # str</span><br><span class="line">                for word in temp_word_line:</span><br><span class="line">                    temp_str += word</span><br><span class="line">                temp_str += line[-1]</span><br><span class="line">                ans.append(temp_str)</span><br><span class="line">        # æœ€åä¸€è¡Œ</span><br><span class="line">        if len(totalLineWords[-1]) == 1:</span><br><span class="line">            ans.append(totalLineWords[-1][0] + self.insert_blank(maxWidth - len(totalLineWords[-1][0])))</span><br><span class="line">        else:</span><br><span class="line">            temp_str = &#x27;&#x27;</span><br><span class="line">            for word in totalLineWords[-1][:-1]:</span><br><span class="line">                temp_str += word + &#x27; &#x27;</span><br><span class="line">            temp_str += totalLineWords[-1][-1]</span><br><span class="line">            ans.append(temp_str + self.insert_blank(maxWidth - len(temp_str)))</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line">    def insert_blank(self, num: int):</span><br><span class="line">        return &#x27; &#x27; * num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    words = [&quot;What&quot;, &quot;must&quot;, &quot;be&quot;, &quot;acknowledgment&quot;, &quot;shall&quot;, &quot;be&quot;]</span><br><span class="line">    maxWidth = 16</span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.fullJustify(words, maxWidth)</span><br></pre></td></tr></table></figure><h2 id="ğŸŒŸ212-å•è¯æœç´¢-II"><a href="#ğŸŒŸ212-å•è¯æœç´¢-II" class="headerlink" title="ğŸŒŸ212. å•è¯æœç´¢ II"></a>ğŸŒŸ212. å•è¯æœç´¢ II</h2><blockquote><p>æœ‰ç‚¹éš¾ æš‚æ—¶ä¸çœ‹</p></blockquote><h2 id="282-ç»™è¡¨è¾¾å¼æ·»åŠ è¿ç®—ç¬¦"><a href="#282-ç»™è¡¨è¾¾å¼æ·»åŠ è¿ç®—ç¬¦" class="headerlink" title="282. ç»™è¡¨è¾¾å¼æ·»åŠ è¿ç®—ç¬¦"></a>282. ç»™è¡¨è¾¾å¼æ·»åŠ è¿ç®—ç¬¦</h2><blockquote><p>å®˜æ–¹é¢˜è§£æ¯”è¾ƒå·§å¦™ åç¼€è¡¨è¾¾å¼å¯ä»¥è§£å†³å¸¦æ‹¬å·çš„</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def addOperators(self, num: str, target: int) -&gt; List[str]:</span><br><span class="line">        num_len = len(num)</span><br><span class="line">        ans = []</span><br><span class="line"></span><br><span class="line">        # é€’å½’å‡½æ•°</span><br><span class="line"></span><br><span class="line">        def backtrack(expr, loc, res, mul):</span><br><span class="line">            &quot;&quot;&quot;</span><br><span class="line">            :param expr: å½“å‰æ„é€ çš„è¡¨è¾¾å¼</span><br><span class="line">            :param loc: å½“å‰æšä¸¾åˆ°çš„å­—ç¬¦ä¸²ä½ç½®</span><br><span class="line">            :param res: å½“å‰è¡¨è¾¾å¼çš„è®¡ç®—ç»“æœ</span><br><span class="line">            :param mul: æœ€åä¸€ä¸ªè¿ä¹˜è¡¨è¾¾å¼çš„è®¡ç®—ç»“æœ å› ä¸ºä¹˜æ³•çš„ä¼˜å…ˆçº§é«˜ ä¸‹ä¸€æ­¥è®¡ç®—æ—¶ å¦‚æœä¸ºä¹˜æ³• åº”è¯¥ä¸ºres-mul+mul*new_num</span><br><span class="line">            :return: null</span><br><span class="line">            &quot;&quot;&quot;</span><br><span class="line">            if loc == num_len:</span><br><span class="line">                if target == res:</span><br><span class="line">                    ans.append(&#x27;&#x27;.join(expr))</span><br><span class="line">                return</span><br><span class="line">                # æœªè¾¾åˆ°æœ€å¤§é•¿åº¦ ç»§ç»­é€’å½’å¯»æ‰¾å¯èƒ½çš„å­—ç¬¦ä¸²</span><br><span class="line">            signIndex = len(expr)  # ç¬¦å·ä½</span><br><span class="line">            if loc &gt; 0:</span><br><span class="line">                expr.append(&#x27;&#x27;)  # ç¬¦å·ä½å ä½</span><br><span class="line">            temp_num = 0  # è¿ç»­çš„æ•°å­—</span><br><span class="line">            for j in range(loc, num_len):</span><br><span class="line">                # å»é™¤å‰å¯¼0 å³ç¬¬ä¸€ä½ä¸èƒ½æ˜¯0</span><br><span class="line">                if j &gt; loc and num[loc] == &#x27;0&#x27;:</span><br><span class="line">                    break</span><br><span class="line">                temp_num = temp_num * 10 + int(num[j])</span><br><span class="line">                expr.append(num[j])</span><br><span class="line">                # åˆ¤æ–­ç¬¦å·çš„æƒ…å†µ</span><br><span class="line">                if loc == 0:</span><br><span class="line">                    backtrack(expr, j + 1, temp_num, temp_num)</span><br><span class="line">                else:</span><br><span class="line">                    expr[signIndex] = &#x27;+&#x27;</span><br><span class="line">                    backtrack(expr, j + 1, res + temp_num, temp_num)</span><br><span class="line">                    expr[signIndex] = &#x27;-&#x27;</span><br><span class="line">                    backtrack(expr, j + 1, res - temp_num, -temp_num)</span><br><span class="line">                    expr[signIndex] = &#x27;*&#x27;</span><br><span class="line">                    backtrack(expr, j + 1, res - mul + mul * temp_num, mul * temp_num)</span><br><span class="line">            del expr[signIndex:]  # æ¸…é™¤è®¡ç®—å¤šä½™çš„å­—ç¬¦ä¸²</span><br><span class="line"></span><br><span class="line">        backtrack([], 0, 0, 0)</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    num = &quot;123&quot;</span><br><span class="line">    target = 6</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.addOperators(num, target)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="301-åˆ é™¤æ— æ•ˆçš„æ‹¬å·"><a href="#301-åˆ é™¤æ— æ•ˆçš„æ‹¬å·" class="headerlink" title="301. åˆ é™¤æ— æ•ˆçš„æ‹¬å·"></a>301. åˆ é™¤æ— æ•ˆçš„æ‹¬å·</h2><blockquote><p>æš‚æ—¶ä¸åš</p></blockquote><h2 id="352-å°†æ•°æ®æµå˜ä¸ºå¤šä¸ªä¸ç›¸äº¤åŒºé—´"><a href="#352-å°†æ•°æ®æµå˜ä¸ºå¤šä¸ªä¸ç›¸äº¤åŒºé—´" class="headerlink" title="352. å°†æ•°æ®æµå˜ä¸ºå¤šä¸ªä¸ç›¸äº¤åŒºé—´"></a>352. å°†æ•°æ®æµå˜ä¸ºå¤šä¸ªä¸ç›¸äº¤åŒºé—´</h2><blockquote><p>è¯´å®è¯ é¢˜ç›®ç»™çš„ç¤ºä¾‹æ²¡çœ‹æ‡‚</p><p>çœ‹äº†å®˜æ–¹é¢˜è§£åå‘ç°è¿™æ˜¯ä¸€ä¸ªåŒºé—´é—®é¢˜ <a href="https://leetcode-cn.com/problems/data-stream-as-disjoint-intervals/solution/jiang-shu-ju-liu-bian-wei-duo-ge-bu-xian-hm1r/">https://leetcode-cn.com/problems/data-stream-as-disjoint-intervals/solution/jiang-shu-ju-liu-bian-wei-duo-ge-bu-xian-hm1r/</a></p><p>ä½¿ç”¨<strong>æœ‰åºæ˜ å°„</strong>æ”¯æŒæŸ¥è¯¢ã€Œæœ€å¤§çš„æ¯”æŸä¸ªå…ƒç´ å°çš„é”®ã€ä»¥åŠã€Œæœ€å°çš„æ¯”æŸä¸ªå…ƒç´ å¤§çš„é”®ã€è¿™ä¸¤ä¸ªæ“ä½œã€‚</p></blockquote><p>é¢˜ç›®æœ‰ç‚¹éš¾ï¼Œå…ˆå­¦å­¦bisectæ¨¡å—å§ï¼Œç”¨åœ¨äºŒåˆ†æœç´¢ã€‚</p><h2 id="502-IPO"><a href="#502-IPO" class="headerlink" title="502. IPO"></a>502. IPO</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">from heapq import heappush, heappop</span><br><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def findMaximizedCapital(self, k: int, w: int, profits: List[int], capital: List[int]) -&gt; int:</span><br><span class="line">        # æ”¶ç›Šè‚¯å®šæ¯”æŠ•èµ„å¤§ æ‰€ä»¥å½“ å½“å‰èµ„æœ¬å¯ä»¥å®Œæˆè€—èµ„æœ€å¤§çš„é¡¹ç›®æ—¶ æ‰€è·åˆ©æ¶¦ä¸€å®šè¶³å¤Ÿå®Œæˆå‰©ä½™é¡¹ç›® å› æ­¤ä»é¡¹ç›®ä¸­é€‰æ‹©kä¸ªåˆ©æ¶¦æœ€å¤§çš„é¡¹ç›®å®Œæˆå³å¯</span><br><span class="line">        if w &gt;= max(capital):</span><br><span class="line">            return w + sum(nlargest(k, profits))</span><br><span class="line">        #  nlargest(k,list) nsmallest() æ‰¾å‡ºé›†åˆä¸­æœ€å¤§æˆ–è€…æœ€å°çš„kä¸ªå…ƒç´ </span><br><span class="line">        n = len(profits)</span><br><span class="line">        # å·²å®Œæˆé¡¹ç›®æ•°</span><br><span class="line">        curr = 0</span><br><span class="line">        # å°†æŠ•èµ„æˆæœ¬å’Œåˆ©æ¶¦ç»‘å®š</span><br><span class="line">        arr = [(capital[i], profits[i]) for i in range(n)]</span><br><span class="line">        # æŒ‰ä»å°åˆ°å¤§çš„é¡ºåºæ’åº</span><br><span class="line">        arr.sort(key=lambda x: x[0])</span><br><span class="line">        print(arr)</span><br><span class="line">        pq = []</span><br><span class="line">        for _ in range(k):</span><br><span class="line">            while curr &lt; n and arr[curr][0] &lt;= w:</span><br><span class="line">                # æˆæœ¬å……è¶³çš„æƒ…å†µä¸‹ å°†åˆ©æ¶¦å‹å…¥å¤§æ ¹å †ä¸­</span><br><span class="line">                heappush(pq, -arr[curr][1])</span><br><span class="line">                curr += 1</span><br><span class="line">            print(pq)</span><br><span class="line">            if pq:</span><br><span class="line">                # å–ç›¸åæ•° ç›¸åŠ </span><br><span class="line">                w -= heappop(pq)</span><br><span class="line">            else:</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">        return w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    k = 3</span><br><span class="line">    w = 0</span><br><span class="line">    profits = [1, 2, 3]  # çº¯åˆ©æ¶¦</span><br><span class="line">    capital = [0, 1, 2]  # æŠ•èµ„æœ€å°èµ„æœ¬</span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.findMaximizedCapital(k, w, profits, capital)</span><br></pre></td></tr></table></figure><h2 id="ğŸŒŸ600-ä¸å«è¿ç»­1çš„éè´Ÿæ•´æ•°"><a href="#ğŸŒŸ600-ä¸å«è¿ç»­1çš„éè´Ÿæ•´æ•°" class="headerlink" title="ğŸŒŸ600. ä¸å«è¿ç»­1çš„éè´Ÿæ•´æ•°"></a>ğŸŒŸ600. ä¸å«è¿ç»­1çš„éè´Ÿæ•´æ•°</h2><blockquote><p>é¢˜è§£ï¼š<a href="https://leetcode-cn.com/problems/non-negative-integers-without-consecutive-ones/solution/suan-fa-xiao-ai-wo-lai-gei-ni-jie-shi-qi-4nh4/">https://leetcode-cn.com/problems/non-negative-integers-without-consecutive-ones/solution/suan-fa-xiao-ai-wo-lai-gei-ni-jie-shi-qi-4nh4/</a></p></blockquote><p><em>å¤ªéš¾äº†æ…¢æ…¢æ”»å…‹</em></p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç®—æ³• </tag>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexoé…ç½®</title>
      <link href="/2021/12/30/hexo%E9%85%8D%E7%BD%AE/"/>
      <url>/2021/12/30/hexo%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="hexoé…ç½®"><a href="#hexoé…ç½®" class="headerlink" title="hexoé…ç½®"></a>hexoé…ç½®</h1><h2 id="æ­£ç¡®çš„package-json"><a href="#æ­£ç¡®çš„package-json" class="headerlink" title="æ­£ç¡®çš„package.json"></a>æ­£ç¡®çš„package.json</h2><blockquote><p>ä¸»è¦è§£å†³ mathjax å…¬å¼æ˜¾ç¤ºbug</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;hexo-site&quot;,</span><br><span class="line">  &quot;version&quot;: &quot;0.0.0&quot;,</span><br><span class="line">  &quot;private&quot;: true,</span><br><span class="line">  &quot;scripts&quot;: &#123;</span><br><span class="line">    &quot;build&quot;: &quot;hexo generate&quot;,</span><br><span class="line">    &quot;clean&quot;: &quot;hexo clean&quot;,</span><br><span class="line">    &quot;deploy&quot;: &quot;hexo deploy&quot;,</span><br><span class="line">    &quot;server&quot;: &quot;hexo server&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hexo&quot;: &#123;</span><br><span class="line">    &quot;version&quot;: &quot;6.0.0&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dependencies&quot;: &#123;</span><br><span class="line">    &quot;hexo&quot;: &quot;^6.0.0&quot;,</span><br><span class="line">    &quot;hexo-generator-archive&quot;: &quot;^1.0.0&quot;,</span><br><span class="line">    &quot;hexo-generator-category&quot;: &quot;^1.0.0&quot;,</span><br><span class="line">    &quot;hexo-generator-index&quot;: &quot;^2.0.0&quot;,</span><br><span class="line">    &quot;hexo-generator-search&quot;: &quot;^2.4.3&quot;,</span><br><span class="line">    &quot;hexo-generator-tag&quot;: &quot;^1.0.0&quot;,</span><br><span class="line">    &quot;hexo-renderer-ejs&quot;: &quot;^2.0.0&quot;,</span><br><span class="line">    &quot;hexo-renderer-kramed&quot;: &quot;^0.1.4&quot;,</span><br><span class="line">    &quot;hexo-renderer-pug&quot;: &quot;^2.0.0&quot;,</span><br><span class="line">    &quot;hexo-renderer-stylus&quot;: &quot;^2.0.1&quot;,</span><br><span class="line">    &quot;hexo-server&quot;: &quot;^2.0.0&quot;,</span><br><span class="line">    &quot;hexo-theme-landscape&quot;: &quot;^0.0.3&quot;,</span><br><span class="line">    &quot;hexo-wordcount&quot;: &quot;^6.0.1&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="GitHub-443é”™è¯¯"><a href="#GitHub-443é”™è¯¯" class="headerlink" title="GitHub 443é”™è¯¯"></a>GitHub 443é”™è¯¯</h2><p>OpenSSL SSL_connect: Connection was reset in connection to github.com:443</p><ul><li><p>æ–¹æ³•ä¸€</p><p>æ£€æŸ¥VPNç«¯å£å·ï¼Œå¹¶æ›¿æ¢1087</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy 127.0.0.1:1087</span><br><span class="line">git config --global https.proxy 127.0.0.1:1087</span><br></pre></td></tr></table></figure><p>â€‹    è‹¥é…ç½®è¿‡ï¼Œæ’¤é”€ä¸Šè¿°é…ç½®</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global --unset http.proxy</span><br><span class="line">git config --global --unset https.proxy</span><br></pre></td></tr></table></figure><blockquote><p>ä¸‹é¢æ˜¯å‡ ä¸ªå¸¸ç”¨çš„gité…ç½®æŸ¥çœ‹å‘½ä»¤ï¼š</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy #æŸ¥çœ‹gitçš„httpä»£ç†é…ç½®</span><br><span class="line">git config --global https.proxy #æŸ¥çœ‹gitçš„httpsä»£ç†é…ç½®</span><br><span class="line">git config --global -l #æŸ¥çœ‹gitçš„æ‰€æœ‰é…ç½®</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æœ€ä¼˜åŒ–æ–¹æ³•</title>
      <link href="/2021/12/30/optimal_method/"/>
      <url>/2021/12/30/optimal_method/</url>
      
        <content type="html"><![CDATA[<h1 id="æœ€ä¼˜åŒ–æ–¹æ³•"><a href="#æœ€ä¼˜åŒ–æ–¹æ³•" class="headerlink" title="æœ€ä¼˜åŒ–æ–¹æ³•"></a>æœ€ä¼˜åŒ–æ–¹æ³•</h1><h2 id="æå°ç‚¹åˆ¤å®šæ¡ä»¶"><a href="#æå°ç‚¹åˆ¤å®šæ¡ä»¶" class="headerlink" title="æå°ç‚¹åˆ¤å®šæ¡ä»¶"></a>æå°ç‚¹åˆ¤å®šæ¡ä»¶</h2><p>å‡¸å‡½æ•°ï¼šHessençŸ©é˜µ åŠæ­£å®š ï¼ˆæ­£å®šæ—¶ä¸ºä¸¥æ ¼å‡¸å‡½æ•°ï¼‰</p><p>å‡¹å‡½æ•°ï¼šHessençŸ©é˜µ åŠè´Ÿå®š</p><h2 id="çº¿æ€§è§„åˆ’"><a href="#çº¿æ€§è§„åˆ’" class="headerlink" title="çº¿æ€§è§„åˆ’"></a>çº¿æ€§è§„åˆ’</h2><p><strong>çº¿æ€§è§„åˆ’</strong>çš„ç›®æ ‡å‡½æ•°<strong>ç­‰å€¼é¢</strong>æ˜¯<strong>å¹³è¡Œå¹³é¢</strong>ã€‚</p><h4 id="æ ‡å‡†çº¿æ€§è§„åˆ’"><a href="#æ ‡å‡†çº¿æ€§è§„åˆ’" class="headerlink" title="æ ‡å‡†çº¿æ€§è§„åˆ’"></a>æ ‡å‡†çº¿æ€§è§„åˆ’</h4><blockquote><p>ä¸»çº¦æŸéƒ½æ˜¯å³ç«¯é¡¹éè´Ÿçš„ç­‰å¼çº¦æŸ</p></blockquote><p>ç»“æœè¦ä¸æ˜¯ æœ€ä¼˜è§£ è¦ä¸æ˜¯ è§£æ— ç•Œã€‚ï¼ˆ<strong>ä¸ä¼šå‡ºç° æ— è§£</strong>ï¼‰</p><p>æ ‡å‡†çº¿æ€§è§„åˆ’æœ‰å®¹è®¸è§£ï¼Œåˆ™å¿…æœ‰åŸºæœ¬å®¹è®¸è§£ã€‚</p><p>è‹¥æœ‰æœ€ä¼˜è§£ï¼Œåˆ™å¿…æœ‰æœ€ä¼˜åŸºæœ¬å®¹è®¸è§£ã€‚</p><h4 id="å…¸èŒƒçº¿æ€§è§„åˆ’"><a href="#å…¸èŒƒçº¿æ€§è§„åˆ’" class="headerlink" title="å…¸èŒƒçº¿æ€§è§„åˆ’"></a>å…¸èŒƒçº¿æ€§è§„åˆ’</h4><p>Ié˜¶æ®µçº¿æ€§è§„åˆ’æˆ–å­˜åœ¨æœ€ä¼˜åŸºæœ¬å®¹è®¸è§£(W=0)ï¼Œæˆ– åŸé—®é¢˜æ— è§£(W&gt;0)ã€‚</p><p>å…¸èŒƒçº¿æ€§è§„åˆ’ æˆ–è€… è§£æ— ç•Œ æˆ–è€… æœ‰æœ€ä¼˜è§£ <strong>ä¸ä¼šå‡ºç°æ— è§£</strong>çš„æƒ…å†µã€‚</p><ul><li><p>ç¬¬ä¸€é˜¶æ®µ</p><p>è§£è¾…åŠ©çº¿æ€§è§„åˆ’ï¼Œç›®çš„æ˜¯æ±‚æ ‡å‡†çº¿æ€§è§„åˆ’ ä¸»çº¦æŸçš„ä¸€ä¸ª G-Jæ–¹ç¨‹ç»„</p></li><li><p>ç¬¬äºŒé˜¶æ®µ</p><p>è§£æ ‡å‡†çº¿æ€§è§„åˆ’ï¼Œå³è§£åŸçº¿æ€§è§„åˆ’</p></li></ul><h3 id="å•çº¯å½¢"><a href="#å•çº¯å½¢" class="headerlink" title="å•çº¯å½¢"></a>å•çº¯å½¢</h3><blockquote><p>æœ¬è´¨ä¸Šæ˜¯è§£å…¸èŒƒçº¿æ€§è§„åˆ’çš„ç®—æ³•</p><p>æ ¹æœ¬ç›®æ ‡æ˜¯è®©äººå·¥å˜é‡å…¨éƒ¨é€€åŸº</p><p>å…·æœ‰æœ‰é™ç»ˆæ­¢æ€§</p></blockquote><p>è‡ªç”±å˜é‡    $x_1 = x_2 -x_3$</p><h4 id="æœ€ä¼˜æ€§æ£€éªŒ"><a href="#æœ€ä¼˜æ€§æ£€éªŒ" class="headerlink" title="æœ€ä¼˜æ€§æ£€éªŒ"></a>æœ€ä¼˜æ€§æ£€éªŒ</h4><p>æœ€å¤§åˆ¤åˆ«æ•°$\delta _l$</p><ul><li>æœ€ä¼˜è§£  $\delta _l \leq 0$</li><li>æ— ç•Œ  $\delta _l \gt 0 $  $a_l \leq0$    å¼‚å·</li><li>æ— è§£ <strong>ç¬¬ä¸€é˜¶æ®µ</strong> æœ€ä¼˜å€¼ $w&gt;0$</li></ul><blockquote><p> $\delta _l \gt 0 $  $a_l \nleq0 $    å¯ä»¥ç»§ç»­è¿­ä»£ï¼Œå…¸èŒƒçº¿æ€§è§„åˆ’ä¸ä¼šå‡ºç°æ— è§£çš„æƒ…å†µã€‚</p></blockquote><h4 id="ç‰¹æ®Šæƒ…å†µ"><a href="#ç‰¹æ®Šæƒ…å†µ" class="headerlink" title="ç‰¹æ®Šæƒ…å†µ"></a>ç‰¹æ®Šæƒ…å†µ</h4><ul><li>è‹¥æ‰€æœ‰åˆ¤åˆ«æ•°éƒ½ &lt;0 ä½†æ˜¯äººå·¥å˜é‡æ²¡æœ‰é€€åŸºï¼Œä»»é€‰ä¸€ä¸ªéäººå·¥å˜é‡ç³»æ•°çš„<strong>é0</strong>å…ƒç´ ä½œä¸ºä¸»å…ƒï¼Œåœ¨è¿›è¡Œä¸€æ¬¡æ¢åŸºè¿ç®—ï¼Œå¾—åˆ°æ ‡å‡†çº¿æ€§è§„åˆ’ä¸»çº¦æŸçš„G-Jæ–¹ç¨‹ç»„ã€‚</li><li>è‹¥åŸºå˜é‡ä¸­æœ‰äººå·¥å˜é‡ï¼Œä½†éäººå·¥å˜é‡å˜é‡çš„ç³»æ•°éƒ½ä¸º0ï¼Œbä¹Ÿä¸º0ï¼Œå¯ä»¥ç›´æ¥åˆ’æ‰ï¼Œè¿›å…¥ç¬¬äºŒé˜¶æ®µã€‚</li><li>æ²¡æœ‰çº¦æŸçš„å˜é‡æ˜¯ è‡ªç”±å˜é‡ï¼Œå˜ä¸º$x_1 = x_2 -x_3$</li></ul><h3 id="ç›´çº¿æœç´¢"><a href="#ç›´çº¿æœç´¢" class="headerlink" title="ç›´çº¿æœç´¢"></a>ç›´çº¿æœç´¢</h3><ul><li>åŒºé—´æ”¶ç¼©æ³•ï¼ˆé»„é‡‘åˆ†å‰²æ³• ç”¨äºä»»ä½•å•è°·å‡½æ•°æ±‚æå°å€¼ï¼‰</li><li>å‡½æ•°é€¼è¿‘æ³•ï¼ˆæŠ›ç‰©çº¿æ’å€¼æ³• é€‚ç”¨äºè¿ç»­å•è°·å‡½æ•°ï¼‰</li></ul><h3 id="æœ€é€Ÿä¸‹é™æ³•"><a href="#æœ€é€Ÿä¸‹é™æ³•" class="headerlink" title="æœ€é€Ÿä¸‹é™æ³•"></a>æœ€é€Ÿä¸‹é™æ³•</h3><blockquote><p>ä¸å…·å¤‡äºŒæ¬¡ç»ˆæ­¢æ€§ï¼Œçº¿æ€§æ”¶æ•›ç®—æ³•ï¼Œæ— é™æ¬¡è¿­ä»£ã€‚</p><p>å¦‚æœåˆå§‹ç‚¹é€‰åœ¨<strong>æ¤­çƒç­‰å€¼é¢ï¼ˆæ¤­åœ†ç­‰å€¼çº¿ï¼‰</strong>ä¸Šï¼Œ<strong>è¿­ä»£ä¸€æ¬¡</strong>å°±ä¼šå¾—åˆ°æå°ç‚¹ï¼Œå¦åˆ™ä¼šæ— é™æ¬¡è¿­ä»£ã€‚</p></blockquote><p>ä¼˜ç‚¹ï¼šç›´è§‚ ç®€å•</p><p>ç¼ºç‚¹ï¼šæ”¶æ•›é€Ÿåº¦æ…¢ å®ç”¨æ€§å·® é”¯é½¿ç°è±¡</p><p>åŸºæœ¬æ€æƒ³ï¼šåœ¨ç‚¹$x_k$å¤„æ²¿è´Ÿæ¢¯åº¦æ–¹å‘$p_k$è¿›è¡Œç›´çº¿æœç´¢ã€‚</p><p>ç›´çº¿æœç´¢çš„æ€§è´¨ï¼š$g_{k+1}Â·g_k = 0$         ç›¸é‚»è¿­ä»£ç‚¹æ¢¯åº¦æ­£äº¤ã€‚</p><p>é”¯é½¿ç°è±¡ï¼šæœ€é€Ÿä¸‹é™æ³•çš„è¿­ä»£ç‚¹åœ¨å‘æå°ç‚¹é è¿‘çš„è¿‡ç¨‹ä¸­ï¼Œèµ°çš„æ˜¯æ›²æŠ˜çš„è·¯çº¿ï¼Œåä¸€æ¬¡æœç´¢æ–¹å‘$p_{k+1}$ä¸å‰ä¸€æ¬¡æœç´¢æ–¹å‘$p_k$å‚ç›´ï¼Œç§°ä¹‹ä¸ºé”¯é½¿ç°è±¡ã€‚</p><h3 id="ç‰›é¡¿æ³•"><a href="#ç‰›é¡¿æ³•" class="headerlink" title="ç‰›é¡¿æ³•"></a>ç‰›é¡¿æ³•</h3><p>åŸºæœ¬æ€æƒ³ï¼šä»$x<em>k$åˆ°$x</em>{k+1}$çš„è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œåœ¨ç‚¹$x_k$å¤„å¯¹$f(x)$æŒ‰Taylorçº§æ•°å±•å¼€åˆ°ç¬¬ä¸‰é¡¹ï¼Œè§£å‡ºæå°ç‚¹ã€‚å½“ç›®æ ‡å‡½æ•°$f(x)$æ˜¯æ­£å®šäºŒæ¬¡å‡½æ•°çš„æ—¶å€™ï¼Œç‰›é¡¿æ³•è¿­ä»£ä¸€æ¬¡å°±ä¼šå¾—åˆ°æœ€ä¼˜è§£ã€‚</p><p>å‡ ä½•è§£é‡Šï¼šåœ¨å‡½æ•°$f(x)$è¿‡ç‚¹$x_k$çš„ç­‰å€¼é¢æ–¹ç¨‹ï¼Œç”¨ä¸€ä¸ªä¸æ›²é¢æœ€å¯†åˆ‡çš„äºŒæ¬¡æ›²é¢ä»£æ›¿ä»–ã€‚</p><p><strong>Taylorå±•å¼€</strong></p><script type="math/tex; mode=display">f(x)=f(x_k)+g_x^T(x-x_k)+\frac{1}{2}(x-x_k)^TG_{x_k}(x-x_k)</script><h4 id="ä¿®æ­£ç‰›é¡¿"><a href="#ä¿®æ­£ç‰›é¡¿" class="headerlink" title="ä¿®æ­£ç‰›é¡¿"></a>ä¿®æ­£ç‰›é¡¿</h4><p>â€‹        å¯¹äº<strong>éæ­£å®šäºŒæ¬¡å‡½æ•°</strong>ï¼Œç‰›é¡¿æ³•ä¸€èˆ¬ä¸ä¼šæœ‰é™æ­¥ç»ˆæ­¢ï¼ŒåŸå› ï¼š</p><p><strong>1.HesseçŸ©é˜µå¥‡å¼‚</strong></p><script type="math/tex; mode=display">p_k = -g_k</script><p>ç›´çº¿æœç´¢</p><script type="math/tex; mode=display">x_{k+1}=x_k+t_kÂ·p_k</script><p><strong>2.HesseçŸ©é˜µå¯é€†</strong></p><ul><li><p>ç‰›é¡¿æ–¹å‘ä¸å­˜åœ¨ï¼ˆå‚ç›´ï¼‰</p><pre><code>1.    $p_k = -g_k$1.    ç›´çº¿æœç´¢</code></pre></li><li><p>æ­¥é•¿ä¸º1ä¸åˆé€‚ï¼ˆä¸‹é™æ–¹å‘ï¼‰</p><ol><li>ç›´çº¿æœç´¢</li></ol></li><li>ç‰›é¡¿æ–¹å‘ä¸æ˜¯ä¸‹é™æ–¹å‘ï¼ˆä¸Šå‡æ–¹å‘ï¼‰<ol><li>$p_k = G_k^{-1}Â·g_k$</li><li>ç›´çº¿æœç´¢</li></ol></li></ul><h3 id="å…±è½­æ–¹å‘æ³•"><a href="#å…±è½­æ–¹å‘æ³•" class="headerlink" title="å…±è½­æ–¹å‘æ³•"></a>å…±è½­æ–¹å‘æ³•</h3><p>ä¼˜ç‚¹ï¼š<strong>å…‹æœäº†æœ€é€Ÿä¸‹é™æ³•çš„é”¯é½¿ç°è±¡</strong>ï¼Œä»è€Œæé«˜äº†æ”¶æ•›é€Ÿåº¦ï¼Œè¿­ä»£å…¬å¼ç®€å•ï¼Œä¸å¿…è®¡ç®—ç›®æ ‡å‡½æ•°çš„äºŒé˜¶å¯¼æ•°ã€‚ä¸ç‰›é¡¿æ³•ç›¸æ¯”ï¼Œå‡å°‘äº†è®¡ç®—é‡å’Œå­˜å‚¨é‡ã€‚</p><p>äºŒæ¬¡ç»ˆæ­¢æ€§ï¼šå¯¹äºnå…ƒæ­£å®šäºŒæ¬¡å‡½æ•°ï¼Œä»ä»»æ„ç‚¹å‡ºå‘ï¼Œé¡ºæ¬¡æ²¿ç€nä¸ªå…±è½­æ–¹å‘ä½œæœ€å¤šnæ¬¡ç›´çº¿æœç´¢ï¼Œå°±å¯ä»¥æ±‚å¾—ç›®æ ‡å‡½æ•°çš„æå°ç‚¹ã€‚</p><p>å…±è½­æ¢¯åº¦æ³•ï¼šåˆå§‹å…±è½­æ¢¯åº¦å‘é‡$p<em>0$æ°å¥½å–ä¸ºåˆå§‹ç‚¹$x_0$çš„è´Ÿæ¢¯åº¦$-g_0$ï¼Œè€Œå…¶ä½™å…±è½­å‘é‡$p_k$ï¼Œç”±ç¬¬$k$ä¸ªè¿­ä»£ç‚¹$x_k$å¤„çš„è´Ÿæ¢¯åº¦$-g_k$ä¸å·²ç»å¾—åˆ°çš„å‘é‡$p</em>{k-1}$çš„çº¿æ€§ç»„åˆæ¥ç¡®å®šï¼Œé‚£ä¹ˆè¿™ä¸ªå…±è½­æ–¹å‘æ³•å°±ç§°ä¸ºå…±è½­æ¢¯åº¦æ³•ã€‚</p><h3 id="DFPç®—æ³•"><a href="#DFPç®—æ³•" class="headerlink" title="DFPç®—æ³•"></a>DFPç®—æ³•</h3><p>æ€§è´¨ï¼šè‹¥åˆå§‹çŸ©é˜µ$H_0$å¯¹ç§°æ­£å®šï¼Œåˆ™$H_k$ä¸­æ¯ä¸€ä¸ªéƒ½å¯¹ç§°æ­£å®šã€‚</p><h3 id="æ­¥é•¿åŠ é€Ÿæ³•"><a href="#æ­¥é•¿åŠ é€Ÿæ³•" class="headerlink" title="æ­¥é•¿åŠ é€Ÿæ³•"></a>æ­¥é•¿åŠ é€Ÿæ³•</h3><p>ä¸è¦æ±‚ç›®æ ‡å‡½æ•°å¯å¯¼æˆ–å¯å¾®ã€‚</p><p>åŸºæœ¬æ€æƒ³ï¼šæ­¥é•¿åŠ é€Ÿæ³•ä¸»è¦ç”±äº¤æ›¿è¿›è¡Œçš„â€œæ¢æµ‹æœç´¢â€å’Œâ€œæ¨¡å¼ç§»åŠ¨â€ç»„æˆã€‚</p><ul><li>æ¢æµ‹æœç´¢ï¼šä¸ºäº†<strong>å¯»æ‰¾å½“å‰è¿­ä»£ç‚¹çš„ä¸‹é™æ–¹å‘</strong></li><li>æ¨¡å¼ç§»åŠ¨ï¼šæ²¿ç€ä¸‹é™æ–¹å‘<strong>å¯»æ‰¾æ–°çš„è¿­ä»£ç‚¹</strong></li></ul><p>æ¢æµ‹çš„å‡ºå‘ç‚¹ï¼š<strong>å‚è€ƒç‚¹</strong></p><p>å‘¨å›´æ¯”ä»–æ›´å¥½çš„ç‚¹ï¼š<strong>åŸºç‚¹</strong></p><p>å¾—åˆ°çš„ä¸‹é™æ–¹å‘ï¼š<strong>æ¨¡å¼</strong></p><p>ä»åŸºç‚¹æ²¿æ¨¡å¼ä½œç›´çº¿æœç´¢ï¼š<strong>æ¨¡å¼ç§»åŠ¨</strong></p><p>Iå‹æ¢æµ‹ï¼š</p><blockquote><p> <strong>åœ¨åŸºç‚¹å‘¨å›´æ„é€ ä¸€ä¸ªæ¨¡å¼</strong></p><p>å¤±è´¥ç¼©å°æ­¥é•¿</p></blockquote><p>IIå‹æ¢æµ‹ï¼š</p><blockquote><p> <strong>åˆ¤åˆ«ä¸Šæ¬¡çš„æ¨¡å¼ç§»åŠ¨æ˜¯å¦æˆåŠŸ</strong></p><p>å¤±è´¥æ’¤é”€ä¸Šæ¬¡æ¨¡å¼ç§»åŠ¨ï¼Œå°†ä¸Šæ¬¡çš„åŸºç‚¹ä½œä¸ºå‚è€ƒç‚¹ï¼Œå¼€å§‹Iå‹æ¢æµ‹</p><p>å¤±è´¥åŸå› ï¼šå‰ä¸€æ¬¡æ¨¡å¼ç§»åŠ¨è¿‡å¤§ï¼Œç¦»å¼€äº†æå°ç‚¹æ‰€åœ¨åŒºåŸŸ</p></blockquote><h3 id="æœ€å°äºŒä¹˜æ³•"><a href="#æœ€å°äºŒä¹˜æ³•" class="headerlink" title="æœ€å°äºŒä¹˜æ³•"></a>æœ€å°äºŒä¹˜æ³•</h3><p>$y=x_1t+x_2$</p><h4 id="çº¿æ€§æ¨¡å‹"><a href="#çº¿æ€§æ¨¡å‹" class="headerlink" title="çº¿æ€§æ¨¡å‹"></a>çº¿æ€§æ¨¡å‹</h4><script type="math/tex; mode=display">min ||Ax-b||^2</script><script type="math/tex; mode=display">min s(x_1,x_2) = \sum(x_1t+x_2-y)^2</script><p>ç­‰ä»·äºè§£ æ³•æ–¹ç¨‹ç»„</p><script type="math/tex; mode=display">A^TAX=A^Tb</script><p>æœ€ä¼˜è§£ï¼š$x^* = (A^TA)^{-1}A^Tb$</p><p>æ£€éªŒ</p><h2 id="çº¦æŸè§„åˆ’é—®é¢˜"><a href="#çº¦æŸè§„åˆ’é—®é¢˜" class="headerlink" title="çº¦æŸè§„åˆ’é—®é¢˜"></a>çº¦æŸè§„åˆ’é—®é¢˜</h2><h3 id="ç­‰å¼çº¦æŸ"><a href="#ç­‰å¼çº¦æŸ" class="headerlink" title="ç­‰å¼çº¦æŸ"></a>ç­‰å¼çº¦æŸ</h3><ul><li>Lagrangeå‡½æ•°</li></ul><p>â€‹        Lagrangeä¹˜å­ï¼Œä½¿å¾—æ±‚è§£ç­‰å¼çº¦æŸé—®é¢˜ï¼Œç­‰ä»·äºæ±‚è§£æ— çº¦æŸé—®é¢˜ã€‚</p><p>å‡ ä½•è¡¨ç¤ºï¼š</p><p>â€‹        æ‹‰æ ¼æœ—æ—¥å‡½æ•°å…³äºxçš„HesseçŸ©é˜µåœ¨$x^<em>$çš„<strong>çº¦æŸæ›²é¢åˆ‡å¹³é¢çš„äº¤é›†ä¸Šæ­£å®š</strong>ï¼Œåˆ™$x^</em>$æ˜¯ç­‰å¼çº¦æŸé—®é¢˜çš„ä¸¥æ ¼å±€éƒ¨æå°ç‚¹ã€‚</p><h3 id="ä¸ç­‰å¼çº¦æŸ"><a href="#ä¸ç­‰å¼çº¦æŸ" class="headerlink" title="ä¸ç­‰å¼çº¦æŸ"></a>ä¸ç­‰å¼çº¦æŸ</h3><p>ä¸ç­‰å¼çº¦æŸå…³äºå®¹è®¸é›†çš„ä»»æ„å†…ç‚¹éƒ½æ˜¯ä¸èµ·ä½œç”¨çš„çº¦æŸï¼Œåªæœ‰å®¹è®¸é›†çš„è¾¹ç•Œç‚¹æ‰èƒ½ä½¿æŸä¸ªæˆ–æŸäº›ä¸ç­‰å¼çº¦æŸå˜æˆèµ·ä½œç”¨çº¦æŸã€‚</p><p>å®¹è®¸æ–¹å‘å‘é‡ï¼š</p><ul><li>å¯¹äºèµ·ä½œç”¨çš„çº¦æŸ</li></ul><script type="math/tex; mode=display">\nabla s_i(x)^Tp>0</script><h4 id="å‡ ä½•æœ€ä¼˜æ€§æ¡ä»¶"><a href="#å‡ ä½•æœ€ä¼˜æ€§æ¡ä»¶" class="headerlink" title="å‡ ä½•æœ€ä¼˜æ€§æ¡ä»¶"></a>å‡ ä½•æœ€ä¼˜æ€§æ¡ä»¶</h4><p>åˆ¤æ–­x* æ˜¯å¦ä¸ºå±€éƒ¨æå°ç‚¹ï¼š</p><p>â€‹        è‹¥$x^<em>$æ˜¯å±€éƒ¨æœ€ä¼˜ç‚¹ï¼Œåˆ™åœ¨ç‚¹$x^</em>$å¤„çš„<strong>å®¹è®¸æ–¹å‘é”¥å’Œä¸‹é™æ–¹å‘é”¥çš„äº¤é›†æ˜¯ç©ºé›†</strong>ã€‚</p><script type="math/tex; mode=display">\nabla s_i(x)^Tp>0 \\\nabla f(x)^Tp<0</script><h4 id="K-Tæ¡ä»¶"><a href="#K-Tæ¡ä»¶" class="headerlink" title="K-Tæ¡ä»¶"></a>K-Tæ¡ä»¶</h4><p>å‡ ä½•è¡¨ç¤ºï¼š</p><p>â€‹        è‹¥$x^<em>$æ˜¯æœ€ä¼˜ç‚¹ï¼Œåˆ™ç›®æ ‡å‡½æ•°åœ¨è¯¥ç‚¹çš„<strong>æ¢¯åº¦</strong>å¿…ä½äºç”±<em>*èµ·ä½œç”¨çº¦æŸå‡½æ•°çš„æ¢¯åº¦å¼ æˆçš„å‡¸é”¥ä¸­</em></em>ã€‚</p><p>å‡¸è§„åˆ’é—®é¢˜çš„<strong>æœ€ä¼˜æ€§</strong>å……åˆ†æ¡ä»¶ï¼š</p><p>â€‹        $f$æ˜¯å¯å¾®å‡¸å‡½æ•°ï¼Œ$s_i$æ˜¯å¯å¾®å‡¹å‡½æ•°ï¼Œ$h_i$æ˜¯çº¿æ€§å‡½æ•°ï¼Œå¦‚æœ$x^*$æ˜¯K-Tç‚¹ï¼Œé‚£ä¹ˆæ˜¯å…¨å±€æœ€ä¼˜ç‚¹ã€‚</p><p>$u_0$ä¸ä¸º0çš„å……è¦æ¡ä»¶ï¼š</p><p>â€‹        åœ¨$x^*$å¤„ï¼Œèµ·ä½œç”¨çš„çº¦æŸå‡½æ•°ï¼Œæ¢¯åº¦å…¨éƒ½çº¿æ€§æ— å…³ã€‚</p><h3 id="Z-å®¹è®¸æ–¹å‘æ³•"><a href="#Z-å®¹è®¸æ–¹å‘æ³•" class="headerlink" title="Z-å®¹è®¸æ–¹å‘æ³•"></a>Z-å®¹è®¸æ–¹å‘æ³•</h3><p>ç»ˆæ­¢æ¡ä»¶ï¼š</p><ul><li>$x^*$ä¸ºK-Tç‚¹çš„å……è¦æ¡ä»¶ï¼š</li></ul><script type="math/tex; mode=display">\nabla f(x)^Tp^*=0</script><p>â€‹        <strong>å¹¶ä¸”</strong>ï¼šAâ€™ å’Œ Cçš„è¡Œå‘é‡çº¿æ€§æ— å…³ã€‚</p><ul><li>ç»§ç»­è¿­ä»£ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªä¸‹é™æ–¹å‘å‘é‡</li></ul><script type="math/tex; mode=display">\nabla f(x)^Tp^*<0</script><ul><li>æ¢ç‚¹</li></ul><script type="math/tex; mode=display">\nabla f(x)^Tp^*>0</script><p>ç®—æ³•ï¼š</p><ul><li>ç¡®å®šå½“å‰è¿­ä»£ç‚¹çš„<strong>ä¸‹é™å®¹è®¸æ–¹å‘</strong></li><li>é€šè¿‡<strong>ç›´çº¿æœç´¢</strong>ç¡®å®šä¸‹ä¸€ä¸ªè¿­ä»£ç‚¹  ï¼ˆåœ¨ä¸‹é™å®¹è®¸æ–¹å‘ä½œls æœ€ä½³æ­¥é•¿å› å­æœ‰ä¸Šç•Œï¼‰</li><li>åˆ¤å®šæ–°çš„è¿­ä»£ç‚¹æ˜¯å¦ä¸ºé—®é¢˜çš„è§£</li></ul><p>åˆ¤æ–­å®¹è®¸æ–¹å‘ï¼š</p><ul><li><p>éçº¿æ€§çº¦æŸ</p><p><strong>$s(x)$ä¸ºèµ·ä½œç”¨çš„çº¦æŸ</strong></p></li></ul><script type="math/tex; mode=display">\nabla s(x)^Tp>0</script><ul><li>çº¿æ€§çº¦æŸ</li></ul><script type="math/tex; mode=display">A'p \geq 0</script><script type="math/tex; mode=display">Cp=0</script><h3 id="å¤–éƒ¨ç½šå‡½æ•°æ³•"><a href="#å¤–éƒ¨ç½šå‡½æ•°æ³•" class="headerlink" title="å¤–éƒ¨ç½šå‡½æ•°æ³•"></a>å¤–éƒ¨ç½šå‡½æ•°æ³•</h3><p>æƒ©ç½šç­–ç•¥ï¼šå¯¹å®¹è®¸ç‚¹ä¸äºˆæƒ©ç½šï¼Œå¯¹äºéå®¹è®¸ç‚¹ç»™äºˆæ— ç©·å¤§çš„æƒ©ç½šï¼Œå°†çº¦æŸé—®é¢˜è½¬åŒ–ä¸ºæ— çº¦æŸé—®é¢˜ã€‚</p><p>æƒ©ç½šé¡¹ç‰¹ç‚¹ï¼š</p><ul><li>åŒ…å«æœ‰å–å€¼è¶Šæ¥è¶Šå¤§çš„æ­£å› å­ $\mu$</li><li>å¯¹äºå®¹è®¸ç‚¹ï¼Œæƒ©ç½šé¡¹å–å€¼ä¸º0ï¼Œå¯¹äºéå®¹è®¸ç‚¹ï¼Œæƒ©ç½šé¡¹å–å€¼ä¸ºæ­£</li></ul><h3 id="H-ä¹˜å­æ³•"><a href="#H-ä¹˜å­æ³•" class="headerlink" title="H-ä¹˜å­æ³•"></a>H-ä¹˜å­æ³•</h3><blockquote><p>H-ä¹˜å­æ³•ç½šå› å­ä¸å¿…è¶‹äºæ— ç©·å¤§ï¼Œè€Œå¤–éƒ¨ç½šå‡½æ•°çš„ç½šå› å­è¦è¶‹äºæ— ç©·å¤§ï¼Œæœ¬è´¨æ˜¯ä¸ºäº†é˜²æ­¢HesseçŸ©é˜µæ¡ä»¶æ•°å˜å¾—è¶Šæ¥è¶Šåï¼Œå¯¼è‡´åœ¨è®¡ç®—ä¸­ï¼Œæ•°å€¼ç¨³å®šæ€§å˜å¾—è¶Šæ¥è¶Šå·®ã€‚</p><p>æ‹‰æ ¼æœ—æ—¥ä¹˜å­$\lambda$ä¸ç½šå› å­$\mu$å–å€¼æ— å…³ï¼Œåªè¦æ±‚$\mu$çš„å–å€¼ä¿è¯ä¹˜å­åºåˆ—æ”¶æ•›å³å¯ï¼Œä¸ç„¶ä¼šæœ‰æ— æ•°ä¸ªæ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼Œè¿™æ˜¯ä¸å¯èƒ½çš„ã€‚</p></blockquote><p><strong>æ”¹è¿›ï¼š</strong></p><ul><li>è§£å†³äº†å¤–éƒ¨ç½šå‡½æ•°å› ç½šå› å­å¢å¤§ï¼Œå¯¼è‡´çš„æ•°å€¼è®¡ç®—ä¸ç¨³å®šçš„é—®é¢˜ã€‚</li></ul><blockquote><p>ä¹˜å­æ³•æ˜¯é’ˆå¯¹å¤–éƒ¨ç½šå‡½æ•°æ³•çš„æ”¹è¿›ï¼Œå¤–éƒ¨ç½šå‡½æ•°æ³•<strong>éšç€ç½šå› å­çš„å¢å¤§</strong>ï¼Œå¢å¹¿ç›®æ ‡å‡½æ•°çš„HesseçŸ©é˜µæ¡ä»¶æ•°å˜å¾—è¶Šæ¥è¶Šåï¼Œå¯¼è‡´åœ¨è®¡ç®—ä¸­ï¼Œ<strong>æ•°å€¼ç¨³å®šæ€§å˜å¾—è¶Šæ¥è¶Šå·®</strong>ï¼Œéš¾ä»¥ç²¾ç¡®æ±‚è§£ã€‚</p></blockquote><p>â€‹        ä¹˜å­æ³•æ˜¯åœ¨<strong>çº¦æŸ</strong>é—®é¢˜çš„<strong>Lagrangeå‡½æ•°</strong>ä¸­åŠ å…¥ç›¸åº”çš„<strong>æƒ©ç½šé¡¹</strong>ï¼Œä½¿å¾—åœ¨æ±‚è§£æ— çº¦æŸé—®é¢˜çš„æ—¶å€™ï¼Œ<strong>ç½šå› å­ä¸å¿…è¶‹äºæ— ç©·å¤§</strong>å°±èƒ½å¾—åˆ°çº¦æŸé—®é¢˜çš„æœ€ä¼˜è§£ï¼Œä¿è¯æ•°å€¼è®¡ç®—çš„ç¨³å®šæ€§ã€‚</p><h4 id="ç»ˆæ­¢å‡†åˆ™"><a href="#ç»ˆæ­¢å‡†åˆ™" class="headerlink" title="ç»ˆæ­¢å‡†åˆ™"></a>ç»ˆæ­¢å‡†åˆ™</h4><p>å¦‚æœæ— çº¦æŸé—®é¢˜çš„æœ€ä¼˜è§£$x^<em>$æ˜¯åŸè§„åˆ’é—®é¢˜çš„<strong>å®¹è®¸ç‚¹</strong>ï¼Œé‚£ä¹ˆä¹Ÿæ˜¯åŸé—®é¢˜çš„<em>*æœ€ä¼˜è§£</em></em>ã€‚</p><p><strong>ç­‰å¼çº¦æŸ</strong></p><ul><li>ç½šå› å­$\mu$çš„ä½œç”¨</li></ul><p>â€‹    a.  ä¹˜å­åºåˆ—${\lambda_k}$ä¸æ”¶æ•›    ${\mu} &lt;\mu^*$</p><p>â€‹    b. æ”¶æ•›çš„æ…¢        ${\mu}\geq \mu^*$ä½†ä¸å¤Ÿå¤§</p><p>â€‹    c. $\frac{h(x<em>k)}{h(x</em>{k-1})} \geq 1$     ä¹˜å­åºåˆ—${\lambda_k}$å‘æ•£</p><p>â€‹    d.$\frac{h(x<em>k)}{h(x</em>{k-1})}$ä»‹äº$(0,1)$ æ”¶æ•›ï¼Œæ¯”å€¼è¶Šå° ï¼Œæ”¶æ•›è¶Šå¿«</p><p>ç»ˆæ­¢å‡†åˆ™ï¼š$h(x)=0$</p><p><strong>ä¸ç­‰å¼çº¦æŸ</strong></p><script type="math/tex; mode=display">min\{s(x),\frac{v^k}{2u}\}=0 \\ h(x)=0</script><p>ä¸€èˆ¬å½¢å¼ç®—æ³•ä¸­çš„ç»ˆæ­¢æ¡ä»¶ï¼šï¼ˆå¹³æ–¹å’Œå¼€æ ¹å·ï¼‰</p><script type="math/tex; mode=display">\varphi_k=[\sum{(min\{s(x_k),\frac{v^k}{2\mu}\})^2}+\sum{h^2_i(x_k)}]^{1/2}</script><p>è‹¥$\varphi_k &lt; \epsilon$ï¼šç»ˆæ­¢</p><p>è‹¥$\frac{\varphi<em>k}{\varphi</em>{k-1}}\geq\theta$ï¼šæ”¾å¤§ç½šå› å­ $\mu = c*\mu$ï¼Œå…¶ä¸­ $\theta \in (0,1)$ï¼Œæ¯”å€¼å¤ªå¤§è¯´æ˜æ”¶æ•›æ•ˆæœä¸å¥½ï¼Œè¦æ”¾å¤§ç½šå› å­ã€‚</p><blockquote><p>åªæœ‰ç­‰å¼çº¦æŸæ—¶ $\frac{h(x<em>k)}{h(x</em>{k-1})}\geq\theta$æ”¾å¤§ç½šå› å­</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å•çº¯å½¢æ³• </tag>
            
            <tag> ç‰›é¡¿æ³• </tag>
            
            <tag> å…±è½­æ¢¯åº¦æ³• </tag>
            
            <tag> DFPç®—æ³• </tag>
            
            <tag> æ­¥é•¿åŠ é€Ÿæ³• </tag>
            
            <tag> Z-å®¹è®¸æ–¹å‘æ³• </tag>
            
            <tag> H-ä¹˜å­æ³• </tag>
            
            <tag> ç½šå‡½æ•°æ³• </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CLeQA æ¨¡å‹å®ç°</title>
      <link href="/2021/12/06/CLeQA%20%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0/"/>
      <url>/2021/12/06/CLeQA%20%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="CLeQA-æ¨¡å‹å®ç°"><a href="#CLeQA-æ¨¡å‹å®ç°" class="headerlink" title="CLeQA æ¨¡å‹å®ç°"></a>CLeQA æ¨¡å‹å®ç°</h1><h2 id="ç¯å¢ƒéƒ¨ç½²"><a href="#ç¯å¢ƒéƒ¨ç½²" class="headerlink" title="ç¯å¢ƒéƒ¨ç½²"></a>ç¯å¢ƒéƒ¨ç½²</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">conda create -n cleqa python=3.7</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch</span><br><span class="line"># æˆ–è€…</span><br><span class="line">pip3 install torch torchvision torchaudio</span><br><span class="line"></span><br><span class="line">pip install transformers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># wbc</span><br><span class="line">pip3 install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/cu110/torch_stable.html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> è½¯ä»¶å¼€å‘&amp;æ¨¡å‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation</title>
      <link href="/2021/11/14/Knowledge%20Enhanced%20Fine-Tuning%20for%20Better%20Handling%20Unseen%20Entities%20in%20Dialogue%20Generation/"/>
      <url>/2021/11/14/Knowledge%20Enhanced%20Fine-Tuning%20for%20Better%20Handling%20Unseen%20Entities%20in%20Dialogue%20Generation/</url>
      
        <content type="html"><![CDATA[<h1 id="Knowledge-Enhanced-Fine-Tuning-for-Better-Handling-Unseen-Entities-in-Dialogue-Generation"><a href="#Knowledge-Enhanced-Fine-Tuning-for-Better-Handling-Unseen-Entities-in-Dialogue-Generation" class="headerlink" title="Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation"></a>Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation</h1><blockquote><p>EMNLP2021</p><p>è®ºæ–‡ï¼š<a href="https://arxiv.org/abs/2109.05487">https://arxiv.org/abs/2109.05487</a></p><p>ä»£ç ï¼š<a href="https://github.com/nealcly/ke-blender">https://github.com/nealcly/ke-blender</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>é¢„è®­ç»ƒæ¨¡å‹åœ¨å¯¹è¯ç”Ÿæˆæ–¹é¢å–å¾—äº†å¾ˆå¤§çš„æˆåŠŸï¼Œä½†å½“è¾“å…¥åŒ…å«é¢„è®­ç»ƒå’Œå¾®è°ƒæ•°æ®é›†ä¸­æ²¡æœ‰å‡ºç°çš„å®ä½“ï¼ˆunseen entityï¼‰æ—¶ï¼Œå®ƒä»¬çš„æ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç°æœ‰çš„æ–¹æ³•åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†åº“æ¥ç”Ÿæˆé€‚å½“çš„å“åº”ã€‚åœ¨ç°å®åœºæ™¯ä¸­ï¼Œå®ä½“å¯èƒ½ä¸è¢«çŸ¥è¯†åº“æ‰€åŒ…å«ï¼Œæˆ–è€…å—åˆ°çŸ¥è¯†æ£€ç´¢ç²¾åº¦çš„å½±å“ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡ä¸å†å¼•å…¥çŸ¥è¯†åº“ä½œä¸ºè¾“å…¥ï¼Œè€Œæ˜¯åªæ ¹æ®è¾“å…¥ä¸Šä¸‹æ–‡ï¼Œé€šè¿‡é¢„æµ‹çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯æ¥å¼ºè¿«æ¨¡å‹å­¦ä¹ æ›´å¥½çš„è¯­ä¹‰è¡¨ç¤ºã€‚</p><p>å…·ä½“æ¥è¯´ï¼Œåœ¨çŸ¥è¯†åº“çš„å¸®åŠ©ä¸‹ï¼Œå¼•å…¥äº†ä¸¤ä¸ª<strong>è¾…åŠ©è®­ç»ƒ</strong>ç›®æ ‡ï¼š</p><ol><li>è§£é‡Šmasked wordï¼šåœ¨ç»™å®šä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹çŒœæµ‹masked entity çš„å«ä¹‰ã€‚ä¾‹å¦‚â€œI want to submit a paper to EMNLPâ€ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæœ‰äººå¯èƒ½ä¸çŸ¥é“EMLNLPè¿™ä¸ªä¸“ä¸šåè¯ï¼Œä½†æ˜¯å¯ä»¥æ ¹æ®ä¸Šä¸‹æ–‡çŒœå‡ºï¼Œè¿™æ˜¯ä¸€ä¸ªâ€œä¼šè®®â€æˆ–è€…â€œæœŸåˆŠâ€ã€‚</li><li>ç”Ÿæˆä¸Šä½è¯ï¼šæ ¹æ®ä¸Šä¸‹æ–‡é¢„æµ‹å®ä½“çš„ä¸Šä½è¯ã€‚</li></ol><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211114105612.png" alt="image-20211114105612902" style="zoom: 67%;" /></p><p>ä»1aä¸­å¯ä»¥çœ‹å‡ºï¼Œä¸åœ¨çŸ¥è¯†åº“ä¸­çš„å®ä½“COVID-19è™½ç„¶ä¸SARSè¯­æ„æ¥è¿‘ï¼Œä½†æ¨¡å‹æ¨ç†ç»™å‡ºäº†å®Œå…¨ä¸åŒçš„ç”Ÿæˆç»“æœã€‚</p><p>1bä¸­å¼•å…¥å¤–éƒ¨çŸ¥è¯†åº“ï¼Œä½†ç”±äºCOVID-19æ˜¯æ¯”è¾ƒæ–°çš„è¯è¯­ï¼Œåœ¨å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ— æ³•æ£€ç´¢å¾—åˆ°ï¼Œç”Ÿæˆç»“æœä»ç„¶é”™è¯¯ã€‚</p><p>1cä¸­å¼•å…¥ä¸¤ä¸ªå­ä»»åŠ¡è¾…åŠ©è®­ç»ƒï¼Œé¢„æµ‹Masked wordvå¹¶é¢„æµ‹SARSçš„ä¸Šä½è¯å¾—åˆ°infectionã€‚æµ‹è¯•æœªçŸ¥å®ä½“COVID-19æ—¶æ¨¡å‹æ•ˆæœæœ‰æ‰€æå‡ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>Knowledge Enhanced Blender (<strong>KE-Blender</strong>ï¼‰</p><h3 id="TASK"><a href="#TASK" class="headerlink" title="TASK"></a>TASK</h3><h4 id="Blender"><a href="#Blender" class="headerlink" title="Blender"></a>Blender</h4><p>è®­ç»ƒé›†ç»“æ„ï¼š</p><script type="math/tex; mode=display">D^S=\{U^S_i, K^S_i, R^S_i\}|^{|L|}_{i=1}</script><p>å…¶ä¸­$U^S_i, K^S_i, R^S_i$åˆ†åˆ«è¡¨ç¤ºï¼Œå¯¹è¯ä¸Šä¸‹æ–‡ã€ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°çš„å¤–éƒ¨çŸ¥è¯†å’Œå›åº”ã€‚</p><script type="math/tex; mode=display">D_P= \{U^P, R^P\}</script><p>æµ‹è¯•é›†æ²¡æœ‰å¤–éƒ¨çŸ¥è¯†ï¼Œå› ä¸ºåœ¨æ¨ç†è¿‡ç¨‹ä¸­å¾ˆéš¾å®æ—¶è·å–æœªè§è¿‡è¯çš„ç›¸å…³èƒŒæ™¯çŸ¥è¯†ã€‚</p><p><strong>ç›®æ ‡ï¼š</strong></p><p>$P(R|U; Î¸)$    with the help of     $K^S$</p><ul><li>å¤–éƒ¨çŸ¥è¯† K ä¸ä½œä¸ºè¾“å…¥ã€‚</li></ul><p>å¯¹è¯ä¸Šä¸‹æ–‡ï¼š</p><script type="math/tex; mode=display">U = {x_1, x_2, . . . , x_T}</script><p>Response:</p><script type="math/tex; mode=display">R = {y_1, y_2, . . . , y_T}</script><p>å¥å­çš„éšè—å±‚è¡¨ç¤ºï¼š</p><script type="math/tex; mode=display">h^{enc}= TRANSFORMER\_ENCODER(U)</script><p>åœ¨è§£ç å™¨çš„ç¬¬tæ­¥ä¸­ï¼Œ$h^{enc}$å’Œå…ˆå‰çš„è¾“å‡ºtoken $y_{1:t-1}$ ä½œä¸ºè¾“å…¥ï¼Œä½¿ç”¨æ³¨æ„ç”Ÿæˆè¡¨ç¤ºï¼š</p><script type="math/tex; mode=display">h^{dec}_t = TRANSFORMER\_DECODER(h^{enc}, y_{1:tâˆ’1})</script><p>y_t çš„æ¦‚ç‡åˆ†å¸ƒï¼š</p><script type="math/tex; mode=display">p(y_t|U, y_{1:tâˆ’1}) = softmax(W^oh^{dec}_t + b^o)</script><blockquote><p> $W^o$ and $b^o$ are trainable parameters.</p></blockquote><p>ä½¿ç”¨æ ‡å‡†æœ€å¤§ä¼¼ç„¶ä¼°è®¡ä¼˜åŒ–æ¨¡å‹å‚æ•° Î¸</p><p>Given a <strong>training pair (U, R)</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211114144959.png" alt="image-20211114144959771" style="zoom: 33%;" /></p><h4 id="Knowledge-Grounded-Blender-KG-Blender"><a href="#Knowledge-Grounded-Blender-KG-Blender" class="headerlink" title="Knowledge Grounded Blender(KG-Blender)"></a>Knowledge Grounded Blender(KG-Blender)</h4><p>KG-Blenderä¸­å°† å¯¹è¯ä¸Šä¸‹æ–‡<strong>U</strong> å’Œ å¤–éƒ¨çŸ¥è¯† <strong>K</strong> ä½œä¸ºè¾“å…¥ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211114145656.png" alt="image-20211114145656180" style="zoom:33%;" /></p><p>ä¸Blenderç›¸æ¯”ï¼ŒæŸå¤±å‡½æ•°ç¨æœ‰ä¸åŒï¼š</p><p>Given a <strong>training pair (U, K, R)</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211114145839.png" alt="image-20211114145839095" style="zoom:33%;" /></p><blockquote><p>å½“çŸ¥è¯†ä¸å¯ç”¨æ—¶ï¼Œå¾ˆéš¾ç›´æ¥ä½¿ç”¨KG-Blenderï¼Œå› ä¸ºKG-Blender ä¾èµ–çŸ¥è¯†ä½œä¸ºè¾“å…¥ã€‚</p></blockquote><h4 id="Knowledge-Enhanced-Blender-KE-Blender"><a href="#Knowledge-Enhanced-Blender-KE-Blender" class="headerlink" title="Knowledge Enhanced Blender(KE-Blender)"></a>Knowledge Enhanced Blender(KE-Blender)</h4><p><strong>è¾…åŠ©ä»»åŠ¡è¯¦ç»†ä»‹ç»</strong></p><h5 id="Interpret-Masked-Wordï¼š"><a href="#Interpret-Masked-Wordï¼š" class="headerlink" title="Interpret Masked Wordï¼š"></a>Interpret Masked Wordï¼š</h5><p>æ ¹æ®ä¸Šä¸‹æ–‡é¢„æµ‹å•è¯çš„å®šä¹‰ï¼Œå…¶ä¸­å®šä¹‰æ˜¯ä»çŸ¥è¯†åº“è·å¾—çš„ã€‚</p><ol><li>mask proper nouns(ä¸“æœ‰åè¯) or pre-defined topic word for specific dataset.</li><li>æ‰¾åˆ°masked wordçš„å¤–éƒ¨çŸ¥è¯†ã€‚</li><li>ç„¶åï¼Œè¦æ±‚é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹é€šè¿‡ä½¿ç”¨è¢«å±è”½çš„è¯è¯­ä½œä¸ºè¾“å…¥æ¥æ¢å¤masked wordå®šä¹‰ã€‚</li></ol><p>å…·ä½“æ“ä½œå¯ä»¥çœ‹ä¸‹æ–¹å…¬å¼ï¼š</p><p><strong>signal utterance</strong></p><script type="math/tex; mode=display">u_{lâˆ’1}= \{x_1, x_2, . . . , x_T\}</script><blockquote><p>$x_j$è¡¨ç¤ºå•è¯ã€‚</p></blockquote><p><strong>$x_i$ </strong>æ˜¯utterance $u_{lâˆ’1}$ çš„topic wordï¼Œç›¸å…³å®šä¹‰ï¼š</p><script type="math/tex; mode=display">K_{x_i}= \{k_1, k_2, . . . , k_{|K_{x_i}|}\}</script><p>å°†topic word maskæ‰ä½œä¸ºè¾“å…¥ï¼š</p><script type="math/tex; mode=display">u^{'}_{lâˆ’1}= \{x_1, . . . , x_{iâˆ’1},[MASK], x_{i+1}, . . . , x^{'}_T\}</script><p>æŸå¤±å‡½æ•°ï¼š</p><p>Given a <strong>training pair $(u^{â€˜}<em>{lâˆ’1}, K</em>{x_i})$</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211114153203.png" alt="image-20211114153203931" style="zoom:33%;" /></p><h5 id="Hypernym-Generation"><a href="#Hypernym-Generation" class="headerlink" title="Hypernym Generation"></a>Hypernym Generation</h5><p>é¢„æµ‹WordNetç»™å‡ºçš„å•è¯çš„ç›¸å…³ä¸Šä½è¯ã€‚</p><p>$u_{lâˆ’1}$= {I submit a paper to the EMNLP}</p><p>ä»WordNetä¸­æ›¿æ¢<strong>EMNLP</strong>ä¸º ä¸Šä½è¯ <strong>conference</strong>ã€‚</p><p>$u^{â€˜}_{lâˆ’1}$= {I submit a paper to the conference}</p><p>æŸå¤±å‡½æ•°ï¼š</p><p>Given a <strong>training pair $(u<em>{lâˆ’1}, u^{â€˜â€™}</em>{lâˆ’1})$</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211114155233.png" alt="image-20211114155233067" style="zoom: 33%;" /></p><p>è”åˆæŸå¤±ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211114160209.png" alt="image-20211114160209893" style="zoom:33%;" /></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211114160558.png" alt="image-20211114160558760"></p><p>ç»™ä¸ªä¾‹å­æ›´ç›´è§‚çš„è§£é‡Šä¸Šé¢ä¸‰éƒ¨åˆ†ã€‚</p><p>â€‹        è¿™ä¸¤ä¸ªè¾…åŠ©ä»»åŠ¡å¼ºè¿«æ¨¡å‹åœ¨è®­ç»ƒæœŸé—´ä»å¤–éƒ¨çŸ¥è¯†åº“å­¦ä¹ æ›´ä¸°å¯Œçš„è¯­ä¹‰çŸ¥è¯†ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡æ›´å¥½çš„çŒœæµ‹unseen entityçš„å«ä¹‰ï¼Œç”Ÿæˆæ›´ç›¸å…³çš„å¯¹è¯ã€‚è¿™ä¸¤ä¸ªè®­ç»ƒç›®æ ‡éƒ½ä¸éœ€è¦è¿›ä¸€æ­¥çš„äººå·¥æ ‡è®°ï¼Œè¿™ä¸ºæ‰©å±•åˆ°å¤§è§„æ¨¡çš„é¢„è®­ç»ƒæä¾›äº†å¯èƒ½ã€‚</p><p>â€‹        ç›¸å¯¹äºåˆ©ç”¨å‘½åå®ä½“æˆ–çŸ¥è¯†åº“æ¥å¢å¼ºé¢„è®­ç»ƒç¼–ç å™¨çš„æ–¹æ³•ï¼Œæœ¬æ–‡åœ¨ç»™å®šunseen wordçš„æƒ…å†µä¸‹æ³¨å…¥çŸ¥è¯†æ¥æé«˜seq2seqæ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>Wizard of Wikipedia</li><li>Reddit Trendings</li></ul><blockquote><p>Reddit Trendingsé¢æ¿åŒ…å«æœ€æ–°çš„çƒ­é—¨è¯é¢˜ï¼Œå¤§éƒ¨åˆ†éƒ½ä¸åŒ…å«åœ¨å¤–éƒ¨çŸ¥è¯†åº“ä¸­ã€‚</p></blockquote><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211114162707.png" alt="image-20211114162707440" style="zoom:67%;" /></p><p>PPLï¼šå›°æƒ‘åº¦</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211114163336.png" alt="image-20211114163336465" style="zoom: 33%;" /></p><p>masked word å’Œ ä¸Šä½è¯é¢„æµ‹æ ·ä¾‹ã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>â€‹        ä¸ºäº†æ›´å¥½åœ°å¤„ç†åŸºäºæœªè§è¯çš„å“åº”ç”Ÿæˆï¼Œæœ¬æ–‡æå‡ºäº†KE-Blenderï¼Œå®ƒä½¿æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ— éœ€å¤–éƒ¨çŸ¥è¯†å°±èƒ½ç”Ÿæˆæœ‰çŸ¥è¯†çš„å“åº”ã€‚ä¸ºäº†å°†çŸ¥è¯†æ˜¾å¼åœ°æ³¨å…¥åˆ°æ¨¡å‹ä¸­ï¼Œæå‡ºäº†ä¸¤ä¸ªè®­ç»ƒç›®æ ‡ï¼ŒåŒ…æ‹¬è§£é‡Šå±è”½è¯å’Œç”Ÿæˆä¸Šä½è¯ã€‚Wizardå’ŒRedditè¶‹åŠ¿çš„ç»“æœæ˜¾ç¤ºï¼ŒKE-Blenderåœ¨å¤–éƒ¨çŸ¥è¯†å¯ç”¨å’Œä¸å¯ç”¨çš„æƒ…å†µä¸‹éƒ½ä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„æ–¹æ³•å’Œå¼ºå¤§çš„åŸºçº¿ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Dialogue </tag>
            
            <tag> Generation </tag>
            
            <tag> ä¼šè¯ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Heterogeneous Graph Attention Network</title>
      <link href="/2021/10/26/Heterogeneous%20Graph%20Attention%20Network/"/>
      <url>/2021/10/26/Heterogeneous%20Graph%20Attention%20Network/</url>
      
        <content type="html"><![CDATA[<h1 id="Heterogeneous-Graph-Attention-Network"><a href="#Heterogeneous-Graph-Attention-Network" class="headerlink" title="Heterogeneous Graph Attention Network"></a>Heterogeneous Graph Attention Network</h1><ul><li>Heterogeneous graph Attention Network, named <strong>HAN</strong></li></ul><p>å¼‚æ„å›¾æ³¨æ„åŠ›ç½‘ç»œ</p><p><strong>heterogeneous graph</strong> which contains different types of nodes and links</p><p><strong>homogeneous graph</strong> which includes only one type of nodes or links</p><p>heterogeneous information network (<strong>HIN</strong>)<br><strong>Meta-path</strong>, a composite relation connecting two objects, is a widely used structure to capture the semantics</p><blockquote><p>è®ºæ–‡ï¼š</p><p>ä»£ç ï¼š</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>å¼‚æ„å›¾ä¸­åŒ…å«ä¸åŒçš„èŠ‚ç‚¹å’Œè¾¹ï¼ŒGNNåšçš„è¿˜ä¸å¤Ÿå®Œå–„ã€‚ç”±äºå¼‚è´¨å›¾çš„å¤æ‚æ€§ï¼Œä¼ ç»Ÿçš„å›¾ç¥ç»ç½‘ç»œä¸èƒ½ç›´æ¥åº”ç”¨äºå¼‚æ„å›¾ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¼‚æ„å›¾ç¥ç»ç½‘ç»œåˆ†å±‚æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¶‰åŠåˆ°èŠ‚ç‚¹çº§åˆ«å’Œè¯­ä¹‰çº§åˆ«ã€‚èŠ‚ç‚¹çº§åˆ«çš„Attentionä¸»è¦å­¦ä¹ èŠ‚ç‚¹åŠå…¶ä¸´è¿‘èŠ‚ç‚¹é—´çš„æƒé‡ï¼Œè¯­ä¹‰çº§åˆ«çš„Attentionæ˜¯æ¥å­¦ä¹ åŸºäºä¸åŒmeta-pathçš„æƒé‡ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211020103917.png" alt="image-20211020103917183" style="zoom:40%;" /></p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><ul><li>Semantic-level attention</li></ul><p>è¯­ä¹‰çº§åˆ«çš„æ³¨æ„åŠ›æ—¨åœ¨äº†è§£æ¯ä¸ªMetapathçš„é‡è¦æ€§ï¼Œå¹¶ä¸ºä»–ä»¬åˆ†é…é€‚å½“çš„æƒé‡ã€‚åŒç­‰å¯¹å¾…meat-pathæ˜¯ä¸åˆ‡å®é™…çš„ï¼Œç›¸åŒçš„æƒé‡ä¼šé™ä½æœ‰ç”¨ä¿¡æ¯çš„æ•ˆæœã€‚</p><ul><li>Node-level attention </li></ul><p>å¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼ŒèŠ‚ç‚¹çº§åˆ«æ³¨æ„åŠ›æ—¨åœ¨äº†è§£åŸºäºmeta-pathçš„é‚»å±…çš„é‡è¦æ€§å¹¶ä¸ºå®ƒä»¬åˆ†é…ä¸åŒçš„æƒé‡ã€‚å‘ç°èŠ‚ç‚¹ä¹‹é—´çš„ç»†å¾®åŒºåˆ«ã€‚</p><p>æ¨¡å‹è´¡çŒ®ï¼š</p><ul><li>æœ¬æ–‡æ˜¯é¦–æ¬¡å°è¯•ç ”ç©¶åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„å¼‚æ„å›¾ç¥ç»ç½‘ç»œã€‚æœ¬æ–‡çš„å·¥ä½œä½¿å¾—å›¾ç¥ç»ç½‘ç»œå¯ä»¥ç›´æ¥åº”ç”¨äºå¼‚æ„å›¾ï¼Œè¿›ä¸€æ­¥æ–¹ä¾¿äº†åŸºäºå¼‚æ„å›¾çš„åº”ç”¨ã€‚</li><li>æå‡ºäº†ä¸€ç§æ–°çš„å¼‚æ„å›¾æ³¨æ„åŠ›ç½‘ç»œ(HAN)ï¼Œå®ƒåŒ…å«äº†èŠ‚ç‚¹çº§å’Œè¯­ä¹‰çº§çš„æ³¨æ„åŠ›ã€‚åˆ©ç”¨è¿™ç§å±‚æ¬¡åŒ–çš„æ³¨æ„ï¼Œæå‡ºçš„HANå¯ä»¥åŒæ—¶è€ƒè™‘èŠ‚ç‚¹å’Œmeat-pathçš„é‡è¦æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è®¡ç®—æ•ˆç‡é«˜ï¼Œè®¡ç®—å¤æ‚åº¦ä¸åŸºäºå…ƒè·¯å¾„çš„èŠ‚ç‚¹å¯¹æ•°ç›®æˆçº¿æ€§å…³ç³»ï¼Œå¯åº”ç”¨äºå¤§è§„æ¨¡å¼‚æ„å›¾ã€‚</li><li>è¿›è¡Œäº†å¤§é‡çš„å®éªŒæ¥è¯„ä¼°æ‰€æå‡ºçš„æ¨¡å‹çš„æ€§èƒ½ã€‚é€šè¿‡ä¸ç°æœ‰æ¨¡å‹çš„æ¯”è¾ƒï¼ŒéªŒè¯äº†è¯¥æ¨¡å‹çš„ä¼˜è¶Šæ€§ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œé€šè¿‡åˆ†æå±‚æ¬¡æ³¨æ„æœºåˆ¶ï¼Œæå‡ºçš„HANåœ¨å¼‚æ„å›¾åˆ†æä¸­å…·æœ‰è‰¯å¥½çš„è§£é‡Šæ€§ã€‚</li></ul><p><strong>æ¨¡å‹ç»“æ„ï¼š</strong><br><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026130417.png" alt="image-20211026130417426" style="zoom: 67%;" /></p><h3 id="Node-level-Attention"><a href="#Node-level-Attention" class="headerlink" title="Node-level Attention"></a>Node-level Attention</h3><p>åœ¨å…·ä½“ä»»åŠ¡ä¸­ï¼Œä¸€ä¸ªèŠ‚ç‚¹åœ¨meta-pathä¸Šçš„é‚»å±…èŠ‚ç‚¹æœ‰ä¸åŒçš„é‡è¦æ€§ã€‚Node-level attentionèƒ½å¤Ÿå­¦ä¹ ä¸€ä¸ªèŠ‚ç‚¹åŸºäºmeta-pathçš„é‚»å±…èŠ‚ç‚¹çš„è¡¨ç¤ºä½œä¸ºè¯¥èŠ‚ç‚¹çš„embeddingã€‚ç”±äºgraphä¸­åŒ…å«ä¸åŒç±»å‹çš„nodeï¼Œæ‰€ä»¥é¦–å…ˆé€šè¿‡è½¬æ¢çŸ©é˜µå°†æ‰€æœ‰èŠ‚ç‚¹è½¬æ¢åˆ°ç»Ÿä¸€çš„ç‰¹å¾ç©ºé—´ã€‚</p><script type="math/tex; mode=display">h^â€²= M_{Ã¸_i}Â· h_i</script><p>ç»™å®šä¸€ä¸ªèŠ‚ç‚¹å¯¹(i , j)ï¼ŒNode-level Attentionèƒ½å­¦ä¹ åˆ°èŠ‚ç‚¹jç›¸å¯¹äºèŠ‚ç‚¹içš„æƒé‡ï¼Œé‡è¦çš„ä¸€ç‚¹æ˜¯(i , j)çš„æƒé‡æ˜¯éå¯¹ç§°çš„ã€‚é€šè¿‡softmaxè®¡ç®—å‡ºèŠ‚ç‚¹jçš„æƒé‡ç³»æ•°ï¼Œå¾—åˆ°çš„ç³»æ•°ä¹Ÿæ˜¯éå¯¹ç§°çš„ã€‚</p><p>é€šè¿‡ä¸‹é¢çš„å¼å­èšåˆæ‰€æœ‰é‚»å±…èŠ‚ç‚¹çš„ç³»æ•°:</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026131153.png" alt="image-20211026131153430" style="zoom: 33%;" /></p><p>å›¾ç¤ºèšåˆè¿‡ç¨‹ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026131235.png" alt="image-20211026131235884" style="zoom: 33%;" /></p><p>ç”±äºå¼‚æ„å›¾æ•°æ®æ˜¯scale freeçš„ï¼Œè®¡ç®—åä¼šæœ‰å¾ˆé«˜çš„æ–¹å·®ï¼Œæœ¬æ–‡é€šè¿‡å°†Node-level Attentionå»¶ä¼¸åˆ°äº†multihead Attentionæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç´§æ¥ç€å°±å¯ä»¥å¾—åˆ°Node i çš„å¤šæ¡meta-pathçš„embeddingé›†åˆï¼Œå³æ˜¯è¯­ä¹‰å±‚çš„embeddingï¼Œå°±æ­¤Node-level Attentionå·¥ä½œå®Œæˆã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026131412.png" alt="image-20211026131412136" style="zoom:33%;" /></p><h3 id="Semantic-level-Attention"><a href="#Semantic-level-Attention" class="headerlink" title="Semantic-level Attention"></a>Semantic-level Attention</h3><p>ä¸ºäº†å­¦ä¹ åˆ°æ›´ç»¼åˆçš„ä¿¡æ¯ï¼Œéœ€è¦æ ¹æ®meta-pathå°†å¤šç§è¯­ä¹‰ä¿¡æ¯èåˆåˆ°ä¸€èµ·ã€‚å°†Node-level Attentionçš„ç»“æœä½œä¸ºè¾“å…¥ï¼Œæ¥å­¦ä¹ æ¯æ¡è¯­ä¹‰çš„æƒé‡ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026131556.png" alt="image-20211026131556645" style="zoom:33%;" /></p><p>è¦å­¦ä¹ æ¯æ¡è¯­ä¹‰çš„æƒé‡ï¼Œé¦–å…ˆä½¿ç”¨ä¸€å±‚çš„MLPå°†Semantic embeddingè¿›è¡Œéçº¿æ€§è½¬æ¢ã€‚é€šè¿‡Semantic-level Attention vector <strong>q</strong> æ¥è¡¡é‡å¤šæ¡Semantic embedding é—´çš„ç›¸ä¼¼æ€§ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026131710.png" alt="image-20211026131710239" style="zoom:33%;" /></p><p>ç»è¿‡Softmaxå‡½æ•°ï¼Œå¾—åˆ°è¯­ä¹‰æƒé‡ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026131832.png" alt="image-20211026131832610" style="zoom:33%;" /></p><p>æœ€åï¼Œè·å¾—è¯­ä¹‰å±‚çš„embeddingï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026131850.png" alt="image-20211026131850158" style="zoom:33%;" /></p><p>æœ‰äº†embeddingä¹‹åï¼Œå°±å¯ä»¥æ„å»ºloss functionäº†ï¼Œæœ¬æ–‡ä½¿ç”¨åŠç›‘ç£çš„æ–¹å¼ï¼Œé€šè¿‡æœ€å°åŒ–Cross-Entropyæ¥è®­ç»ƒã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026131949.png" alt="image-20211026131949789" style="zoom:33%;" /></p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>DBLPã€ACMã€IMDB</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026132307.png" alt="image-20211026132307432"></p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><ul><li>åˆ†ç±»ä»»åŠ¡</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026132516.png" alt="image-20211026132516650"></p><p>ç”±äºå›¾ç»“æ„æ•°æ®çš„æ–¹å·®éå¸¸é«˜ï¼Œå› æ­¤é‡å¤å¤„ç†10æ¬¡ï¼ŒTable3 ä¸­ä¸ºå¹³å‡Macro-F1å’ŒMacro-F1ã€‚</p><ul><li>èšç±»ä»»åŠ¡</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211026132717.png" alt="image-20211026132717327"></p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>æœ¬æ–‡é’ˆå¯¹å¼‚æ„å›¾åˆ†æä¸­çš„å‡ ä¸ªåŸºæœ¬é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„åŠç›‘ç£å¼‚æ„å›¾ç¥ç»ç½‘ç»œã€‚æ‰€æå‡ºçš„HANèƒ½å¤Ÿæ•è·å¼‚æ„å›¾èƒŒåå¤æ‚çš„ç»“æ„å’Œä¸°å¯Œçš„è¯­ä¹‰ã€‚è¯¥æ¨¡å‹åˆ©ç”¨node-levelæ³¨æ„åŠ›å’Œsemantic-levelæ³¨æ„åŠ›åˆ†åˆ«å­¦ä¹ nodeå’Œmeta pathçš„é‡è¦æ€§ã€‚åŒæ—¶ï¼Œè¯¥æ¨¡å‹ç»Ÿä¸€åˆ©ç”¨äº†ç»“æ„ä¿¡æ¯å’Œç‰¹å¾ä¿¡æ¯ã€‚å®éªŒç»“æœåŒ…æ‹¬åˆ†ç±»å’Œèšç±»ï¼Œè¯æ˜äº†HANç®—æ³•çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡åˆ†æå­¦ä¹ åˆ°çš„æ³¨æ„åŠ›æƒé‡åŒ…æ‹¬èŠ‚ç‚¹çº§å’Œè¯­ä¹‰çº§ï¼Œè¯æ˜äº†HANå…·æœ‰è‰¯å¥½çš„è§£é‡Šæ€§ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Social Network </tag>
            
            <tag> HAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Knowledge Generation MRCæ¨¡å‹å¤ç°</title>
      <link href="/2021/10/06/KnowledgeGenerationMRC%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/"/>
      <url>/2021/10/06/KnowledgeGenerationMRC%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="Knowledge-Generation-MRCæ¨¡å‹å¤ç°"><a href="#Knowledge-Generation-MRCæ¨¡å‹å¤ç°" class="headerlink" title="Knowledge Generation MRCæ¨¡å‹å¤ç°"></a>Knowledge Generation MRCæ¨¡å‹å¤ç°</h1><h2 id="æ‰©å±•çŸ¥è¯†"><a href="#æ‰©å±•çŸ¥è¯†" class="headerlink" title="æ‰©å±•çŸ¥è¯†"></a>æ‰©å±•çŸ¥è¯†</h2><ul><li>å“ˆå·¥å¤§ RoBERTa-wwm-ext, Chinese <a href="https://github.com/ymcui/Chinese-BERT-wwm">https://github.com/ymcui/Chinese-BERT-wwm</a></li></ul><h2 id="ç¯å¢ƒé…ç½®"><a href="#ç¯å¢ƒé…ç½®" class="headerlink" title="ç¯å¢ƒé…ç½®"></a>ç¯å¢ƒé…ç½®</h2><ul><li>conda</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n mq_mrc python=3.6</span><br><span class="line">source activate mq_mrc</span><br></pre></td></tr></table></figure><ul><li><p>PyTorch </p><blockquote><p>pytorch å®˜ç½‘ è‡ªåŠ¨å®‰è£…cudnn</p><p><a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch  cudatoolkit=10.1 -c pytorch</span><br><span class="line"># å®˜æ–¹ç‰ˆ</span><br><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch</span><br><span class="line"># æµ‹è¯•ï¼š</span><br><span class="line">import torch </span><br><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure><p>â€‹    conda æŠ¥é”™å¯ä»¥è¯•è¯•pip</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio</span><br></pre></td></tr></table></figure><ul><li>ï¼ä¸ä½¿ç”¨ pytorch-pretrained-bert</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall pytorch-pretrained-bert</span><br></pre></td></tr></table></figure><p>é…ç½®ï¼š<a href="https://www.asimok.site/2020/12/07/Berté¢„è®­ç»ƒæ¨¡å‹çš„ä½¿ç”¨/">https://www.asimok.site/2020/12/07/Berté¢„è®­ç»ƒæ¨¡å‹çš„ä½¿ç”¨/</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/data0/maqi/.conda/envs/mq_mrc/lib/python3.6/site-packages/pytorch_pretrained_bert</span><br></pre></td></tr></table></figure><ul><li>ä½¿ç”¨transformersè°ƒç”¨é¢„è®­ç»ƒæ¨¡å‹</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers</span><br></pre></td></tr></table></figure><h2 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h2><h3 id="æ•°æ®é›†å¤„ç†"><a href="#æ•°æ®é›†å¤„ç†" class="headerlink" title="æ•°æ®é›†å¤„ç†"></a>æ•°æ®é›†å¤„ç†</h3><p>æ•°æ®é›†é€‰æ‹©åŸå§‹ä¸­æ–‡æ•°æ®é›†ï¼Œç¼–ç </p><p>å­—æ®µåªè¦æ®µè½å’Œä½œè€…ï¼Ÿï¼Ÿ</p><h4 id="æ•°æ®é›†ç»“æ„"><a href="#æ•°æ®é›†ç»“æ„" class="headerlink" title="æ•°æ®é›†ç»“æ„"></a>æ•°æ®é›†ç»“æ„</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- pid</span><br><span class="line">- is_classical</span><br><span class="line">- title</span><br><span class="line">- author</span><br><span class="line">- paragraphs</span><br><span class="line">- qas</span><br><span class="line">-- qid</span><br><span class="line">-- question</span><br><span class="line">-- answer</span><br><span class="line">-- pKnowledges</span><br><span class="line">-- qKnowledges</span><br></pre></td></tr></table></figure><p>æœ€ç»ˆéœ€è¦çš„æ•°æ®ç»“æ„ï¼š</p><ul><li>å°†questionç‹¬ç«‹å‡ºæ¥</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- title</span><br><span class="line">- author</span><br><span class="line">- paragraphs</span><br><span class="line">- question</span><br><span class="line">- answer</span><br><span class="line">- pKnowledges</span><br><span class="line">- qKnowledges</span><br></pre></td></tr></table></figure><h4 id="æ•°æ®é›†ç±»"><a href="#æ•°æ®é›†ç±»" class="headerlink" title="æ•°æ®é›†ç±»"></a>æ•°æ®é›†ç±»</h4><p>åœ¨<code>__init__</code>æ–¹æ³•ä¸­è¯»å–æ•°æ®é›†ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è½¯ä»¶å¼€å‘&amp;æ¨¡å‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining</title>
      <link href="/2021/10/05/A%20Hierarchical%20Network%20for%20Abstractive%20Meeting%20Summarization%20with%20Cross-%20Domain%20Pretraining/"/>
      <url>/2021/10/05/A%20Hierarchical%20Network%20for%20Abstractive%20Meeting%20Summarization%20with%20Cross-%20Domain%20Pretraining/</url>
      
        <content type="html"><![CDATA[<h1 id="A-Hierarchical-Network-for-Abstractive-Meeting-Summarization-with-Cross-Domain-Pretraining"><a href="#A-Hierarchical-Network-for-Abstractive-Meeting-Summarization-with-Cross-Domain-Pretraining" class="headerlink" title="A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining"></a>A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining</h1><blockquote><p> <a href="https://arxiv.org/abs/2004.02016">è®ºæ–‡ï¼šA Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining</a></p><p> ä»£ç ï¼š<a href="https://github.com/JudeLee19/HMNet-End-to-End-Abstractive-Summarization-for-Meetings">https://github.com/JudeLee19/HMNet-End-to-End-Abstractive-Summarization-for-Meetings</a></p><ul><li>éå®˜æ–¹ä½†æ¯”è¾ƒç®€æ´æ˜“æ‡‚çš„ä»£ç </li></ul></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>ä¼ ç»Ÿçš„ä¼šè®®æ€»ç»“æ–¹æ³•ä¾èµ–äºå¤æ‚çš„multi-step pipelinesï¼Œä½¿å¾—è”åˆä¼˜åŒ–éš¾ä»¥å®ç°ï¼Œå¹¶ä¸”ä¼šè®®è®°å½•çš„è¯­ä¹‰ç»“æ„å’Œé£æ ¼ä¸æ–‡ç« å’Œå¯¹è¯æœ‰å¾ˆå¤§ä¸åŒã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„abstractive summary networkï¼Œä»¥é€‚åº”ä¼šè®®çš„åœºæ™¯ã€‚</p><p>ä¼ ç»Ÿæ¨¡å‹éœ€è¦å¤æ‚çš„å¤šé˜¶æ®µæœºå™¨å­¦ä¹ ç®¡é“ï¼Œå¦‚æ¨¡æ¿ç”Ÿæˆã€å¥å­èšç±»ã€å¤šå¥å­å‹ç¼©ã€å€™é€‰å¥å­ç”Ÿæˆå’Œæ’åã€‚ç”±äºè¿™äº›æ–¹æ³•ä¸æ˜¯ç«¯åˆ°ç«¯çš„å¯ä¼˜åŒ–çš„ï¼Œå› æ­¤å¾ˆéš¾è”åˆæ”¹è¿›ç®¡é“ä¸­çš„å„ä¸ªéƒ¨åˆ†ä»¥æé«˜æ•´ä½“æ€§èƒ½ã€‚æ­¤å¤–ï¼Œä¸€äº›ç»„ä»¶ï¼Œä¾‹å¦‚æ¨¡æ¿ç”Ÿæˆï¼Œéœ€è¦å¤§é‡çš„äººåŠ›å‚ä¸ï¼Œä½¿è§£å†³æ–¹æ¡ˆæ— æ³•æ‰©å±•æˆ–è½¬ç§»ã€‚</p><h3 id="ç›®æ ‡"><a href="#ç›®æ ‡" class="headerlink" title="ç›®æ ‡"></a>ç›®æ ‡</h3><p>æ ¹æ®è¾“å…¥çš„ä¼šè®®è®°å½•è¾“å‡ºä¼šè®®æ€»ç»“ã€‚</p><p><strong>æ•ˆæœå±•ç¤ºï¼š</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211003162004.png" alt="image-20211003162004076" style="zoom:50%;" /></p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><blockquote><p> Hierarchical Meeting summarization Network (HMNet)</p></blockquote><p>æœ¬æ–‡è®¾è®¡äº†ä¸€ä¸ªåˆ†å±‚(Hierarchical)ç»“æ„æ¥é€‚åº”é•¿çš„ä¼šè®®è®°å½•ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªè§’è‰²å‘é‡æ¥æè¿°å‘è¨€è€…ä¹‹é—´çš„å·®å¼‚ã€‚</p><ul><li><p>ä¸ºä¼šè®®ä¸­çš„æ¯ä¸ªè§’è‰²è®¾è®¡ä¸€ä¸ªè§’è‰²å‘é‡æè¿°ä¸åŒä¸ä¼šè€…çš„ç«‹åœºå·®å¼‚</p></li><li><p>ä½¿ç”¨æ–°é—»æ•°æ®é¢„è®­ç»ƒæ¨¡å‹åº”å¯¹ä¼šè®®æ•°æ®ä¸è¶³çš„æƒ…å†µ</p></li></ul><p><strong>æ¨¡å‹ç»“æ„ï¼š</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211003215719.png" alt="image-20211003215719379"></p><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><ul><li>Role Encode è€ƒè™‘ various participants</li></ul><h3 id="Hierarchical-Transformer"><a href="#Hierarchical-Transformer" class="headerlink" title="Hierarchical Transformer"></a>Hierarchical Transformer</h3><p>transformer block ç”±multi-head attention layer å’Œä¸€ä¸ª feed-forward layerç»„æˆ</p><p>ç”±äºæ³¨æ„æœºåˆ¶æ˜¯ä½ç½®ä¸å¯çŸ¥çš„ï¼Œå°†ä½ç½®ç¼–ç é™„åŠ åˆ°è¾“å…¥å‘é‡ä¸­</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211003213825.png" alt="image-20211003213825911" style="zoom:50%;" /></p><blockquote><p>å…¶ä¸­ $PE_{(iï¼Œj)}$ä»£è¡¨è¾“å…¥åºåˆ—ä¸­ç¬¬iä¸ªwordçš„ä½ç½®ç¼–ç çš„ç¬¬jç»´ã€‚</p></blockquote><p>transformer blockçš„è¾“å…¥ä¸è¾“å‡ºç»´åº¦ç›¸åŒï¼Œå› æ­¤å¯ä»¥å åŠ ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211003214249.png" alt="image-20211003214249510" style="zoom:50%;" /></p><h4 id="Word-level-Transformer"><a href="#Word-level-Transformer" class="headerlink" title="Word-level Transformer"></a>Word-level Transformer</h4><p>ä¸ºäº†ç»“åˆå¥æ³•å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œè®­ç»ƒäº†ä¸¤ä¸ªåµŒå…¥çŸ©é˜µæ¥è¡¨ç¤ºè¯æ€§æ ‡è®°å’Œå®ä½“æ ‡è®°ã€‚</p><blockquote><p>part-of-speech (POS) and entity (ENT) tags</p></blockquote><p>åœ¨åºåˆ—å‰æ·»åŠ äº†ä¸€ä¸ªç‰¹æ®Šçš„æ ‡è®°[BOS]ï¼Œä»¥è¡¨ç¤ºä¸€ä¸ªå›åˆçš„å¼€å§‹ã€‚</p><h4 id="Turn-level-Transformer"><a href="#Turn-level-Transformer" class="headerlink" title="Turn-level Transformer"></a>Turn-level Transformer</h4><p>å°†Word-level Transformerçš„è¾“å‡º[EOS]ä¸æ­¤è½®roleå‘é‡è¿æ¥èµ·æ¥è¡¨ç¤ºç¬¬iè½®ã€‚</p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>è§£ç å™¨ä½¿ç”¨lower triangular mask é˜²æ­¢æ¨¡å‹çœ‹åˆ°æœªæ¥çš„tokenã€‚</p><p>åˆ©ç”¨embeddingçŸ©é˜µçš„æƒé‡å°†è§£ç å™¨çš„è¾“å‡º$V_{K-1}$è§£ç ä¸ºè¯è¡¨ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211004084039.png" alt="image-20211004084039926" style="zoom:50%;" /></p><p><strong>æŸå¤±å‡½æ•°ï¼š</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211004083836.png" alt="image-20211004083836814" style="zoom:50%;" /></p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>AMI</li><li>ICSI</li></ul><p>è¿™ä¸¤ä¸ªæ•°æ®é›†åˆ†åˆ«åŒ…å«æ¥è‡ªè‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)çš„ä¼šè®®è®°å½•ã€‚</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p>è¯„æµ‹ç»“æœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211004154102.png" alt="image-20211004154102213"></p><p>ä¸ä¹‹å‰æ¨¡å‹æ€§èƒ½ç›¸æ¯”ï¼Œæå‡ç›¸å½“å¤§ã€‚æ¨¡å‹åœ¨è‡ªåŠ¨æŒ‡æ ‡å’Œäººå·¥è¯„ä¼°æ–¹é¢éƒ½ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨ICSIæ•°æ®é›†ä¸Šï¼ŒROUGE-1å¾—åˆ†ä»34.66%å¢åŠ åˆ°46.28%ã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºæŠ½è±¡ä¼šè®®æ‘˜è¦çš„ç«¯åˆ°ç«¯åˆ†å±‚ç¥ç»ç½‘ç»œHMNetã€‚é‡‡ç”¨ä¸¤çº§åˆ†å±‚ç»“æ„æ¥é€‚åº”é•¿çš„ä¼šè®®è®°å½•ï¼Œå¹¶ç”¨è§’è‰²å‘é‡æ¥è¡¨ç¤ºæ¯ä¸ªä¸ä¼šè€…ã€‚è¿˜é€šè¿‡å¯¹æ–°é—»æ‘˜è¦æ•°æ®è¿›è¡Œé¢„è®­ç»ƒæ¥ç¼“è§£æ•°æ®ç¨€ç¼ºæ€§é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼ŒHMNetåœ¨automatic metricså’Œäººå·¥è¯„ä»·æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚é€šè¿‡ä¸€ä¸ªæ¶ˆèå®éªŒï¼Œè¡¨æ˜è§’è‰²å‘é‡ã€å±‚æ¬¡ç»“æ„å’Œé¢„è®­ç»ƒéƒ½æœ‰åŠ©äºæ¨¡å‹çš„æ€§èƒ½ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Abstract </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLPçš„ä¸€äº›è¯„ä»·æŒ‡æ ‡</title>
      <link href="/2021/10/04/NLP%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
      <url>/2021/10/04/NLP%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</url>
      
        <content type="html"><![CDATA[<h1 id="NLPçš„ä¸€äº›è¯„ä»·æŒ‡æ ‡"><a href="#NLPçš„ä¸€äº›è¯„ä»·æŒ‡æ ‡" class="headerlink" title="NLPçš„ä¸€äº›è¯„ä»·æŒ‡æ ‡"></a>NLPçš„ä¸€äº›è¯„ä»·æŒ‡æ ‡</h1><h3 id="ROUGE"><a href="#ROUGE" class="headerlink" title="ROUGE"></a>ROUGE</h3><p>ROUGE æŒ‡æ ‡çš„å…¨ç§°æ˜¯ (Recall-Oriented Understudy for Gisting Evaluation)ï¼Œä¸»è¦åŸºäºå¬å›ç‡ã€‚ROUGE æ˜¯ä¸€ç§å¸¸ç”¨çš„æœºå™¨ç¿»è¯‘å’Œæ–‡ç« æ‘˜è¦è¯„ä»·æŒ‡æ ‡ï¼Œç”± Chin-Yew Lin æå‡ºã€‚å®ƒé€šè¿‡å°†è‡ªåŠ¨ç”Ÿæˆçš„æ‘˜è¦æˆ–ç¿»è¯‘ä¸ä¸€ç»„å‚è€ƒæ‘˜è¦ï¼ˆé€šå¸¸æ˜¯äººå·¥ç”Ÿæˆçš„ï¼‰è¿›è¡Œæ¯”è¾ƒè®¡ç®—ï¼Œå¾—å‡ºç›¸åº”çš„åˆ†å€¼ï¼Œä»¥è¡¡é‡è‡ªåŠ¨ç”Ÿæˆçš„æ‘˜è¦æˆ–ç¿»è¯‘ä¸å‚è€ƒæ‘˜è¦ä¹‹é—´çš„â€œç›¸ä¼¼åº¦â€ã€‚</p><p> 4 ç§ ROUGE æ–¹æ³•ï¼š</p><ul><li>ROUGE-N: åœ¨ N-gram ä¸Šè®¡ç®—å¬å›ç‡ã€‚</li><li>ROUGE-L: è€ƒè™‘äº†æœºå™¨è¯‘æ–‡å’Œå‚è€ƒè¯‘æ–‡ä¹‹é—´çš„æœ€é•¿å…¬å…±å­åºåˆ—ï¼ˆé•¿åº¦è¶Šé•¿ï¼Œå¾—åˆ†è¶Šé«˜ï¼ŒåŸºäºFå€¼ã€‚ï¼‰</li><li>ROUGE-W: æ”¹è¿›äº†ROUGE-Lï¼Œç”¨åŠ æƒçš„æ–¹æ³•è®¡ç®—æœ€é•¿å…¬å…±å­åºåˆ—ã€‚</li></ul><h4 id="è®¡ç®—å…¬å¼"><a href="#è®¡ç®—å…¬å¼" class="headerlink" title="è®¡ç®—å…¬å¼"></a>è®¡ç®—å…¬å¼</h4><ul><li><strong>ROUGE-Nï¼š</strong></li></ul><p><img src="https://www.zhihu.com/equation?tex=ROUGE-N+%3D+%5Cfrac+++++%7B+++++++++%5Csum_%5Climits%7BS%5Cin+%5C%7BReferenceSummaries%5C%7D%7D+++++%5Csum_%5Climits%7Bgram_n%5Cin+S%7D+++++Count_%7Bmatch%7D%28gram_n%29+++++%7D+++++%7B+++++++++%5Csum_%5Climits%7BS%5Cin+%5C%7BReferenceSummaries%5C%7D%7D+++++%5Csum_%5Climits%7Bgram_n%5Cin+S%7D+++++Count%28gram_n%29+++++%7D" alt=""></p><p>å…¶ä¸­ï¼Œ$n$ è¡¨ç¤ºn-gramï¼Œ$Count(gram<em>n)$è¡¨ç¤ºä¸€ä¸ªn-gramçš„å‡ºç°æ¬¡æ•°ï¼Œ$Count</em>{match}(gram_n)$ è¡¨ç¤ºä¸€ä¸ªn-gramçš„å…±ç°æ¬¡æ•°ã€‚</p><ul><li><strong>ROUGE-Lï¼š</strong></li></ul><p><img src="https://www.zhihu.com/equation?tex=ROUGE-L+%3D+%5Cfrac+%7B%281%2B%5Cbeta%5E2%29+R_%7Blcs%7D+P_%7Blcs%7D%7D+%7BR_%7Blcs%7D+%2B+%5Cbeta%5E2+P_%7Blcs%7D%7D+%5C%5C+R_%7Blcs%7D+%3D+%5Cfrac+%7BLCS%28X%2C+Y%29%7D+%7Bm%7D+%5C%5C+P_%7Blcs%7D+%3D+%5Cfrac+%7BLCS%28X%2C+Y%29%7D+%7Bn%7D" alt=""></p><p>å…¶ä¸­ï¼Œ $X$è¡¨ç¤ºå€™é€‰æ‘˜è¦ï¼Œ$Y$è¡¨ç¤ºå‚è€ƒæ‘˜è¦ï¼Œ $LCS(X,Y)$ è¡¨ç¤ºå€™é€‰æ‘˜è¦ä¸å‚è€ƒæ‘˜è¦çš„æœ€é•¿å…¬å…±å­åºåˆ—çš„é•¿åº¦ï¼Œ$m$è¡¨ç¤ºå‚è€ƒæ‘˜è¦çš„é•¿åº¦ï¼Œ$n$è¡¨ç¤ºå€™é€‰æ‘˜è¦çš„é•¿åº¦ã€‚</p><h3 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h3><p>BLEU çš„å…¨ç§°æ˜¯ åŒè¯­è¯„ä¼°è¾…åŠ©å·¥å…·(Bilingual evaluation understudy)ï¼ŒBLEU çš„åˆ†æ•°å–å€¼èŒƒå›´æ˜¯ 0ï½1ï¼Œåˆ†æ•°è¶Šæ¥è¿‘1ï¼Œè¯´æ˜ç¿»è¯‘çš„è´¨é‡è¶Šé«˜ã€‚BLEU ä¸»è¦åŸºäºç²¾ç¡®ç‡(Precision)ã€‚</p><h4 id="è®¡ç®—å…¬å¼-1"><a href="#è®¡ç®—å…¬å¼-1" class="headerlink" title="è®¡ç®—å…¬å¼"></a>è®¡ç®—å…¬å¼</h4><p><img src="https://www.zhihu.com/equation?tex=BLEU+%3D+BP+%5Ccdot+exp%28%5Csum_%5Climits%7Bn%3D1%7D%5EN+w_n+log%5C%2C+p_n+%29" alt=""></p><p>å…¶ä¸­$n$è¡¨ç¤ºn-gramï¼Œ$w_n$ è¡¨ç¤ºn-gramçš„æƒé‡ã€‚</p><p>$BP$è¡¨ç¤ºçŸ­å¥å­æƒ©ç½šå› å­ï¼ˆbrevity penaty)ï¼Œç”¨$r$è¡¨ç¤ºæœ€çŸ­çš„å‚è€ƒç¿»è¯‘çš„é•¿åº¦ï¼Œ$c$è¡¨ç¤ºå€™é€‰ç¿»è¯‘çš„é•¿åº¦ã€‚$BP$å…·ä½“è®¡ç®—æ–¹æ³•ä¸ºï¼š</p><script type="math/tex; mode=display">f(x) =   \begin{array}{lr}    1 & c>r\\   e^{(1-r/c)} & c \le r  \end{array}</script><p>$p_n$è¡¨ç¤ºn-gramçš„è¦†ç›–ç‡ï¼Œå…·ä½“è®¡ç®—æ–¹å¼ä¸ºï¼š</p><p><img src="https://www.zhihu.com/equation?tex=p_n+%3D+%5Cfrac+++++%7B+++++++++%5Csum_%5Climits%7BC%5Cin+%5C%7BCandidates%5C%7D%7D+++++%5Csum_%5Climits%7Bn-gram%5Cin+C%7D+++++Count_%7Bclip%7D%28n-gram%29+++++%7D+++++%7B+++++++++%5Csum_%5Climits%7BC%27%5Cin+%5C%7BCandidates%5C%7D%7D+++++%5Csum_%5Climits%7Bn-gram%5Cin+C%27%7D+++++Count%28n-gram%29+++++%7D" alt=""></p><p>$Count_{clip}$æ˜¯æˆªæ–­è®¡æ•°ï¼Œå…¶è®¡æ•°æ–¹å¼ä¸ºï¼šå°†ä¸€ä¸ªn-gramåœ¨å€™é€‰ç¿»è¯‘ä¸­å‡ºç°çš„æ¬¡æ•°ï¼Œä¸åœ¨å„ä¸ªå‚è€ƒç¿»è¯‘ä¸­å‡ºç°æ¬¡æ•°çš„æœ€å¤§å€¼è¿›è¡Œæ¯”è¾ƒï¼Œå–è¾ƒå°çš„é‚£ä¸€ä¸ªã€‚</p><h3 id="METEOR"><a href="#METEOR" class="headerlink" title="METEOR"></a>METEOR</h3><p>METEORå…¨ç§°æ˜¾å¼æ’åºçš„ç¿»è¯‘è¯„ä¼°æŒ‡æ ‡(Metric for Evaluation of Translation with Explicit Ordering)ã€‚</p><p>METEOR æ˜¯åŸºäºBLEUè¿›è¡Œäº†ä¸€äº›æ”¹è¿›ï¼Œå…¶ç›®çš„æ˜¯è§£å†³ä¸€äº› BLEU æ ‡å‡†ä¸­å›ºæœ‰çš„ç¼ºé™· ã€‚ä½¿ç”¨ WordNet è®¡ç®—ç‰¹å®šçš„åºåˆ—åŒ¹é…ï¼ŒåŒä¹‰è¯ï¼Œè¯æ ¹å’Œè¯ç¼€ï¼Œé‡Šä¹‰ä¹‹é—´çš„åŒ¹é…å…³ç³»ï¼Œæ”¹å–„äº†BLEUçš„æ•ˆæœï¼Œä½¿å…¶è·Ÿäººå·¥åˆ¤åˆ«å…±æ›´å¼ºçš„ç›¸å…³æ€§ã€‚å¹¶ä¸”ï¼Œæ˜¯åŸºäºFå€¼çš„ã€‚</p><h4 id="è®¡ç®—å…¬å¼-2"><a href="#è®¡ç®—å…¬å¼-2" class="headerlink" title="è®¡ç®—å…¬å¼"></a>è®¡ç®—å…¬å¼</h4><p><img src="https://www.zhihu.com/equation?tex=METEOR+%3D+%281-pen%29%5Ctimes+F_%7Bmeans%7D" alt=""></p><p>å…¶ä¸­ï¼š</p><p><img src="https://www.zhihu.com/equation?tex=F_%7Bmeans%7D+%3D+%5Cfrac+%7BPR%7D+%7B%5Calpha+P+%2B+%281-%5Calpha%29R%7D%5C%5C+P+%3D+%5Cfrac+%7Bm%7D+%7Bc%7D%5C%5C+R+%3D+%5Cfrac+%7Bm%7D+%7Br%7D" alt=""></p><p>$\alpha$ ä¸ºå¯è°ƒæ§çš„å‚æ•°ï¼Œ$m$ ä¸ºå€™é€‰ç¿»è¯‘ä¸­èƒ½å¤Ÿè¢«åŒ¹é…çš„ä¸€å…ƒç»„çš„æ•°é‡ï¼Œ$c$ ä¸ºå€™é€‰ç¿»è¯‘çš„é•¿åº¦ï¼Œ$r$ä¸ºå‚è€ƒæ‘˜è¦çš„é•¿åº¦ã€‚</p><p>$pen$ ä¸ºæƒ©ç½šå› å­ï¼Œæƒ©ç½šçš„æ˜¯å€™é€‰ç¿»è¯‘ä¸­çš„è¯åºä¸å‚è€ƒç¿»è¯‘ä¸­çš„è¯åºä¸åŒï¼Œå…·ä½“è®¡ç®—æ–¹æ³•ä¸ºï¼š</p><p><img src="https://www.zhihu.com/equation?tex=Pen+%3D+%5Cfrac+%7B%5C%23chunks%7D+%7Bm%7D" alt=""></p><p>$m$æ˜¯å€™é€‰ç¿»è¯‘ä¸­èƒ½å¤Ÿè¢«åŒ¹é…çš„ä¸€å…ƒç»„çš„æ•°é‡ï¼Œ$#chunks$ æŒ‡çš„æ˜¯chunkçš„æ•°é‡ï¼Œå³æ—¢åœ¨å€™é€‰ç¿»è¯‘ä¸­ç›¸é‚»åˆåœ¨å‚è€ƒç¿»è¯‘ä¸­ç›¸é‚»çš„è¢«åŒ¹é…çš„ä¸€å…ƒç»„èšé›†è€Œæˆçš„å•ä½ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> metric </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hugging Face åœ¨çº¿æŸ¥çœ‹NLPæ•°æ®é›†</title>
      <link href="/2021/10/03/Huggingface/"/>
      <url>/2021/10/03/Huggingface/</url>
      
        <content type="html"><![CDATA[<h1 id="Hugging-Face-åœ¨çº¿æŸ¥çœ‹NLPæ•°æ®é›†"><a href="#Hugging-Face-åœ¨çº¿æŸ¥çœ‹NLPæ•°æ®é›†" class="headerlink" title="Hugging Face åœ¨çº¿æŸ¥çœ‹NLPæ•°æ®é›†"></a>Hugging Face åœ¨çº¿æŸ¥çœ‹NLPæ•°æ®é›†</h1><blockquote><p> å®˜ç½‘ï¼š<a href="https://huggingface.co">https://huggingface.co</a></p></blockquote><p>Hugging Faceåœ¨githubä¸Šå¼€æºçš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼Œé¢„è®­ç»ƒæ¨¡å‹åº“ Transformersï¼Œ æä¾›äº†NLPé¢†åŸŸå¤§é‡state-of-artçš„ é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ç»“æ„çš„æ¨¡å‹å’Œè°ƒç”¨æ¡†æ¶ã€‚åœ°å€ï¼š<a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p><p>ä»“åº“åç§°çš„å˜è¿è¿‡ç¨‹ï¼špytorch-pretrained-bert â€”&gt; pytorch-transformers â€”&gt; transformers</p><ul><li>åœ¨çŸ¥ä¹å‘ç°ä¸€ç¯‡ååˆ†è¯¦å°½çš„å…¥é—¨æ•™ç¨‹ï¼š<a href="https://zhuanlan.zhihu.com/p/120315111">https://zhuanlan.zhihu.com/p/120315111</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Hugging Face </tag>
            
            <tag> transformers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è¿›åˆ¶è½¬æ¢</title>
      <link href="/2021/10/03/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/"/>
      <url>/2021/10/03/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="è¿›åˆ¶è½¬æ¢"><a href="#è¿›åˆ¶è½¬æ¢" class="headerlink" title="è¿›åˆ¶è½¬æ¢"></a>è¿›åˆ¶è½¬æ¢</h1><blockquote><p>æ˜¨å¤©åšleetcodeçš„æ¯æ—¥ä¸€é¢˜ï¼Œè¿›åˆ¶è½¬æ¢çš„æ—¶å€™çªç„¶è”æƒ³åˆ°äº†è¾—è½¬ç›¸é™¤æ³•ï¼Œå†è·Ÿå®¤å‹äº¤æµä¹‹åæ‰å¼„æ˜ç™½è¾—è½¬ç›¸é™¤æ³•æ˜¯æ±‚æœ€å¤§å…¬çº¦æ•°çš„ï¼Œä¸ºäº†æ‹æ¸…æ¥šè¿›åˆ¶è½¬æ¢é—®é¢˜ï¼Œåœ¨è¿™ç¯‡åšå®¢é‡Œç”¨ä¸¤ç§æ–¹æ³•è§£å†³ã€‚</p></blockquote><p>èƒŒæ™¯ï¼š405. æ•°å­—è½¬æ¢ä¸ºåå…­è¿›åˆ¶æ•°</p><blockquote><p>ç»™å®šä¸€ä¸ªæ•´æ•°ï¼Œç¼–å†™ä¸€ä¸ªç®—æ³•å°†è¿™ä¸ªæ•°è½¬æ¢ä¸ºåå…­è¿›åˆ¶æ•°ã€‚å¯¹äºè´Ÿæ•´æ•°ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨ è¡¥ç è¿ç®— æ–¹æ³•ã€‚</p></blockquote><h2 id="è¿é™¤å–ä½™æ³•"><a href="#è¿é™¤å–ä½™æ³•" class="headerlink" title="è¿é™¤å–ä½™æ³•"></a>è¿é™¤å–ä½™æ³•</h2><blockquote><p>è¿™ä¸ªæ–¹æ³•æ¯”è¾ƒå¸¸è§„ ä¸€ç›´å–ä½™æ•° æœ€åå°†ä½™æ•°å€’ç€è¾“å‡ºå°±å¥½å•¦</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    </span><br><span class="line">    def toHex(self, num: int) -&gt; str:</span><br><span class="line">        CONV = &quot;0123456789abcdef&quot;</span><br><span class="line">        ans =[]</span><br><span class="line">        # 32ä½äºŒè¿›åˆ¶æ•° è½¬æˆåå…­è¿›åˆ¶ å…±8ä½ 4*8</span><br><span class="line">        for _ in range(8): </span><br><span class="line">            temp = num % 16</span><br><span class="line">            num = num//16</span><br><span class="line">            ans.append(temp)</span><br><span class="line">            if not num:</span><br><span class="line">                break</span><br><span class="line">        # å€’ç€è¾“å‡º</span><br><span class="line">        return &#x27;&#x27;.join(CONV[j] for j in ans[::-1])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ä½è¿ç®—"><a href="#ä½è¿ç®—" class="headerlink" title="ä½è¿ç®—"></a>ä½è¿ç®—</h2><blockquote><p>è¿™ä¸ªæ“ä½œç›¸å½“ç§€äº†ã€‚ä»ACMå¤§ä½¬é‚£é‡Œå­¦åˆ°ä¸€æ‹›ï¼šå°†/2æ“ä½œå˜æˆå³ç§»ä¸€ä½ï¼Œä¸1åšä¸è¿ç®—åˆ¤æ–­å¥‡å¶æ€§æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ã€‚</p></blockquote><p>é¢„å¤‡çŸ¥è¯†ï¼š</p><ul><li>åœ¨ç¼–ç¨‹è¯­è¨€ä¸­ï¼Œåè¿›åˆ¶æ•°åšä½è¿ç®—çš„æ—¶å€™ç›´æ¥æ˜¯å½“ä½œäºŒè¿›åˆ¶æ•°æ“ä½œçš„ã€‚</li><li>å³ç§»ä¸€ä½ç›¸å½“äºæ˜¯é™¤2^1 ï¼Œæ˜¾ç„¶ï¼Œè½¬16è¿›åˆ¶æ—¶æ¯æ¬¡è¦é™¤16ï¼Œå³2^4 ï¼Œå³ç§»4ä½ æ¯é™¤ä¸€æ¬¡å¾—åˆ°æœ€é«˜ä½çš„åå…­è¿›åˆ¶æ•°ã€‚</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211003085947.png" alt="image-20211003085946977"></p><blockquote><p>è§£é‡Šä¸¤ç‚¹è‡ªå·±çš„ç–‘æƒ‘ï¼š</p><ul><li><p>int val = (num &gt;&gt; (4 * i)) &amp; 0xf;</p><p>å°†äºŒè¿›åˆ¶æ•°å››ä¸ªä¸€ç»„ è½¬æ¢æˆåå…­è¿›åˆ¶ æ¯æ¬¡å°†å¾…è½¬æ¢çš„å››ä½å³ç§»åˆ°æœ€ä½ä½ã€‚ä¸0xfåšä¸è¿ç®—çš„åŸå› åœ¨äºï¼Œåªå–æœ€ä½4ä½ï¼Œå…¶ä»–ä½å…¨ç½®ä¸º0.</p></li><li><p>int i = 7; i &gt;= 0; i â€”</p><p>ä»æœ€é«˜ä½å¼€å§‹ ä¾æ¬¡åŠ å…¥å­—ç¬¦ä¸²</p></li></ul></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    string toHex(int num) &#123;</span><br><span class="line">        if (num == 0) &#123;</span><br><span class="line">            return &quot;0&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">        string sb;</span><br><span class="line">        for (int i = 7; i &gt;= 0; i --) &#123;</span><br><span class="line">            int val = (num &gt;&gt; (4 * i)) &amp; 0xf;</span><br><span class="line">            if (sb.length() &gt; 0 || val &gt; 0) &#123;</span><br><span class="line">                char digit = val &lt; 10 ? (char) (&#x27;0&#x27; + val) : (char) (&#x27;a&#x27; + val - 10);</span><br><span class="line">                sb.push_back(digit);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return sb;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç®—æ³• </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Automatically Learning Data Augmentation Policies for Dialogue Tasks</title>
      <link href="/2021/09/28/Automatically%20Learning%20Data%20Augmentation%20Policies%20for%20Dialogue%20Tasks/"/>
      <url>/2021/09/28/Automatically%20Learning%20Data%20Augmentation%20Policies%20for%20Dialogue%20Tasks/</url>
      
        <content type="html"><![CDATA[<h1 id="Automatically-Learning-Data-Augmentation-Policies-for-Dialogue-Tasks"><a href="#Automatically-Learning-Data-Augmentation-Policies-for-Dialogue-Tasks" class="headerlink" title="Automatically Learning Data Augmentation Policies for Dialogue Tasks"></a>Automatically Learning Data Augmentation Policies for Dialogue Tasks</h1><blockquote><p> <a href="https://arxiv.org/abs/1909.12868">è®ºæ–‡ï¼šAutomatically Learning Data Augmentation Policies for Dialogue Tasks</a></p><p> <a href="https://github.com/WolfNiu/AutoAugDialogue">ä»£ç ï¼šhttps://github.com/WolfNiu/AutoAugDialogue</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><blockquote><p>AutoAugmentç®—æ³•ä¸»è¦åº”ç”¨åœ¨CVé¢†åŸŸï¼Œæœ¬æ–‡è°ƒæ•´AutoAugmentç®—æ³•åº”ç”¨åœ¨å¯¹è¯ä»»åŠ¡ä¸Šã€‚</p></blockquote><p>è‡ªåŠ¨æ•°æ®å¢å¼ºï¼ˆAutoAugmentï¼‰é€šè¿‡ä½¿ç”¨ç›®æ ‡ä»»åŠ¡ä¸Šçš„é‡‡æ ·ç­–ç•¥çš„æ€§èƒ½å¥–åŠ±è®­ç»ƒçš„æ§åˆ¶å™¨æœç´¢æœ€ä½³æ‰°åŠ¨ç­–ç•¥ï¼Œä»è€Œå‡å°‘data-levelæ¨¡å‹çš„åå·®ã€‚</p><p>æœ¬æ–‡è°ƒæ•´äº†AutoAugmentï¼Œä»¥è‡ªåŠ¨å‘ç°è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡çš„effective perturbation policies(æœ‰æ•ˆæ‰°åŠ¨ç­–ç•¥)ï¼Œå¦‚å¯¹è¯ç”Ÿæˆã€‚</p><p>è¿˜æ¢ç´¢äº†ä»¥ç›®æ ‡ä»»åŠ¡çš„æºè¾“å…¥ä¸ºæ¡ä»¶çš„æ§åˆ¶å™¨ï¼Œå› ä¸ºæŸäº›ç­–ç•¥å¯èƒ½ä¸é€‚ç”¨äºä¸åŒ…å«è¯¥ç­–ç•¥æ‰€éœ€è¯­è¨€ç‰¹å¾çš„è¾“å…¥ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>ä»ä¸€ä¸ªåŸå­æ“ä½œæ± å¼€å§‹ï¼Œå¯¹å¯¹è¯ä»»åŠ¡çš„æºè¾“å…¥è¿›è¡Œå¾®å¦™çš„è¯­ä¹‰ä¿æŠ¤æ€§æ‰°åŠ¨ï¼ˆä¾‹å¦‚ï¼Œä¸åŒçš„POS-æ ‡ç­¾ç±»å‹çš„åœé¡¿è¯ã€è¯­æ³•é”™è¯¯å’Œæ„è¯‘ï¼‰ã€‚</p><p>æ¥ä¸‹æ¥ï¼Œå…è®¸æ§åˆ¶å™¨é€šè¿‡æœç´¢è¿™äº›åŸå­æ“ä½œçš„å„ç§ç»„åˆçš„ç©ºé—´æ¥å­¦ä¹ æ›´å¤æ‚çš„å¢å¼ºç­–ç•¥ã€‚</p><p><strong>æ•°æ®å¢å¼ºç­–ç•¥ï¼š</strong></p><p>ä¸‹å›¾ä¸­ï¼Œç¬¬ä¸€ä¸ªæ“ä½œï¼ˆParaphrase, 2, 0.7ï¼‰ä»¥0.7çš„æ¦‚ç‡å¯¹è¾“å…¥è¿›è¡Œä¸¤æ¬¡è½¬è¿°ï¼›ç¬¬äºŒä¸ªæ“ä½œï¼ˆGrammar Errors, 1, 0.4ï¼‰ä»¥0.4çš„æ¦‚ç‡æ’å…¥ä¸€ä¸ªè¯­æ³•é”™è¯¯ã€‚å› æ­¤ï¼Œæ¯ä¸ªå­ç­–ç•¥æœ€å¤šå¯èƒ½æœ‰4ä¸ªç»“æœã€‚è¿™ç§ä¿®æ”¹ä¸ºæ¨¡å‹æä¾›äº†ä¸€ä¸ªæ›´å¤§çš„æ“ä½œç»„åˆç©ºé—´ï¼Œä½¿å…¶æœ‰å¯èƒ½å­¦ä¹ åˆ°æ›´å¤æ‚å’Œç»†å¾®çš„å¢å¼ºç­–ç•¥ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210928204241.png" alt="image-20210928204241718" style="zoom:67%;" /></p><h3 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h3><p>æ¨¡å‹åŒ…å«controllerå’Œtarget model</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210928205335.png" alt="image-20210928205335327" style="zoom:67%;" /></p><p>controlleré¦–å…ˆå¯¹ä¸€ä¸ªç­–ç•¥è¿›è¡Œé‡‡æ ·ï¼Œå°†åŸå§‹æ•°æ®è½¬åŒ–ä¸ºå¢å¼ºæ•°æ®ï¼Œç›®æ ‡æ¨¡å‹åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œè®­ç»ƒã€‚è®­ç»ƒç»“æŸåï¼Œå¯¹ç›®æ ‡æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œä»¥è·å¾—éªŒè¯é›†ä¸Šçš„æ€§èƒ½ã€‚ç„¶åï¼Œè¿™ä¸ªæ€§èƒ½è¢«åé¦ˆç»™controllerä½œä¸ºreward signalã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210928205353.png" alt="image-20210928205353335" style="zoom:67%;" /></p><p>input-agnosticï¼šç”±ä¸€ä¸ªå•ä¸€çš„è§£ç å™¨ç»„æˆï¼Œä¾æ¬¡å¯¹æ¯ä¸ªæ“ä½œè¿›è¡Œé‡‡æ ·ã€‚</p><blockquote><p> ä¸€ä¸ªæ“ä½œç”±3ä¸ªå‚æ•°å®šä¹‰ã€‚æ“ä½œç±»å‹ã€å…è®¸æ‰§è¡Œæ“ä½œçš„æœ€å¤§æ¬¡æ•°ã€åº”ç”¨è¯¥æ“ä½œçš„æ¦‚ç‡ã€‚</p></blockquote><p>input-awareï¼šåŠ å…¥ä¸€ä¸ªç¼–ç å™¨ï¼Œå°†è®­ç»ƒæ•°æ®ä½œä¸ºè¾“å…¥ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªseq2seqæ¨¡å‹ã€‚ç”±äºå¯¹äºæ¯ä¸ªè¾“å…¥æºï¼Œå¯èƒ½æœ‰ä¸€ç»„ä¸åŒçš„æ‰°åŠ¨æœ€é€‚åˆå®ƒï¼Œæ¨¡å‹çš„è¾“å…¥æ„ŸçŸ¥æ§åˆ¶å™¨æ—¨åœ¨ä¸ºæ¯ä¸ªè®­ç»ƒå®ä¾‹æä¾›å®šåˆ¶æ“ä½œã€‚</p><ul><li><p>æœç´¢ç®—æ³•ï¼šREINFORCE</p><blockquote><p>å¯¹å¤šä¸ªå­ç­–ç•¥è¿›è¡ŒæŠ½æ ·ä»¥å½¢æˆä¸€ä¸ªç­–ç•¥ï¼Œæä¾›äº†å¯¹æ§åˆ¶å™¨æ€§èƒ½ä¸å¤ªåé¢‡çš„ä¼°è®¡ã€‚</p></blockquote></li></ul><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>Variational Hierarchical Encoder-Decoder (VHRED)</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p>è¡¨1è¯´æ˜æ‰€æœ‰çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼ˆæœ€å3è¡Œï¼‰éƒ½æ¯”æœ€å¼ºçš„åŸºçº¿VHREDï¼ˆw/attentionï¼‰æœ‰æ˜æ˜¾çš„æ”¹å–„ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211001124428.png" alt="image-20211001124428442" style="zoom: 33%;" /></p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>æœ¬æ–‡ä½¿AutoAugmenté€‚ç”¨äºå¯¹è¯ï¼Œå¹¶å°†å…¶æ§åˆ¶å™¨æ‰©å±•åˆ°ä¸€ä¸ªæœ‰æ¡ä»¶çš„æ¨¡å‹ã€‚é€šè¿‡è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°è¡¨æ˜ï¼ŒAutoAugmentæ¨¡å‹å­¦ä¼šäº†æœ‰ç”¨çš„æ•°æ®å¢å¼ºç­–ç•¥ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> Dialogue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SEQUENTIAL LATENT KNOWLEDGE SELECTION FOR KNOWLEDGE-GROUNDED DIALOGUE</title>
      <link href="/2021/08/27/SEQUENTIAL%20LATENT%20KNOWLEDGE%20SELECTION%20FOR%20KNOWLEDGE-GROUNDED%20DIALOGUE/"/>
      <url>/2021/08/27/SEQUENTIAL%20LATENT%20KNOWLEDGE%20SELECTION%20FOR%20KNOWLEDGE-GROUNDED%20DIALOGUE/</url>
      
        <content type="html"><![CDATA[<h1 id="SEQUENTIAL-LATENT-KNOWLEDGE-SELECTION-FOR-KNOWLEDGE-GROUNDED-DIALOGUE"><a href="#SEQUENTIAL-LATENT-KNOWLEDGE-SELECTION-FOR-KNOWLEDGE-GROUNDED-DIALOGUE" class="headerlink" title="SEQUENTIAL LATENT KNOWLEDGE SELECTION FOR KNOWLEDGE-GROUNDED DIALOGUE"></a>SEQUENTIAL LATENT KNOWLEDGE SELECTION FOR KNOWLEDGE-GROUNDED DIALOGUE</h1><blockquote><p> <a href="https://arxiv.org/abs/2002.07510">è®ºæ–‡ï¼šhttps://arxiv.org/abs/2002.07510</a></p><p> <a href="https://github.com/bckim92/sequential-knowledge-transformer">ä»£ç ï¼šhttps://github.com/bckim92/sequential-knowledge-transformer</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯æ˜¯ä¸€é¡¹åŸºäºè¯è¯­èƒŒæ™¯å’Œå¤–éƒ¨çŸ¥è¯†äº§ç”Ÿä¿¡æ¯æ€§ååº”çš„ä»»åŠ¡ã€‚</p><p>æå‡ºsequential latent variable modelï¼ˆsequential knowledge transformer (SKT)ï¼‰æ›´å¥½åœ°æ¨¡æ‹Ÿå¤šè½®çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ä¸­çš„çŸ¥è¯†é€‰æ‹©ï¼Œè¯¥æ¨¡å‹å¯ä»¥è·Ÿè¸ªçŸ¥è¯†çš„å…ˆéªŒå’ŒåéªŒåˆ†å¸ƒï¼›å› æ­¤ï¼Œä¸ä»…å¯ä»¥å‡å°‘å¯¹è¯ä¸­çŸ¥è¯†é€‰æ‹©çš„å¤šæ ·æ€§é€ æˆçš„æ¨¡ç³Šæ€§ï¼Œè¿˜å¯ä»¥æ›´å¥½åœ°åˆ©ç”¨å“åº”ä¿¡æ¯æ¥æ­£ç¡®é€‰æ‹©çŸ¥è¯†ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p><strong>ä¸»è¦è´¡çŒ®ï¼š</strong></p><ol><li><p>æœ¬æ–‡æå‡ºäº†sequential knowledge transformer (SKT)æ¨¡å‹ã€‚è¯¥æ¨¡å‹æ˜¯ç¬¬ä¸€æ¬¡å°è¯•åˆ©ç”¨é¡ºåºæ½œå˜é‡æ¨¡å‹è¿›è¡ŒçŸ¥è¯†é€‰æ‹©ï¼Œéšåæ”¹å–„ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ã€‚</p></li><li><p>å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¨¡å‹ä¸ä»…æé«˜äº†çŸ¥è¯†é€‰æ‹©çš„å‡†ç¡®æ€§ï¼Œè€Œä¸”è¿˜æé«˜äº†è¯­æ–™ç”Ÿæˆçš„æ€§èƒ½ã€‚åœ¨Wizard of Wikipediaå’ŒHoll-Eæ•°æ®é›†çš„çŸ¥è¯†æ³¨é‡Šç‰ˆæœ¬ä¸Šå–å¾—äº†æ–°çš„æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p></li></ol><h3 id="APPROACH"><a href="#APPROACH" class="headerlink" title="APPROACH"></a>APPROACH</h3><p><strong>æ¨¡å‹ç»“æ„ï¼š</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210825100719.png" alt="image-20210825100719031"></p><p>SKTä¾æ¬¡å¯¹ä»¥å‰é€‰æ‹©çš„çŸ¥è¯†è¿›è¡Œå¤„ç†ï¼Œä»¥äº§ç”Ÿååº”ã€‚</p><p>æ¨¡å‹ç¬¬tè½®çš„è¾“å…¥æ˜¯ä¹‹å‰çš„å¯¹è¯å›åˆï¼ŒåŒ…å«<strong>apprentice</strong>çš„è¯è¯­$x<em>1, â€¦, x_t$, <strong>wizard</strong>çš„è¯è¯­ $y_1, â€¦, y</em>{tâˆ’1}$ï¼Œknowledge pool $k_1, â€¦, k_t$ï¼Œè¾“å‡ºä¸ºselected knowledge $k_s^t$ and the wizardâ€™s response $y_t$ã€‚</p><h4 id="Sentence-Encoding"><a href="#Sentence-Encoding" class="headerlink" title="Sentence Encoding"></a>Sentence Encoding</h4><p>apprentice utterance $x^t$ï¼š</p><p>ä½¿ç”¨BERTç¼–ç ä¸ºembedding $h_x^t$ï¼Œæ¯ä¸ªæ—¶é—´æ­¥ä½¿ç”¨average poolingã€‚</p><script type="math/tex; mode=display">H^t_x= BERT_{base}([x^t_1; ...; x^t_M]) âˆˆ R^{MÃ—768}</script><script type="math/tex; mode=display">h^t_ x= avgpool(H^t_ x) âˆˆ R^{768}</script><p>åŒæ ·ï¼ŒWizard utterance $y^{t-1}$ç¼–ç ä¸º$h<em>y^{t-1}$ï¼Œknowledge sentencesç¼–ç ä¸º${h^{t,l}</em> k} = h^{t,1}<em> k, â€¦, h^{t,L}</em> k$ã€‚</p><p>apprentice-wizard utterance pair $h<em>{xy}^t=[h_x^t,h_y^t]$åœ¨ç¬¬tè½®å¯¹è¯ä½¿ç”¨GRUè”åˆè¡¨ç¤ºä¸ºï¼š$d^t</em>{xy}=GRU<em>{dialog}(d^{t-1}</em>{xy},h^t_{xy})âˆˆ R^{768}$</p><blockquote><p>1 â‰¤ t â‰¤ Tï¼šä»£è¡¨å¯¹è¯çš„è½®æ¬¡</p><p>1 â‰¤ m â‰¤ M and 1 â‰¤ n â‰¤ N ï¼šåˆ†åˆ«è¡¨ç¤º apprentice å’Œ wizard å¯¹è¯ä¸­çš„å•è¯</p><p>1 â‰¤ l â‰¤ Lï¼šè¡¨ç¤ºknowledge sentences in the pool</p><p>Tæ˜¯å¯¹è¯é•¿åº¦ï¼ŒMå’ŒNæ˜¯apprentice å’Œ wizardçš„æ¯ä¸ªè¯è¯­çš„é•¿åº¦ï¼ŒLæ˜¯çŸ¥è¯†æ± çš„å¤§å°</p></blockquote><h4 id="Sequential-Knowledge-Selection"><a href="#Sequential-Knowledge-Selection" class="headerlink" title="Sequential Knowledge Selection"></a>Sequential Knowledge Selection</h4><p>ä¸¤ä¸ªè°ƒæ•´ï¼š</p><ul><li><p>å°†çŸ¥è¯†é€‰æ‹©è§†ä¸ºä¸€ä¸ªè¿ç»­çš„å†³ç­–è¿‡ç¨‹ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå•æ­¥å†³ç­–è¿‡ç¨‹</p></li><li><p>ç”±äºå¯¹è¯ä¸­çŸ¥è¯†é€‰æ‹©çš„å¤šæ ·æ€§ï¼Œå°†å…¶å»ºæ¨¡ä¸ºæ½œåœ¨çš„å˜é‡ã€‚</p><p>å› æ­¤ï¼Œå¯ä»¥å¯¹å¤šè½®çŸ¥è¯†é€‰æ‹©å’Œååº”ç”Ÿæˆè¿›è¡Œè”åˆæ¨ç†ï¼Œè€Œä¸æ˜¯é€è½®è¿›è¡Œå•ç‹¬æ¨ç†ã€‚</p></li></ul><p>prior distribution of knowledge :$Ï€_Î¸$</p><script type="math/tex; mode=display">Ï€_Î¸(k^t|xâ‰¤t, y<t, k_sâ‰¤tâˆ’1 ) = softmax(q^t_{prior}[h^{t,1}_ k, ..., h^{t,L}_k]^{\top}) âˆˆ R^L</script><p>posterior distribution :$q_Ï†$</p><script type="math/tex; mode=display">q_Ï†(k^t|xâ‰¤t, y<t, k_sâ‰¤tâˆ’1 ) = softmax(q^t_{post}[h^{t,1}_ k, ..., h^{t,L}_k]^{\top}) âˆˆ R^L</script><h4 id="Decoding-with-Copy-Mechanism"><a href="#Decoding-with-Copy-Mechanism" class="headerlink" title="Decoding with Copy Mechanism"></a>Decoding with Copy Mechanism</h4><p>wizardåœ¨ç¬¬$t$è½®çš„å›åº”ç”±å½“å‰context $x^t$ï¼Œå’Œé€‰æ‹©çš„knowledge sentence $k^t_s$ç”Ÿæˆã€‚</p><script type="math/tex; mode=display">H^t_{xk_s}= [H^t_x; H^t_{k_s}]</script><p>Copy Mechanismä½¿ç”¨Transformerä½œä¸ºè§£ç å™¨ã€‚</p><script type="math/tex; mode=display">h^t_ n= Decoder(H^t_ {xk_s}, y^t <n)</script><script type="math/tex; mode=display">p_{t,n}(w) = (1 âˆ’ Î±^{copy}_{t,n}) âˆ— p^{gen}_{t,n}(w) + Î±^{copy}_{t,n} âˆ— p^{copy} _{t,n}(w)</script><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>åœ¨æœ‰æ— çœŸå®æ ‡ç­¾çš„è®­ç»ƒä¸­ï¼ŒçŸ¥è¯†é€‰æ‹©çš„å‡†ç¡®æ€§å­˜åœ¨å¾ˆå¤§å·®è·ã€‚å› æ­¤ä½¿ç”¨knowledge lossï¼ˆå³é¢„æµ‹å’ŒçœŸå®çŸ¥è¯†å¥å­ä¹‹é—´çš„äº¤å‰ç†µæŸå¤±ï¼‰ä½œä¸ºæ½œå˜é‡çš„è¾…åŠ©æŸå¤±ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210826181250.png" alt="image-20210826181250713"></p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>Wizard of Wikipedia (WoW)</li><li>Holl-E</li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><ul><li>Wizard of Wikipediaæ•°æ®é›†</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210826202539.png" alt="image-20210826202539226"></p><blockquote><ul><li>æœ¬æ–‡æ¨¡å‹åœ¨çŸ¥è¯†é€‰æ‹©ï¼ˆå‡†ç¡®ç‡ï¼‰å’Œè¯­ç¯‡ç”Ÿæˆï¼ˆunigram F1ï¼Œbigram F1ï¼‰çš„æ‰€æœ‰æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºæœ€å…ˆè¿›çš„ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯æ¨¡å‹ã€‚</li><li>åœ¨æ²¡æœ‰çŸ¥è¯†æ ‡ç­¾çš„æƒ…å†µä¸‹è®­ç»ƒçš„PostKSåœ¨çŸ¥è¯†é€‰æ‹©æ–¹é¢æ˜¾ç¤ºå‡ºè¾ƒä½çš„å‡†ç¡®ç‡ï¼Œæ¯”éšæœºçŒœæµ‹ç•¥å¥½ã€‚è€Œåœ¨WoW Test Seenä¸­ï¼Œå®ƒè¾¾åˆ°äº†æ¯”E2E Transformer MemNetæ›´å¥½çš„æ€§èƒ½ï¼Œè¿™è¡¨æ˜åˆ©ç”¨å…ˆéªŒå’ŒåéªŒçŸ¥è¯†åˆ†å¸ƒå¯¹çŸ¥è¯†åŸºç¡€çš„å¯¹è¯æ˜¯æœ‰æ•ˆçš„ï¼Œ</li><li>BERTæé«˜äº†çŸ¥è¯†é€‰æ‹©çš„å‡†ç¡®æ€§ï¼Œä½†ç”±äºå¯¹è¯çŸ¥è¯†é€‰æ‹©çš„å¤šæ ·æ€§ï¼Œå…¶æé«˜å¹…åº¦å¹¶ä¸åƒTextQAé‚£æ ·å¤§ã€‚</li><li>E2E BERT + PostKS + Copyåœ¨åŸºçº¿ä¸­è¡¨ç°æœ€å¥½ï¼Œè¿™éªŒè¯äº†é¡ºåºæ½œå˜é‡å»ºæ¨¡å¯¹äºæé«˜çŸ¥è¯†é€‰æ‹©å’Œéšåçš„è¯­ç¯‡ç”Ÿæˆçš„å‡†ç¡®æ€§è‡³å…³é‡è¦ã€‚</li><li>å’ŒåŸºçº¿ä¹‹é—´çš„æ€§èƒ½å·®è·åœ¨ Test Unseen ä¸­æ›´å¤§ã€‚å¯ä»¥ç†è§£ä¸ºï¼Œé¡ºåºæ½œå˜é‡å¯ä»¥æ›´å¥½åœ°è¿›è¡Œæ³›åŒ–ã€‚</li><li>åœ¨åŸºçº¿ä¸­åŠ å…¥å¤åˆ¶æœºåˆ¶ï¼Œå¤§å¹…æé«˜äº†è¯­æ–™ç”Ÿæˆçš„å‡†ç¡®æ€§ï¼Œä½†å‡ ä¹æ²¡æœ‰æ”¹å–„çŸ¥è¯†é€‰æ‹©ï¼Œè¿™ä¹Ÿè¯æ˜äº†é¡ºåºæ½œå˜é‡çš„æœ‰æ•ˆæ€§ã€‚</li><li>Transformerï¼ˆno knowledgeï¼‰åœ¨WoW Test Seen ä¸­æ˜¾ç¤ºå‡ºæœ€ä½çš„å›°æƒ‘ï¼Œè¿™ä¸»è¦æ˜¯ç”±äºå®ƒå¯èƒ½åªç”Ÿæˆä¸€èˆ¬å’Œç®€å•çš„è¯­æ–™ï¼Œå› ä¸ºæ²¡æœ‰çŸ¥è¯†åŸºç¡€ã€‚è¿™ç§è¡Œä¸ºå¯¹å›°æƒ‘åº¦æ˜¯æœ‰åˆ©çš„ï¼Œè€Œå…¶ä»–åŸºäºçŸ¥è¯†çš„æ¨¡å‹åˆ™æœ‰é¢„æµ‹é”™è¯¯çŸ¥è¯†çš„é£é™©ï¼Œè¿™å¯¹å›°æƒ‘åº¦æ˜¯ä¸åˆ©çš„ã€‚</li></ul></blockquote><ul><li>Holl-E</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210826202712.png" alt="image-20210826202712236"></p><blockquote><ul><li><p>æœ¬æ–‡çš„æ¨¡å‹åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºæ‰€æœ‰åŸºçº¿</p></li><li><p>ä¸€ä¸ªå€¼å¾—æ³¨æ„çš„è¶‹åŠ¿æ˜¯ï¼ŒBERTå¤§å¤§é™ä½äº†æ‰€æœ‰æ¨¡å‹çš„å›°æƒ‘åº¦ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºHoll-Eçš„æ•°æ®é›†è§„æ¨¡æ¯”WoWå°å¾—å¤šï¼ŒBERTå¯ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚</p></li></ul></blockquote><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>æœ¬æ–‡ç ”ç©¶äº†å¤šè½®çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ä¸­çš„çŸ¥è¯†é€‰æ‹©é—®é¢˜ï¼Œå¹¶é¦–æ¬¡æå‡ºäº†ä¸€ä¸ªé¡ºåºæ½œå˜é‡æ¨¡å‹SKTã€‚æ¨¡å‹åœ¨Wizard of Wikipediaå’ŒHoll-Eæ•°æ®é›†çš„çŸ¥è¯†æ³¨é‡Šç‰ˆæœ¬ä¸Šå–å¾—äº†æ–°çš„æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ‰€æå‡ºçš„æ¨¡å‹æé«˜äº†çŸ¥è¯†é€‰æ‹©çš„å‡†ç¡®æ€§ï¼Œä»è€Œæé«˜äº†è¯­ç¯‡ç”Ÿæˆçš„æ€§èƒ½ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Dialogue </tag>
            
            <tag> SKT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlowå¸¸ç”¨æ“ä½œ</title>
      <link href="/2021/08/23/TensorFlow%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
      <url>/2021/08/23/TensorFlow%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="æŒ‡å®šGPU"><a href="#æŒ‡å®šGPU" class="headerlink" title="æŒ‡å®šGPU"></a>æŒ‡å®šGPU</h2><ul><li>ç»ˆç«¯æŒ‡å®š</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 nohup python demo.py &gt;&gt; base_log.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><ul><li>ç¨‹åºæŒ‡å®š</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;</span><br></pre></td></tr></table></figure><h1 id="TensorFlowå¸¸ç”¨æ“ä½œ"><a href="#TensorFlowå¸¸ç”¨æ“ä½œ" class="headerlink" title="TensorFlowå¸¸ç”¨æ“ä½œ"></a>TensorFlowå¸¸ç”¨æ“ä½œ</h1><h2 id="æ£€æµ‹GPUæ˜¯å¦å¯ç”¨"><a href="#æ£€æµ‹GPUæ˜¯å¦å¯ç”¨" class="headerlink" title="æ£€æµ‹GPUæ˜¯å¦å¯ç”¨"></a>æ£€æµ‹GPUæ˜¯å¦å¯ç”¨</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">tf.test.is_gpu_available()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ•™ç¨‹ </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨TensorFlowå®ç°GRU</title>
      <link href="/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0GRU/"/>
      <url>/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0GRU/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨TensorFlowå®ç°GRU"><a href="#ä½¿ç”¨TensorFlowå®ç°GRU" class="headerlink" title="ä½¿ç”¨TensorFlowå®ç°GRU"></a>ä½¿ç”¨TensorFlowå®ç°GRU</h1><h2 id="ä½¿ç”¨Cellå®ç°"><a href="#ä½¿ç”¨Cellå®ç°" class="headerlink" title="ä½¿ç”¨Cellå®ç°"></a>ä½¿ç”¨Cellå®ç°</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"># ä»¥Cellæ–¹å¼å®ç°GRU</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># æŒ‡å®šGPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;2&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 128  # æ‰¹é‡å¤§å°</span><br><span class="line">total_words = 10000  # è¯æ±‡è¡¨å¤§å°N_vocab</span><br><span class="line">max_review_len = 80  # å¥å­æœ€å¤§é•¿åº¦sï¼Œå¤§äºçš„å¥å­éƒ¨åˆ†å°†æˆªæ–­ï¼Œå°äºçš„å°†å¡«å……</span><br><span class="line">embedding_len = 100  # è¯å‘é‡ç‰¹å¾é•¿åº¦f</span><br><span class="line"># åŠ è½½IMDBæ•°æ®é›†ï¼Œæ­¤å¤„çš„æ•°æ®é‡‡ç”¨æ•°å­—ç¼–ç ï¼Œä¸€ä¸ªæ•°å­—ä»£è¡¨ä¸€ä¸ªå•è¯</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(x_train[0])</span><br><span class="line"># %%</span><br><span class="line"># æ•°å­—ç¼–ç è¡¨</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># ç¿»è½¬ç¼–ç è¡¨</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">decode_review(x_train[8])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># æˆªæ–­å’Œå¡«å……å¥å­ï¼Œä½¿å¾—ç­‰é•¿ï¼Œæ­¤å¤„é•¿å¥å­ä¿ç•™å¥å­åé¢çš„éƒ¨åˆ†ï¼ŒçŸ­å¥å­åœ¨å‰é¢å¡«å……</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"># æ„å»ºæ•°æ®é›†ï¼Œæ‰“æ•£ï¼Œæ‰¹é‡ï¼Œå¹¶ä¸¢æ‰æœ€åä¸€ä¸ªä¸å¤Ÿbatch_sizeçš„batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Cellæ–¹å¼æ„å»ºå¤šå±‚ç½‘ç»œ</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # [b, 64]ï¼Œæ„å»ºCellåˆå§‹åŒ–çŠ¶æ€å‘é‡ï¼Œé‡å¤ä½¿ç”¨</span><br><span class="line">        # GRUä¸RNNç›¸åŒ éšè—å±‚çŠ¶æ€ä¸º1ä¸ª LSTMä¸¤ä¸ª</span><br><span class="line">        self.state0 = [tf.zeros([batch_size, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batch_size, units])]</span><br><span class="line">        # è¯å‘é‡ç¼–ç  [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # æ„å»º2ä¸ªCell</span><br><span class="line">        self.rnn_cell0 = layers.GRUCell(units, dropout=0.5)</span><br><span class="line">        self.rnn_cell1 = layers.GRUCell(units, dropout=0.5)</span><br><span class="line">        # æ„å»ºåˆ†ç±»ç½‘ç»œï¼Œç”¨äºå°†CELLçš„è¾“å‡ºç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œ2åˆ†ç±»</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(units),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        state0 = self.state0</span><br><span class="line">        state1 = self.state1</span><br><span class="line">        out1 = None</span><br><span class="line">        for word in tf.unstack(x, axis=1):  # word: [b, 100]</span><br><span class="line">            out0, state0 = self.rnn_cell0(word, state0, training)</span><br><span class="line">            out1, state1 = self.rnn_cell1(out0, state1, training)</span><br><span class="line">        # æœ«å±‚æœ€åä¸€ä¸ªè¾“å‡ºä½œä¸ºåˆ†ç±»ç½‘ç»œçš„è¾“å…¥: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(out1, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 64  # RNNçŠ¶æ€å‘é‡é•¿åº¦f</span><br><span class="line">    epochs = 50  # è®­ç»ƒepochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # è£…é…</span><br><span class="line">    model.compile(optimizer=optimizers.RMSprop(0.001),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # è®­ç»ƒå’ŒéªŒè¯</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # æµ‹è¯•</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ä½¿ç”¨Layerå®ç°"><a href="#ä½¿ç”¨Layerå®ç°" class="headerlink" title="ä½¿ç”¨Layerå®ç°"></a>ä½¿ç”¨Layerå®ç°</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"># ä»¥Layeræ–¹å¼å®ç°GRU</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># æŒ‡å®šGPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;3&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 128  # æ‰¹é‡å¤§å°</span><br><span class="line">total_words = 10000  # è¯æ±‡è¡¨å¤§å°N_vocab</span><br><span class="line">max_review_len = 80  # å¥å­æœ€å¤§é•¿åº¦sï¼Œå¤§äºçš„å¥å­éƒ¨åˆ†å°†æˆªæ–­ï¼Œå°äºçš„å°†å¡«å……</span><br><span class="line">embedding_len = 100  # è¯å‘é‡ç‰¹å¾é•¿åº¦f</span><br><span class="line"># åŠ è½½IMDBæ•°æ®é›†ï¼Œæ­¤å¤„çš„æ•°æ®é‡‡ç”¨æ•°å­—ç¼–ç ï¼Œä¸€ä¸ªæ•°å­—ä»£è¡¨ä¸€ä¸ªå•è¯</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(x_train[0])</span><br><span class="line"># %%</span><br><span class="line"># æ•°å­—ç¼–ç è¡¨</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># ç¿»è½¬ç¼–ç è¡¨</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">decode_review(x_train[8])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># æˆªæ–­å’Œå¡«å……å¥å­ï¼Œä½¿å¾—ç­‰é•¿ï¼Œæ­¤å¤„é•¿å¥å­ä¿ç•™å¥å­åé¢çš„éƒ¨åˆ†ï¼ŒçŸ­å¥å­åœ¨å‰é¢å¡«å……</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"># æ„å»ºæ•°æ®é›†ï¼Œæ‰“æ•£ï¼Œæ‰¹é‡ï¼Œå¹¶ä¸¢æ‰æœ€åä¸€ä¸ªä¸å¤Ÿbatchszçš„batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Cellæ–¹å¼æ„å»ºå¤šå±‚ç½‘ç»œ</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # è¯å‘é‡ç¼–ç  [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # æ„å»ºRNN</span><br><span class="line">        self.rnn = keras.Sequential([</span><br><span class="line">            layers.GRU(units, dropout=0.5, return_sequences=True),</span><br><span class="line">            layers.GRU(units, dropout=0.5)</span><br><span class="line">        ])</span><br><span class="line">        # æ„å»ºåˆ†ç±»ç½‘ç»œï¼Œç”¨äºå°†CELLçš„è¾“å‡ºç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œ2åˆ†ç±»</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(32),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None,mask=None):</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        x = self.rnn(x)</span><br><span class="line">        # æœ«å±‚æœ€åä¸€ä¸ªè¾“å‡ºä½œä¸ºåˆ†ç±»ç½‘ç»œçš„è¾“å…¥: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(x, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 32  # RNNçŠ¶æ€å‘é‡é•¿åº¦f</span><br><span class="line">    epochs = 50  # è®­ç»ƒepochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # è£…é…</span><br><span class="line">    model.compile(optimizer=optimizers.Adam(0.001),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # è®­ç»ƒå’ŒéªŒè¯</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # æµ‹è¯•</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
            <tag> GRU </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨TensorFlowå®ç°LSTM</title>
      <link href="/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0LSTM/"/>
      <url>/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0LSTM/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨TensorFlowå®ç°LSTM"><a href="#ä½¿ç”¨TensorFlowå®ç°LSTM" class="headerlink" title="ä½¿ç”¨TensorFlowå®ç°LSTM"></a>ä½¿ç”¨TensorFlowå®ç°LSTM</h1><h2 id="ä½¿ç”¨Cellå®ç°"><a href="#ä½¿ç”¨Cellå®ç°" class="headerlink" title="ä½¿ç”¨Cellå®ç°"></a>ä½¿ç”¨Cellå®ç°</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"># ä»¥Cellæ–¹å¼å®ç°LSTM</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># æŒ‡å®šGPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 128  # æ‰¹é‡å¤§å°</span><br><span class="line">total_words = 10000  # è¯æ±‡è¡¨å¤§å°N_vocab</span><br><span class="line">max_review_len = 80  # å¥å­æœ€å¤§é•¿åº¦sï¼Œå¤§äºçš„å¥å­éƒ¨åˆ†å°†æˆªæ–­ï¼Œå°äºçš„å°†å¡«å……</span><br><span class="line">embedding_len = 100  # è¯å‘é‡ç‰¹å¾é•¿åº¦f</span><br><span class="line"># åŠ è½½IMDBæ•°æ®é›†ï¼Œæ­¤å¤„çš„æ•°æ®é‡‡ç”¨æ•°å­—ç¼–ç ï¼Œä¸€ä¸ªæ•°å­—ä»£è¡¨ä¸€ä¸ªå•è¯</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(x_train[0])</span><br><span class="line"># %%</span><br><span class="line"># æ•°å­—ç¼–ç è¡¨</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># ç¿»è½¬ç¼–ç è¡¨</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">decode_review(x_train[8])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># æˆªæ–­å’Œå¡«å……å¥å­ï¼Œä½¿å¾—ç­‰é•¿ï¼Œæ­¤å¤„é•¿å¥å­ä¿ç•™å¥å­åé¢çš„éƒ¨åˆ†ï¼ŒçŸ­å¥å­åœ¨å‰é¢å¡«å……</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"># æ„å»ºæ•°æ®é›†ï¼Œæ‰“æ•£ï¼Œæ‰¹é‡ï¼Œå¹¶ä¸¢æ‰æœ€åä¸€ä¸ªä¸å¤Ÿbatchszçš„batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Cellæ–¹å¼æ„å»ºå¤šå±‚ç½‘ç»œ</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # [b, 64]ï¼Œæ„å»ºCellåˆå§‹åŒ–çŠ¶æ€å‘é‡ï¼Œé‡å¤ä½¿ç”¨</span><br><span class="line">        # ä¸RNNä¸åŒ LSTMæœ‰ä¸¤ä¸ªè¾“å‡º éšè—å±‚çŠ¶æ€ä¹Ÿä¸ºä¸¤ä¸ª</span><br><span class="line">        self.state0 = [tf.zeros([batch_size, units]), tf.zeros([batch_size, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batch_size, units]), tf.zeros([batch_size, units])]</span><br><span class="line">        # è¯å‘é‡ç¼–ç  [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # æ„å»º2ä¸ªCell</span><br><span class="line">        self.rnn_cell0 = layers.LSTMCell(units, dropout=0.5)</span><br><span class="line">        self.rnn_cell1 = layers.LSTMCell(units, dropout=0.5)</span><br><span class="line">        # æ„å»ºåˆ†ç±»ç½‘ç»œï¼Œç”¨äºå°†CELLçš„è¾“å‡ºç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œ2åˆ†ç±»</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(units),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        state0 = self.state0</span><br><span class="line">        state1 = self.state1</span><br><span class="line">        out1 = None</span><br><span class="line">        for word in tf.unstack(x, axis=1):  # word: [b, 100]</span><br><span class="line">            out0, state0 = self.rnn_cell0(word, state0, training)</span><br><span class="line">            out1, state1 = self.rnn_cell1(out0, state1, training)</span><br><span class="line">        # æœ«å±‚æœ€åä¸€ä¸ªè¾“å‡ºä½œä¸ºåˆ†ç±»ç½‘ç»œçš„è¾“å…¥: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(out1, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 64  # RNNçŠ¶æ€å‘é‡é•¿åº¦f</span><br><span class="line">    epochs = 50  # è®­ç»ƒepochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # è£…é…</span><br><span class="line">    model.compile(optimizer=optimizers.RMSprop(0.001),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # è®­ç»ƒå’ŒéªŒè¯</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # æµ‹è¯•</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ä½¿ç”¨Layerå®ç°"><a href="#ä½¿ç”¨Layerå®ç°" class="headerlink" title="ä½¿ç”¨Layerå®ç°"></a>ä½¿ç”¨Layerå®ç°</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"># ä»¥Layeræ–¹å¼å®ç°LSTM</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># æŒ‡å®šGPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;2&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 128  # æ‰¹é‡å¤§å°</span><br><span class="line">total_words = 10000  # è¯æ±‡è¡¨å¤§å°N_vocab</span><br><span class="line">max_review_len = 80  # å¥å­æœ€å¤§é•¿åº¦sï¼Œå¤§äºçš„å¥å­éƒ¨åˆ†å°†æˆªæ–­ï¼Œå°äºçš„å°†å¡«å……</span><br><span class="line">embedding_len = 100  # è¯å‘é‡ç‰¹å¾é•¿åº¦f</span><br><span class="line"># åŠ è½½IMDBæ•°æ®é›†ï¼Œæ­¤å¤„çš„æ•°æ®é‡‡ç”¨æ•°å­—ç¼–ç ï¼Œä¸€ä¸ªæ•°å­—ä»£è¡¨ä¸€ä¸ªå•è¯</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(x_train[0])</span><br><span class="line"># %%</span><br><span class="line"># æ•°å­—ç¼–ç è¡¨</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># ç¿»è½¬ç¼–ç è¡¨</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">decode_review(x_train[8])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># æˆªæ–­å’Œå¡«å……å¥å­ï¼Œä½¿å¾—ç­‰é•¿ï¼Œæ­¤å¤„é•¿å¥å­ä¿ç•™å¥å­åé¢çš„éƒ¨åˆ†ï¼ŒçŸ­å¥å­åœ¨å‰é¢å¡«å……</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"># æ„å»ºæ•°æ®é›†ï¼Œæ‰“æ•£ï¼Œæ‰¹é‡ï¼Œå¹¶ä¸¢æ‰æœ€åä¸€ä¸ªä¸å¤Ÿbatchszçš„batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Cellæ–¹å¼æ„å»ºå¤šå±‚ç½‘ç»œ</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # è¯å‘é‡ç¼–ç  [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # æ„å»ºRNN</span><br><span class="line">        self.rnn = keras.Sequential([</span><br><span class="line">            layers.LSTM(units, dropout=0.5, return_sequences=True),</span><br><span class="line">            layers.LSTM(units, dropout=0.5)</span><br><span class="line">        ])</span><br><span class="line">        # æ„å»ºåˆ†ç±»ç½‘ç»œï¼Œç”¨äºå°†CELLçš„è¾“å‡ºç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œ2åˆ†ç±»</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(32),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        x = self.rnn(x)</span><br><span class="line">        # æœ«å±‚æœ€åä¸€ä¸ªè¾“å‡ºä½œä¸ºåˆ†ç±»ç½‘ç»œçš„è¾“å…¥: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(x, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 32  # RNNçŠ¶æ€å‘é‡é•¿åº¦f</span><br><span class="line">    epochs = 50  # è®­ç»ƒepochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # è£…é…</span><br><span class="line">    model.compile(optimizer=optimizers.Adam(0.001),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # è®­ç»ƒå’ŒéªŒè¯</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # æµ‹è¯•</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨TensorFlowå®ç°RNN</title>
      <link href="/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0RNN/"/>
      <url>/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0RNN/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨TensorFlowå®ç°RNN"><a href="#ä½¿ç”¨TensorFlowå®ç°RNN" class="headerlink" title="ä½¿ç”¨TensorFlowå®ç°RNN"></a>ä½¿ç”¨TensorFlowå®ç°RNN</h1><h2 id="ä½¿ç”¨Cellå®ç°"><a href="#ä½¿ç”¨Cellå®ç°" class="headerlink" title="ä½¿ç”¨Cellå®ç°"></a>ä½¿ç”¨Cellå®ç°</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"># ä»¥cellæ–¹å¼å®ç°RNN</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># æŒ‡å®šGPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line"># é¿å…è¾“å‡ºæ— å…³è°ƒè¯•ä¿¡æ¯</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 128  # æ‰¹é‡å¤§å°</span><br><span class="line">total_words = 10000  # è¯æ±‡è¡¨å¤§å°N_vocab</span><br><span class="line">max_review_len = 80  # å¥å­æœ€å¤§é•¿åº¦sï¼Œå¤§äºçš„å¥å­éƒ¨åˆ†å°†æˆªæ–­ï¼Œå°äºçš„å°†å¡«å……</span><br><span class="line">embedding_len = 100  # è¯å‘é‡ç‰¹å¾é•¿åº¦f</span><br><span class="line"></span><br><span class="line"># åŠ è½½IMDBæ•°æ®é›†ï¼Œæ­¤å¤„çš„æ•°æ®é‡‡ç”¨æ•°å­—ç¼–ç ï¼Œä¸€ä¸ªæ•°å­—ä»£è¡¨ä¸€ä¸ªå•è¯</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(&#x27;dataset shape&#x27;)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(&#x27;dataset x_train[0]: &#x27;, x_train[0])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"># æ•°å­—ç¼–ç è¡¨</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line"># è°ƒæ•´ç‰¹æ®Šè¯æ±‡ä½ç½®</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># ç¿»è½¬ç¼–ç è¡¨</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    # dict.get(key, default=None)</span><br><span class="line">    # default -- å¦‚æœæŒ‡å®šé”®çš„å€¼ä¸å­˜åœ¨æ—¶ï¼Œè¿”å›è¯¥é»˜è®¤å€¼ã€‚</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ç¼–ç --&gt;å¥å­</span><br><span class="line">print(decode_review(x_train[8]))</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># æˆªæ–­å’Œå¡«å……å¥å­ï¼Œä½¿å¾—ç­‰é•¿ï¼Œæ­¤å¤„é•¿å¥å­ä¿ç•™å¥å­åé¢çš„éƒ¨åˆ†ï¼ŒçŸ­å¥å­åœ¨å‰é¢å¡«å……</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"></span><br><span class="line"># æ„å»ºæ•°æ®é›†ï¼Œæ‰“æ•£ï¼Œæ‰¹é‡ï¼Œå¹¶ä¸¢æ‰æœ€åä¸€ä¸ªä¸å¤Ÿbatch_sizeçš„batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Cellæ–¹å¼æ„å»ºå¤šå±‚ç½‘ç»œ</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        # units [b, 64]</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # [b, 64]ï¼Œæ„å»ºCellåˆå§‹åŒ–çŠ¶æ€å‘é‡ï¼Œé‡å¤ä½¿ç”¨</span><br><span class="line">        self.state0 = [tf.zeros([batch_size, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batch_size, units])]</span><br><span class="line">        # è¯å‘é‡ç¼–ç  [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # æ„å»º2ä¸ªCell</span><br><span class="line">        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.5)</span><br><span class="line">        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.5)</span><br><span class="line">        # æ„å»ºåˆ†ç±»ç½‘ç»œï¼Œç”¨äºå°†CELLçš„è¾“å‡ºç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œ2åˆ†ç±»</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(units),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line">        # æµ‹è¯•é˜¶æ®µ training=false</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        # åˆå§‹åŒ–éšè—å±‚çŠ¶æ€</span><br><span class="line">        state0 = self.state0</span><br><span class="line">        state1 = self.state1</span><br><span class="line">        out1 = None</span><br><span class="line">        for word in tf.unstack(x, axis=1):  # word: [b, 100]</span><br><span class="line">            out0, state0 = self.rnn_cell0(word, state0, training)</span><br><span class="line">            # ç¬¬äºŒå±‚çš„è¾“å…¥ä¸ºç¬¬ä¸€å±‚çš„è¾“å‡º</span><br><span class="line">            out1, state1 = self.rnn_cell1(out0, state1, training)</span><br><span class="line">        # æœ«å±‚æœ€åä¸€ä¸ªè¾“å‡ºä½œä¸ºåˆ†ç±»ç½‘ç»œçš„è¾“å…¥: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(out1, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 64  # RNNçŠ¶æ€å‘é‡é•¿åº¦f</span><br><span class="line">    epochs = 50  # è®­ç»ƒepochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # è£…é…</span><br><span class="line">    model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-3),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # è®­ç»ƒå’ŒéªŒè¯</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # æµ‹è¯•</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="ä½¿ç”¨Layerå®ç°"><a href="#ä½¿ç”¨Layerå®ç°" class="headerlink" title="ä½¿ç”¨Layerå®ç°"></a>ä½¿ç”¨Layerå®ç°</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"># ä»¥Layeræ–¹å¼å®ç°RNN</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># æŒ‡å®šGPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 512  # æ‰¹é‡å¤§å°</span><br><span class="line">total_words = 10000  # è¯æ±‡è¡¨å¤§å°N_vocab</span><br><span class="line">max_review_len = 80  # å¥å­æœ€å¤§é•¿åº¦sï¼Œå¤§äºçš„å¥å­éƒ¨åˆ†å°†æˆªæ–­ï¼Œå°äºçš„å°†å¡«å……</span><br><span class="line">embedding_len = 100  # è¯å‘é‡ç‰¹å¾é•¿åº¦f</span><br><span class="line"></span><br><span class="line"># åŠ è½½IMDBæ•°æ®é›†ï¼Œæ­¤å¤„çš„æ•°æ®é‡‡ç”¨æ•°å­—ç¼–ç ï¼Œä¸€ä¸ªæ•°å­—ä»£è¡¨ä¸€ä¸ªå•è¯</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(x_train[0])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"># æ•°å­—ç¼–ç è¡¨</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># ç¿»è½¬ç¼–ç è¡¨</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">decode_review(x_train[8])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># æˆªæ–­å’Œå¡«å……å¥å­ï¼Œä½¿å¾—ç­‰é•¿ï¼Œæ­¤å¤„é•¿å¥å­ä¿ç•™å¥å­åé¢çš„éƒ¨åˆ†ï¼ŒçŸ­å¥å­åœ¨å‰é¢å¡«å……</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"></span><br><span class="line"># æ„å»ºæ•°æ®é›†ï¼Œæ‰“æ•£ï¼Œæ‰¹é‡ï¼Œå¹¶ä¸¢æ‰æœ€åä¸€ä¸ªä¸å¤Ÿbatch_sizeçš„batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Layeræ–¹å¼æ„å»ºå¤šå±‚ç½‘ç»œ</span><br><span class="line">    # è¯¥æ–¹å¼ä¸éœ€è¦è®¾ç½®RNNåˆå§‹çŠ¶æ€</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # è¯å‘é‡ç¼–ç  [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # æ„å»ºRNN ä½¿ç”¨Sequentialç®¡ç†ä¸¤å±‚RNN</span><br><span class="line">        # return_sequences=True ä½¿è¯¥å±‚è¾“å‡ºä½œä¸ºä¸‹ä¸€å±‚è¾“å…¥</span><br><span class="line">        self.rnn = keras.Sequential([</span><br><span class="line">            layers.SimpleRNN(units, dropout=0.5, return_sequences=True),</span><br><span class="line">            layers.SimpleRNN(units, dropout=0.5)</span><br><span class="line">        ])</span><br><span class="line">        # æ„å»ºåˆ†ç±»ç½‘ç»œï¼Œç”¨äºå°†CELLçš„è¾“å‡ºç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œ2åˆ†ç±»</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(32),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        # Layeræ–¹å¼ä¸ç”¨æ‰‹åŠ¨ç®¡ç†éšè—å±‚çŠ¶æ€</span><br><span class="line">        x = self.rnn(x)</span><br><span class="line">        # æœ«å±‚æœ€åä¸€ä¸ªè¾“å‡ºä½œä¸ºåˆ†ç±»ç½‘ç»œçš„è¾“å…¥: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(x, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 64  # RNNçŠ¶æ€å‘é‡é•¿åº¦f</span><br><span class="line">    epochs = 5  # è®­ç»ƒepochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # è£…é…</span><br><span class="line">    model.compile(optimizer=optimizers.Adam(0.001),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # è®­ç»ƒå’ŒéªŒè¯</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # æµ‹è¯•</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ™ºèƒ½å°è½¦å¼€å‘æ–‡æ¡£</title>
      <link href="/2021/08/23/%E6%99%BA%E8%83%BD%E5%B0%8F%E8%BD%A6%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3/"/>
      <url>/2021/08/23/%E6%99%BA%E8%83%BD%E5%B0%8F%E8%BD%A6%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3/</url>
      
        <content type="html"><![CDATA[<p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210823152407.JPG" alt="1"></p><h1 id="MQTT"><a href="#MQTT" class="headerlink" title="MQTT"></a>MQTT</h1><h2 id="ä¸»é¢˜ï¼š"><a href="#ä¸»é¢˜ï¼š" class="headerlink" title="ä¸»é¢˜ï¼š"></a>ä¸»é¢˜ï¼š</h2><p>å°ç¨‹åºâ€”â€”-ç¡¬ä»¶ï¼šjm_y2m</p><p>ç¡¬ä»¶â€”â€”-å°ç¨‹åºï¼šjm_m2y</p><h1 id="å¼•è„š"><a href="#å¼•è„š" class="headerlink" title="å¼•è„š"></a>å¼•è„š</h1><h2 id="uno-r3-å¼•è„šå®šä¹‰"><a href="#uno-r3-å¼•è„šå®šä¹‰" class="headerlink" title="uno r3 å¼•è„šå®šä¹‰"></a>uno r3 å¼•è„šå®šä¹‰</h2><p>  ç›´æµç”µæœºé©±åŠ¨æ¿ï¼š5 6 10 11<br>  èœ‚é¸£å™¨ 5vï¼š8<br>  è¶…å£°æ³¢ä¼ æ„Ÿå™¨ 5vï¼šA0 A1<br>  LED 5vï¼š7<br>  å…‰çº¿ä¼ æ„Ÿå™¨ 5vï¼šA3<br>  äººä½“çº¢å¤–ä¼ æ„Ÿå™¨ 3.3vï¼šA2<br>  è½¯ä¸²å£ï¼š3, 4</p><h2 id="wifi-d1-å¼•è„šå®šä¹‰"><a href="#wifi-d1-å¼•è„šå®šä¹‰" class="headerlink" title="wifi d1 å¼•è„šå®šä¹‰"></a>wifi d1 å¼•è„šå®šä¹‰</h2><p>  DHT11 5v ï¼šD7<br>  è§¦æ‘¸æŒ‰é”® 3.3v ï¼šD8<br>  OLED 5v ï¼šD15â€”SCL D14â€”SDA<br>  è½¯ä¸²å£ï¼šRX=D8,TX=D9</p><h1 id="æŒ‡ä»¤"><a href="#æŒ‡ä»¤" class="headerlink" title="æŒ‡ä»¤"></a>æŒ‡ä»¤</h1><h2 id="esp8266â€”â€”-gt-uno-r3"><a href="#esp8266â€”â€”-gt-uno-r3" class="headerlink" title="esp8266â€”â€”-&gt;uno r3"></a>esp8266â€”â€”-&gt;uno r3</h2><h3 id="ä¸²å£"><a href="#ä¸²å£" class="headerlink" title="ä¸²å£"></a>ä¸²å£</h3><p>æ–¹å‘ï¼š</p><blockquote><p>å‰ï¼šw</p><p>åï¼šs</p><p>å·¦ï¼ša</p><p>å³ï¼šd</p><p>åˆ¹è½¦ï¼š q</p></blockquote><p>èœ‚é¸£å™¨ï¼š</p><blockquote><p>è®¾ç½®ï¼ˆ1å£°ï¼‰ï¼š1</p><p>æ¶ˆæ¯ï¼ˆ3å£°ï¼‰ï¼š3</p></blockquote><p>è®¾ç½®å°å¤œç¯æ¨¡å‹ï¼š</p><blockquote><p>å°å¤œç¯å¼€ï¼šn</p><p>å°å¤œç¯å…³ï¼šl</p></blockquote><p>è®¾ç½®é¿éšœæ¨¡å¼ï¼š</p><blockquote><p>å¼€å¯é¿éšœï¼šo</p><p>å…³é—­é¿éšœï¼šp</p></blockquote><p>åˆå§‹åŒ–å®Œæˆæç¤ºï¼š</p><blockquote><p>æ¶ˆæ¯ï¼ˆ3å£°ï¼‰ï¼š3</p></blockquote><p>è½¦é€Ÿè®¾ç½®ï¼š</p><blockquote><p>1 2 3æ¡£</p><p>z x c</p></blockquote><h2 id="å°ç¨‹åºâ€”â€”â€”-gt-esp8266"><a href="#å°ç¨‹åºâ€”â€”â€”-gt-esp8266" class="headerlink" title="å°ç¨‹åºâ€”â€”â€”-&gt;esp8266"></a>å°ç¨‹åºâ€”â€”â€”-&gt;esp8266</h2><h3 id="æ¶ˆæ¯"><a href="#æ¶ˆæ¯" class="headerlink" title="æ¶ˆæ¯"></a>æ¶ˆæ¯</h3><ul><li>å°ç¨‹åºå‘é€</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;msg&quot;,</span><br><span class="line">  &quot;msg1&quot;: &quot;å¾®ä¿¡æŸ¥æ‰¾å…¬ä¼—å·&quot;,</span><br><span class="line">  &quot;msg2&quot;: &quot;1234567&quot;,</span><br><span class="line">  &quot;msg3&quot;: &quot;qwertydf&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;success\&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="è®¾ç½®"><a href="#è®¾ç½®" class="headerlink" title="è®¾ç½®"></a>è®¾ç½®</h3><p><strong>æ¶ˆæ¯æé†’æ¬¡æ•°</strong></p><ul><li>å°ç¨‹åºå‘é€</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;MSG_BEEP_TIMES&quot;,</span><br><span class="line">&quot;payload&quot;:3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>å¤‡å¿˜å½•æ¨¡å¼</strong></p><ul><li><p>å°ç¨‹åºå‘é€</p><blockquote><p>1å¼€  0å…³</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;KEEP_MSG&quot;,</span><br><span class="line">&quot;payload&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>å°å¤œç¯å¼€å…³</strong></p><ul><li><p>å°ç¨‹åºå‘é€</p><blockquote><p> //n å¼€ l å…³</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;night_light&quot;,</span><br><span class="line">&quot;payload&quot;:&quot;n&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>é¿éšœæ¨¡å¼å¼€å…³</strong></p><ul><li><p>å°ç¨‹åºå‘é€</p><blockquote><p> //o å¼€ p å…³</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;barrier_status&quot;,</span><br><span class="line">&quot;payload&quot;:&quot;o&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>é™éŸ³æ¨¡å¼</strong></p><ul><li>å°ç¨‹åºå‘é€ </li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> //1 æ™®é€š 2 é™éŸ³</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;MODE&quot;,</span><br><span class="line">&quot;payload&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>é‡æ–°é…ç½‘</strong></p><ul><li>å°ç¨‹åºå‘é€</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;changewifi&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>ä¿®æ”¹åŸå¸‚</strong></p><ul><li>å°ç¨‹åºå‘é€</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;CITY&quot;,</span><br><span class="line">&quot;payload&quot;:&quot;lanzhou&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>æ›´æ¢APIKEY</strong></p><ul><li>å°ç¨‹åºå‘é€</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;APIKEY&quot;,</span><br><span class="line">&quot;payload&quot;:&quot;123dasdasd&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>åˆ¤æ–­8266æ˜¯å¦åœ¨çº¿</strong></p><ul><li>å°ç¨‹åºå‘é€</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;is_connected&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;is_connected\&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="ä¸Šä¼ æ•°æ®"><a href="#ä¸Šä¼ æ•°æ®" class="headerlink" title="ä¸Šä¼ æ•°æ®"></a>ä¸Šä¼ æ•°æ®</h3><p><strong>è·å–ç¯å¢ƒæ¸©æ¹¿åº¦ è·å–å°å¤œç¯çŠ¶æ€</strong></p><ul><li>å°ç¨‹åºå‘é€</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;update&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;temp&quot;:20,&quot;humi&quot;:30,&quot;barrier_status&quot;,&quot;o&quot;,night_light_status&quot;:&quot;n&quot;,&quot;MODE&quot;:1,&quot;KEEP_MSG&quot;:0,&quot;car_speed&quot;:&quot;&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="å°è½¦æ§åˆ¶"><a href="#å°è½¦æ§åˆ¶" class="headerlink" title="å°è½¦æ§åˆ¶"></a>å°è½¦æ§åˆ¶</h3><p><strong>å‰åå·¦å³</strong></p><ul><li>å°ç¨‹åºå‘é€</li></ul><p>å‰ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;front&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>åï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;back&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å·¦ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;left&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å³ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;right&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>åœï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;stop&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;received\&quot;&#125;&quot;</span><br></pre></td></tr></table></figure><p><strong>è½¦é€Ÿ</strong></p><ul><li><p>å°ç¨‹åºå‘é€</p><blockquote><p>ä¸€æ¡£z ï¼šspeed1</p><p>äºŒæ¡£x ï¼šspeed2</p><p>ä¸‰æ¡£cï¼šspeed3</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;speed1&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266åé¦ˆ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;received\&quot;&#125;&quot;</span><br></pre></td></tr></table></figure><image class="main" src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210815224418.JPG"  style="position: absolute; left: 0rpx; top: -218rpx; width: 750rpx; height: 1497rpx; display: flex; box-sizing: border-box"></image>]]></content>
      
      
      <categories>
          
          <category> ç¡¬ä»¶å¼€å‘ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQTT </tag>
            
            <tag> Arduino </tag>
            
            <tag> å¾®ä¿¡å°ç¨‹åº </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Improving Low-resource Reading Comprehension via Cross-lingual Transposition Rethinking</title>
      <link href="/2021/08/20/Improving%20Low-resource%20Reading%20Comprehension%20via%20Cross-lingual%20Transposition%20Rethinking/"/>
      <url>/2021/08/20/Improving%20Low-resource%20Reading%20Comprehension%20via%20Cross-lingual%20Transposition%20Rethinking/</url>
      
        <content type="html"><![CDATA[<h1 id="Improving-Low-resource-Reading-Comprehension-via-Cross-lingual-Transposition-Rethinking"><a href="#Improving-Low-resource-Reading-Comprehension-via-Cross-lingual-Transposition-Rethinking" class="headerlink" title="Improving Low-resource Reading Comprehension via Cross-lingual Transposition Rethinking"></a>Improving Low-resource Reading Comprehension via Cross-lingual Transposition Rethinking</h1><blockquote><p> <a href="https://arxiv.org/abs/2107.05002">è®ºæ–‡ï¼šhttps://arxiv.org/abs/2107.05002</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>è§£å†³æŠ½å–å¼é˜…è¯»ç†è§£ä¸­ä½èµ„æºè¯­è¨€è®­ç»ƒæ•°æ®ä¸è¶³çš„é—®é¢˜ã€‚ é€šè¿‡åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­å¯¹ç°æœ‰çš„é«˜è´¨é‡æå–å¼é˜…è¯»ç†è§£æ•°æ®é›†è¿›è¡Œå»ºæ¨¡ï¼Œæå‡ºäº†ä¸€ä¸ªè·¨è¯­è¨€è½¬ç½®å†æ€è€ƒï¼ˆXLTTï¼‰æ¨¡å‹ï¼ˆ<strong>Cross-Lingual Transposition ReThinking</strong>ï¼‰ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>æå‡ºäº†å¤šè¯­è¨€é€‚åº”æ€§æ³¨æ„ï¼ˆmultilingual adaptive attention MAAï¼‰ï¼Œå°†intra-attentionï¼Œinter-attentionç»“åˆèµ·æ¥ï¼Œä»æ¯ä¸€å¯¹è¯­è¨€å®¶æ—ä¸­å­¦ä¹ æ›´æ™®éçš„å¯å½’çº³çš„è¯­ä¹‰å’Œè¯æ³•çŸ¥è¯†ã€‚ä¸ºäº†å……åˆ†åˆ©ç”¨ç°æœ‰çš„æ•°æ®é›†ï¼Œæœ¬æ–‡é‡‡ç”¨äº†ä¸€ä¸ªæ–°çš„è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªç°æœ‰æ•°æ®é›†å’Œç›®æ ‡æ•°æ®é›†ä¹‹é—´çš„ä»»åŠ¡çº§ç›¸ä¼¼åº¦æ¥è®­ç»ƒæ¨¡å‹ã€‚</p><h3 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h3><ul><li>é¦–å…ˆï¼Œå¯¹äºç°æœ‰çš„æŠ½å–å¼é˜…è¯»ç†è§£æ•°æ®é›†ï¼Œé¦–å…ˆåˆ©ç”¨GNMTæ„å»ºäº†å¤šä¸ªè¯­ç³»çš„å¤šè¯­è¨€å¹³è¡Œè¯­æ–™ï¼Œå¦‚ï¼ˆè‹±è¯­ã€æ—¥è¯­ã€éŸ©è¯­â€¦â€¦ï¼‰ã€‚ </li><li>å…¶æ¬¡ï¼Œåˆ©ç”¨å¤šè¯­è¨€è‡ªé€‚åº”æ³¨æ„åŠ›ï¼Œåœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­å­¦ä¹ è¯­è¨€å­¦ç›¸å…³çš„è¯­ä¹‰å’Œè¯æ±‡çŸ¥è¯†ï¼Œä»¥æ™®åŠåˆ°ä½èµ„æºè¯­è¨€ã€‚ </li><li>ç„¶åï¼Œè®¡ç®—æ¯ä¸ªè®­ç»ƒæ•°æ®é›†å’Œç›®æ ‡æ•°æ®é›†ä¹‹é—´çš„ä»»åŠ¡çº§ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨TF-IDFè®¡ç®—ï¼‰ï¼Œä»¥ä½¿ç”¨å¤šä¸ªè®­ç»ƒæ•°æ®é›†ã€‚</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210818111737.png" alt="image-20210818111737645" style="zoom:67%;" /></p><p>ä½¿ç”¨å…±äº«çš„å¤šè¯­è¨€ç¼–ç å™¨ï¼Œå¦‚Multi-BERTå’ŒXLM-Rï¼Œå¯¹æ„å»ºçš„å¤šè¯­è¨€å¹³è¡Œè¯­æ–™åº“è¿›è¡Œç¼–ç ï¼Œä»¥è·å¾—ä¸Šä¸‹æ–‡çš„å‘é‡è¡¨ç¤ºã€‚</p><p>ä¸»è¦è´¡çŒ®ï¼š</p><ul><li>æå‡ºäº†ä¸€ç§è·¨è¯­è¨€è½¬ç½®å†æ€è€ƒï¼ˆXLTTï¼‰çš„æ–¹æ³•ï¼Œåœ¨å¤šè¯­è¨€èƒŒæ™¯ä¸‹åˆ©ç”¨ç°æœ‰çš„å¤§è§„æ¨¡é«˜è´¨é‡ERCï¼ˆæŠ½å–å¼æœºå™¨é˜…è¯»ç†è§£ï¼‰æ•°æ®é›†æ¥è§£å†³ä½èµ„æºERCçš„é—®é¢˜ã€‚</li><li>æå‡ºäº†å¤šè¯­è¨€é€‚åº”æ€§æ³¨æ„åŠ›ï¼ˆMAAï¼‰æœºåˆ¶ï¼Œé€šè¿‡ç»“åˆintra-attentionå’Œinter-attentionçš„å…³ç³»ï¼Œå¯ä»¥ä½¿æŠ½å–æ€§RCæ¨¡å‹ä»æ¯ä¸€å¯¹è¯­è¨€å®¶æ—ä¸­æ•æ‰åˆ°æ›´æ™®éçš„å¯å½’çº³çš„è¯­ä¹‰å’Œè¯æ±‡ä¿¡æ¯ï¼Œæœ‰åˆ©äºæ¨å¹¿åˆ°ä½èµ„æºè¯­è¨€ã€‚æœ¬æ–‡è¿˜æå‡ºäº†ä¸€ä¸ªæ–°çš„è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªç°æœ‰è®­ç»ƒæ•°æ®é›†å’Œç›®æ ‡æ•°æ®é›†ä¹‹é—´çš„ä»»åŠ¡çº§ç›¸ä¼¼åº¦æ¥è®­ç»ƒERCæ¨¡å‹ã€‚</li><li>å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ¬æ–‡æå‡ºçš„æ¨¡å‹åœ¨2ä¸ªå¤šè¯­è¨€æå–é˜…è¯»ç†è§£åŸºå‡†ä¸Šçš„è¡¨ç°ä¼˜äº6ä¸ªåŸºå‡†ï¼Œè¯æ˜äº†å¤šè¯­è¨€å»ºæ¨¡æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li></ul><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p><strong>MLQA</strong></p><blockquote><p>ä¸ƒç§è¯­è¨€çš„å¤šå‘å¹³è¡ŒæŠ½å–å¼é—®é¢˜å›ç­”è¯„ä¼°åŸºå‡†</p></blockquote><p>TYDI QA</p><blockquote><p> æ¶µç›–11ç§ä¸åŒç±»å‹è¯­è¨€çš„QAæ•°æ®é›†ï¼Œæœ‰204Kä¸ªQAå¯¹ã€‚</p></blockquote><p><strong>XQuAD</strong></p><blockquote><p> é€šè¿‡å°†å®ä¾‹ç¿»è¯‘æˆåç§è¯­è¨€ï¼Œä»240ä¸ªæ®µè½ä¸­è·å¾—äº†1190ä¸ªSQuAD v1.1 QAå¯¹çš„æ•°æ®é›†ã€‚</p></blockquote><p>XTREME</p><blockquote><p>å¤§è§„æ¨¡çš„å¤šè¯­è¨€å¤šä»»åŠ¡åŸºå‡†ï¼Œç”¨äºéªŒè¯å’Œç¡®è®¤å¤šè¯­è¨€æ¨¡å‹çš„è·¨è¯­è¨€æ³›åŒ–èƒ½åŠ›ã€‚</p></blockquote><h2 id="æ€§èƒ½æ°´å¹³-amp-ç»“è®º"><a href="#æ€§èƒ½æ°´å¹³-amp-ç»“è®º" class="headerlink" title="æ€§èƒ½æ°´å¹³&amp;ç»“è®º"></a>æ€§èƒ½æ°´å¹³&amp;ç»“è®º</h2><p>MLQAæ•°æ®é›†æµ‹è¯•ç»“æœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210818195927.png" alt="QQ20210818-195753"></p><p>XQuADæ•°æ®é›†æµ‹è¯•ç»“æœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210818195842.png" alt="QQ20210818-195811"></p><p>ä¸ä¹‹å‰çš„æœ€ä½³æ¨¡å‹ç›¸æ¯”ï¼ŒXLTTæ¨¡å‹åœ¨MLQAæµ‹è¯•é›†ä¸Šå–å¾—äº†å¹³å‡5.1çš„F1æˆç»©å’Œ4.5çš„EMæˆç»©ï¼Œåœ¨XQuADæµ‹è¯•é›†ä¸Šè·å¾—äº†å¹³å‡2.7çš„F1æˆç»©å’Œ3.6çš„EMæˆç»©ã€‚ä¸¤ç§å¤šè¯­è¨€ERCçš„å®éªŒç»“æœè¯æ˜äº†æœ¬æ–‡æå‡ºçš„å¤šè¯­è¨€ERCæ–¹æ³•å¯¹å¯¹ä½èµ„æºè¯­è¨€çš„æœ‰æ•ˆæ€§ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> Low-resource </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MS MARCO NLGä»»åŠ¡è°ƒç ”</title>
      <link href="/2021/08/13/MS-MARCO-NLG%E4%BB%BB%E5%8A%A1%E8%B0%83%E7%A0%94/"/>
      <url>/2021/08/13/MS-MARCO-NLG%E4%BB%BB%E5%8A%A1%E8%B0%83%E7%A0%94/</url>
      
        <content type="html"><![CDATA[<h1 id="MS-MARCO-NLGä»»åŠ¡è°ƒç ”"><a href="#MS-MARCO-NLGä»»åŠ¡è°ƒç ”" class="headerlink" title="MS MARCO NLGä»»åŠ¡è°ƒç ”"></a>MS MARCO NLGä»»åŠ¡è°ƒç ”</h1><blockquote><p>NLGâ€”â€”è‡ªç„¶è¯­è¨€ç”Ÿæˆ</p><p><a href="https://microsoft.github.io/msmarco/">MS MARCO:https://microsoft.github.io/msmarco/</a></p><p>Natural Language Generation Task:RETIRED(03/01/2018-10/30/2020)</p></blockquote><h2 id="å‚è€ƒè®ºæ–‡"><a href="#å‚è€ƒè®ºæ–‡" class="headerlink" title="å‚è€ƒè®ºæ–‡"></a>å‚è€ƒè®ºæ–‡</h2><div class="table-container"><table><thead><tr><th>Rank</th><th>Model</th><th>Paper</th><th>Code</th><th>Submissio Date</th><th>Rouge-L</th><th>Bleu-1</th></tr></thead><tbody><tr><td>2</td><td><strong>PALM</strong> Alibaba Damo NLP</td><td><a href="https://arxiv.org/abs/2004.07159">PALM: Pre-training an Autoencoding&amp;Autoregressive Language Model for Context-conditioned Generation</a></td><td><a href="https://github.com/alibaba/AliceMind/tree/main/PALM">https://github.com/alibaba/AliceMind/tree/main/PALM</a></td><td>December 16th,2019</td><td>0.498</td><td>0.499</td></tr><tr><td>4</td><td><strong>Masque NLGEN Style</strong> NTT Media Intelligence Laboratories</td><td><a href="https://arxiv.org/abs/1901.02262">Multi-style Generative Reading Comprehension</a></td><td></td><td>January 3rd, 2019</td><td>0.496</td><td>0.501</td></tr><tr><td>15</td><td><strong>VNET</strong> Baidu NLP</td><td><a href="https://arxiv.org/abs/1805.02220">Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification</a></td><td></td><td>November 8th, 2018</td><td>0.484</td><td>0.468</td></tr><tr><td>40</td><td><strong>ConZNet</strong> Samsung Research</td><td><a href="https://aclanthology.org/D18-1054/">Cut to the Chase: A Context Zoom-in Network for Reading Comprehension</a></td><td></td><td>July 16th, 2018</td><td>0.421</td><td>0.386</td></tr><tr><td>90</td><td><strong>BiDaF Baseline(Implemented By MSMARCO Team)</strong> Allen Institute for AI &amp; University of Washington</td><td><a href="https://arxiv.org/abs/1611.01603">Bidirectional Attention Flow for Machine Comprehension</a></td><td><a href="https://github.com/allenai/bi-att-flow">https://github.com/allenai/bi-att-flow</a></td><td>April 23th, 2018</td><td>0.169</td><td>0.093</td></tr></tbody></table></div><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><div class="table-container"><table><thead><tr><th>Dataset</th><th>Segment</th><th>Query Source</th><th>Answer</th><th>Queries</th><th>Document</th></tr></thead><tbody><tr><td>SQuAD</td><td>No</td><td>Crowd-sourced</td><td>Span</td><td>100k</td><td>536</td></tr><tr><td>CNN/Daily Mail</td><td>No</td><td>close</td><td>Fill in entity</td><td>1.4M</td><td>93K CNN, 220K DM</td></tr><tr><td>MS MARCO v2</td><td>Yes</td><td>User logs</td><td>Human generated</td><td>1M</td><td>8.8M passages, 3.2M docs</td></tr><tr><td>NarrativeQA</td><td>No</td><td>Crowd-sourced</td><td>Human generated</td><td>47k</td><td>1572 stories</td></tr><tr><td>DuReader</td><td>No</td><td>Crowd-sourced</td><td>Human generated</td><td>200K</td><td>1M</td></tr></tbody></table></div><h2 id="å¸¸ç”¨æ¨¡å‹"><a href="#å¸¸ç”¨æ¨¡å‹" class="headerlink" title="å¸¸ç”¨æ¨¡å‹"></a>å¸¸ç”¨æ¨¡å‹</h2><div class="table-container"><table><thead><tr><th>Model</th><th>ä»‹ç»</th><th>è®ºæ–‡</th></tr></thead><tbody><tr><td><strong>PALM</strong></td><td>Pre-training an Autoencoding&amp;Autoregressive Language Model</td><td><a href="https://arxiv.org/abs/2004.07159">PALM: Pre-training an Autoencoding&amp;Autoregressive Language Model for Context-conditioned Generation</a></td></tr><tr><td><strong>ConZNet</strong></td><td>context zoom-in network</td><td><a href="https://aclanthology.org/D18-1054/">Cut to the Chase: A Context Zoom-in Network for Reading Comprehension</a></td></tr><tr><td><strong>V-NET</strong></td><td>an end-to-end frame- work to tackle the multi-passage MRC task</td><td><a href="https://arxiv.org/abs/1805.02220">Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification</a></td></tr><tr><td>S-Net</td><td>an extraction-then-synthesis framework</td><td><a href="https://arxiv.org/abs/1706.04815">S-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension</a></td></tr><tr><td>Selector NLGEN</td><td></td><td></td></tr><tr><td>BERT+Multi-Pointer</td><td></td><td></td></tr><tr><td>CompLM</td><td></td><td></td></tr><tr><td><strong>Masque</strong></td><td>based on multi-source abstractive summarization and learns multi-style answers together</td><td><a href="https://arxiv.org/abs/1901.02262">Multi-style Generative Reading Comprehension</a></td></tr><tr><td><strong>BiDAF</strong></td><td>Bi-Directional Attention Flow</td><td><a href="https://arxiv.org/abs/1611.01603">Bidirectional Attention Flow for Machine Comprehension</a></td></tr><tr><td>MRU</td><td>Multi-Range Reasoning Units</td><td><a href="https://arxiv.org/abs/1803.09074">Multi-range Reasoning for Machine Comprehension</a></td></tr></tbody></table></div><h2 id="è¯„ä»·æŒ‡æ ‡"><a href="#è¯„ä»·æŒ‡æ ‡" class="headerlink" title="è¯„ä»·æŒ‡æ ‡"></a>è¯„ä»·æŒ‡æ ‡</h2><p>NLGå¸¸ç”¨metricsï¼š</p><ul><li><strong>BLEU</strong></li><li><strong>ROUGE</strong></li><li><strong>METEOR</strong></li><li>lNIST/CIDEr</li><li>STM</li><li>TER</li><li>TERp</li></ul><h3 id="ROUGE"><a href="#ROUGE" class="headerlink" title="ROUGE"></a>ROUGE</h3><p>ROUGE æŒ‡æ ‡çš„å…¨ç§°æ˜¯ (Recall-Oriented Understudy for Gisting Evaluation)ï¼Œä¸»è¦åŸºäºå¬å›ç‡ã€‚ROUGE æ˜¯ä¸€ç§å¸¸ç”¨çš„æœºå™¨ç¿»è¯‘å’Œæ–‡ç« æ‘˜è¦è¯„ä»·æŒ‡æ ‡ï¼Œç”± Chin-Yew Lin æå‡ºã€‚</p><p> 4 ç§ ROUGE æ–¹æ³•ï¼š</p><ul><li>ROUGE-N: åœ¨ N-gram ä¸Šè®¡ç®—å¬å›ç‡ã€‚</li><li>ROUGE-L: è€ƒè™‘äº†æœºå™¨è¯‘æ–‡å’Œå‚è€ƒè¯‘æ–‡ä¹‹é—´çš„æœ€é•¿å…¬å…±å­åºåˆ—ï¼ˆé•¿åº¦è¶Šé•¿ï¼Œå¾—åˆ†è¶Šé«˜ï¼ŒåŸºäºFå€¼ã€‚ï¼‰</li><li>ROUGE-W: æ”¹è¿›äº†ROUGE-Lï¼Œç”¨åŠ æƒçš„æ–¹æ³•è®¡ç®—æœ€é•¿å…¬å…±å­åºåˆ—ã€‚</li></ul><h4 id="è®¡ç®—å…¬å¼"><a href="#è®¡ç®—å…¬å¼" class="headerlink" title="è®¡ç®—å…¬å¼"></a>è®¡ç®—å…¬å¼</h4><ul><li><strong>ROUGE-Nï¼š</strong></li></ul><p><img src="https://www.zhihu.com/equation?tex=ROUGE-N+%3D+%5Cfrac+++++%7B+++++++++%5Csum_%5Climits%7BS%5Cin+%5C%7BReferenceSummaries%5C%7D%7D+++++%5Csum_%5Climits%7Bgram_n%5Cin+S%7D+++++Count_%7Bmatch%7D%28gram_n%29+++++%7D+++++%7B+++++++++%5Csum_%5Climits%7BS%5Cin+%5C%7BReferenceSummaries%5C%7D%7D+++++%5Csum_%5Climits%7Bgram_n%5Cin+S%7D+++++Count%28gram_n%29+++++%7D" alt=""></p><p>å…¶ä¸­ï¼Œ$n$ è¡¨ç¤ºn-gramï¼Œ$Count(gram<em>n)$è¡¨ç¤ºä¸€ä¸ªn-gramçš„å‡ºç°æ¬¡æ•°ï¼Œ$Count</em>{match}(gram_n)$ è¡¨ç¤ºä¸€ä¸ªn-gramçš„å…±ç°æ¬¡æ•°ã€‚</p><ul><li><strong>ROUGE-Lï¼š</strong></li></ul><p><img src="https://www.zhihu.com/equation?tex=ROUGE-L+%3D+%5Cfrac+%7B%281%2B%5Cbeta%5E2%29+R_%7Blcs%7D+P_%7Blcs%7D%7D+%7BR_%7Blcs%7D+%2B+%5Cbeta%5E2+P_%7Blcs%7D%7D+%5C%5C+R_%7Blcs%7D+%3D+%5Cfrac+%7BLCS%28X%2C+Y%29%7D+%7Bm%7D+%5C%5C+P_%7Blcs%7D+%3D+%5Cfrac+%7BLCS%28X%2C+Y%29%7D+%7Bn%7D" alt=""></p><p>å…¶ä¸­ï¼Œ $X$è¡¨ç¤ºå€™é€‰æ‘˜è¦ï¼Œ$Y$è¡¨ç¤ºå‚è€ƒæ‘˜è¦ï¼Œ $LCS(X,Y)$ è¡¨ç¤ºå€™é€‰æ‘˜è¦ä¸å‚è€ƒæ‘˜è¦çš„æœ€é•¿å…¬å…±å­åºåˆ—çš„é•¿åº¦ï¼Œ$m$â€‹è¡¨ç¤ºå‚è€ƒæ‘˜è¦çš„é•¿åº¦ï¼Œ$n$â€‹è¡¨ç¤ºå€™é€‰æ‘˜è¦çš„é•¿åº¦ã€‚</p><h3 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h3><p>BLEU çš„å…¨ç§°æ˜¯ åŒè¯­è¯„ä¼°è¾…åŠ©å·¥å…·(Bilingual evaluation understudy)ï¼ŒBLEU çš„åˆ†æ•°å–å€¼èŒƒå›´æ˜¯ 0ï½1ï¼Œåˆ†æ•°è¶Šæ¥è¿‘1ï¼Œè¯´æ˜ç¿»è¯‘çš„è´¨é‡è¶Šé«˜ã€‚BLEU ä¸»è¦åŸºäºç²¾ç¡®ç‡(Precision)ã€‚</p><h4 id="è®¡ç®—å…¬å¼-1"><a href="#è®¡ç®—å…¬å¼-1" class="headerlink" title="è®¡ç®—å…¬å¼"></a>è®¡ç®—å…¬å¼</h4><p><img src="https://www.zhihu.com/equation?tex=BLEU+%3D+BP+%5Ccdot+exp%28%5Csum_%5Climits%7Bn%3D1%7D%5EN+w_n+log%5C%2C+p_n+%29" alt=""></p><p>å…¶ä¸­$n$è¡¨ç¤ºn-gramï¼Œ$w_n$â€‹ è¡¨ç¤ºn-gramçš„æƒé‡ã€‚</p><p>$BP$è¡¨ç¤ºçŸ­å¥å­æƒ©ç½šå› å­ï¼ˆbrevity penaty)ï¼Œç”¨$r$è¡¨ç¤ºæœ€çŸ­çš„å‚è€ƒç¿»è¯‘çš„é•¿åº¦ï¼Œ$c$è¡¨ç¤ºå€™é€‰ç¿»è¯‘çš„é•¿åº¦ã€‚$BP$å…·ä½“è®¡ç®—æ–¹æ³•ä¸ºï¼š</p><script type="math/tex; mode=display">f(x) =   \begin{array}{lr}    1 & c>r\\   e^{(1-r/c)} & c \le r  \end{array}</script><p>$p_n$è¡¨ç¤ºn-gramçš„è¦†ç›–ç‡ï¼Œå…·ä½“è®¡ç®—æ–¹å¼ä¸ºï¼š</p><p><img src="https://www.zhihu.com/equation?tex=p_n+%3D+%5Cfrac+++++%7B+++++++++%5Csum_%5Climits%7BC%5Cin+%5C%7BCandidates%5C%7D%7D+++++%5Csum_%5Climits%7Bn-gram%5Cin+C%7D+++++Count_%7Bclip%7D%28n-gram%29+++++%7D+++++%7B+++++++++%5Csum_%5Climits%7BC%27%5Cin+%5C%7BCandidates%5C%7D%7D+++++%5Csum_%5Climits%7Bn-gram%5Cin+C%27%7D+++++Count%28n-gram%29+++++%7D" alt=""></p><p>$Count_{clip}$æ˜¯æˆªæ–­è®¡æ•°ï¼Œå…¶è®¡æ•°æ–¹å¼ä¸ºï¼šå°†ä¸€ä¸ªn-gramåœ¨å€™é€‰ç¿»è¯‘ä¸­å‡ºç°çš„æ¬¡æ•°ï¼Œä¸åœ¨å„ä¸ªå‚è€ƒç¿»è¯‘ä¸­å‡ºç°æ¬¡æ•°çš„æœ€å¤§å€¼è¿›è¡Œæ¯”è¾ƒï¼Œå–è¾ƒå°çš„é‚£ä¸€ä¸ªã€‚</p><h3 id="METEOR"><a href="#METEOR" class="headerlink" title="METEOR"></a>METEOR</h3><p>METEORå…¨ç§°æ˜¾å¼æ’åºçš„ç¿»è¯‘è¯„ä¼°æŒ‡æ ‡(Metric for Evaluation of Translation with Explicit Ordering)ã€‚</p><p>METEOR æ˜¯åŸºäºBLEUè¿›è¡Œäº†ä¸€äº›æ”¹è¿›ï¼Œå…¶ç›®çš„æ˜¯è§£å†³ä¸€äº› BLEU æ ‡å‡†ä¸­å›ºæœ‰çš„ç¼ºé™· ã€‚ä½¿ç”¨ WordNet è®¡ç®—ç‰¹å®šçš„åºåˆ—åŒ¹é…ï¼ŒåŒä¹‰è¯ï¼Œè¯æ ¹å’Œè¯ç¼€ï¼Œé‡Šä¹‰ä¹‹é—´çš„åŒ¹é…å…³ç³»ï¼Œæ”¹å–„äº†BLEUçš„æ•ˆæœï¼Œä½¿å…¶è·Ÿäººå·¥åˆ¤åˆ«å…±æ›´å¼ºçš„ç›¸å…³æ€§ã€‚å¹¶ä¸”ï¼Œæ˜¯åŸºäºFå€¼çš„ã€‚</p><h4 id="è®¡ç®—å…¬å¼-2"><a href="#è®¡ç®—å…¬å¼-2" class="headerlink" title="è®¡ç®—å…¬å¼"></a>è®¡ç®—å…¬å¼</h4><p><img src="https://www.zhihu.com/equation?tex=METEOR+%3D+%281-pen%29%5Ctimes+F_%7Bmeans%7D" alt=""></p><p>å…¶ä¸­ï¼š</p><p><img src="https://www.zhihu.com/equation?tex=F_%7Bmeans%7D+%3D+%5Cfrac+%7BPR%7D+%7B%5Calpha+P+%2B+%281-%5Calpha%29R%7D%5C%5C+P+%3D+%5Cfrac+%7Bm%7D+%7Bc%7D%5C%5C+R+%3D+%5Cfrac+%7Bm%7D+%7Br%7D" alt=""></p><p>$\alpha$ ä¸ºå¯è°ƒæ§çš„å‚æ•°ï¼Œ$m$ ä¸ºå€™é€‰ç¿»è¯‘ä¸­èƒ½å¤Ÿè¢«åŒ¹é…çš„ä¸€å…ƒç»„çš„æ•°é‡ï¼Œ$c$ ä¸ºå€™é€‰ç¿»è¯‘çš„é•¿åº¦ï¼Œ$r$ä¸ºå‚è€ƒæ‘˜è¦çš„é•¿åº¦ã€‚</p><p>$pen$ ä¸ºæƒ©ç½šå› å­ï¼Œæƒ©ç½šçš„æ˜¯å€™é€‰ç¿»è¯‘ä¸­çš„è¯åºä¸å‚è€ƒç¿»è¯‘ä¸­çš„è¯åºä¸åŒï¼Œå…·ä½“è®¡ç®—æ–¹æ³•ä¸ºï¼š</p><p><img src="https://www.zhihu.com/equation?tex=Pen+%3D+%5Cfrac+%7B%5C%23chunks%7D+%7Bm%7D" alt=""></p><p>$m$â€‹æ˜¯å€™é€‰ç¿»è¯‘ä¸­èƒ½å¤Ÿè¢«åŒ¹é…çš„ä¸€å…ƒç»„çš„æ•°é‡ï¼Œ$#chunks$â€‹â€‹â€‹ æŒ‡çš„æ˜¯chunkçš„æ•°é‡ï¼Œå³æ—¢åœ¨å€™é€‰ç¿»è¯‘ä¸­ç›¸é‚»åˆåœ¨å‚è€ƒç¿»è¯‘ä¸­ç›¸é‚»çš„è¢«åŒ¹é…çš„ä¸€å…ƒç»„èšé›†è€Œæˆçš„å•ä½ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MARCO </tag>
            
            <tag> NLG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç®€ç‰ˆ-ç¿»è¯‘ã€æ‘˜è¦ã€ä¼šè¯ã€æ–‡æœ¬ç”Ÿæˆä»»åŠ¡é¡¶ä¼šè®ºæ–‡</title>
      <link href="/2021/08/13/%E7%AE%80%E7%89%88-%E7%BF%BB%E8%AF%91%E3%80%81%E6%91%98%E8%A6%81%E3%80%81%E4%BC%9A%E8%AF%9D%E3%80%81%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/"/>
      <url>/2021/08/13/%E7%AE%80%E7%89%88-%E7%BF%BB%E8%AF%91%E3%80%81%E6%91%98%E8%A6%81%E3%80%81%E4%BC%9A%E8%AF%9D%E3%80%81%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h1 id="ç®€ç‰ˆ-ç¿»è¯‘ã€æ‘˜è¦ã€ä¼šè¯ã€æ–‡æœ¬ç”Ÿæˆä»»åŠ¡é¡¶ä¼šè®ºæ–‡"><a href="#ç®€ç‰ˆ-ç¿»è¯‘ã€æ‘˜è¦ã€ä¼šè¯ã€æ–‡æœ¬ç”Ÿæˆä»»åŠ¡é¡¶ä¼šè®ºæ–‡" class="headerlink" title="ç®€ç‰ˆ-ç¿»è¯‘ã€æ‘˜è¦ã€ä¼šè¯ã€æ–‡æœ¬ç”Ÿæˆä»»åŠ¡é¡¶ä¼šè®ºæ–‡"></a>ç®€ç‰ˆ-ç¿»è¯‘ã€æ‘˜è¦ã€ä¼šè¯ã€æ–‡æœ¬ç”Ÿæˆä»»åŠ¡é¡¶ä¼šè®ºæ–‡</h1><h2 id="æœºå™¨ç¿»è¯‘"><a href="#æœºå™¨ç¿»è¯‘" class="headerlink" title="æœºå™¨ç¿»è¯‘"></a>æœºå™¨ç¿»è¯‘</h2><h3 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1811.00357&#39;]">Latent Variable Model for Multi-modal Translation</a></td><td></td><td><a href="https://github.com/iacercalixto/variational_mmt">https://github.com/iacercalixto/variational_mmt</a></td><td><a href="https://arxiv.org/pdf/1811.00357">https://arxiv.org/pdf/1811.00357</a></td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.05414&#39;]">Rewriter-Evaluator Architecture for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.05414">https://arxiv.org/pdf/2012.05414</a></td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.08226&#39;]">Consistency Regularization for Cross-Lingual Fine-Tuning</a></td><td></td><td><a href="https://github.com/bozheng-hit/xTune">https://github.com/bozheng-hit/xTune</a></td><td><a href="https://arxiv.org/pdf/2106.08226">https://arxiv.org/pdf/2106.08226</a></td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06381&#39;]">Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment</a></td><td></td><td><a href="https://github.com/CZWin32768/XLM-Align">https://github.com/CZWin32768/XLM-Align</a></td><td><a href="https://arxiv.org/pdf/2106.06381">https://arxiv.org/pdf/2106.06381</a></td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15127&#39;]">Improving Zero-Shot Translation by Disentangling Positional Information</a></td><td></td><td><a href="https://github.com/nlp-dke/NMTGMinor/tree/master/recipes/zero-shot">https://github.com/nlp-dke/NMTGMinor/tree/master/recipes/zero-shot</a></td><td><a href="https://arxiv.org/pdf/2012.15127">https://arxiv.org/pdf/2012.15127</a></td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15715&#39;]">Beyond Offline Mapping: Learning Cross-lingual Word Embeddings through Context Anchoring</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15715">https://arxiv.org/pdf/2012.15715</a></td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15421&#39;]">Verb Knowledge Injection for Multilingual Event Processing</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15421">https://arxiv.org/pdf/2012.15421</a></td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06937&#39;]">Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning</a></td><td></td><td><a href="https://github.com/INK-USC/XCSR">https://github.com/INK-USC/XCSR</a></td><td><a href="https://arxiv.org/pdf/2106.06937">https://arxiv.org/pdf/2106.06937</a></td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00148&#39;]">Bilingual Lexicon Induction via Unsupervised Bitext Construction and Word Alignment</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2101.00148">https://arxiv.org/pdf/2101.00148</a></td></tr><tr><td>10</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11867&#39;]">Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation</a></td><td></td><td><a href="https://github.com/bzhangGo/zero">https://github.com/bzhangGo/zero</a></td><td><a href="https://arxiv.org/pdf/2004.11867">https://arxiv.org/pdf/2004.11867</a></td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13169&#39;]">Simultaneous Translation Policies: From Fixed to Adaptive</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.13169">https://arxiv.org/pdf/2004.13169</a></td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14021&#39;]">Multiscale Collaborative Deep Models for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/pemywei/MSC-NMT">https://github.com/pemywei/MSC-NMT</a></td><td><a href="https://arxiv.org/pdf/2004.14021">https://arxiv.org/pdf/2004.14021</a></td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14788&#39;]">Character-Level Translation with Self-attention</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14788">https://arxiv.org/pdf/2004.14788</a></td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00850&#39;]">ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/lifu-tu/ENGINE">https://github.com/lifu-tu/ENGINE</a></td><td><a href="https://arxiv.org/pdf/2005.00850">https://arxiv.org/pdf/2005.00850</a></td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00308&#39;]">Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.00308">https://arxiv.org/pdf/2005.00308</a></td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.06606&#39;]">Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/xlhex/dpe">https://github.com/xlhex/dpe</a></td><td><a href="https://arxiv.org/pdf/2005.06606">https://arxiv.org/pdf/2005.06606</a></td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.02014&#39;]">Norm-Based Curriculum Learning for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/NLP2CT/norm-nmt">https://github.com/NLP2CT/norm-nmt</a></td><td><a href="https://arxiv.org/pdf/2006.02014">https://arxiv.org/pdf/2006.02014</a></td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2007.02671&#39;]">Bilingual Dictionary Based Neural Machine Translation without Using Parallel Sentences</a></td><td></td><td><a href="https://github.com/mttravel/Dictionary-based-MT">https://github.com/mttravel/Dictionary-based-MT</a></td><td><a href="https://arxiv.org/pdf/2007.02671">https://arxiv.org/pdf/2007.02671</a></td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11867&#39;]">Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation</a></td><td></td><td><a href="https://github.com/bzhangGo/zero">https://github.com/bzhangGo/zero</a></td><td><a href="https://arxiv.org/pdf/2004.11867">https://arxiv.org/pdf/2004.11867</a></td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00850&#39;]">ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/lifu-tu/ENGINE">https://github.com/lifu-tu/ENGINE</a></td><td><a href="https://arxiv.org/pdf/2005.00850">https://arxiv.org/pdf/2005.00850</a></td></tr><tr><td>21</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.01313&#39;]">An Effective Approach to Unsupervised Machine Translation</a></td><td></td><td><a href="https://github.com/artetxem/monoses">https://github.com/artetxem/monoses</a></td><td><a href="https://arxiv.org/pdf/1902.01313">https://arxiv.org/pdf/1902.01313</a></td></tr><tr><td>22</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.05979&#39;]">When a Good Translation is Wrong in Context: Context-Aware Machine Translation Improves on Deixis, Ellipsis, and Lexical Cohesion</a></td><td></td><td><a href="https://github.com/lena-voita/good-translation-wrong-in-context">https://github.com/lena-voita/good-translation-wrong-in-context</a></td><td><a href="https://arxiv.org/pdf/1905.05979">https://arxiv.org/pdf/1905.05979</a></td></tr><tr><td>23</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.02780&#39;]">Syntactically Supervised Transformers for Faster Neural Machine Translation</a></td><td></td><td><a href="https://github.com/dojoteef/synst">https://github.com/dojoteef/synst</a></td><td><a href="https://arxiv.org/pdf/1906.02780">https://arxiv.org/pdf/1906.02780</a></td></tr><tr><td>24</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/2106.08680&#39;, &#39;https://arxiv.org/abs/1906.00591&#39;]">Evaluating Gender Bias in Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.08680">https://arxiv.org/pdf/2106.08680</a></td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01787&#39;]">Learning Deep Transformer Models for Machine Translation</a></td><td></td><td><a href="https://github.com/wangqiangneu/dlcl">https://github.com/wangqiangneu/dlcl</a></td><td><a href="https://arxiv.org/pdf/1906.01787">https://arxiv.org/pdf/1906.01787</a></td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00376&#39;]">Domain Adaptation of Neural Machine Translation by Lexicon Induction</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.00376">https://arxiv.org/pdf/1906.00376</a></td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.09444&#39;]">Retrieving Sequential Information for Non-Autoregressive Neural Machine Translation</a></td><td></td><td><a href="https://github.com/ictnlp/RSI-NAT">https://github.com/ictnlp/RSI-NAT</a></td><td><a href="https://arxiv.org/pdf/1906.09444">https://arxiv.org/pdf/1906.09444</a></td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1810.06729&#39;]">Robust Neural Machine Translation with Joint Textual and Phonetic Embedding</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1810.06729">https://arxiv.org/pdf/1810.06729</a></td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.13872&#39;]">Simple and Effective Paraphrastic Similarity from Parallel Translations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.13872">https://arxiv.org/pdf/1909.13872</a></td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.04980&#39;]">Unsupervised Question Answering by Cloze Translation</a></td><td></td><td><a href="https://github.com/facebookresearch/UnsupervisedQA">https://github.com/facebookresearch/UnsupervisedQA</a></td><td><a href="https://arxiv.org/pdf/1906.04980">https://arxiv.org/pdf/1906.04980</a></td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.10761&#39;]">Bilingual Lexicon Induction through Unsupervised Machine Translation</a></td><td></td><td><a href="https://github.com/artetxem/monoses">https://github.com/artetxem/monoses</a></td><td><a href="https://arxiv.org/pdf/1907.10761">https://arxiv.org/pdf/1907.10761</a></td></tr><tr><td>32</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.10523&#39;]">Soft Contextual Data Augmentation for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/teslacool/SCA">https://github.com/teslacool/SCA</a></td><td><a href="https://arxiv.org/pdf/1905.10523">https://arxiv.org/pdf/1905.10523</a></td></tr><tr><td>33</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03785&#39;]">Generalized Data Augmentation for Low-Resource Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.03785">https://arxiv.org/pdf/1906.03785</a></td></tr></tbody></table></div><h3 id="EMNLP"><a href="#EMNLP" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.10485&#39;]">Fully Quantized Transformer for Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1910.10485">https://arxiv.org/pdf/1910.10485</a></td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.10260&#39;]">Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.10260">https://arxiv.org/pdf/2002.10260</a></td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14109&#39;]">Adversarial Subword Regularization for Robust Neural Machine Translation</a></td><td></td><td><a href="https://github.com/dmis-lab/AdvSR">https://github.com/dmis-lab/AdvSR</a></td><td><a href="https://arxiv.org/pdf/2004.14109">https://arxiv.org/pdf/2004.14109</a></td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02353&#39;]">Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages</a></td><td></td><td><a href="https://github.com/masakhane-io/masakhane-mt">https://github.com/masakhane-io/masakhane-mt</a></td><td><a href="https://arxiv.org/pdf/2010.02353">https://arxiv.org/pdf/2010.02353</a></td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.14824&#39;]">On Romanization for Model Transfer Between Scripts in Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.14824">https://arxiv.org/pdf/2009.14824</a></td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13781&#39;]">Graph-to-Tree Neural Networks for Learning Structured Input-Output Translation with Applications to Semantic Parsing and Math Word Problem</a></td><td></td><td><a href="https://github.com/IBM/Graph2Tree">https://github.com/IBM/Graph2Tree</a></td><td><a href="https://arxiv.org/pdf/2004.13781">https://arxiv.org/pdf/2004.13781</a></td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04924&#39;]">On Long-Tailed Phenomena in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/vyraun/long-tailed">https://github.com/vyraun/long-tailed</a></td><td><a href="https://arxiv.org/pdf/2010.04924">https://arxiv.org/pdf/2010.04924</a></td></tr><tr><td>8</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.02955&#39;]">A Multilingual View of Unsupervised Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.02955">https://arxiv.org/pdf/2002.02955</a></td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.00180&#39;]">Explicit Cross-lingual Pre-training for Unsupervised Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.00180">https://arxiv.org/pdf/1909.00180</a></td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.00157&#39;]">Improving Back-Translation with Uncertainty-based Confidence Estimation</a></td><td></td><td><a href="https://github.com/THUNLP-MT/UCE4BT">https://github.com/THUNLP-MT/UCE4BT</a></td><td><a href="https://arxiv.org/pdf/1909.00157">https://arxiv.org/pdf/1909.00157</a></td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1912.07239&#39;]">Iterative Dual Domain Adaptation for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1912.07239">https://arxiv.org/pdf/1912.07239</a></td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01383&#39;]">Context-Aware Monolingual Repair for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/lena-voita/good-translation-wrong-in-context">https://github.com/lena-voita/good-translation-wrong-in-context</a></td><td><a href="https://arxiv.org/pdf/1909.01383">https://arxiv.org/pdf/1909.01383</a></td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.09646&#39;]">Dynamic Past and Future for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/zhengzx-nlp/dynamic-nmt">https://github.com/zhengzx-nlp/dynamic-nmt</a></td><td><a href="https://arxiv.org/pdf/1904.09646">https://arxiv.org/pdf/1904.09646</a></td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01559&#39;]">Simpler and Faster Learning of Adaptive Policies for Simultaneous Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.01559">https://arxiv.org/pdf/1909.01559</a></td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.10430&#39;]">Unsupervised Domain Adaptation for Neural Machine Translation with Domain-Aware Feature Embeddings</a></td><td></td><td><a href="https://github.com/zdou0830/DAFE">https://github.com/zdou0830/DAFE</a></td><td><a href="https://arxiv.org/pdf/1908.10430">https://arxiv.org/pdf/1908.10430</a></td></tr><tr><td>16</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1911.00835&#39;]">Controlling Text Complexity in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/sweta20/ComplexityControlledMT">https://github.com/sweta20/ComplexityControlledMT</a></td><td><a href="https://arxiv.org/pdf/1911.00835">https://arxiv.org/pdf/1911.00835</a></td></tr><tr><td>17</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.05731&#39;]">Simple and Effective Noisy Channel Modeling for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></td><td><a href="https://arxiv.org/pdf/1908.05731">https://arxiv.org/pdf/1908.05731</a></td></tr><tr><td>18</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.06708&#39;]">Hint-Based Training for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/zhuohan123/hint-nart">https://github.com/zhuohan123/hint-nart</a></td><td><a href="https://arxiv.org/pdf/1909.06708">https://arxiv.org/pdf/1909.06708</a></td></tr></tbody></table></div><h3 id="NAACL"><a href="#NAACL" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.04507&#39;]">Self-Training for Unsupervised Neural Machine Translation in Unbalanced Training Data Scenarios</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.04507">https://arxiv.org/pdf/2004.04507</a></td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2009.11201&#39;]">Harnessing Multilinguality in Unsupervised Machine Translation for Rare Languages</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.11201">https://arxiv.org/pdf/2009.11201</a></td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.06799&#39;]">Towards Continual Learning for Multilingual Machine Translation via Vocabulary Substitution</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2103.06799">https://arxiv.org/pdf/2103.06799</a></td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2003.09586&#39;]">Probing Word Translations in the Transformer and Trading Decoder for Encoder Layers</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2003.09586">https://arxiv.org/pdf/2003.09586</a></td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.06490&#39;, &#39;https://arxiv.org/abs/1911.00234&#39;]">Sequence Tagging and Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1911.00234">https://arxiv.org/pdf/1911.00234</a></td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2008.09396&#39;]">Neural Machine Translation without Embeddings</a></td><td></td><td><a href="https://github.com/UriSha/EmbeddinglessNMT">https://github.com/UriSha/EmbeddinglessNMT</a></td><td><a href="https://arxiv.org/pdf/2008.09396">https://arxiv.org/pdf/2008.09396</a></td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.07316&#39;]">From Masked Language Modeling to Translation: Non-English Auxiliary Tasks Improve Zero-shot Spoken Language Understanding</a></td><td></td><td><a href="https://bitbucket.org/robvanderg/xsid">https://bitbucket.org/robvanderg/xsid</a></td><td><a href="https://arxiv.org/pdf/2105.07316">https://arxiv.org/pdf/2105.07316</a></td></tr><tr><td>8</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.10531&#39;]">Improving the Lexical Ability of Pretrained Language Models for Unsupervised Neural Machine Translation</a></td><td></td><td><a href="https://github.com/alexandra-chron/lexical_xlm_relm">https://github.com/alexandra-chron/lexical_xlm_relm</a></td><td><a href="https://arxiv.org/pdf/2103.10531">https://arxiv.org/pdf/2103.10531</a></td></tr><tr><td>9</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12868&#39;]">Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/yongchanghao/multi-task-nat">https://github.com/yongchanghao/multi-task-nat</a></td><td><a href="https://arxiv.org/pdf/2010.12868">https://arxiv.org/pdf/2010.12868</a></td></tr><tr><td>10</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05146&#39;]">Assessing Reference-Free Peer Evaluation for Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.05146">https://arxiv.org/pdf/2104.05146</a></td></tr><tr><td>11</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2009.09654&#39;]">Generative Imagination Elevates Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.09654">https://arxiv.org/pdf/2009.09654</a></td></tr><tr><td>12</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12827&#39;]">Context-aware Decoder for Neural Machine Translation using a Target-side Document-Level Language Model</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12827">https://arxiv.org/pdf/2010.12827</a></td></tr><tr><td>13</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05964&#39;]">Restoring and Mining the Records of the Joseon Dynasty via Neural Language Modeling and Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.05964">https://arxiv.org/pdf/2104.05964</a></td></tr><tr><td>14</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.06683&#39;]">The Curious Case of Hallucinations in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/vyraun/hallucinations">https://github.com/vyraun/hallucinations</a></td><td><a href="https://arxiv.org/pdf/2104.06683">https://arxiv.org/pdf/2104.06683</a></td></tr><tr><td>15</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.08942&#39;]">Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/samuki/reinforce-joey">https://github.com/samuki/reinforce-joey</a></td><td><a href="https://arxiv.org/pdf/2106.08942">https://arxiv.org/pdf/2106.08942</a></td></tr><tr><td>16</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.03137&#39;]">Cross-lingual Supervision Improves Unsupervised Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.03137">https://arxiv.org/pdf/2004.03137</a></td></tr><tr><td>17</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.02461&#39;]">ReWE: Regressing Word Embeddings for Regularization of Neural Machine Translation Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.02461">https://arxiv.org/pdf/1904.02461</a></td></tr><tr><td>18</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09514&#39;]">Lost in Machine Translation: A Method to Reduce Meaning Loss</a></td><td></td><td><a href="https://github.com/reubenharry/pragmatic-translation">https://github.com/reubenharry/pragmatic-translation</a></td><td><a href="https://arxiv.org/pdf/1902.09514">https://arxiv.org/pdf/1902.09514</a></td></tr><tr><td>19</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.02878&#39;]">Syntax-Enhanced Neural Machine Translation with Syntax-Aware Word Representations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1905.02878">https://arxiv.org/pdf/1905.02878</a></td></tr><tr><td>20</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09508&#39;, &#39;https://arxiv.org/abs/1902.01509&#39;]">Improving Robustness of Machine Translation with Synthetic Noise</a></td><td></td><td><a href="https://github.com/MysteryVaibhav/robust_mtnt">https://github.com/MysteryVaibhav/robust_mtnt</a></td><td><a href="https://arxiv.org/pdf/1902.09508">https://arxiv.org/pdf/1902.09508</a></td></tr><tr><td>21</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.04079&#39;]">Differentiable Sampling with Flexible Reference Word Order for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/Izecson/saml-nmt">https://github.com/Izecson/saml-nmt</a></td><td><a href="https://arxiv.org/pdf/1904.04079">https://arxiv.org/pdf/1904.04079</a></td></tr><tr><td>22</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00556&#39;]">Fluent Translations from Disfluent Speech in End-to-End Speech Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.00556">https://arxiv.org/pdf/1906.00556</a></td></tr><tr><td>23</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.08788&#39;]">Selective Attention for Context-aware Neural Machine Translation</a></td><td></td><td><a href="https://github.com/sameenmaruf/selective-attn">https://github.com/sameenmaruf/selective-attn</a></td><td><a href="https://arxiv.org/pdf/1903.08788">https://arxiv.org/pdf/1903.08788</a></td></tr></tbody></table></div><h3 id="COLING"><a href="#COLING" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00890&#39;]">Emergent Communication Pretraining for Few-Shot Machine Translation</a></td><td></td><td><a href="https://github.com/cambridgeltl/ECNMT">https://github.com/cambridgeltl/ECNMT</a></td><td><a href="https://arxiv.org/pdf/2011.00890">https://arxiv.org/pdf/2011.00890</a></td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00678&#39;]">Investigating Catastrophic Forgetting During Continual Training for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00678">https://arxiv.org/pdf/2011.00678</a></td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.01482&#39;]">Layer-wise Multi-view Learning for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.01482">https://arxiv.org/pdf/2011.01482</a></td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.03732&#39;]">Leveraging Discourse Rewards for Document-Level Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.03732">https://arxiv.org/pdf/2010.03732</a></td></tr><tr><td>5</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.02266&#39;]">Optimized Transformer for Low-resource Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.02266">https://arxiv.org/pdf/2011.02266</a></td></tr><tr><td>6</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12549&#39;]">Robust Unsupervised Neural Machine Translation with Adversarial Denoising Training</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.12549">https://arxiv.org/pdf/2002.12549</a></td></tr><tr><td>7</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.11018&#39;]">Token Drop mechanism for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/zhajiahe/Token_Drop">https://github.com/zhajiahe/Token_Drop</a></td><td><a href="https://arxiv.org/pdf/2010.11018">https://arxiv.org/pdf/2010.11018</a></td></tr><tr><td>8</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.03469&#39;]">Understanding Pure Character-Based Neural Machine Translation: The Case of Translating Finnish into English</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.03469">https://arxiv.org/pdf/2011.03469</a></td></tr></tbody></table></div><h2 id="ä¼šè¯-å¯¹è¯ç³»ç»Ÿ"><a href="#ä¼šè¯-å¯¹è¯ç³»ç»Ÿ" class="headerlink" title="ä¼šè¯/å¯¹è¯ç³»ç»Ÿ"></a>ä¼šè¯/å¯¹è¯ç³»ç»Ÿ</h2><h3 id="ACL-1"><a href="#ACL-1" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.12458&#39;]">TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.12458">https://arxiv.org/pdf/2012.12458</a></td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00162&#39;]">HERALD: An Annotation Efficient Method to Detect User Disengagement in Social Conversations</a></td><td></td><td><a href="https://github.com/Weixin-Liang/HERALD">https://github.com/Weixin-Liang/HERALD</a></td><td><a href="https://arxiv.org/pdf/2106.00162">https://arxiv.org/pdf/2106.00162</a></td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.13073&#39;]">Maria: A Visual Experience Powered Conversational Agent</a></td><td></td><td><a href="https://github.com/jokieleung/Maria">https://github.com/jokieleung/Maria</a></td><td><a href="https://arxiv.org/pdf/2105.13073">https://arxiv.org/pdf/2105.13073</a></td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.14756&#39;]">Dialogue Response Selection with Hierarchical Curriculum Learning</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.14756">https://arxiv.org/pdf/2012.14756</a></td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.14556&#39;]">Diversifying Dialog Generation via Adaptive Label Smoothing</a></td><td></td><td><a href="https://github.com/lemon234071/AdaLabel">https://github.com/lemon234071/AdaLabel</a></td><td><a href="https://arxiv.org/pdf/2105.14556">https://arxiv.org/pdf/2105.14556</a></td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06169&#39;]">BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data</a></td><td></td><td><a href="https://github.com/songhaoyu/BoB">https://github.com/songhaoyu/BoB</a></td><td><a href="https://arxiv.org/pdf/2106.06169">https://arxiv.org/pdf/2106.06169</a></td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.13391&#39;]">I like fish, especially dolphins: Addressing Contradictions in Dialogue Modeling</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.13391">https://arxiv.org/pdf/2012.13391</a></td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2011.09553&#39;]">A Sequence-to-Sequence Approach to Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/sweetalyssum/Seq2Seq-DU">https://github.com/sweetalyssum/Seq2Seq-DU</a></td><td><a href="https://arxiv.org/pdf/2011.09553">https://arxiv.org/pdf/2011.09553</a></td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.03410&#39;]">Generating Relevant and Coherent Dialogue Responses using Self-Separated Conditional Variational AutoEncoders</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.03410">https://arxiv.org/pdf/2106.03410</a></td></tr><tr><td>10</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00123&#39;]">Intent Classification and Slot Filling for Privacy Policies</a></td><td></td><td><a href="https://github.com/wasiahmad/PolicyIE">https://github.com/wasiahmad/PolicyIE</a></td><td><a href="https://arxiv.org/pdf/2101.00123">https://arxiv.org/pdf/2101.00123</a></td></tr><tr><td>11</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.12578&#39;]">Dual Slot Selector via Local Reliability Verification for Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/guojinyu88/DSSDST">https://github.com/guojinyu88/DSSDST</a></td><td><a href="https://arxiv.org/pdf/2107.12578">https://arxiv.org/pdf/2107.12578</a></td></tr><tr><td>12</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.15171&#39;]">Learning from Perturbations: Diverse and Informative Dialogue Generation with Inverse Adversarial Training</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.15171">https://arxiv.org/pdf/2105.15171</a></td></tr><tr><td>13</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.11164&#39;]">Modeling Bilingual Conversational Characteristics for Neural Chat Translation</a></td><td></td><td><a href="https://github.com/XL2248/CPCC">https://github.com/XL2248/CPCC</a></td><td><a href="https://arxiv.org/pdf/2107.11164">https://arxiv.org/pdf/2107.11164</a></td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11019&#39;]">Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/LooperXX/DF-Net">https://github.com/LooperXX/DF-Net</a></td><td><a href="https://arxiv.org/pdf/2004.11019">https://arxiv.org/pdf/2004.11019</a></td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11054&#39;]">Learning Dialog Policies from Weak Demonstrations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.11054">https://arxiv.org/pdf/2004.11054</a></td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.08866&#39;]">Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained Conversational Representations</a></td><td></td><td><a href="https://github.com/PolyAI-LDN/task-specific-datasets">https://github.com/PolyAI-LDN/task-specific-datasets</a></td><td><a href="https://arxiv.org/pdf/2005.08866">https://arxiv.org/pdf/2005.08866</a></td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.04346&#39;]">Diversifying Dialogue Generation with Non-Conversational Text</a></td><td></td><td><a href="https://github.com/chin-gyou/Div-Non-Conv">https://github.com/chin-gyou/Div-Non-Conv</a></td><td><a href="https://arxiv.org/pdf/2005.04346">https://arxiv.org/pdf/2005.04346</a></td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.09544&#39;]">Grounding Conversations with Improvised Dialogues</a></td><td></td><td><a href="https://github.com/wise-east/spolin">https://github.com/wise-east/spolin</a></td><td><a href="https://arxiv.org/pdf/2004.09544">https://arxiv.org/pdf/2004.09544</a></td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04908&#39;]">Designing Precise and Robust Dialogue Response Evaluators</a></td><td></td><td><a href="https://github.com/ZHAOTING/dialog-processing">https://github.com/ZHAOTING/dialog-processing</a></td><td><a href="https://arxiv.org/pdf/2004.04908">https://arxiv.org/pdf/2004.04908</a></td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.07931&#39;]">PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research">https://github.com/PaddlePaddle/Research</a></td><td><a href="https://arxiv.org/pdf/1910.07931">https://arxiv.org/pdf/1910.07931</a></td></tr><tr><td>21</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00891&#39;]">Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/stanford-oval/zero-shot-multiwoz-acl2020">https://github.com/stanford-oval/zero-shot-multiwoz-acl2020</a></td><td><a href="https://arxiv.org/pdf/2005.00891">https://arxiv.org/pdf/2005.00891</a></td></tr><tr><td>22</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.03809&#39;]">Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward Decomposition</a></td><td></td><td><a href="https://github.com/truthless11/MADPL">https://github.com/truthless11/MADPL</a></td><td><a href="https://arxiv.org/pdf/2004.03809">https://arxiv.org/pdf/2004.03809</a></td></tr><tr><td>23</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.03954&#39;]">Towards Conversational Recommendation over Multi-Type Dialogs</a></td><td></td><td><a href="https://github.com/PaddlePaddle/models">https://github.com/PaddlePaddle/models</a></td><td><a href="https://arxiv.org/pdf/2005.03954">https://arxiv.org/pdf/2005.03954</a></td></tr><tr><td>24</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04100&#39;]">KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation</a></td><td></td><td><a href="https://github.com/thu-coai/KdConv">https://github.com/thu-coai/KdConv</a></td><td><a href="https://arxiv.org/pdf/2004.04100">https://arxiv.org/pdf/2004.04100</a></td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.08854&#39;]">Incremental Transformer with Deliberation Decoder for Document Grounded Conversations</a></td><td></td><td><a href="https://github.com/lizekang/ITDD">https://github.com/lizekang/ITDD</a></td><td><a href="https://arxiv.org/pdf/1907.08854">https://arxiv.org/pdf/1907.08854</a></td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.05373&#39;]">E3: Entailment-driven Extracting and Editing for Conversational Machine Reading</a></td><td></td><td><a href="https://github.com/vzhong/e3">https://github.com/vzhong/e3</a></td><td><a href="https://arxiv.org/pdf/1906.05373">https://arxiv.org/pdf/1906.05373</a></td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.07004&#39;]">Improving Multi-turn Dialogue Modelling with Utterance ReWriter</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.07004">https://arxiv.org/pdf/1906.07004</a></td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.12866&#39;]">Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</a></td><td></td><td><a href="https://github.com/wenhuchen/HDSA-Dialog">https://github.com/wenhuchen/HDSA-Dialog</a></td><td><a href="https://arxiv.org/pdf/1905.12866">https://arxiv.org/pdf/1905.12866</a></td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.00326&#39;]">Observing Dialogue in Therapy: Categorizing and Forecasting Behavioral Codes</a></td><td></td><td><a href="https://github.com/utahnlp/therapist-observer">https://github.com/utahnlp/therapist-observer</a></td><td><a href="https://arxiv.org/pdf/1907.00326">https://arxiv.org/pdf/1907.00326</a></td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.01166&#39;]">Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems</a></td><td></td><td><a href="https://github.com/henryhungle/MTN">https://github.com/henryhungle/MTN</a></td><td><a href="https://arxiv.org/pdf/1907.01166">https://arxiv.org/pdf/1907.01166</a></td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.06725&#39;]">Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good</a></td><td></td><td><a href="https://gitlab.com/ucdavisnlp/persuasionforgood">https://gitlab.com/ucdavisnlp/persuasionforgood</a></td><td><a href="https://arxiv.org/pdf/1906.06725">https://arxiv.org/pdf/1906.06725</a></td></tr></tbody></table></div><h3 id="EMNLP-1"><a href="#EMNLP-1" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.09378&#39;]">Difference-aware Knowledge Selection for Knowledge-grounded Conversation Generation</a></td><td></td><td><a href="https://github.com/chujiezheng/DiffKS">https://github.com/chujiezheng/DiffKS</a></td><td><a href="https://arxiv.org/pdf/2009.09378">https://arxiv.org/pdf/2009.09378</a></td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12328&#39;]">Few-shot Natural Language Generation for Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/pengbaolin/SC-GPT">https://github.com/pengbaolin/SC-GPT</a></td><td><a href="https://arxiv.org/pdf/2002.12328">https://arxiv.org/pdf/2002.12328</a></td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.13656&#39;]">Learning Knowledge Bases with Parameters for Task-Oriented Dialogue Systems</a></td><td></td><td><a href="https://github.com/HLTCHKUST/ke-dialogue">https://github.com/HLTCHKUST/ke-dialogue</a></td><td><a href="https://arxiv.org/pdf/2009.13656">https://arxiv.org/pdf/2009.13656</a></td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04344&#39;]">Plug-and-Play Conversational Models</a></td><td></td><td><a href="https://github.com/andreamad8/PPCM">https://github.com/andreamad8/PPCM</a></td><td><a href="https://arxiv.org/pdf/2010.04344">https://arxiv.org/pdf/2010.04344</a></td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02795&#39;]">COSMIC: COmmonSense knowledge for eMotion Identification in Conversations</a></td><td></td><td><a href="https://github.com/declare-lab/conv-emotion">https://github.com/declare-lab/conv-emotion</a></td><td><a href="https://arxiv.org/pdf/2010.02795">https://arxiv.org/pdf/2010.02795</a></td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.03755&#39;]">Generalizable and Explainable Dialogue Generation via Explicit Action Learning</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.03755">https://arxiv.org/pdf/2010.03755</a></td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02260&#39;]">Effects of Naturalistic Variation in Goal-Oriented Dialog</a></td><td></td><td><a href="https://github.com/IBM/naturalistic-variation-goal-oriented-dialog-datasets">https://github.com/IBM/naturalistic-variation-goal-oriented-dialog-datasets</a></td><td><a href="https://arxiv.org/pdf/2010.02260">https://arxiv.org/pdf/2010.02260</a></td></tr><tr><td>8</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11540&#39;]">DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation</a></td><td></td><td><a href="https://github.com/SenticNet/conv-emotion">https://github.com/SenticNet/conv-emotion</a></td><td><a href="https://arxiv.org/pdf/1908.11540">https://arxiv.org/pdf/1908.11540</a></td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11546&#39;]">Modeling Multi-Action Policy for Task-Oriented Dialogues</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1908.11546">https://arxiv.org/pdf/1908.11546</a></td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.12868&#39;]">Automatically Learning Data Augmentation Policies for Dialogue Tasks</a></td><td></td><td><a href="https://github.com/WolfNiu/AutoAugDialogue">https://github.com/WolfNiu/AutoAugDialogue</a></td><td><a href="https://arxiv.org/pdf/1909.12868">https://arxiv.org/pdf/1909.12868</a></td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.03317&#39;]">Dependency Parsing for Spoken Dialog Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.03317">https://arxiv.org/pdf/1909.03317</a></td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.05391&#39;]">Towards Knowledge-Based Recommender Dialog System</a></td><td></td><td><a href="https://github.com/THUDM/KBRD">https://github.com/THUDM/KBRD</a></td><td><a href="https://arxiv.org/pdf/1908.05391">https://arxiv.org/pdf/1908.05391</a></td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.00610&#39;]">DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic Knowledge Graphs</a></td><td></td><td><a href="https://github.com/Pascalson/DyKGChat">https://github.com/Pascalson/DyKGChat</a></td><td><a href="https://arxiv.org/pdf/1910.00610">https://arxiv.org/pdf/1910.00610</a></td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01388&#39;]">How to Build User Simulators to Train RL-based Dialog Systems</a></td><td></td><td><a href="https://github.com/wyshi/user-simulator">https://github.com/wyshi/user-simulator</a></td><td><a href="https://arxiv.org/pdf/1909.01388">https://arxiv.org/pdf/1909.01388</a></td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09368&#39;]">Dual Attention Networks for Visual Reference Resolution in Visual Dialog</a></td><td></td><td><a href="https://github.com/gicheonkang/DAN-VisDial">https://github.com/gicheonkang/DAN-VisDial</a></td><td><a href="https://arxiv.org/pdf/1902.09368">https://arxiv.org/pdf/1902.09368</a></td></tr><tr><td>16</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11487&#39;]">Dialog Intent Induction with Deep Multi-View Clustering</a></td><td></td><td><a href="https://github.com/asappresearch/dialog-intent-induction">https://github.com/asappresearch/dialog-intent-induction</a></td><td><a href="https://arxiv.org/pdf/1908.11487">https://arxiv.org/pdf/1908.11487</a></td></tr><tr><td>17</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.05069&#39;]">Multi-Task Learning for Conversational Question Answering over a Large-Scale Knowledge Base</a></td><td></td><td><a href="https://github.com/taoshen58/MaSP">https://github.com/taoshen58/MaSP</a></td><td><a href="https://arxiv.org/pdf/1910.05069">https://arxiv.org/pdf/1910.05069</a></td></tr></tbody></table></div><h3 id="NAACL-1"><a href="#NAACL-1" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.04898&#39;]">Open-Domain Question Answering Goes Conversational via Question Rewriting</a></td><td></td><td><a href="https://github.com/apple/ml-qrecc">https://github.com/apple/ml-qrecc</a></td><td><a href="https://arxiv.org/pdf/2010.04898">https://arxiv.org/pdf/2010.04898</a></td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.00783&#39;]">Action-Based Conversations Dataset: A Corpus for Building More In-Depth Task- Oriented Dialogue Systems</a></td><td></td><td><a href="https://github.com/asappresearch/abcd">https://github.com/asappresearch/abcd</a></td><td><a href="https://arxiv.org/pdf/2104.00783">https://arxiv.org/pdf/2104.00783</a></td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.11230&#39;]">Self-Supervised Contrastive Learning for Efficient User Satisfaction Prediction in Conversational Agents</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.11230">https://arxiv.org/pdf/2010.11230</a></td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.07831&#39;]">Human-like informative conversations: Better acknowledgements using conditional mutual information</a></td><td></td><td><a href="https://github.com/AshwinParanjape/human-like-informative-conversations">https://github.com/AshwinParanjape/human-like-informative-conversations</a></td><td><a href="https://arxiv.org/pdf/2104.07831">https://arxiv.org/pdf/2104.07831</a></td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2102.02191&#39;]">DiSCoL: Toward Engaging Dialogue Systems through Conversational Line Guided Response Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2102.02191">https://arxiv.org/pdf/2102.02191</a></td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12757&#39;]">Adding Chit-Chat to Enhance Task-Oriented Dialogues</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12757">https://arxiv.org/pdf/2010.12757</a></td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.10663&#39;]">Fast and Scalable Dialogue State Tracking with Explicit Modular Decomposition</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.10663">https://arxiv.org/pdf/2004.10663</a></td></tr><tr><td>8</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1810.13327&#39;]">Cross-lingual Transfer Learning for Multilingual Task Oriented Dialog</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1810.13327">https://arxiv.org/pdf/1810.13327</a></td></tr><tr><td>9</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.03371&#39;]">Evaluating Coherence in Dialogue Systems using Entailment</a></td><td></td><td><a href="https://github.com/nouhadziri/DialogEntailment">https://github.com/nouhadziri/DialogEntailment</a></td><td><a href="https://arxiv.org/pdf/1904.03371">https://arxiv.org/pdf/1904.03371</a></td></tr></tbody></table></div><h3 id="COLING-1"><a href="#COLING-1" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2012.04080&#39;]">A Taxonomy of Empathetic Response Intents in Human Social Conversations</a></td><td></td><td><a href="https://github.com/anuradha1992/EmpatheticIntents">https://github.com/anuradha1992/EmpatheticIntents</a></td><td><a href="https://arxiv.org/pdf/2012.04080">https://arxiv.org/pdf/2012.04080</a></td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2105.10606&#39;]">CEREC: A Corpus for Entity Resolution in Email Conversations</a></td><td></td><td><a href="https://github.com/paragdakle/emailcoref">https://github.com/paragdakle/emailcoref</a></td><td><a href="https://arxiv.org/pdf/2105.10606">https://arxiv.org/pdf/2105.10606</a></td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.00671&#39;]">Conversational Machine Comprehension: a Literature Review</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2006.00671">https://arxiv.org/pdf/2006.00671</a></td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00615&#39;]">Improving Conversational Question Answering Systems after Deployment using Feedback-Weighted Learning</a></td><td></td><td><a href="https://github.com/jjacampos/FeedbackWeightedLearning">https://github.com/jjacampos/FeedbackWeightedLearning</a></td><td><a href="https://arxiv.org/pdf/2011.00615">https://arxiv.org/pdf/2011.00615</a></td></tr><tr><td>5</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04125&#39;]">Towards Topic-Guided Conversational Recommender System</a></td><td></td><td><a href="https://github.com/RUCAIBox/TG-ReDial">https://github.com/RUCAIBox/TG-ReDial</a></td><td><a href="https://arxiv.org/pdf/2010.04125">https://arxiv.org/pdf/2010.04125</a></td></tr><tr><td>6</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00483&#39;]">Deconstruct to Reconstruct a Configurable Evaluation Metric for Open-Domain Dialogue Systems</a></td><td></td><td><a href="https://github.com/vitouphy/usl_dialogue_metric">https://github.com/vitouphy/usl_dialogue_metric</a></td><td><a href="https://arxiv.org/pdf/2011.00483">https://arxiv.org/pdf/2011.00483</a></td></tr><tr><td>7</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00564&#39;]">Recent Neural Methods on Slot Filling and Intent Classification for Task-Oriented Dialogue Systems: A Survey</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00564">https://arxiv.org/pdf/2011.00564</a></td></tr></tbody></table></div><h2 id="æ–‡æœ¬ç”Ÿæˆ"><a href="#æ–‡æœ¬ç”Ÿæˆ" class="headerlink" title="æ–‡æœ¬ç”Ÿæˆ"></a>æ–‡æœ¬ç”Ÿæˆ</h2><h3 id="ACL-2"><a href="#ACL-2" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.03432&#39;]">Generalising Multilingual Concept-to-Text NLG with Language Agnostic Delexicalisation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.03432">https://arxiv.org/pdf/2105.03432</a></td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00190&#39;]">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2101.00190">https://arxiv.org/pdf/2101.00190</a></td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00288&#39;]">Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models</a></td><td></td><td><a href="https://github.com/tongshuangwu/polyjuice">https://github.com/tongshuangwu/polyjuice</a></td><td><a href="https://arxiv.org/pdf/2101.00288">https://arxiv.org/pdf/2101.00288</a></td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15786&#39;]">Conditional Generation of Temporally-ordered Event Sequences</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15786">https://arxiv.org/pdf/2012.15786</a></td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06471&#39;]">Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.06471">https://arxiv.org/pdf/2106.06471</a></td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.15053&#39;]">Factorising Meaning and Form for Intent-Preserving Paraphrasing</a></td><td></td><td><a href="https://github.com/tomhosking/separator">https://github.com/tomhosking/separator</a></td><td><a href="https://arxiv.org/pdf/2105.15053">https://arxiv.org/pdf/2105.15053</a></td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00210&#39;]">Improving Formality Style Transfer with Context-Aware Rule Injection</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.00210">https://arxiv.org/pdf/2106.00210</a></td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.01875&#39;]">DeepRapper: Neural Rap Generation with Rhyme and Rhythm Modeling</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2107.01875">https://arxiv.org/pdf/2107.01875</a></td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15329&#39;]">Generating Landmark Navigation Instructions from Maps as a Graph-to-Text Problem</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15329">https://arxiv.org/pdf/2012.15329</a></td></tr><tr><td>10</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.11134&#39;]">One2Set: Generating Diverse Keyphrases as a Set</a></td><td></td><td><a href="https://github.com/jiacheng-ye/kg_one2set">https://github.com/jiacheng-ye/kg_one2set</a></td><td><a href="https://arxiv.org/pdf/2105.11134">https://arxiv.org/pdf/2105.11134</a></td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03829&#39;]">Distilling Knowledge Learned in BERT for Text Generation</a></td><td></td><td><a href="https://github.com/ChenRocks/Distill-BERT-Textgen">https://github.com/ChenRocks/Distill-BERT-Textgen</a></td><td><a href="https://arxiv.org/pdf/1911.03829">https://arxiv.org/pdf/1911.03829</a></td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.08022&#39;]">Rigid Formats Controlled Text Generation</a></td><td></td><td><a href="https://github.com/lipiji/SongNet">https://github.com/lipiji/SongNet</a></td><td><a href="https://arxiv.org/pdf/2004.08022">https://arxiv.org/pdf/2004.08022</a></td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.12704&#39;]">Semantic Graphs for Generating Deep Questions</a></td><td></td><td><a href="https://github.com/WING-NUS/SG-Deep-Question-Generation">https://github.com/WING-NUS/SG-Deep-Question-Generation</a></td><td><a href="https://arxiv.org/pdf/2004.12704">https://arxiv.org/pdf/2004.12704</a></td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14257&#39;]">Politeness Transfer: A Tag and Generate Approach</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14257">https://arxiv.org/pdf/2004.14257</a></td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.09123&#39;]">GPT-too: A language-model-first approach for AMR-to-text generation</a></td><td></td><td><a href="https://github.com/IBM/GPT-too-AMR2text">https://github.com/IBM/GPT-too-AMR2text</a></td><td><a href="https://arxiv.org/pdf/2005.09123">https://arxiv.org/pdf/2005.09123</a></td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.04560&#39;]">Posterior Control of Blackbox Generation</a></td><td></td><td><a href="https://github.com/XiangLi1999/PosteriorControl-NLG">https://github.com/XiangLi1999/PosteriorControl-NLG</a></td><td><a href="https://arxiv.org/pdf/2005.04560">https://arxiv.org/pdf/2005.04560</a></td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.07522&#39;]">Parallel Data Augmentation for Formality Style Transfer</a></td><td></td><td><a href="https://github.com/lancopku/Augmented_Data_for_FST">https://github.com/lancopku/Augmented_Data_for_FST</a></td><td><a href="https://arxiv.org/pdf/2005.07522">https://arxiv.org/pdf/2005.07522</a></td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.01096&#39;]">Neural Data-to-Text Generation via Jointly Learning the Segmentation and Correspondence</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.01096">https://arxiv.org/pdf/2005.01096</a></td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.13461&#39;]">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1910.13461">https://arxiv.org/pdf/1910.13461</a></td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03882&#39;]">Pre-train and Plug-in: Flexible Conditional Text Generation with Variational Auto- Encoders</a></td><td></td><td><a href="https://github.com/WHUIR/PPVAE">https://github.com/WHUIR/PPVAE</a></td><td><a href="https://arxiv.org/pdf/1911.03882">https://arxiv.org/pdf/1911.03882</a></td></tr><tr><td>21</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1909.10158&#39;]">Two Birds, One Stone: A Simple, Unified Model for Text Generation from Structured and Unstructured Data</a></td><td></td><td><a href="https://github.com/h-shahidi/2birds-gen">https://github.com/h-shahidi/2birds-gen</a></td><td><a href="https://arxiv.org/pdf/1909.10158">https://arxiv.org/pdf/1909.10158</a></td></tr><tr><td>22</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.02247&#39;]">Unsupervised Opinion Summarization as Copycat-Review Generation</a></td><td></td><td><a href="https://github.com/ixlan/CopyCat-abstractive-opinion-summarizer">https://github.com/ixlan/CopyCat-abstractive-opinion-summarizer</a></td><td><a href="https://arxiv.org/pdf/1911.02247">https://arxiv.org/pdf/1911.02247</a></td></tr><tr><td>23</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.08101&#39;]">Evidence-Aware Inferential Text Generation with Vector Quantised Variational AutoEncoder</a></td><td></td><td><a href="https://github.com/microsoft/EA-VQ-VAE">https://github.com/microsoft/EA-VQ-VAE</a></td><td><a href="https://arxiv.org/pdf/2006.08101">https://arxiv.org/pdf/2006.08101</a></td></tr><tr><td>24</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04696&#39;]">BLEURT: Learning Robust Metrics for Text Generation</a></td><td></td><td><a href="https://github.com/google-research/bleurt">https://github.com/google-research/bleurt</a></td><td><a href="https://arxiv.org/pdf/2004.04696">https://arxiv.org/pdf/2004.04696</a></td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01834&#39;]">Automatic Generation of High Quality CCGbanks for Parser Domain Adaptation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.01834">https://arxiv.org/pdf/1906.01834</a></td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.07870&#39;]">PaperRobot: Incremental Draft Generation of Scientific Ideas</a></td><td></td><td><a href="https://github.com/EagleW/PaperRobot">https://github.com/EagleW/PaperRobot</a></td><td><a href="https://arxiv.org/pdf/1905.07870">https://arxiv.org/pdf/1905.07870</a></td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03221&#39;]">Data-to-text Generation with Entity Modeling</a></td><td></td><td><a href="https://github.com/ratishsp/data2text-entity-py">https://github.com/ratishsp/data2text-entity-py</a></td><td><a href="https://arxiv.org/pdf/1906.03221">https://arxiv.org/pdf/1906.03221</a></td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.03067&#39;]">Key Fact as Pivot: A Two-Stage Model for Low Resource Table-to-Text Generation</a></td><td></td><td><a href="https://github.com/lancopku/Pivot">https://github.com/lancopku/Pivot</a></td><td><a href="https://arxiv.org/pdf/1908.03067">https://arxiv.org/pdf/1908.03067</a></td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.12667&#39;]">Reinforced Dynamic Reasoning for Conversational Question Generation</a></td><td></td><td><a href="https://github.com/ZJULearning/ReDR">https://github.com/ZJULearning/ReDR</a></td><td><a href="https://arxiv.org/pdf/1907.12667">https://arxiv.org/pdf/1907.12667</a></td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.04106&#39;]">Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</a></td><td></td><td><a href="https://github.com/kenchan0226/keyphrase-generation-rl">https://github.com/kenchan0226/keyphrase-generation-rl</a></td><td><a href="https://arxiv.org/pdf/1906.04106">https://arxiv.org/pdf/1906.04106</a></td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03889&#39;]">Topic-Aware Neural Keyphrase Generation for Social Media Language</a></td><td></td><td><a href="https://github.com/yuewang-cuhk/TAKG">https://github.com/yuewang-cuhk/TAKG</a></td><td><a href="https://arxiv.org/pdf/1906.03889">https://arxiv.org/pdf/1906.03889</a></td></tr><tr><td>32</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03717&#39;]">Argument Generation with Retrieval, Planning, and Realization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.03717">https://arxiv.org/pdf/1906.03717</a></td></tr><tr><td>33</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.12866&#39;]">Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</a></td><td></td><td><a href="https://github.com/wenhuchen/HDSA-Dialog">https://github.com/wenhuchen/HDSA-Dialog</a></td><td><a href="https://arxiv.org/pdf/1905.12866">https://arxiv.org/pdf/1905.12866</a></td></tr><tr><td>34</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01231&#39;]">Coherent Comments Generation for Chinese Articles with a Graph-to-Sequence Model</a></td><td></td><td><a href="https://github.com/lancopku/Graph-to-seq-comment-generation">https://github.com/lancopku/Graph-to-seq-comment-generation</a></td><td><a href="https://arxiv.org/pdf/1906.01231">https://arxiv.org/pdf/1906.01231</a></td></tr><tr><td>35</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.02525&#39;]">Cross-Lingual Training for Automatic Question Generation</a></td><td></td><td><a href="https://github.com/vishwajeet93/clqg">https://github.com/vishwajeet93/clqg</a></td><td><a href="https://arxiv.org/pdf/1906.02525">https://arxiv.org/pdf/1906.02525</a></td></tr><tr><td>36</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.00756&#39;]">Graph Neural Networks with Generated Parameters for Relation Extraction</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.00756">https://arxiv.org/pdf/1902.00756</a></td></tr><tr><td>37</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.09699&#39;]">Learning to Select, Track, and Generate for Data-to-Text</a></td><td></td><td><a href="https://github.com/aistairc/rotowire-modified">https://github.com/aistairc/rotowire-modified</a></td><td><a href="https://arxiv.org/pdf/1907.09699">https://arxiv.org/pdf/1907.09699</a></td></tr><tr><td>38</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.08540&#39;]">Predicting Human Activities from User-Generated Content</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1907.08540">https://arxiv.org/pdf/1907.08540</a></td></tr></tbody></table></div><h3 id="EMNLP-2"><a href="#EMNLP-2" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12328&#39;]">Few-shot Natural Language Generation for Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/pengbaolin/SC-GPT">https://github.com/pengbaolin/SC-GPT</a></td><td><a href="https://arxiv.org/pdf/2002.12328">https://arxiv.org/pdf/2002.12328</a></td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03587&#39;]">How Decoding Strategies Affect the Verifiability of Generated Text</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1911.03587">https://arxiv.org/pdf/1911.03587</a></td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14983&#39;]">Control, Generate, Augment: A Scalable Framework for Multi-Attribute Text Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14983">https://arxiv.org/pdf/2004.14983</a></td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.07576&#39;]">Pretrained Language Models for Dialogue Generation with Multiple Input Sources</a></td><td></td><td><a href="https://github.com/caoyu-noob/Multi-GPT2">https://github.com/caoyu-noob/Multi-GPT2</a></td><td><a href="https://arxiv.org/pdf/2010.07576">https://arxiv.org/pdf/2010.07576</a></td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14579&#39;]">Logic2Text: High-Fidelity Natural Language Generation from Logical Forms</a></td><td></td><td><a href="https://github.com/czyssrs/Logic2Text">https://github.com/czyssrs/Logic2Text</a></td><td><a href="https://arxiv.org/pdf/2004.14579">https://arxiv.org/pdf/2004.14579</a></td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.10056&#39;]">Composed Variational Natural Language Generation for Few-shot Intents</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.10056">https://arxiv.org/pdf/2009.10056</a></td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.00910&#39;]">Continual Learning for Natural Language Generation in Task-oriented Dialog Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.00910">https://arxiv.org/pdf/2010.00910</a></td></tr><tr><td>8</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04246&#39;]">Dual Inference for Improving Language Understanding and Generation</a></td><td></td><td><a href="https://github.com/MiuLab/DuaLUG">https://github.com/MiuLab/DuaLUG</a></td><td><a href="https://arxiv.org/pdf/2010.04246">https://arxiv.org/pdf/2010.04246</a></td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.09022&#39;]">Neural data-to-text generation: A comparison between pipeline and end- to-end architectures</a></td><td></td><td><a href="https://github.com/ThiagoCF05/webnlg">https://github.com/ThiagoCF05/webnlg</a></td><td><a href="https://arxiv.org/pdf/1908.09022">https://arxiv.org/pdf/1908.09022</a></td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.02622&#39;]">MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.02622">https://arxiv.org/pdf/1909.02622</a></td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.04453&#39;]">Select and Attend: Towards Controllable Content Selection in Text Generation</a></td><td></td><td><a href="https://github.com/chin-gyou/controllable-selection">https://github.com/chin-gyou/controllable-selection</a></td><td><a href="https://arxiv.org/pdf/1909.04453">https://arxiv.org/pdf/1909.04453</a></td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.10245&#39;]">Knowledge Aware Conversation Generation with Explainable Reasoning over Augmented Graphs</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research/tree/master/NLP/EMNLP2019-AKGCM">https://github.com/PaddlePaddle/Research/tree/master/NLP/EMNLP2019-AKGCM</a></td><td><a href="https://arxiv.org/pdf/1903.10245">https://arxiv.org/pdf/1903.10245</a></td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11658&#39;]">Autoregressive Text Generation Beyond Feedback Loops</a></td><td></td><td><a href="https://github.com/schmiflo/crf-generation">https://github.com/schmiflo/crf-generation</a></td><td><a href="https://arxiv.org/pdf/1908.11658">https://arxiv.org/pdf/1908.11658</a></td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.07195&#39;]">ARAML: A Stable Adversarial Training Framework for Text Generation</a></td><td></td><td><a href="https://github.com/kepei1106/ARAML">https://github.com/kepei1106/ARAML</a></td><td><a href="https://arxiv.org/pdf/1908.07195">https://arxiv.org/pdf/1908.07195</a></td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1901.00398&#39;]">Judge the Judges: A Large-Scale Evaluation Study of Neural Language Models for Online Review Generation</a></td><td></td><td><a href="https://github.com/Crista23/JudgeTheJudges">https://github.com/Crista23/JudgeTheJudges</a></td><td><a href="https://arxiv.org/pdf/1901.00398">https://arxiv.org/pdf/1901.00398</a></td></tr></tbody></table></div><h3 id="NAACL-2"><a href="#NAACL-2" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2005.00054&#39;]">APo-VAE: Text Generation in Hyperbolic Space</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.00054">https://arxiv.org/pdf/2005.00054</a></td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05218&#39;]">FUDGE: Controlled Text Generation With Future Discriminators</a></td><td></td><td><a href="https://github.com/yangkevin2/naacl-2021-fudge-controlled-generation">https://github.com/yangkevin2/naacl-2021-fudge-controlled-generation</a></td><td><a href="https://arxiv.org/pdf/2104.05218">https://arxiv.org/pdf/2104.05218</a></td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12884&#39;]">NeuroLogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12884">https://arxiv.org/pdf/2010.12884</a></td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05801&#39;]">Plot-guided Adversarial Example Construction for Evaluating Open-domain Story Generation</a></td><td></td><td><a href="https://github.com/PlusLabNLP/Plot-guided-Coherence-Evaluation">https://github.com/PlusLabNLP/Plot-guided-Coherence-Evaluation</a></td><td><a href="https://arxiv.org/pdf/2104.05801">https://arxiv.org/pdf/2104.05801</a></td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2006.15720&#39;]">Progressive Generation of Long Text with Pretrained Language Models</a></td><td></td><td><a href="https://github.com/tanyuqian/progressive-generation">https://github.com/tanyuqian/progressive-generation</a></td><td><a href="https://arxiv.org/pdf/2006.15720">https://arxiv.org/pdf/2006.15720</a></td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.02484&#39;]">OodGAN: Generative Adversarial Network for Out-of-Domain Data Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.02484">https://arxiv.org/pdf/2104.02484</a></td></tr><tr><td>7</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.11205&#39;]">Jointly Optimizing Diversity and Relevance in Neural Response Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.11205">https://arxiv.org/pdf/1902.11205</a></td></tr><tr><td>8</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.11564&#39;]">Neural Text Generation from Rich Semantic Representations</a></td><td></td><td><a href="https://github.com/shlurbee/dmrs-text-generation-naacl2019">https://github.com/shlurbee/dmrs-text-generation-naacl2019</a></td><td><a href="https://arxiv.org/pdf/1904.11564">https://arxiv.org/pdf/1904.11564</a></td></tr><tr><td>9</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.02342&#39;]">Text Generation from Knowledge Graphs with Graph Transformers</a></td><td></td><td><a href="https://github.com/rikdz/GraphWriter">https://github.com/rikdz/GraphWriter</a></td><td><a href="https://arxiv.org/pdf/1904.02342">https://arxiv.org/pdf/1904.02342</a></td></tr><tr><td>10</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.04428&#39;]">Text Generation with Exemplar-based Adaptive Decoding</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.04428">https://arxiv.org/pdf/1904.04428</a></td></tr><tr><td>11</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1809.01694&#39;]">Accelerated Reinforcement Learning for Sentence Generation by Vocabulary Prediction</a></td><td></td><td><a href="https://github.com/hassyGo/NLG-RL">https://github.com/hassyGo/NLG-RL</a></td><td><a href="https://arxiv.org/pdf/1809.01694">https://arxiv.org/pdf/1809.01694</a></td></tr><tr><td>12</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.09722&#39;]">Pre-trained language model representations for language generation</a></td><td></td><td><a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></td><td><a href="https://arxiv.org/pdf/1903.09722">https://arxiv.org/pdf/1903.09722</a></td></tr><tr><td>13</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.01301&#39;]">Pragmatically Informative Text Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.01301">https://arxiv.org/pdf/1904.01301</a></td></tr><tr><td>14</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1806.08462&#39;]">Stochastic Wasserstein Autoencoder for Probabilistic Sentence Generation</a></td><td></td><td><a href="https://github.com/HareeshBahuleyan/probabilistic_nlg">https://github.com/HareeshBahuleyan/probabilistic_nlg</a></td><td><a href="https://arxiv.org/pdf/1806.08462">https://arxiv.org/pdf/1806.08462</a></td></tr></tbody></table></div><h3 id="COLING-2"><a href="#COLING-2" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.04000&#39;, &#39;https://arxiv.org/abs/1911.03587&#39;, &#39;https://arxiv.org/abs/1704.06851&#39;]">Affective Text Generation</a></td><td></td><td><a href="https://github.com/ishikasingh/Affective-text-gen">https://github.com/ishikasingh/Affective-text-gen</a></td><td><a href="https://arxiv.org/pdf/2011.04000">https://arxiv.org/pdf/2011.04000</a></td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.13588&#39;]">Curious Case of Language Generation Evaluation Metrics: A Cautionary Tale</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.13588">https://arxiv.org/pdf/2010.13588</a></td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2012.04332&#39;]">Facts2Story: Controlling Text Generation by Key Facts</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.04332">https://arxiv.org/pdf/2012.04332</a></td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00592&#39;]">Vec2Sent: Probing Sentence Embeddings with Natural Language Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00592">https://arxiv.org/pdf/2011.00592</a></td></tr></tbody></table></div><h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><h3 id="ACL-3"><a href="#ACL-3" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.13648&#39;]">Cross-Lingual Abstractive Summarization with Limited Parallel Resources</a></td><td></td><td><a href="https://github.com/WoodenWhite/MCLAS">https://github.com/WoodenWhite/MCLAS</a></td><td><a href="https://arxiv.org/pdf/2105.13648">https://arxiv.org/pdf/2105.13648</a></td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.04623&#39;]">Improving Factual Consistency of Abstractive Summarization via Question Answering</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.04623">https://arxiv.org/pdf/2105.04623</a></td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.03801&#39;]">Long-Span Summarization via Local Attention and Content Selection</a></td><td></td><td><a href="https://github.com/potsawee/longsum0">https://github.com/potsawee/longsum0</a></td><td><a href="https://arxiv.org/pdf/2105.03801">https://arxiv.org/pdf/2105.03801</a></td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.15135&#39;]">TWAG: A Topic-Guided Wikipedia Abstract Generator</a></td><td></td><td><a href="https://github.com/THU-KEG/TWAG">https://github.com/THU-KEG/TWAG</a></td><td><a href="https://arxiv.org/pdf/2106.15135">https://arxiv.org/pdf/2106.15135</a></td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.12544&#39;]">Language Model as an Annotator: Exploring DialoGPT for Dialogue Summarization</a></td><td></td><td><a href="https://github.com/xcfcode/PLM_annotator">https://github.com/xcfcode/PLM_annotator</a></td><td><a href="https://arxiv.org/pdf/2105.12544">https://arxiv.org/pdf/2105.12544</a></td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.12041&#39;]">BASS: Boosting Abstractive Summarization with Unified Semantic Graph</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.12041">https://arxiv.org/pdf/2105.12041</a></td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.11921&#39;]">Focus Attention: Promoting Faithfulness and Diversity in Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.11921">https://arxiv.org/pdf/2105.11921</a></td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.14774&#39;]">Generating Query Focused Summaries from Query-Free Resources</a></td><td></td><td><a href="https://github.com/yumoxu/marge">https://github.com/yumoxu/marge</a></td><td><a href="https://arxiv.org/pdf/2012.14774">https://arxiv.org/pdf/2012.14774</a></td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00829&#39;]">ConvoSumm: Conversation Summarization Benchmark and Improved Abstractive Summarization with Argument Mining</a></td><td></td><td><a href="https://github.com/Yale-LILY/ConvoSumm">https://github.com/Yale-LILY/ConvoSumm</a></td><td><a href="https://arxiv.org/pdf/2106.00829">https://arxiv.org/pdf/2106.00829</a></td></tr><tr><td>10</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00661&#39;]">On Faithfulness and Factuality in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/google-research-datasets/xsum_hallucination_annotations">https://github.com/google-research-datasets/xsum_hallucination_annotations</a></td><td><a href="https://arxiv.org/pdf/2005.00661">https://arxiv.org/pdf/2005.00661</a></td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.03754&#39;]">FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/esdurmus/summary-faithfulness">https://github.com/esdurmus/summary-faithfulness</a></td><td><a href="https://arxiv.org/pdf/2005.03754">https://arxiv.org/pdf/2005.03754</a></td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00661&#39;]">On Faithfulness and Factuality in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/google-research-datasets/xsum_hallucination_annotations">https://github.com/google-research-datasets/xsum_hallucination_annotations</a></td><td><a href="https://arxiv.org/pdf/2005.00661">https://arxiv.org/pdf/2005.00661</a></td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.01159&#39;]">Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward</a></td><td></td><td><a href="https://github.com/luyang-huang96/GraphAugmentedSum">https://github.com/luyang-huang96/GraphAugmentedSum</a></td><td><a href="https://arxiv.org/pdf/2005.01159">https://arxiv.org/pdf/2005.01159</a></td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2105.05361&#39;]">The Summary Loop: Learning to Write Abstractive Summaries Without Examples</a></td><td></td><td><a href="https://github.com/cannylab/summary_loop">https://github.com/cannylab/summary_loop</a></td><td><a href="https://arxiv.org/pdf/2105.05361">https://arxiv.org/pdf/2105.05361</a></td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.10043&#39;]">Leveraging Graph to Improve Abstractive Multi-Document Summarization</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research">https://github.com/PaddlePaddle/Research</a></td><td><a href="https://arxiv.org/pdf/2005.10043">https://arxiv.org/pdf/2005.10043</a></td></tr><tr><td>16</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00077&#39;]">Scoring Sentence Singletons and Pairs for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/ucfnlp/summarization-sing-pair-mix">https://github.com/ucfnlp/summarization-sing-pair-mix</a></td><td><a href="https://arxiv.org/pdf/1906.00077">https://arxiv.org/pdf/1906.00077</a></td></tr></tbody></table></div><h3 id="EMNLP-3"><a href="#EMNLP-3" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.02016&#39;]">A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining</a></td><td></td><td><a href="https://github.com/microsoft/HMNet">https://github.com/microsoft/HMNet</a></td><td><a href="https://arxiv.org/pdf/2004.02016">https://arxiv.org/pdf/2004.02016</a></td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13983&#39;]">Conditional Neural Generation using Sub-Aspect Functions for Extractive News Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.13983">https://arxiv.org/pdf/2004.13983</a></td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.08242&#39;]">Unsupervised Extractive Summarization by Pre-training Hierarchical Transformers</a></td><td></td><td><a href="https://github.com/xssstory/STAS">https://github.com/xssstory/STAS</a></td><td><a href="https://arxiv.org/pdf/2010.08242">https://arxiv.org/pdf/2010.08242</a></td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.01786&#39;]">Corpora Evaluation and System Bias detection in Multi Document Summarization</a></td><td></td><td><a href="https://github.com/LCS2-IIITD/summarization_bias">https://github.com/LCS2-IIITD/summarization_bias</a></td><td><a href="https://arxiv.org/pdf/2010.01786">https://arxiv.org/pdf/2010.01786</a></td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.05139&#39;]">An Empirical Study of Cross-Dataset Evaluation for Neural Summarization Systems</a></td><td></td><td><a href="https://github.com/zide05/CDEvalSumm">https://github.com/zide05/CDEvalSumm</a></td><td><a href="https://arxiv.org/pdf/2010.05139">https://arxiv.org/pdf/2010.05139</a></td></tr><tr><td>6</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.13114&#39;]">Contrastive Attention Mechanism for Abstractive Sentence Summarization</a></td><td></td><td><a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td><a href="https://arxiv.org/pdf/1910.13114">https://arxiv.org/pdf/1910.13114</a></td></tr><tr><td>7</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.08486&#39;]">Concept Pointer Network for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/wprojectsn/codes">https://github.com/wprojectsn/codes</a></td><td><a href="https://arxiv.org/pdf/1910.08486">https://arxiv.org/pdf/1910.08486</a></td></tr><tr><td>8</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.13114&#39;]">Contrastive Attention Mechanism for Abstractive Sentence Summarization</a></td><td></td><td><a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td><a href="https://arxiv.org/pdf/1910.13114">https://arxiv.org/pdf/1910.13114</a></td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.00863&#39;]">Neural Extractive Text Summarization with Syntactic Compression</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.00863">https://arxiv.org/pdf/1902.00863</a></td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.08345&#39;]">Text Summarization with Pretrained Encoders</a></td><td></td><td><a href="https://github.com/nlpyang/PreSumm">https://github.com/nlpyang/PreSumm</a></td><td><a href="https://arxiv.org/pdf/1908.08345">https://arxiv.org/pdf/1908.08345</a></td></tr></tbody></table></div><h3 id="NAACL-3"><a href="#NAACL-3" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.08014&#39;]">GSum: A General Framework for Guided Neural Abstractive Summarization</a></td><td></td><td><a href="https://github.com/neulab/guided_summarization">https://github.com/neulab/guided_summarization</a></td><td><a href="https://arxiv.org/pdf/2010.08014">https://arxiv.org/pdf/2010.08014</a></td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12836&#39;]">Improving Zero and Few-Shot Abstractive Summarization with Intermediate Fine- tuning and Data Augmentation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12836">https://arxiv.org/pdf/2010.12836</a></td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.08400&#39;]">Structure-Aware Abstractive Conversation Summarization via Discourse and Action Graphs</a></td><td></td><td><a href="https://github.com/GT-SALT/Structure-Aware-BART">https://github.com/GT-SALT/Structure-Aware-BART</a></td><td><a href="https://arxiv.org/pdf/2104.08400">https://arxiv.org/pdf/2104.08400</a></td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.11332&#39;]">AdaptSum: Towards Low-Resource Domain Adaptation for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/TysonYu/AdaptSum">https://github.com/TysonYu/AdaptSum</a></td><td><a href="https://arxiv.org/pdf/2103.11332">https://arxiv.org/pdf/2103.11332</a></td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.01726&#39;]">A New Approach to Overgenerating and Scoring Abstractive Summaries</a></td><td></td><td><a href="https://github.com/ucfnlp/varying-length-summ">https://github.com/ucfnlp/varying-length-summ</a></td><td><a href="https://arxiv.org/pdf/2104.01726">https://arxiv.org/pdf/2104.01726</a></td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.09061&#39;]">Improving Faithfulness in Abstractive Summarization with Contrast Candidate Generation and Selection</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.09061">https://arxiv.org/pdf/2104.09061</a></td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.01317&#39;]">Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/jiangycTarheel/TPT-Summ">https://github.com/jiangycTarheel/TPT-Summ</a></td><td><a href="https://arxiv.org/pdf/2106.01317">https://arxiv.org/pdf/2106.01317</a></td></tr><tr><td>8</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.02205&#39;]">Attention Head Masking for Inference Time Content Selection in Abstractive Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.02205">https://arxiv.org/pdf/2104.02205</a></td></tr><tr><td>9</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.13346&#39;]">Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics</a></td><td></td><td><a href="https://github.com/artidoro/frank">https://github.com/artidoro/frank</a></td><td><a href="https://arxiv.org/pdf/2104.13346">https://arxiv.org/pdf/2104.13346</a></td></tr></tbody></table></div><h3 id="COLING-3"><a href="#COLING-3" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00692&#39;]">How Domain Terminology Affects Meeting Summarization Performance</a></td><td></td><td><a href="https://github.com/ucfnlp/meeting-domain-terminology">https://github.com/ucfnlp/meeting-domain-terminology</a></td><td><a href="https://arxiv.org/pdf/2011.00692">https://arxiv.org/pdf/2011.00692</a></td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.09739&#39;]">Fact-level Extractive Summarization with Hierarchical Graph Mask on BERT</a></td><td></td><td><a href="https://github.com/Ruifeng-paper/FactExsum-coling2020">https://github.com/Ruifeng-paper/FactExsum-coling2020</a></td><td><a href="https://arxiv.org/pdf/2011.09739">https://arxiv.org/pdf/2011.09739</a></td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.01421&#39;]">WSL-DS: Weakly Supervised Learning with Distant Supervision for Query Focused Multi-Document Abstractive Summarization</a></td><td></td><td><a href="https://github.com/tahmedge/WSL-DS-COLING-2020">https://github.com/tahmedge/WSL-DS-COLING-2020</a></td><td><a href="https://arxiv.org/pdf/2011.01421">https://arxiv.org/pdf/2011.01421</a></td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> arxiv </tag>
            
            <tag> ACL </tag>
            
            <tag> NAACL </tag>
            
            <tag> EMNLP </tag>
            
            <tag> COLING </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å®Œæ•´ç‰ˆ-ç¿»è¯‘ã€æ‘˜è¦ã€ä¼šè¯ã€æ–‡æœ¬ç”Ÿæˆä»»åŠ¡é¡¶ä¼šè®ºæ–‡</title>
      <link href="/2021/08/13/%E5%AE%8C%E6%95%B4%E7%89%88-%E7%BF%BB%E8%AF%91%E3%80%81%E6%91%98%E8%A6%81%E3%80%81%E4%BC%9A%E8%AF%9D%E3%80%81%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/"/>
      <url>/2021/08/13/%E5%AE%8C%E6%95%B4%E7%89%88-%E7%BF%BB%E8%AF%91%E3%80%81%E6%91%98%E8%A6%81%E3%80%81%E4%BC%9A%E8%AF%9D%E3%80%81%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h1 id="å®Œæ•´ç‰ˆ-ç¿»è¯‘ã€æ‘˜è¦ã€ä¼šè¯ã€æ–‡æœ¬ç”Ÿæˆä»»åŠ¡é¡¶ä¼šè®ºæ–‡"><a href="#å®Œæ•´ç‰ˆ-ç¿»è¯‘ã€æ‘˜è¦ã€ä¼šè¯ã€æ–‡æœ¬ç”Ÿæˆä»»åŠ¡é¡¶ä¼šè®ºæ–‡" class="headerlink" title="å®Œæ•´ç‰ˆ-ç¿»è¯‘ã€æ‘˜è¦ã€ä¼šè¯ã€æ–‡æœ¬ç”Ÿæˆä»»åŠ¡é¡¶ä¼šè®ºæ–‡"></a>å®Œæ•´ç‰ˆ-ç¿»è¯‘ã€æ‘˜è¦ã€ä¼šè¯ã€æ–‡æœ¬ç”Ÿæˆä»»åŠ¡é¡¶ä¼šè®ºæ–‡</h1><h2 id="æœºå™¨ç¿»è¯‘"><a href="#æœºå™¨ç¿»è¯‘" class="headerlink" title="æœºå™¨ç¿»è¯‘"></a>æœºå™¨ç¿»è¯‘</h2><h3 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1811.00357&#39;]">Latent Variable Model for Multi-modal Translation</a></td><td></td><td><a href="https://github.com/iacercalixto/variational_mmt">https://github.com/iacercalixto/variational_mmt</a></td><td><a href="https://arxiv.org/pdf/1811.00357">https://arxiv.org/pdf/1811.00357</a></td><td>In this work, we propose to model the interaction between visual and textual features for multi-modal neural machine translation (MMT) through a latent variable model. This latent variable can be seen as a multi-modal stochastic embedding of an image and its description in a foreign language. It is used in a target-language decoder and also to predict image features. Importantly, our model formulation utilises visual and textual inputs during training but does not require that images be available at test time. We show that our latent variable MMT formulation improves considerably over strong baselines, including a multi-task learning approach (Elliott and KÃ¡dÃ¡r, 2017) and a conditional variational auto-encoder approach (Toyama et al., 2016). Finally, we show improvements due to (i) predicting image features in addition to only conditioning on them, (ii) imposing a constraint on the minimum amount of information encoded in the latent variable, and (iii) by training on additional target-language image descriptions (i.e. synthetic data).</td><td>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å»ºè®®é€šè¿‡æ½œåœ¨å˜é‡æ¨¡å‹ä¸ºå¤šæ¨¡æ€ç¥ç»æœºå™¨ç¿»è¯‘ (MMT) çš„è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾ä¹‹é—´çš„äº¤äº’å»ºæ¨¡ã€‚è¿™ä¸ªæ½œåœ¨å˜é‡å¯ä»¥çœ‹ä½œæ˜¯å›¾åƒçš„å¤šæ¨¡æ€éšæœºåµŒå…¥åŠå…¶åœ¨å¤–è¯­ä¸­çš„æè¿°ã€‚å®ƒç”¨äºç›®æ ‡è¯­è¨€è§£ç å™¨ï¼Œä¹Ÿç”¨äºé¢„æµ‹å›¾åƒç‰¹å¾ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å…¬å¼åœ¨è®­ç»ƒæœŸé—´åˆ©ç”¨è§†è§‰å’Œæ–‡æœ¬è¾“å…¥ï¼Œä½†ä¸éœ€è¦åœ¨æµ‹è¯•æ—¶æä¾›å›¾åƒã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ½œåœ¨å˜é‡ MMT å…¬å¼åœ¨å¼ºåŸºçº¿ä¸Šæœ‰ç›¸å½“å¤§çš„æ”¹è¿›ï¼ŒåŒ…æ‹¬å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•ï¼ˆElliott å’Œ KÃ¡dÃ¡rï¼Œ2017 å¹´ï¼‰å’Œæ¡ä»¶å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨æ–¹æ³•ï¼ˆToyama ç­‰äººï¼Œ2016 å¹´ï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†ç”±äºï¼ˆiï¼‰é¢„æµ‹å›¾åƒç‰¹å¾ä»¥åŠä»…å¯¹å®ƒä»¬è¿›è¡Œè°ƒèŠ‚ï¼Œï¼ˆiiï¼‰å¯¹æ½œåœ¨å˜é‡ä¸­ç¼–ç çš„æœ€å°ä¿¡æ¯é‡æ–½åŠ çº¦æŸï¼Œä»¥åŠï¼ˆiiiï¼‰é€šè¿‡é¢å¤–ç›®æ ‡è¯­è¨€è®­ç»ƒçš„æ”¹è¿›å›¾åƒæè¿°ï¼ˆå³åˆæˆæ•°æ®ï¼‰ã€‚</td><td>Iacer Calixto   Miguel Rios   Wilker Aziz</td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.05414&#39;]">Rewriter-Evaluator Architecture for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.05414">https://arxiv.org/pdf/2012.05414</a></td><td>Encoder-decoder has been widely used in neural machine translation (NMT). A few methods have been proposed to improve it with multiple passes of decoding. However, their full potential is limited by a lack of appropriate termination policies. To address this issue, we present a novel architecture, Rewriter-Evaluator. It consists of a rewriter and an evaluator. Translating a source sentence involves multiple passes. At every pass, the rewriter produces a new translation to improve the past translation and the evaluator estimates the translation quality to decide whether to terminate the rewriting process. We also propose prioritized gradient descent (PGD) that facilitates training the rewriter and the evaluator jointly. Though incurring multiple passes of decoding, Rewriter-Evaluator with the proposed PGD method can be trained with a similar time to that of training encoder-decoder models. We apply the proposed architecture to improve the general NMT models (e.g., Transformer). We conduct extensive experiments on two translation tasks, Chinese-English and English-German, and show that the proposed architecture notably improves the performances of NMT models and significantly outperforms previous baselines.</td><td>ç¼–ç å™¨-è§£ç å™¨å·²å¹¿æ³›åº”ç”¨äºç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆNMTï¼‰ã€‚å·²ç»æå‡ºäº†ä¸€äº›æ–¹æ³•æ¥é€šè¿‡å¤šæ¬¡è§£ç æ¥æ”¹è¿›å®ƒã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹é€‚å½“çš„ç»ˆæ­¢æ”¿ç­–ï¼Œå®ƒä»¬çš„å…¨éƒ¨æ½œåŠ›å—åˆ°é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¶æ„ï¼ŒRewriter-Evaluatorã€‚å®ƒç”±é‡å†™å™¨å’Œè¯„ä¼°å™¨ç»„æˆã€‚ç¿»è¯‘æºå¥å­æ¶‰åŠå¤šæ¬¡ä¼ é€’ã€‚åœ¨æ¯æ¬¡é€šè¿‡æ—¶ï¼Œé‡å†™è€…éƒ½ä¼šç”Ÿæˆä¸€ä¸ªæ–°çš„ç¿»è¯‘æ¥æ”¹è¿›è¿‡å»çš„ç¿»è¯‘ï¼Œè€Œè¯„ä¼°è€…åˆ™è¯„ä¼°ç¿»è¯‘è´¨é‡ä»¥å†³å®šæ˜¯å¦ç»ˆæ­¢é‡å†™è¿‡ç¨‹ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¼˜å…ˆæ¢¯åº¦ä¸‹é™ (PGD)ï¼Œå®ƒæœ‰åŠ©äºè”åˆè®­ç»ƒé‡å†™å™¨å’Œè¯„ä¼°å™¨ã€‚å°½ç®¡ä¼šå¯¼è‡´å¤šæ¬¡è§£ç ï¼Œä½†å¯ä»¥ä½¿ç”¨ä¸è®­ç»ƒç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ç›¸ä¼¼çš„æ—¶é—´æ¥è®­ç»ƒä½¿ç”¨æ‰€æå‡ºçš„ PGD æ–¹æ³•çš„ Rewriter-Evaluatorã€‚æˆ‘ä»¬åº”ç”¨æ‰€æå‡ºçš„æ¶æ„æ¥æ”¹è¿›ä¸€èˆ¬çš„ NMT æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼ŒTransformerï¼‰ã€‚æˆ‘ä»¬å¯¹æ±‰è¯­-è‹±è¯­å’Œè‹±è¯­-å¾·è¯­è¿™ä¸¤ä¸ªç¿»è¯‘ä»»åŠ¡è¿›è¡Œäº†å¤§é‡å®éªŒï¼Œç»“æœè¡¨æ˜æ‰€æå‡ºçš„æ¶æ„æ˜¾ç€æé«˜äº† NMT æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶æ˜¾ç€ä¼˜äºä»¥å‰çš„åŸºçº¿ã€‚</td><td>Yangming Li   Kaisheng Yao</td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.08226&#39;]">Consistency Regularization for Cross-Lingual Fine-Tuning</a></td><td></td><td><a href="https://github.com/bozheng-hit/xTune">https://github.com/bozheng-hit/xTune</a></td><td><a href="https://arxiv.org/pdf/2106.08226">https://arxiv.org/pdf/2106.08226</a></td><td>Fine-tuning pre-trained cross-lingual language models can transfer task-specific supervision from one language to the others. In this work, we propose to improve cross-lingual fine-tuning with consistency regularization. Specifically, we use example consistency regularization to penalize the prediction sensitivity to four types of data augmentations, i.e., subword sampling, Gaussian noise, code-switch substitution, and machine translation. In addition, we employ model consistency to regularize the models trained with two augmented versions of the same training set. Experimental results on the XTREME benchmark show that our method significantly improves cross-lingual fine-tuning across various tasks, including text classification, question answering, and sequence labeling.</td><td></td><td>Bo Zheng   Li Dong   Shaohan Huang   Wenhui Wang   Zewen Chi   Saksham Singhal   Wanxiang Che   Ting Liu   Xia Song   Furu Wei</td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06381&#39;]">Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment</a></td><td></td><td><a href="https://github.com/CZWin32768/XLM-Align">https://github.com/CZWin32768/XLM-Align</a></td><td><a href="https://arxiv.org/pdf/2106.06381">https://arxiv.org/pdf/2106.06381</a></td><td>The cross-lingual language models are typically pretrained with masked language modeling on multilingual text or parallel sentences. In this paper, we introduce denoising word alignment as a new cross-lingual pre-training task. Specifically, the model first self-labels word alignments for parallel sentences. Then we randomly mask tokens in a bitext pair. Given a masked token, the model uses a pointer network to predict the aligned token in the other language. We alternately perform the above two steps in an expectation-maximization manner. Experimental results show that our method improves cross-lingual transferability on various datasets, especially on the token-level tasks, such as question answering, and structured prediction. Moreover, the model can serve as a pretrained word aligner, which achieves reasonably low error rates on the alignment benchmarks. The code and pretrained parameters are available at <a href="https://github.com/CZWin32768/XLM-Align">https://github.com/CZWin32768/XLM-Align</a>.</td><td>è·¨è¯­è¨€è¯­è¨€æ¨¡å‹é€šå¸¸ä½¿ç”¨å¤šè¯­è¨€æ–‡æœ¬æˆ–å¹³è¡Œå¥å­çš„æ©ç è¯­è¨€æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†å»å™ªè¯å¯¹é½ä½œä¸ºä¸€ç§æ–°çš„è·¨è¯­è¨€é¢„è®­ç»ƒä»»åŠ¡å¼•å…¥ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ¨¡å‹é¦–å…ˆè‡ªæˆ‘æ ‡è®°å¹³è¡Œå¥å­çš„è¯å¯¹é½ã€‚ç„¶åæˆ‘ä»¬éšæœºå±è”½ä¸€ä¸ª bittext å¯¹ä¸­çš„ä»¤ç‰Œã€‚ç»™å®šä¸€ä¸ªæ©ç æ ‡è®°ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨æŒ‡é’ˆç½‘ç»œæ¥é¢„æµ‹å…¶ä»–è¯­è¨€ä¸­å¯¹é½çš„æ ‡è®°ã€‚æˆ‘ä»¬ä»¥æœŸæœ›æœ€å¤§åŒ–çš„æ–¹å¼äº¤æ›¿æ‰§è¡Œä¸Šè¿°ä¸¤ä¸ªæ­¥éª¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†å„ç§æ•°æ®é›†çš„è·¨è¯­è¨€è¿ç§»èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨ä»¤ç‰Œçº§ä»»åŠ¡ä¸Šï¼Œä¾‹å¦‚é—®ç­”å’Œç»“æ„åŒ–é¢„æµ‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä½œä¸ºé¢„è®­ç»ƒçš„è¯å¯¹é½å™¨ï¼Œåœ¨å¯¹é½åŸºå‡†ä¸Šå®ç°ç›¸å½“ä½çš„é”™è¯¯ç‡ã€‚ä»£ç å’Œé¢„è®­ç»ƒå‚æ•°å¯ä» <a href="https://github.com/CZWin32768/XLM-Align">https://github.com/CZWin32768/XLM-Align</a> è·å¾—ã€‚</td><td>Zewen Chi   Li Dong   Bo Zheng   Shaohan Huang   Xian-Ling Mao   Heyan Huang   Furu Wei</td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15127&#39;]">Improving Zero-Shot Translation by Disentangling Positional Information</a></td><td></td><td><a href="https://github.com/nlp-dke/NMTGMinor/tree/master/recipes/zero-shot">https://github.com/nlp-dke/NMTGMinor/tree/master/recipes/zero-shot</a></td><td><a href="https://arxiv.org/pdf/2012.15127">https://arxiv.org/pdf/2012.15127</a></td><td>Multilingual neural machine translation has shown the capability of directly translating between language pairs unseen in training, i.e. zero-shot translation. Despite being conceptually attractive, it often suffers from low output quality. The difficulty of generalizing to new translation directions suggests the model representations are highly specific to those language pairs seen in training. We demonstrate that a main factor causing the language-specific representations is the positional correspondence to input tokens. We show that this can be easily alleviated by removing residual connections in an encoder layer. With this modification, we gain up to 18.5 BLEU points on zero-shot translation while retaining quality on supervised directions. The improvements are particularly prominent between related languages, where our proposed model outperforms pivot-based translation. Moreover, our approach allows easy integration of new languages, which substantially expands translation coverage. By thorough inspections of the hidden layer outputs, we show that our approach indeed leads to more language-independent representations.</td><td>å¤šè¯­è¨€ç¥ç»æœºå™¨ç¿»è¯‘å·²ç»æ˜¾ç¤ºå‡ºåœ¨è®­ç»ƒä¸­çœ‹ä¸åˆ°çš„è¯­è¨€å¯¹ä¹‹é—´ç›´æ¥ç¿»è¯‘çš„èƒ½åŠ›ï¼Œå³é›¶æ ·æœ¬ç¿»è¯‘ã€‚å°½ç®¡åœ¨æ¦‚å¿µä¸Šå¾ˆæœ‰å¸å¼•åŠ›ï¼Œä½†å®ƒç»å¸¸å—åˆ°è¾“å‡ºè´¨é‡ä½çš„å½±å“ã€‚æ¨å¹¿åˆ°æ–°çš„ç¿»è¯‘æ–¹å‘çš„å›°éš¾è¡¨æ˜æ¨¡å‹è¡¨ç¤ºå¯¹äºè®­ç»ƒä¸­çœ‹åˆ°çš„é‚£äº›è¯­è¨€å¯¹æ˜¯é«˜åº¦ç‰¹å®šçš„ã€‚æˆ‘ä»¬è¯æ˜äº†å¯¼è‡´è¯­è¨€ç‰¹å®šè¡¨ç¤ºçš„ä¸€ä¸ªä¸»è¦å› ç´ æ˜¯ä¸è¾“å…¥æ ‡è®°çš„ä½ç½®å¯¹åº”ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œé€šè¿‡åˆ é™¤ç¼–ç å™¨å±‚ä¸­çš„æ®‹å·®è¿æ¥å¯ä»¥è½»æ¾ç¼“è§£è¿™ç§æƒ…å†µã€‚é€šè¿‡è¿™ç§ä¿®æ”¹ï¼Œæˆ‘ä»¬åœ¨é›¶æ ·æœ¬å¹³ç§»ä¸Šè·å¾—äº†é«˜è¾¾ 18.5 BLEU ç‚¹ï¼ŒåŒæ—¶åœ¨ç›‘ç£æ–¹å‘ä¸Šä¿æŒäº†è´¨é‡ã€‚ç›¸å…³è¯­è¨€ä¹‹é—´çš„æ”¹è¿›å°¤ä¸ºçªå‡ºï¼Œæˆ‘ä»¬æå‡ºçš„æ¨¡å‹ä¼˜äºåŸºäºæ¢è½´çš„ç¿»è¯‘ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å…è®¸è½»æ¾é›†æˆæ–°è¯­è¨€ï¼Œä»è€Œå¤§å¤§æ‰©å±•äº†ç¿»è¯‘èŒƒå›´ã€‚é€šè¿‡å¯¹éšè—å±‚è¾“å‡ºçš„å½»åº•æ£€æŸ¥ï¼Œæˆ‘ä»¬è¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•ç¡®å®å¯¼è‡´äº†æ›´å¤šä¸è¯­è¨€æ— å…³çš„è¡¨ç¤ºã€‚</td><td>Danni Liu   Jan Niehues   James Cross   Francisco GuzmÃ¡n   Xian Li</td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15715&#39;]">Beyond Offline Mapping: Learning Cross-lingual Word Embeddings through Context Anchoring</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15715">https://arxiv.org/pdf/2012.15715</a></td><td>Recent research on cross-lingual word embeddings has been dominated by unsupervised mapping approaches that align monolingual embeddings. Such methods critically rely on those embeddings having a similar structure, but it was recently shown that the separate training in different languages causes departures from this assumption. In this paper, we propose an alternative approach that does not have this limitation, while requiring a weak seed dictionary (e.g., a list of identical words) as the only form of supervision. Rather than aligning two fixed embedding spaces, our method works by fixing the target language embeddings, and learning a new set of embeddings for the source language that are aligned with them. To that end, we use an extension of skip-gram that leverages translated context words as anchor points, and incorporates self-learning and iterative restarts to reduce the dependency on the initial dictionary. Our approach outperforms conventional mapping methods on bilingual lexicon induction, and obtains competitive results in the downstream XNLI task.</td><td>æœ€è¿‘å…³äºè·¨è¯­è¨€è¯åµŒå…¥çš„ç ”ç©¶ä¸»è¦ç”±å¯¹é½å•è¯­åµŒå…¥çš„æ— ç›‘ç£æ˜ å°„æ–¹æ³•ä¸»å¯¼ã€‚è¿™äº›æ–¹æ³•ä¸¥é‡ä¾èµ–äºé‚£äº›å…·æœ‰ç›¸ä¼¼ç»“æ„çš„åµŒå…¥ï¼Œä½†æœ€è¿‘è¡¨æ˜ï¼Œä¸åŒè¯­è¨€çš„å•ç‹¬è®­ç»ƒä¼šå¯¼è‡´åç¦»è¿™ä¸€å‡è®¾ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ²¡æœ‰è¿™ç§é™åˆ¶çš„æ›¿ä»£æ–¹æ³•ï¼ŒåŒæ—¶éœ€è¦ä¸€ä¸ªå¼±ç§å­å­—å…¸ï¼ˆä¾‹å¦‚ï¼Œç›¸åŒå•è¯çš„åˆ—è¡¨ï¼‰ä½œä¸ºå”¯ä¸€çš„ç›‘ç£å½¢å¼ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸æ˜¯å¯¹é½ä¸¤ä¸ªå›ºå®šçš„åµŒå…¥ç©ºé—´ï¼Œè€Œæ˜¯é€šè¿‡ä¿®å¤ç›®æ ‡è¯­è¨€åµŒå…¥ï¼Œå¹¶ä¸ºæºè¯­è¨€å­¦ä¹ ä¸€ç»„ä¸å®ƒä»¬å¯¹é½çš„æ–°åµŒå…¥æ¥å·¥ä½œã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†skip-gram çš„æ‰©å±•ï¼Œå®ƒåˆ©ç”¨ç¿»è¯‘çš„ä¸Šä¸‹æ–‡è¯ä½œä¸ºé”šç‚¹ï¼Œå¹¶ç»“åˆè‡ªå­¦ä¹ å’Œè¿­ä»£é‡å¯æ¥å‡å°‘å¯¹åˆå§‹å­—å…¸çš„ä¾èµ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨åŒè¯­è¯å…¸å½’çº³æ–¹é¢ä¼˜äºä¼ ç»Ÿçš„æ˜ å°„æ–¹æ³•ï¼Œå¹¶åœ¨ä¸‹æ¸¸ XNLI ä»»åŠ¡ä¸­è·å¾—äº†æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚</td><td>Aitor Ormazabal   Mikel Artetxe   Aitor Soroa   Gorka Labaka   Eneko Agirre</td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15421&#39;]">Verb Knowledge Injection for Multilingual Event Processing</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15421">https://arxiv.org/pdf/2012.15421</a></td><td>In parallel to their overwhelming success across NLP tasks, language ability of deep Transformer networks, pretrained via language modeling (LM) objectives has undergone extensive scrutiny. While probing revealed that these models encode a range of syntactic and semantic properties of a language, they are still prone to fall back on superficial cues and simple heuristics to solve downstream tasks, rather than leverage deeper linguistic knowledge. In this paper, we target one such area of their deficiency, verbal reasoning. We investigate whether injecting explicit information on verbsâ€™ semantic-syntactic behaviour improves the performance of LM-pretrained Transformers in event extraction tasks â€” downstream tasks for which accurate verb processing is paramount. Concretely, we impart the verb knowledge from curated lexical resources into dedicated adapter modules (dubbed verb adapters), allowing it to complement, in downstream tasks, the language knowledge obtained during LM-pretraining. We first demonstrate that injecting verb knowledge leads to performance gains in English event extraction. We then explore the utility of verb adapters for event extraction in other languages: we investigate (1) zero-shot language transfer with multilingual Transformers as well as (2) transfer via (noisy automatic) translation of English verb-based lexical constraints. Our results show that the benefits of verb knowledge injection indeed extend to other languages, even when verb adapters are trained on noisily translated constraints.</td><td>åœ¨ NLP ä»»åŠ¡ä¸­å–å¾—å‹å€’æ€§æˆåŠŸçš„åŒæ—¶ï¼Œé€šè¿‡è¯­è¨€å»ºæ¨¡ (LM) ç›®æ ‡é¢„è®­ç»ƒçš„æ·±åº¦ Transformer ç½‘ç»œçš„è¯­è¨€èƒ½åŠ›ä¹Ÿå—åˆ°äº†å¹¿æ³›çš„å®¡æŸ¥ã€‚è™½ç„¶æ¢ç´¢è¡¨æ˜è¿™äº›æ¨¡å‹ç¼–ç äº†è¯­è¨€çš„ä¸€ç³»åˆ—å¥æ³•å’Œè¯­ä¹‰å±æ€§ï¼Œä½†å®ƒä»¬ä»ç„¶å€¾å‘äºä¾é è¡¨é¢çº¿ç´¢å’Œç®€å•çš„å¯å‘å¼æ–¹æ³•æ¥è§£å†³ä¸‹æ¸¸ä»»åŠ¡ï¼Œè€Œä¸æ˜¯åˆ©ç”¨æ›´æ·±å±‚æ¬¡çš„è¯­è¨€çŸ¥è¯†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é’ˆå¯¹ä»–ä»¬çš„ä¸è¶³ä¹‹å¤„ä¹‹ä¸€ï¼Œå³è¯­è¨€æ¨ç†ã€‚æˆ‘ä»¬è°ƒæŸ¥äº†æ³¨å…¥å…³äºåŠ¨è¯è¯­ä¹‰å¥æ³•è¡Œä¸ºçš„æ˜¾å¼ä¿¡æ¯æ˜¯å¦å¯ä»¥æé«˜ LM é¢„è®­ç»ƒ Transformer åœ¨äº‹ä»¶æå–ä»»åŠ¡ä¸­çš„æ€§èƒ½ - å‡†ç¡®çš„åŠ¨è¯å¤„ç†è‡³å…³é‡è¦çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†ç²¾é€‰è¯æ±‡èµ„æºä¸­çš„åŠ¨è¯çŸ¥è¯†ä¼ æˆç»™ä¸“ç”¨çš„é€‚é…å™¨æ¨¡å—ï¼ˆç§°ä¸ºåŠ¨è¯é€‚é…å™¨ï¼‰ï¼Œä½¿å…¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¥å…… LM é¢„è®­ç»ƒæœŸé—´è·å¾—çš„è¯­è¨€çŸ¥è¯†ã€‚æˆ‘ä»¬é¦–å…ˆè¯æ˜æ³¨å…¥åŠ¨è¯çŸ¥è¯†å¯ä»¥æé«˜è‹±è¯­äº‹ä»¶æå–çš„æ€§èƒ½ã€‚ç„¶åï¼Œæˆ‘ä»¬æ¢ç´¢äº†åŠ¨è¯é€‚é…å™¨åœ¨å…¶ä»–è¯­è¨€ä¸­ç”¨äºäº‹ä»¶æå–çš„æ•ˆç”¨ï¼šæˆ‘ä»¬ç ”ç©¶äº† (1) ä½¿ç”¨å¤šè¯­è¨€ Transformer çš„é›¶æ ·æœ¬è¯­è¨€è¿ç§»ä»¥åŠ (2) é€šè¿‡ï¼ˆå˜ˆæ‚çš„è‡ªåŠ¨ï¼‰ç¿»è¯‘åŸºäºè‹±è¯­åŠ¨è¯çš„è¯æ±‡çº¦æŸçš„è¿ç§»ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒåŠ¨è¯çŸ¥è¯†æ³¨å…¥çš„å¥½å¤„ç¡®å®æ‰©å±•åˆ°å…¶ä»–è¯­è¨€ï¼Œå³ä½¿åŠ¨è¯é€‚é…å™¨åœ¨å˜ˆæ‚çš„ç¿»è¯‘çº¦æŸä¸Šè¿›è¡Œè®­ç»ƒã€‚</td><td>Olga Majewska   Ivan VuliÄ‡   Goran GlavaÅ¡   Edoardo M. Ponti   Anna Korhonen</td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06937&#39;]">Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning</a></td><td></td><td><a href="https://github.com/INK-USC/XCSR">https://github.com/INK-USC/XCSR</a></td><td><a href="https://arxiv.org/pdf/2106.06937">https://arxiv.org/pdf/2106.06937</a></td><td>Commonsense reasoning research has so far been limited to English. We aim to evaluate and improve popular multilingual language models (ML-LMs) to help advance commonsense reasoning (CSR) beyond English. We collect the Mickey Corpus, consisting of 561k sentences in 11 different languages, which can be used for analyzing and improving ML-LMs. We propose Mickey Probe, a language-agnostic probing task for fairly evaluating the common sense of popular ML-LMs across different languages. In addition, we also create two new datasets, X-CSQA and X-CODAH, by translating their English versions to 15 other languages, so that we can evaluate popular ML-LMs for cross-lingual commonsense reasoning. To improve the performance beyond English, we propose a simple yet effective method â€” multilingual contrastive pre-training (MCP). It significantly enhances sentence representations, yielding a large performance gain on both benchmarks.</td><td></td><td>Bill Yuchen Lin   Seyeon Lee   Xiaoyang Qiao   Xiang Ren</td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00148&#39;]">Bilingual Lexicon Induction via Unsupervised Bitext Construction and Word Alignment</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2101.00148">https://arxiv.org/pdf/2101.00148</a></td><td>Bilingual lexicons map words in one language to their translations in another, and are typically induced by learning linear projections to align monolingual word embedding spaces. In this paper, we show it is possible to produce much higher quality lexicons with methods that combine (1) unsupervised bitext mining and (2) unsupervised word alignment. Directly applying a pipeline that uses recent algorithms for both subproblems significantly improves induced lexicon quality and further gains are possible by learning to filter the resulting lexical entries, with both unsupervised and semi-supervised schemes. Our final model outperforms the state of the art on the BUCC 2020 shared task by 14 $F_1$ points averaged over 12 language pairs, while also providing a more interpretable approach that allows for rich reasoning of word meaning in context. Further analysis of our output and the standard reference lexicons suggests they are of comparable quality, and new benchmarks may be needed to measure further progress on this task.</td><td>åŒè¯­è¯å…¸å°†ä¸€ç§è¯­è¨€ä¸­çš„å•è¯æ˜ å°„åˆ°å¦ä¸€ç§è¯­è¨€ä¸­çš„ç¿»è¯‘ï¼Œå¹¶ä¸”é€šå¸¸é€šè¿‡å­¦ä¹ çº¿æ€§æŠ•å½±æ¥å¯¹é½å•è¯­å•è¯åµŒå…¥ç©ºé—´æ¥è¯±å¯¼ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä½¿ç”¨ç»“åˆ (1) æ— ç›‘ç£åŒæ–‡æœ¬æŒ–æ˜å’Œ (2) æ— ç›‘ç£è¯å¯¹é½çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆæ›´é«˜è´¨é‡çš„è¯å…¸ã€‚ç›´æ¥åº”ç”¨å¯¹ä¸¤ä¸ªå­é—®é¢˜ä½¿ç”¨æœ€æ–°ç®—æ³•çš„ç®¡é“å¯ä»¥æ˜¾ç€æé«˜è¯±å¯¼è¯å…¸çš„è´¨é‡ï¼Œå¹¶ä¸”é€šè¿‡å­¦ä¹ è¿‡æ»¤ç”Ÿæˆçš„è¯æ¡ï¼Œå¯ä»¥ä½¿ç”¨æ— ç›‘ç£å’ŒåŠç›‘ç£æ–¹æ¡ˆè¿›ä¸€æ­¥æé«˜ã€‚æˆ‘ä»¬çš„æœ€ç»ˆæ¨¡å‹åœ¨ BUCC 2020 å…±äº«ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œåœ¨ 12 ä¸ªè¯­è¨€å¯¹ä¸Šå¹³å‡æé«˜äº† 14 $F_1$ ç‚¹ï¼ŒåŒæ—¶è¿˜æä¾›äº†ä¸€ç§æ›´å…·å¯è§£é‡Šæ€§çš„æ–¹æ³•ï¼Œå…è®¸åœ¨ä¸Šä¸‹æ–‡ä¸­å¯¹è¯ä¹‰è¿›è¡Œä¸°å¯Œçš„æ¨ç†ã€‚å¯¹æˆ‘ä»¬çš„è¾“å‡ºå’Œæ ‡å‡†å‚è€ƒè¯å…¸çš„è¿›ä¸€æ­¥åˆ†æè¡¨æ˜å®ƒä»¬çš„è´¨é‡ç›¸å½“ï¼Œå¯èƒ½éœ€è¦æ–°çš„åŸºå‡†æ¥è¡¡é‡è¿™é¡¹ä»»åŠ¡çš„è¿›ä¸€æ­¥è¿›å±•ã€‚</td><td>Haoyue Shi   Luke Zettlemoyer   Sida I. Wang</td></tr><tr><td>10</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11867&#39;]">Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation</a></td><td></td><td><a href="https://github.com/bzhangGo/zero">https://github.com/bzhangGo/zero</a></td><td><a href="https://arxiv.org/pdf/2004.11867">https://arxiv.org/pdf/2004.11867</a></td><td>Massively multilingual models for neural machine translation (NMT) are theoretically attractive, but often underperform bilingual models and deliver poor zero-shot translations. In this paper, we explore ways to improve them. We argue that multilingual NMT requires stronger modeling capacity to support language pairs with varying typological characteristics, and overcome this bottleneck via language-specific components and deepening NMT architectures. We identify the off-target translation issue (i.e. translating into a wrong target language) as the major source of the inferior zero-shot performance, and propose random online backtranslation to enforce the translation of unseen training language pairs. Experiments on OPUS-100 (a novel multilingual dataset with 100 languages) show that our approach substantially narrows the performance gap with bilingual models in both one-to-many and many-to-many settings, and improves zero-shot performance by ~10 BLEU, approaching conventional pivot-based methods.</td><td>ç”¨äºç¥ç»æœºå™¨ç¿»è¯‘ (NMT) çš„å¤§è§„æ¨¡å¤šè¯­è¨€æ¨¡å‹åœ¨ç†è®ºä¸Šå¾ˆæœ‰å¸å¼•åŠ›ï¼Œä½†é€šå¸¸è¡¨ç°ä¸å¦‚åŒè¯­æ¨¡å‹å¹¶ä¸”æä¾›ç³Ÿç³•çš„é›¶æ ·æœ¬ç¿»è¯‘ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†æ”¹è¿›å®ƒä»¬çš„æ–¹æ³•ã€‚æˆ‘ä»¬è®¤ä¸ºå¤šè¯­è¨€ NMT éœ€è¦æ›´å¼ºçš„å»ºæ¨¡èƒ½åŠ›æ¥æ”¯æŒå…·æœ‰ä¸åŒç±»å‹ç‰¹å¾çš„è¯­è¨€å¯¹ï¼Œå¹¶é€šè¿‡ç‰¹å®šäºè¯­è¨€çš„ç»„ä»¶å’Œæ·±åŒ– NMT æ¶æ„æ¥å…‹æœè¿™ä¸€ç“¶é¢ˆã€‚æˆ‘ä»¬å°†è„±é¶ç¿»è¯‘é—®é¢˜ï¼ˆå³ç¿»è¯‘æˆé”™è¯¯çš„ç›®æ ‡è¯­è¨€ï¼‰ç¡®å®šä¸ºè¾ƒå·®çš„é›¶æ ·æœ¬æ€§èƒ½çš„ä¸»è¦æ¥æºï¼Œå¹¶æå‡ºéšæœºåœ¨çº¿åå‘ç¿»è¯‘æ¥å¼ºåˆ¶ç¿»è¯‘çœ‹ä¸è§çš„è®­ç»ƒè¯­è¨€å¯¹ã€‚åœ¨ OPUS-100ï¼ˆä¸€ä¸ªåŒ…å« 100 ç§è¯­è¨€çš„æ–°å‹å¤šè¯­è¨€æ•°æ®é›†ï¼‰ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¤§å¤§ç¼©å°äº†åœ¨ä¸€å¯¹å¤šå’Œå¤šå¯¹å¤šè®¾ç½®ä¸­ä¸åŒè¯­æ¨¡å‹çš„æ€§èƒ½å·®è·ï¼Œå¹¶å°†é›¶æ ·æœ¬æ€§èƒ½æé«˜äº†çº¦ 10 BLEUï¼Œæ¥è¿‘ä¼ ç»Ÿçš„åŸºäºæ¢è½´çš„æ–¹æ³•ã€‚</td><td>Biao Zhang   Philip Williams   Ivan Titov   Rico Sennrich</td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13169&#39;]">Simultaneous Translation Policies: From Fixed to Adaptive</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.13169">https://arxiv.org/pdf/2004.13169</a></td><td>Adaptive policies are better than fixed policies for simultaneous translation, since they can flexibly balance the tradeoff between translation quality and latency based on the current context information. But previous methods on obtaining adaptive policies either rely on complicated training process, or underperform simple fixed policies. We design an algorithm to achieve adaptive policies via a simple heuristic composition of a set of fixed policies. Experiments on Chinese -&gt; English and German -&gt; English show that our adaptive policies can outperform fixed ones by up to 4 BLEU points for the same latency, and more surprisingly, it even surpasses the BLEU score of full-sentence translation in the greedy mode (and very close to beam mode), but with much lower latency.</td><td>å¯¹äºåŒæ­¥ç¿»è¯‘ï¼Œè‡ªé€‚åº”ç­–ç•¥ä¼˜äºå›ºå®šç­–ç•¥ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥æ ¹æ®å½“å‰ä¸Šä¸‹æ–‡ä¿¡æ¯çµæ´»åœ°å¹³è¡¡ç¿»è¯‘è´¨é‡å’Œå»¶è¿Ÿä¹‹é—´çš„æƒè¡¡ã€‚ä½†æ˜¯ä»¥å‰è·å–è‡ªé€‚åº”ç­–ç•¥çš„æ–¹æ³•è¦ä¹ˆä¾èµ–äºå¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ï¼Œè¦ä¹ˆè¡¨ç°ä¸ä½³ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç®—æ³•ï¼Œé€šè¿‡ä¸€ç»„å›ºå®šç­–ç•¥çš„ç®€å•å¯å‘å¼ç»„åˆæ¥å®ç°è‡ªé€‚åº”ç­–ç•¥ã€‚ä¸­æ–‡ -&gt; è‹±æ–‡å’Œå¾·æ–‡ -&gt; è‹±æ–‡çš„å®éªŒè¡¨æ˜ï¼Œåœ¨ç›¸åŒçš„å»¶è¿Ÿä¸‹ï¼Œæˆ‘ä»¬çš„è‡ªé€‚åº”ç­–ç•¥å¯ä»¥æ¯”å›ºå®šç­–ç•¥é«˜å‡ºå¤šè¾¾ 4 ä¸ª BLEU ç‚¹ï¼Œæ›´ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå®ƒç”šè‡³è¶…è¿‡äº†è´ªå©ªæ¨¡å¼ä¸‹å®Œæ•´å¥å­ç¿»è¯‘çš„ BLEU åˆ†æ•°ï¼ˆå¹¶ä¸”éå¸¸æ¥è¿‘å…‰æŸæ¨¡å¼ï¼‰ï¼Œä½†å»¶è¿Ÿè¦ä½å¾—å¤šã€‚</td><td>Baigong Zheng   Kaibo Liu   Renjie Zheng   Mingbo Ma   Hairong Liu   Liang Huang</td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14021&#39;]">Multiscale Collaborative Deep Models for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/pemywei/MSC-NMT">https://github.com/pemywei/MSC-NMT</a></td><td><a href="https://arxiv.org/pdf/2004.14021">https://arxiv.org/pdf/2004.14021</a></td><td>Recent evidence reveals that Neural Machine Translation (NMT) models with deeper neural networks can be more effective but are difficult to train. In this paper, we present a MultiScale Collaborative (MSC) framework to ease the training of NMT models that are substantially deeper than those used previously. We explicitly boost the gradient back-propagation from top to bottom levels by introducing a block-scale collaboration mechanism into deep NMT models. Then, instead of forcing the whole encoder stack directly learns a desired representation, we let each encoder block learns a fine-grained representation and enhance it by encoding spatial dependencies using a context-scale collaboration. We provide empirical evidence showing that the MSC nets are easy to optimize and can obtain improvements of translation quality from considerably increased depth. On IWSLT translation tasks with three translation directions, our extremely deep models (with 72-layer encoders) surpass strong baselines by +2.2~+3.1 BLEU points. In addition, our deep MSC achieves a BLEU score of 30.56 on WMT14 English-German task that significantly outperforms state-of-the-art deep NMT models.</td><td>æœ€è¿‘çš„è¯æ®è¡¨æ˜ï¼Œå…·æœ‰æ›´æ·±ç¥ç»ç½‘ç»œçš„ç¥ç»æœºå™¨ç¿»è¯‘ (NMT) æ¨¡å‹å¯èƒ½æ›´æœ‰æ•ˆï¼Œä½†éš¾ä»¥è®­ç»ƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šå°ºåº¦åä½œ (MSC) æ¡†æ¶ï¼Œä»¥ç®€åŒ– NMT æ¨¡å‹çš„è®­ç»ƒï¼Œè¿™äº›æ¨¡å‹æ¯”ä»¥å‰ä½¿ç”¨çš„æ¨¡å‹è¦æ·±å¾—å¤šã€‚æˆ‘ä»¬é€šè¿‡åœ¨æ·±åº¦ NMT æ¨¡å‹ä¸­å¼•å…¥å—çº§åä½œæœºåˆ¶ï¼Œæ˜¾å¼åœ°æå‡äº†ä»ä¸Šåˆ°ä¸‹çš„æ¢¯åº¦åå‘ä¼ æ’­ã€‚ç„¶åï¼Œæˆ‘ä»¬ä¸æ˜¯å¼ºåˆ¶æ•´ä¸ªç¼–ç å™¨å †æ ˆç›´æ¥å­¦ä¹ æ‰€éœ€çš„è¡¨ç¤ºï¼Œè€Œæ˜¯è®©æ¯ä¸ªç¼–ç å™¨å—å­¦ä¹ ç»†ç²’åº¦çš„è¡¨ç¤ºï¼Œå¹¶é€šè¿‡ä½¿ç”¨ä¸Šä¸‹æ–‡å°ºåº¦åä½œå¯¹ç©ºé—´ä¾èµ–æ€§è¿›è¡Œç¼–ç æ¥å¢å¼ºå®ƒã€‚æˆ‘ä»¬æä¾›çš„ç»éªŒè¯æ®è¡¨æ˜ï¼ŒMSC ç½‘ç»œæ˜“äºä¼˜åŒ–ï¼Œå¹¶ä¸”å¯ä»¥ä»æ˜¾ç€å¢åŠ çš„æ·±åº¦ä¸­è·å¾—ç¿»è¯‘è´¨é‡çš„æ”¹è¿›ã€‚åœ¨å…·æœ‰ä¸‰ä¸ªç¿»è¯‘æ–¹å‘çš„ IWSLT ç¿»è¯‘ä»»åŠ¡ä¸Šï¼Œæˆ‘ä»¬ææ·±çš„æ¨¡å‹ï¼ˆå…·æœ‰ 72 å±‚ç¼–ç å™¨ï¼‰è¶…è¿‡å¼ºåŸºçº¿ +2.2~+3.1 BLEU ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ·±åº¦ MSC åœ¨ WMT14 è‹±å¾·ä»»åŠ¡ä¸Šè·å¾—äº† 30.56 çš„ BLEU åˆ†æ•°ï¼Œæ˜æ˜¾ä¼˜äºæœ€å…ˆè¿›çš„æ·±åº¦ NMT æ¨¡å‹ã€‚</td><td>Xiangpeng Wei   Heng Yu   Yue Hu   Yue Zhang   Rongxiang Weng   Weihua Luo</td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14788&#39;]">Character-Level Translation with Self-attention</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14788">https://arxiv.org/pdf/2004.14788</a></td><td>We explore the suitability of self-attention models for character-level neural machine translation. We test the standard transformer model, as well as a novel variant in which the encoder block combines information from nearby characters using convolutions. We perform extensive experiments on WMT and UN datasets, testing both bilingual and multilingual translation to English using up to three input languages (French, Spanish, and Chinese). Our transformer variant consistently outperforms the standard transformer at the character-level and converges faster while learning more robust character-level alignments.</td><td>æˆ‘ä»¬æ¢ç´¢äº†è‡ªæ³¨æ„åŠ›æ¨¡å‹å¯¹å­—ç¬¦çº§ç¥ç»æœºå™¨ç¿»è¯‘çš„é€‚ç”¨æ€§ã€‚æˆ‘ä»¬æµ‹è¯•äº†æ ‡å‡†è½¬æ¢å™¨æ¨¡å‹ï¼Œä»¥åŠä¸€ç§æ–°çš„å˜ä½“ï¼Œå…¶ä¸­ç¼–ç å™¨å—ä½¿ç”¨å·ç§¯ç»“åˆæ¥è‡ªé™„è¿‘å­—ç¬¦çš„ä¿¡æ¯ã€‚æˆ‘ä»¬å¯¹ WMT å’Œ UN æ•°æ®é›†è¿›è¡Œäº†å¤§é‡å®éªŒï¼Œä½¿ç”¨æœ€å¤šä¸‰ç§è¾“å…¥è¯­è¨€ï¼ˆæ³•è¯­ã€è¥¿ç­ç‰™è¯­å’Œä¸­æ–‡ï¼‰æµ‹è¯•åŒè¯­å’Œå¤šè¯­ç§ç¿»è¯‘æˆè‹±è¯­ã€‚æˆ‘ä»¬çš„è½¬æ¢å™¨å˜ä½“åœ¨å­—ç¬¦çº§åˆ«å§‹ç»ˆä¼˜äºæ ‡å‡†è½¬æ¢å™¨ï¼Œå¹¶ä¸”åœ¨å­¦ä¹ æ›´å¼ºå¤§çš„å­—ç¬¦çº§åˆ«å¯¹é½çš„åŒæ—¶æ”¶æ•›é€Ÿåº¦æ›´å¿«ã€‚</td><td>Yingqiang Gao   Nikola I. Nikolov   Yuhuang Hu   Richard H. R. Hahnloser</td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00850&#39;]">ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/lifu-tu/ENGINE">https://github.com/lifu-tu/ENGINE</a></td><td><a href="https://arxiv.org/pdf/2005.00850">https://arxiv.org/pdf/2005.00850</a></td><td>We propose to train a non-autoregressive machine translation model to minimize the energy defined by a pretrained autoregressive model. In particular, we view our non-autoregressive translation system as an inference network (Tu and Gimpel, 2018) trained to minimize the autoregressive teacher energy. This contrasts with the popular approach of training a non-autoregressive model on a distilled corpus consisting of the beam-searched outputs of such a teacher model. Our approach, which we call ENGINE (ENerGy-based Inference NEtworks), achieves state-of-the-art non-autoregressive results on the IWSLT 2014 DE-EN and WMT 2016 RO-EN datasets, approaching the performance of autoregressive models.</td><td>æˆ‘ä»¬å»ºè®®è®­ç»ƒä¸€ä¸ªéè‡ªå›å½’æœºå™¨ç¿»è¯‘æ¨¡å‹ï¼Œä»¥æœ€å°åŒ–ç”±é¢„è®­ç»ƒè‡ªå›å½’æ¨¡å‹å®šä¹‰çš„èƒ½é‡ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„éè‡ªå›å½’ç¿»è¯‘ç³»ç»Ÿè§†ä¸ºä¸€ä¸ªæ¨ç†ç½‘ç»œï¼ˆTu å’Œ Gimpelï¼Œ2018ï¼‰ï¼Œç»è¿‡è®­ç»ƒä»¥æœ€å°åŒ–è‡ªå›å½’æ•™å¸ˆèƒ½é‡ã€‚è¿™ä¸åœ¨ç”±è¿™ç§æ•™å¸ˆæ¨¡å‹çš„æ³¢æŸæœç´¢è¾“å‡ºç»„æˆçš„è’¸é¦è¯­æ–™åº“ä¸Šè®­ç»ƒéè‡ªå›å½’æ¨¡å‹çš„æµè¡Œæ–¹æ³•å½¢æˆå¯¹æ¯”ã€‚æˆ‘ä»¬ç§°ä¸º ENGINEï¼ˆåŸºäºèƒ½æºçš„æ¨ç†ç½‘ç»œï¼‰çš„æ–¹æ³•åœ¨ IWSLT 2014 DE-EN å’Œ WMT 2016 RO-EN æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„éè‡ªå›å½’ç»“æœï¼Œæ¥è¿‘è‡ªå›å½’æ¨¡å‹çš„æ€§èƒ½ã€‚</td><td>Lifu Tu   Richard Yuanzhe Pang   Sam Wiseman   Kevin Gimpel</td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00308&#39;]">Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.00308">https://arxiv.org/pdf/2005.00308</a></td><td>Machine translation (MT) has benefited from using synthetic training data originating from translating monolingual corpora, a technique known as backtranslation. Combining backtranslated data from different sources has led to better results than when using such data in isolation. In this work we analyse the impact that data translated with rule-based, phrase-based statistical and neural MT systems has on new MT systems. We use a real-world low-resource use-case (Basque-to-Spanish in the clinical domain) as well as a high-resource language pair (German-to-English) to test different scenarios with backtranslation and employ data selection to optimise the synthetic corpora. We exploit different data selection strategies in order to reduce the amount of data used, while at the same time maintaining high-quality MT systems. We further tune the data selection method by taking into account the quality of the MT systems used for backtranslation and lexical diversity of the resulting corpora. Our experiments show that incorporating backtranslated data from different sources can be beneficial, and that availing of data selection can yield improved performance.</td><td>æœºå™¨ç¿»è¯‘ (MT) å—ç›Šäºä½¿ç”¨æºè‡ªç¿»è¯‘å•è¯­è¯­æ–™åº“çš„åˆæˆè®­ç»ƒæ•°æ®ï¼Œè¿™ç§æŠ€æœ¯ç§°ä¸ºåå‘ç¿»è¯‘ã€‚ä¸å•ç‹¬ä½¿ç”¨è¿™äº›æ•°æ®ç›¸æ¯”ï¼Œå°†æ¥è‡ªä¸åŒæ¥æºçš„åå‘ç¿»è¯‘æ•°æ®ç»“åˆèµ·æ¥ä¼šäº§ç”Ÿæ›´å¥½çš„ç»“æœã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åˆ†æäº†ä½¿ç”¨åŸºäºè§„åˆ™ã€åŸºäºçŸ­è¯­çš„ç»Ÿè®¡å’Œç¥ç» MT ç³»ç»Ÿç¿»è¯‘çš„æ•°æ®å¯¹æ–° MT ç³»ç»Ÿçš„å½±å“ã€‚æˆ‘ä»¬ä½¿ç”¨ç°å®ä¸–ç•Œçš„ä½èµ„æºç”¨ä¾‹ï¼ˆä¸´åºŠé¢†åŸŸçš„å·´æ–¯å…‹è¯­åˆ°è¥¿ç­ç‰™è¯­ï¼‰ä»¥åŠé«˜èµ„æºè¯­è¨€å¯¹ï¼ˆå¾·è¯­åˆ°è‹±è¯­ï¼‰æ¥æµ‹è¯•ä¸åŒçš„åå‘ç¿»è¯‘åœºæ™¯ï¼Œå¹¶é‡‡ç”¨æ•°æ®é€‰æ‹©æ¥ä¼˜åŒ–åˆæˆè¯­æ–™åº“ã€‚æˆ‘ä»¬åˆ©ç”¨ä¸åŒçš„æ•°æ®é€‰æ‹©ç­–ç•¥æ¥å‡å°‘ä½¿ç”¨çš„æ•°æ®é‡ï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡çš„ MT ç³»ç»Ÿã€‚æˆ‘ä»¬é€šè¿‡è€ƒè™‘ç”¨äºåå‘ç¿»è¯‘çš„ MT ç³»ç»Ÿçš„è´¨é‡å’Œç»“æœè¯­æ–™åº“çš„è¯æ±‡å¤šæ ·æ€§æ¥è¿›ä¸€æ­¥è°ƒæ•´æ•°æ®é€‰æ‹©æ–¹æ³•ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œåˆå¹¶æ¥è‡ªä¸åŒæ¥æºçš„åå‘ç¿»è¯‘æ•°æ®å¯èƒ½æ˜¯æœ‰ç›Šçš„ï¼Œå¹¶ä¸”åˆ©ç”¨æ•°æ®é€‰æ‹©å¯ä»¥æé«˜æ€§èƒ½ã€‚</td><td>Xabier Soto   Dimitar Shterionov   Alberto Poncelas   Andy Way</td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.06606&#39;]">Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/xlhex/dpe">https://github.com/xlhex/dpe</a></td><td><a href="https://arxiv.org/pdf/2005.06606">https://arxiv.org/pdf/2005.06606</a></td><td>This paper introduces Dynamic Programming Encoding (DPE), a new segmentation algorithm for tokenizing sentences into subword units. We view the subword segmentation of output sentences as a latent variable that should be marginalized out for learning and inference. A mixed character-subword transformer is proposed, which enables exact log marginal likelihood estimation and exact MAP inference to find target segmentations with maximum posterior probability. DPE uses a lightweight mixed character-subword transformer as a means of pre-processing parallel data to segment output sentences using dynamic programming. Empirical results on machine translation suggest that DPE is effective for segmenting output sentences and can be combined with BPE dropout for stochastic segmentation of source sentences. DPE achieves an average improvement of 0.9 BLEU over BPE (Sennrich et al., 2016) and an average improvement of 0.55 BLEU over BPE dropout (Provilkov et al., 2019) on several WMT datasets including English &lt;=&gt; (German, Romanian, Estonian, Finnish, Hungarian).</td><td>æœ¬æ–‡ä»‹ç»äº†åŠ¨æ€ç¼–ç¨‹ç¼–ç  (DPE)ï¼Œè¿™æ˜¯ä¸€ç§å°†å¥å­æ ‡è®°ä¸ºå­è¯å•å…ƒçš„æ–°åˆ†è¯ç®—æ³•ã€‚æˆ‘ä»¬å°†è¾“å‡ºå¥å­çš„å­è¯åˆ†å‰²è§†ä¸ºä¸€ä¸ªæ½œåœ¨å˜é‡ï¼Œåº”è¯¥è¢«è¾¹ç¼˜åŒ–ä»¥è¿›è¡Œå­¦ä¹ å’Œæ¨ç†ã€‚æå‡ºäº†ä¸€ç§æ··åˆå­—ç¬¦-å­å­—è½¬æ¢å™¨ï¼Œå®ƒèƒ½å¤Ÿè¿›è¡Œç²¾ç¡®çš„å¯¹æ•°è¾¹é™…ä¼¼ç„¶ä¼°è®¡å’Œç²¾ç¡®çš„ MAP æ¨ç†ï¼Œä»¥æ‰¾åˆ°å…·æœ‰æœ€å¤§åéªŒæ¦‚ç‡çš„ç›®æ ‡åˆ†æ®µã€‚ DPE ä½¿ç”¨è½»é‡çº§æ··åˆå­—ç¬¦-å­å­—è½¬æ¢å™¨ä½œä¸ºé¢„å¤„ç†å¹¶è¡Œæ•°æ®çš„ä¸€ç§æ‰‹æ®µï¼Œä»¥ä½¿ç”¨åŠ¨æ€ç¼–ç¨‹å¯¹è¾“å‡ºå¥å­è¿›è¡Œåˆ†æ®µã€‚æœºå™¨ç¿»è¯‘çš„å®è¯ç»“æœè¡¨æ˜ï¼ŒDPE å¯¹åˆ†å‰²è¾“å‡ºå¥å­æ˜¯æœ‰æ•ˆçš„ï¼Œå¹¶ä¸”å¯ä»¥ä¸ BPE dropout ç»“åˆç”¨äºæºå¥å­çš„éšæœºåˆ†å‰²ã€‚ DPE åœ¨åŒ…æ‹¬è‹±è¯­ &lt;=&gt;ï¼ˆå¾·è¯­ã€ç½—é©¬å°¼äºšè¯­ã€çˆ±æ²™å°¼äºšè¯­ã€èŠ¬å…°è¯­ã€åŒˆç‰™åˆ©è¯­ï¼‰ã€‚</td><td>Xuanli He   Gholamreza Haffari   Mohammad Norouzi</td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.02014&#39;]">Norm-Based Curriculum Learning for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/NLP2CT/norm-nmt">https://github.com/NLP2CT/norm-nmt</a></td><td><a href="https://arxiv.org/pdf/2006.02014">https://arxiv.org/pdf/2006.02014</a></td><td>A neural machine translation (NMT) system is expensive to train, especially with high-resource settings. As the NMT architectures become deeper and wider, this issue gets worse and worse. In this paper, we aim to improve the efficiency of training an NMT by introducing a novel norm-based curriculum learning method. We use the norm (aka length or module) of a word embedding as a measure of 1) the difficulty of the sentence, 2) the competence of the model, and 3) the weight of the sentence. The norm-based sentence difficulty takes the advantages of both linguistically motivated and model-based sentence difficulties. It is easy to determine and contains learning-dependent features. The norm-based model competence makes NMT learn the curriculum in a fully automated way, while the norm-based sentence weight further enhances the learning of the vector representation of the NMT. Experimental results for the WMTâ€™14 English-German and WMTâ€™17 Chinese-English translation tasks demonstrate that the proposed method outperforms strong baselines in terms of BLEU score (+1.17/+1.56) and training speedup (2.22x/3.33x).</td><td></td><td>Xuebo Liu   Houtim Lai   Derek F. Wong   Lidia S. Chao</td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2007.02671&#39;]">Bilingual Dictionary Based Neural Machine Translation without Using Parallel Sentences</a></td><td></td><td><a href="https://github.com/mttravel/Dictionary-based-MT">https://github.com/mttravel/Dictionary-based-MT</a></td><td><a href="https://arxiv.org/pdf/2007.02671">https://arxiv.org/pdf/2007.02671</a></td><td>In this paper, we propose a new task of machine translation (MT), which is based on no parallel sentences but can refer to a ground-truth bilingual dictionary. Motivated by the ability of a monolingual speaker learning to translate via looking up the bilingual dictionary, we propose the task to see how much potential an MT system can attain using the bilingual dictionary and large scale monolingual corpora, while is independent on parallel sentences. We propose anchored training (AT) to tackle the task. AT uses the bilingual dictionary to establish anchoring points for closing the gap between source language and target language. Experiments on various language pairs show that our approaches are significantly better than various baselines, including dictionary-based word-by-word translation, dictionary-supervised cross-lingual word embedding transformation, and unsupervised MT. On distant language pairs that are hard for unsupervised MT to perform well, AT performs remarkably better, achieving performances comparable to supervised SMT trained on more than 4M parallel sentences.</td><td>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†æœºå™¨ç¿»è¯‘ (MT) çš„ä¸€é¡¹æ–°ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡ä¸åŸºäºå¹³è¡Œå¥ï¼Œä½†å¯ä»¥å‚è€ƒçœŸå€¼åŒè¯­è¯å…¸ã€‚å—å•è¯­è¯´è¯è€…é€šè¿‡æŸ¥æ‰¾åŒè¯­è¯å…¸å­¦ä¹ ç¿»è¯‘çš„èƒ½åŠ›çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€é¡¹ä»»åŠ¡ï¼Œå³åœ¨ç‹¬ç«‹äºå¹³è¡Œå¥å­çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨åŒè¯­è¯å…¸å’Œå¤§è§„æ¨¡å•è¯­è¯­æ–™åº“æŸ¥çœ‹ MT ç³»ç»Ÿå¯ä»¥å®ç°å¤šå°‘æ½œåŠ›ã€‚æˆ‘ä»¬å»ºè®®é”šå®šè®­ç»ƒï¼ˆATï¼‰æ¥è§£å†³è¿™ä¸ªä»»åŠ¡ã€‚ AT ä½¿ç”¨åŒè¯­è¯å…¸å»ºç«‹å®šä½ç‚¹ï¼Œä»¥ç¼©å°æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ä¹‹é—´çš„å·®è·ã€‚åœ¨å„ç§è¯­è¨€å¯¹ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜æ˜¾ä¼˜äºå„ç§åŸºçº¿ï¼ŒåŒ…æ‹¬åŸºäºå­—å…¸çš„é€å­—ç¿»è¯‘ã€å­—å…¸ç›‘ç£çš„è·¨è¯­è¨€è¯åµŒå…¥è½¬æ¢å’Œæ— ç›‘ç£çš„æœºå™¨ç¿»è¯‘ã€‚åœ¨æ— ç›‘ç£ MT éš¾ä»¥è¡¨ç°è‰¯å¥½çš„è¿œè·ç¦»è¯­è¨€å¯¹ä¸Šï¼ŒAT è¡¨ç°å¾—éå¸¸å¥½ï¼Œè¾¾åˆ°äº†ä¸åœ¨è¶…è¿‡ 4M å¹¶è¡Œå¥å­ä¸Šè®­ç»ƒçš„æœ‰ç›‘ç£ SMT ç›¸å½“çš„æ€§èƒ½ã€‚</td><td>Xiangyu Duan   Baijun Ji   Hao Jia   Min Tan   Min Zhang   Boxing Chen   Weihua Luo   Yue Zhang</td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11867&#39;]">Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation</a></td><td></td><td><a href="https://github.com/bzhangGo/zero">https://github.com/bzhangGo/zero</a></td><td><a href="https://arxiv.org/pdf/2004.11867">https://arxiv.org/pdf/2004.11867</a></td><td>Massively multilingual models for neural machine translation (NMT) are theoretically attractive, but often underperform bilingual models and deliver poor zero-shot translations. In this paper, we explore ways to improve them. We argue that multilingual NMT requires stronger modeling capacity to support language pairs with varying typological characteristics, and overcome this bottleneck via language-specific components and deepening NMT architectures. We identify the off-target translation issue (i.e. translating into a wrong target language) as the major source of the inferior zero-shot performance, and propose random online backtranslation to enforce the translation of unseen training language pairs. Experiments on OPUS-100 (a novel multilingual dataset with 100 languages) show that our approach substantially narrows the performance gap with bilingual models in both one-to-many and many-to-many settings, and improves zero-shot performance by ~10 BLEU, approaching conventional pivot-based methods.</td><td>ç”¨äºç¥ç»æœºå™¨ç¿»è¯‘ (NMT) çš„å¤§è§„æ¨¡å¤šè¯­è¨€æ¨¡å‹åœ¨ç†è®ºä¸Šå¾ˆæœ‰å¸å¼•åŠ›ï¼Œä½†é€šå¸¸è¡¨ç°ä¸å¦‚åŒè¯­æ¨¡å‹å¹¶ä¸”æä¾›ç³Ÿç³•çš„é›¶æ ·æœ¬ç¿»è¯‘ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†æ”¹è¿›å®ƒä»¬çš„æ–¹æ³•ã€‚æˆ‘ä»¬è®¤ä¸ºå¤šè¯­è¨€ NMT éœ€è¦æ›´å¼ºçš„å»ºæ¨¡èƒ½åŠ›æ¥æ”¯æŒå…·æœ‰ä¸åŒç±»å‹ç‰¹å¾çš„è¯­è¨€å¯¹ï¼Œå¹¶é€šè¿‡ç‰¹å®šäºè¯­è¨€çš„ç»„ä»¶å’Œæ·±åŒ– NMT æ¶æ„æ¥å…‹æœè¿™ä¸€ç“¶é¢ˆã€‚æˆ‘ä»¬å°†è„±é¶ç¿»è¯‘é—®é¢˜ï¼ˆå³ç¿»è¯‘æˆé”™è¯¯çš„ç›®æ ‡è¯­è¨€ï¼‰ç¡®å®šä¸ºè¾ƒå·®çš„é›¶æ ·æœ¬æ€§èƒ½çš„ä¸»è¦æ¥æºï¼Œå¹¶æå‡ºéšæœºåœ¨çº¿åå‘ç¿»è¯‘æ¥å¼ºåˆ¶ç¿»è¯‘çœ‹ä¸è§çš„è®­ç»ƒè¯­è¨€å¯¹ã€‚åœ¨ OPUS-100ï¼ˆä¸€ä¸ªåŒ…å« 100 ç§è¯­è¨€çš„æ–°å‹å¤šè¯­è¨€æ•°æ®é›†ï¼‰ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¤§å¤§ç¼©å°äº†åœ¨ä¸€å¯¹å¤šå’Œå¤šå¯¹å¤šè®¾ç½®ä¸­ä¸åŒè¯­æ¨¡å‹çš„æ€§èƒ½å·®è·ï¼Œå¹¶å°†é›¶æ ·æœ¬æ€§èƒ½æé«˜äº†çº¦ 10 BLEUï¼Œæ¥è¿‘ä¼ ç»Ÿçš„åŸºäºæ¢è½´çš„æ–¹æ³•ã€‚</td><td>Biao Zhang   Philip Williams   Ivan Titov   Rico Sennrich</td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00850&#39;]">ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/lifu-tu/ENGINE">https://github.com/lifu-tu/ENGINE</a></td><td><a href="https://arxiv.org/pdf/2005.00850">https://arxiv.org/pdf/2005.00850</a></td><td>We propose to train a non-autoregressive machine translation model to minimize the energy defined by a pretrained autoregressive model. In particular, we view our non-autoregressive translation system as an inference network (Tu and Gimpel, 2018) trained to minimize the autoregressive teacher energy. This contrasts with the popular approach of training a non-autoregressive model on a distilled corpus consisting of the beam-searched outputs of such a teacher model. Our approach, which we call ENGINE (ENerGy-based Inference NEtworks), achieves state-of-the-art non-autoregressive results on the IWSLT 2014 DE-EN and WMT 2016 RO-EN datasets, approaching the performance of autoregressive models.</td><td>æˆ‘ä»¬å»ºè®®è®­ç»ƒä¸€ä¸ªéè‡ªå›å½’æœºå™¨ç¿»è¯‘æ¨¡å‹ï¼Œä»¥æœ€å°åŒ–ç”±é¢„è®­ç»ƒè‡ªå›å½’æ¨¡å‹å®šä¹‰çš„èƒ½é‡ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„éè‡ªå›å½’ç¿»è¯‘ç³»ç»Ÿè§†ä¸ºä¸€ä¸ªæ¨ç†ç½‘ç»œï¼ˆTu å’Œ Gimpelï¼Œ2018ï¼‰ï¼Œç»è¿‡è®­ç»ƒä»¥æœ€å°åŒ–è‡ªå›å½’æ•™å¸ˆèƒ½é‡ã€‚è¿™ä¸åœ¨ç”±è¿™ç§æ•™å¸ˆæ¨¡å‹çš„æ³¢æŸæœç´¢è¾“å‡ºç»„æˆçš„è’¸é¦è¯­æ–™åº“ä¸Šè®­ç»ƒéè‡ªå›å½’æ¨¡å‹çš„æµè¡Œæ–¹æ³•å½¢æˆå¯¹æ¯”ã€‚æˆ‘ä»¬ç§°ä¸º ENGINEï¼ˆåŸºäºèƒ½æºçš„æ¨ç†ç½‘ç»œï¼‰çš„æ–¹æ³•åœ¨ IWSLT 2014 DE-EN å’Œ WMT 2016 RO-EN æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„éè‡ªå›å½’ç»“æœï¼Œæ¥è¿‘è‡ªå›å½’æ¨¡å‹çš„æ€§èƒ½ã€‚</td><td>Lifu Tu   Richard Yuanzhe Pang   Sam Wiseman   Kevin Gimpel</td></tr><tr><td>21</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.01313&#39;]">An Effective Approach to Unsupervised Machine Translation</a></td><td></td><td><a href="https://github.com/artetxem/monoses">https://github.com/artetxem/monoses</a></td><td><a href="https://arxiv.org/pdf/1902.01313">https://arxiv.org/pdf/1902.01313</a></td><td>While machine translation has traditionally relied on large amounts of parallel corpora, a recent research line has managed to train both Neural Machine Translation (NMT) and Statistical Machine Translation (SMT) systems using monolingual corpora only. In this paper, we identify and address several deficiencies of existing unsupervised SMT approaches by exploiting subword information, developing a theoretically well founded unsupervised tuning method, and incorporating a joint refinement procedure. Moreover, we use our improved SMT system to initialize a dual NMT model, which is further fine-tuned through on-the-fly back-translation. Together, we obtain large improvements over the previous state-of-the-art in unsupervised machine translation. For instance, we get 22.5 BLEU points in English-to-German WMT 2014, 5.5 points more than the previous best unsupervised system, and 0.5 points more than the (supervised) shared task winner back in 2014.</td><td>è™½ç„¶æœºå™¨ç¿»è¯‘ä¼ ç»Ÿä¸Šä¾èµ–äºå¤§é‡çš„å¹³è¡Œè¯­æ–™åº“ï¼Œä½†æœ€è¿‘çš„ä¸€é¡¹ç ”ç©¶æˆåŠŸåœ°ä»…ä½¿ç”¨å•è¯­è¯­æ–™åº“æ¥è®­ç»ƒç¥ç»æœºå™¨ç¿»è¯‘ (NMT) å’Œç»Ÿè®¡æœºå™¨ç¿»è¯‘ (SMT) ç³»ç»Ÿã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨å­å­—ä¿¡æ¯ã€å¼€å‘ç†è®ºä¸Šæœ‰å……åˆ†æ ¹æ®çš„æ— ç›‘ç£è°ƒæ•´æ–¹æ³•å¹¶ç»“åˆè”åˆç»†åŒ–ç¨‹åºæ¥è¯†åˆ«å’Œè§£å†³ç°æœ‰æ— ç›‘ç£ SMT æ–¹æ³•çš„å‡ ä¸ªç¼ºé™·ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨æ”¹è¿›çš„ SMT ç³»ç»Ÿæ¥åˆå§‹åŒ–åŒ NMT æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡åŠ¨æ€åå‘ç¿»è¯‘è¿›ä¸€æ­¥å¾®è°ƒã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬åœ¨æ— ç›‘ç£æœºå™¨ç¿»è¯‘æ–¹é¢æ¯”ä»¥å‰çš„æœ€æ–°æŠ€æœ¯å–å¾—äº†å¾ˆå¤§çš„æ”¹è¿›ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬åœ¨ English-to-German WMT 2014 ä¸­è·å¾— 22.5 BLEU åˆ†ï¼Œæ¯”ä¹‹å‰æœ€å¥½çš„æ— ç›‘ç£ç³»ç»Ÿå¤š 5.5 åˆ†ï¼Œæ¯” 2014 å¹´çš„ï¼ˆç›‘ç£ï¼‰å…±äº«ä»»åŠ¡è·èƒœè€…å¤š 0.5 åˆ†ã€‚</td><td>Mikel Artetxe   Gorka Labaka   Eneko Agirre</td></tr><tr><td>22</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.05979&#39;]">When a Good Translation is Wrong in Context: Context-Aware Machine Translation Improves on Deixis, Ellipsis, and Lexical Cohesion</a></td><td></td><td><a href="https://github.com/lena-voita/good-translation-wrong-in-context">https://github.com/lena-voita/good-translation-wrong-in-context</a></td><td><a href="https://arxiv.org/pdf/1905.05979">https://arxiv.org/pdf/1905.05979</a></td><td>Though machine translation errors caused by the lack of context beyond one sentence have long been acknowledged, the development of context-aware NMT systems is hampered by several problems. Firstly, standard metrics are not sensitive to improvements in consistency in document-level translations. Secondly, previous work on context-aware NMT assumed that the sentence-aligned parallel data consisted of complete documents while in most practical scenarios such document-level data constitutes only a fraction of the available parallel data. To address the first issue, we perform a human study on an English-Russian subtitles dataset and identify deixis, ellipsis and lexical cohesion as three main sources of inconsistency. We then create test sets targeting these phenomena. To address the second shortcoming, we consider a set-up in which a much larger amount of sentence-level data is available compared to that aligned at the document level. We introduce a model that is suitable for this scenario and demonstrate major gains over a context-agnostic baseline on our new benchmarks without sacrificing performance as measured with BLEU.</td><td>å°½ç®¡ç”±äºç¼ºä¹ä¸€ä¸ªå¥å­ä¹‹å¤–çš„ä¸Šä¸‹æ–‡è€Œå¯¼è‡´æœºå™¨ç¿»è¯‘é”™è¯¯æ—©å·²å¾—åˆ°æ‰¿è®¤ï¼Œä½†ä¸Šä¸‹æ–‡æ„ŸçŸ¥ NMT ç³»ç»Ÿçš„å‘å±•å—åˆ°å‡ ä¸ªé—®é¢˜çš„é˜»ç¢ã€‚é¦–å…ˆï¼Œæ ‡å‡†æŒ‡æ ‡å¯¹æ–‡æ¡£çº§ç¿»è¯‘ä¸€è‡´æ€§çš„æ”¹è¿›ä¸æ•æ„Ÿã€‚å…¶æ¬¡ï¼Œä¹‹å‰å…³äºä¸Šä¸‹æ–‡æ„ŸçŸ¥ NMT çš„å·¥ä½œå‡è®¾å¥å­å¯¹é½çš„å¹¶è¡Œæ•°æ®ç”±å®Œæ•´çš„æ–‡æ¡£ç»„æˆï¼Œè€Œåœ¨å¤§å¤šæ•°å®é™…åœºæ™¯ä¸­ï¼Œæ­¤ç±»æ–‡æ¡£çº§æ•°æ®ä»…æ„æˆå¯ç”¨å¹¶è¡Œæ•°æ®çš„ä¸€å°éƒ¨åˆ†ã€‚ä¸ºäº†è§£å†³ç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯¹è‹±ä¿„å­—å¹•æ•°æ®é›†è¿›è¡Œäº†äººç±»ç ”ç©¶ï¼Œå¹¶å°†æŒ‡ç¤ºç¬¦ã€çœç•¥å·å’Œè¯æ±‡è¡”æ¥ç¡®å®šä¸ºä¸ä¸€è‡´çš„ä¸‰ä¸ªä¸»è¦æ¥æºã€‚ç„¶åæˆ‘ä»¬åˆ›å»ºé’ˆå¯¹è¿™äº›ç°è±¡çš„æµ‹è¯•é›†ã€‚ä¸ºäº†è§£å†³ç¬¬äºŒä¸ªç¼ºç‚¹ï¼Œæˆ‘ä»¬è€ƒè™‘äº†ä¸€ç§è®¾ç½®ï¼Œå…¶ä¸­ä¸åœ¨æ–‡æ¡£çº§åˆ«å¯¹é½çš„æ•°æ®ç›¸æ¯”ï¼Œå¯ç”¨çš„å¥å­çº§åˆ«æ•°æ®è¦å¤šå¾—å¤šã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªé€‚ç”¨äºè¿™ç§æƒ…å†µçš„æ¨¡å‹ï¼Œå¹¶åœ¨ä¸ç‰ºç‰²ä½¿ç”¨ BLEU æµ‹é‡çš„æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œåœ¨æˆ‘ä»¬çš„æ–°åŸºå‡†æµ‹è¯•ä¸­å±•ç¤ºäº†ç›¸å¯¹äºä¸Šä¸‹æ–‡æ— å…³åŸºçº¿çš„ä¸»è¦æ”¶ç›Šã€‚</td><td>Elena Voita   Rico Sennrich   Ivan Titov</td></tr><tr><td>23</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.02780&#39;]">Syntactically Supervised Transformers for Faster Neural Machine Translation</a></td><td></td><td><a href="https://github.com/dojoteef/synst">https://github.com/dojoteef/synst</a></td><td><a href="https://arxiv.org/pdf/1906.02780">https://arxiv.org/pdf/1906.02780</a></td><td>Standard decoders for neural machine translation autoregressively generate a single target token per time step, which slows inference especially for long outputs. While architectural advances such as the Transformer fully parallelize the decoder computations at training time, inference still proceeds sequentially. Recent developments in non- and semi- autoregressive decoding produce multiple tokens per time step independently of the others, which improves inference speed but deteriorates translation quality. In this work, we propose the syntactically supervised Transformer (SynST), which first autoregressively predicts a chunked parse tree before generating all of the target tokens in one shot conditioned on the predicted parse. A series of controlled experiments demonstrates that SynST decodes sentences ~ 5x faster than the baseline autoregressive Transformer while achieving higher BLEU scores than most competing methods on En-De and En-Fr datasets.</td><td>ç”¨äºç¥ç»æœºå™¨ç¿»è¯‘çš„æ ‡å‡†è§£ç å™¨åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿è‡ªåŠ¨å›å½’ç”Ÿæˆå•ä¸ªç›®æ ‡æ ‡è®°ï¼Œè¿™ä¼šå‡æ…¢æ¨ç†é€Ÿåº¦ï¼Œå°¤å…¶æ˜¯å¯¹äºé•¿è¾“å‡ºã€‚è™½ç„¶è¯¸å¦‚ Transformer ä¹‹ç±»çš„æ¶æ„è¿›æ­¥åœ¨è®­ç»ƒæ—¶å®Œå…¨å¹¶è¡ŒåŒ–äº†è§£ç å™¨è®¡ç®—ï¼Œä½†æ¨ç†ä»ç„¶æŒ‰é¡ºåºè¿›è¡Œã€‚éè‡ªå›å½’è§£ç å’ŒåŠè‡ªå›å½’è§£ç çš„æœ€æ–°å‘å±•åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿ç”Ÿæˆå¤šä¸ªæ ‡è®°ï¼Œç‹¬ç«‹äºå…¶ä»–æ ‡è®°ï¼Œè¿™æé«˜äº†æ¨ç†é€Ÿåº¦ï¼Œä½†é™ä½äº†ç¿»è¯‘è´¨é‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å¥æ³•ç›‘ç£çš„ Transformer (SynST)ï¼Œå®ƒé¦–å…ˆè‡ªå›å½’é¢„æµ‹ä¸€ä¸ªåˆ†å—çš„è§£ææ ‘ï¼Œç„¶ååœ¨ä¸€æ¬¡ä»¥é¢„æµ‹è§£æä¸ºæ¡ä»¶çš„é•œå¤´ä¸­ç”Ÿæˆæ‰€æœ‰ç›®æ ‡æ ‡è®°ã€‚ä¸€ç³»åˆ—å—æ§å®éªŒè¡¨æ˜ï¼ŒSynST è§£ç å¥å­çš„é€Ÿåº¦æ¯”åŸºçº¿è‡ªå›å½’ Transformer å¿« 5 å€ï¼ŒåŒæ—¶åœ¨ En-De å’Œ En-Fr æ•°æ®é›†ä¸Šè·å¾—æ¯”å¤§å¤šæ•°ç«äº‰æ–¹æ³•æ›´é«˜çš„ BLEU åˆ†æ•°ã€‚</td><td>Nader Akoury   Kalpesh Krishna   Mohit Iyyer</td></tr><tr><td>24</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/2106.08680&#39;, &#39;https://arxiv.org/abs/1906.00591&#39;]">Evaluating Gender Bias in Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.08680">https://arxiv.org/pdf/2106.08680</a></td><td>With language models being deployed increasingly in the real world, it is essential to address the issue of the fairness of their outputs. The word embedding representations of these language models often implicitly draw unwanted associations that form a social bias within the model. The nature of gendered languages like Hindi, poses an additional problem to the quantification and mitigation of bias, owing to the change in the form of the words in the sentence, based on the gender of the subject. Additionally, there is sparse work done in the realm of measuring and debiasing systems for Indic languages. In our work, we attempt to evaluate and quantify the gender bias within a Hindi-English machine translation system. We implement a modified version of the existing TGBI metric based on the grammatical considerations for Hindi. We also compare and contrast the resulting bias measurements across multiple metrics for pre-trained embeddings and the ones learned by our machine translation model.</td><td>éšç€è¯­è¨€æ¨¡å‹åœ¨ç°å®ä¸–ç•Œä¸­è¶Šæ¥è¶Šå¤šåœ°éƒ¨ç½²ï¼Œè§£å†³å…¶è¾“å‡ºçš„å…¬å¹³æ€§é—®é¢˜è‡³å…³é‡è¦ã€‚è¿™äº›è¯­è¨€æ¨¡å‹çš„è¯åµŒå…¥è¡¨ç¤ºé€šå¸¸ä¼šéšå«åœ°ç»˜åˆ¶ä¸éœ€è¦çš„å…³è”ï¼Œä»è€Œåœ¨æ¨¡å‹å†…å½¢æˆç¤¾ä¼šåè§ã€‚ç”±äºåŸºäºä¸»é¢˜çš„æ€§åˆ«ï¼Œå¥å­ä¸­å•è¯çš„å½¢å¼å‘ç”Ÿäº†å˜åŒ–ï¼Œåƒå°åœ°è¯­è¿™æ ·çš„æ€§åˆ«åŒ–è¯­è¨€çš„æ€§è´¨ç»™åè§çš„é‡åŒ–å’Œç¼“è§£å¸¦æ¥äº†é¢å¤–çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œåœ¨å°åº¦è¯­è¨€çš„æµ‹é‡å’Œå»åå·®ç³»ç»Ÿé¢†åŸŸå®Œæˆçš„å·¥ä½œå¾ˆå°‘ã€‚åœ¨æˆ‘ä»¬çš„å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å°è¯•è¯„ä¼°å’Œé‡åŒ–å°åœ°è¯­-è‹±è¯­æœºå™¨ç¿»è¯‘ç³»ç»Ÿä¸­çš„æ€§åˆ«åè§ã€‚æˆ‘ä»¬åŸºäºå°åœ°è¯­çš„è¯­æ³•è€ƒè™‘å®æ–½äº†ç°æœ‰ TGBI æŒ‡æ ‡çš„ä¿®æ”¹ç‰ˆæœ¬ã€‚æˆ‘ä»¬è¿˜æ¯”è¾ƒå’Œå¯¹æ¯”äº†é¢„è®­ç»ƒåµŒå…¥å’Œæˆ‘ä»¬çš„æœºå™¨ç¿»è¯‘æ¨¡å‹å­¦ä¹ çš„åµŒå…¥çš„å¤šä¸ªæŒ‡æ ‡çš„åå·®æµ‹é‡ç»“æœã€‚</td><td>Gauri Gupta   Krithika Ramesh   Sanjay Singh   Gabriel Stanovsky   Noah A. Smith   Luke Zettlemoyer</td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01787&#39;]">Learning Deep Transformer Models for Machine Translation</a></td><td></td><td><a href="https://github.com/wangqiangneu/dlcl">https://github.com/wangqiangneu/dlcl</a></td><td><a href="https://arxiv.org/pdf/1906.01787">https://arxiv.org/pdf/1906.01787</a></td><td>Transformer is the state-of-the-art model in recent machine translation evaluations. Two strands of research are promising to improve models of this kind: the first uses wide networks (a.k.a. Transformer-Big) and has been the de facto standard for the development of the Transformer system, and the other uses deeper language representation but faces the difficulty arising from learning deep networks. Here, we continue the line of research on the latter. We claim that a truly deep Transformer model can surpass the Transformer-Big counterpart by 1) proper use of layer normalization and 2) a novel way of passing the combination of previous layers to the next. On WMTâ€™16 English- German, NIST OpenMTâ€™12 Chinese-English and larger WMTâ€™18 Chinese-English tasks, our deep system (30/25-layer encoder) outperforms the shallow Transformer-Big/Base baseline (6-layer encoder) by 0.4-2.4 BLEU points. As another bonus, the deep model is 1.6X smaller in size and 3X faster in training than Transformer-Big.</td><td>Transformer æ˜¯æœ€è¿‘æœºå™¨ç¿»è¯‘è¯„ä¼°ä¸­æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚æœ‰ä¸¤æ–¹é¢çš„ç ”ç©¶æœ‰æœ›æ”¹è¿›æ­¤ç±»æ¨¡å‹ï¼šä¸€æ˜¯ä½¿ç”¨å®½ç½‘ç»œï¼ˆåˆå Transformer-Bigï¼‰å¹¶ä¸”å·²ç»æˆä¸º Transformer ç³»ç»Ÿå¼€å‘çš„äº‹å®ä¸Šçš„æ ‡å‡†ï¼Œå¦ä¸€æ–¹é¢ä½¿ç”¨æ›´æ·±å±‚æ¬¡çš„è¯­è¨€è¡¨ç¤ºä½†é¢ä¸´å›°éš¾æºäºå­¦ä¹ æ·±åº¦ç½‘ç»œã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç»§ç»­å¯¹åè€…è¿›è¡Œç ”ç©¶ã€‚æˆ‘ä»¬å£°ç§°ï¼Œä¸€ä¸ªçœŸæ­£çš„æ·±åº¦ Transformer æ¨¡å‹å¯ä»¥é€šè¿‡ 1) æ­£ç¡®ä½¿ç”¨å±‚å½’ä¸€åŒ–å’Œ 2) ä¸€ç§å°†å‰ä¸€å±‚çš„ç»„åˆä¼ é€’åˆ°ä¸‹ä¸€å±‚çš„æ–°æ–¹æ³•æ¥è¶…è¶Š Transformer-Big å¯¹åº”ç‰©ã€‚åœ¨ WMTâ€™16 English-Germanã€NIST OpenMTâ€™12 Chinese-English å’Œæ›´å¤§çš„ WMTâ€™18 Chinese-English ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬çš„æ·±å±‚ç³»ç»Ÿï¼ˆ30/25 å±‚ç¼–ç å™¨ï¼‰ä¼˜äºæµ…å±‚ Transformer-Big/Base åŸºçº¿ï¼ˆ6 å±‚ç¼–ç å™¨ï¼‰ ) 0.4-2.4 BLEU ç‚¹ã€‚ä½œä¸ºå¦ä¸€ä¸ªå¥½å¤„ï¼Œæ·±åº¦æ¨¡å‹çš„å¤§å°æ¯” Transformer-Big å° 1.6 å€ï¼Œè®­ç»ƒé€Ÿåº¦å¿« 3 å€ã€‚</td><td>Qiang Wang   Bei Li   Tong Xiao   Jingbo Zhu   Changliang Li   Derek F. Wong   Lidia S. Chao</td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00376&#39;]">Domain Adaptation of Neural Machine Translation by Lexicon Induction</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.00376">https://arxiv.org/pdf/1906.00376</a></td><td>It has been previously noted that neural machine translation (NMT) is very sensitive to domain shift. In this paper, we argue that this is a dual effect of the highly lexicalized nature of NMT, resulting in failure for sentences with large numbers of unknown words, and lack of supervision for domain-specific words. To remedy this problem, we propose an unsupervised adaptation method which fine-tunes a pre-trained out-of-domain NMT model using a pseudo-in-domain corpus. Specifically, we perform lexicon induction to extract an in-domain lexicon, and construct a pseudo-parallel in-domain corpus by performing word-for-word back-translation of monolingual in-domain target sentences. In five domains over twenty pairwise adaptation settings and two model architectures, our method achieves consistent improvements without using any in-domain parallel sentences, improving up to 14 BLEU over unadapted models, and up to 2 BLEU over strong back-translation baselines.</td><td>ä¹‹å‰å·²ç»æ³¨æ„åˆ°ç¥ç»æœºå™¨ç¿»è¯‘ (NMT) å¯¹åŸŸè½¬ç§»éå¸¸æ•æ„Ÿã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯ NMT é«˜åº¦è¯æ±‡åŒ–æ€§è´¨çš„åŒé‡å½±å“ï¼Œå¯¼è‡´å…·æœ‰å¤§é‡æœªçŸ¥å•è¯çš„å¥å­å¤±è´¥ï¼Œä»¥åŠç¼ºä¹å¯¹ç‰¹å®šé¢†åŸŸå•è¯çš„ç›‘ç£ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„è‡ªé€‚åº”æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ä¼ªåŸŸå†…è¯­æ–™åº“å¯¹é¢„è®­ç»ƒçš„åŸŸå¤– NMT æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è¿›è¡Œè¯å…¸å½’çº³ä»¥æå–åŸŸå†…è¯å…¸ï¼Œå¹¶é€šè¿‡å¯¹å•è¯­åŸŸå†…ç›®æ ‡å¥å­è¿›è¡Œé€å­—åå‘ç¿»è¯‘æ¥æ„å»ºä¼ªå¹³è¡ŒåŸŸå†…è¯­æ–™åº“ã€‚åœ¨è¶…è¿‡ 20 ä¸ªæˆå¯¹é€‚åº”è®¾ç½®å’Œä¸¤ä¸ªæ¨¡å‹æ¶æ„çš„äº”ä¸ªåŸŸä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸ä½¿ç”¨ä»»ä½•åŸŸå†…å¹¶è¡Œè¯­å¥çš„æƒ…å†µä¸‹å®ç°äº†ä¸€è‡´çš„æ”¹è¿›ï¼Œåœ¨æœªé€‚åº”æ¨¡å‹ä¸Šæé«˜äº† 14 ä¸ª BLEUï¼Œåœ¨å¼ºåå‘ç¿»è¯‘åŸºçº¿ä¸Šæé«˜äº† 2 ä¸ª BLEUã€‚</td><td>Junjie Hu   Mengzhou Xia   Graham Neubig   Jaime Carbonell</td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.09444&#39;]">Retrieving Sequential Information for Non-Autoregressive Neural Machine Translation</a></td><td></td><td><a href="https://github.com/ictnlp/RSI-NAT">https://github.com/ictnlp/RSI-NAT</a></td><td><a href="https://arxiv.org/pdf/1906.09444">https://arxiv.org/pdf/1906.09444</a></td><td>Non-Autoregressive Transformer (NAT) aims to accelerate the Transformer model through discarding the autoregressive mechanism and generating target words independently, which fails to exploit the target sequential information. Over-translation and under-translation errors often occur for the above reason, especially in the long sentence translation scenario. In this paper, we propose two approaches to retrieve the target sequential information for NAT to enhance its translation ability while preserving the fast-decoding property. Firstly, we propose a sequence-level training method based on a novel reinforcement algorithm for NAT (Reinforce-NAT) to reduce the variance and stabilize the training procedure. Secondly, we propose an innovative Transformer decoder named FS-decoder to fuse the target sequential information into the top layer of the decoder. Experimental results on three translation tasks show that the Reinforce-NAT surpasses the baseline NAT system by a significant margin on BLEU without decelerating the decoding speed and the FS-decoder achieves comparable translation performance to the autoregressive Transformer with considerable speedup.</td><td>Non-Autoregressive Transformer (NAT) æ—¨åœ¨é€šè¿‡ä¸¢å¼ƒè‡ªå›å½’æœºåˆ¶å¹¶ç‹¬ç«‹ç”Ÿæˆç›®æ ‡è¯æ¥åŠ é€Ÿ Transformer æ¨¡å‹ï¼Œè¿™æ— æ³•åˆ©ç”¨ç›®æ ‡åºåˆ—ä¿¡æ¯ã€‚ç”±äºä¸Šè¿°åŸå› ï¼Œç»å¸¸ä¼šå‡ºç°è¿‡åº¦ç¿»è¯‘å’Œç¿»è¯‘ä¸è¶³çš„é”™è¯¯ï¼Œå°¤å…¶æ˜¯åœ¨é•¿å¥ç¿»è¯‘åœºæ™¯ä¸­ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ–¹æ³•æ¥æ£€ç´¢ NAT çš„ç›®æ ‡åºåˆ—ä¿¡æ¯ï¼Œä»¥å¢å¼ºå…¶ç¿»è¯‘èƒ½åŠ›ï¼ŒåŒæ—¶ä¿ç•™å¿«é€Ÿè§£ç ç‰¹æ€§ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ–°çš„ NAT å¼ºåŒ–ç®—æ³•ï¼ˆReinforce-NATï¼‰çš„åºåˆ—çº§è®­ç»ƒæ–¹æ³•ï¼Œä»¥å‡å°‘æ–¹å·®å¹¶ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸º FS-decoder çš„åˆ›æ–° Transformer è§£ç å™¨ï¼Œå°†ç›®æ ‡åºåˆ—ä¿¡æ¯èåˆåˆ°è§£ç å™¨çš„é¡¶å±‚ã€‚åœ¨ä¸‰ä¸ªç¿»è¯‘ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸é™ä½è§£ç é€Ÿåº¦çš„æƒ…å†µä¸‹ï¼ŒReinforce-NAT åœ¨ BLEU ä¸Šå¤§å¤§è¶…è¿‡äº†åŸºçº¿ NAT ç³»ç»Ÿï¼Œå¹¶ä¸” FS-decoder ä»¥ç›¸å½“å¤§çš„é€Ÿåº¦å®ç°äº†ä¸è‡ªå›å½’ Transformer ç›¸å½“çš„ç¿»è¯‘æ€§èƒ½ã€‚</td><td>Chenze Shao   Yang Feng   Jinchao Zhang   Fandong Meng   Xilin Chen   Jie Zhou</td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1810.06729&#39;]">Robust Neural Machine Translation with Joint Textual and Phonetic Embedding</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1810.06729">https://arxiv.org/pdf/1810.06729</a></td><td>Neural machine translation (NMT) is notoriously sensitive to noises, but noises are almost inevitable in practice. One special kind of noise is the homophone noise, where words are replaced by other words with similar pronunciations. We propose to improve the robustness of NMT to homophone noises by 1) jointly embedding both textual and phonetic information of source sentences, and 2) augmenting the training dataset with homophone noises. Interestingly, to achieve better translation quality and more robustness, we found that most (though not all) weights should be put on the phonetic rather than textual information. Experiments show that our method not only significantly improves the robustness of NMT to homophone noises, but also surprisingly improves the translation quality on some clean test sets.</td><td>ä¼—æ‰€å‘¨çŸ¥ï¼Œç¥ç»æœºå™¨ç¿»è¯‘ (NMT) å¯¹å™ªéŸ³éå¸¸æ•æ„Ÿï¼Œä½†åœ¨å®è·µä¸­å™ªéŸ³å‡ ä¹æ˜¯ä¸å¯é¿å…çš„ã€‚ä¸€ç§ç‰¹æ®Šçš„å™ªéŸ³æ˜¯åŒéŸ³å™ªéŸ³ï¼Œå…¶ä¸­å•è¯è¢«å…¶ä»–å…·æœ‰ç›¸ä¼¼å‘éŸ³çš„å•è¯æ›¿æ¢ã€‚æˆ‘ä»¬å»ºè®®é€šè¿‡ 1) è”åˆåµŒå…¥æºå¥å­çš„æ–‡æœ¬å’Œè¯­éŸ³ä¿¡æ¯ï¼Œä»¥åŠ 2) ç”¨åŒéŸ³å™ªå£°å¢å¼ºè®­ç»ƒæ•°æ®é›†æ¥æé«˜ NMT å¯¹åŒéŸ³å™ªå£°çš„é²æ£’æ€§ã€‚æœ‰è¶£çš„æ˜¯ï¼Œä¸ºäº†è·å¾—æ›´å¥½çš„ç¿»è¯‘è´¨é‡å’Œæ›´å¼ºçš„é²æ£’æ€§ï¼Œæˆ‘ä»¬å‘ç°å¤§å¤šæ•°ï¼ˆå°½ç®¡ä¸æ˜¯å…¨éƒ¨ï¼‰æƒé‡åº”è¯¥æ”¾åœ¨è¯­éŸ³ä¿¡æ¯è€Œä¸æ˜¯æ–‡æœ¬ä¿¡æ¯ä¸Šã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…æ˜¾ç€æé«˜äº† NMT å¯¹åŒéŸ³å­—å™ªå£°çš„é²æ£’æ€§ï¼Œè€Œä¸”è¿˜ä»¤äººæƒŠè®¶åœ°æé«˜äº†ä¸€äº›å¹²å‡€æµ‹è¯•é›†çš„ç¿»è¯‘è´¨é‡ã€‚</td><td>Hairong Liu   Mingbo Ma   Liang Huang   Hao Xiong   Zhongjun He</td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.13872&#39;]">Simple and Effective Paraphrastic Similarity from Parallel Translations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.13872">https://arxiv.org/pdf/1909.13872</a></td><td>We present a model and methodology for learning paraphrastic sentence embeddings directly from bitext, removing the time-consuming intermediate step of creating paraphrase corpora. Further, we show that the resulting model can be applied to cross-lingual tasks where it both outperforms and is orders of magnitude faster than more complex state-of-the-art baselines.</td><td></td><td>John Wieting   Kevin Gimpel   Graham Neubig   Taylor Berg-Kirkpatrick</td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.04980&#39;]">Unsupervised Question Answering by Cloze Translation</a></td><td></td><td><a href="https://github.com/facebookresearch/UnsupervisedQA">https://github.com/facebookresearch/UnsupervisedQA</a></td><td><a href="https://arxiv.org/pdf/1906.04980">https://arxiv.org/pdf/1906.04980</a></td><td>Obtaining training data for Question Answering (QA) is time-consuming and resource-intensive, and existing QA datasets are only available for limited domains and languages. In this work, we explore to what extent high quality training data is actually required for Extractive QA, and investigate the possibility of unsupervised Extractive QA. We approach this problem by first learning to generate context, question and answer triples in an unsupervised manner, which we then use to synthesize Extractive QA training data automatically. To generate such triples, we first sample random context paragraphs from a large corpus of documents and then random noun phrases or named entity mentions from these paragraphs as answers. Next we convert answers in context to â€œfill-in-the-blankâ€ cloze questions and finally translate them into natural questions. We propose and compare various unsupervised ways to perform cloze-to-natural question translation, including training an unsupervised NMT model using non-aligned corpora of natural questions and cloze questions as well as a rule-based approach. We find that modern QA models can learn to answer human questions surprisingly well using only synthetic training data. We demonstrate that, without using the SQuAD training data at all, our approach achieves 56.4 F1 on SQuAD v1 (64.5 F1 when the answer is a Named entity mention), outperforming early supervised models.</td><td>è·å–é—®ç­” (QA) çš„è®­ç»ƒæ•°æ®æ—¢è€—æ—¶åˆè€—è´¹èµ„æºï¼Œç°æœ‰çš„ QA æ•°æ®é›†ä»…é€‚ç”¨äºæœ‰é™çš„é¢†åŸŸå’Œè¯­è¨€ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº† Extractive QA åœ¨å¤šå¤§ç¨‹åº¦ä¸Šéœ€è¦é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œå¹¶ç ”ç©¶äº†æ— ç›‘ç£ Extractive QA çš„å¯èƒ½æ€§ã€‚æˆ‘ä»¬é€šè¿‡é¦–å…ˆå­¦ä¹ ä»¥æ— ç›‘ç£çš„æ–¹å¼ç”Ÿæˆä¸Šä¸‹æ–‡ã€é—®é¢˜å’Œç­”æ¡ˆä¸‰å…ƒç»„æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç„¶åæˆ‘ä»¬å°†å…¶ç”¨äºè‡ªåŠ¨åˆæˆæå– QA è®­ç»ƒæ•°æ®ã€‚ä¸ºäº†ç”Ÿæˆè¿™æ ·çš„ä¸‰å…ƒç»„ï¼Œæˆ‘ä»¬é¦–å…ˆä»å¤§å‹æ–‡æ¡£è¯­æ–™åº“ä¸­éšæœºæŠ½å–ä¸Šä¸‹æ–‡æ®µè½ï¼Œç„¶åä»è¿™äº›æ®µè½ä¸­éšæœºæŠ½å–åè¯çŸ­è¯­æˆ–å‘½åå®ä½“ä½œä¸ºç­”æ¡ˆã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä¸Šä¸‹æ–‡ä¸­çš„ç­”æ¡ˆè½¬æ¢ä¸ºâ€œå¡«ç©ºâ€å®Œå½¢å¡«ç©ºé¢˜ï¼Œæœ€åå°†å®ƒä»¬è½¬æ¢ä¸ºè‡ªç„¶é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºå¹¶æ¯”è¾ƒäº†æ‰§è¡Œå®Œå½¢å¡«ç©ºåˆ°è‡ªç„¶é—®é¢˜ç¿»è¯‘çš„å„ç§æ— ç›‘ç£æ–¹æ³•ï¼ŒåŒ…æ‹¬ä½¿ç”¨è‡ªç„¶é—®é¢˜å’Œå®Œå½¢å¡«ç©ºé—®é¢˜çš„éå¯¹é½è¯­æ–™åº“ä»¥åŠåŸºäºè§„åˆ™çš„æ–¹æ³•è®­ç»ƒæ— ç›‘ç£ NMT æ¨¡å‹ã€‚æˆ‘ä»¬å‘ç°ç°ä»£ QA æ¨¡å‹å¯ä»¥å­¦ä¹ ä»…ä½¿ç”¨åˆæˆè®­ç»ƒæ•°æ®å°±å‡ºäººæ„æ–™åœ°å¾ˆå¥½åœ°å›ç­”äººç±»é—®é¢˜ã€‚æˆ‘ä»¬è¯æ˜ï¼Œåœ¨å®Œå…¨ä¸ä½¿ç”¨ SQuAD è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ SQuAD v1 ä¸Šè¾¾åˆ°äº† 56.4 F1ï¼ˆå½“ç­”æ¡ˆæ˜¯å‘½åå®ä½“æåŠæ—¶ä¸º 64.5 F1ï¼‰ï¼Œä¼˜äºæ—©æœŸçš„ç›‘ç£æ¨¡å‹ã€‚</td><td>Patrick Lewis   Ludovic Denoyer   Sebastian Riedel</td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.10761&#39;]">Bilingual Lexicon Induction through Unsupervised Machine Translation</a></td><td></td><td><a href="https://github.com/artetxem/monoses">https://github.com/artetxem/monoses</a></td><td><a href="https://arxiv.org/pdf/1907.10761">https://arxiv.org/pdf/1907.10761</a></td><td>A recent research line has obtained strong results on bilingual lexicon induction by aligning independently trained word embeddings in two languages and using the resulting cross-lingual embeddings to induce word translation pairs through nearest neighbor or related retrieval methods. In this paper, we propose an alternative approach to this problem that builds on the recent work on unsupervised machine translation. This way, instead of directly inducing a bilingual lexicon from cross-lingual embeddings, we use them to build a phrase-table, combine it with a language model, and use the resulting machine translation system to generate a synthetic parallel corpus, from which we extract the bilingual lexicon using statistical word alignment techniques. As such, our method can work with any word embedding and cross-lingual mapping technique, and it does not require any additional resource besides the monolingual corpus used to train the embeddings. When evaluated on the exact same cross-lingual embeddings, our proposed method obtains an average improvement of 6 accuracy points over nearest neighbor and 4 points over CSLS retrieval, establishing a new state-of-the-art in the standard MUSE dataset.</td><td>æœ€è¿‘çš„ä¸€æ¡ç ”ç©¶çº¿é€šè¿‡å¯¹é½ä¸¤ç§è¯­è¨€ä¸­ç‹¬ç«‹è®­ç»ƒçš„è¯åµŒå…¥å¹¶ä½¿ç”¨äº§ç”Ÿçš„è·¨è¯­è¨€åµŒå…¥é€šè¿‡æœ€è¿‘é‚»æˆ–ç›¸å…³æ£€ç´¢æ–¹æ³•æ¥è¯±å¯¼è¯ç¿»è¯‘å¯¹ï¼Œåœ¨åŒè¯­è¯å…¸å½’çº³æ–¹é¢å–å¾—äº†å¾ˆå¥½çš„æˆæœã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›¿ä»£æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¯¥æ–¹æ³•å»ºç«‹åœ¨æœ€è¿‘å…³äºæ— ç›‘ç£æœºå™¨ç¿»è¯‘çš„å·¥ä½œåŸºç¡€ä¸Šã€‚è¿™æ ·ï¼Œæˆ‘ä»¬ä¸æ˜¯ç›´æ¥ä»è·¨è¯­è¨€åµŒå…¥ä¸­å½’çº³å‡ºåŒè¯­è¯å…¸ï¼Œè€Œæ˜¯ä½¿ç”¨å®ƒä»¬æ¥æ„å»ºçŸ­è¯­è¡¨ï¼Œå°†å…¶ä¸è¯­è¨€æ¨¡å‹ç»“åˆï¼Œå¹¶ä½¿ç”¨ç”Ÿæˆçš„æœºå™¨ç¿»è¯‘ç³»ç»Ÿç”Ÿæˆåˆæˆå¹³è¡Œè¯­æ–™åº“ï¼Œä»ä¸­æˆ‘ä»¬ä½¿ç”¨ç»Ÿè®¡è¯å¯¹é½æŠ€æœ¯æå–åŒè¯­è¯å…¸ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ä¸ä»»ä½•è¯åµŒå…¥å’Œè·¨è¯­è¨€æ˜ å°„æŠ€æœ¯ä¸€èµ·ä½¿ç”¨ï¼Œé™¤äº†ç”¨äºè®­ç»ƒåµŒå…¥çš„å•è¯­è¯­æ–™åº“ä¹‹å¤–ï¼Œå®ƒä¸éœ€è¦ä»»ä½•é¢å¤–çš„èµ„æºã€‚å½“å¯¹å®Œå…¨ç›¸åŒçš„è·¨è¯­è¨€åµŒå…¥è¿›è¡Œè¯„ä¼°æ—¶ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•æ¯”æœ€è¿‘é‚»å¹³å‡æé«˜äº† 6 ä¸ªç²¾åº¦ç‚¹ï¼Œæ¯” CSLS æ£€ç´¢å¹³å‡æé«˜äº† 4 ä¸ªç‚¹ï¼Œåœ¨æ ‡å‡† MUSE æ•°æ®é›†ä¸­å»ºç«‹äº†æ–°çš„æœ€æ–°æŠ€æœ¯ã€‚</td><td>Mikel Artetxe   Gorka Labaka   Eneko Agirre</td></tr><tr><td>32</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.10523&#39;]">Soft Contextual Data Augmentation for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/teslacool/SCA">https://github.com/teslacool/SCA</a></td><td><a href="https://arxiv.org/pdf/1905.10523">https://arxiv.org/pdf/1905.10523</a></td><td>While data augmentation is an important trick to boost the accuracy of deep learning methods in computer vision tasks, its study in natural language tasks is still very limited. In this paper, we present a novel data augmentation method for neural machine translation. Different from previous augmentation methods that randomly drop, swap or replace words with other words in a sentence, we softly augment a randomly chosen word in a sentence by its contextual mixture of multiple related words. More accurately, we replace the one-hot representation of a word by a distribution (provided by a language model) over the vocabulary, i.e., replacing the embedding of this word by a weighted combination of multiple semantically similar words. Since the weights of those words depend on the contextual information of the word to be replaced, the newly generated sentences capture much richer information than previous augmentation methods. Experimental results on both small scale and large scale machine translation datasets demonstrate the superiority of our method over strong baselines.</td><td>è™½ç„¶æ•°æ®å¢å¼ºæ˜¯åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­æé«˜æ·±åº¦å­¦ä¹ æ–¹æ³•å‡†ç¡®æ€§çš„é‡è¦æŠ€å·§ï¼Œä½†å®ƒåœ¨è‡ªç„¶è¯­è¨€ä»»åŠ¡ä¸­çš„ç ”ç©¶ä»ç„¶éå¸¸æœ‰é™ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç¥ç»æœºå™¨ç¿»è¯‘æ•°æ®å¢å¼ºæ–¹æ³•ã€‚ä¸ä¹‹å‰éšæœºåˆ é™¤ã€äº¤æ¢æˆ–æ›¿æ¢å¥å­ä¸­çš„å…¶ä»–å•è¯çš„å¢å¼ºæ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬é€šè¿‡å¤šä¸ªç›¸å…³å•è¯çš„ä¸Šä¸‹æ–‡æ··åˆæ¥è½»æŸ”åœ°å¢å¼ºå¥å­ä¸­éšæœºé€‰æ‹©çš„å•è¯ã€‚æ›´å‡†ç¡®åœ°è¯´ï¼Œæˆ‘ä»¬ç”¨è¯æ±‡è¡¨ä¸Šçš„åˆ†å¸ƒï¼ˆç”±è¯­è¨€æ¨¡å‹æä¾›ï¼‰æ›¿æ¢ä¸€ä¸ªè¯çš„ one-hot è¡¨ç¤ºï¼Œå³ç”¨å¤šä¸ªè¯­ä¹‰ç›¸ä¼¼è¯çš„åŠ æƒç»„åˆæ›¿æ¢è¿™ä¸ªè¯çš„åµŒå…¥ã€‚ç”±äºè¿™äº›è¯çš„æƒé‡å–å†³äºè¦æ›¿æ¢çš„è¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå› æ­¤æ–°ç”Ÿæˆçš„å¥å­æ¯”ä»¥å‰çš„å¢å¼ºæ–¹æ³•æ•è·äº†æ›´ä¸°å¯Œçš„ä¿¡æ¯ã€‚åœ¨å°è§„æ¨¡å’Œå¤§è§„æ¨¡æœºå™¨ç¿»è¯‘æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¼ºåŸºçº¿ä¸Šçš„ä¼˜è¶Šæ€§ã€‚</td><td>Jinhua Zhu   Fei Gao   Lijun Wu   Yingce Xia   Tao Qin   Wengang Zhou   Xueqi Cheng   Tie-Yan Liu</td></tr><tr><td>33</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03785&#39;]">Generalized Data Augmentation for Low-Resource Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.03785">https://arxiv.org/pdf/1906.03785</a></td><td>Translation to or from low-resource languages LRLs poses challenges for machine translation in terms of both adequacy and fluency. Data augmentation utilizing large amounts of monolingual data is regarded as an effective way to alleviate these problems. In this paper, we propose a general framework for data augmentation in low-resource machine translation that not only uses target-side monolingual data, but also pivots through a related high-resource language HRL. Specifically, we experiment with a two-step pivoting method to convert high-resource data to the LRL, making use of available resources to better approximate the true data distribution of the LRL. First, we inject LRL words into HRL sentences through an induced bilingual dictionary. Second, we further edit these modified sentences using a modified unsupervised machine translation framework. Extensive experiments on four low-resource datasets show that under extreme low-resource settings, our data augmentation techniques improve translation quality by up to~1.5 to~8 BLEU points compared to supervised back-translation baselines</td><td>ä¸ä½èµ„æºè¯­è¨€ LRL ä¹‹é—´çš„ç¿»è¯‘åœ¨å……åˆ†æ€§å’Œæµç•…æ€§æ–¹é¢å¯¹æœºå™¨ç¿»è¯‘æå‡ºäº†æŒ‘æˆ˜ã€‚åˆ©ç”¨å¤§é‡å•è¯­æ•°æ®çš„æ•°æ®å¢å¼ºè¢«è®¤ä¸ºæ˜¯ç¼“è§£è¿™äº›é—®é¢˜çš„æœ‰æ•ˆæ–¹æ³•ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºä½èµ„æºæœºå™¨ç¿»è¯‘ä¸­æ•°æ®å¢å¼ºçš„é€šç”¨æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸ä»…ä½¿ç”¨ç›®æ ‡ç«¯å•è¯­æ•°æ®ï¼Œè€Œä¸”è¿˜é€šè¿‡ç›¸å…³çš„é«˜èµ„æºè¯­è¨€ HRL è¿›è¡Œæ”¯ç‚¹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°è¯•ä½¿ç”¨ä¸¤æ­¥æ—‹è½¬æ–¹æ³•å°†é«˜èµ„æºæ•°æ®è½¬æ¢ä¸º LRLï¼Œåˆ©ç”¨å¯ç”¨èµ„æºæ›´å¥½åœ°è¿‘ä¼¼ LRL çš„çœŸå®æ•°æ®åˆ†å¸ƒã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡è¯±å¯¼åŒè¯­è¯å…¸å°† LRL è¯æ³¨å…¥ HRL å¥å­ä¸­ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¿®æ”¹åçš„æ— ç›‘ç£æœºå™¨ç¿»è¯‘æ¡†æ¶è¿›ä¸€æ­¥ç¼–è¾‘è¿™äº›ä¿®æ”¹åçš„å¥å­ã€‚å¯¹å››ä¸ªä½èµ„æºæ•°æ®é›†çš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨æç«¯ä½èµ„æºè®¾ç½®ä¸‹ï¼Œä¸æœ‰ç›‘ç£çš„åå‘ç¿»è¯‘åŸºçº¿ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ•°æ®å¢å¼ºæŠ€æœ¯å°†ç¿»è¯‘è´¨é‡æé«˜äº† 1.5 åˆ° 8 ä¸ª BLEU ç‚¹</td><td>Mengzhou Xia   Xiang Kong   Antonios Anastasopoulos   Graham Neubig</td></tr></tbody></table></div><h3 id="EMNLP"><a href="#EMNLP" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.10485&#39;]">Fully Quantized Transformer for Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1910.10485">https://arxiv.org/pdf/1910.10485</a></td><td>State-of-the-art neural machine translation methods employ massive amounts of parameters. Drastically reducing computational costs of such methods without affecting performance has been up to this point unsuccessful. To this end, we propose FullyQT: an all-inclusive quantization strategy for the Transformer. To the best of our knowledge, we are the first to show that it is possible to avoid any loss in translation quality with a fully quantized Transformer. Indeed, compared to full-precision, our 8-bit models score greater or equal BLEU on most tasks. Comparing ourselves to all previously proposed methods, we achieve state-of-the-art quantization results.</td><td>æœ€å…ˆè¿›çš„ç¥ç»æœºå™¨ç¿»è¯‘æ–¹æ³•ä½¿ç”¨å¤§é‡å‚æ•°ã€‚åœ¨ä¸å½±å“æ€§èƒ½çš„æƒ…å†µä¸‹å¤§å¹…é™ä½æ­¤ç±»æ–¹æ³•çš„è®¡ç®—æˆæœ¬åˆ°ç›®å‰ä¸ºæ­¢è¿˜æ²¡æœ‰æˆåŠŸã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº† FullQTï¼šTransformer çš„å…¨åŒ…é‡åŒ–ç­–ç•¥ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æ˜¯ç¬¬ä¸€ä¸ªè¯æ˜ä½¿ç”¨å®Œå…¨é‡åŒ–çš„ Transformer å¯ä»¥é¿å…ç¿»è¯‘è´¨é‡ä¸‹é™çš„äººã€‚äº‹å®ä¸Šï¼Œä¸å…¨ç²¾åº¦ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ 8 ä½æ¨¡å‹åœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸Šçš„å¾—åˆ†æ›´é«˜æˆ–ç­‰äº BLEUã€‚ä¸ä¹‹å‰æå‡ºçš„æ‰€æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬å®ç°äº†æœ€å…ˆè¿›çš„é‡åŒ–ç»“æœã€‚</td><td>Gabriele Prato   Ella Charlaix   Mehdi Rezagholizadeh</td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.10260&#39;]">Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.10260">https://arxiv.org/pdf/2002.10260</a></td><td>Transformer-based models have brought a radical change to neural machine translation. A key feature of the Transformer architecture is the so-called multi-head attention mechanism, which allows the model to focus simultaneously on different parts of the input. However, recent works have shown that most attention heads learn simple, and often redundant, positional patterns. In this paper, we propose to replace all but one attention head of each encoder layer with simple fixed â€” non-learnable â€” attentive patterns that are solely based on position and do not require any external knowledge. Our experiments with different data sizes and multiple language pairs show that fixing the attention heads on the encoder side of the Transformer at training time does not impact the translation quality and even increases BLEU scores by up to 3 points in low-resource scenarios.</td><td>åŸºäº Transformer çš„æ¨¡å‹ç»™ç¥ç»æœºå™¨ç¿»è¯‘å¸¦æ¥äº†æ ¹æœ¬æ€§çš„å˜åŒ–ã€‚ Transformer æ¶æ„çš„ä¸€ä¸ªå…³é”®ç‰¹æ€§æ˜¯æ‰€è°“çš„å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒå…è®¸æ¨¡å‹åŒæ—¶å…³æ³¨è¾“å…¥çš„ä¸åŒéƒ¨åˆ†ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„å·¥ä½œè¡¨æ˜ï¼Œå¤§å¤šæ•°æ³¨æ„åŠ›å¤´å­¦ä¹ ç®€å•çš„ã€é€šå¸¸æ˜¯å†—ä½™çš„ä½ç½®æ¨¡å¼ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å»ºè®®ç”¨ç®€å•çš„å›ºå®šçš„â€”â€”ä¸å¯å­¦ä¹ çš„â€”â€”æ³¨æ„åŠ›æ¨¡å¼æ›¿æ¢æ¯ä¸ªç¼–ç å™¨å±‚çš„é™¤ä¸€ä¸ªæ³¨æ„åŠ›å¤´ä¹‹å¤–çš„æ‰€æœ‰æ³¨æ„åŠ›æ¨¡å¼ï¼Œè¿™äº›æ¨¡å¼å®Œå…¨åŸºäºä½ç½®å¹¶ä¸”ä¸éœ€è¦ä»»ä½•å¤–éƒ¨çŸ¥è¯†ã€‚æˆ‘ä»¬å¯¹ä¸åŒæ•°æ®å¤§å°å’Œå¤šè¯­è¨€å¯¹çš„å®éªŒè¡¨æ˜ï¼Œåœ¨è®­ç»ƒæ—¶å°†æ³¨æ„åŠ›å¤´å›ºå®šåœ¨ Transformer çš„ç¼–ç å™¨ç«¯ä¸ä¼šå½±å“ç¿»è¯‘è´¨é‡ï¼Œç”šè‡³åœ¨ä½èµ„æºåœºæ™¯ä¸­å°† BLEU åˆ†æ•°æé«˜å¤šè¾¾ 3 åˆ†ã€‚</td><td>Alessandro Raganato   Yves Scherrer   JÃ¶rg Tiedemann</td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14109&#39;]">Adversarial Subword Regularization for Robust Neural Machine Translation</a></td><td></td><td><a href="https://github.com/dmis-lab/AdvSR">https://github.com/dmis-lab/AdvSR</a></td><td><a href="https://arxiv.org/pdf/2004.14109">https://arxiv.org/pdf/2004.14109</a></td><td>Exposing diverse subword segmentations to neural machine translation (NMT) models often improves the robustness of machine translation as NMT models can experience various subword candidates. However, the diversification of subword segmentations mostly relies on the pre-trained subword language models from which erroneous segmentations of unseen words are less likely to be sampled. In this paper, we present adversarial subword regularization (ADVSR) to study whether gradient signals during training can be a substitute criterion for exposing diverse subword segmentations. We experimentally show that our model-based adversarial samples effectively encourage NMT models to be less sensitive to segmentation errors and improve the performance of NMT models in low-resource and out-domain datasets.</td><td>å°†ä¸åŒçš„å­è¯åˆ†å‰²æš´éœ²ç»™ç¥ç»æœºå™¨ç¿»è¯‘ (NMT) æ¨¡å‹é€šå¸¸ä¼šæé«˜æœºå™¨ç¿»è¯‘çš„é²æ£’æ€§ï¼Œå› ä¸º NMT æ¨¡å‹å¯ä»¥ä½“éªŒå„ç§å­è¯å€™é€‰ã€‚ç„¶è€Œï¼Œå­è¯åˆ‡åˆ†çš„å¤šæ ·åŒ–ä¸»è¦ä¾èµ–äºé¢„è®­ç»ƒçš„å­è¯è¯­è¨€æ¨¡å‹ï¼Œä»è¿™äº›æ¨¡å‹ä¸­ä¸å¤ªå¯èƒ½å¯¹ä¸å¯è§è¯çš„é”™è¯¯åˆ‡åˆ†è¿›è¡Œé‡‡æ ·ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å¯¹æŠ—æ€§å­è¯æ­£åˆ™åŒ–ï¼ˆADVSRï¼‰æ¥ç ”ç©¶è®­ç»ƒæœŸé—´çš„æ¢¯åº¦ä¿¡å·æ˜¯å¦å¯ä»¥ä½œä¸ºæš´éœ²ä¸åŒå­è¯åˆ†å‰²çš„æ›¿ä»£æ ‡å‡†ã€‚æˆ‘ä»¬é€šè¿‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬åŸºäºæ¨¡å‹çš„å¯¹æŠ—æ ·æœ¬æœ‰æ•ˆåœ°é¼“åŠ± NMT æ¨¡å‹å¯¹åˆ†å‰²é”™è¯¯ä¸é‚£ä¹ˆæ•æ„Ÿï¼Œå¹¶æé«˜äº† NMT æ¨¡å‹åœ¨ä½èµ„æºå’ŒåŸŸå¤–æ•°æ®é›†ä¸­çš„æ€§èƒ½ã€‚</td><td>Jungsoo Park   Mujeen Sung   Jinhyuk Lee   Jaewoo Kang</td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02353&#39;]">Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages</a></td><td></td><td><a href="https://github.com/masakhane-io/masakhane-mt">https://github.com/masakhane-io/masakhane-mt</a></td><td><a href="https://arxiv.org/pdf/2010.02353">https://arxiv.org/pdf/2010.02353</a></td><td>Research in NLP lacks geographic diversity, and the question of how NLP can be scaled to low-resourced languages has not yet been adequately solved. â€œLow-resourcedâ€-ness is a complex problem going beyond data availability and reflects systemic problems in society. In this paper, we focus on the task of Machine Translation (MT), that plays a crucial role for information accessibility and communication worldwide. Despite immense improvements in MT over the past decade, MT is centered around a few high-resourced languages. As MT researchers cannot solve the problem of low-resourcedness alone, we propose participatory research as a means to involve all necessary agents required in the MT development process. We demonstrate the feasibility and scalability of participatory research with a case study on MT for African languages. Its implementation leads to a collection of novel translation datasets, MT benchmarks for over 30 languages, with human evaluations for a third of them, and enables participants without formal training to make a unique scientific contribution. Benchmarks, models, data, code, and evaluation results are released under <a href="https://github.com/masakhane-io/masakhane-mt">https://github.com/masakhane-io/masakhane-mt</a>.</td><td></td><td>Wilhelmina Nekoto   Vukosi Marivate   Tshinondiwa Matsila   Timi Fasubaa   Tajudeen Kolawole   Taiwo Fagbohungbe   Solomon Oluwole Akinola   Shamsuddeen Hassan Muhammad   Salomon Kabongo   Salomey Osei   Sackey Freshia   Rubungo Andre Niyongabo   Ricky Macharm   Perez Ogayo   Orevaoghene Ahia   Musie Meressa   Mofe Adeyemi   Masabata Mokgesi-Selinga   Lawrence Okegbemi   Laura Jane Martinus   Kolawole Tajudeen   Kevin Degila   Kelechi Ogueji   Kathleen Siminyu   Julia Kreutzer</td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.14824&#39;]">On Romanization for Model Transfer Between Scripts in Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.14824">https://arxiv.org/pdf/2009.14824</a></td><td>Transfer learning is a popular strategy to improve the quality of low-resource machine translation. For an optimal transfer of the embedding layer, the child and parent model should share a substantial part of the vocabulary. This is not the case when transferring to languages with a different script. We explore the benefit of romanization in this scenario. Our results show that romanization entails information loss and is thus not always superior to simpler vocabulary transfer methods, but can improve the transfer between related languages with different scripts. We compare two romanization tools and find that they exhibit different degrees of information loss, which affects translation quality. Finally, we extend romanization to the target side, showing that this can be a successful strategy when coupled with a simple deromanization model.</td><td>è¿ç§»å­¦ä¹ æ˜¯æé«˜ä½èµ„æºæœºå™¨ç¿»è¯‘è´¨é‡çš„æµè¡Œç­–ç•¥ã€‚ä¸ºäº†ä¼˜åŒ–åµŒå…¥å±‚çš„è½¬ç§»ï¼Œå­æ¨¡å‹å’Œçˆ¶æ¨¡å‹åº”è¯¥å…±äº«è¯æ±‡è¡¨çš„å¤§éƒ¨åˆ†ã€‚è½¬æ¢ä¸ºå…·æœ‰ä¸åŒè„šæœ¬çš„è¯­è¨€æ—¶ï¼Œæƒ…å†µå¹¶éå¦‚æ­¤ã€‚æˆ‘ä»¬æ¢è®¨äº†åœ¨è¿™ç§æƒ…å†µä¸‹ç½—é©¬åŒ–çš„å¥½å¤„ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œç½—é©¬åŒ–ä¼šå¯¼è‡´ä¿¡æ¯ä¸¢å¤±ï¼Œå› æ­¤å¹¶ä¸æ€»æ˜¯ä¼˜äºæ›´ç®€å•çš„è¯æ±‡è½¬ç§»æ–¹æ³•ï¼Œä½†å¯ä»¥æ”¹å–„å…·æœ‰ä¸åŒè„šæœ¬çš„ç›¸å…³è¯­è¨€ä¹‹é—´çš„è½¬ç§»ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†ä¸¤ç§ç½—é©¬åŒ–å·¥å…·ï¼Œå‘ç°å®ƒä»¬è¡¨ç°å‡ºä¸åŒç¨‹åº¦çš„ä¿¡æ¯ä¸¢å¤±ï¼Œè¿™ä¼šå½±å“ç¿»è¯‘è´¨é‡ã€‚æœ€åï¼Œæˆ‘ä»¬å°†ç½—é©¬åŒ–æ‰©å±•åˆ°ç›®æ ‡ç«¯ï¼Œè¡¨æ˜å½“ä¸ç®€å•çš„å»ç½—é©¬åŒ–æ¨¡å‹ç›¸ç»“åˆæ—¶ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªæˆåŠŸçš„ç­–ç•¥ã€‚</td><td>Chantal Amrhein   Rico Sennrich</td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13781&#39;]">Graph-to-Tree Neural Networks for Learning Structured Input-Output Translation with Applications to Semantic Parsing and Math Word Problem</a></td><td></td><td><a href="https://github.com/IBM/Graph2Tree">https://github.com/IBM/Graph2Tree</a></td><td><a href="https://arxiv.org/pdf/2004.13781">https://arxiv.org/pdf/2004.13781</a></td><td>The celebrated Seq2Seq technique and its numerous variants achieve excellent performance on many tasks such as neural machine translation, semantic parsing, and math word problem solving. However, these models either only consider input objects as sequences while ignoring the important structural information for encoding, or they simply treat output objects as sequence outputs instead of structural objects for decoding. In this paper, we present a novel Graph-to-Tree Neural Networks, namely Graph2Tree consisting of a graph encoder and a hierarchical tree decoder, that encodes an augmented graph-structured input and decodes a tree-structured output. In particular, we investigated our model for solving two problems, neural semantic parsing and math word problem. Our extensive experiments demonstrate that our Graph2Tree model outperforms or matches the performance of other state-of-the-art models on these tasks.</td><td>è‘—åçš„ Seq2Seq æŠ€æœ¯åŠå…¶ä¼—å¤šå˜ä½“åœ¨ç¥ç»æœºå™¨ç¿»è¯‘ã€è¯­ä¹‰è§£æå’Œæ•°å­¦å•è¯é—®é¢˜è§£å†³ç­‰è®¸å¤šä»»åŠ¡ä¸Šéƒ½å–å¾—äº†å‡ºè‰²çš„è¡¨ç°ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹è¦ä¹ˆåªå°†è¾“å…¥å¯¹è±¡è§†ä¸ºåºåˆ—è€Œå¿½ç•¥ç¼–ç çš„é‡è¦ç»“æ„ä¿¡æ¯ï¼Œè¦ä¹ˆå°†è¾“å‡ºå¯¹è±¡ç®€å•åœ°è§†ä¸ºåºåˆ—è¾“å‡ºè€Œä¸æ˜¯ç»“æ„å¯¹è±¡è¿›è¡Œè§£ç ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å›¾åˆ°æ ‘ç¥ç»ç½‘ç»œï¼Œå³ç”±å›¾ç¼–ç å™¨å’Œåˆ†å±‚æ ‘è§£ç å™¨ç»„æˆçš„ Graph2Treeï¼Œå®ƒå¯¹å¢å¼ºçš„å›¾ç»“æ„è¾“å…¥è¿›è¡Œç¼–ç å¹¶è§£ç æ ‘ç»“æ„è¾“å‡ºã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬ç ”ç©¶äº†è§£å†³ä¸¤ä¸ªé—®é¢˜çš„æ¨¡å‹ï¼Œç¥ç»è¯­ä¹‰è§£æå’Œæ•°å­¦å•è¯é—®é¢˜ã€‚æˆ‘ä»¬å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ Graph2Tree æ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºæˆ–åŒ¹é…å…¶ä»–æœ€å…ˆè¿›æ¨¡å‹çš„æ€§èƒ½ã€‚</td><td>Shucheng Li   Lingfei Wu   Shiwei Feng   Fangli Xu   Fengyuan Xu   Sheng Zhong</td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04924&#39;]">On Long-Tailed Phenomena in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/vyraun/long-tailed">https://github.com/vyraun/long-tailed</a></td><td><a href="https://arxiv.org/pdf/2010.04924">https://arxiv.org/pdf/2010.04924</a></td><td>State-of-the-art Neural Machine Translation (NMT) models struggle with generating low-frequency tokens, tackling which remains a major challenge. The analysis of long-tailed phenomena in the context of structured prediction tasks is further hindered by the added complexities of search during inference. In this work, we quantitatively characterize such long-tailed phenomena at two levels of abstraction, namely, token classification and sequence generation. We propose a new loss function, the Anti-Focal loss, to better adapt model training to the structural dependencies of conditional text generation by incorporating the inductive biases of beam search in the training process. We show the efficacy of the proposed technique on a number of Machine Translation (MT) datasets, demonstrating that it leads to significant gains over cross-entropy across different language pairs, especially on the generation of low-frequency words. We have released the code to reproduce our results.</td><td>æœ€å…ˆè¿›çš„ç¥ç»æœºå™¨ç¿»è¯‘ (NMT) æ¨¡å‹éš¾ä»¥ç”Ÿæˆä½é¢‘æ ‡è®°ï¼Œè¿™ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜ã€‚åœ¨ç»“æ„åŒ–é¢„æµ‹ä»»åŠ¡çš„ä¸Šä¸‹æ–‡ä¸­å¯¹é•¿å°¾ç°è±¡çš„åˆ†æè¿›ä¸€æ­¥å—åˆ°æ¨ç†æœŸé—´æœç´¢å¤æ‚æ€§çš„é˜»ç¢ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªæŠ½è±¡å±‚æ¬¡ä¸Šå®šé‡æè¿°äº†è¿™ç§é•¿å°¾ç°è±¡ï¼Œå³æ ‡è®°åˆ†ç±»å’Œåºåˆ—ç”Ÿæˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°ï¼Œå³ Anti-Focal æŸå¤±ï¼Œé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç»“åˆæ³¢æŸæœç´¢çš„å½’çº³åå·®ï¼Œæ›´å¥½åœ°ä½¿æ¨¡å‹è®­ç»ƒé€‚åº”æ¡ä»¶æ–‡æœ¬ç”Ÿæˆçš„ç»“æ„ä¾èµ–æ€§ã€‚æˆ‘ä»¬å±•ç¤ºäº†æ‰€æå‡ºçš„æŠ€æœ¯åœ¨è®¸å¤šæœºå™¨ç¿»è¯‘ (MT) æ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜å®ƒåœ¨è·¨ä¸åŒè¯­è¨€å¯¹çš„äº¤å‰ç†µä¸Šå¸¦æ¥äº†æ˜¾ç€çš„æ”¶ç›Šï¼Œå°¤å…¶æ˜¯åœ¨ä½é¢‘è¯çš„ç”Ÿæˆæ–¹é¢ã€‚æˆ‘ä»¬å·²ç»å‘å¸ƒäº†ä»£ç æ¥é‡ç°æˆ‘ä»¬çš„ç»“æœã€‚</td><td>Vikas Raunak   Siddharth Dalmia   Vivek Gupta   Florian Metze</td></tr><tr><td>8</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.02955&#39;]">A Multilingual View of Unsupervised Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.02955">https://arxiv.org/pdf/2002.02955</a></td><td>We present a probabilistic framework for multilingual neural machine translation that encompasses supervised and unsupervised setups, focusing on unsupervised translation. In addition to studying the vanilla case where there is only monolingual data available, we propose a novel setup where one language in the (source, target) pair is not associated with any parallel data, but there may exist auxiliary parallel data that contains the other. This auxiliary data can naturally be utilized in our probabilistic framework via a novel cross-translation loss term. Empirically, we show that our approach results in higher BLEU scores over state-of-the-art unsupervised models on the WMTâ€™14 English-French, WMTâ€™16 English-German, and WMTâ€™16 English-Romanian datasets in most directions. In particular, we obtain a +1.65 BLEU advantage over the best-performing unsupervised model in the Romanian-English direction.</td><td>æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç”¨äºå¤šè¯­è¨€ç¥ç»æœºå™¨ç¿»è¯‘çš„æ¦‚ç‡æ¡†æ¶ï¼Œå…¶ä¸­åŒ…æ‹¬æœ‰ç›‘ç£å’Œæ— ç›‘ç£è®¾ç½®ï¼Œé‡ç‚¹æ˜¯æ— ç›‘ç£ç¿»è¯‘ã€‚é™¤äº†ç ”ç©¶åªæœ‰å•è¯­æ•°æ®å¯ç”¨çš„æ™®é€šæƒ…å†µå¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°é¢–çš„è®¾ç½®ï¼Œå…¶ä¸­ï¼ˆæºã€ç›®æ ‡ï¼‰å¯¹ä¸­çš„ä¸€ç§è¯­è¨€ä¸ä»»ä½•å¹¶è¡Œæ•°æ®æ— å…³ï¼Œä½†å¯èƒ½å­˜åœ¨åŒ…å«å¦ä¸€ç§è¯­è¨€çš„è¾…åŠ©å¹¶è¡Œæ•°æ®.é€šè¿‡æ–°çš„äº¤å‰ç¿»è¯‘æŸå¤±é¡¹ï¼Œè¿™äº›è¾…åŠ©æ•°æ®å¯ä»¥è‡ªç„¶åœ°ç”¨äºæˆ‘ä»¬çš„æ¦‚ç‡æ¡†æ¶ä¸­ã€‚æ ¹æ®ç»éªŒï¼Œæˆ‘ä»¬è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ WMTâ€™14 English-Frenchã€WMTâ€™16 English-German å’Œ WMTâ€™16 English-Romanian æ•°æ®é›†çš„å¤§å¤šæ•°æ–¹å‘ä¸Šæ¯”æœ€å…ˆè¿›çš„æ— ç›‘ç£æ¨¡å‹è·å¾—æ›´é«˜çš„ BLEU åˆ†æ•°ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬åœ¨ç½—é©¬å°¼äºšè¯­-è‹±è¯­æ–¹å‘ä¸Šè·å¾—äº†ä¼˜äºæ€§èƒ½æœ€ä½³çš„æ— ç›‘ç£æ¨¡å‹çš„ +1.65 BLEU ä¼˜åŠ¿ã€‚</td><td>Xavier Garcia   Pierre Foret   Thibault Sellam   Ankur P. Parikh</td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.00180&#39;]">Explicit Cross-lingual Pre-training for Unsupervised Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.00180">https://arxiv.org/pdf/1909.00180</a></td><td>Pre-training has proven to be effective in unsupervised machine translation due to its ability to model deep context information in cross-lingual scenarios. However, the cross-lingual information obtained from shared BPE spaces is inexplicit and limited. In this paper, we propose a novel cross-lingual pre-training method for unsupervised machine translation by incorporating explicit cross-lingual training signals. Specifically, we first calculate cross-lingual n-gram embeddings and infer an n-gram translation table from them. With those n-gram translation pairs, we propose a new pre-training model called Cross-lingual Masked Language Model (CMLM), which randomly chooses source n-grams in the input text stream and predicts their translation candidates at each time step. Experiments show that our method can incorporate beneficial cross-lingual information into pre-trained models. Taking pre-trained CMLM models as the encoder and decoder, we significantly improve the performance of unsupervised machine translation.</td><td>é¢„è®­ç»ƒå·²è¢«è¯æ˜åœ¨æ— ç›‘ç£æœºå™¨ç¿»è¯‘ä¸­æ˜¯æœ‰æ•ˆçš„ï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿåœ¨è·¨è¯­è¨€åœºæ™¯ä¸­å¯¹æ·±å±‚ä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œå»ºæ¨¡ã€‚ç„¶è€Œï¼Œä»å…±äº« BPE ç©ºé—´è·å¾—çš„è·¨è¯­è¨€ä¿¡æ¯æ˜¯ä¸æ˜ç¡®å’Œæœ‰é™çš„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ç»“åˆæ˜ç¡®çš„è·¨è¯­è¨€è®­ç»ƒä¿¡å·ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è·¨è¯­è¨€é¢„è®­ç»ƒæ–¹æ³•ï¼Œç”¨äºæ— ç›‘ç£æœºå™¨ç¿»è¯‘ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆè®¡ç®—è·¨è¯­è¨€ n-gram åµŒå…¥å¹¶ä»ä¸­æ¨æ–­å‡º n-gram ç¿»è¯‘è¡¨ã€‚åˆ©ç”¨è¿™äº› n-gram ç¿»è¯‘å¯¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸ºè·¨è¯­è¨€æ©ç è¯­è¨€æ¨¡å‹ (CMLM) çš„æ–°é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨è¾“å…¥æ–‡æœ¬æµä¸­éšæœºé€‰æ‹©æº n-gram å¹¶åœ¨æ¯ä¸ªæ—¶é—´æ­¥é¢„æµ‹å®ƒä»¬çš„ç¿»è¯‘å€™é€‰ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å°†æœ‰ç›Šçš„è·¨è¯­è¨€ä¿¡æ¯æ•´åˆåˆ°é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ä¸­ã€‚ä»¥é¢„è®­ç»ƒçš„ CMLM æ¨¡å‹ä½œä¸ºç¼–ç å™¨å’Œè§£ç å™¨ï¼Œæˆ‘ä»¬æ˜¾ç€æé«˜äº†æ— ç›‘ç£æœºå™¨ç¿»è¯‘çš„æ€§èƒ½ã€‚</td><td>Shuo Ren   Yu Wu   Shujie Liu   Ming Zhou   Shuai Ma</td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.00157&#39;]">Improving Back-Translation with Uncertainty-based Confidence Estimation</a></td><td></td><td><a href="https://github.com/THUNLP-MT/UCE4BT">https://github.com/THUNLP-MT/UCE4BT</a></td><td><a href="https://arxiv.org/pdf/1909.00157">https://arxiv.org/pdf/1909.00157</a></td><td>While back-translation is simple and effective in exploiting abundant monolingual corpora to improve low-resource neural machine translation (NMT), the synthetic bilingual corpora generated by NMT models trained on limited authentic bilingual data are inevitably noisy. In this work, we propose to quantify the confidence of NMT model predictions based on model uncertainty. With word- and sentence-level confidence measures based on uncertainty, it is possible for back-translation to better cope with noise in synthetic bilingual corpora. Experiments on Chinese-English and English-German translation tasks show that uncertainty-based confidence estimation significantly improves the performance of back-translation.</td><td>è™½ç„¶åå‘ç¿»è¯‘åœ¨åˆ©ç”¨ä¸°å¯Œçš„å•è¯­è¯­æ–™åº“æ¥æ”¹è¿›ä½èµ„æºç¥ç»æœºå™¨ç¿»è¯‘ (NMT) æ–¹é¢ç®€å•è€Œæœ‰æ•ˆï¼Œä½†ç”±åœ¨æœ‰é™çœŸå®åŒè¯­æ•°æ®ä¸Šè®­ç»ƒçš„ NMT æ¨¡å‹ç”Ÿæˆçš„åˆæˆåŒè¯­è¯­æ–™åº“ä¸å¯é¿å…åœ°å­˜åœ¨å™ªå£°ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å»ºè®®åŸºäºæ¨¡å‹ä¸ç¡®å®šæ€§é‡åŒ– NMT æ¨¡å‹é¢„æµ‹çš„ç½®ä¿¡åº¦ã€‚é€šè¿‡åŸºäºä¸ç¡®å®šæ€§çš„å•è¯å’Œå¥å­çº§åˆ«çš„ç½®ä¿¡åº¦åº¦é‡ï¼Œå›è¯‘å¯ä»¥æ›´å¥½åœ°åº”å¯¹åˆæˆåŒè¯­è¯­æ–™åº“ä¸­çš„å™ªå£°ã€‚æ±‰è‹±å’Œè‹±å¾·ç¿»è¯‘ä»»åŠ¡çš„å®éªŒè¡¨æ˜ï¼ŒåŸºäºä¸ç¡®å®šæ€§çš„ç½®ä¿¡åº¦ä¼°è®¡æ˜¾ç€æé«˜äº†å›è¯‘çš„æ€§èƒ½ã€‚</td><td>Shuo Wang   Yang Liu   Chao Wang   Huanbo Luan   Maosong Sun</td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1912.07239&#39;]">Iterative Dual Domain Adaptation for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1912.07239">https://arxiv.org/pdf/1912.07239</a></td><td>Previous studies on the domain adaptation for neural machine translation (NMT) mainly focus on the one-pass transferring out-of-domain translation knowledge to in-domain NMT model. In this paper, we argue that such a strategy fails to fully extract the domain-shared translation knowledge, and repeatedly utilizing corpora of different domains can lead to better distillation of domain-shared translation knowledge. To this end, we propose an iterative dual domain adaptation framework for NMT. Specifically, we first pre-train in-domain and out-of-domain NMT models using their own training corpora respectively, and then iteratively perform bidirectional translation knowledge transfer (from in-domain to out-of-domain and then vice versa) based on knowledge distillation until the in-domain NMT model convergences. Furthermore, we extend the proposed framework to the scenario of multiple out-of-domain training corpora, where the above-mentioned transfer is performed sequentially between the in-domain and each out-of-domain NMT models in the ascending order of their domain similarities. Empirical results on Chinese-English and English-German translation tasks demonstrate the effectiveness of our framework.</td><td>å…ˆå‰å…³äºç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆNMTï¼‰é¢†åŸŸé€‚åº”çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å°†åŸŸå¤–ç¿»è¯‘çŸ¥è¯†ä¸€æ¬¡æ€§è½¬ç§»åˆ°åŸŸå†… NMT æ¨¡å‹ä¸Šã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºè¿™ç§ç­–ç•¥æ— æ³•å®Œå…¨æå–é¢†åŸŸå…±äº«ç¿»è¯‘çŸ¥è¯†ï¼Œé‡å¤åˆ©ç”¨ä¸åŒé¢†åŸŸçš„è¯­æ–™åº“å¯ä»¥æ›´å¥½åœ°æç‚¼é¢†åŸŸå…±äº«ç¿»è¯‘çŸ¥è¯†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä¸º NMT æå‡ºäº†ä¸€ä¸ªè¿­ä»£åŒåŸŸé€‚åº”æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ†åˆ«ä½¿ç”¨è‡ªå·±çš„è®­ç»ƒè¯­æ–™å¯¹åŸŸå†…å’ŒåŸŸå¤– NMT æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åè¿­ä»£æ‰§è¡ŒåŒå‘ç¿»è¯‘çŸ¥è¯†è½¬ç§»ï¼ˆä»åŸŸå†…åˆ°åŸŸå¤–ï¼Œåä¹‹äº¦ç„¶ï¼‰ã€‚çŸ¥è¯†è’¸é¦ï¼Œç›´åˆ°åŸŸå†… NMT æ¨¡å‹æ”¶æ•›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ‰€æå‡ºçš„æ¡†æ¶æ‰©å±•åˆ°å¤šä¸ªåŸŸå¤–è®­ç»ƒè¯­æ–™åº“çš„åœºæ™¯ï¼Œå…¶ä¸­ä¸Šè¿°è½¬ç§»æ˜¯åœ¨åŸŸå†…å’ŒåŸŸå¤– NMT æ¨¡å‹ä¹‹é—´æŒ‰ç…§åŸŸçš„å‡åºé¡ºåºæ‰§è¡Œçš„ç›¸ä¼¼ä¹‹å¤„ã€‚æ±‰è‹±å’Œè‹±å¾·ç¿»è¯‘ä»»åŠ¡çš„å®è¯ç»“æœè¯æ˜äº†æˆ‘ä»¬æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚</td><td>Jiali Zeng   Yang Liu   Jinsong Su   Yubin Ge   Yaojie Lu   Yongjing Yin   Jiebo Luo</td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01383&#39;]">Context-Aware Monolingual Repair for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/lena-voita/good-translation-wrong-in-context">https://github.com/lena-voita/good-translation-wrong-in-context</a></td><td><a href="https://arxiv.org/pdf/1909.01383">https://arxiv.org/pdf/1909.01383</a></td><td>Modern sentence-level NMT systems often produce plausible translations of isolated sentences. However, when put in context, these translations may end up being inconsistent with each other. We propose a monolingual DocRepair model to correct inconsistencies between sentence-level translations. DocRepair performs automatic post-editing on a sequence of sentence-level translations, refining translations of sentences in context of each other. For training, the DocRepair model requires only monolingual document-level data in the target language. It is trained as a monolingual sequence-to-sequence model that maps inconsistent groups of sentences into consistent ones. The consistent groups come from the original training data; the inconsistent groups are obtained by sampling round-trip translations for each isolated sentence. We show that this approach successfully imitates inconsistencies we aim to fix: using contrastive evaluation, we show large improvements in the translation of several contextual phenomena in an English-Russian translation task, as well as improvements in the BLEU score. We also conduct a human evaluation and show a strong preference of the annotators to corrected translations over the baseline ones. Moreover, we analyze which discourse phenomena are hard to capture using monolingual data only.</td><td>ç°ä»£å¥å­çº§ NMT ç³»ç»Ÿé€šå¸¸ä¼šå¯¹å­¤ç«‹çš„å¥å­äº§ç”Ÿåˆç†çš„ç¿»è¯‘ã€‚ç„¶è€Œï¼Œå½“æ”¾åœ¨ä¸Šä¸‹æ–‡ä¸­æ—¶ï¼Œè¿™äº›ç¿»è¯‘æœ€ç»ˆå¯èƒ½ä¼šå½¼æ­¤ä¸ä¸€è‡´ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å•è¯­ DocRepair æ¨¡å‹æ¥çº æ­£å¥å­çº§ç¿»è¯‘ä¹‹é—´çš„ä¸ä¸€è‡´ã€‚ DocRepair å¯¹ä¸€ç³»åˆ—å¥å­çº§ç¿»è¯‘æ‰§è¡Œè‡ªåŠ¨åæœŸç¼–è¾‘ï¼Œåœ¨å½¼æ­¤çš„ä¸Šä¸‹æ–‡ä¸­å®Œå–„å¥å­çš„ç¿»è¯‘ã€‚å¯¹äºè®­ç»ƒï¼ŒDocRepair æ¨¡å‹åªéœ€è¦ç›®æ ‡è¯­è¨€çš„å•è¯­æ–‡æ¡£çº§æ•°æ®ã€‚å®ƒè¢«è®­ç»ƒä¸ºå•è¯­åºåˆ—åˆ°åºåˆ—æ¨¡å‹ï¼Œå°†ä¸ä¸€è‡´çš„å¥å­ç»„æ˜ å°„åˆ°ä¸€è‡´çš„å¥å­ç»„ã€‚ä¸€è‡´ç»„æ¥è‡ªåŸå§‹è®­ç»ƒæ•°æ®ï¼›ä¸ä¸€è‡´çš„ç»„æ˜¯é€šè¿‡å¯¹æ¯ä¸ªå­¤ç«‹å¥å­çš„å¾€è¿”ç¿»è¯‘è¿›è¡Œé‡‡æ ·æ¥è·å¾—çš„ã€‚æˆ‘ä»¬è¡¨æ˜è¿™ç§æ–¹æ³•æˆåŠŸåœ°æ¨¡ä»¿äº†æˆ‘ä»¬æ—¨åœ¨è§£å†³çš„ä¸ä¸€è‡´é—®é¢˜ï¼šä½¿ç”¨å¯¹æ¯”è¯„ä¼°ï¼Œæˆ‘ä»¬åœ¨è‹±ä¿„ç¿»è¯‘ä»»åŠ¡ä¸­çš„å‡ ç§ä¸Šä¸‹æ–‡ç°è±¡çš„ç¿»è¯‘æ–¹é¢å–å¾—äº†å¾ˆå¤§çš„æ”¹è¿›ï¼Œä»¥åŠ BLEU åˆ†æ•°çš„æ”¹è¿›ã€‚æˆ‘ä»¬è¿˜è¿›è¡Œäº†äººå·¥è¯„ä¼°ï¼Œå¹¶æ˜¾ç¤ºå‡ºæ³¨é‡Šè€…å¯¹æ›´æ­£ç¿»è¯‘çš„å¼ºçƒˆåå¥½ï¼Œè€Œä¸æ˜¯åŸºçº¿ç¿»è¯‘ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ†æäº†ä»…ä½¿ç”¨å•è¯­æ•°æ®éš¾ä»¥æ•æ‰å“ªäº›è¯è¯­ç°è±¡ã€‚</td><td>Elena Voita   Rico Sennrich   Ivan Titov</td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.09646&#39;]">Dynamic Past and Future for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/zhengzx-nlp/dynamic-nmt">https://github.com/zhengzx-nlp/dynamic-nmt</a></td><td><a href="https://arxiv.org/pdf/1904.09646">https://arxiv.org/pdf/1904.09646</a></td><td>Previous studies have shown that neural machine translation (NMT) models can benefit from explicitly modeling translated (Past) and untranslated (Future) to groups of translated and untranslated contents through parts-to-wholes assignment. The assignment is learned through a novel variant of routing-by-agreement mechanism (Sabour et al., 2017), namely {\em Guided Dynamic Routing}, where the translating status at each decoding step {\em guides} the routing process to assign each source word to its associated group (i.e., translated or untranslated content) represented by a capsule, enabling translation to be made from holistic context. Experiments show that our approach achieves substantial improvements over both RNMT and Transformer by producing more adequate translations. Extensive analysis demonstrates that our method is highly interpretable, which is able to recognize the translated and untranslated contents as expected.</td><td>å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼Œç¥ç»æœºå™¨ç¿»è¯‘ (NMT) æ¨¡å‹å¯ä»¥å—ç›Šäºé€šè¿‡éƒ¨åˆ†åˆ°æ•´ä½“åˆ†é…å°†å·²ç¿»è¯‘ï¼ˆè¿‡å»ï¼‰å’Œæœªç¿»è¯‘ï¼ˆæœªæ¥ï¼‰æ˜¾å¼å»ºæ¨¡ä¸ºå·²ç¿»è¯‘å’Œæœªç¿»è¯‘å†…å®¹çš„ç»„ã€‚è¯¥åˆ†é…æ˜¯é€šè¿‡åè®®è·¯ç”±æœºåˆ¶çš„ä¸€ç§æ–°å˜ä½“ï¼ˆSabour ç­‰äººï¼Œ2017 å¹´ï¼‰å­¦ä¹ çš„ï¼Œå³ {\em å¼•å¯¼åŠ¨æ€è·¯ç”±}ï¼Œå…¶ä¸­æ¯ä¸ªè§£ç æ­¥éª¤çš„ç¿»è¯‘çŠ¶æ€{\em å¼•å¯¼}è·¯ç”±è¿‡ç¨‹åˆ°å°†æ¯ä¸ªæºè¯åˆ†é…ç»™ç”±èƒ¶å›Šè¡¨ç¤ºçš„ç›¸å…³ç»„ï¼ˆå³ç¿»è¯‘æˆ–æœªç¿»è¯‘çš„å†…å®¹ï¼‰ï¼Œä»è€Œèƒ½å¤Ÿä»æ•´ä½“ä¸Šä¸‹æ–‡è¿›è¡Œç¿»è¯‘ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡äº§ç”Ÿæ›´å……åˆ†çš„ç¿»è¯‘ï¼Œåœ¨ RNMT å’Œ Transformer ä¸Šå–å¾—äº†å®è´¨æ€§çš„æ”¹è¿›ã€‚å¹¿æ³›çš„åˆ†æè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å…·æœ‰é«˜åº¦çš„å¯è§£é‡Šæ€§ï¼Œèƒ½å¤ŸæŒ‰é¢„æœŸè¯†åˆ«ç¿»è¯‘å’Œæœªç¿»è¯‘çš„å†…å®¹ã€‚</td><td>Zaixiang Zheng   Shujian Huang   Zhaopeng Tu   Xin-Yu Dai   Jiajun Chen</td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01559&#39;]">Simpler and Faster Learning of Adaptive Policies for Simultaneous Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.01559">https://arxiv.org/pdf/1909.01559</a></td><td>Simultaneous translation is widely useful but remains challenging. Previous work falls into two main categories: (a) fixed-latency policies such as Ma et al. (2019) and (b) adaptive policies such as Gu et al. (2017). The former are simple and effective, but have to aggressively predict future content due to diverging source-target word order; the latter do not anticipate, but suffer from unstable and inefficient training. To combine the merits of both approaches, we propose a simple supervised-learning framework to learn an adaptive policy from oracle READ/WRITE sequences generated from parallel text. At each step, such an oracle sequence chooses to WRITE the next target word if the available source sentence context provides enough information to do so, otherwise READ the next source word. Experiments on German&lt;-&gt;English show that our method, without retraining the underlying NMT model, can learn flexible policies with better BLEU scores and similar latencies compared to previous work.</td><td>åŒå£°ä¼ è¯‘å…·æœ‰å¹¿æ³›çš„ç”¨é€”ï¼Œä½†ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä»¥å‰çš„å·¥ä½œåˆ†ä¸ºä¸¤å¤§ç±»ï¼šï¼ˆaï¼‰å›ºå®šå»¶è¿Ÿç­–ç•¥ï¼Œå¦‚ Ma ç­‰äººã€‚ (2019) å’Œ (b) é€‚åº”æ€§æ”¿ç­–ï¼Œå¦‚ Gu ç­‰äººã€‚ (2017)ã€‚å‰è€…ç®€å•æœ‰æ•ˆï¼Œä½†ç”±äºæºç›®æ ‡è¯åºä¸åŒï¼Œå¿…é¡»ç§¯æé¢„æµ‹æœªæ¥çš„å†…å®¹ï¼›åè€…æ²¡æœ‰é¢„æœŸï¼Œè€Œæ˜¯é­å—ä¸ç¨³å®šå’Œä½æ•ˆçš„è®­ç»ƒã€‚ä¸ºäº†ç»“åˆè¿™ä¸¤ç§æ–¹æ³•çš„ä¼˜ç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç®€å•çš„ç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œä»å¹¶è¡Œæ–‡æœ¬ç”Ÿæˆçš„ oracle READ/WRITE åºåˆ—ä¸­å­¦ä¹ è‡ªé€‚åº”ç­–ç•¥ã€‚åœ¨æ¯ä¸€æ­¥ï¼Œå¦‚æœå¯ç”¨çš„æºå¥å­ä¸Šä¸‹æ–‡æä¾›äº†è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œè¿™æ ·çš„é¢„è¨€æœºåºåˆ—é€‰æ‹©å†™å…¥ä¸‹ä¸€ä¸ªç›®æ ‡è¯ï¼Œå¦åˆ™è¯»å–ä¸‹ä¸€ä¸ªæºè¯ã€‚åœ¨å¾·è¯­&lt;-&gt;è‹±è¯­ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸ä¹‹å‰çš„å·¥ä½œç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ— éœ€é‡æ–°è®­ç»ƒåº•å±‚ NMT æ¨¡å‹ï¼Œå°±å¯ä»¥å­¦ä¹ å…·æœ‰æ›´å¥½ BLEU åˆ†æ•°å’Œç±»ä¼¼å»¶è¿Ÿçš„çµæ´»ç­–ç•¥ã€‚</td><td>Baigong Zheng   Renjie Zheng   Mingbo Ma   Liang Huang</td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.10430&#39;]">Unsupervised Domain Adaptation for Neural Machine Translation with Domain-Aware Feature Embeddings</a></td><td></td><td><a href="https://github.com/zdou0830/DAFE">https://github.com/zdou0830/DAFE</a></td><td><a href="https://arxiv.org/pdf/1908.10430">https://arxiv.org/pdf/1908.10430</a></td><td>The recent success of neural machine translation models relies on the availability of high quality, in-domain data. Domain adaptation is required when domain-specific data is scarce or nonexistent. Previous unsupervised domain adaptation strategies include training the model with in-domain copied monolingual or back-translated data. However, these methods use generic representations for text regardless of domain shift, which makes it infeasible for translation models to control outputs conditional on a specific domain. In this work, we propose an approach that adapts models with domain-aware feature embeddings, which are learned via an auxiliary language modeling task. Our approach allows the model to assign domain-specific representations to words and output sentences in the desired domain. Our empirical results demonstrate the effectiveness of the proposed strategy, achieving consistent improvements in multiple experimental settings. In addition, we show that combining our method with back translation can further improve the performance of the model.</td><td>æœ€è¿‘ç¥ç»æœºå™¨ç¿»è¯‘æ¨¡å‹çš„æˆåŠŸä¾èµ–äºé«˜è´¨é‡åŸŸå†…æ•°æ®çš„å¯ç”¨æ€§ã€‚å½“ç‰¹å®šäºåŸŸçš„æ•°æ®ç¨€ç¼ºæˆ–ä¸å­˜åœ¨æ—¶ï¼Œéœ€è¦åŸŸè‡ªé€‚åº”ã€‚ä»¥å‰çš„æ— ç›‘ç£åŸŸé€‚åº”ç­–ç•¥åŒ…æ‹¬ä½¿ç”¨åŸŸå†…å¤åˆ¶çš„å•è¯­æˆ–åå‘ç¿»è¯‘æ•°æ®è®­ç»ƒæ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä½¿ç”¨æ–‡æœ¬çš„é€šç”¨è¡¨ç¤ºè€Œä¸è€ƒè™‘åŸŸè½¬ç§»ï¼Œè¿™ä½¿å¾—ç¿»è¯‘æ¨¡å‹æ— æ³•æ§åˆ¶ä»¥ç‰¹å®šåŸŸä¸ºæ¡ä»¶çš„è¾“å‡ºã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥é€šè¿‡è¾…åŠ©è¯­è¨€å»ºæ¨¡ä»»åŠ¡å­¦ä¹ å…·æœ‰é¢†åŸŸæ„ŸçŸ¥ç‰¹å¾åµŒå…¥çš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å…è®¸æ¨¡å‹å°†ç‰¹å®šäºåŸŸçš„è¡¨ç¤ºåˆ†é…ç»™æ‰€éœ€åŸŸä¸­çš„å•è¯å’Œè¾“å‡ºå¥å­ã€‚æˆ‘ä»¬çš„å®è¯ç»“æœè¯æ˜äº†æ‰€æå‡ºç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œåœ¨å¤šä¸ªå®éªŒç¯å¢ƒä¸­å®ç°äº†ä¸€è‡´çš„æ”¹è¿›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¡¨æ˜å°†æˆ‘ä»¬çš„æ–¹æ³•ä¸åå‘ç¿»è¯‘ç›¸ç»“åˆå¯ä»¥è¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚</td><td>Zi-Yi Dou   Junjie Hu   Antonios Anastasopoulos   Graham Neubig</td></tr><tr><td>16</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1911.00835&#39;]">Controlling Text Complexity in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/sweta20/ComplexityControlledMT">https://github.com/sweta20/ComplexityControlledMT</a></td><td><a href="https://arxiv.org/pdf/1911.00835">https://arxiv.org/pdf/1911.00835</a></td><td>This work introduces a machine translation task where the output is aimed at audiences of different levels of target language proficiency. We collect a high quality dataset of news articles available in English and Spanish, written for diverse grade levels and propose a method to align segments across comparable bilingual articles. The resulting dataset makes it possible to train multi-task sequence-to-sequence models that translate Spanish into English targeted at an easier reading grade level than the original Spanish. We show that these multi-task models outperform pipeline approaches that translate and simplify text independently.</td><td>è¿™é¡¹å·¥ä½œå¼•å…¥äº†æœºå™¨ç¿»è¯‘ä»»åŠ¡ï¼Œå…¶ä¸­è¾“å‡ºé’ˆå¯¹ä¸åŒç›®æ ‡è¯­è¨€æ°´å¹³çš„å—ä¼—ã€‚æˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªé«˜è´¨é‡çš„è‹±è¯­å’Œè¥¿ç­ç‰™è¯­æ–°é—»æ–‡ç« æ•°æ®é›†ï¼Œä¸ºä¸åŒå¹´çº§ç¼–å†™ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–¹æ³•æ¥å¯¹é½å¯æ¯”åŒè¯­æ–‡ç« ä¸­çš„ç‰‡æ®µã€‚ç”±æ­¤äº§ç”Ÿçš„æ•°æ®é›†å¯ä»¥è®­ç»ƒå¤šä»»åŠ¡åºåˆ—åˆ°åºåˆ—æ¨¡å‹ï¼Œå°†è¥¿ç­ç‰™è¯­ç¿»è¯‘æˆè‹±è¯­ï¼Œç›®æ ‡æ˜¯æ¯”åŸå§‹è¥¿ç­ç‰™è¯­æ›´å®¹æ˜“é˜…è¯»ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œè¿™äº›å¤šä»»åŠ¡æ¨¡å‹ä¼˜äºç‹¬ç«‹ç¿»è¯‘å’Œç®€åŒ–æ–‡æœ¬çš„ç®¡é“æ–¹æ³•ã€‚</td><td>Sweta Agrawal   Marine Carpuat</td></tr><tr><td>17</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.05731&#39;]">Simple and Effective Noisy Channel Modeling for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></td><td><a href="https://arxiv.org/pdf/1908.05731">https://arxiv.org/pdf/1908.05731</a></td><td>Previous work on neural noisy channel modeling relied on latent variable models that incrementally process the source and target sentence. This makes decoding decisions based on partial source prefixes even though the full source is available. We pursue an alternative approach based on standard sequence to sequence models which utilize the entire source. These models perform remarkably well as channel models, even though they have neither been trained on, nor designed to factor over incomplete target sentences. Experiments with neural language models trained on billions of words show that noisy channel models can outperform a direct model by up to 3.2 BLEU on WMTâ€™17 German-English translation. We evaluate on four language-pairs and our channel models consistently outperform strong alternatives such right-to-left reranking models and ensembles of direct models.</td><td>å…ˆå‰å…³äºç¥ç»å™ªå£°é€šé“å»ºæ¨¡çš„å·¥ä½œä¾èµ–äºå¢é‡å¤„ç†æºè¯­å¥å’Œç›®æ ‡è¯­å¥çš„æ½œåœ¨å˜é‡æ¨¡å‹ã€‚å³ä½¿å®Œæ•´æºå¯ç”¨ï¼Œè¿™ä¹Ÿä¼šåŸºäºéƒ¨åˆ†æºå‰ç¼€åšå‡ºè§£ç å†³ç­–ã€‚æˆ‘ä»¬å¯»æ±‚ä¸€ç§åŸºäºæ ‡å‡†åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„æ›¿ä»£æ–¹æ³•ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨æ•´ä¸ªæºã€‚è¿™äº›æ¨¡å‹ä½œä¸ºé€šé“æ¨¡å‹çš„è¡¨ç°éå¸¸å¥½ï¼Œå³ä½¿å®ƒä»¬æ—¢æ²¡æœ‰æ¥å—è¿‡è®­ç»ƒï¼Œä¹Ÿæ²¡æœ‰è¢«è®¾è®¡ä¸ºè€ƒè™‘ä¸å®Œæ•´çš„ç›®æ ‡å¥å­ã€‚åœ¨æ•°åäº¿å•è¯ä¸Šè®­ç»ƒçš„ç¥ç»è¯­è¨€æ¨¡å‹çš„å®éªŒè¡¨æ˜ï¼Œåœ¨ WMTâ€™17 å¾·è‹±ç¿»è¯‘ä¸­ï¼Œå™ªå£°é€šé“æ¨¡å‹çš„æ€§èƒ½æ¯”ç›´æ¥æ¨¡å‹é«˜ 3.2 BLEUã€‚æˆ‘ä»¬å¯¹å››ä¸ªè¯­è¨€å¯¹è¿›è¡Œè¯„ä¼°ï¼Œæˆ‘ä»¬çš„é€šé“æ¨¡å‹å§‹ç»ˆä¼˜äºå¼ºå¤§çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä¾‹å¦‚ä»å³åˆ°å·¦çš„é‡æ–°æ’åºæ¨¡å‹å’Œç›´æ¥æ¨¡å‹çš„é›†åˆã€‚</td><td>Kyra Yee   Nathan Ng   Yann N. Dauphin   Michael Auli</td></tr><tr><td>18</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.06708&#39;]">Hint-Based Training for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/zhuohan123/hint-nart">https://github.com/zhuohan123/hint-nart</a></td><td><a href="https://arxiv.org/pdf/1909.06708">https://arxiv.org/pdf/1909.06708</a></td><td>Due to the unparallelizable nature of the autoregressive factorization, AutoRegressive Translation (ART) models have to generate tokens sequentially during decoding and thus suffer from high inference latency. Non-AutoRegressive Translation (NART) models were proposed to reduce the inference time, but could only achieve inferior translation accuracy. In this paper, we proposed a novel approach to leveraging the hints from hidden states and word alignments to help the training of NART models. The results achieve significant improvement over previous NART models for the WMT14 En-De and De-En datasets and are even comparable to a strong LSTM-based ART baseline but one order of magnitude faster in inference.</td><td>ç”±äºè‡ªå›å½’åˆ†è§£çš„æ— ä¸ä¼¦æ¯”çš„æ€§è´¨ï¼Œè‡ªå›å½’ç¿»è¯‘ (ART) æ¨¡å‹å¿…é¡»åœ¨è§£ç æœŸé—´æŒ‰é¡ºåºç”Ÿæˆä»¤ç‰Œï¼Œå› æ­¤ä¼šé­å—é«˜æ¨ç†å»¶è¿Ÿã€‚æå‡ºäº†éè‡ªå›å½’ç¿»è¯‘ (NART) æ¨¡å‹ä»¥å‡å°‘æ¨ç†æ—¶é—´ï¼Œä½†åªèƒ½å®ç°è¾ƒå·®çš„ç¿»è¯‘å‡†ç¡®åº¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨éšè—çŠ¶æ€å’Œè¯å¯¹é½çš„æç¤ºæ¥å¸®åŠ©è®­ç»ƒ NART æ¨¡å‹çš„æ–°æ–¹æ³•ã€‚ä¸ WMT14 En-De å’Œ De-En æ•°æ®é›†çš„å…ˆå‰ NART æ¨¡å‹ç›¸æ¯”ï¼Œç»“æœå®ç°äº†æ˜¾ç€æ”¹è¿›ï¼Œç”šè‡³å¯ä¸åŸºäº LSTM çš„å¼ºå¤§ ART åŸºçº¿ç›¸åª²ç¾ï¼Œä½†æ¨ç†é€Ÿåº¦å¿«äº†ä¸€ä¸ªæ•°é‡çº§ã€‚</td><td>Zhuohan Li   Zi Lin   Di He   Fei Tian   Tao Qin   Liwei Wang   Tie-Yan Liu</td></tr></tbody></table></div><h3 id="NAACL"><a href="#NAACL" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.04507&#39;]">Self-Training for Unsupervised Neural Machine Translation in Unbalanced Training Data Scenarios</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.04507">https://arxiv.org/pdf/2004.04507</a></td><td>Unsupervised neural machine translation (UNMT) that relies solely on massive monolingual corpora has achieved remarkable results in several translation tasks. However, in real-world scenarios, massive monolingual corpora do not exist for some extremely low-resource languages such as Estonian, and UNMT systems usually perform poorly when there is not adequate training corpus for one language. In this paper, we first define and analyze the unbalanced training data scenario for UNMT. Based on this scenario, we propose UNMT self-training mechanisms to train a robust UNMT system and improve its performance in this case. Experimental results on several language pairs show that the proposed methods substantially outperform conventional UNMT systems.</td><td>ä»…ä¾èµ–æµ·é‡å•è¯­è¯­æ–™åº“çš„æ— ç›‘ç£ç¥ç»æœºå™¨ç¿»è¯‘ (UNMT) åœ¨å¤šé¡¹ç¿»è¯‘ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆæœã€‚ç„¶è€Œï¼Œåœ¨ç°å®ä¸–ç•Œçš„åœºæ™¯ä¸­ï¼Œå¯¹äºä¸€äº›èµ„æºæå°‘çš„è¯­è¨€ï¼ˆä¾‹å¦‚çˆ±æ²™å°¼äºšè¯­ï¼‰ï¼Œä¸å­˜åœ¨å¤§é‡çš„å•è¯­è¯­æ–™åº“ï¼Œå¹¶ä¸”å½“ä¸€ç§è¯­è¨€æ²¡æœ‰è¶³å¤Ÿçš„è®­ç»ƒè¯­æ–™åº“æ—¶ï¼ŒUNMT ç³»ç»Ÿé€šå¸¸è¡¨ç°ä¸ä½³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆå®šä¹‰å’Œåˆ†æäº† UNMT çš„ä¸å¹³è¡¡è®­ç»ƒæ•°æ®åœºæ™¯ã€‚åŸºäºè¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬æå‡ºäº† UNMT è‡ªè®­ç»ƒæœºåˆ¶æ¥è®­ç»ƒä¸€ä¸ªå¼ºå¤§çš„ UNMT ç³»ç»Ÿå¹¶åœ¨è¿™ç§æƒ…å†µä¸‹æé«˜å…¶æ€§èƒ½ã€‚åœ¨å‡ ä¸ªè¯­è¨€å¯¹ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å¤§å¤§ä¼˜äºä¼ ç»Ÿçš„ UNMT ç³»ç»Ÿã€‚</td><td>Haipeng Sun   Rui Wang   Kehai Chen   Masao Utiyama   Eiichiro Sumita   Tiejun Zhao</td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2009.11201&#39;]">Harnessing Multilinguality in Unsupervised Machine Translation for Rare Languages</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.11201">https://arxiv.org/pdf/2009.11201</a></td><td>Unsupervised translation has reached impressive performance on resource-rich language pairs such as English-French and English-German. However, early studies have shown that in more realistic settings involving low-resource, rare languages, unsupervised translation performs poorly, achieving less than 3.0 BLEU. In this work, we show that multilinguality is critical to making unsupervised systems practical for low-resource settings. In particular, we present a single model for 5 low-resource languages (Gujarati, Kazakh, Nepali, Sinhala, and Turkish) to and from English directions, which leverages monolingual and auxiliary parallel data from other high-resource language pairs via a three-stage training scheme. We outperform all current state-of-the-art unsupervised baselines for these languages, achieving gains of up to 14.4 BLEU. Additionally, we outperform a large collection of supervised WMT submissions for various language pairs as well as match the performance of the current state-of-the-art supervised model for Nepali-English. We conduct a series of ablation studies to establish the robustness of our model under different degrees of data quality, as well as to analyze the factors which led to the superior performance of the proposed approach over traditional unsupervised models.</td><td>æ— ç›‘ç£ç¿»è¯‘åœ¨è‹±è¯­-æ³•è¯­å’Œè‹±è¯­-å¾·è¯­ç­‰èµ„æºä¸°å¯Œçš„è¯­è¨€å¯¹ä¸Šå–å¾—äº†ä»¤äººç©ç›®çš„è¡¨ç°ã€‚ç„¶è€Œï¼Œæ—©æœŸç ”ç©¶è¡¨æ˜ï¼Œåœ¨æ¶‰åŠèµ„æºåŒ®ä¹ã€ç¨€æœ‰è¯­è¨€çš„æ›´ç°å®ç¯å¢ƒä¸­ï¼Œæ— ç›‘ç£ç¿»è¯‘è¡¨ç°ä¸ä½³ï¼Œè¾¾åˆ° 3.0 BLEU ä»¥ä¸‹ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜å¤šè¯­è¨€å¯¹äºä½¿æ— ç›‘ç£ç³»ç»Ÿé€‚ç”¨äºä½èµ„æºç¯å¢ƒè‡³å…³é‡è¦ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬ä¸º 5 ç§ä½èµ„æºè¯­è¨€ï¼ˆå¤å‰æ‹‰ç‰¹è¯­ã€å“ˆè¨å…‹è¯­ã€å°¼æ³Šå°”è¯­ã€åƒ§ä¼½ç½—è¯­å’ŒåœŸè€³å…¶è¯­ï¼‰ä¸è‹±è¯­æ–¹å‘ä¹‹é—´æä¾›äº†ä¸€ä¸ªå•ä¸€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨æ¥è‡ªå…¶ä»–é«˜èµ„æºè¯­è¨€å¯¹çš„å•è¯­å’Œè¾…åŠ©å¹¶è¡Œæ•°æ®ï¼Œé€šè¿‡ä¸‰ä¸ª-é˜¶æ®µè®­ç»ƒè®¡åˆ’ã€‚æˆ‘ä»¬ä¼˜äºè¿™äº›è¯­è¨€çš„æ‰€æœ‰å½“å‰æœ€å…ˆè¿›çš„æ— ç›‘ç£åŸºçº¿ï¼Œå®ç°äº†é«˜è¾¾ 14.4 BLEU çš„å¢ç›Šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨å„ç§è¯­è¨€å¯¹çš„ç›‘ç£ WMT æäº¤ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¸”ä¸å½“å‰æœ€å…ˆè¿›çš„å°¼æ³Šå°”è¯­-è‹±è¯­ç›‘ç£æ¨¡å‹çš„æ€§èƒ½ç›¸åŒ¹é…ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€ç³»åˆ—æ¶ˆèç ”ç©¶ï¼Œä»¥å»ºç«‹æˆ‘ä»¬æ¨¡å‹åœ¨ä¸åŒæ•°æ®è´¨é‡ç¨‹åº¦ä¸‹çš„ç¨³å¥æ€§ï¼Œå¹¶åˆ†æå¯¼è‡´æ‰€æå‡ºæ–¹æ³•ä¼˜äºä¼ ç»Ÿæ— ç›‘ç£æ¨¡å‹çš„å› ç´ ã€‚</td><td>Xavier Garcia   Aditya Siddhant   Orhan Firat   Ankur P. Parikh</td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.06799&#39;]">Towards Continual Learning for Multilingual Machine Translation via Vocabulary Substitution</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2103.06799">https://arxiv.org/pdf/2103.06799</a></td><td>We propose a straightforward vocabulary adaptation scheme to extend the language capacity of multilingual machine translation models, paving the way towards efficient continual learning for multilingual machine translation. Our approach is suitable for large-scale datasets, applies to distant languages with unseen scripts, incurs only minor degradation on the translation performance for the original language pairs and provides competitive performance even in the case where we only possess monolingual data for the new languages.</td><td>æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•çš„è¯æ±‡é€‚åº”æ–¹æ¡ˆæ¥æ‰©å±•å¤šè¯­è¨€æœºå™¨ç¿»è¯‘æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›ï¼Œä¸ºå¤šè¯­è¨€æœºå™¨ç¿»è¯‘çš„é«˜æ•ˆæŒç»­å­¦ä¹ é“ºå¹³é“è·¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®é›†ï¼Œé€‚ç”¨äºå…·æœ‰çœ‹ä¸è§çš„è„šæœ¬çš„è¿œç¨‹è¯­è¨€ï¼Œå¯¹åŸå§‹è¯­è¨€å¯¹çš„ç¿»è¯‘æ€§èƒ½ä»…é€ æˆè½»å¾®çš„ä¸‹é™ï¼Œå¹¶ä¸”å³ä½¿åœ¨æˆ‘ä»¬ä»…æ‹¥æœ‰æ–°è¯­è¨€çš„å•è¯­æ•°æ®çš„æƒ…å†µä¸‹ä¹Ÿèƒ½æä¾›æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚</td><td>Xavier Garcia   Noah Constant   Ankur P. Parikh   Orhan Firat</td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2003.09586&#39;]">Probing Word Translations in the Transformer and Trading Decoder for Encoder Layers</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2003.09586">https://arxiv.org/pdf/2003.09586</a></td><td>Due to its effectiveness and performance, the Transformer translation model has attracted wide attention, most recently in terms of probing-based approaches. Previous work focuses on using or probing source linguistic features in the encoder. To date, the way word translation evolves in Transformer layers has not yet been investigated. Naively, one might assume that encoder layers capture source information while decoder layers translate. In this work, we show that this is not quite the case: translation already happens progressively in encoder layers and even in the input embeddings. More surprisingly, we find that some of the lower decoder layers do not actually do that much decoding. We show all of this in terms of a probing approach where we project representations of the layer analyzed to the final trained and frozen classifier level of the Transformer decoder to measure word translation accuracy. Our findings motivate and explain a Transformer configuration change: if translation already happens in the encoder layers, perhaps we can increase the number of encoder layers, while decreasing the number of decoder layers, boosting decoding speed, without loss in translation quality? Our experiments show that this is indeed the case: we can increase speed by up to a factor 2.3 with small gains in translation quality, while an 18-4 deep encoder configuration boosts translation quality by +1.42 BLEU (En-De) at a speed-up of 1.4.</td><td>ç”±äºå…¶æœ‰æ•ˆæ€§å’Œæ€§èƒ½ï¼ŒTransformer ç¿»è¯‘æ¨¡å‹å¼•èµ·äº†å¹¿æ³›å…³æ³¨ï¼Œæœ€è¿‘åœ¨åŸºäºæ¢æµ‹çš„æ–¹æ³•æ–¹é¢ã€‚ä»¥å‰çš„å·¥ä½œä¾§é‡äºåœ¨ç¼–ç å™¨ä¸­ä½¿ç”¨æˆ–æ¢æµ‹æºè¯­è¨€ç‰¹å¾ã€‚è¿„ä»Šä¸ºæ­¢ï¼Œå°šæœªç ”ç©¶å•è¯ç¿»è¯‘åœ¨ Transformer å±‚ä¸­çš„æ¼”å˜æ–¹å¼ã€‚å¤©çœŸåœ°ï¼Œäººä»¬å¯èƒ½ä¼šå‡è®¾ç¼–ç å™¨å±‚åœ¨è§£ç å™¨å±‚è½¬æ¢æ—¶æ•è·æºä¿¡æ¯ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜æƒ…å†µå¹¶éå¦‚æ­¤ï¼šç¿»è¯‘å·²ç»åœ¨ç¼–ç å™¨å±‚ç”šè‡³è¾“å…¥åµŒå…¥ä¸­é€æ­¥å‘ç”Ÿã€‚æ›´ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°ä¸€äº›è¾ƒä½çš„è§£ç å™¨å±‚å®é™…ä¸Šå¹¶æ²¡æœ‰åšé‚£ä¹ˆå¤šè§£ç ã€‚æˆ‘ä»¬ä»¥æ¢æµ‹æ–¹æ³•å±•ç¤ºäº†æ‰€æœ‰è¿™äº›ï¼Œå…¶ä¸­æˆ‘ä»¬å°†åˆ†æçš„å±‚çš„è¡¨ç¤ºæŠ•å½±åˆ° Transformer è§£ç å™¨çš„æœ€ç»ˆè®­ç»ƒå’Œå†»ç»“åˆ†ç±»å™¨çº§åˆ«ï¼Œä»¥æµ‹é‡å•è¯ç¿»è¯‘çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„å‘ç°æ¿€å‘å¹¶è§£é‡Šäº† Transformer é…ç½®çš„å˜åŒ–ï¼šå¦‚æœç¿»è¯‘å·²ç»å‘ç”Ÿåœ¨ç¼–ç å™¨å±‚ï¼Œä¹Ÿè®¸æˆ‘ä»¬å¯ä»¥å¢åŠ ç¼–ç å™¨å±‚çš„æ•°é‡ï¼ŒåŒæ—¶å‡å°‘è§£ç å™¨å±‚çš„æ•°é‡ï¼Œæé«˜è§£ç é€Ÿåº¦ï¼Œè€Œä¸æŸå¤±ç¿»è¯‘è´¨é‡ï¼Ÿæˆ‘ä»¬çš„å®éªŒè¡¨æ˜æƒ…å†µç¡®å®å¦‚æ­¤ï¼šæˆ‘ä»¬å¯ä»¥å°†é€Ÿåº¦æé«˜ 2.3 å€ï¼Œè€Œç¿»è¯‘è´¨é‡çš„æé«˜å¾ˆå°ï¼Œè€Œ 18-4 æ·±åº¦ç¼–ç å™¨é…ç½®ä»¥ +1.42 BLEU (En-De) çš„é€Ÿåº¦å°†ç¿»è¯‘è´¨é‡æé«˜- 1.4ã€‚</td><td>Hongfei Xu   Josef van Genabith   Qiuhui Liu   Deyi Xiong</td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.06490&#39;, &#39;https://arxiv.org/abs/1911.00234&#39;]">Sequence Tagging and Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1911.00234">https://arxiv.org/pdf/1911.00234</a></td><td>While deep learning is a powerful tool for natural language processing (NLP) problems, successful solutions to these problems rely heavily on large amounts of annotated samples. However, manually annotating data is expensive and time-consuming. Active Learning (AL) strategies reduce the need for huge volumes of labeled data by iteratively selecting a small number of examples for manual annotation based on their estimated utility in training the given model. In this paper, we argue that since AL strategies choose examples independently, they may potentially select similar examples, all of which may not contribute significantly to the learning process. Our proposed approach, Active$\mathbf{^2}$ Learning (A$\mathbf{^2}$L), actively adapts to the deep learning model being trained to eliminate further such redundant examples chosen by an AL strategy. We show that A$\mathbf{^2}$L is widely applicable by using it in conjunction with several different AL strategies and NLP tasks. We empirically demonstrate that the proposed approach is further able to reduce the data requirements of state-of-the-art AL strategies by an absolute percentage reduction of $\approx\mathbf{3-25\%}$ on multiple NLP tasks while achieving the same performance with no additional computation overhead.</td><td>è™½ç„¶æ·±åº¦å­¦ä¹ æ˜¯è§£å†³è‡ªç„¶è¯­è¨€å¤„ç† (NLP) é—®é¢˜çš„å¼ºå¤§å·¥å…·ï¼Œä½†è¿™äº›é—®é¢˜çš„æˆåŠŸè§£å†³æ–¹æ¡ˆåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºå¤§é‡å¸¦æ³¨é‡Šçš„æ ·æœ¬ã€‚ä½†æ˜¯ï¼Œæ‰‹åŠ¨æ³¨é‡Šæ•°æ®æ—¢æ˜‚è´µåˆè€—æ—¶ã€‚ä¸»åŠ¨å­¦ä¹  (AL) ç­–ç•¥é€šè¿‡è¿­ä»£é€‰æ‹©å°‘é‡ç¤ºä¾‹è¿›è¡Œæ‰‹åŠ¨æ³¨é‡Šï¼ŒåŸºäºå®ƒä»¬åœ¨è®­ç»ƒç»™å®šæ¨¡å‹ä¸­çš„ä¼°è®¡æ•ˆç”¨ï¼Œå‡å°‘äº†å¯¹å¤§é‡æ ‡è®°æ•°æ®çš„éœ€æ±‚ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºç”±äº AL ç­–ç•¥ç‹¬ç«‹é€‰æ‹©ç¤ºä¾‹ï¼Œå®ƒä»¬å¯èƒ½ä¼šé€‰æ‹©ç›¸ä¼¼çš„ç¤ºä¾‹ï¼Œæ‰€æœ‰è¿™äº›ç¤ºä¾‹å¯èƒ½å¯¹å­¦ä¹ è¿‡ç¨‹æ²¡æœ‰æ˜¾ç€è´¡çŒ®ã€‚æˆ‘ä»¬æå‡ºçš„æ–¹æ³• Active$\mathbf{^2}$ Learning (A$\mathbf{^2}$L) ä¸»åŠ¨é€‚åº”æ­£åœ¨è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä»¥è¿›ä¸€æ­¥æ¶ˆé™¤ AL ç­–ç•¥é€‰æ‹©çš„æ­¤ç±»å†—ä½™ç¤ºä¾‹ã€‚æˆ‘ä»¬é€šè¿‡å°† A$\mathbf{^2}$L ä¸å‡ ç§ä¸åŒçš„ AL ç­–ç•¥å’Œ NLP ä»»åŠ¡ç»“åˆä½¿ç”¨ï¼Œè¡¨æ˜å®ƒå…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚æˆ‘ä»¬å‡­ç»éªŒè¯æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿé€šè¿‡åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸Šå‡å°‘ $\approx\mathbf{3-25\%}$ çš„ç»å¯¹ç™¾åˆ†æ¯”æ¥è¿›ä¸€æ­¥é™ä½æœ€å…ˆè¿›çš„ AL ç­–ç•¥çš„æ•°æ®éœ€æ±‚ï¼ŒåŒæ—¶å®ç°ç›¸åŒçš„æ€§èƒ½ï¼Œæ²¡æœ‰é¢å¤–çš„è®¡ç®—å¼€é”€ã€‚</td><td>Rishi Hazra   Parag Dutta   Shubham Gupta   Mohammed Abdul Qaathir   Ambedkar Dukkipati   Rishi Hazra   Parag Dutta   Shubham Gupta   Mohammed Abdul Qaathir   Ambedkar Dukkipati</td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2008.09396&#39;]">Neural Machine Translation without Embeddings</a></td><td></td><td><a href="https://github.com/UriSha/EmbeddinglessNMT">https://github.com/UriSha/EmbeddinglessNMT</a></td><td><a href="https://arxiv.org/pdf/2008.09396">https://arxiv.org/pdf/2008.09396</a></td><td>Many NLP models operate over sequences of subword tokens produced by hand-crafted tokenization rules and heuristic subword induction algorithms. A simple universal alternative is to represent every computerized text as a sequence of bytes via UTF-8, obviating the need for an embedding layer since there are fewer token types (256) than dimensions. Surprisingly, replacing the ubiquitous embedding layer with one-hot representations of each byte does not hurt performance; experiments on byte-to-byte machine translation from English to 10 different languages show a consistent improvement in BLEU, rivaling character-level and even standard subword-level models. A deeper investigation reveals that the combination of embeddingless models with decoder-input dropout amounts to token dropout, which benefits byte-to-byte models in particular.</td><td></td><td>Uri Shaham   Omer Levy</td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.07316&#39;]">From Masked Language Modeling to Translation: Non-English Auxiliary Tasks Improve Zero-shot Spoken Language Understanding</a></td><td></td><td><a href="https://bitbucket.org/robvanderg/xsid">https://bitbucket.org/robvanderg/xsid</a></td><td><a href="https://arxiv.org/pdf/2105.07316">https://arxiv.org/pdf/2105.07316</a></td><td>The lack of publicly available evaluation data for low-resource languages limits progress in Spoken Language Understanding (SLU). As key tasks like intent classification and slot filling require abundant training data, it is desirable to reuse existing data in high-resource languages to develop models for low-resource scenarios. We introduce xSID, a new benchmark for cross-lingual Slot and Intent Detection in 13 languages from 6 language families, including a very low-resource dialect. To tackle the challenge, we propose a joint learning approach, with English SLU training data and non-English auxiliary tasks from raw text, syntax and translation for transfer. We study two setups which differ by type and language coverage of the pre-trained embeddings. Our results show that jointly learning the main tasks with masked language modeling is effective for slots, while machine translation transfer works best for intent classification.</td><td>ç¼ºä¹å¯¹ä½èµ„æºè¯­è¨€çš„å…¬å¼€è¯„ä¼°æ•°æ®é™åˆ¶äº†å£è¯­ç†è§£ (SLU) çš„è¿›å±•ã€‚ç”±äºæ„å›¾åˆ†ç±»å’Œæ§½å¡«å……ç­‰å…³é”®ä»»åŠ¡éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œå› æ­¤éœ€è¦é‡ç”¨é«˜èµ„æºè¯­è¨€çš„ç°æœ‰æ•°æ®æ¥å¼€å‘ä½èµ„æºåœºæ™¯çš„æ¨¡å‹ã€‚æˆ‘ä»¬å¼•å…¥äº† xSIDï¼Œè¿™æ˜¯ä¸€ç§è·¨è¯­è¨€æ§½å’Œæ„å›¾æ£€æµ‹çš„æ–°åŸºå‡†ï¼Œç”¨äº 6 ä¸ªè¯­è¨€å®¶æ—çš„ 13 ç§è¯­è¨€ï¼ŒåŒ…æ‹¬èµ„æºéå¸¸å°‘çš„æ–¹è¨€ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è”åˆå­¦ä¹ æ–¹æ³•ï¼Œä½¿ç”¨è‹±è¯­ SLU è®­ç»ƒæ•°æ®å’Œæ¥è‡ªåŸå§‹æ–‡æœ¬ã€è¯­æ³•å’Œç¿»è¯‘çš„éè‹±è¯­è¾…åŠ©ä»»åŠ¡è¿›è¡Œè¿ç§»ã€‚æˆ‘ä»¬ç ”ç©¶äº†ä¸¤ç§ä¸åŒçš„è®¾ç½®ï¼Œå®ƒä»¬å› é¢„è®­ç»ƒåµŒå…¥çš„ç±»å‹å’Œè¯­è¨€è¦†ç›–èŒƒå›´è€Œå¼‚ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æ©ç è¯­è¨€å»ºæ¨¡è”åˆå­¦ä¹ ä¸»è¦ä»»åŠ¡å¯¹æ§½æœ‰æ•ˆï¼Œè€Œæœºå™¨ç¿»è¯‘è¿ç§»æœ€é€‚åˆæ„å›¾åˆ†ç±»ã€‚</td><td>Rob van der Goot   Ibrahim Sharaf   Aizhan Imankulova   Ahmet ÃœstÃ¼n   Marija StepanoviÄ‡   Alan Ramponi   Siti Oryza Khairunnisa   Mamoru Komachi   Barbara Plank</td></tr><tr><td>8</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.10531&#39;]">Improving the Lexical Ability of Pretrained Language Models for Unsupervised Neural Machine Translation</a></td><td></td><td><a href="https://github.com/alexandra-chron/lexical_xlm_relm">https://github.com/alexandra-chron/lexical_xlm_relm</a></td><td><a href="https://arxiv.org/pdf/2103.10531">https://arxiv.org/pdf/2103.10531</a></td><td>Successful methods for unsupervised neural machine translation (UNMT) employ crosslingual pretraining via self-supervision, often in the form of a masked language modeling or a sequence generation task, which requires the model to align the lexical- and high-level representations of the two languages. While cross-lingual pretraining works for similar languages with abundant corpora, it performs poorly in low-resource and distant languages. Previous research has shown that this is because the representations are not sufficiently aligned. In this paper, we enhance the bilingual masked language model pretraining with lexical-level information by using type-level cross-lingual subword embeddings. Empirical results demonstrate improved performance both on UNMT (up to 4.5 BLEU) and bilingual lexicon induction using our method compared to a UNMT baseline.</td><td>æ— ç›‘ç£ç¥ç»æœºå™¨ç¿»è¯‘ (UNMT) çš„æˆåŠŸæ–¹æ³•é€šè¿‡è‡ªæˆ‘ç›‘ç£é‡‡ç”¨è·¨è¯­è¨€é¢„è®­ç»ƒï¼Œé€šå¸¸é‡‡ç”¨æ©ç è¯­è¨€å»ºæ¨¡æˆ–åºåˆ—ç”Ÿæˆä»»åŠ¡çš„å½¢å¼ï¼Œè¿™éœ€è¦æ¨¡å‹å¯¹é½ä¸¤è€…çš„è¯æ±‡å’Œé«˜çº§è¡¨ç¤ºè¯­è¨€ã€‚è™½ç„¶è·¨è¯­è¨€é¢„è®­ç»ƒé€‚ç”¨äºå…·æœ‰ä¸°å¯Œè¯­æ–™åº“çš„ç›¸ä¼¼è¯­è¨€ï¼Œä½†å®ƒåœ¨èµ„æºåŒ®ä¹å’Œè·ç¦»è¾ƒè¿œçš„è¯­è¨€ä¸­è¡¨ç°ä¸ä½³ã€‚å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼Œè¿™æ˜¯å› ä¸ºè¡¨ç¤ºæ²¡æœ‰å……åˆ†å¯¹é½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨ç±»å‹çº§åˆ«çš„è·¨è¯­è¨€å­è¯åµŒå…¥æ¥å¢å¼ºå…·æœ‰è¯æ±‡çº§åˆ«ä¿¡æ¯çš„åŒè¯­æ©ç è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œä¸ UNMT åŸºçº¿ç›¸æ¯”ï¼Œä½¿ç”¨æˆ‘ä»¬çš„æ–¹æ³•åœ¨ UNMTï¼ˆé«˜è¾¾ 4.5 BLEUï¼‰å’ŒåŒè¯­è¯å…¸å½’çº³æ–¹é¢çš„æ€§èƒ½éƒ½æœ‰æ‰€æé«˜ã€‚</td><td>Alexandra Chronopoulou   Dario Stojanovski   Alexander Fraser</td></tr><tr><td>9</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12868&#39;]">Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/yongchanghao/multi-task-nat">https://github.com/yongchanghao/multi-task-nat</a></td><td><a href="https://arxiv.org/pdf/2010.12868">https://arxiv.org/pdf/2010.12868</a></td><td>Non-Autoregressive machine Translation (NAT) models have demonstrated significant inference speedup but suffer from inferior translation accuracy. The common practice to tackle the problem is transferring the Autoregressive machine Translation (AT) knowledge to NAT models, e.g., with knowledge distillation. In this work, we hypothesize and empirically verify that AT and NAT encoders capture different linguistic properties of source sentences. Therefore, we propose to adopt Multi-Task learning to transfer the AT knowledge to NAT models through encoder sharing. Specifically, we take the AT model as an auxiliary task to enhance NAT model performance. Experimental results on WMT14 English-German and WMT16 English-Romanian datasets show that the proposed Multi-Task NAT achieves significant improvements over the baseline NAT models. Furthermore, the performance on large-scale WMT19 and WMT20 English-German datasets confirm the consistency of our proposed method. In addition, experimental results demonstrate that our Multi-Task NAT is complementary to knowledge distillation, the standard knowledge transfer method for NAT.</td><td>éè‡ªå›å½’æœºå™¨ç¿»è¯‘ (NAT) æ¨¡å‹å·²ç»è¯æ˜äº†æ˜¾ç€çš„æ¨ç†åŠ é€Ÿï¼Œä½†ç¿»è¯‘å‡†ç¡®æ€§è¾ƒå·®ã€‚è§£å†³è¯¥é—®é¢˜çš„å¸¸è§åšæ³•æ˜¯å°†è‡ªå›å½’æœºå™¨ç¿»è¯‘ (AT) çŸ¥è¯†è½¬ç§»åˆ° NAT æ¨¡å‹ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å‡è®¾å¹¶å‡­ç»éªŒéªŒè¯ AT å’Œ NAT ç¼–ç å™¨æ•è·æºå¥å­çš„ä¸åŒè¯­è¨€å±æ€§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å»ºè®®é‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ ï¼Œé€šè¿‡ç¼–ç å™¨å…±äº«å°† AT çŸ¥è¯†è½¬ç§»åˆ° NAT æ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°† AT æ¨¡å‹ä½œä¸ºè¾…åŠ©ä»»åŠ¡æ¥å¢å¼º NAT æ¨¡å‹çš„æ€§èƒ½ã€‚ WMT14 English-German å’Œ WMT16 English-Romanian æ•°æ®é›†çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„å¤šä»»åŠ¡ NAT æ¯”åŸºçº¿ NAT æ¨¡å‹å–å¾—äº†æ˜¾ç€çš„æ”¹è¿›ã€‚æ­¤å¤–ï¼Œå¤§è§„æ¨¡ WMT19 å’Œ WMT20 è‹±å¾·æ•°æ®é›†çš„æ€§èƒ½è¯å®äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å¤šä»»åŠ¡ NAT æ˜¯çŸ¥è¯†è’¸é¦çš„è¡¥å……ï¼Œè¿™æ˜¯ NAT çš„æ ‡å‡†çŸ¥è¯†è½¬ç§»æ–¹æ³•ã€‚</td><td>Yongchang Hao   Shilin He   Wenxiang Jiao   Zhaopeng Tu   Michael Lyu   Xing Wang</td></tr><tr><td>10</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05146&#39;]">Assessing Reference-Free Peer Evaluation for Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.05146">https://arxiv.org/pdf/2104.05146</a></td><td>Reference-free evaluation has the potential to make machine translation evaluation substantially more scalable, allowing us to pivot easily to new languages or domains. It has been recently shown that the probabilities given by a large, multilingual model can achieve state of the art results when used as a reference-free metric. We experiment with various modifications to this model and demonstrate that by scaling it up we can match the performance of BLEU. We analyze various potential weaknesses of the approach and find that it is surprisingly robust and likely to offer reasonable performance across a broad spectrum of domains and different system qualities.</td><td></td><td>Sweta Agrawal   George Foster   Markus Freitag   Colin Cherry</td></tr><tr><td>11</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2009.09654&#39;]">Generative Imagination Elevates Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.09654">https://arxiv.org/pdf/2009.09654</a></td><td>There are common semantics shared across text and images. Given a sentence in a source language, whether depicting the visual scene helps translation into a target language? Existing multimodal neural machine translation methods (MNMT) require triplets of bilingual sentence - image for training and tuples of source sentence - image for inference. In this paper, we propose ImagiT, a novel machine translation method via visual imagination. ImagiT first learns to generate visual representation from the source sentence, and then utilizes both source sentence and the â€œimagined representationâ€ to produce a target translation. Unlike previous methods, it only needs the source sentence at the inference time. Experiments demonstrate that ImagiT benefits from visual imagination and significantly outperforms the text-only neural machine translation baselines. Further analysis reveals that the imagination process in ImagiT helps fill in missing information when performing the degradation strategy.</td><td>æ–‡æœ¬å’Œå›¾åƒä¹‹é—´å…±äº«é€šç”¨è¯­ä¹‰ã€‚ç»™å®šä¸€ä¸ªæºè¯­è¨€çš„å¥å­ï¼Œæç»˜è§†è§‰åœºæ™¯æ˜¯å¦æœ‰åŠ©äºç¿»è¯‘æˆç›®æ ‡è¯­è¨€ï¼Ÿç°æœ‰çš„å¤šæ¨¡æ€ç¥ç»æœºå™¨ç¿»è¯‘æ–¹æ³• (MNMT) éœ€è¦åŒè¯­å¥å­çš„ä¸‰å…ƒç»„ - ç”¨äºè®­ç»ƒçš„å›¾åƒå’Œç”¨äºæ¨ç†çš„æºå¥å…ƒç»„ - å›¾åƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† ImagiTï¼Œä¸€ç§é€šè¿‡è§†è§‰æƒ³è±¡çš„æ–°å‹æœºå™¨ç¿»è¯‘æ–¹æ³•ã€‚ ImagiT é¦–å…ˆå­¦ä¹ ä»æºå¥ç”Ÿæˆè§†è§‰è¡¨ç¤ºï¼Œç„¶ååˆ©ç”¨æºå¥å’Œâ€œæƒ³è±¡çš„è¡¨ç¤ºâ€æ¥ç”Ÿæˆç›®æ ‡ç¿»è¯‘ã€‚ä¸ä»¥å‰çš„æ–¹æ³•ä¸åŒï¼Œå®ƒåªéœ€è¦æ¨ç†æ—¶çš„æºè¯­å¥ã€‚å®éªŒè¡¨æ˜ï¼ŒImagiT å—ç›Šäºè§†è§‰æƒ³è±¡åŠ›ï¼Œå¹¶æ˜¾ç€ä¼˜äºçº¯æ–‡æœ¬ç¥ç»æœºå™¨ç¿»è¯‘åŸºçº¿ã€‚è¿›ä¸€æ­¥çš„åˆ†æè¡¨æ˜ï¼Œåœ¨æ‰§è¡Œé€€åŒ–ç­–ç•¥æ—¶ï¼ŒImagiT ä¸­çš„æƒ³è±¡è¿‡ç¨‹æœ‰åŠ©äºå¡«è¡¥ç¼ºå¤±çš„ä¿¡æ¯ã€‚</td><td>Quanyu Long   Mingxuan Wang   Lei Li</td></tr><tr><td>12</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12827&#39;]">Context-aware Decoder for Neural Machine Translation using a Target-side Document-Level Language Model</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12827">https://arxiv.org/pdf/2010.12827</a></td><td>Although many context-aware neural machine translation models have been proposed to incorporate contexts in translation, most of those models are trained end-to-end on parallel documents aligned in sentence-level. Because only a few domains (and language pairs) have such document-level parallel data, we cannot perform accurate context-aware translation in most domains. We therefore present a simple method to turn a sentence-level translation model into a context-aware model by incorporating a document-level language model into the decoder. Our context-aware decoder is built upon only a sentence-level parallel corpora and monolingual corpora; thus no document-level parallel data is needed. In a theoretical viewpoint, the core part of this work is the novel representation of contextual information using point-wise mutual information between context and the current sentence. We show the effectiveness of our approach in three language pairs, English to French, English to Russian, and Japanese to English, by evaluation in \textsc{bleu} and contrastive tests for context-aware translation.</td><td>å°½ç®¡å·²ç»æå‡ºäº†è®¸å¤šä¸Šä¸‹æ–‡æ„ŸçŸ¥ç¥ç»æœºå™¨ç¿»è¯‘æ¨¡å‹æ¥å°†ä¸Šä¸‹æ–‡ç»“åˆåˆ°ç¿»è¯‘ä¸­ï¼Œä½†è¿™äº›æ¨¡å‹ä¸­çš„å¤§å¤šæ•°éƒ½æ˜¯åœ¨å¥å­çº§åˆ«å¯¹é½çš„å¹¶è¡Œæ–‡æ¡£ä¸Šè¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒçš„ã€‚å› ä¸ºåªæœ‰å°‘æ•°åŸŸï¼ˆå’Œè¯­è¨€å¯¹ï¼‰æœ‰è¿™æ ·çš„æ–‡æ¡£çº§å¹¶è¡Œæ•°æ®ï¼Œæˆ‘ä»¬æ— æ³•åœ¨å¤§å¤šæ•°åŸŸä¸­æ‰§è¡Œå‡†ç¡®çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç¿»è¯‘ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•çš„æ–¹æ³•ï¼Œé€šè¿‡å°†æ–‡æ¡£çº§è¯­è¨€æ¨¡å‹åˆå¹¶åˆ°è§£ç å™¨ä¸­ï¼Œå°†å¥å­çº§ç¿»è¯‘æ¨¡å‹è½¬å˜ä¸ºä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨¡å‹ã€‚æˆ‘ä»¬çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§£ç å™¨ä»…å»ºç«‹åœ¨å¥å­çº§å¹³è¡Œè¯­æ–™åº“å’Œå•è¯­è¯­æ–™åº“ä¸Šï¼›å› æ­¤ä¸éœ€è¦æ–‡æ¡£çº§å¹¶è¡Œæ•°æ®ã€‚ä»ç†è®ºçš„è§’åº¦æ¥çœ‹ï¼Œè¿™é¡¹å·¥ä½œçš„æ ¸å¿ƒéƒ¨åˆ†æ˜¯ä½¿ç”¨ä¸Šä¸‹æ–‡å’Œå½“å‰å¥å­ä¹‹é—´çš„é€ç‚¹äº’ä¿¡æ¯å¯¹ä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œæ–°é¢–çš„è¡¨ç¤ºã€‚æˆ‘ä»¬é€šè¿‡ \textsc{bleu} ä¸­çš„è¯„ä¼°å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥ç¿»è¯‘çš„å¯¹æ¯”æµ‹è¯•ï¼Œå±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨è‹±è¯­åˆ°æ³•è¯­ã€è‹±è¯­åˆ°ä¿„è¯­å’Œæ—¥è¯­åˆ°è‹±è¯­è¿™ä¸‰ç§è¯­è¨€å¯¹ä¸­çš„æœ‰æ•ˆæ€§ã€‚</td><td>Amane Sugiyama   Naoki Yoshinaga</td></tr><tr><td>13</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05964&#39;]">Restoring and Mining the Records of the Joseon Dynasty via Neural Language Modeling and Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.05964">https://arxiv.org/pdf/2104.05964</a></td><td>Understanding voluminous historical records provides clues on the past in various aspects, such as social and political issues and even natural science facts. However, it is generally difficult to fully utilize the historical records, since most of the documents are not written in a modern language and part of the contents are damaged over time. As a result, restoring the damaged or unrecognizable parts as well as translating the records into modern languages are crucial tasks. In response, we present a multi-task learning approach to restore and translate historical documents based on a self-attention mechanism, specifically utilizing two Korean historical records, ones of the most voluminous historical records in the world. Experimental results show that our approach significantly improves the accuracy of the translation task than baselines without multi-task learning. In addition, we present an in-depth exploratory analysis on our translated results via topic modeling, uncovering several significant historical events.</td><td>äº†è§£å¤§é‡çš„å†å²è®°å½•å¯ä»¥ä»å„ä¸ªæ–¹é¢æä¾›æœ‰å…³è¿‡å»çš„çº¿ç´¢ï¼Œä¾‹å¦‚ç¤¾ä¼šå’Œæ”¿æ²»é—®é¢˜ï¼Œç”šè‡³è‡ªç„¶ç§‘å­¦äº‹å®ã€‚ç„¶è€Œï¼Œè¦å……åˆ†åˆ©ç”¨å†å²è®°å½•ï¼Œä¸€èˆ¬æ¥è¯´æ˜¯å›°éš¾çš„ï¼Œå› ä¸ºå¤§å¤šæ•°æ–‡ä»¶ä¸æ˜¯ç”¨ç°ä»£è¯­è¨€å†™æˆçš„ï¼Œéƒ¨åˆ†å†…å®¹éšç€æ—¶é—´çš„æ¨ç§»è€ŒæŸåã€‚å› æ­¤ï¼Œä¿®å¤æŸåæˆ–æ— æ³•è¯†åˆ«çš„éƒ¨åˆ†ä»¥åŠå°†è®°å½•ç¿»è¯‘æˆç°ä»£è¯­è¨€æ˜¯è‡³å…³é‡è¦çš„ä»»åŠ¡ã€‚ä½œä¸ºå›åº”ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•æ¥æ¢å¤å’Œç¿»è¯‘å†å²æ–‡çŒ®ï¼Œç‰¹åˆ«æ˜¯åˆ©ç”¨äº†ä¸¤ä¸ªéŸ©å›½å†å²è®°å½•ï¼Œè¿™æ˜¯ä¸–ç•Œä¸Šæœ€ä¸°å¯Œçš„å†å²è®°å½•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æ²¡æœ‰å¤šä»»åŠ¡å­¦ä¹ çš„åŸºçº¿ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾ç€æé«˜äº†ç¿»è¯‘ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡ä¸»é¢˜å»ºæ¨¡å¯¹æˆ‘ä»¬çš„ç¿»è¯‘ç»“æœè¿›è¡Œäº†æ·±å…¥çš„æ¢ç´¢æ€§åˆ†æï¼Œæ­ç¤ºäº†å‡ ä¸ªé‡è¦çš„å†å²äº‹ä»¶ã€‚</td><td>Kyeongpil Kang   Kyohoon Jin   Soyoung Yang   Sujin Jang   Jaegul Choo   Youngbin Kim</td></tr><tr><td>14</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.06683&#39;]">The Curious Case of Hallucinations in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/vyraun/hallucinations">https://github.com/vyraun/hallucinations</a></td><td><a href="https://arxiv.org/pdf/2104.06683">https://arxiv.org/pdf/2104.06683</a></td><td>In this work, we study hallucinations in Neural Machine Translation (NMT), which lie at an extreme end on the spectrum of NMT pathologies. Firstly, we connect the phenomenon of hallucinations under source perturbation to the Long-Tail theory of Feldman (2020), and present an empirically validated hypothesis that explains hallucinations under source perturbation. Secondly, we consider hallucinations under corpus-level noise (without any source perturbation) and demonstrate that two prominent types of natural hallucinations (detached and oscillatory outputs) could be generated and explained through specific corpus-level noise patterns. Finally, we elucidate the phenomenon of hallucination amplification in popular data-generation processes such as Backtranslation and sequence-level Knowledge Distillation.</td><td>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ç¥ç»æœºå™¨ç¿»è¯‘ (NMT) ä¸­çš„å¹»è§‰ï¼Œå®ƒå¤„äº NMT ç—…ç†èŒƒå›´çš„æç«¯ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†æºæ‰°åŠ¨ä¸‹çš„å¹»è§‰ç°è±¡ä¸ Feldman (2020) çš„é•¿å°¾ç†è®ºè”ç³»èµ·æ¥ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç»è¿‡å®è¯éªŒè¯çš„å‡è®¾æ¥è§£é‡Šæºæ‰°åŠ¨ä¸‹çš„å¹»è§‰ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è€ƒè™‘äº†è¯­æ–™åº“çº§åˆ«å™ªå£°ï¼ˆæ²¡æœ‰ä»»ä½•æºæ‰°åŠ¨ï¼‰ä¸‹çš„å¹»è§‰ï¼Œå¹¶è¯æ˜å¯ä»¥é€šè¿‡ç‰¹å®šçš„è¯­æ–™åº“çº§åˆ«å™ªå£°æ¨¡å¼ç”Ÿæˆå’Œè§£é‡Šä¸¤ç§ä¸»è¦ç±»å‹çš„è‡ªç„¶å¹»è§‰ï¼ˆåˆ†ç¦»è¾“å‡ºå’ŒæŒ¯è¡è¾“å‡ºï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬é˜æ˜äº†æµè¡Œçš„æ•°æ®ç”Ÿæˆè¿‡ç¨‹ï¼ˆä¾‹å¦‚åå‘ç¿»è¯‘å’Œåºåˆ—çº§çŸ¥è¯†è’¸é¦ï¼‰ä¸­çš„å¹»è§‰æ”¾å¤§ç°è±¡ã€‚</td><td>Vikas Raunak   Arul Menezes   Marcin Junczys-Dowmunt</td></tr><tr><td>15</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.08942&#39;]">Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/samuki/reinforce-joey">https://github.com/samuki/reinforce-joey</a></td><td><a href="https://arxiv.org/pdf/2106.08942">https://arxiv.org/pdf/2106.08942</a></td><td>Policy gradient algorithms have found wide adoption in NLP, but have recently become subject to criticism, doubting their suitability for NMT. Choshen et al. (2020) identify multiple weaknesses and suspect that their success is determined by the shape of output distributions rather than the reward. In this paper, we revisit these claims and study them under a wider range of configurations. Our experiments on in-domain and cross-domain adaptation reveal the importance of exploration and reward scaling, and provide empirical counter-evidence to these claims.</td><td>ç­–ç•¥æ¢¯åº¦ç®—æ³•åœ¨ NLP ä¸­è¢«å¹¿æ³›é‡‡ç”¨ï¼Œä½†æœ€è¿‘å—åˆ°æ‰¹è¯„ï¼Œæ€€ç–‘å®ƒä»¬æ˜¯å¦é€‚ç”¨äº NMTã€‚ Choshen ç­‰äººã€‚ (2020) ç¡®å®šäº†å¤šä¸ªå¼±ç‚¹ï¼Œå¹¶æ€€ç–‘å®ƒä»¬çš„æˆåŠŸå–å†³äºè¾“å‡ºåˆ†å¸ƒçš„å½¢çŠ¶è€Œä¸æ˜¯å¥–åŠ±ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é‡æ–°å®¡è§†è¿™äº›ä¸»å¼ å¹¶åœ¨æ›´å¹¿æ³›çš„é…ç½®ä¸‹ç ”ç©¶å®ƒä»¬ã€‚æˆ‘ä»¬å¯¹åŸŸå†…å’Œè·¨åŸŸé€‚åº”çš„å®éªŒæ­ç¤ºäº†æ¢ç´¢å’Œå¥–åŠ±ç¼©æ”¾çš„é‡è¦æ€§ï¼Œå¹¶ä¸ºè¿™äº›ä¸»å¼ æä¾›äº†å®è¯åè¯ã€‚</td><td>Samuel Kiegeland   Julia Kreutzer</td></tr><tr><td>16</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.03137&#39;]">Cross-lingual Supervision Improves Unsupervised Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.03137">https://arxiv.org/pdf/2004.03137</a></td><td>Neural machine translation~(NMT) is ineffective for zero-resource languages. Recent works exploring the possibility of unsupervised neural machine translation (UNMT) with only monolingual data can achieve promising results. However, there are still big gaps between UNMT and NMT with parallel supervision. In this work, we introduce a multilingual unsupervised NMT (\method) framework to leverage weakly supervised signals from high-resource language pairs to zero-resource translation directions. More specifically, for unsupervised language pairs \texttt{En-De}, we can make full use of the information from parallel dataset \texttt{En-Fr} to jointly train the unsupervised translation directions all in one model. \method is based on multilingual models which require no changes to the standard unsupervised NMT. Empirical results demonstrate that \method significantly improves the translation quality by more than 3 BLEU score on six benchmark unsupervised translation directions.</td><td>ç¥ç»æœºå™¨ç¿»è¯‘~ï¼ˆNMTï¼‰å¯¹é›¶èµ„æºè¯­è¨€æ— æ•ˆã€‚æœ€è¿‘æ¢ç´¢ä»…ä½¿ç”¨å•è¯­æ•°æ®è¿›è¡Œæ— ç›‘ç£ç¥ç»æœºå™¨ç¿»è¯‘ (UNMT) çš„å¯èƒ½æ€§çš„å·¥ä½œå¯ä»¥è·å¾—æœ‰å¸Œæœ›çš„ç»“æœã€‚ç„¶è€Œï¼Œå¹¶è¡Œç›‘ç£çš„UNMTå’ŒNMTä¹‹é—´ä»ç„¶å­˜åœ¨å¾ˆå¤§å·®è·ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å¤šè¯­è¨€æ— ç›‘ç£ NMTï¼ˆ\methodï¼‰æ¡†æ¶ï¼Œä»¥åˆ©ç”¨æ¥è‡ªé«˜èµ„æºè¯­è¨€å¯¹çš„å¼±ç›‘ç£ä¿¡å·åˆ°é›¶èµ„æºç¿»è¯‘æ–¹å‘ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œå¯¹äºæ— ç›‘ç£è¯­è¨€å¯¹ \texttt{En-De}ï¼Œæˆ‘ä»¬å¯ä»¥å……åˆ†åˆ©ç”¨æ¥è‡ªå¹¶è¡Œæ•°æ®é›† \texttt{En-Fr} çš„ä¿¡æ¯ï¼Œåœ¨ä¸€ä¸ªæ¨¡å‹ä¸­è”åˆè®­ç»ƒæ— ç›‘ç£ç¿»è¯‘æ–¹å‘ã€‚ \method åŸºäºå¤šè¯­è¨€æ¨¡å‹ï¼Œæ— éœ€æ›´æ”¹æ ‡å‡†çš„æ— ç›‘ç£ NMTã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œ\method åœ¨å…­ä¸ªåŸºå‡†æ— ç›‘ç£ç¿»è¯‘æ–¹å‘ä¸Šæ˜¾ç€æé«˜äº†è¶…è¿‡ 3 BLEU åˆ†æ•°çš„ç¿»è¯‘è´¨é‡ã€‚</td><td>Mingxuan Wang   Hongxiao Bai   Hai Zhao   Lei Li</td></tr><tr><td>17</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.02461&#39;]">ReWE: Regressing Word Embeddings for Regularization of Neural Machine Translation Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.02461">https://arxiv.org/pdf/1904.02461</a></td><td>Regularization of neural machine translation is still a significant problem, especially in low-resource settings. To mollify this problem, we propose regressing word embeddings (ReWE) as a new regularization technique in a system that is jointly trained to predict the next word in the translation (categorical value) and its word embedding (continuous value). Such a joint training allows the proposed system to learn the distributional properties represented by the word embeddings, empirically improving the generalization to unseen sentences. Experiments over three translation datasets have showed a consistent improvement over a strong baseline, ranging between 0.91 and 2.54 BLEU points, and also a marked improvement over a state-of-the-art system.</td><td>ç¥ç»æœºå™¨ç¿»è¯‘çš„æ­£åˆ™åŒ–ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºåŒ®ä¹çš„ç¯å¢ƒä¸­ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºå›å½’è¯åµŒå…¥ (ReWE) ä½œä¸ºä¸€ç§æ–°çš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œè¯¥ç³»ç»Ÿç»è¿‡è”åˆè®­ç»ƒä»¥é¢„æµ‹ç¿»è¯‘ä¸­çš„ä¸‹ä¸€ä¸ªè¯ï¼ˆåˆ†ç±»å€¼ï¼‰åŠå…¶è¯åµŒå…¥ï¼ˆè¿ç»­å€¼ï¼‰ã€‚è¿™ç§è”åˆè®­ç»ƒå…è®¸æ‰€æå‡ºçš„ç³»ç»Ÿå­¦ä¹ ç”±è¯åµŒå…¥è¡¨ç¤ºçš„åˆ†å¸ƒç‰¹æ€§ï¼Œä»ç»éªŒä¸Šæ”¹è¿›å¯¹çœ‹ä¸è§çš„å¥å­çš„æ³›åŒ–ã€‚åœ¨ä¸‰ä¸ªç¿»è¯‘æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåœ¨å¼ºå¤§çš„åŸºçº¿ä¸Šæœ‰æŒç»­çš„æ”¹è¿›ï¼ŒèŒƒå›´åœ¨ 0.91 åˆ° 2.54 BLEU ç‚¹ä¹‹é—´ï¼Œå¹¶ä¸”æ¯”æœ€å…ˆè¿›çš„ç³»ç»Ÿä¹Ÿæœ‰æ˜¾ç€çš„æ”¹è¿›ã€‚</td><td>Inigo Jauregi Unanue   Ehsan Zare Borzeshi   Nazanin Esmaili   Massimo Piccardi</td></tr><tr><td>18</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09514&#39;]">Lost in Machine Translation: A Method to Reduce Meaning Loss</a></td><td></td><td><a href="https://github.com/reubenharry/pragmatic-translation">https://github.com/reubenharry/pragmatic-translation</a></td><td><a href="https://arxiv.org/pdf/1902.09514">https://arxiv.org/pdf/1902.09514</a></td><td>A desideratum of high-quality translation systems is that they preserve meaning, in the sense that two sentences with different meanings should not translate to one and the same sentence in another language. However, state-of-the-art systems often fail in this regard, particularly in cases where the source and target languages partition the â€œmeaning spaceâ€ in different ways. For instance, â€œI cut my finger.â€ and â€œI cut my finger off.â€ describe different states of the world but are translated to French (by both Fairseq and Google Translate) as â€œJe me suis coupe le doigt.â€, which is ambiguous as to whether the finger is detached. More generally, translation systems are typically many-to-one (non-injective) functions from source to target language, which in many cases results in important distinctions in meaning being lost in translation. Building on Bayesian models of informative utterance production, we present a method to define a less ambiguous translation system in terms of an underlying pre-trained neural sequence-to-sequence model. This method increases injectivity, resulting in greater preservation of meaning as measured by improvement in cycle-consistency, without impeding translation quality (measured by BLEU score).</td><td>é«˜è´¨é‡ç¿»è¯‘ç³»ç»Ÿçš„ä¸€ä¸ªå¿…è¦æ¡ä»¶æ˜¯å®ƒä»¬èƒ½å¤Ÿä¿ç•™æ„ä¹‰ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸¤ä¸ªæ„ä¹‰ä¸åŒçš„å¥å­ä¸åº”ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€çš„åŒä¸€ä¸ªå¥å­ã€‚ç„¶è€Œï¼Œæœ€å…ˆè¿›çš„ç³»ç»Ÿåœ¨è¿™æ–¹é¢ç»å¸¸å¤±è´¥ï¼Œç‰¹åˆ«æ˜¯åœ¨æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ä»¥ä¸åŒæ–¹å¼åˆ’åˆ†â€œæ„ä¹‰ç©ºé—´â€çš„æƒ…å†µä¸‹ã€‚ä¾‹å¦‚ï¼Œâ€œæˆ‘å‰²ç ´äº†æ‰‹æŒ‡â€ã€‚å’Œâ€œæˆ‘åˆ‡æ‰äº†æˆ‘çš„æ‰‹æŒ‡ã€‚â€æè¿°ä¸–ç•Œçš„ä¸åŒçŠ¶æ€ï¼Œä½†è¢«ç¿»è¯‘æˆæ³•è¯­ï¼ˆç”± Fairseq å’Œè°·æ­Œç¿»è¯‘ï¼‰ä¸ºâ€œJe me suis coupe le doigt.â€ï¼Œå¯¹äºæ‰‹æŒ‡æ˜¯å¦åˆ†ç¦»æ˜¯æ¨¡æ£±ä¸¤å¯çš„ã€‚æ›´ä¸€èˆ¬åœ°è¯´ï¼Œç¿»è¯‘ç³»ç»Ÿé€šå¸¸æ˜¯ä»æºè¯­è¨€åˆ°ç›®æ ‡è¯­è¨€çš„å¤šå¯¹ä¸€ï¼ˆéå†…å°„ï¼‰åŠŸèƒ½ï¼Œè¿™åœ¨è®¸å¤šæƒ…å†µä¸‹å¯¼è‡´ç¿»è¯‘ä¸­ä¸¢å¤±æ„ä¹‰çš„é‡è¦åŒºåˆ«ã€‚åŸºäºä¿¡æ¯æ€§è¯è¯­äº§ç”Ÿçš„è´å¶æ–¯æ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œæ ¹æ®åº•å±‚çš„é¢„è®­ç»ƒç¥ç»åºåˆ—åˆ°åºåˆ—æ¨¡å‹å®šä¹‰ä¸€ä¸ªä¸é‚£ä¹ˆæ¨¡ç³Šçš„ç¿»è¯‘ç³»ç»Ÿã€‚è¿™ç§æ–¹æ³•å¢åŠ äº†æ³¨å…¥æ€§ï¼Œä»è€Œåœ¨ä¸å½±å“ç¿»è¯‘è´¨é‡ï¼ˆç”± BLEU åˆ†æ•°è¡¡é‡ï¼‰çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡æ”¹è¿›å¾ªç¯ä¸€è‡´æ€§æ¥è¡¡é‡æ›´å¥½åœ°ä¿ç•™æ„ä¹‰ã€‚</td><td>Reuben Cohn-Gordon   Noah Goodman</td></tr><tr><td>19</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.02878&#39;]">Syntax-Enhanced Neural Machine Translation with Syntax-Aware Word Representations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1905.02878">https://arxiv.org/pdf/1905.02878</a></td><td>Syntax has been demonstrated highly effective in neural machine translation (NMT). Previous NMT models integrate syntax by representing 1-best tree outputs from a well-trained parsing system, e.g., the representative Tree-RNN and Tree-Linearization methods, which may suffer from error propagation. In this work, we propose a novel method to integrate source-side syntax implicitly for NMT. The basic idea is to use the intermediate hidden representations of a well-trained end-to-end dependency parser, which are referred to as syntax-aware word representations (SAWRs). Then, we simply concatenate such SAWRs with ordinary word embeddings to enhance basic NMT models. The method can be straightforwardly integrated into the widely-used sequence-to-sequence (Seq2Seq) NMT models. We start with a representative RNN-based Seq2Seq baseline system, and test the effectiveness of our proposed method on two benchmark datasets of the Chinese-English and English-Vietnamese translation tasks, respectively. Experimental results show that the proposed approach is able to bring significant BLEU score improvements on the two datasets compared with the baseline, 1.74 points for Chinese-English translation and 0.80 point for English-Vietnamese translation, respectively. In addition, the approach also outperforms the explicit Tree-RNN and Tree-Linearization methods.</td><td>è¯­æ³•å·²è¢«è¯æ˜åœ¨ç¥ç»æœºå™¨ç¿»è¯‘ (NMT) ä¸­éå¸¸æœ‰æ•ˆã€‚ä»¥å‰çš„ NMT æ¨¡å‹é€šè¿‡è¡¨ç¤ºæ¥è‡ªè®­ç»ƒæœ‰ç´ çš„è§£æç³»ç»Ÿçš„ 1-best æ ‘è¾“å‡ºæ¥é›†æˆè¯­æ³•ï¼Œä¾‹å¦‚ä»£è¡¨æ€§çš„ Tree-RNN å’Œ Tree-Linearization æ–¹æ³•ï¼Œå®ƒä»¬å¯èƒ½ä¼šå—åˆ°é”™è¯¯ä¼ æ’­çš„å½±å“ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸º NMT éšå¼é›†æˆæºç«¯è¯­æ³•çš„æ–°æ–¹æ³•ã€‚åŸºæœ¬æ€æƒ³æ˜¯ä½¿ç”¨è®­ç»ƒæœ‰ç´ çš„ç«¯åˆ°ç«¯ä¾èµ–è§£æå™¨çš„ä¸­é—´éšè—è¡¨ç¤ºï¼Œç§°ä¸ºè¯­æ³•æ„ŸçŸ¥è¯è¡¨ç¤º (SAWR)ã€‚ç„¶åï¼Œæˆ‘ä»¬ç®€å•åœ°å°†è¿™äº› SAWR ä¸æ™®é€šçš„è¯åµŒå…¥è¿æ¥èµ·æ¥ï¼Œä»¥å¢å¼ºåŸºæœ¬çš„ NMT æ¨¡å‹ã€‚è¯¥æ–¹æ³•å¯ä»¥ç›´æ¥é›†æˆåˆ°å¹¿æ³›ä½¿ç”¨çš„åºåˆ—åˆ°åºåˆ— (Seq2Seq) NMT æ¨¡å‹ä¸­ã€‚æˆ‘ä»¬ä»ä¸€ä¸ªä»£è¡¨æ€§çš„åŸºäº RNN çš„ Seq2Seq åŸºçº¿ç³»ç»Ÿå¼€å§‹ï¼Œå¹¶åˆ†åˆ«åœ¨æ±‰è‹±å’Œè‹±è¶Šç¿»è¯‘ä»»åŠ¡çš„ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæµ‹è¯•æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šå¸¦æ¥æ˜¾ç€çš„ BLEU åˆ†æ•°æ”¹è¿›ï¼Œæ±‰è‹±ç¿»è¯‘åˆ†åˆ«ä¸º 1.74 åˆ†å’Œè‹±è¶Šç¿»è¯‘ 0.80 åˆ†ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜ä¼˜äºæ˜¾å¼ Tree-RNN å’Œ Tree-Linearization æ–¹æ³•ã€‚</td><td>Meishan Zhang   Zhenghua Li   Guohong Fu   Min Zhang</td></tr><tr><td>20</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09508&#39;, &#39;https://arxiv.org/abs/1902.01509&#39;]">Improving Robustness of Machine Translation with Synthetic Noise</a></td><td></td><td><a href="https://github.com/MysteryVaibhav/robust_mtnt">https://github.com/MysteryVaibhav/robust_mtnt</a></td><td><a href="https://arxiv.org/pdf/1902.09508">https://arxiv.org/pdf/1902.09508</a></td><td>Modern Machine Translation (MT) systems perform consistently well on clean, in-domain text. However most human generated text, particularly in the realm of social media, is full of typos, slang, dialect, idiolect and other noise which can have a disastrous impact on the accuracy of output translation. In this paper we leverage the Machine Translation of Noisy Text (MTNT) dataset to enhance the robustness of MT systems by emulating naturally occurring noise in otherwise clean data. Synthesizing noise in this manner we are ultimately able to make a vanilla MT system resilient to naturally occurring noise and partially mitigate loss in accuracy resulting therefrom.</td><td>ç°ä»£æœºå™¨ç¿»è¯‘ (MT) ç³»ç»Ÿåœ¨å¹²å‡€çš„åŸŸå†…æ–‡æœ¬ä¸Šå§‹ç»ˆè¡¨ç°è‰¯å¥½ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°äººå·¥ç”Ÿæˆçš„æ–‡æœ¬ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¤¾äº¤åª’ä½“é¢†åŸŸï¼Œå……æ»¡äº†æ‹¼å†™é”™è¯¯ã€ä¿šè¯­ã€æ–¹è¨€ã€æ–¹è¨€å’Œå…¶ä»–å™ªéŸ³ï¼Œè¿™äº›å™ªéŸ³ä¼šå¯¹è¾“å‡ºç¿»è¯‘çš„å‡†ç¡®æ€§äº§ç”Ÿç¾éš¾æ€§çš„å½±å“ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨å˜ˆæ‚æ–‡æœ¬æœºå™¨ç¿»è¯‘ (MTNT) æ•°æ®é›†é€šè¿‡åœ¨å…¶ä»–å¹²å‡€çš„æ•°æ®ä¸­æ¨¡æ‹Ÿè‡ªç„¶å‘ç”Ÿçš„å™ªå£°æ¥å¢å¼º MT ç³»ç»Ÿçš„é²æ£’æ€§ã€‚ä»¥è¿™ç§æ–¹å¼åˆæˆå™ªå£°ï¼Œæˆ‘ä»¬æœ€ç»ˆèƒ½å¤Ÿä½¿æ™®é€š MT ç³»ç»Ÿå¯¹è‡ªç„¶å‘ç”Ÿçš„å™ªå£°å…·æœ‰å¼¹æ€§ï¼Œå¹¶éƒ¨åˆ†å‡è½»ç”±æ­¤å¯¼è‡´çš„ç²¾åº¦æŸå¤±ã€‚</td><td>Vaibhav Vaibhav   Sumeet Singh   Craig Stewart   Graham Neubig   Vladimir Karpukhin   Omer Levy   Jacob Eisenstein   Marjan Ghazvininejad</td></tr><tr><td>21</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.04079&#39;]">Differentiable Sampling with Flexible Reference Word Order for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/Izecson/saml-nmt">https://github.com/Izecson/saml-nmt</a></td><td><a href="https://arxiv.org/pdf/1904.04079">https://arxiv.org/pdf/1904.04079</a></td><td>Despite some empirical success at correcting exposure bias in machine translation, scheduled sampling algorithms suffer from a major drawback: they incorrectly assume that words in the reference translations and in sampled sequences are aligned at each time step. Our new differentiable sampling algorithm addresses this issue by optimizing the probability that the reference can be aligned with the sampled output, based on a soft alignment predicted by the model itself. As a result, the output distribution at each time step is evaluated with respect to the whole predicted sequence. Experiments on IWSLT translation tasks show that our approach improves BLEU compared to maximum likelihood and scheduled sampling baselines. In addition, our approach is simpler to train with no need for sampling schedule and yields models that achieve larger improvements with smaller beam sizes.</td><td></td><td>Weijia Xu   Xing Niu   Marine Carpuat</td></tr><tr><td>22</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00556&#39;]">Fluent Translations from Disfluent Speech in End-to-End Speech Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.00556">https://arxiv.org/pdf/1906.00556</a></td><td>Spoken language translation applications for speech suffer due to conversational speech phenomena, particularly the presence of disfluencies. With the rise of end-to-end speech translation models, processing steps such as disfluency removal that were previously an intermediate step between speech recognition and machine translation need to be incorporated into model architectures. We use a sequence-to-sequence model to translate from noisy, disfluent speech to fluent text with disfluencies removed using the recently collected `copy-editedâ€™ references for the Fisher Spanish-English dataset. We are able to directly generate fluent translations and introduce considerations about how to evaluate success on this task. This work provides a baseline for a new task, the translation of conversational speech with joint removal of disfluencies.</td><td>ç”±äºä¼šè¯è¯­éŸ³ç°è±¡ï¼Œç‰¹åˆ«æ˜¯ä¸æµç•…çš„å­˜åœ¨ï¼Œè¯­éŸ³çš„å£è¯­ç¿»è¯‘åº”ç”¨ç¨‹åºå—åˆ°å½±å“ã€‚éšç€ç«¯åˆ°ç«¯è¯­éŸ³ç¿»è¯‘æ¨¡å‹çš„å…´èµ·ï¼Œä¹‹å‰ä½œä¸ºè¯­éŸ³è¯†åˆ«å’Œæœºå™¨ç¿»è¯‘ä¹‹é—´çš„ä¸­é—´æ­¥éª¤çš„ä¸æµç•…å»é™¤ç­‰å¤„ç†æ­¥éª¤éœ€è¦çº³å…¥æ¨¡å‹æ¶æ„ä¸­ã€‚æˆ‘ä»¬ä½¿ç”¨åºåˆ—åˆ°åºåˆ—æ¨¡å‹å°†å˜ˆæ‚ã€ä¸æµåˆ©çš„è¯­éŸ³è½¬æ¢ä¸ºæµåˆ©çš„æ–‡æœ¬ï¼Œå¹¶ä½¿ç”¨æœ€è¿‘æ”¶é›†çš„ Fisher è¥¿ç­ç‰™è¯­-è‹±è¯­æ•°æ®é›†çš„â€œå¤åˆ¶ç¼–è¾‘â€å‚è€ƒåˆ é™¤äº†ä¸æµåˆ©ä¹‹å¤„ã€‚æˆ‘ä»¬èƒ½å¤Ÿç›´æ¥ç”Ÿæˆæµç•…çš„ç¿»è¯‘ï¼Œå¹¶å¼•å…¥æœ‰å…³å¦‚ä½•è¯„ä¼°æ­¤ä»»åŠ¡æˆåŠŸçš„æ³¨æ„äº‹é¡¹ã€‚è¿™é¡¹å·¥ä½œä¸ºä¸€é¡¹æ–°ä»»åŠ¡æä¾›äº†åŸºçº¿ï¼Œå³ç¿»è¯‘ä¼šè¯è¯­éŸ³å¹¶è”åˆæ¶ˆé™¤ä¸æµç•…ã€‚</td><td>Elizabeth Salesky   Matthias Sperber   Alex Waibel</td></tr><tr><td>23</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.08788&#39;]">Selective Attention for Context-aware Neural Machine Translation</a></td><td></td><td><a href="https://github.com/sameenmaruf/selective-attn">https://github.com/sameenmaruf/selective-attn</a></td><td><a href="https://arxiv.org/pdf/1903.08788">https://arxiv.org/pdf/1903.08788</a></td><td>Despite the progress made in sentence-level NMT, current systems still fall short at achieving fluent, good quality translation for a full document. Recent works in context-aware NMT consider only a few previous sentences as context and may not scale to entire documents. To this end, we propose a novel and scalable top-down approach to hierarchical attention for context-aware NMT which uses sparse attention to selectively focus on relevant sentences in the document context and then attends to key words in those sentences. We also propose single-level attention approaches based on sentence or word-level information in the context. The document-level context representation, produced from these attention modules, is integrated into the encoder or decoder of the Transformer model depending on whether we use monolingual or bilingual context. Our experiments and evaluation on English-German datasets in different document MT settings show that our selective attention approach not only significantly outperforms context-agnostic baselines but also surpasses context-aware baselines in most cases.</td><td>å°½ç®¡åœ¨å¥å­çº§ NMT æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†å½“å‰çš„ç³»ç»Ÿä»ç„¶æ— æ³•å®ç°å¯¹å®Œæ•´æ–‡æ¡£çš„æµç•…ã€é«˜è´¨é‡çš„ç¿»è¯‘ã€‚æœ€è¿‘åœ¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥ NMT ä¸­çš„å·¥ä½œåªè€ƒè™‘å‰é¢çš„å‡ ä¸ªå¥å­ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œå¯èƒ½æ— æ³•æ‰©å±•åˆ°æ•´ä¸ªæ–‡æ¡£ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”å¯æ‰©å±•çš„è‡ªä¸Šè€Œä¸‹çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥ NMT åˆ†å±‚æ³¨æ„åŠ›æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›æ¥é€‰æ‹©æ€§åœ°å…³æ³¨æ–‡æ¡£ä¸Šä¸‹æ–‡ä¸­çš„ç›¸å…³å¥å­ï¼Œç„¶åå…³æ³¨è¿™äº›å¥å­ä¸­çš„å…³é”®è¯ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†åŸºäºä¸Šä¸‹æ–‡ä¸­å¥å­æˆ–å•è¯çº§ä¿¡æ¯çš„å•çº§æ³¨æ„åŠ›æ–¹æ³•ã€‚ç”±è¿™äº›æ³¨æ„åŠ›æ¨¡å—äº§ç”Ÿçš„æ–‡æ¡£çº§ä¸Šä¸‹æ–‡è¡¨ç¤ºè¢«é›†æˆåˆ° Transformer æ¨¡å‹çš„ç¼–ç å™¨æˆ–è§£ç å™¨ä¸­ï¼Œå…·ä½“å–å†³äºæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯å•è¯­è¿˜æ˜¯åŒè¯­ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬åœ¨ä¸åŒæ–‡æ¡£ MT è®¾ç½®ä¸­å¯¹è‹±å¾·æ•°æ®é›†çš„å®éªŒå’Œè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„é€‰æ‹©æ€§æ³¨æ„æ–¹æ³•ä¸ä»…æ˜¾ç€ä¼˜äºä¸Šä¸‹æ–‡æ— å…³åŸºçº¿ï¼Œè€Œä¸”åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¹Ÿè¶…è¿‡äº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥åŸºçº¿ã€‚</td><td>Sameen Maruf   AndrÃ© F. T. Martins   Gholamreza Haffari</td></tr></tbody></table></div><h3 id="COLING"><a href="#COLING" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00890&#39;]">Emergent Communication Pretraining for Few-Shot Machine Translation</a></td><td></td><td><a href="https://github.com/cambridgeltl/ECNMT">https://github.com/cambridgeltl/ECNMT</a></td><td><a href="https://arxiv.org/pdf/2011.00890">https://arxiv.org/pdf/2011.00890</a></td><td>While state-of-the-art models that rely upon massively multilingual pretrained encoders achieve sample efficiency in downstream applications, they still require abundant amounts of unlabelled text. Nevertheless, most of the worldâ€™s languages lack such resources. Hence, we investigate a more radical form of unsupervised knowledge transfer in the absence of linguistic data. In particular, for the first time we pretrain neural networks via emergent communication from referential games. Our key assumption is that grounding communication on imagesâ€”-as a crude approximation of real-world environmentsâ€”-inductively biases the model towards learning natural languages. On the one hand, we show that this substantially benefits machine translation in few-shot settings. On the other hand, this also provides an extrinsic evaluation protocol to probe the properties of emergent languages ex vitro. Intuitively, the closer they are to natural languages, the higher the gains from pretraining on them should be. For instance, in this work we measure the influence of communication success and maximum sequence length on downstream performances. Finally, we introduce a customised adapter layer and annealing strategies for the regulariser of maximum-a-posteriori inference during fine-tuning. These turn out to be crucial to facilitate knowledge transfer and prevent catastrophic forgetting. Compared to a recurrent baseline, our method yields gains of $59.0\%<script type="math/tex">\sim</script>147.6\%$ in BLEU score with only $500$ NMT training instances and $65.1\%<script type="math/tex">\sim</script>196.7\%$ with $1,000$ NMT training instances across four language pairs. These proof-of-concept results reveal the potential of emergent communication pretraining for both natural language processing tasks in resource-poor settings and extrinsic evaluation of artificial languages.</td><td></td><td>Yaoyiran Li   Edoardo M. Ponti   Ivan VuliÄ‡   Anna Korhonen</td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00678&#39;]">Investigating Catastrophic Forgetting During Continual Training for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00678">https://arxiv.org/pdf/2011.00678</a></td><td>Neural machine translation (NMT) models usually suffer from catastrophic forgetting during continual training where the models tend to gradually forget previously learned knowledge and swing to fit the newly added data which may have a different distribution, e.g. a different domain. Although many methods have been proposed to solve this problem, we cannot get to know what causes this phenomenon yet. Under the background of domain adaptation, we investigate the cause of catastrophic forgetting from the perspectives of modules and parameters (neurons). The investigation on the modules of the NMT model shows that some modules have tight relation with the general-domain knowledge while some other modules are more essential in the domain adaptation. And the investigation on the parameters shows that some parameters are important for both the general-domain and in-domain translation and the great change of them during continual training brings about the performance decline in general-domain. We conduct experiments across different language pairs and domains to ensure the validity and reliability of our findings.</td><td>ç¥ç»æœºå™¨ç¿»è¯‘ (NMT) æ¨¡å‹åœ¨æŒç»­è®­ç»ƒæœŸé—´é€šå¸¸ä¼šé­å—ç¾éš¾æ€§é—å¿˜ï¼Œå…¶ä¸­æ¨¡å‹å¾€å¾€ä¼šé€æ¸å¿˜è®°å…ˆå‰å­¦åˆ°çš„çŸ¥è¯†å¹¶æ‘†åŠ¨ä»¥é€‚åº”å¯èƒ½å…·æœ‰ä¸åŒåˆ†å¸ƒçš„æ–°æ·»åŠ æ•°æ®ï¼Œä¾‹å¦‚ä¸åŒçš„åŸŸã€‚è™½ç„¶å·²ç»æå‡ºäº†å¾ˆå¤šæ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†æˆ‘ä»¬è¿˜ä¸èƒ½çŸ¥é“æ˜¯ä»€ä¹ˆå¯¼è‡´äº†è¿™ç§ç°è±¡ã€‚åœ¨é¢†åŸŸé€‚åº”çš„èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬ä»æ¨¡å—å’Œå‚æ•°ï¼ˆç¥ç»å…ƒï¼‰çš„è§’åº¦ç ”ç©¶äº†ç¾éš¾æ€§é—å¿˜çš„åŸå› ã€‚å¯¹ NMT æ¨¡å‹æ¨¡å—çš„è°ƒæŸ¥è¡¨æ˜ï¼Œä¸€äº›æ¨¡å—ä¸é€šç”¨é¢†åŸŸçŸ¥è¯†å…³ç³»å¯†åˆ‡ï¼Œè€Œå¦ä¸€äº›æ¨¡å—åœ¨é¢†åŸŸé€‚åº”ä¸­æ›´ä¸ºé‡è¦ã€‚å¯¹å‚æ•°çš„è°ƒæŸ¥è¡¨æ˜ï¼Œä¸€äº›å‚æ•°å¯¹é€šç”¨åŸŸå’ŒåŸŸå†…ç¿»è¯‘éƒ½å¾ˆé‡è¦ï¼Œå¹¶ä¸”åœ¨æŒç»­è®­ç»ƒè¿‡ç¨‹ä¸­å®ƒä»¬çš„å·¨å¤§å˜åŒ–å¯¼è‡´é€šç”¨åŸŸçš„æ€§èƒ½ä¸‹é™ã€‚æˆ‘ä»¬åœ¨ä¸åŒçš„è¯­è¨€å¯¹å’Œé¢†åŸŸè¿›è¡Œå®éªŒï¼Œä»¥ç¡®ä¿æˆ‘ä»¬å‘ç°çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚</td><td>Shuhao Gu   Yang Feng</td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.01482&#39;]">Layer-wise Multi-view Learning for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.01482">https://arxiv.org/pdf/2011.01482</a></td><td>Traditional neural machine translation is limited to the topmost encoder layerâ€™s context representation and cannot directly perceive the lower encoder layers. Existing solutions usually rely on the adjustment of network architecture, making the calculation more complicated or introducing additional structural restrictions. In this work, we propose layer-wise multi-view learning to solve this problem, circumventing the necessity to change the model structure. We regard each encoder layerâ€™s off-the-shelf output, a by-product in layer-by-layer encoding, as the redundant view for the input sentence. In this way, in addition to the topmost encoder layer (referred to as the primary view), we also incorporate an intermediate encoder layer as the auxiliary view. We feed the two views to a partially shared decoder to maintain independent prediction. Consistency regularization based on KL divergence is used to encourage the two views to learn from each other. Extensive experimental results on five translation tasks show that our approach yields stable improvements over multiple strong baselines. As another bonus, our method is agnostic to network architectures and can maintain the same inference speed as the original model.</td><td>ä¼ ç»Ÿçš„ç¥ç»æœºå™¨ç¿»è¯‘ä»…é™äºæœ€é¡¶å±‚ç¼–ç å™¨å±‚çš„ä¸Šä¸‹æ–‡è¡¨ç¤ºï¼Œæ— æ³•ç›´æ¥æ„ŸçŸ¥è¾ƒä½çš„ç¼–ç å™¨å±‚ã€‚ç°æœ‰çš„è§£å†³æ–¹æ¡ˆé€šå¸¸ä¾èµ–äºç½‘ç»œæ¶æ„çš„è°ƒæ•´ï¼Œä½¿è®¡ç®—æ›´åŠ å¤æ‚æˆ–å¼•å…¥é¢å¤–çš„ç»“æ„é™åˆ¶ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åˆ†å±‚å¤šè§†å›¾å­¦ä¹ æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé¿å…äº†æ”¹å˜æ¨¡å‹ç»“æ„çš„å¿…è¦æ€§ã€‚æˆ‘ä»¬å°†æ¯ä¸ªç¼–ç å™¨å±‚çš„ç°æˆè¾“å‡ºï¼ˆé€å±‚ç¼–ç çš„å‰¯äº§å“ï¼‰è§†ä¸ºè¾“å…¥å¥å­çš„å†—ä½™è§†å›¾ã€‚è¿™æ ·ï¼Œé™¤äº†æœ€é¡¶å±‚çš„ç¼–ç å™¨å±‚ï¼ˆç§°ä¸ºä¸»è§†å›¾ï¼‰ï¼Œæˆ‘ä»¬è¿˜åˆå¹¶äº†ä¸€ä¸ªä¸­é—´ç¼–ç å™¨å±‚ä½œä¸ºè¾…åŠ©è§†å›¾ã€‚æˆ‘ä»¬å°†ä¸¤ä¸ªè§†å›¾æä¾›ç»™éƒ¨åˆ†å…±äº«çš„è§£ç å™¨ä»¥ä¿æŒç‹¬ç«‹é¢„æµ‹ã€‚åŸºäºKLæ•£åº¦çš„ä¸€è‡´æ€§æ­£åˆ™åŒ–ç”¨äºé¼“åŠ±ä¸¤ç§è§‚ç‚¹ç›¸äº’å­¦ä¹ ã€‚äº”é¡¹ç¿»è¯‘ä»»åŠ¡çš„å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªå¼ºåŸºçº¿ä¸Šäº§ç”Ÿäº†ç¨³å®šçš„æ”¹è¿›ã€‚ä½œä¸ºå¦ä¸€ä¸ªå¥½å¤„ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ç½‘ç»œæ¶æ„æ— å…³ï¼Œå¹¶ä¸”å¯ä»¥ä¿æŒä¸åŸå§‹æ¨¡å‹ç›¸åŒçš„æ¨ç†é€Ÿåº¦ã€‚</td><td>Qiang Wang   Changliang Li   Yue Zhang   Tong Xiao   Jingbo Zhu</td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.03732&#39;]">Leveraging Discourse Rewards for Document-Level Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.03732">https://arxiv.org/pdf/2010.03732</a></td><td>Document-level machine translation focuses on the translation of entire documents from a source to a target language. It is widely regarded as a challenging task since the translation of the individual sentences in the document needs to retain aspects of the discourse at document level. However, document-level translation models are usually not trained to explicitly ensure discourse quality. Therefore, in this paper we propose a training approach that explicitly optimizes two established discourse metrics, lexical cohesion (LC) and coherence (COH), by using a reinforcement learning objective. Experiments over four different language pairs and three translation domains have shown that our training approach has been able to achieve more cohesive and coherent document translations than other competitive approaches, yet without compromising the faithfulness to the reference translation. In the case of the Zh-En language pair, our method has achieved an improvement of 2.46 percentage points (pp) in LC and 1.17 pp in COH over the runner-up, while at the same time improving 0.63 pp in BLEU score and 0.47 pp in F_BERT.</td><td>æ–‡æ¡£çº§æœºå™¨ç¿»è¯‘ä¾§é‡äºå°†æ•´ä¸ªæ–‡æ¡£ä»æºè¯­è¨€ç¿»è¯‘æˆç›®æ ‡è¯­è¨€ã€‚å®ƒè¢«å¹¿æ³›è®¤ä¸ºæ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºæ–‡æ¡£ä¸­å•ä¸ªå¥å­çš„ç¿»è¯‘éœ€è¦åœ¨æ–‡æ¡£çº§åˆ«ä¿ç•™è¯è¯­çš„å„ä¸ªæ–¹é¢ã€‚ç„¶è€Œï¼Œæ–‡æ¡£çº§ç¿»è¯‘æ¨¡å‹é€šå¸¸æ²¡æœ‰ç»è¿‡è®­ç»ƒä»¥æ˜ç¡®ç¡®ä¿è¯è¯­è´¨é‡ã€‚å› æ­¤ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è®­ç»ƒæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç›®æ ‡æ˜ç¡®ä¼˜åŒ–ä¸¤ä¸ªå·²å»ºç«‹çš„è¯è¯­æŒ‡æ ‡ï¼Œè¯æ±‡è¡”æ¥ (LC) å’Œè¿è´¯ (COH)ã€‚å¯¹å››ç§ä¸åŒè¯­è¨€å¯¹å’Œä¸‰ä¸ªç¿»è¯‘é¢†åŸŸçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„è®­ç»ƒæ–¹æ³•æ¯”å…¶ä»–ç«äº‰æ–¹æ³•èƒ½å¤Ÿå®ç°æ›´å…·å‡èšåŠ›å’Œè¿è´¯æ€§çš„æ–‡æ¡£ç¿»è¯‘ï¼ŒåŒæ—¶åˆä¸å½±å“å¯¹å‚è€ƒç¿»è¯‘çš„å¿ å®åº¦ã€‚åœ¨ Zh-En è¯­è¨€å¯¹çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ LC å’Œ COH æ–¹é¢æ¯”äºšå†›æé«˜äº† 2.46 ä¸ªç™¾åˆ†ç‚¹ï¼ˆppï¼‰ï¼ŒåŒæ—¶åœ¨ BLEU å¾—åˆ†ä¸Šæé«˜äº† 0.63 ä¸ªç™¾åˆ†ç‚¹ï¼ˆppï¼‰å’Œ 0.47 F_BERT ä¸­çš„ ppã€‚</td><td>Inigo Jauregi Unanue   Nazanin Esmaili   Gholamreza Haffari   Massimo Piccardi</td></tr><tr><td>5</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.02266&#39;]">Optimized Transformer for Low-resource Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.02266">https://arxiv.org/pdf/2011.02266</a></td><td>Language pairs with limited amounts of parallel data, also known as low-resource languages, remain a challenge for neural machine translation. While the Transformer model has achieved significant improvements for many language pairs and has become the de facto mainstream architecture, its capability under low-resource conditions has not been fully investigated yet. Our experiments on different subsets of the IWSLT14 training data show that the effectiveness of Transformer under low-resource conditions is highly dependent on the hyper-parameter settings. Our experiments show that using an optimized Transformer for low-resource conditions improves the translation quality up to 7.3 BLEU points compared to using the Transformer default settings.</td><td>å¹¶è¡Œæ•°æ®é‡æœ‰é™çš„è¯­è¨€å¯¹ï¼Œä¹Ÿç§°ä¸ºä½èµ„æºè¯­è¨€ï¼Œä»ç„¶æ˜¯ç¥ç»æœºå™¨ç¿»è¯‘çš„æŒ‘æˆ˜ã€‚è™½ç„¶ Transformer æ¨¡å‹åœ¨è®¸å¤šè¯­è¨€å¯¹ä¸Šéƒ½å–å¾—äº†æ˜¾ç€çš„æ”¹è¿›ï¼Œå·²ç»æˆä¸ºäº‹å®ä¸Šçš„ä¸»æµæ¶æ„ï¼Œä½†å…¶åœ¨ä½èµ„æºæ¡ä»¶ä¸‹çš„èƒ½åŠ›å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚æˆ‘ä»¬å¯¹ IWSLT14 è®­ç»ƒæ•°æ®çš„ä¸åŒå­é›†è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒTransformer åœ¨ä½èµ„æºæ¡ä»¶ä¸‹çš„æœ‰æ•ˆæ€§é«˜åº¦ä¾èµ–äºè¶…å‚æ•°è®¾ç½®ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œä¸ä½¿ç”¨ Transformer é»˜è®¤è®¾ç½®ç›¸æ¯”ï¼Œåœ¨ä½èµ„æºæ¡ä»¶ä¸‹ä½¿ç”¨ä¼˜åŒ–çš„ Transformer å¯å°†ç¿»è¯‘è´¨é‡æé«˜å¤šè¾¾ 7.3 BLEU ç‚¹ã€‚</td><td>Ali Araabi   Christof Monz</td></tr><tr><td>6</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12549&#39;]">Robust Unsupervised Neural Machine Translation with Adversarial Denoising Training</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.12549">https://arxiv.org/pdf/2002.12549</a></td><td>Unsupervised neural machine translation (UNMT) has recently attracted great interest in the machine translation community. The main advantage of the UNMT lies in its easy collection of required large training text sentences while with only a slightly worse performance than supervised neural machine translation which requires expensive annotated translation pairs on some translation tasks. In most studies, the UMNT is trained with clean data without considering its robustness to the noisy data. However, in real-world scenarios, there usually exists noise in the collected input sentences which degrades the performance of the translation system since the UNMT is sensitive to the small perturbations of the input sentences. In this paper, we first time explicitly take the noisy data into consideration to improve the robustness of the UNMT based systems. First of all, we clearly defined two types of noises in training sentences, i.e., word noise and word order noise, and empirically investigate its effect in the UNMT, then we propose adversarial training methods with denoising process in the UNMT. Experimental results on several language pairs show that our proposed methods substantially improved the robustness of the conventional UNMT systems in noisy scenarios.</td><td>æ— ç›‘ç£ç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆUNMTï¼‰æœ€è¿‘å¼•èµ·äº†æœºå™¨ç¿»è¯‘ç¤¾åŒºçš„æå¤§å…´è¶£ã€‚ UNMT çš„ä¸»è¦ä¼˜åŠ¿åœ¨äºå®ƒå¯ä»¥è½»æ¾æ”¶é›†æ‰€éœ€çš„å¤§å‹è®­ç»ƒæ–‡æœ¬å¥å­ï¼Œè€Œå…¶æ€§èƒ½ä»…æ¯”ç›‘ç£ç¥ç»æœºå™¨ç¿»è¯‘ç¨å·®ï¼Œåè€…åœ¨æŸäº›ç¿»è¯‘ä»»åŠ¡ä¸Šéœ€è¦æ˜‚è´µçš„æ³¨é‡Šç¿»è¯‘å¯¹ã€‚åœ¨å¤§å¤šæ•°ç ”ç©¶ä¸­ï¼ŒUMNT æ˜¯ç”¨å¹²å‡€çš„æ•°æ®è®­ç»ƒçš„ï¼Œè€Œæ²¡æœ‰è€ƒè™‘å®ƒå¯¹å™ªå£°æ•°æ®çš„é²æ£’æ€§ã€‚ç„¶è€Œï¼Œåœ¨å®é™…åœºæ™¯ä¸­ï¼Œç”±äº UNMT å¯¹è¾“å…¥å¥å­çš„å°æ‰°åŠ¨å¾ˆæ•æ„Ÿï¼Œå› æ­¤æ”¶é›†çš„è¾“å…¥å¥å­ä¸­é€šå¸¸å­˜åœ¨å™ªå£°ï¼Œè¿™ä¼šé™ä½ç¿»è¯‘ç³»ç»Ÿçš„æ€§èƒ½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç¬¬ä¸€æ¬¡æ˜ç¡®åœ°å°†å™ªå£°æ•°æ®è€ƒè™‘åœ¨å†…ï¼Œä»¥æé«˜åŸºäº UNMT çš„ç³»ç»Ÿçš„é²æ£’æ€§ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ˜ç¡®å®šä¹‰äº†è®­ç»ƒå¥å­ä¸­çš„ä¸¤ç±»å™ªå£°ï¼Œå³è¯å™ªå£°å’Œè¯åºå™ªå£°ï¼Œå¹¶å®è¯ç ”ç©¶äº†å…¶åœ¨ UNMT ä¸­çš„å½±å“ï¼Œç„¶åæˆ‘ä»¬åœ¨ UNMT ä¸­æå‡ºäº†å…·æœ‰å»å™ªè¿‡ç¨‹çš„å¯¹æŠ—æ€§è®­ç»ƒæ–¹æ³•ã€‚å‡ ä¸ªè¯­è¨€å¯¹çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•å¤§å¤§æé«˜äº†ä¼ ç»Ÿ UNMT ç³»ç»Ÿåœ¨å˜ˆæ‚åœºæ™¯ä¸­çš„é²æ£’æ€§ã€‚</td><td>Haipeng Sun   Rui Wang   Kehai Chen   Xugang Lu   Masao Utiyama   Eiichiro Sumita   Tiejun Zhao</td></tr><tr><td>7</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.11018&#39;]">Token Drop mechanism for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/zhajiahe/Token_Drop">https://github.com/zhajiahe/Token_Drop</a></td><td><a href="https://arxiv.org/pdf/2010.11018">https://arxiv.org/pdf/2010.11018</a></td><td>Neural machine translation with millions of parameters is vulnerable to unfamiliar inputs. We propose Token Drop to improve generalization and avoid overfitting for the NMT model. Similar to word dropout, whereas we replace dropped token with a special token instead of setting zero to words. We further introduce two self-supervised objectives: Replaced Token Detection and Dropped Token Prediction. Our method aims to force model generating target translation with less information, in this way the model can learn textual representation better. Experiments on Chinese-English and English-Romanian benchmark demonstrate the effectiveness of our approach and our model achieves significant improvements over a strong Transformer baseline.</td><td>å…·æœ‰æ•°ç™¾ä¸‡ä¸ªå‚æ•°çš„ç¥ç»æœºå™¨ç¿»è¯‘å®¹æ˜“å—åˆ°é™Œç”Ÿè¾“å…¥çš„å½±å“ã€‚æˆ‘ä»¬æå‡º Token Drop æ¥æé«˜æ³›åŒ–èƒ½åŠ›å¹¶é¿å…å¯¹ NMT æ¨¡å‹çš„è¿‡åº¦æ‹Ÿåˆã€‚ç±»ä¼¼äºå•è¯ä¸¢å¤±ï¼Œè€Œæˆ‘ä»¬ç”¨ç‰¹æ®Šæ ‡è®°æ›¿æ¢æ‰çš„æ ‡è®°ï¼Œè€Œä¸æ˜¯å°†å•è¯è®¾ç½®ä¸ºé›¶ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥ä»‹ç»äº†ä¸¤ä¸ªè‡ªæˆ‘ç›‘ç£çš„ç›®æ ‡ï¼šæ›¿æ¢ä»¤ç‰Œæ£€æµ‹å’Œä¸¢å¼ƒä»¤ç‰Œé¢„æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ—¨åœ¨ç”¨æ›´å°‘çš„ä¿¡æ¯å¼ºåˆ¶æ¨¡å‹ç”Ÿæˆç›®æ ‡ç¿»è¯‘ï¼Œè¿™æ ·æ¨¡å‹å¯ä»¥æ›´å¥½åœ°å­¦ä¹ æ–‡æœ¬è¡¨ç¤ºã€‚ä¸­æ–‡-è‹±æ–‡å’Œè‹±æ–‡-ç½—é©¬å°¼äºšè¯­åŸºå‡†çš„å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å¼ºå¤§çš„ Transformer åŸºçº¿ä¸Šå–å¾—äº†æ˜¾ç€çš„æ”¹è¿›ã€‚</td><td>Huaao Zhang   Shigui Qiu   Xiangyu Duan   Min Zhang</td></tr><tr><td>8</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.03469&#39;]">Understanding Pure Character-Based Neural Machine Translation: The Case of Translating Finnish into English</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.03469">https://arxiv.org/pdf/2011.03469</a></td><td>Recent work has shown that deeper character-based neural machine translation (NMT) models can outperform subword-based models. However, it is still unclear what makes deeper character-based models successful. In this paper, we conduct an investigation into pure character-based models in the case of translating Finnish into English, including exploring the ability to learn word senses and morphological inflections and the attention mechanism. We demonstrate that word-level information is distributed over the entire character sequence rather than over a single character, and characters at different positions play different roles in learning linguistic knowledge. In addition, character-based models need more layers to encode word senses which explains why only deeper models outperform subword-based models. The attention distribution pattern shows that separators attract a lot of attention and we explore a sparse word-level attention to enforce character hidden states to capture the full word-level information. Experimental results show that the word-level attention with a single head results in 1.2 BLEU points drop.</td><td>æœ€è¿‘çš„å·¥ä½œè¡¨æ˜ï¼Œæ›´æ·±å±‚æ¬¡çš„åŸºäºå­—ç¬¦çš„ç¥ç»æœºå™¨ç¿»è¯‘ (NMT) æ¨¡å‹å¯ä»¥èƒœè¿‡åŸºäºå­è¯çš„æ¨¡å‹ã€‚ç„¶è€Œï¼Œç›®å‰å°šä¸æ¸…æ¥šæ˜¯ä»€ä¹ˆè®©æ›´æ·±å±‚æ¬¡çš„åŸºäºå­—ç¬¦çš„æ¨¡å‹æˆåŠŸã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åœ¨å°†èŠ¬å…°è¯­ç¿»è¯‘æˆè‹±è¯­çš„æƒ…å†µä¸‹å¯¹çº¯åŸºäºå­—ç¬¦çš„æ¨¡å‹è¿›è¡Œäº†è°ƒæŸ¥ï¼ŒåŒ…æ‹¬æ¢ç´¢å­¦ä¹ è¯ä¹‰å’Œå½¢æ€å˜åŒ–çš„èƒ½åŠ›ä»¥åŠæ³¨æ„æœºåˆ¶ã€‚æˆ‘ä»¬è¯æ˜äº†è¯çº§ä¿¡æ¯åˆ†å¸ƒåœ¨æ•´ä¸ªå­—ç¬¦åºåˆ—è€Œä¸æ˜¯å•ä¸ªå­—ç¬¦ä¸Šï¼Œå¹¶ä¸”ä¸åŒä½ç½®çš„å­—ç¬¦åœ¨å­¦ä¹ è¯­è¨€çŸ¥è¯†ä¸­æ‰®æ¼”ç€ä¸åŒçš„è§’è‰²ã€‚æ­¤å¤–ï¼ŒåŸºäºå­—ç¬¦çš„æ¨¡å‹éœ€è¦æ›´å¤šå±‚æ¥ç¼–ç è¯ä¹‰ï¼Œè¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆåªæœ‰æ›´æ·±çš„æ¨¡å‹æ‰èƒ½èƒœè¿‡åŸºäºå­è¯çš„æ¨¡å‹ã€‚æ³¨æ„åŠ›åˆ†å¸ƒæ¨¡å¼è¡¨æ˜åˆ†éš”ç¬¦å¸å¼•äº†å¾ˆå¤šæ³¨æ„åŠ›ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ä¸€ç§ç¨€ç–çš„è¯çº§æ³¨æ„åŠ›æ¥å¼ºåˆ¶å­—ç¬¦éšè—çŠ¶æ€æ¥æ•è·å®Œæ•´çš„è¯çº§ä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå•ä¸ªå¤´éƒ¨çš„è¯çº§æ³¨æ„åŠ›å¯¼è‡´ 1.2 BLEU ç‚¹ä¸‹é™ã€‚</td><td>Gongbo Tang   Rico Sennrich   Joakim Nivre</td></tr></tbody></table></div><h2 id="ä¼šè¯-å¯¹è¯ç³»ç»Ÿ"><a href="#ä¼šè¯-å¯¹è¯ç³»ç»Ÿ" class="headerlink" title="ä¼šè¯/å¯¹è¯ç³»ç»Ÿ"></a>ä¼šè¯/å¯¹è¯ç³»ç»Ÿ</h2><h3 id="ACL-1"><a href="#ACL-1" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.12458&#39;]">TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.12458">https://arxiv.org/pdf/2012.12458</a></td><td>We present a data-driven, end-to-end approach to transaction-based dialog systems that performs at near-human levels in terms of verbal response quality and factual grounding accuracy. We show that two essential components of the system produce these results: a sufficiently large and diverse, in-domain labeled dataset, and a neural network-based, pre-trained model that generates both verbal responses and API call predictions. In terms of data, we introduce TicketTalk, a movie ticketing dialog dataset with 23,789 annotated conversations. The movie ticketing conversations range from completely open-ended and unrestricted to more structured, both in terms of their knowledge base, discourse features, and number of turns. In qualitative human evaluations, model-generated responses trained on just 10,000 TicketTalk dialogs were rated to â€œmake senseâ€ 86.5 percent of the time, almost the same as human responses in the same contexts. Our simple, API-focused annotation schema results in a much easier labeling task making it faster and more cost effective. It is also the key component for being able to predict API calls accurately. We handle factual grounding by incorporating API calls in the training data, allowing our model to learn which actions to take and when. Trained on the same 10,000-dialog set, the modelâ€™s API call predictions were rated to be correct 93.9 percent of the time in our evaluations, surpassing the ratings for the corresponding human labels. We show how API prediction and response generation scores improve as the dataset size incrementally increases from 5000 to 21,000 dialogs. Our analysis also clearly illustrates the benefits of pre-training. We are publicly releasing the TicketTalk dataset with this paper to facilitate future work on transaction-based dialogs.</td><td>æˆ‘ä»¬ä¸ºåŸºäºäº‹åŠ¡çš„å¯¹è¯ç³»ç»Ÿæä¾›äº†ä¸€ç§æ•°æ®é©±åŠ¨çš„ç«¯åˆ°ç«¯æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨å£å¤´å“åº”è´¨é‡å’Œäº‹å®åŸºç¡€å‡†ç¡®æ€§æ–¹é¢çš„è¡¨ç°æ¥è¿‘äººç±»æ°´å¹³ã€‚æˆ‘ä»¬å±•ç¤ºäº†ç³»ç»Ÿçš„ä¸¤ä¸ªåŸºæœ¬ç»„æˆéƒ¨åˆ†ä¼šäº§ç”Ÿè¿™äº›ç»“æœï¼šä¸€ä¸ªè¶³å¤Ÿå¤§ä¸”å¤šæ ·åŒ–çš„åŸŸå†…æ ‡è®°æ•°æ®é›†ï¼Œä»¥åŠä¸€ä¸ªåŸºäºç¥ç»ç½‘ç»œçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç”Ÿæˆå£å¤´å“åº”å’Œ API è°ƒç”¨é¢„æµ‹ã€‚åœ¨æ•°æ®æ–¹é¢ï¼Œæˆ‘ä»¬å¼•å…¥äº† TicketTalkï¼Œè¿™æ˜¯ä¸€ä¸ªç”µå½±ç¥¨åŠ¡å¯¹è¯æ•°æ®é›†ï¼ŒåŒ…å« 23,789 ä¸ªå¸¦æ³¨é‡Šçš„å¯¹è¯ã€‚ç”µå½±ç¥¨åŠ¡å¯¹è¯çš„èŒƒå›´ä»å®Œå…¨å¼€æ”¾å’Œä¸å—é™åˆ¶åˆ°æ›´åŠ ç»“æ„åŒ–ï¼Œæ— è®ºæ˜¯åœ¨çŸ¥è¯†åŸºç¡€ã€è¯è¯­ç‰¹å¾è¿˜æ˜¯å›åˆæ•°æ–¹é¢ã€‚åœ¨å®šæ€§çš„äººç±»è¯„ä¼°ä¸­ï¼Œä»…åœ¨ 10,000 ä¸ª TicketTalk å¯¹è¯ä¸Šè®­ç»ƒçš„æ¨¡å‹ç”Ÿæˆçš„å“åº”è¢«è¯„ä¸ºâ€œæœ‰æ„ä¹‰â€çš„æ—¶é—´ä¸º 86.5%ï¼Œå‡ ä¹ä¸ç›¸åŒä¸Šä¸‹æ–‡ä¸­çš„äººç±»å“åº”ç›¸åŒã€‚æˆ‘ä»¬ä»¥ API ä¸ºä¸­å¿ƒçš„ç®€å•æ³¨é‡Šæ¨¡å¼ä½¿æ ‡è®°ä»»åŠ¡å˜å¾—æ›´åŠ ç®€å•ï¼Œä»è€Œä½¿å…¶æ›´å¿«ã€æ›´å…·æˆæœ¬æ•ˆç›Šã€‚å®ƒä¹Ÿæ˜¯èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹ API è°ƒç”¨çš„å…³é”®ç»„ä»¶ã€‚æˆ‘ä»¬é€šè¿‡åœ¨è®­ç»ƒæ•°æ®ä¸­åŠ å…¥ API è°ƒç”¨æ¥å¤„ç†äº‹å®åŸºç¡€ï¼Œè®©æˆ‘ä»¬çš„æ¨¡å‹äº†è§£è¦é‡‡å–å“ªäº›è¡ŒåŠ¨ä»¥åŠä½•æ—¶é‡‡å–è¡ŒåŠ¨ã€‚åœ¨ç›¸åŒçš„ 10,000 ä¸ªå¯¹è¯é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ¨¡å‹çš„ API è°ƒç”¨é¢„æµ‹åœ¨æˆ‘ä»¬çš„è¯„ä¼°ä¸­è¢«è¯„ä¸º 93.9% çš„æ­£ç¡®ç‡ï¼Œè¶…è¿‡äº†ç›¸åº”äººå·¥æ ‡ç­¾çš„è¯„åˆ†ã€‚æˆ‘ä»¬å±•ç¤ºäº† API é¢„æµ‹å’Œå“åº”ç”Ÿæˆåˆ†æ•°å¦‚ä½•éšç€æ•°æ®é›†å¤§å°ä» 5000 ä¸ªå¯¹è¯é€æ¸å¢åŠ åˆ° 21,000 ä¸ªè€Œæé«˜ã€‚æˆ‘ä»¬çš„åˆ†æè¿˜æ¸…æ¥šåœ°è¯´æ˜äº†é¢„è®­ç»ƒçš„å¥½å¤„ã€‚æˆ‘ä»¬å°†éšæœ¬æ–‡å…¬å¼€å‘å¸ƒ TicketTalk æ•°æ®é›†ï¼Œä»¥ä¿ƒè¿›åŸºäºäº‹åŠ¡çš„å¯¹è¯çš„æœªæ¥å·¥ä½œã€‚</td><td>Bill Byrne   Karthik Krishnamoorthi   Saravanan Ganesh   Mihir Sanjay Kale</td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00162&#39;]">HERALD: An Annotation Efficient Method to Detect User Disengagement in Social Conversations</a></td><td></td><td><a href="https://github.com/Weixin-Liang/HERALD">https://github.com/Weixin-Liang/HERALD</a></td><td><a href="https://arxiv.org/pdf/2106.00162">https://arxiv.org/pdf/2106.00162</a></td><td>Open-domain dialog systems have a user-centric goal: to provide humans with an engaging conversation experience. User engagement is one of the most important metrics for evaluating open-domain dialog systems, and could also be used as real-time feedback to benefit dialog policy learning. Existing work on detecting user disengagement typically requires hand-labeling many dialog samples. We propose HERALD, an efficient annotation framework that reframes the training data annotation process as a denoising problem. Specifically, instead of manually labeling training samples, we first use a set of labeling heuristics to label training samples automatically. We then denoise the weakly labeled data using the Shapley algorithm. Finally, we use the denoised data to train a user engagement detector. Our experiments show that HERALD improves annotation efficiency significantly and achieves 86% user disengagement detection accuracy in two dialog corpora.</td><td>å¼€æ”¾åŸŸå¯¹è¯ç³»ç»Ÿæœ‰ä¸€ä¸ªä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„ç›®æ ‡ï¼šä¸ºäººç±»æä¾›å¼•äººå…¥èƒœçš„å¯¹è¯ä½“éªŒã€‚ç”¨æˆ·å‚ä¸åº¦æ˜¯è¯„ä¼°å¼€æ”¾åŸŸå¯¹è¯ç³»ç»Ÿçš„æœ€é‡è¦æŒ‡æ ‡ä¹‹ä¸€ï¼Œä¹Ÿå¯ä»¥ç”¨ä½œå®æ—¶åé¦ˆä»¥ä¿ƒè¿›å¯¹è¯ç­–ç•¥å­¦ä¹ ã€‚æ£€æµ‹ç”¨æˆ·è„±ç¦»çš„ç°æœ‰å·¥ä½œé€šå¸¸éœ€è¦æ‰‹åŠ¨æ ‡è®°è®¸å¤šå¯¹è¯æ ·æœ¬ã€‚æˆ‘ä»¬æå‡ºäº† HERALDï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„æ³¨é‡Šæ¡†æ¶ï¼Œå¯å°†è®­ç»ƒæ•°æ®æ³¨é‡Šè¿‡ç¨‹é‡æ–°æ„å»ºä¸ºå»å™ªé—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨ä¸€ç»„æ ‡è®°å¯å‘å¼æ–¹æ³•æ¥è‡ªåŠ¨æ ‡è®°è®­ç»ƒæ ·æœ¬ï¼Œè€Œä¸æ˜¯æ‰‹åŠ¨æ ‡è®°è®­ç»ƒæ ·æœ¬ã€‚ç„¶åæˆ‘ä»¬ä½¿ç”¨ Shapley ç®—æ³•å¯¹å¼±æ ‡è®°æ•°æ®è¿›è¡Œå»å™ªã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨å»å™ªæ•°æ®æ¥è®­ç»ƒç”¨æˆ·å‚ä¸æ£€æµ‹å™¨ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒHERALD æ˜¾ç€æé«˜äº†æ³¨é‡Šæ•ˆç‡ï¼Œå¹¶åœ¨ä¸¤ä¸ªå¯¹è¯è¯­æ–™åº“ä¸­å®ç°äº† 86% çš„ç”¨æˆ·è„±ç¦»æ£€æµ‹å‡†ç¡®ç‡ã€‚</td><td>Weixin Liang   Kai-Hui Liang   Zhou Yu</td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.13073&#39;]">Maria: A Visual Experience Powered Conversational Agent</a></td><td></td><td><a href="https://github.com/jokieleung/Maria">https://github.com/jokieleung/Maria</a></td><td><a href="https://arxiv.org/pdf/2105.13073">https://arxiv.org/pdf/2105.13073</a></td><td>Arguably, the visual perception of conversational agents to the physical world is a key way for them to exhibit the human-like intelligence. Image-grounded conversation is thus proposed to address this challenge. Existing works focus on exploring the multimodal dialog models that ground the conversation on a given image. In this paper, we take a step further to study image-grounded conversation under a fully open-ended setting where no paired dialog and image are assumed available. Specifically, we present Maria, a neural conversation agent powered by the visual world experiences which are retrieved from a large-scale image index. Maria consists of three flexible components, i.e., text-to-image retriever, visual concept detector and visual-knowledge-grounded response generator. The retriever aims to retrieve a correlated image to the dialog from an image index, while the visual concept detector extracts rich visual knowledge from the image. Then, the response generator is grounded on the extracted visual knowledge and dialog context to generate the target response. Extensive experiments demonstrate Maria outperforms previous state-of-the-art methods on automatic metrics and human evaluation, and can generate informative responses that have some visual commonsense of the physical world.</td><td>å¯ä»¥è¯´ï¼Œä¼šè¯ä»£ç†å¯¹ç‰©ç†ä¸–ç•Œçš„è§†è§‰æ„ŸçŸ¥æ˜¯ä»–ä»¬å±•ç¤ºç±»äººæ™ºèƒ½çš„å…³é”®æ–¹å¼ã€‚å› æ­¤ï¼Œæå‡ºäº†åŸºäºå›¾åƒçš„å¯¹è¯æ¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚ç°æœ‰çš„å·¥ä½œä¾§é‡äºæ¢ç´¢åŸºäºç»™å®šå›¾åƒè¿›è¡Œå¯¹è¯çš„å¤šæ¨¡æ€å¯¹è¯æ¨¡å‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥ç ”ç©¶åœ¨å®Œå…¨å¼€æ”¾çš„è®¾ç½®ä¸‹åŸºäºå›¾åƒçš„å¯¹è¯ï¼Œå‡è®¾æ²¡æœ‰é…å¯¹çš„å¯¹è¯å’Œå›¾åƒå¯ç”¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å±•ç¤ºäº† Mariaï¼Œä¸€ç§ç¥ç»å¯¹è¯ä»£ç†ï¼Œç”±ä»å¤§è§„æ¨¡å›¾åƒç´¢å¼•ä¸­æ£€ç´¢çš„è§†è§‰ä¸–ç•Œä½“éªŒæä¾›æ”¯æŒã€‚ Maria ç”±ä¸‰ä¸ªçµæ´»çš„ç»„ä»¶ç»„æˆï¼Œå³æ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢å™¨ã€è§†è§‰æ¦‚å¿µæ£€æµ‹å™¨å’ŒåŸºäºè§†è§‰çŸ¥è¯†çš„å“åº”ç”Ÿæˆå™¨ã€‚æ£€ç´¢å™¨æ—¨åœ¨ä»å›¾åƒç´¢å¼•ä¸­æ£€ç´¢ä¸å¯¹è¯ç›¸å…³çš„å›¾åƒï¼Œè€Œè§†è§‰æ¦‚å¿µæ£€æµ‹å™¨ä»å›¾åƒä¸­æå–ä¸°å¯Œçš„è§†è§‰çŸ¥è¯†ã€‚ç„¶åï¼Œå“åº”ç”Ÿæˆå™¨åŸºäºæå–çš„è§†è§‰çŸ¥è¯†å’Œå¯¹è¯ä¸Šä¸‹æ–‡æ¥ç”Ÿæˆç›®æ ‡å“åº”ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMaria åœ¨è‡ªåŠ¨åº¦é‡å’Œäººå·¥è¯„ä¼°æ–¹é¢ä¼˜äºä»¥å‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥ç”Ÿæˆå…·æœ‰ç‰©ç†ä¸–ç•Œä¸€äº›è§†è§‰å¸¸è¯†çš„ä¿¡æ¯å“åº”ã€‚</td><td>Zujie Liang   Huang Hu   Can Xu   Chongyang Tao   Xiubo Geng   Yining Chen   Fan Liang   Daxin Jiang</td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.14756&#39;]">Dialogue Response Selection with Hierarchical Curriculum Learning</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.14756">https://arxiv.org/pdf/2012.14756</a></td><td>We study the learning of a matching model for dialogue response selection. Motivated by the recent finding that models trained with random negative samples are not ideal in real-world scenarios, we propose a hierarchical curriculum learning framework that trains the matching model in an â€œeasy-to-difficultâ€ scheme. Our learning framework consists of two complementary curricula: (1) corpus-level curriculum (CC); and (2) instance-level curriculum (IC). In CC, the model gradually increases its ability in finding the matching clues between the dialogue context and a response candidate. As for IC, it progressively strengthens the modelâ€™s ability in identifying the mismatching information between the dialogue context and a response candidate. Empirical studies on three benchmark datasets with three state-of-the-art matching models demonstrate that the proposed learning framework significantly improves the model performance across various evaluation metrics.</td><td></td><td>Yixuan Su   Deng Cai   Qingyu Zhou   Zibo Lin   Simon Baker   Yunbo Cao   Shuming Shi   Nigel Collier   Yan Wang</td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.14556&#39;]">Diversifying Dialog Generation via Adaptive Label Smoothing</a></td><td></td><td><a href="https://github.com/lemon234071/AdaLabel">https://github.com/lemon234071/AdaLabel</a></td><td><a href="https://arxiv.org/pdf/2105.14556">https://arxiv.org/pdf/2105.14556</a></td><td>Neural dialogue generation models trained with the one-hot target distribution suffer from the over-confidence issue, which leads to poor generation diversity as widely reported in the literature. Although existing approaches such as label smoothing can alleviate this issue, they fail to adapt to diverse dialog contexts. In this paper, we propose an Adaptive Label Smoothing (AdaLabel) approach that can adaptively estimate a target label distribution at each time step for different contexts. The maximum probability in the predicted distribution is used to modify the soft target distribution produced by a novel light-weight bi-directional decoder module. The resulting target distribution is aware of both previous and future contexts and is adjusted to avoid over-training the dialogue model. Our model can be trained in an end-to-end manner. Extensive experiments on two benchmark datasets show that our approach outperforms various competitive baselines in producing diverse responses.</td><td>ä½¿ç”¨ one-hot ç›®æ ‡åˆ†å¸ƒè®­ç»ƒçš„ç¥ç»å¯¹è¯ç”Ÿæˆæ¨¡å‹å­˜åœ¨è¿‡åº¦è‡ªä¿¡çš„é—®é¢˜ï¼Œè¿™å¯¼è‡´äº†æ–‡çŒ®ä¸­å¹¿æ³›æŠ¥é“çš„ç”Ÿæˆå¤šæ ·æ€§è¾ƒå·®ã€‚å°½ç®¡æ ‡ç­¾å¹³æ»‘ç­‰ç°æœ‰æ–¹æ³•å¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œä½†å®ƒä»¬æ— æ³•é€‚åº”ä¸åŒçš„å¯¹è¯ä¸Šä¸‹æ–‡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ ‡ç­¾å¹³æ»‘ (AdaLabel) æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥é’ˆå¯¹ä¸åŒçš„ä¸Šä¸‹æ–‡åœ¨æ¯ä¸ªæ—¶é—´æ­¥è‡ªé€‚åº”åœ°ä¼°è®¡ç›®æ ‡æ ‡ç­¾åˆ†å¸ƒã€‚é¢„æµ‹åˆ†å¸ƒä¸­çš„æœ€å¤§æ¦‚ç‡ç”¨äºä¿®æ”¹ç”±æ–°å‹è½»é‡çº§åŒå‘è§£ç å™¨æ¨¡å—äº§ç”Ÿçš„è½¯ç›®æ ‡åˆ†å¸ƒã€‚ç”±æ­¤äº§ç”Ÿçš„ç›®æ ‡åˆ†å¸ƒäº†è§£ä¹‹å‰å’Œæœªæ¥çš„ä¸Šä¸‹æ–‡ï¼Œå¹¶è¿›è¡Œè°ƒæ•´ä»¥é¿å…è¿‡åº¦è®­ç»ƒå¯¹è¯æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚å¯¹ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†çš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨äº§ç”Ÿä¸åŒå“åº”æ–¹é¢ä¼˜äºå„ç§ç«äº‰åŸºçº¿ã€‚</td><td>Yida Wang   Yinhe Zheng   Yong Jiang   Minlie Huang</td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06169&#39;]">BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data</a></td><td></td><td><a href="https://github.com/songhaoyu/BoB">https://github.com/songhaoyu/BoB</a></td><td><a href="https://arxiv.org/pdf/2106.06169">https://arxiv.org/pdf/2106.06169</a></td><td>Maintaining consistent personas is essential for dialogue agents. Although tremendous advancements have been brought, the limited-scale of annotated persona-dense data are still barriers towards training robust and consistent persona-based dialogue models. In this work, we show how the challenges can be addressed by disentangling persona-based dialogue generation into two sub-tasks with a novel BERT-over-BERT (BoB) model. Specifically, the model consists of a BERT-based encoder and two BERT-based decoders, where one decoder is for response generation, and another is for consistency understanding. In particular, to learn the ability of consistency understanding from large-scale non-dialogue inference data, we train the second decoder in an unlikelihood manner. Under different limited data settings, both automatic and human evaluations demonstrate that the proposed model outperforms strong baselines in response quality and persona consistency.</td><td>ä¿æŒä¸€è‡´çš„è§’è‰²å¯¹äºå¯¹è¯ä»£ç†è‡³å…³é‡è¦ã€‚å°½ç®¡å·²ç»å¸¦æ¥äº†å·¨å¤§çš„è¿›æ­¥ï¼Œä½†å¸¦æ³¨é‡Šçš„è§’è‰²å¯†é›†æ•°æ®çš„è§„æ¨¡æœ‰é™ä»ç„¶æ˜¯è®­ç»ƒå¼ºå¤§ä¸”ä¸€è‡´çš„åŸºäºè§’è‰²çš„å¯¹è¯æ¨¡å‹çš„éšœç¢ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ä½¿ç”¨æ–°é¢–çš„ BERT-over-BERT (BoB) æ¨¡å‹å°†åŸºäºè§’è‰²çš„å¯¹è¯ç”Ÿæˆåˆ†è§£ä¸ºä¸¤ä¸ªå­ä»»åŠ¡æ¥è§£å†³æŒ‘æˆ˜ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ¨¡å‹ç”±ä¸€ä¸ªåŸºäº BERT çš„ç¼–ç å™¨å’Œä¸¤ä¸ªåŸºäº BERT çš„è§£ç å™¨ç»„æˆï¼Œå…¶ä¸­ä¸€ä¸ªè§£ç å™¨ç”¨äºå“åº”ç”Ÿæˆï¼Œå¦ä¸€ä¸ªç”¨äºä¸€è‡´æ€§ç†è§£ã€‚ç‰¹åˆ«æ˜¯ï¼Œä¸ºäº†ä»å¤§è§„æ¨¡éå¯¹è¯æ¨ç†æ•°æ®ä¸­å­¦ä¹ ä¸€è‡´æ€§ç†è§£èƒ½åŠ›ï¼Œæˆ‘ä»¬ä»¥ä¸å¤ªå¯èƒ½çš„æ–¹å¼è®­ç»ƒç¬¬äºŒä¸ªè§£ç å™¨ã€‚åœ¨ä¸åŒçš„æœ‰é™æ•°æ®è®¾ç½®ä¸‹ï¼Œè‡ªåŠ¨å’Œäººå·¥è¯„ä¼°éƒ½è¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¨¡å‹åœ¨å“åº”è´¨é‡å’Œè§’è‰²ä¸€è‡´æ€§æ–¹é¢ä¼˜äºå¼ºå¤§çš„åŸºçº¿ã€‚</td><td>Haoyu Song   Yan Wang   Kaiyan Zhang   Wei-Nan Zhang   Ting Liu</td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.13391&#39;]">I like fish, especially dolphins: Addressing Contradictions in Dialogue Modeling</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.13391">https://arxiv.org/pdf/2012.13391</a></td><td>To quantify how well natural language understanding models can capture consistency in a general conversation, we introduce the DialoguE COntradiction DEtection task (DECODE) and a new conversational dataset containing both human-human and human-bot contradictory dialogues. We then compare a structured utterance-based approach of using pre-trained Transformer models for contradiction detection with the typical unstructured approach. Results reveal that: (i) our newly collected dataset is notably more effective at providing supervision for the dialogue contradiction detection task than existing NLI data including those aimed to cover the dialogue domain; (ii) the structured utterance-based approach is more robust and transferable on both analysis and out-of-distribution dialogues than its unstructured counterpart. We also show that our best contradiction detection model correlates well with human judgments and further provide evidence for its usage in both automatically evaluating and improving the consistency of state-of-the-art generative chatbots.</td><td>ä¸ºäº†é‡åŒ–è‡ªç„¶è¯­è¨€ç†è§£æ¨¡å‹åœ¨ä¸€èˆ¬å¯¹è¯ä¸­æ•æ‰ä¸€è‡´æ€§çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¯¹è¯çŸ›ç›¾æ£€æµ‹ä»»åŠ¡ (DECODE) å’Œä¸€ä¸ªåŒ…å«äººä¸äººå’Œäººä¸æœºå™¨äººçŸ›ç›¾å¯¹è¯çš„æ–°å¯¹è¯æ•°æ®é›†ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é¢„è®­ç»ƒçš„ Transformer æ¨¡å‹è¿›è¡ŒçŸ›ç›¾æ£€æµ‹çš„åŸºäºç»“æ„åŒ–è¯è¯­çš„æ–¹æ³•ä¸å…¸å‹çš„éç»“æ„åŒ–æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚ç»“æœè¡¨æ˜ï¼šï¼ˆiï¼‰æˆ‘ä»¬æ–°æ”¶é›†çš„æ•°æ®é›†åœ¨ä¸ºå¯¹è¯çŸ›ç›¾æ£€æµ‹ä»»åŠ¡æä¾›ç›‘ç£æ–¹é¢æ¯”ç°æœ‰çš„ NLI æ•°æ®ï¼ˆåŒ…æ‹¬æ—¨åœ¨è¦†ç›–å¯¹è¯åŸŸçš„æ•°æ®ï¼‰æ›´æœ‰æ•ˆï¼› (ii) åŸºäºç»“æ„åŒ–è¯è¯­çš„æ–¹æ³•åœ¨åˆ†æå’Œåˆ†å¸ƒå¤–å¯¹è¯ä¸Šéƒ½æ¯”å…¶éç»“æ„åŒ–æ–¹æ³•æ›´å¥å£®å’Œå¯è½¬ç§»ã€‚æˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œæˆ‘ä»¬æœ€å¥½çš„çŸ›ç›¾æ£€æµ‹æ¨¡å‹ä¸äººç±»åˆ¤æ–­å¯†åˆ‡ç›¸å…³ï¼Œå¹¶è¿›ä¸€æ­¥ä¸ºå…¶åœ¨è‡ªåŠ¨è¯„ä¼°å’Œæé«˜æœ€å…ˆè¿›ç”ŸæˆèŠå¤©æœºå™¨äººçš„ä¸€è‡´æ€§æ–¹é¢çš„ä½¿ç”¨æä¾›äº†è¯æ®ã€‚</td><td>Yixin Nie   Mary Williamson   Mohit Bansal   Douwe Kiela   Jason Weston</td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2011.09553&#39;]">A Sequence-to-Sequence Approach to Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/sweetalyssum/Seq2Seq-DU">https://github.com/sweetalyssum/Seq2Seq-DU</a></td><td><a href="https://arxiv.org/pdf/2011.09553">https://arxiv.org/pdf/2011.09553</a></td><td>This paper is concerned with dialogue state tracking (DST) in a task-oriented dialogue system. Building a DST module that is highly effective is still a challenging issue, although significant progresses have been made recently. This paper proposes a new approach to dialogue state tracking, referred to as Seq2Seq-DU, which formalizes DST as a sequence-to-sequence problem. Seq2Seq-DU employs two BERT-based encoders to respectively encode the utterances in the dialogue and the descriptions of schemas, an attender to calculate attentions between the utterance embeddings and the schema embeddings, and a decoder to generate pointers to represent the current state of dialogue. Seq2Seq-DU has the following advantages. It can jointly model intents, slots, and slot values; it can leverage the rich representations of utterances and schemas based on BERT; it can effectively deal with categorical and non-categorical slots, and unseen schemas. In addition, Seq2Seq-DU can also be used in the NLU (natural language understanding) module of a dialogue system. Experimental results on benchmark datasets in different settings (SGD, MultiWOZ2.2, MultiWOZ2.1, WOZ2.0, DSTC2, M2M, SNIPS, and ATIS) show that Seq2Seq-DU outperforms the existing methods.</td><td>æœ¬æ–‡å…³æ³¨çš„æ˜¯é¢å‘ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿä¸­çš„å¯¹è¯çŠ¶æ€è·Ÿè¸ªï¼ˆDSTï¼‰ã€‚å°½ç®¡æœ€è¿‘å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†æ„å»ºé«˜æ•ˆçš„ DST æ¨¡å—ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¯¹è¯çŠ¶æ€è·Ÿè¸ªæ–¹æ³•ï¼Œç§°ä¸º Seq2Seq-DUï¼Œå®ƒå°† DST å½¢å¼åŒ–ä¸ºåºåˆ—åˆ°åºåˆ—é—®é¢˜ã€‚ Seq2Seq-DU ä½¿ç”¨ä¸¤ä¸ªåŸºäº BERT çš„ç¼–ç å™¨åˆ†åˆ«å¯¹å¯¹è¯ä¸­çš„è¯è¯­å’Œæ¨¡å¼æè¿°è¿›è¡Œç¼–ç ï¼Œä¸€ä¸ªå‚ä¸å™¨è®¡ç®—è¯è¯­åµŒå…¥å’Œæ¨¡å¼åµŒå…¥ä¹‹é—´çš„æ³¨æ„åŠ›ï¼Œä»¥åŠä¸€ä¸ªè§£ç å™¨æ¥ç”Ÿæˆè¡¨ç¤ºå½“å‰å¯¹è¯çŠ¶æ€çš„æŒ‡é’ˆ. Seq2Seq-DU å…·æœ‰ä»¥ä¸‹ä¼˜ç‚¹ã€‚å®ƒå¯ä»¥è”åˆå»ºæ¨¡æ„å›¾ã€æ§½ä½å’Œæ§½ä½å€¼ï¼›å®ƒå¯ä»¥åˆ©ç”¨åŸºäº BERT çš„ä¸°å¯Œçš„è¯è¯­å’Œæ¨¡å¼è¡¨ç¤ºï¼›å®ƒå¯ä»¥æœ‰æ•ˆåœ°å¤„ç†åˆ†ç±»å’Œéåˆ†ç±»æ§½ä»¥åŠçœ‹ä¸è§çš„æ¨¡å¼ã€‚æ­¤å¤–ï¼ŒSeq2Seq-DU è¿˜å¯ä»¥ç”¨äºå¯¹è¯ç³»ç»Ÿçš„ NLUï¼ˆè‡ªç„¶è¯­è¨€ç†è§£ï¼‰æ¨¡å—ã€‚åœ¨ä¸åŒè®¾ç½®ï¼ˆSGDã€MultiWOZ2.2ã€MultiWOZ2.1ã€WOZ2.0ã€DSTC2ã€M2Mã€SNIPS å’Œ ATISï¼‰çš„åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒSeq2Seq-DU ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</td><td>Yue Feng   Yang Wang   Hang Li</td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.03410&#39;]">Generating Relevant and Coherent Dialogue Responses using Self-Separated Conditional Variational AutoEncoders</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.03410">https://arxiv.org/pdf/2106.03410</a></td><td>Conditional Variational AutoEncoder (CVAE) effectively increases the diversity and informativeness of responses in open-ended dialogue generation tasks through enriching the context vector with sampled latent variables. However, due to the inherent one-to-many and many-to-one phenomena in human dialogues, the sampled latent variables may not correctly reflect the contextsâ€™ semantics, leading to irrelevant and incoherent generated responses. To resolve this problem, we propose Self-separated Conditional Variational AutoEncoder (abbreviated as SepaCVAE) that introduces group information to regularize the latent variables, which enhances CVAE by improving the responsesâ€™ relevance and coherence while maintaining their diversity and informativeness. SepaCVAE actively divides the input data into groups, and then widens the absolute difference between data pairs from distinct groups, while narrowing the relative distance between data pairs in the same group. Empirical results from automatic evaluation and detailed analysis demonstrate that SepaCVAE can significantly boost responses in well-established open-domain dialogue datasets.</td><td>æ¡ä»¶å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ (CVAE) é€šè¿‡ç”¨é‡‡æ ·çš„æ½œåœ¨å˜é‡ä¸°å¯Œä¸Šä¸‹æ–‡å‘é‡ï¼Œæœ‰æ•ˆåœ°å¢åŠ äº†å¼€æ”¾å¼å¯¹è¯ç”Ÿæˆä»»åŠ¡ä¸­å“åº”çš„å¤šæ ·æ€§å’Œä¿¡æ¯é‡ã€‚ç„¶è€Œï¼Œç”±äºäººç±»å¯¹è¯ä¸­å›ºæœ‰çš„ä¸€å¯¹å¤šå’Œå¤šå¯¹ä¸€ç°è±¡ï¼Œé‡‡æ ·çš„æ½œåœ¨å˜é‡å¯èƒ½æ— æ³•æ­£ç¡®åæ˜ ä¸Šä¸‹æ–‡çš„è¯­ä¹‰ï¼Œå¯¼è‡´ç”Ÿæˆçš„å“åº”ä¸ç›¸å…³å’Œä¸è¿è´¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªåˆ†ç¦»æ¡ä»¶å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆSepaCVAEï¼‰ï¼Œå®ƒå¼•å…¥äº†ç»„ä¿¡æ¯æ¥è§„èŒƒæ½œåœ¨å˜é‡ï¼Œé€šè¿‡æé«˜å“åº”çš„ç›¸å…³æ€§å’Œè¿è´¯æ€§æ¥å¢å¼º CVAEï¼ŒåŒæ—¶ä¿æŒå®ƒä»¬çš„å¤šæ ·æ€§å’Œä¿¡æ¯é‡ã€‚ SepaCVAE ä¸»åŠ¨å°†è¾“å…¥æ•°æ®åˆ†ç»„ï¼Œç„¶åæ‰©å¤§æ¥è‡ªä¸åŒç»„çš„æ•°æ®å¯¹ä¹‹é—´çš„ç»å¯¹å·®å¼‚ï¼ŒåŒæ—¶ç¼©å°åŒä¸€ç»„ä¸­æ•°æ®å¯¹ä¹‹é—´çš„ç›¸å¯¹è·ç¦»ã€‚è‡ªåŠ¨è¯„ä¼°å’Œè¯¦ç»†åˆ†æçš„å®è¯ç»“æœè¡¨æ˜ï¼ŒSepaCVAE å¯ä»¥æ˜¾ç€æé«˜åœ¨å®Œå–„çš„å¼€æ”¾åŸŸå¯¹è¯æ•°æ®é›†ä¸­çš„å“åº”ã€‚</td><td>Bin Sun   Shaoxiong Feng   Yiwei Li   Jiamou Liu   Kan Li</td></tr><tr><td>10</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00123&#39;]">Intent Classification and Slot Filling for Privacy Policies</a></td><td></td><td><a href="https://github.com/wasiahmad/PolicyIE">https://github.com/wasiahmad/PolicyIE</a></td><td><a href="https://arxiv.org/pdf/2101.00123">https://arxiv.org/pdf/2101.00123</a></td><td>Understanding privacy policies is crucial for users as it empowers them to learn about the information that matters to them. Sentences written in a privacy policy document explain privacy practices, and the constituent text spans convey further specific information about that practice. We refer to predicting the privacy practice explained in a sentence as intent classification and identifying the text spans sharing specific information as slot filling. In this work, we propose PolicyIE, an English corpus consisting of 5,250 intent and 11,788 slot annotations spanning 31 privacy policies of websites and mobile applications. PolicyIE corpus is a challenging real-world benchmark with limited labeled examples reflecting the cost of collecting large-scale annotations from domain experts. We present two alternative neural approaches as baselines, (1) intent classification and slot filling as a joint sequence tagging and (2) modeling them as a sequence-to-sequence (Seq2Seq) learning task. The experiment results show that both approaches perform comparably in intent classification, while the Seq2Seq method outperforms the sequence tagging approach in slot filling by a large margin. We perform a detailed error analysis to reveal the challenges of the proposed corpus.</td><td>äº†è§£éšç§æ”¿ç­–å¯¹ç”¨æˆ·è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒä½¿ä»–ä»¬èƒ½å¤Ÿäº†è§£å¯¹ä»–ä»¬è€Œè¨€é‡è¦çš„ä¿¡æ¯ã€‚å†™åœ¨éšç§æ”¿ç­–æ–‡ä»¶ä¸­çš„å¥å­è§£é‡Šäº†éšç§å®è·µï¼Œæ„æˆæ–‡æœ¬çš„è·¨åº¦ä¼ è¾¾äº†æœ‰å…³è¯¥å®è·µçš„è¿›ä¸€æ­¥å…·ä½“ä¿¡æ¯ã€‚æˆ‘ä»¬å°†é¢„æµ‹åœ¨å¥å­ä¸­è§£é‡Šçš„éšç§å®è·µç§°ä¸ºæ„å›¾åˆ†ç±»ï¼Œå¹¶å°†å…±äº«ç‰¹å®šä¿¡æ¯çš„æ–‡æœ¬è·¨åº¦ç§°ä¸ºæ’æ§½å¡«å……ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† PolicyIEï¼Œè¿™æ˜¯ä¸€ä¸ªè‹±è¯­è¯­æ–™åº“ï¼Œç”± 5,250 ä¸ªæ„å›¾å’Œ 11,788 ä¸ªæ§½æ³¨é‡Šç»„æˆï¼Œæ¶µç›– 31 ä¸ªç½‘ç«™å’Œç§»åŠ¨åº”ç”¨ç¨‹åºçš„éšç§æ”¿ç­–ã€‚ PolicyIE è¯­æ–™åº“æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ç°å®ä¸–ç•ŒåŸºå‡†ï¼Œå…¶æœ‰é™çš„æ ‡è®°ç¤ºä¾‹åæ˜ äº†ä»é¢†åŸŸä¸“å®¶é‚£é‡Œæ”¶é›†å¤§è§„æ¨¡æ³¨é‡Šçš„æˆæœ¬ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ç§æ›¿ä»£ç¥ç»æ–¹æ³•ä½œä¸ºåŸºçº¿ï¼Œ(1) æ„å›¾åˆ†ç±»å’Œæ§½å¡«å……ä½œä¸ºè”åˆåºåˆ—æ ‡è®°ï¼Œ(2) å°†å®ƒä»¬å»ºæ¨¡ä¸ºåºåˆ—åˆ°åºåˆ— (Seq2Seq) å­¦ä¹ ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸¤ç§æ–¹æ³•åœ¨æ„å›¾åˆ†ç±»æ–¹é¢çš„è¡¨ç°ç›¸å½“ï¼Œè€Œ Seq2Seq æ–¹æ³•åœ¨æ§½å¡«å……æ–¹é¢ä¼˜äºåºåˆ—æ ‡è®°æ–¹æ³•ã€‚æˆ‘ä»¬è¿›è¡Œäº†è¯¦ç»†çš„é”™è¯¯åˆ†æï¼Œä»¥æ­ç¤ºæ‰€æå‡ºçš„è¯­æ–™åº“çš„æŒ‘æˆ˜ã€‚</td><td>Wasi Uddin Ahmad   Jianfeng Chi   Tu Le   Thomas Norton   Yuan Tian   Kai-Wei Chang</td></tr><tr><td>11</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.12578&#39;]">Dual Slot Selector via Local Reliability Verification for Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/guojinyu88/DSSDST">https://github.com/guojinyu88/DSSDST</a></td><td><a href="https://arxiv.org/pdf/2107.12578">https://arxiv.org/pdf/2107.12578</a></td><td>The goal of dialogue state tracking (DST) is to predict the current dialogue state given all previous dialogue contexts. Existing approaches generally predict the dialogue state at every turn from scratch. However, the overwhelming majority of the slots in each turn should simply inherit the slot values from the previous turn. Therefore, the mechanism of treating slots equally in each turn not only is inefficient but also may lead to additional errors because of the redundant slot value generation. To address this problem, we devise the two-stage DSS-DST which consists of the Dual Slot Selector based on the current turn dialogue, and the Slot Value Generator based on the dialogue history. The Dual Slot Selector determines each slot whether to update slot value or to inherit the slot value from the previous turn from two aspects: (1) if there is a strong relationship between it and the current turn dialogue utterances; (2) if a slot value with high reliability can be obtained for it through the current turn dialogue. The slots selected to be updated are permitted to enter the Slot Value Generator to update values by a hybrid method, while the other slots directly inherit the values from the previous turn. Empirical results show that our method achieves 56.93%, 60.73%, and 58.04% joint accuracy on MultiWOZ 2.0, MultiWOZ 2.1, and MultiWOZ 2.2 datasets respectively and achieves a new state-of-the-art performance with significant improvements.</td><td>å¯¹è¯çŠ¶æ€è·Ÿè¸ªï¼ˆDSTï¼‰çš„ç›®æ ‡æ˜¯åœ¨ç»™å®šæ‰€æœ‰å…ˆå‰å¯¹è¯ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹é¢„æµ‹å½“å‰å¯¹è¯çŠ¶æ€ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä»å¤´å¼€å§‹é¢„æµ‹æ¯ä¸€è½®çš„å¯¹è¯çŠ¶æ€ã€‚ç„¶è€Œï¼Œæ¯ä¸€å›åˆä¸­çš„ç»å¤§å¤šæ•°æ§½ä½åº”è¯¥ç®€å•åœ°ç»§æ‰¿ä¸Šä¸€å›åˆçš„æ§½ä½å€¼ã€‚å› æ­¤ï¼Œåœ¨æ¯ä¸€è½®ä¸­å¹³ç­‰å¯¹å¾…æ§½çš„æœºåˆ¶ä¸ä»…æ•ˆç‡ä½ä¸‹ï¼Œè€Œä¸”å¯èƒ½ç”±äºå†—ä½™æ§½å€¼çš„ç”Ÿæˆè€Œå¯¼è‡´é¢å¤–çš„é”™è¯¯ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸¤é˜¶æ®µ DSS-DSTï¼Œå®ƒç”±åŸºäºå½“å‰å›åˆå¯¹è¯çš„åŒæ§½é€‰æ‹©å™¨å’ŒåŸºäºå¯¹è¯å†å²çš„æ§½å€¼ç”Ÿæˆå™¨ç»„æˆã€‚ Dual Slot Selectorä»ä¸¤ä¸ªæ–¹é¢å†³å®šæ¯ä¸ªæ§½æ˜¯æ›´æ–°æ§½å€¼è¿˜æ˜¯ç»§æ‰¿ä¸Šä¸€å›åˆçš„æ§½å€¼ï¼šï¼ˆ1ï¼‰æ˜¯å¦ä¸å½“å‰å›åˆå¯¹è¯è¯è¯­æœ‰å¾ˆå¼ºçš„å…³ç³»ï¼› (2) æ˜¯å¦å¯ä»¥é€šè¿‡å½“å‰å›åˆå¯¹è¯ä¸ºå…¶è·å¾—é«˜å¯é æ€§çš„æ§½å€¼ã€‚é€‰æ‹©æ›´æ–°çš„æ§½ä½è¢«å…è®¸è¿›å…¥æ§½ä½å€¼ç”Ÿæˆå™¨ä»¥æ··åˆæ–¹å¼æ›´æ–°å€¼ï¼Œè€Œå…¶ä»–æ§½ä½ç›´æ¥ç»§æ‰¿ä¸Šä¸€å›åˆçš„å€¼ã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ MultiWOZ 2.0ã€MultiWOZ 2.1 å’Œ MultiWOZ 2.2 æ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº† 56.93%ã€60.73% å’Œ 58.04% çš„è”åˆç²¾åº¦ï¼Œå¹¶å®ç°äº†æ–°çš„æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å…·æœ‰æ˜¾ç€çš„æ”¹è¿›ã€‚</td><td>Jinyu Guo   Kai Shuang   Jijie Li   Zihan Wang</td></tr><tr><td>12</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.15171&#39;]">Learning from Perturbations: Diverse and Informative Dialogue Generation with Inverse Adversarial Training</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.15171">https://arxiv.org/pdf/2105.15171</a></td><td>In this paper, we propose Inverse Adversarial Training (IAT) algorithm for training neural dialogue systems to avoid generic responses and model dialogue history better. In contrast to standard adversarial training algorithms, IAT encourages the model to be sensitive to the perturbation in the dialogue history and therefore learning from perturbations. By giving higher rewards for responses whose output probability reduces more significantly when dialogue history is perturbed, the model is encouraged to generate more diverse and consistent responses. By penalizing the model when generating the same response given perturbed dialogue history, the model is forced to better capture dialogue history and generate more informative responses. Experimental results on two benchmark datasets show that our approach can better model dialogue history and generate more diverse and consistent responses. In addition, we point out a problem of the widely used maximum mutual information (MMI) based methods for improving the diversity of dialogue response generation models and demonstrate it empirically.</td><td>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºè®­ç»ƒç¥ç»å¯¹è¯ç³»ç»Ÿçš„åå‘å¯¹æŠ—è®­ç»ƒ (IAT) ç®—æ³•ï¼Œä»¥æ›´å¥½åœ°é¿å…é€šç”¨å“åº”å’Œæ¨¡å‹å¯¹è¯å†å²ã€‚ä¸æ ‡å‡†çš„å¯¹æŠ—è®­ç»ƒç®—æ³•ç›¸æ¯”ï¼ŒIAT é¼“åŠ±æ¨¡å‹å¯¹å¯¹è¯å†å²ä¸­çš„æ‰°åŠ¨æ•æ„Ÿï¼Œä»è€Œä»æ‰°åŠ¨ä¸­å­¦ä¹ ã€‚é€šè¿‡å¯¹å¯¹è¯å†å²å—åˆ°æ‰°åŠ¨æ—¶è¾“å‡ºæ¦‚ç‡é™ä½æ›´æ˜¾ç€çš„å“åº”ç»™äºˆæ›´é«˜çš„å¥–åŠ±ï¼Œé¼“åŠ±æ¨¡å‹ç”Ÿæˆæ›´å¤šæ ·åŒ–å’Œä¸€è‡´çš„å“åº”ã€‚é€šè¿‡åœ¨ç»™å®šæ‰°åŠ¨çš„å¯¹è¯å†å²æ—¶ç”Ÿæˆç›¸åŒå“åº”æ—¶æƒ©ç½šæ¨¡å‹ï¼Œè¯¥æ¨¡å‹è¢«è¿«æ›´å¥½åœ°æ•è·å¯¹è¯å†å²å¹¶ç”Ÿæˆæ›´å¤šä¿¡æ¯å“åº”ã€‚åœ¨ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ›´å¥½åœ°å¯¹å¯¹è¯å†å²è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ç”Ÿæˆæ›´å¤šæ ·åŒ–å’Œä¸€è‡´çš„å“åº”ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æŒ‡å‡ºäº†å¹¿æ³›ä½¿ç”¨çš„åŸºäºæœ€å¤§äº’ä¿¡æ¯ï¼ˆMMIï¼‰çš„æ–¹æ³•ç”¨äºæé«˜å¯¹è¯å“åº”ç”Ÿæˆæ¨¡å‹çš„å¤šæ ·æ€§çš„é—®é¢˜ï¼Œå¹¶è¿›è¡Œäº†å®è¯è¯æ˜ã€‚</td><td>Wangchunshu Zhou   Qifei Li   Chenle Li</td></tr><tr><td>13</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.11164&#39;]">Modeling Bilingual Conversational Characteristics for Neural Chat Translation</a></td><td></td><td><a href="https://github.com/XL2248/CPCC">https://github.com/XL2248/CPCC</a></td><td><a href="https://arxiv.org/pdf/2107.11164">https://arxiv.org/pdf/2107.11164</a></td><td>Neural chat translation aims to translate bilingual conversational text, which has a broad application in international exchanges and cooperation. Despite the impressive performance of sentence-level and context-aware Neural Machine Translation (NMT), there still remain challenges to translate bilingual conversational text due to its inherent characteristics such as role preference, dialogue coherence, and translation consistency. In this paper, we aim to promote the translation quality of conversational text by modeling the above properties. Specifically, we design three latent variational modules to learn the distributions of bilingual conversational characteristics. Through sampling from these learned distributions, the latent variables, tailored for role preference, dialogue coherence, and translation consistency, are incorporated into the NMT model for better translation. We evaluate our approach on the benchmark dataset BConTrasT (English-German) and a self-collected bilingual dialogue corpus, named BMELD (English-Chinese). Extensive experiments show that our approach notably boosts the performance over strong baselines by a large margin and significantly surpasses some state-of-the-art context-aware NMT models in terms of BLEU and TER. Additionally, we make the BMELD dataset publicly available for the research community.</td><td>ç¥ç»èŠå¤©ç¿»è¯‘æ—¨åœ¨ç¿»è¯‘åŒè¯­ä¼šè¯æ–‡æœ¬ï¼Œåœ¨å›½é™…äº¤æµä¸åˆä½œä¸­æœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚å°½ç®¡å¥å­çº§å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥ç¥ç»æœºå™¨ç¿»è¯‘ (NMT) çš„è¡¨ç°ä»¤äººå°è±¡æ·±åˆ»ï¼Œä½†ç”±äºå…¶å›ºæœ‰çš„ç‰¹æ€§ï¼Œä¾‹å¦‚è§’è‰²åå¥½ã€å¯¹è¯è¿è´¯æ€§å’Œç¿»è¯‘ä¸€è‡´æ€§ï¼Œç¿»è¯‘åŒè¯­ä¼šè¯æ–‡æœ¬ä»ç„¶å­˜åœ¨æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ—¨åœ¨é€šè¿‡å¯¹ä¸Šè¿°å±æ€§è¿›è¡Œå»ºæ¨¡æ¥æé«˜ä¼šè¯æ–‡æœ¬çš„ç¿»è¯‘è´¨é‡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸‰ä¸ªæ½œåœ¨çš„å˜åˆ†æ¨¡å—æ¥å­¦ä¹ åŒè¯­ä¼šè¯ç‰¹å¾çš„åˆ†å¸ƒã€‚é€šè¿‡ä»è¿™äº›å­¦ä¹ åˆ°çš„åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œä¸ºè§’è‰²åå¥½ã€å¯¹è¯è¿è´¯æ€§å’Œç¿»è¯‘ä¸€è‡´æ€§é‡èº«å®šåˆ¶çš„æ½œåœ¨å˜é‡è¢«çº³å…¥ NMT æ¨¡å‹ä¸­ï¼Œä»¥å®ç°æ›´å¥½çš„ç¿»è¯‘ã€‚æˆ‘ä»¬åœ¨åŸºå‡†æ•°æ®é›† BConTrasTï¼ˆè‹±å¾·ï¼‰å’Œè‡ªæ”¶é›†çš„åŒè¯­å¯¹è¯è¯­æ–™åº“ BMELDï¼ˆè‹±æ±‰ï¼‰ä¸Šè¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾ç€æé«˜äº†å¼ºåŸºçº¿çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨ BLEU å’Œ TER æ–¹é¢æ˜¾ç€è¶…è¶Šäº†ä¸€äº›æœ€å…ˆè¿›çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥ NMT æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å‘ç ”ç©¶ç¤¾åŒºå…¬å¼€ BMELD æ•°æ®é›†ã€‚</td><td>Yunlong Liang   Fandong Meng   Yufeng Chen   Jinan Xu   Jie Zhou</td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11019&#39;]">Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/LooperXX/DF-Net">https://github.com/LooperXX/DF-Net</a></td><td><a href="https://arxiv.org/pdf/2004.11019">https://arxiv.org/pdf/2004.11019</a></td><td>Recent studies have shown remarkable success in end-to-end task-oriented dialog system. However, most neural models rely on large training data, which are only available for a certain number of task domains, such as navigation and scheduling.</td><td></td><td></td></tr><tr><td>This makes it difficult to scalable for a new domain with limited labeled data. However, there has been relatively little research on how to effectively use data from all domains to improve the performance of each domain and also unseen domains. To this end, we investigate methods that can make explicit use of domain knowledge and introduce a shared-private network to learn shared and specific knowledge. In addition, we propose a novel Dynamic Fusion Network (DF-Net) which automatically exploit the relevance between the target domain and each domain. Results show that our model outperforms existing methods on multi-domain dialogue, giving the state-of-the-art in the literature. Besides, with little training data, we show its transferability by outperforming prior best model by 13.9\% on average.</td><td>æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œç«¯åˆ°ç«¯çš„é¢å‘ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿå–å¾—äº†æ˜¾ç€çš„æˆåŠŸã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç¥ç»æ¨¡å‹ä¾èµ–äºå¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè¿™äº›æ•°æ®ä»…é€‚ç”¨äºä¸€å®šæ•°é‡çš„ä»»åŠ¡åŸŸï¼Œä¾‹å¦‚å¯¼èˆªå’Œè°ƒåº¦ã€‚</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>è¿™ä½¿å¾—éš¾ä»¥é’ˆå¯¹å…·æœ‰æœ‰é™æ ‡è®°æ•°æ®çš„æ–°åŸŸè¿›è¡Œæ‰©å±•ã€‚ç„¶è€Œï¼Œå…³äºå¦‚ä½•æœ‰æ•ˆåœ°ä½¿ç”¨æ¥è‡ªæ‰€æœ‰é¢†åŸŸçš„æ•°æ®æ¥æé«˜æ¯ä¸ªé¢†åŸŸå’Œä¸å¯è§é¢†åŸŸçš„æ€§èƒ½çš„ç ”ç©¶ç›¸å¯¹è¾ƒå°‘ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¯ä»¥æ˜ç¡®ä½¿ç”¨é¢†åŸŸçŸ¥è¯†å¹¶å¼•å…¥å…±äº«ç§æœ‰ç½‘ç»œæ¥å­¦ä¹ å…±äº«å’Œç‰¹å®šçŸ¥è¯†çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŠ¨æ€èåˆç½‘ç»œï¼ˆDF-Netï¼‰ï¼Œå®ƒå¯ä»¥è‡ªåŠ¨åˆ©ç”¨ç›®æ ‡åŸŸå’Œæ¯ä¸ªåŸŸä¹‹é—´çš„ç›¸å…³æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å¤šé¢†åŸŸå¯¹è¯æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæä¾›äº†æ–‡çŒ®ä¸­çš„æœ€æ–°æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œåœ¨è®­ç»ƒæ•°æ®å¾ˆå°‘çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é€šè¿‡æ¯”å…ˆå‰çš„æœ€ä½³æ¨¡å‹å¹³å‡é«˜å‡º 13.9% æ¥å±•ç¤ºå…¶å¯è¿ç§»æ€§ã€‚</td><td>Libo Qin   Xiao Xu   Wanxiang Che   Yue Zhang   Ting Liu</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11054&#39;]">Learning Dialog Policies from Weak Demonstrations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.11054">https://arxiv.org/pdf/2004.11054</a></td><td>Deep reinforcement learning is a promising approach to training a dialog manager, but current methods struggle with the large state and action spaces of multi-domain dialog systems. Building upon Deep Q-learning from Demonstrations (DQfD), an algorithm that scores highly in difficult Atari games, we leverage dialog data to guide the agent to successfully respond to a userâ€™s requests. We make progressively fewer assumptions about the data needed, using labeled, reduced-labeled, and even unlabeled data to train expert demonstrators. We introduce Reinforced Fine-tune Learning, an extension to DQfD, enabling us to overcome the domain gap between the datasets and the environment. Experiments in a challenging multi-domain dialog system framework validate our approaches, and get high success rates even when trained on out-of-domain data.</td><td>æ·±åº¦å¼ºåŒ–å­¦ä¹ æ˜¯è®­ç»ƒå¯¹è¯ç®¡ç†å™¨çš„ä¸€ç§å¾ˆæœ‰å‰é€”çš„æ–¹æ³•ï¼Œä½†å½“å‰çš„æ–¹æ³•éš¾ä»¥åº”å¯¹å¤šåŸŸå¯¹è¯ç³»ç»Ÿçš„å¤§å‹çŠ¶æ€å’ŒåŠ¨ä½œç©ºé—´ã€‚åŸºäºæ¼”ç¤ºä¸­çš„æ·±åº¦ Q å­¦ä¹  (DQfD)ï¼Œä¸€ç§åœ¨å›°éš¾çš„ Atari æ¸¸æˆä¸­å¾—åˆ†å¾ˆé«˜çš„ç®—æ³•ï¼Œæˆ‘ä»¬åˆ©ç”¨å¯¹è¯æ•°æ®æ¥æŒ‡å¯¼ä»£ç†æˆåŠŸå“åº”ç”¨æˆ·çš„è¯·æ±‚ã€‚æˆ‘ä»¬é€æ¸å‡å°‘å¯¹æ‰€éœ€æ•°æ®çš„å‡è®¾ï¼Œä½¿ç”¨æ ‡è®°ã€å‡å°‘æ ‡è®°ç”šè‡³æœªæ ‡è®°çš„æ•°æ®æ¥è®­ç»ƒä¸“å®¶æ¼”ç¤ºè€…ã€‚æˆ‘ä»¬å¼•å…¥äº†å¼ºåŒ–å¾®è°ƒå­¦ä¹ ï¼Œè¿™æ˜¯ DQfD çš„æ‰©å±•ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿå…‹æœæ•°æ®é›†å’Œç¯å¢ƒä¹‹é—´çš„é¢†åŸŸå·®è·ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å¤šåŸŸå¯¹è¯ç³»ç»Ÿæ¡†æ¶ä¸­è¿›è¡Œçš„å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå³ä½¿åœ¨åŸŸå¤–æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒæ—¶ä¹Ÿèƒ½è·å¾—å¾ˆé«˜çš„æˆåŠŸç‡ã€‚</td><td>Gabriel Gordon-Hall   Philip John Gorinski   Shay B. Cohen</td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.08866&#39;]">Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained Conversational Representations</a></td><td></td><td><a href="https://github.com/PolyAI-LDN/task-specific-datasets">https://github.com/PolyAI-LDN/task-specific-datasets</a></td><td><a href="https://arxiv.org/pdf/2005.08866">https://arxiv.org/pdf/2005.08866</a></td><td>We introduce Span-ConveRT, a light-weight model for dialog slot-filling which frames the task as a turn-based span extraction task. This formulation allows for a simple integration of conversational knowledge coded in large pretrained conversational models such as ConveRT (Henderson et al., 2019). We show that leveraging such knowledge in Span-ConveRT is especially useful for few-shot learning scenarios: we report consistent gains over 1) a span extractor that trains representations from scratch in the target domain, and 2) a BERT-based span extractor. In order to inspire more work on span extraction for the slot-filling task, we also release RESTAURANTS-8K, a new challenging data set of 8,198 utterances, compiled from actual conversations in the restaurant booking domain.</td><td>æˆ‘ä»¬å¼•å…¥äº† Span-ConveRTï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå¯¹è¯æ§½å¡«å……çš„è½»é‡çº§æ¨¡å‹ï¼Œå®ƒå°†ä»»åŠ¡æ¡†æ¶ä¸ºåŸºäºå›åˆçš„è·¨åº¦æå–ä»»åŠ¡ã€‚è¿™ç§å…¬å¼å…è®¸ç®€å•åœ°é›†æˆåœ¨å¤§å‹é¢„è®­ç»ƒä¼šè¯æ¨¡å‹ï¼ˆå¦‚ ConveRTï¼‰ä¸­ç¼–ç çš„ä¼šè¯çŸ¥è¯†ï¼ˆHenderson ç­‰ï¼Œ2019ï¼‰ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œåœ¨ Span-ConveRT ä¸­åˆ©ç”¨è¿™äº›çŸ¥è¯†å¯¹äºå°‘æ ·æœ¬å­¦ä¹ åœºæ™¯ç‰¹åˆ«æœ‰ç”¨ï¼šæˆ‘ä»¬æŠ¥å‘Šäº†ä¸€è‡´çš„æ”¶ç›Šï¼š1ï¼‰ä¸€ä¸ªè·¨åº¦æå–å™¨ï¼Œåœ¨ç›®æ ‡åŸŸä¸­ä»å¤´å¼€å§‹è®­ç»ƒè¡¨ç¤ºï¼Œ2ï¼‰ä¸€ä¸ªåŸºäº BERT çš„è·¨åº¦æå–å™¨ã€‚ä¸ºäº†æ¿€å‘æ›´å¤šå…³äºæ§½ä½å¡«å……ä»»åŠ¡çš„è·¨åº¦æå–å·¥ä½œï¼Œæˆ‘ä»¬è¿˜å‘å¸ƒäº† RESTAURANTS-8Kï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ï¼ŒåŒ…å« 8,198 æ¡è¯è¯­ï¼Œç”±é¤å…é¢„è®¢é¢†åŸŸçš„å®é™…å¯¹è¯ç¼–è¯‘è€Œæˆã€‚</td><td>Sam Coope   Tyler Farghly   Daniela Gerz   Ivan VuliÄ‡   Matthew Henderson</td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.04346&#39;]">Diversifying Dialogue Generation with Non-Conversational Text</a></td><td></td><td><a href="https://github.com/chin-gyou/Div-Non-Conv">https://github.com/chin-gyou/Div-Non-Conv</a></td><td><a href="https://arxiv.org/pdf/2005.04346">https://arxiv.org/pdf/2005.04346</a></td><td>Neural network-based sequence-to-sequence (seq2seq) models strongly suffer from the low-diversity problem when it comes to open-domain dialogue generation. As bland and generic utterances usually dominate the frequency distribution in our daily chitchat, avoiding them to generate more interesting responses requires complex data filtering, sampling techniques or modifying the training objective. In this paper, we propose a new perspective to diversify dialogue generation by leveraging non-conversational text. Compared with bilateral conversations, non-conversational text are easier to obtain, more diverse and cover a much broader range of topics. We collect a large-scale non-conversational corpus from multi sources including forum comments, idioms and book snippets. We further present a training paradigm to effectively incorporate these text via iterative back translation. The resulting model is tested on two conversational datasets and is shown to produce significantly more diverse responses without sacrificing the relevance with context.</td><td>å½“æ¶‰åŠåˆ°å¼€æ”¾åŸŸå¯¹è¯ç”Ÿæˆæ—¶ï¼ŒåŸºäºç¥ç»ç½‘ç»œçš„åºåˆ—åˆ°åºåˆ— (seq2seq) æ¨¡å‹ä¸¥é‡å—åˆ°ä½å¤šæ ·æ€§é—®é¢˜çš„å½±å“ã€‚ç”±äºå¹³æ·¡å’Œé€šç”¨çš„è¯è¯­é€šå¸¸åœ¨æˆ‘ä»¬çš„æ—¥å¸¸èŠå¤©ä¸­å æ®é¢‘ç‡åˆ†å¸ƒçš„ä¸»å¯¼åœ°ä½ï¼Œå› æ­¤é¿å…å®ƒä»¬äº§ç”Ÿæ›´æœ‰è¶£çš„å“åº”éœ€è¦å¤æ‚çš„æ•°æ®è¿‡æ»¤ã€é‡‡æ ·æŠ€æœ¯æˆ–ä¿®æ”¹è®­ç»ƒç›®æ ‡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„è§†è§’ï¼Œé€šè¿‡åˆ©ç”¨éå¯¹è¯æ–‡æœ¬æ¥ä½¿å¯¹è¯ç”Ÿæˆå¤šæ ·åŒ–ã€‚ä¸åŒè¾¹å¯¹è¯ç›¸æ¯”ï¼Œéå¯¹è¯æ–‡æœ¬æ›´å®¹æ˜“è·å–ã€æ›´å¤šæ ·åŒ–å¹¶ä¸”æ¶µç›–çš„ä¸»é¢˜èŒƒå›´æ›´å¹¿ã€‚æˆ‘ä»¬ä»åŒ…æ‹¬è®ºå›è¯„è®ºã€ä¹ è¯­å’Œä¹¦ç±ç‰‡æ®µåœ¨å†…çš„å¤šä¸ªæ¥æºæ”¶é›†äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„éä¼šè¯è¯­æ–™åº“ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§è®­ç»ƒèŒƒå¼ï¼Œä»¥é€šè¿‡è¿­ä»£å›è¯‘æœ‰æ•ˆåœ°åˆå¹¶è¿™äº›æ–‡æœ¬ã€‚ç”Ÿæˆçš„æ¨¡å‹åœ¨ä¸¤ä¸ªä¼šè¯æ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œç»“æœè¡¨æ˜å¯ä»¥åœ¨ä¸ç‰ºç‰²ä¸ä¸Šä¸‹æ–‡çš„ç›¸å…³æ€§çš„æƒ…å†µä¸‹äº§ç”Ÿæ›´åŠ å¤šæ ·åŒ–çš„å“åº”ã€‚</td><td>Hui Su   Xiaoyu Shen   Sanqiang Zhao   Xiao Zhou   Pengwei Hu   Randy Zhong   Cheng Niu   Jie Zhou</td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.09544&#39;]">Grounding Conversations with Improvised Dialogues</a></td><td></td><td><a href="https://github.com/wise-east/spolin">https://github.com/wise-east/spolin</a></td><td><a href="https://arxiv.org/pdf/2004.09544">https://arxiv.org/pdf/2004.09544</a></td><td>Effective dialogue involves grounding, the process of establishing mutual knowledge that is essential for communication between people. Modern dialogue systems are not explicitly trained to build common ground, and therefore overlook this important aspect of communication. Improvisational theater (improv) intrinsically contains a high proportion of dialogue focused on building common ground, and makes use of the yes-and principle, a strong grounding speech act, to establish coherence and an actionable objective reality. We collect a corpus of more than 26,000 yes-and turns, transcribing them from improv dialogues and extracting them from larger, but more sparsely populated movie script dialogue corpora, via a bootstrapped classifier. We fine-tune chit-chat dialogue systems with our corpus to encourage more grounded, relevant conversation and confirm these findings with human evaluations.</td><td>æœ‰æ•ˆçš„å¯¹è¯æ¶‰åŠåŸºç¡€ï¼Œå³å»ºç«‹ç›¸äº’äº†è§£çš„è¿‡ç¨‹ï¼Œè¿™å¯¹äºäººä¸äººä¹‹é—´çš„äº¤æµè‡³å…³é‡è¦ã€‚ç°ä»£å¯¹è¯ç³»ç»Ÿæ²¡æœ‰ç»è¿‡æ˜ç¡®è®­ç»ƒæ¥å»ºç«‹å…±åŒç‚¹ï¼Œå› æ­¤å¿½ç•¥äº†æ²Ÿé€šçš„è¿™ä¸€é‡è¦æ–¹é¢ã€‚å³å…´æˆå‰§ (improv) æœ¬è´¨ä¸ŠåŒ…å«ç€å¤§é‡ä¾§é‡äºå»ºç«‹å…±åŒç‚¹çš„å¯¹è¯ï¼Œå¹¶åˆ©ç”¨æ˜¯å’ŒåŸåˆ™ï¼Œä¸€ç§å¼ºå¤§çš„åŸºç¡€è¨€è¯­è¡Œä¸ºï¼Œå»ºç«‹è¿è´¯æ€§å’Œå¯æ“ä½œçš„å®¢è§‚ç°å®ã€‚æˆ‘ä»¬æ”¶é›†äº†è¶…è¿‡ 26,000 ä¸ªæ˜¯å’Œè½¬çš„è¯­æ–™åº“ï¼Œä»å³å…´å¯¹è¯ä¸­è½¬å½•å®ƒä»¬ï¼Œå¹¶é€šè¿‡è‡ªä¸¾åˆ†ç±»å™¨ä»æ›´å¤§ä½†äººå£æ›´ç¨€å°‘çš„ç”µå½±å‰§æœ¬å¯¹è¯è¯­æ–™åº“ä¸­æå–å®ƒä»¬ã€‚æˆ‘ä»¬ä½¿ç”¨æˆ‘ä»¬çš„è¯­æ–™åº“å¾®è°ƒé—²èŠå¯¹è¯ç³»ç»Ÿï¼Œä»¥é¼“åŠ±æ›´æ‰å®ã€ç›¸å…³çš„å¯¹è¯ï¼Œå¹¶é€šè¿‡äººå·¥è¯„ä¼°ç¡®è®¤è¿™äº›å‘ç°ã€‚</td><td>Hyundong Cho   Jonathan May</td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04908&#39;]">Designing Precise and Robust Dialogue Response Evaluators</a></td><td></td><td><a href="https://github.com/ZHAOTING/dialog-processing">https://github.com/ZHAOTING/dialog-processing</a></td><td><a href="https://arxiv.org/pdf/2004.04908">https://arxiv.org/pdf/2004.04908</a></td><td>Automatic dialogue response evaluator has been proposed as an alternative to automated metrics and human evaluation. However, existing automatic evaluators achieve only moderate correlation with human judgement and they are not robust. In this work, we propose to build a reference-free evaluator and exploit the power of semi-supervised training and pretrained (masked) language models. Experimental results demonstrate that the proposed evaluator achieves a strong correlation (&gt; 0.6) with human judgement and generalizes robustly to diverse responses and corpora. We open-source the code and data in <a href="https://github.com/ZHAOTING/dialog-processing">https://github.com/ZHAOTING/dialog-processing</a>.</td><td>è‡ªåŠ¨å¯¹è¯å“åº”è¯„ä¼°å™¨å·²è¢«æè®®ä½œä¸ºè‡ªåŠ¨åº¦é‡å’Œäººå·¥è¯„ä¼°çš„æ›¿ä»£æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œç°æœ‰çš„è‡ªåŠ¨è¯„ä¼°å™¨ä¸äººç±»åˆ¤æ–­ä»…å®ç°ä¸­ç­‰ç¨‹åº¦çš„ç›¸å…³æ€§ï¼Œå¹¶ä¸”å®ƒä»¬å¹¶ä¸ç¨³å¥ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å»ºè®®æ„å»ºä¸€ä¸ªæ— å‚è€ƒè¯„ä¼°å™¨ï¼Œå¹¶åˆ©ç”¨åŠç›‘ç£è®­ç»ƒå’Œé¢„è®­ç»ƒï¼ˆå±è”½ï¼‰è¯­è¨€æ¨¡å‹çš„åŠ›é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„è¯„ä¼°å™¨ä¸äººç±»åˆ¤æ–­å…·æœ‰å¾ˆå¼ºçš„ç›¸å…³æ€§ï¼ˆ&gt; 0.6ï¼‰ï¼Œå¹¶ä¸”å¯ä»¥ç¨³å¥åœ°æ¨å¹¿åˆ°ä¸åŒçš„å“åº”å’Œè¯­æ–™åº“ã€‚æˆ‘ä»¬åœ¨ <a href="https://github.com/ZHAOTING/dialog-processing">https://github.com/ZHAOTING/dialog-processing</a> ä¸­å¼€æºäº†ä»£ç å’Œæ•°æ®ã€‚</td><td>Tianyu Zhao   Divesh Lala   Tatsuya Kawahara</td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.07931&#39;]">PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research">https://github.com/PaddlePaddle/Research</a></td><td><a href="https://arxiv.org/pdf/1910.07931">https://arxiv.org/pdf/1910.07931</a></td><td>Pre-training models have been proved effective for a wide range of natural language processing tasks. Inspired by this, we propose a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering. In this framework, we adopt flexible attention mechanisms to fully leverage the bi-directional context and the uni-directional characteristic of language generation. We also introduce discrete latent variables to tackle the inherent one-to-many mapping problem in response generation. Two reciprocal tasks of response generation and latent act recognition are designed and carried out simultaneously within a shared network. Comprehensive experiments on three publicly available datasets verify the effectiveness and superiority of the proposed framework.</td><td>é¢„è®­ç»ƒæ¨¡å‹å·²è¢«è¯æ˜å¯¹å¹¿æ³›çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡æœ‰æ•ˆã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¯¹è¯ç”Ÿæˆé¢„è®­ç»ƒæ¡†æ¶ï¼Œä»¥æ”¯æŒå„ç§å¯¹è¯ï¼ŒåŒ…æ‹¬é—²èŠã€åŸºäºçŸ¥è¯†çš„å¯¹è¯å’Œå¯¹è¯é—®ç­”ã€‚åœ¨è¿™ä¸ªæ¡†æ¶ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨çµæ´»çš„æ³¨æ„åŠ›æœºåˆ¶æ¥å……åˆ†åˆ©ç”¨åŒå‘ä¸Šä¸‹æ–‡å’Œè¯­è¨€ç”Ÿæˆçš„å•å‘ç‰¹æ€§ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ç¦»æ•£æ½œåœ¨å˜é‡æ¥è§£å†³å“åº”ç”Ÿæˆä¸­å›ºæœ‰çš„ä¸€å¯¹å¤šæ˜ å°„é—®é¢˜ã€‚å“åº”ç”Ÿæˆå’Œæ½œåœ¨è¡Œä¸ºè¯†åˆ«è¿™ä¸¤ä¸ªäº’æƒ ä»»åŠ¡æ˜¯åœ¨å…±äº«ç½‘ç»œä¸­åŒæ—¶è®¾è®¡å’Œæ‰§è¡Œçš„ã€‚å¯¹ä¸‰ä¸ªå…¬å¼€å¯ç”¨æ•°æ®é›†çš„ç»¼åˆå®éªŒéªŒè¯äº†æ‰€æå‡ºæ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</td><td>Siqi Bao   Huang He   Fan Wang   Hua Wu   Haifeng Wang</td></tr><tr><td>21</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00891&#39;]">Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/stanford-oval/zero-shot-multiwoz-acl2020">https://github.com/stanford-oval/zero-shot-multiwoz-acl2020</a></td><td><a href="https://arxiv.org/pdf/2005.00891">https://arxiv.org/pdf/2005.00891</a></td><td>Zero-shot transfer learning for multi-domain dialogue state tracking can allow us to handle new domains without incurring the high cost of data acquisition. This paper proposes new zero-short transfer learning technique for dialogue state tracking where the in-domain training data are all synthesized from an abstract dialogue model and the ontology of the domain. We show that data augmentation through synthesized data can improve the accuracy of zero-shot learning for both the TRADE model and the BERT-based SUMBT model on the MultiWOZ 2.1 dataset. We show training with only synthesized in-domain data on the SUMBT model can reach about 2/3 of the accuracy obtained with the full training dataset. We improve the zero-shot learning state of the art on average across domains by 21%.</td><td>ç”¨äºå¤šåŸŸå¯¹è¯çŠ¶æ€è·Ÿè¸ªçš„é›¶æ ·æœ¬è¿ç§»å­¦ä¹ å¯ä»¥è®©æˆ‘ä»¬å¤„ç†æ–°åŸŸï¼Œè€Œä¸ä¼šäº§ç”Ÿé«˜æ˜‚çš„æ•°æ®é‡‡é›†æˆæœ¬ã€‚æœ¬æ–‡æå‡ºäº†æ–°çš„ç”¨äºå¯¹è¯çŠ¶æ€è·Ÿè¸ªçš„é›¶çŸ­è½¬ç§»å­¦ä¹ æŠ€æœ¯ï¼Œå…¶ä¸­åŸŸå†…è®­ç»ƒæ•°æ®å…¨éƒ¨ç”±æŠ½è±¡å¯¹è¯æ¨¡å‹å’ŒåŸŸæœ¬ä½“åˆæˆã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œé€šè¿‡åˆæˆæ•°æ®è¿›è¡Œæ•°æ®å¢å¼ºå¯ä»¥æé«˜ MultiWOZ 2.1 æ•°æ®é›†ä¸Šçš„ TRADE æ¨¡å‹å’ŒåŸºäº BERT çš„ SUMBT æ¨¡å‹çš„é›¶æ ·æœ¬å­¦ä¹ çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œä»…åœ¨ SUMBT æ¨¡å‹ä¸Šä½¿ç”¨åˆæˆçš„åŸŸå†…æ•°æ®è¿›è¡Œè®­ç»ƒå¯ä»¥è¾¾åˆ°ä½¿ç”¨å®Œæ•´è®­ç»ƒæ•°æ®é›†è·å¾—çš„å‡†ç¡®åº¦çš„ 2/3 å·¦å³ã€‚æˆ‘ä»¬å°†è·¨é¢†åŸŸçš„é›¶æ ·æœ¬å­¦ä¹ æŠ€æœ¯å¹³å‡æé«˜äº† 21%ã€‚</td><td>Giovanni Campagna   Agata Foryciarz   Mehrad Moradshahi   Monica S. Lam</td></tr><tr><td>22</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.03809&#39;]">Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward Decomposition</a></td><td></td><td><a href="https://github.com/truthless11/MADPL">https://github.com/truthless11/MADPL</a></td><td><a href="https://arxiv.org/pdf/2004.03809">https://arxiv.org/pdf/2004.03809</a></td><td>Many studies have applied reinforcement learning to train a dialog policy and show great promise these years. One common approach is to employ a user simulator to obtain a large number of simulated user experiences for reinforcement learning algorithms. However, modeling a realistic user simulator is challenging. A rule-based simulator requires heavy domain expertise for complex tasks, and a data-driven simulator requires considerable data and it is even unclear how to evaluate a simulator. To avoid explicitly building a user simulator beforehand, we propose Multi-Agent Dialog Policy Learning, which regards both the system and the user as the dialog agents. Two agents interact with each other and are jointly learned simultaneously. The method uses the actor-critic framework to facilitate pretraining and improve scalability. We also propose Hybrid Value Network for the role-aware reward decomposition to integrate role-specific domain knowledge of each agent in the task-oriented dialog. Results show that our method can successfully build a system policy and a user policy simultaneously, and two agents can achieve a high task success rate through conversational interaction.</td><td>è®¸å¤šç ”ç©¶å·²ç»åº”ç”¨å¼ºåŒ–å­¦ä¹ æ¥è®­ç»ƒå¯¹è¯ç­–ç•¥ï¼Œå¹¶ä¸”è¿™äº›å¹´æ¥æ˜¾ç¤ºå‡ºå·¨å¤§çš„å¸Œæœ›ã€‚ä¸€ç§å¸¸è§çš„æ–¹æ³•æ˜¯ä½¿ç”¨ç”¨æˆ·æ¨¡æ‹Ÿå™¨ä¸ºå¼ºåŒ–å­¦ä¹ ç®—æ³•è·å–å¤§é‡æ¨¡æ‹Ÿç”¨æˆ·ä½“éªŒã€‚ç„¶è€Œï¼Œå¯¹çœŸå®çš„ç”¨æˆ·æ¨¡æ‹Ÿå™¨å»ºæ¨¡æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚åŸºäºè§„åˆ™çš„æ¨¡æ‹Ÿå™¨éœ€è¦å¤§é‡çš„é¢†åŸŸä¸“ä¸šçŸ¥è¯†æ¥å¤„ç†å¤æ‚çš„ä»»åŠ¡ï¼Œè€Œæ•°æ®é©±åŠ¨çš„æ¨¡æ‹Ÿå™¨éœ€è¦å¤§é‡æ•°æ®ï¼Œç”šè‡³ä¸æ¸…æ¥šå¦‚ä½•è¯„ä¼°æ¨¡æ‹Ÿå™¨ã€‚ä¸ºäº†é¿å…äº‹å…ˆæ˜ç¡®æ„å»ºç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šä»£ç†å¯¹è¯ç­–ç•¥å­¦ä¹ ï¼Œå®ƒå°†ç³»ç»Ÿå’Œç”¨æˆ·éƒ½è§†ä¸ºå¯¹è¯ä»£ç†ã€‚ä¸¤ä¸ªä»£ç†ç›¸äº’äº¤äº’å¹¶åŒæ—¶å…±åŒå­¦ä¹ ã€‚è¯¥æ–¹æ³•ä½¿ç”¨ actor-critic æ¡†æ¶æ¥ä¿ƒè¿›é¢„è®­ç»ƒå¹¶æé«˜å¯æ‰©å±•æ€§ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ç”¨äºè§’è‰²æ„ŸçŸ¥å¥–åŠ±åˆ†è§£çš„æ··åˆä»·å€¼ç½‘ç»œï¼Œä»¥åœ¨é¢å‘ä»»åŠ¡çš„å¯¹è¯ä¸­é›†æˆæ¯ä¸ªä»£ç†çš„ç‰¹å®šäºè§’è‰²çš„é¢†åŸŸçŸ¥è¯†ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æˆåŠŸåœ°åŒæ—¶æ„å»ºç³»ç»Ÿç­–ç•¥å’Œç”¨æˆ·ç­–ç•¥ï¼Œå¹¶ä¸”ä¸¤ä¸ªä»£ç†å¯ä»¥é€šè¿‡å¯¹è¯äº¤äº’å®ç°è¾ƒé«˜çš„ä»»åŠ¡æˆåŠŸç‡ã€‚</td><td>Ryuichi Takanobu   Runze Liang   Minlie Huang</td></tr><tr><td>23</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.03954&#39;]">Towards Conversational Recommendation over Multi-Type Dialogs</a></td><td></td><td><a href="https://github.com/PaddlePaddle/models">https://github.com/PaddlePaddle/models</a></td><td><a href="https://arxiv.org/pdf/2005.03954">https://arxiv.org/pdf/2005.03954</a></td><td>We propose a new task of conversational recommendation over multi-type dialogs, where the bots can proactively and naturally lead a conversation from a non-recommendation dialog (e.g., QA) to a recommendation dialog, taking into account userâ€™s interests and feedback. To facilitate the study of this task, we create a human-to-human Chinese dialog dataset \emph{DuRecDial} (about 10k dialogs, 156k utterances), which contains multiple sequential dialogs for every pair of a recommendation seeker (user) and a recommender (bot). In each dialog, the recommender proactively leads a multi-type dialog to approach recommendation targets and then makes multiple recommendations with rich interaction behavior. This dataset allows us to systematically investigate different parts of the overall problem, e.g., how to naturally lead a dialog, how to interact with users for recommendation. Finally we establish baseline results on DuRecDial for future studies. Dataset and codes are publicly available at <a href="https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2020-DuRecDial">https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2020-DuRecDial</a>.</td><td>æˆ‘ä»¬æå‡ºäº†å¤šç±»å‹å¯¹è¯çš„å¯¹è¯æ¨èæ–°ä»»åŠ¡ï¼Œå…¶ä¸­æœºå™¨äººå¯ä»¥ä¸»åŠ¨ä¸”è‡ªç„¶åœ°å°†å¯¹è¯ä»éæ¨èå¯¹è¯ï¼ˆä¾‹å¦‚ QAï¼‰å¼•å¯¼åˆ°æ¨èå¯¹è¯ï¼ŒåŒæ—¶è€ƒè™‘åˆ°ç”¨æˆ·çš„å…´è¶£å’Œåé¦ˆã€‚ä¸ºäº†ä¿ƒè¿›è¿™é¡¹ä»»åŠ¡çš„ç ”ç©¶ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªäººå¯¹äººçš„ä¸­æ–‡å¯¹è¯æ•°æ®é›† \emph{DuRecDial}ï¼ˆå¤§çº¦ 10k ä¸ªå¯¹è¯ï¼Œ156k ä¸ªè¯è¯­ï¼‰ï¼Œå…¶ä¸­åŒ…å«æ¯å¯¹æ¨èæœç´¢è€…ï¼ˆç”¨æˆ·ï¼‰å’Œä¸€ä¸ªæ¨èäººï¼ˆæœºå™¨äººï¼‰ã€‚åœ¨æ¯ä¸ªå¯¹è¯ä¸­ï¼Œæ¨èè€…ä¸»åŠ¨å¼•å¯¼å¤šç±»å‹å¯¹è¯æ¥è¿‘æ¨èç›®æ ‡ï¼Œç„¶ååšå‡ºå…·æœ‰ä¸°å¯Œäº¤äº’è¡Œä¸ºçš„å¤šé‡æ¨èã€‚è¯¥æ•°æ®é›†å…è®¸æˆ‘ä»¬ç³»ç»Ÿåœ°è°ƒæŸ¥æ•´ä¸ªé—®é¢˜çš„ä¸åŒéƒ¨åˆ†ï¼Œä¾‹å¦‚ï¼Œå¦‚ä½•è‡ªç„¶åœ°å¼•å¯¼å¯¹è¯ï¼Œå¦‚ä½•ä¸ç”¨æˆ·äº¤äº’ä»¥è¿›è¡Œæ¨èã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨ DuRecDial ä¸Šå»ºç«‹åŸºçº¿ç»“æœä»¥ä¾›æœªæ¥ç ”ç©¶ã€‚æ•°æ®é›†å’Œä»£ç å¯åœ¨ <a href="https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2020-DuRecDial">https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2020-DuRecDial</a> å…¬å¼€è·å¾—ã€‚</td><td>Zeming Liu   Haifeng Wang   Zheng-Yu Niu   Hua Wu   Wanxiang Che   Ting Liu</td></tr><tr><td>24</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04100&#39;]">KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation</a></td><td></td><td><a href="https://github.com/thu-coai/KdConv">https://github.com/thu-coai/KdConv</a></td><td><a href="https://arxiv.org/pdf/2004.04100">https://arxiv.org/pdf/2004.04100</a></td><td>The research of knowledge-driven conversational systems is largely limited due to the lack of dialog data which consist of multi-turn conversations on multiple topics and with knowledge annotations. In this paper, we propose a Chinese multi-domain knowledge-driven conversation dataset, KdConv, which grounds the topics in multi-turn conversations to knowledge graphs. Our corpus contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. These conversations contain in-depth discussions on related topics and natural transition between multiple topics. To facilitate the following research on this corpus, we provide several benchmark models. Comparative results show that the models can be enhanced by introducing background knowledge, yet there is still a large space for leveraging knowledge to model multi-turn conversations for further research. Results also show that there are obvious performance differences between different domains, indicating that it is worth to further explore transfer learning and domain adaptation. The corpus and benchmark models are publicly available.</td><td>ç”±äºç¼ºä¹ç”±å¤šä¸ªä¸»é¢˜çš„å¤šè½®å¯¹è¯å’ŒçŸ¥è¯†æ³¨é‡Šç»„æˆçš„å¯¹è¯æ•°æ®ï¼ŒçŸ¥è¯†é©±åŠ¨çš„å¯¹è¯ç³»ç»Ÿçš„ç ”ç©¶åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå—åˆ°é™åˆ¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸­æ–‡å¤šé¢†åŸŸçŸ¥è¯†é©±åŠ¨å¯¹è¯æ•°æ®é›† KdConvï¼Œå®ƒå°†å¤šè½®å¯¹è¯ä¸­çš„ä¸»é¢˜åŸºäºçŸ¥è¯†å›¾è°±ã€‚æˆ‘ä»¬çš„è¯­æ–™åº“åŒ…å«æ¥è‡ªä¸‰ä¸ªé¢†åŸŸï¼ˆç”µå½±ã€éŸ³ä¹å’Œæ—…è¡Œï¼‰çš„ 4.5K å¯¹è¯å’Œ 86K è¯è¯­ï¼Œå¹³å‡è½®æ•°ä¸º 19.0ã€‚è¿™äº›å¯¹è¯åŒ…å«å¯¹ç›¸å…³ä¸»é¢˜çš„æ·±å…¥è®¨è®ºä»¥åŠå¤šä¸ªä¸»é¢˜ä¹‹é—´çš„è‡ªç„¶è¿‡æ¸¡ã€‚ä¸ºäº†ä¾¿äºå¯¹è¯¥è¯­æ–™åº“çš„åç»­ç ”ç©¶ï¼Œæˆ‘ä»¬æä¾›äº†å‡ ä¸ªåŸºå‡†æ¨¡å‹ã€‚å¯¹æ¯”ç»“æœè¡¨æ˜ï¼Œå¯ä»¥é€šè¿‡å¼•å…¥èƒŒæ™¯çŸ¥è¯†æ¥å¢å¼ºæ¨¡å‹ï¼Œä½†åˆ©ç”¨çŸ¥è¯†å¯¹å¤šè½®å¯¹è¯è¿›è¡Œå»ºæ¨¡ä»¥ä¾›è¿›ä¸€æ­¥ç ”ç©¶ä»æœ‰å¾ˆå¤§çš„ç©ºé—´ã€‚ç»“æœè¿˜è¡¨æ˜ï¼Œä¸åŒé¢†åŸŸä¹‹é—´å­˜åœ¨æ˜æ˜¾çš„æ€§èƒ½å·®å¼‚ï¼Œè¡¨æ˜å€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢è¿ç§»å­¦ä¹ å’Œé¢†åŸŸé€‚åº”ã€‚è¯­æ–™åº“å’ŒåŸºå‡†æ¨¡å‹æ˜¯å…¬å¼€çš„ã€‚</td><td>Hao Zhou   Chujie Zheng   Kaili Huang   Minlie Huang   Xiaoyan Zhu</td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.08854&#39;]">Incremental Transformer with Deliberation Decoder for Document Grounded Conversations</a></td><td></td><td><a href="https://github.com/lizekang/ITDD">https://github.com/lizekang/ITDD</a></td><td><a href="https://arxiv.org/pdf/1907.08854">https://arxiv.org/pdf/1907.08854</a></td><td>Document Grounded Conversations is a task to generate dialogue responses when chatting about the content of a given document. Obviously, document knowledge plays a critical role in Document Grounded Conversations, while existing dialogue models do not exploit this kind of knowledge effectively enough. In this paper, we propose a novel Transformer-based architecture for multi-turn document grounded conversations. In particular, we devise an Incremental Transformer to encode multi-turn utterances along with knowledge in related documents. Motivated by the human cognitive process, we design a two-pass decoder (Deliberation Decoder) to improve context coherence and knowledge correctness. Our empirical study on a real-world Document Grounded Dataset proves that responses generated by our model significantly outperform competitive baselines on both context coherence and knowledge relevance.</td><td>Document Grounded Conversations æ˜¯ä¸€é¡¹åœ¨è®¨è®ºç»™å®šæ–‡æ¡£çš„å†…å®¹æ—¶ç”Ÿæˆå¯¹è¯å“åº”çš„ä»»åŠ¡ã€‚æ˜¾ç„¶ï¼Œæ–‡æ¡£çŸ¥è¯†åœ¨åŸºäºæ–‡æ¡£çš„å¯¹è¯ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œè€Œç°æœ‰çš„å¯¹è¯æ¨¡å‹å¹¶æ²¡æœ‰è¶³å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨è¿™ç§çŸ¥è¯†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäº Transformer çš„æ¶æ„ï¼Œç”¨äºå¤šè½®æ–‡æ¡£åŸºç¡€å¯¹è¯ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¢é‡è½¬æ¢å™¨æ¥ç¼–ç å¤šè½®è¯è¯­ä»¥åŠç›¸å…³æ–‡æ¡£ä¸­çš„çŸ¥è¯†ã€‚å—äººç±»è®¤çŸ¥è¿‡ç¨‹çš„å¯å‘ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä¸¤éè§£ç å™¨ï¼ˆDeliberation Decoderï¼‰æ¥æé«˜ä¸Šä¸‹æ–‡çš„ä¸€è‡´æ€§å’ŒçŸ¥è¯†çš„æ­£ç¡®æ€§ã€‚æˆ‘ä»¬å¯¹çœŸå®ä¸–ç•Œæ–‡æ¡£æ¥åœ°æ•°æ®é›†çš„å®è¯ç ”ç©¶è¯æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ç”Ÿæˆçš„å“åº”åœ¨ä¸Šä¸‹æ–‡ä¸€è‡´æ€§å’ŒçŸ¥è¯†ç›¸å…³æ€§æ–¹é¢éƒ½æ˜¾ç€ä¼˜äºç«äº‰åŸºå‡†ã€‚</td><td>Zekang Li   Cheng Niu   Fandong Meng   Yang Feng   Qian Li   Jie Zhou</td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.05373&#39;]">E3: Entailment-driven Extracting and Editing for Conversational Machine Reading</a></td><td></td><td><a href="https://github.com/vzhong/e3">https://github.com/vzhong/e3</a></td><td><a href="https://arxiv.org/pdf/1906.05373">https://arxiv.org/pdf/1906.05373</a></td><td>Conversational machine reading systems help users answer high-level questions (e.g. determine if they qualify for particular government benefits) when they do not know the exact rules by which the determination is made(e.g. whether they need certain income levels or veteran status). The key challenge is that these rules are only provided in the form of a procedural text (e.g. guidelines from government website) which the system must read to figure out what to ask the user. We present a new conversational machine reading model that jointly extracts a set of decision rules from the procedural text while reasoning about which are entailed by the conversational history and which still need to be edited to create questions for the user. On the recently introduced ShARC conversational machine reading dataset, our Entailment-driven Extract and Edit network (E3) achieves a new state-of-the-art, outperforming existing systems as well as a new BERT-based baseline. In addition, by explicitly highlighting which information still needs to be gathered, E3 provides a more explainable alternative to prior work. We release source code for our models and experiments at <a href="https://github.com/vzhong/e3">https://github.com/vzhong/e3</a>.</td><td>å½“ç”¨æˆ·ä¸çŸ¥é“åšå‡ºå†³å®šçš„ç¡®åˆ‡è§„åˆ™ï¼ˆä¾‹å¦‚ï¼Œä»–ä»¬æ˜¯å¦éœ€è¦æŸäº›æ”¶å…¥æ°´å¹³æˆ–é€€ä¼å†›äººèº«ä»½ï¼‰æ—¶ï¼Œå¯¹è¯å¼æœºå™¨é˜…è¯»ç³»ç»Ÿå¯å¸®åŠ©ç”¨æˆ·å›ç­”é«˜çº§é—®é¢˜ï¼ˆä¾‹å¦‚ï¼Œç¡®å®šä»–ä»¬æ˜¯å¦æœ‰èµ„æ ¼è·å¾—ç‰¹å®šçš„æ”¿åºœç¦åˆ©ï¼‰ã€‚å…³é”®çš„æŒ‘æˆ˜åœ¨äºï¼Œè¿™äº›è§„åˆ™ä»…ä»¥ç¨‹åºæ–‡æœ¬çš„å½¢å¼æä¾›ï¼ˆä¾‹å¦‚æ”¿åºœç½‘ç«™ä¸Šçš„æŒ‡å—ï¼‰ï¼Œç³»ç»Ÿå¿…é¡»é˜…è¯»è¿™äº›æ–‡æœ¬æ‰èƒ½å¼„æ¸…æ¥šè¦é—®ç”¨æˆ·ä»€ä¹ˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¯¹è¯æœºå™¨é˜…è¯»æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä»ç¨‹åºæ–‡æœ¬ä¸­è”åˆæå–ä¸€ç»„å†³ç­–è§„åˆ™ï¼ŒåŒæ—¶æ¨ç†å¯¹è¯å†å²æ‰€åŒ…å«çš„å“ªäº›è§„åˆ™ä»¥åŠå“ªäº›ä»éœ€è¦ç¼–è¾‘ä»¥ä¸ºç”¨æˆ·åˆ›å»ºé—®é¢˜ã€‚åœ¨æœ€è¿‘æ¨å‡ºçš„ ShARC å¯¹è¯å¼æœºå™¨é˜…è¯»æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„ Entailment-driven æå–å’Œç¼–è¾‘ç½‘ç»œ (E3) å®ç°äº†æ–°çš„æœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œä¼˜äºç°æœ‰ç³»ç»Ÿä»¥åŠæ–°çš„åŸºäº BERT çš„åŸºçº¿ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ˜ç¡®çªå‡ºæ˜¾ç¤ºå“ªäº›ä¿¡æ¯ä»éœ€è¦æ”¶é›†ï¼ŒE3 ä¸ºä¹‹å‰çš„å·¥ä½œæä¾›äº†ä¸€ä¸ªæ›´æ˜“äºè§£é‡Šçš„æ›¿ä»£æ–¹æ¡ˆã€‚æˆ‘ä»¬åœ¨ <a href="https://github.com/vzhong/e3">https://github.com/vzhong/e3</a> ä¸Šå‘å¸ƒäº†æˆ‘ä»¬çš„æ¨¡å‹å’Œå®éªŒçš„æºä»£ç ã€‚</td><td>Victor Zhong   Luke Zettlemoyer</td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.07004&#39;]">Improving Multi-turn Dialogue Modelling with Utterance ReWriter</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.07004">https://arxiv.org/pdf/1906.07004</a></td><td>Recent research has made impressive progress in single-turn dialogue modelling. In the multi-turn setting, however, current models are still far from satisfactory. One major challenge is the frequently occurred coreference and information omission in our daily conversation, making it hard for machines to understand the real intention. In this paper, we propose rewriting the human utterance as a pre-process to help multi-turn dialgoue modelling. Each utterance is first rewritten to recover all coreferred and omitted information. The next processing steps are then performed based on the rewritten utterance. To properly train the utterance rewriter, we collect a new dataset with human annotations and introduce a Transformer-based utterance rewriting architecture using the pointer network. We show the proposed architecture achieves remarkably good performance on the utterance rewriting task. The trained utterance rewriter can be easily integrated into online chatbots and brings general improvement over different domains.</td><td></td><td>Hui Su   Xiaoyu Shen   Rongzhi Zhang   Fei Sun   Pengwei Hu   Cheng Niu   Jie Zhou</td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.12866&#39;]">Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</a></td><td></td><td><a href="https://github.com/wenhuchen/HDSA-Dialog">https://github.com/wenhuchen/HDSA-Dialog</a></td><td><a href="https://arxiv.org/pdf/1905.12866">https://arxiv.org/pdf/1905.12866</a></td><td>Semantically controlled neural response generation on limited-domain has achieved great performance. However, moving towards multi-domain large-scale scenarios are shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the graph. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the large-scale Multi-Domain-WOZ dataset, our model can yield a significant improvement over the baselines on various automatic and human evaluation metrics.</td><td>åœ¨æœ‰é™åŸŸä¸Šè¯­ä¹‰æ§åˆ¶çš„ç¥ç»å“åº”ç”Ÿæˆå·²ç»å–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç”±äºè¯­ä¹‰è¾“å…¥çš„å¯èƒ½ç»„åˆéšç€åŸŸçš„æ•°é‡å‘ˆæŒ‡æ•°å¢é•¿ï¼Œå› æ­¤è½¬å‘å¤šåŸŸå¤§è§„æ¨¡åœºæ™¯æ˜¯å¾ˆå›°éš¾çš„ã€‚ä¸ºäº†ç¼“è§£è¿™ç§å¯æ‰©å±•æ€§é—®é¢˜ï¼Œæˆ‘ä»¬åˆ©ç”¨å¯¹è¯è¡Œä¸ºçš„ç»“æ„æ¥æ„å»ºå¤šå±‚åˆ†å±‚å›¾ï¼Œå…¶ä¸­æ¯ä¸ªè¡Œä¸ºåœ¨å›¾ä¸Šè¡¨ç¤ºä¸ºä»æ ¹åˆ°å¶çš„è·¯çº¿ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™ç§å…ˆéªŒå›¾ç»“æ„ä½œä¸ºå½’çº³åç½®æ¥æ„å»ºåˆ†å±‚è§£ç¼ ç»“çš„è‡ªæ³¨æ„åŠ›ç½‘ç»œï¼Œåœ¨å…¶ä¸­æˆ‘ä»¬è§£å¼€æ³¨æ„åŠ›å¤´ä»¥æ¨¡æ‹Ÿå¯¹è¯è¡Œä¸ºå›¾ä¸Šçš„æŒ‡å®šèŠ‚ç‚¹ã€‚é€šè¿‡åœ¨æ¯ä¸€å±‚æ¿€æ´»ä¸åŒçš„ï¼ˆè§£å¼€çš„ï¼‰å¤´ï¼Œå¯ä»¥ç»„åˆåœ°å¯¹è®¸å¤šå¯¹è¯è¡Œä¸ºè¯­ä¹‰è¿›è¡Œå»ºæ¨¡ä»¥æ§åˆ¶ç¥ç»å“åº”çš„ç”Ÿæˆã€‚åœ¨å¤§è§„æ¨¡å¤šåŸŸ WOZ æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥åœ¨å„ç§è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°æŒ‡æ ‡çš„åŸºçº¿ä¸Šäº§ç”Ÿæ˜¾ç€æ”¹è¿›ã€‚</td><td>Wenhu Chen   Jianshu Chen   Pengda Qin   Xifeng Yan   William Yang Wang</td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.00326&#39;]">Observing Dialogue in Therapy: Categorizing and Forecasting Behavioral Codes</a></td><td></td><td><a href="https://github.com/utahnlp/therapist-observer">https://github.com/utahnlp/therapist-observer</a></td><td><a href="https://arxiv.org/pdf/1907.00326">https://arxiv.org/pdf/1907.00326</a></td><td>Automatically analyzing dialogue can help understand and guide behavior in domains such as counseling, where interactions are largely mediated by conversation. In this paper, we study modeling behavioral codes used to asses a psychotherapy treatment style called Motivational Interviewing (MI), which is effective for addressing substance abuse and related problems. Specifically, we address the problem of providing real-time guidance to therapists with a dialogue observer that (1) categorizes therapist and client MI behavioral codes and, (2) forecasts codes for upcoming utterances to help guide the conversation and potentially alert the therapist. For both tasks, we define neural network models that build upon recent successes in dialogue modeling. Our experiments demonstrate that our models can outperform several baselines for both tasks. We also report the results of a careful analysis that reveals the impact of the various network design tradeoffs for modeling therapy dialogue.</td><td>è‡ªåŠ¨åˆ†æå¯¹è¯å¯ä»¥å¸®åŠ©ç†è§£å’ŒæŒ‡å¯¼å’¨è¯¢ç­‰é¢†åŸŸçš„è¡Œä¸ºï¼Œåœ¨è¿™äº›é¢†åŸŸï¼Œäº’åŠ¨ä¸»è¦é€šè¿‡å¯¹è¯è¿›è¡Œã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ç”¨äºè¯„ä¼°ç§°ä¸ºåŠ¨æœºè®¿è°ˆ (MI) çš„å¿ƒç†æ²»ç–—æ²»ç–—æ–¹å¼çš„è¡Œä¸ºä»£ç å»ºæ¨¡ï¼Œè¯¥æ–¹å¼å¯æœ‰æ•ˆè§£å†³è¯ç‰©æ»¥ç”¨å’Œç›¸å…³é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è§£å†³äº†é€šè¿‡å¯¹è¯è§‚å¯Ÿå‘˜å‘æ²»ç–—å¸ˆæä¾›å®æ—¶æŒ‡å¯¼çš„é—®é¢˜ï¼Œè¯¥å¯¹è¯è§‚å¯Ÿå‘˜ (1) å¯¹æ²»ç–—å¸ˆå’Œå®¢æˆ· MI è¡Œä¸ºä»£ç è¿›è¡Œåˆ†ç±»ï¼Œä»¥åŠ (2) é¢„æµ‹å³å°†å‡ºç°çš„è¯è¯­çš„ä»£ç ï¼Œä»¥å¸®åŠ©æŒ‡å¯¼å¯¹è¯å¹¶å¯èƒ½æé†’æ²»ç–—å¸ˆã€‚å¯¹äºè¿™ä¸¤ä¸ªä»»åŠ¡ï¼Œæˆ‘ä»¬å®šä¹‰äº†å»ºç«‹åœ¨å¯¹è¯å»ºæ¨¡æœ€è¿‘æˆåŠŸåŸºç¡€ä¸Šçš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨è¿™ä¸¤ä¸ªä»»åŠ¡ä¸Šéƒ½å¯ä»¥èƒœè¿‡å‡ ä¸ªåŸºçº¿ã€‚æˆ‘ä»¬è¿˜æŠ¥å‘Šäº†ä»”ç»†åˆ†æçš„ç»“æœï¼Œæ­ç¤ºäº†å„ç§ç½‘ç»œè®¾è®¡æƒè¡¡å¯¹å»ºæ¨¡æ²»ç–—å¯¹è¯çš„å½±å“ã€‚</td><td>Jie Cao   Michael Tanana   Zac E. Imel   Eric Poitras   David C. Atkins   Vivek Srikumar</td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.01166&#39;]">Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems</a></td><td></td><td><a href="https://github.com/henryhungle/MTN">https://github.com/henryhungle/MTN</a></td><td><a href="https://arxiv.org/pdf/1907.01166">https://arxiv.org/pdf/1907.01166</a></td><td>Developing Video-Grounded Dialogue Systems (VGDS), where a dialogue is conducted based on visual and audio aspects of a given video, is significantly more challenging than traditional image or text-grounded dialogue systems because (1) feature space of videos span across multiple picture frames, making it difficult to obtain semantic information; and (2) a dialogue agent must perceive and process information from different modalities (audio, video, caption, etc.) to obtain a comprehensive understanding. Most existing work is based on RNNs and sequence-to-sequence architectures, which are not very effective for capturing complex long-term dependencies (like in videos). To overcome this, we propose Multimodal Transformer Networks (MTN) to encode videos and incorporate information from different modalities. We also propose query-aware attention through an auto-encoder to extract query-aware features from non-text modalities. We develop a training procedure to simulate token-level decoding to improve the quality of generated responses during inference. We get state of the art performance on Dialogue System Technology Challenge 7 (DSTC7). Our model also generalizes to another multimodal visual-grounded dialogue task, and obtains promising performance. We implemented our models using PyTorch and the code is released at <a href="https://github.com/henryhungle/MTN">https://github.com/henryhungle/MTN</a>.</td><td>å¼€å‘åŸºäºè§†é¢‘çš„å¯¹è¯ç³»ç»Ÿ (VGDS)ï¼Œå…¶ä¸­åŸºäºç»™å®šè§†é¢‘çš„è§†è§‰å’ŒéŸ³é¢‘æ–¹é¢è¿›è¡Œå¯¹è¯ï¼Œæ¯”ä¼ ç»Ÿçš„å›¾åƒæˆ–æ–‡æœ¬å¯¹è¯ç³»ç»Ÿæ›´å…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸º (1) è§†é¢‘çš„ç‰¹å¾ç©ºé—´è·¨è¶Šå¤šä¸ªå›¾ç‰‡æ¡†ï¼Œè¯­ä¹‰ä¿¡æ¯è·å–å›°éš¾ï¼› (2) å¯¹è¯ä»£ç†å¿…é¡»æ„ŸçŸ¥å’Œå¤„ç†æ¥è‡ªä¸åŒå½¢å¼ï¼ˆéŸ³é¢‘ã€è§†é¢‘ã€å­—å¹•ç­‰ï¼‰çš„ä¿¡æ¯ï¼Œä»¥è·å¾—å…¨é¢çš„ç†è§£ã€‚å¤§å¤šæ•°ç°æœ‰å·¥ä½œåŸºäº RNN å’Œåºåˆ—åˆ°åºåˆ—æ¶æ„ï¼Œè¿™å¯¹äºæ•è·å¤æ‚çš„é•¿æœŸä¾èµ–å…³ç³»ï¼ˆå¦‚è§†é¢‘ï¼‰ä¸æ˜¯å¾ˆæœ‰æ•ˆã€‚ä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šæ¨¡æ€å˜å‹å™¨ç½‘ç»œ (MTN) æ¥ç¼–ç è§†é¢‘å¹¶åˆå¹¶æ¥è‡ªä¸åŒæ¨¡æ€çš„ä¿¡æ¯ã€‚æˆ‘ä»¬è¿˜é€šè¿‡è‡ªåŠ¨ç¼–ç å™¨æå‡ºäº†æŸ¥è¯¢æ„ŸçŸ¥æ³¨æ„åŠ›ï¼Œä»¥ä»éæ–‡æœ¬æ¨¡å¼ä¸­æå–æŸ¥è¯¢æ„ŸçŸ¥ç‰¹å¾ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªè®­ç»ƒç¨‹åºæ¥æ¨¡æ‹Ÿä»¤ç‰Œçº§è§£ç ï¼Œä»¥æé«˜æ¨ç†è¿‡ç¨‹ä¸­ç”Ÿæˆå“åº”çš„è´¨é‡ã€‚æˆ‘ä»¬åœ¨å¯¹è¯ç³»ç»ŸæŠ€æœ¯æŒ‘æˆ˜ 7 (DSTC7) ä¸Šè·å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ¨¡å‹è¿˜æ¨å¹¿åˆ°å¦ä¸€ä¸ªå¤šæ¨¡æ€åŸºäºè§†è§‰çš„å¯¹è¯ä»»åŠ¡ï¼Œå¹¶è·å¾—äº†æœ‰å¸Œæœ›çš„æ€§èƒ½ã€‚æˆ‘ä»¬ä½¿ç”¨ PyTorch å®ç°äº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œä»£ç å‘å¸ƒåœ¨ <a href="https://github.com/henryhungle/MTNã€‚">https://github.com/henryhungle/MTNã€‚</a></td><td>Hung Le   Doyen Sahoo   Nancy F. Chen   Steven C. H. Hoi</td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.06725&#39;]">Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good</a></td><td></td><td><a href="https://gitlab.com/ucdavisnlp/persuasionforgood">https://gitlab.com/ucdavisnlp/persuasionforgood</a></td><td><a href="https://arxiv.org/pdf/1906.06725">https://arxiv.org/pdf/1906.06725</a></td><td>Developing intelligent persuasive conversational agents to change peopleâ€™s opinions and actions for social good is the frontier in advancing the ethical development of automated dialogue systems. To do so, the first step is to understand the intricate organization of strategic disclosures and appeals employed in human persuasion conversations. We designed an online persuasion task where one participant was asked to persuade the other to donate to a specific charity. We collected a large dataset with 1,017 dialogues and annotated emerging persuasion strategies from a subset. Based on the annotation, we built a baseline classifier with context information and sentence-level features to predict the 10 persuasion strategies used in the corpus. Furthermore, to develop an understanding of personalized persuasion processes, we analyzed the relationships between individualsâ€™ demographic and psychological backgrounds including personality, morality, value systems, and their willingness for donation. Then, we analyzed which types of persuasion strategies led to a greater amount of donation depending on the individualsâ€™ personal backgrounds. This work lays the ground for developing a personalized persuasive dialogue system.</td><td>å¼€å‘æ™ºèƒ½çš„æœ‰è¯´æœåŠ›çš„å¯¹è¯ä»£ç†æ¥æ”¹å˜äººä»¬çš„æ„è§å’Œè¡Œä¸ºä»¥ä¿ƒè¿›ç¤¾ä¼šåˆ©ç›Šæ˜¯æ¨è¿›è‡ªåŠ¨å¯¹è¯ç³»ç»Ÿä¼¦ç†å‘å±•çš„å‰æ²¿ã€‚ä¸ºæ­¤ï¼Œç¬¬ä¸€æ­¥æ˜¯äº†è§£äººç±»è¯´æœå¯¹è¯ä¸­é‡‡ç”¨çš„æˆ˜ç•¥æŠ«éœ²å’Œå‘¼åçš„å¤æ‚ç»„ç»‡ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€é¡¹åœ¨çº¿è¯´æœä»»åŠ¡ï¼Œè¦æ±‚ä¸€åå‚ä¸è€…è¯´æœå¦ä¸€åå‚ä¸è€…å‘ç‰¹å®šæ…ˆå–„æœºæ„ææ¬¾ã€‚æˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªåŒ…å« 1,017 ä¸ªå¯¹è¯çš„å¤§å‹æ•°æ®é›†ï¼Œå¹¶ä»ä¸€ä¸ªå­é›†ä¸­æ³¨é‡Šäº†æ–°å…´çš„è¯´æœç­–ç•¥ã€‚åŸºäºæ³¨é‡Šï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå…·æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œå¥å­çº§ç‰¹å¾çš„åŸºçº¿åˆ†ç±»å™¨ï¼Œä»¥é¢„æµ‹è¯­æ–™åº“ä¸­ä½¿ç”¨çš„ 10 ç§è¯´æœç­–ç•¥ã€‚æ­¤å¤–ï¼Œä¸ºäº†äº†è§£ä¸ªæ€§åŒ–è¯´æœè¿‡ç¨‹ï¼Œæˆ‘ä»¬åˆ†æäº†ä¸ªäººçš„äººå£ç»Ÿè®¡å­¦å’Œå¿ƒç†èƒŒæ™¯ä¹‹é—´çš„å…³ç³»ï¼ŒåŒ…æ‹¬ä¸ªæ€§ã€é“å¾·ã€ä»·å€¼ä½“ç³»å’Œä»–ä»¬çš„æèµ æ„æ„¿ã€‚ç„¶åï¼Œæˆ‘ä»¬æ ¹æ®ä¸ªäººçš„ä¸ªäººèƒŒæ™¯åˆ†æäº†å“ªäº›ç±»å‹çš„è¯´æœç­–ç•¥ä¼šå¯¼è‡´æ›´å¤šçš„æèµ ã€‚è¿™é¡¹å·¥ä½œä¸ºå¼€å‘ä¸ªæ€§åŒ–çš„è¯´æœæ€§å¯¹è¯ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚</td><td>Xuewei Wang   Weiyan Shi   Richard Kim   Yoojung Oh   Sijia Yang   Jingwen Zhang   Zhou Yu</td></tr></tbody></table></div><h3 id="EMNLP-1"><a href="#EMNLP-1" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.09378&#39;]">Difference-aware Knowledge Selection for Knowledge-grounded Conversation Generation</a></td><td></td><td><a href="https://github.com/chujiezheng/DiffKS">https://github.com/chujiezheng/DiffKS</a></td><td><a href="https://arxiv.org/pdf/2009.09378">https://arxiv.org/pdf/2009.09378</a></td><td>In a multi-turn knowledge-grounded dialog, the difference between the knowledge selected at different turns usually provides potential clues to knowledge selection, which has been largely neglected in previous research. In this paper, we propose a difference-aware knowledge selection method. It first computes the difference between the candidate knowledge sentences provided at the current turn and those chosen in the previous turns. Then, the differential information is fused with or disentangled from the contextual information to facilitate final knowledge selection. Automatic, human observational, and interactive evaluation shows that our method is able to select knowledge more accurately and generate more informative responses, significantly outperforming the state-of-the-art baselines. The codes are available at <a href="https://github.com/chujiezheng/DiffKS">https://github.com/chujiezheng/DiffKS</a>.</td><td>åœ¨å¤šè½®åŸºäºçŸ¥è¯†çš„å¯¹è¯ä¸­ï¼Œä¸åŒè½®é€‰æ‹©çš„çŸ¥è¯†ä¹‹é—´çš„å·®å¼‚é€šå¸¸ä¸ºçŸ¥è¯†é€‰æ‹©æä¾›äº†æ½œåœ¨çš„çº¿ç´¢ï¼Œè€Œè¿™åœ¨ä»¥å‰çš„ç ”ç©¶ä¸­è¢«å¾ˆå¤§ç¨‹åº¦ä¸Šå¿½ç•¥äº†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å·®å¼‚æ„ŸçŸ¥çŸ¥è¯†é€‰æ‹©æ–¹æ³•ã€‚å®ƒé¦–å…ˆè®¡ç®—å½“å‰å›åˆæä¾›çš„å€™é€‰çŸ¥è¯†å¥å­ä¸å‰ä¸€å›åˆé€‰æ‹©çš„å€™é€‰çŸ¥è¯†å¥å­ä¹‹é—´çš„å·®å¼‚ã€‚ç„¶åï¼Œå·®å¼‚ä¿¡æ¯ä¸ä¸Šä¸‹æ–‡ä¿¡æ¯èåˆæˆ–åˆ†ç¦»ï¼Œä»¥ä¿ƒè¿›æœ€ç»ˆçš„çŸ¥è¯†é€‰æ‹©ã€‚è‡ªåŠ¨ã€äººå·¥è§‚å¯Ÿå’Œäº¤äº’å¼è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿæ›´å‡†ç¡®åœ°é€‰æ‹©çŸ¥è¯†å¹¶ç”Ÿæˆæ›´å¤šä¿¡æ¯å“åº”ï¼Œæ˜¾ç€ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿ã€‚ä»£ç å¯åœ¨ <a href="https://github.com/chujiezeng/DiffKS">https://github.com/chujiezeng/DiffKS</a> è·å¾—ã€‚</td><td>Chujie Zheng   Yunbo Cao   Daxin Jiang   Minlie Huang</td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12328&#39;]">Few-shot Natural Language Generation for Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/pengbaolin/SC-GPT">https://github.com/pengbaolin/SC-GPT</a></td><td><a href="https://arxiv.org/pdf/2002.12328">https://arxiv.org/pdf/2002.12328</a></td><td>As a crucial component in task-oriented dialog systems, the Natural Language Generation (NLG) module converts a dialog act represented in a semantic form into a response in natural language. The success of traditional template-based or statistical models typically relies on heavily annotated data, which is infeasible for new domains. Therefore, it is pivotal for an NLG system to generalize well with limited labelled data in real applications. To this end, we present FewShotWoz, the first NLG benchmark to simulate the few-shot learning setting in task-oriented dialog systems. Further, we develop the SC-GPT model. It is pre-trained on a large set of annotated NLG corpus to acquire the controllable generation ability, and fine-tuned with only a few domain-specific labels to adapt to new domains. Experiments on FewShotWoz and the large Multi-Domain-WOZ datasets show that the proposed SC-GPT significantly outperforms existing methods, measured by various automatic metrics and human evaluations.</td><td>ä½œä¸ºé¢å‘ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿä¸­çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œè‡ªç„¶è¯­è¨€ç”Ÿæˆ (NLG) æ¨¡å—å°†ä»¥è¯­ä¹‰å½¢å¼è¡¨ç¤ºçš„å¯¹è¯è¡Œä¸ºè½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€çš„å“åº”ã€‚ä¼ ç»Ÿçš„åŸºäºæ¨¡æ¿æˆ–ç»Ÿè®¡æ¨¡å‹çš„æˆåŠŸé€šå¸¸ä¾èµ–äºå¤§é‡æ³¨é‡Šçš„æ•°æ®ï¼Œè¿™å¯¹äºæ–°é¢†åŸŸæ˜¯ä¸å¯è¡Œçš„ã€‚å› æ­¤ï¼ŒNLG ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­åˆ©ç”¨æœ‰é™çš„æ ‡è®°æ•°æ®å¾ˆå¥½åœ°æ³›åŒ–æ˜¯è‡³å…³é‡è¦çš„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†FewShotWozï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåœ¨é¢å‘ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿä¸­æ¨¡æ‹Ÿå°æ ·æœ¬å­¦ä¹ è®¾ç½®çš„NLG åŸºå‡†æµ‹è¯•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº† SC-GPT æ¨¡å‹ã€‚å®ƒåœ¨å¤§é‡å¸¦æ³¨é‡Šçš„ NLG è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒä»¥è·å¾—å¯æ§ç”Ÿæˆèƒ½åŠ›ï¼Œå¹¶ä»…ä½¿ç”¨å°‘æ•°ç‰¹å®šé¢†åŸŸçš„æ ‡ç­¾è¿›è¡Œå¾®è°ƒä»¥é€‚åº”æ–°é¢†åŸŸã€‚åœ¨FewShotWoz å’Œå¤§å‹Multi-Domain-WOZ æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„SC-GPT æ˜¾ç€ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œé€šè¿‡å„ç§è‡ªåŠ¨æŒ‡æ ‡å’Œäººå·¥è¯„ä¼°æ¥è¡¡é‡ã€‚</td><td>Baolin Peng   Chenguang Zhu   Chunyuan Li   Xiujun Li   Jinchao Li   Michael Zeng   Jianfeng Gao</td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.13656&#39;]">Learning Knowledge Bases with Parameters for Task-Oriented Dialogue Systems</a></td><td></td><td><a href="https://github.com/HLTCHKUST/ke-dialogue">https://github.com/HLTCHKUST/ke-dialogue</a></td><td><a href="https://arxiv.org/pdf/2009.13656">https://arxiv.org/pdf/2009.13656</a></td><td>Task-oriented dialogue systems are either modularized with separate dialogue state tracking (DST) and management steps or end-to-end trainable. In either case, the knowledge base (KB) plays an essential role in fulfilling user requests. Modularized systems rely on DST to interact with the KB, which is expensive in terms of annotation and inference time. End-to-end systems use the KB directly as input, but they cannot scale when the KB is larger than a few hundred entries. In this paper, we propose a method to embed the KB, of any size, directly into the model parameters. The resulting model does not require any DST or template responses, nor the KB as input, and it can dynamically update its KB via fine-tuning. We evaluate our solution in five task-oriented dialogue datasets with small, medium, and large KB size. Our experiments show that end-to-end models can effectively embed knowledge bases in their parameters and achieve competitive performance in all evaluated datasets.</td><td>é¢å‘ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿè¦ä¹ˆé‡‡ç”¨å•ç‹¬çš„å¯¹è¯çŠ¶æ€è·Ÿè¸ª (DST) å’Œç®¡ç†æ­¥éª¤è¿›è¡Œæ¨¡å—åŒ–ï¼Œè¦ä¹ˆé‡‡ç”¨ç«¯åˆ°ç«¯å¯è®­ç»ƒã€‚æ— è®ºå“ªç§æƒ…å†µï¼ŒçŸ¥è¯†åº“ (KB) åœ¨æ»¡è¶³ç”¨æˆ·è¯·æ±‚æ–¹é¢éƒ½èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚æ¨¡å—åŒ–ç³»ç»Ÿä¾èµ– DST ä¸ KB äº¤äº’ï¼Œè¿™åœ¨æ³¨é‡Šå’Œæ¨ç†æ—¶é—´æ–¹é¢å¾ˆæ˜‚è´µã€‚ç«¯åˆ°ç«¯ç³»ç»Ÿç›´æ¥ä½¿ç”¨ KB ä½œä¸ºè¾“å…¥ï¼Œä½†å½“ KB å¤§äºå‡ ç™¾ä¸ªæ¡ç›®æ—¶ï¼Œå®ƒä»¬æ— æ³•æ‰©å±•ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å°†ä»»æ„å¤§å°çš„çŸ¥è¯†åº“ç›´æ¥åµŒå…¥æ¨¡å‹å‚æ•°çš„æ–¹æ³•ã€‚ç”Ÿæˆçš„æ¨¡å‹ä¸éœ€è¦ä»»ä½• DST æˆ–æ¨¡æ¿å“åº”ï¼Œä¹Ÿä¸éœ€è¦ KB ä½œä¸ºè¾“å…¥ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡å¾®è°ƒåŠ¨æ€æ›´æ–°å…¶ KBã€‚æˆ‘ä»¬åœ¨å…·æœ‰å°ã€ä¸­å’Œå¤§ KB å¤§å°çš„äº”ä¸ªé¢å‘ä»»åŠ¡çš„å¯¹è¯æ•°æ®é›†ä¸­è¯„ä¼°æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œç«¯åˆ°ç«¯æ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°å°†çŸ¥è¯†åº“åµŒå…¥å…¶å‚æ•°ä¸­ï¼Œå¹¶åœ¨æ‰€æœ‰è¯„ä¼°æ•°æ®é›†ä¸­å®ç°å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚</td><td>Andrea Madotto   Samuel Cahyawijaya   Genta Indra Winata   Yan Xu   Zihan Liu   Zhaojiang Lin   Pascale Fung</td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04344&#39;]">Plug-and-Play Conversational Models</a></td><td></td><td><a href="https://github.com/andreamad8/PPCM">https://github.com/andreamad8/PPCM</a></td><td><a href="https://arxiv.org/pdf/2010.04344">https://arxiv.org/pdf/2010.04344</a></td><td>There has been considerable progress made towards conversational models that generate coherent and fluent responses; however, this often involves training large language models on large dialogue datasets, such as Reddit. These large conversational models provide little control over the generated responses, and this control is further limited in the absence of annotated conversational datasets for attribute specific generation that can be used for fine-tuning the model. In this paper, we first propose and evaluate plug-and-play methods for controllable response generation, which does not require dialogue specific datasets and does not rely on fine-tuning a large model. While effective, the decoding procedure induces considerable computational overhead, rendering the conversational model unsuitable for interactive usage. To overcome this, we introduce an approach that does not require further computation at decoding time, while also does not require any fine-tuning of a large language model. We demonstrate, through extensive automatic and human evaluation, a high degree of control over the generated conversational responses with regard to multiple desired attributes, while being fluent.</td><td>åœ¨äº§ç”Ÿè¿è´¯å’Œæµç•…ååº”çš„å¯¹è¯æ¨¡å‹æ–¹é¢å–å¾—äº†ç›¸å½“å¤§çš„è¿›å±•ï¼›ç„¶è€Œï¼Œè¿™é€šå¸¸æ¶‰åŠåœ¨å¤§å‹å¯¹è¯æ•°æ®é›†ï¼ˆä¾‹å¦‚ Redditï¼‰ä¸Šè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¿™äº›å¤§å‹å¯¹è¯æ¨¡å‹å¯¹ç”Ÿæˆçš„å“åº”å‡ ä¹æ²¡æœ‰æ§åˆ¶ï¼Œå¹¶ä¸”è¿™ç§æ§åˆ¶åœ¨ç¼ºå°‘å¯ç”¨äºå¾®è°ƒæ¨¡å‹çš„ç‰¹å®šå±æ€§ç”Ÿæˆçš„å¸¦æ³¨é‡Šå¯¹è¯æ•°æ®é›†çš„æƒ…å†µä¸‹è¿›ä¸€æ­¥å—åˆ°é™åˆ¶ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºå¹¶è¯„ä¼°äº†ç”¨äºå¯æ§å“åº”ç”Ÿæˆçš„å³æ’å³ç”¨æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦å¯¹è¯ç‰¹å®šçš„æ•°æ®é›†ï¼Œä¹Ÿä¸ä¾èµ–äºå¯¹å¤§å‹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚è™½ç„¶æœ‰æ•ˆï¼Œä½†è§£ç è¿‡ç¨‹ä¼šå¼•èµ·ç›¸å½“å¤§çš„è®¡ç®—å¼€é”€ï¼Œä½¿ä¼šè¯æ¨¡å‹ä¸é€‚åˆäº¤äº’å¼ä½¿ç”¨ã€‚ä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åœ¨è§£ç æ—¶ä¸éœ€è¦è¿›ä¸€æ­¥è®¡ç®—çš„æ–¹æ³•ï¼ŒåŒæ—¶ä¹Ÿä¸éœ€è¦å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä»»ä½•å¾®è°ƒã€‚æˆ‘ä»¬é€šè¿‡å¹¿æ³›çš„è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°å±•ç¤ºäº†å¯¹ç”Ÿæˆçš„å…³äºå¤šä¸ªæ‰€éœ€å±æ€§çš„å¯¹è¯å“åº”çš„é«˜åº¦æ§åˆ¶ï¼ŒåŒæ—¶æµç•…ã€‚</td><td>Andrea Madotto   Etsuko Ishii   Zhaojiang Lin   Sumanth Dathathri   Pascale Fung</td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02795&#39;]">COSMIC: COmmonSense knowledge for eMotion Identification in Conversations</a></td><td></td><td><a href="https://github.com/declare-lab/conv-emotion">https://github.com/declare-lab/conv-emotion</a></td><td><a href="https://arxiv.org/pdf/2010.02795">https://arxiv.org/pdf/2010.02795</a></td><td>In this paper, we address the task of utterance level emotion recognition in conversations using commonsense knowledge. We propose COSMIC, a new framework that incorporates different elements of commonsense such as mental states, events, and causal relations, and build upon them to learn interactions between interlocutors participating in a conversation. Current state-of-the-art methods often encounter difficulties in context propagation, emotion shift detection, and differentiating between related emotion classes. By learning distinct commonsense representations, COSMIC addresses these challenges and achieves new state-of-the-art results for emotion recognition on four different benchmark conversational datasets. Our code is available at <a href="https://github.com/declare-lab/conv-emotion">https://github.com/declare-lab/conv-emotion</a>.</td><td>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å¸¸è¯†çŸ¥è¯†è§£å†³å¯¹è¯ä¸­è¯è¯­çº§æƒ…æ„Ÿè¯†åˆ«çš„ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºäº† COSMICï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°æ¡†æ¶ï¼Œå®ƒç»“åˆäº†ä¸åŒçš„å¸¸è¯†å…ƒç´ ï¼Œä¾‹å¦‚å¿ƒç†çŠ¶æ€ã€äº‹ä»¶å’Œå› æœå…³ç³»ï¼Œå¹¶ä»¥æ­¤ä¸ºåŸºç¡€æ¥å­¦ä¹ å‚ä¸å¯¹è¯çš„å¯¹è¯è€…ä¹‹é—´çš„äº’åŠ¨ã€‚å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•åœ¨ä¸Šä¸‹æ–‡ä¼ æ’­ã€æƒ…æ„Ÿè½¬ç§»æ£€æµ‹å’Œç›¸å…³æƒ…æ„Ÿç±»åˆ«ä¹‹é—´çš„åŒºåˆ†æ–¹é¢ç»å¸¸é‡åˆ°å›°éš¾ã€‚é€šè¿‡å­¦ä¹ ä¸åŒçš„å¸¸è¯†è¡¨ç¤ºï¼ŒCOSMIC è§£å†³äº†è¿™äº›æŒ‘æˆ˜ï¼Œå¹¶åœ¨å››ä¸ªä¸åŒçš„åŸºå‡†ä¼šè¯æ•°æ®é›†ä¸Šå®ç°äº†æƒ…æ„Ÿè¯†åˆ«çš„æœ€æ–°ç»“æœã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ <a href="https://github.com/declare-lab/conv-emotion">https://github.com/declare-lab/conv-emotion</a> è·å¾—ã€‚</td><td>Deepanway Ghosal   Navonil Majumder   Alexander Gelbukh   Rada Mihalcea   Soujanya Poria</td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.03755&#39;]">Generalizable and Explainable Dialogue Generation via Explicit Action Learning</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.03755">https://arxiv.org/pdf/2010.03755</a></td><td>Response generation for task-oriented dialogues implicitly optimizes two objectives at the same time: task completion and language quality. Conditioned response generation serves as an effective approach to separately and better optimize these two objectives. Such an approach relies on system action annotations which are expensive to obtain. To alleviate the need of action annotations, latent action learning is introduced to map each utterance to a latent representation. However, this approach is prone to over-dependence on the training data, and the generalization capability is thus restricted. To address this issue, we propose to learn natural language actions that represent utterances as a span of words. This explicit action representation promotes generalization via the compositional structure of language. It also enables an explainable generation process. Our proposed unsupervised approach learns a memory component to summarize system utterances into a short span of words. To further promote a compact action representation, we propose an auxiliary task that restores state annotations as the summarized dialogue context using the memory component. Our proposed approach outperforms latent action baselines on MultiWOZ, a benchmark multi-domain dataset.</td><td>é¢å‘ä»»åŠ¡çš„å¯¹è¯çš„å“åº”ç”ŸæˆåŒæ—¶éšå¼ä¼˜åŒ–äº†ä¸¤ä¸ªç›®æ ‡ï¼šä»»åŠ¡å®Œæˆå’Œè¯­è¨€è´¨é‡ã€‚æ¡ä»¶ååº”ç”Ÿæˆæ˜¯åˆ†åˆ«å’Œæ›´å¥½åœ°ä¼˜åŒ–è¿™ä¸¤ä¸ªç›®æ ‡çš„æœ‰æ•ˆæ–¹æ³•ã€‚è¿™ç§æ–¹æ³•ä¾èµ–äºè·å–æ˜‚è´µçš„ç³»ç»ŸåŠ¨ä½œæ³¨é‡Šã€‚ä¸ºäº†å‡è½»å¯¹åŠ¨ä½œæ³¨é‡Šçš„éœ€è¦ï¼Œå¼•å…¥äº†æ½œåœ¨åŠ¨ä½œå­¦ä¹ ä»¥å°†æ¯ä¸ªè¯è¯­æ˜ å°„åˆ°æ½œåœ¨è¡¨ç¤ºã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å®¹æ˜“è¿‡åº¦ä¾èµ–è®­ç»ƒæ•°æ®ï¼Œä»è€Œé™åˆ¶äº†æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å»ºè®®å­¦ä¹ å°†è¯è¯­è¡¨ç¤ºä¸ºå•è¯è·¨åº¦çš„è‡ªç„¶è¯­è¨€åŠ¨ä½œã€‚è¿™ç§æ˜¾å¼çš„åŠ¨ä½œè¡¨ç¤ºé€šè¿‡è¯­è¨€çš„ç»„åˆç»“æ„ä¿ƒè¿›äº†æ³›åŒ–ã€‚å®ƒè¿˜æ”¯æŒå¯è§£é‡Šçš„ç”Ÿæˆè¿‡ç¨‹ã€‚æˆ‘ä»¬æå‡ºçš„æ— ç›‘ç£æ–¹æ³•å­¦ä¹ äº†ä¸€ä¸ªè®°å¿†ç»„ä»¶ï¼Œå°†ç³»ç»Ÿçš„è¯è¯­æ¦‚æ‹¬ä¸ºä¸€ä¸ªçŸ­çš„å•è¯è·¨åº¦ã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¿ƒè¿›ç´§å‡‘çš„åŠ¨ä½œè¡¨ç¤ºï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè¾…åŠ©ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡ä½¿ç”¨è®°å¿†ç»„ä»¶å°†çŠ¶æ€æ³¨é‡Šæ¢å¤ä¸ºæ±‡æ€»çš„å¯¹è¯ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬æå‡ºçš„æ–¹æ³•ä¼˜äºåŸºå‡†å¤šåŸŸæ•°æ®é›† MultiWOZ ä¸Šçš„æ½œåœ¨åŠ¨ä½œåŸºçº¿ã€‚</td><td>Xinting Huang   Jianzhong Qi   Yu Sun   Rui Zhang</td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02260&#39;]">Effects of Naturalistic Variation in Goal-Oriented Dialog</a></td><td></td><td><a href="https://github.com/IBM/naturalistic-variation-goal-oriented-dialog-datasets">https://github.com/IBM/naturalistic-variation-goal-oriented-dialog-datasets</a></td><td><a href="https://arxiv.org/pdf/2010.02260">https://arxiv.org/pdf/2010.02260</a></td><td>Existing benchmarks used to evaluate the performance of end-to-end neural dialog systems lack a key component: natural variation present in human conversations. Most datasets are constructed through crowdsourcing, where the crowd workers follow a fixed template of instructions while enacting the role of a user/agent. This results in straight-forward, somewhat routine, and mostly trouble-free conversations, as crowd workers do not think to represent the full range of actions that occur naturally with real users. In this work, we investigate the impact of naturalistic variation on two goal-oriented datasets: bAbI dialog task and Stanford Multi-Domain Dataset (SMD). We also propose new and more effective testbeds for both datasets, by introducing naturalistic variation by the user. We observe that there is a significant drop in performance (more than 60% in Ent. F1 on SMD and 85% in per-dialog accuracy on bAbI task) of recent state-of-the-art end-to-end neural methods such as BossNet and GLMP on both datasets.</td><td>ç”¨äºè¯„ä¼°ç«¯åˆ°ç«¯ç¥ç»å¯¹è¯ç³»ç»Ÿæ€§èƒ½çš„ç°æœ‰åŸºå‡†ç¼ºä¹ä¸€ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šäººç±»å¯¹è¯ä¸­å­˜åœ¨çš„è‡ªç„¶å˜åŒ–ã€‚å¤§å¤šæ•°æ•°æ®é›†æ˜¯é€šè¿‡ä¼—åŒ…æ„å»ºçš„ï¼Œä¼—åŒ…å·¥ä½œäººå‘˜åœ¨æ‰®æ¼”ç”¨æˆ·/ä»£ç†è§’è‰²çš„åŒæ—¶éµå¾ªå›ºå®šçš„æŒ‡ä»¤æ¨¡æ¿ã€‚è¿™å¯¼è‡´äº†ç›´æ¥çš„ã€æœ‰ç‚¹å¸¸è§„çš„ã€å¹¶ä¸”å¤§éƒ¨åˆ†æ˜¯æ— æ•…éšœçš„å¯¹è¯ï¼Œå› ä¸ºäººç¾¤å·¥ä½œäººå‘˜å¹¶ä¸è®¤ä¸ºä»£è¡¨çœŸå®ç”¨æˆ·è‡ªç„¶å‘ç”Ÿçš„å…¨éƒ¨åŠ¨ä½œã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†è‡ªç„¶å˜åŒ–å¯¹ä¸¤ä¸ªé¢å‘ç›®æ ‡çš„æ•°æ®é›†çš„å½±å“ï¼šbAbI å¯¹è¯ä»»åŠ¡å’Œæ–¯å¦ç¦å¤šåŸŸæ•°æ®é›† (SMD)ã€‚æˆ‘ä»¬è¿˜é€šè¿‡å¼•å…¥ç”¨æˆ·çš„è‡ªç„¶å˜åŒ–ï¼Œä¸ºè¿™ä¸¤ä¸ªæ•°æ®é›†æå‡ºäº†æ–°çš„ã€æ›´æœ‰æ•ˆçš„æµ‹è¯•å¹³å°ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œæœ€è¿‘æœ€å…ˆè¿›çš„ç«¯åˆ°ç«¯ç¥ç»æ–¹æ³•çš„æ€§èƒ½æ˜¾ç€ä¸‹é™ï¼ˆSMD ä¸Šçš„ Ent.F1 è¶…è¿‡ 60%ï¼ŒbAbI ä»»åŠ¡çš„æ¯ä¸ªå¯¹è¯å‡†ç¡®åº¦ä¸‹é™äº† 85%ï¼‰ï¼Œä¾‹å¦‚ä½œä¸ºä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„ BossNet å’Œ GLMPã€‚</td><td>Jatin Ganhotra   Robert Moore   Sachindra Joshi   Kahini Wadhawan</td></tr><tr><td>8</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11540&#39;]">DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation</a></td><td></td><td><a href="https://github.com/SenticNet/conv-emotion">https://github.com/SenticNet/conv-emotion</a></td><td><a href="https://arxiv.org/pdf/1908.11540">https://arxiv.org/pdf/1908.11540</a></td><td>Emotion recognition in conversation (ERC) has received much attention, lately, from researchers due to its potential widespread applications in diverse areas, such as health-care, education, and human resources. In this paper, we present Dialogue Graph Convolutional Network (DialogueGCN), a graph neural network based approach to ERC. We leverage self and inter-speaker dependency of the interlocutors to model conversational context for emotion recognition. Through the graph network, DialogueGCN addresses context propagation issues present in the current RNN-based methods. We empirically show that this method alleviates such issues, while outperforming the current state of the art on a number of benchmark emotion classification datasets.</td><td></td><td>Deepanway Ghosal   Navonil Majumder   Soujanya Poria   Niyati Chhaya   Alexander Gelbukh</td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11546&#39;]">Modeling Multi-Action Policy for Task-Oriented Dialogues</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1908.11546">https://arxiv.org/pdf/1908.11546</a></td><td>Dialogue management (DM) plays a key role in the quality of the interaction with the user in a task-oriented dialogue system. In most existing approaches, the agent predicts only one DM policy action per turn. This significantly limits the expressive power of the conversational agent and introduces unwanted turns of interactions that may challenge usersâ€™ patience. Longer conversations also lead to more errors and the system needs to be more robust to handle them. In this paper, we compare the performance of several models on the task of predicting multiple acts for each turn. A novel policy model is proposed based on a recurrent cell called gated Continue-Act-Slots (gCAS) that overcomes the limitations of the existing models. Experimental results show that gCAS outperforms other approaches. The code is available at <a href="https://leishu02.github.io/">https://leishu02.github.io/</a></td><td>åœ¨é¢å‘ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿä¸­ï¼Œå¯¹è¯ç®¡ç† (DM) åœ¨ä¸ç”¨æˆ·äº¤äº’çš„è´¨é‡ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚åœ¨å¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¸­ï¼Œä»£ç†æ¯å›åˆä»…é¢„æµ‹ä¸€ä¸ª DM ç­–ç•¥æ“ä½œã€‚è¿™æ˜¾ç€é™åˆ¶äº†å¯¹è¯ä»£ç†çš„è¡¨è¾¾èƒ½åŠ›ï¼Œå¹¶å¼•å…¥äº†å¯èƒ½æŒ‘æˆ˜ç”¨æˆ·è€å¿ƒçš„ä¸å¿…è¦çš„äº¤äº’è½¬å˜ã€‚æ›´é•¿çš„å¯¹è¯ä¹Ÿä¼šå¯¼è‡´æ›´å¤šçš„é”™è¯¯ï¼Œç³»ç»Ÿéœ€è¦æ›´å¼ºå¤§æ¥å¤„ç†å®ƒä»¬ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†å‡ ç§æ¨¡å‹åœ¨é¢„æµ‹æ¯ä¸ªå›åˆçš„å¤šä¸ªåŠ¨ä½œçš„ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚åŸºäºç§°ä¸ºé—¨æ§Continue-Act-Slotsï¼ˆgCASï¼‰çš„å¾ªç¯å•å…ƒæå‡ºäº†ä¸€ç§æ–°é¢–çš„ç­–ç•¥æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…‹æœäº†ç°æœ‰æ¨¡å‹çš„å±€é™æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒgCAS ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚ä»£ç å¯åœ¨ <a href="https://leishu02.github.io/">https://leishu02.github.io/</a> è·å¾—</td><td>Lei Shu   Hu Xu   Bing Liu   Piero Molino</td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.12868&#39;]">Automatically Learning Data Augmentation Policies for Dialogue Tasks</a></td><td></td><td><a href="https://github.com/WolfNiu/AutoAugDialogue">https://github.com/WolfNiu/AutoAugDialogue</a></td><td><a href="https://arxiv.org/pdf/1909.12868">https://arxiv.org/pdf/1909.12868</a></td><td>Automatic data augmentation (AutoAugment) (Cubuk et al., 2019) searches for optimal perturbation policies via a controller trained using performance rewards of a sampled policy on the target task, hence reducing data-level model bias. While being a powerful algorithm, their work has focused on computer vision tasks, where it is comparatively easy to apply imperceptible perturbations without changing an imageâ€™s semantic meaning. In our work, we adapt AutoAugment to automatically discover effective perturbation policies for natural language processing (NLP) tasks such as dialogue generation. We start with a pool of atomic operations that apply subtle semantic-preserving perturbations to the source inputs of a dialogue task (e.g., different POS-tag types of stopword dropout, grammatical errors, and paraphrasing). Next, we allow the controller to learn more complex augmentation policies by searching over the space of the various combinations of these atomic operations. Moreover, we also explore conditioning the controller on the source inputs of the target task, since certain strategies may not apply to inputs that do not contain that strategyâ€™s required linguistic features. Empirically, we demonstrate that both our input-agnostic and input-aware controllers discover useful data augmentation policies, and achieve significant improvements over the previous state-of-the-art, including trained on manually-designed policies.</td><td>è‡ªåŠ¨æ•°æ®å¢å¼º (AutoAugment) (Cubuk et al., 2019) é€šè¿‡ä½¿ç”¨ç›®æ ‡ä»»åŠ¡é‡‡æ ·ç­–ç•¥çš„æ€§èƒ½å¥–åŠ±è®­ç»ƒçš„æ§åˆ¶å™¨æœç´¢æœ€ä½³æ‰°åŠ¨ç­–ç•¥ï¼Œä»è€Œå‡å°‘æ•°æ®çº§æ¨¡å‹åå·®ã€‚è™½ç„¶æ˜¯ä¸€ç§å¼ºå¤§çš„ç®—æ³•ï¼Œä½†ä»–ä»¬çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸Šï¼Œåœ¨ä¸æ”¹å˜å›¾åƒè¯­ä¹‰çš„æƒ…å†µä¸‹åº”ç”¨ä¸æ˜“å¯Ÿè§‰çš„æ‰°åŠ¨ç›¸å¯¹å®¹æ˜“ã€‚åœ¨æˆ‘ä»¬çš„å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨ AutoAugment è‡ªåŠ¨å‘ç°è‡ªç„¶è¯­è¨€å¤„ç† (NLP) ä»»åŠ¡ï¼ˆå¦‚å¯¹è¯ç”Ÿæˆï¼‰çš„æœ‰æ•ˆæ‰°åŠ¨ç­–ç•¥ã€‚æˆ‘ä»¬ä»ä¸€ç»„åŸå­æ“ä½œå¼€å§‹ï¼Œè¿™äº›æ“ä½œå°†å¾®å¦™çš„è¯­ä¹‰ä¿ç•™æ‰°åŠ¨åº”ç”¨äºå¯¹è¯ä»»åŠ¡çš„æºè¾“å…¥ï¼ˆä¾‹å¦‚ï¼Œä¸åŒçš„ POS æ ‡ç­¾ç±»å‹çš„åœç”¨è¯ä¸¢å¤±ã€è¯­æ³•é”™è¯¯å’Œé‡Šä¹‰ï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å…è®¸æ§åˆ¶å™¨é€šè¿‡æœç´¢è¿™äº›åŸå­æ“ä½œçš„å„ç§ç»„åˆçš„ç©ºé—´æ¥å­¦ä¹ æ›´å¤æ‚çš„å¢å¼ºç­–ç•¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢ç´¢åœ¨ç›®æ ‡ä»»åŠ¡çš„æºè¾“å…¥ä¸Šè°ƒèŠ‚æ§åˆ¶å™¨ï¼Œå› ä¸ºæŸäº›ç­–ç•¥å¯èƒ½ä¸é€‚ç”¨äºä¸åŒ…å«è¯¥ç­–ç•¥æ‰€éœ€è¯­è¨€ç‰¹å¾çš„è¾“å…¥ã€‚ä»ç»éªŒä¸Šè®²ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„è¾“å…¥ä¸å¯çŸ¥å’Œè¾“å…¥æ„ŸçŸ¥æ§åˆ¶å™¨éƒ½å‘ç°äº†æœ‰ç”¨çš„æ•°æ®å¢å¼ºç­–ç•¥ï¼Œå¹¶ä¸”æ¯”ä»¥å‰çš„æœ€å…ˆè¿›æŠ€æœ¯å–å¾—äº†æ˜¾ç€çš„æ”¹è¿›ï¼ŒåŒ…æ‹¬å¯¹æ‰‹åŠ¨è®¾è®¡çš„ç­–ç•¥è¿›è¡Œè®­ç»ƒã€‚</td><td>Tong Niu   Mohit Bansal</td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.03317&#39;]">Dependency Parsing for Spoken Dialog Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.03317">https://arxiv.org/pdf/1909.03317</a></td><td>Dependency parsing of conversational input can play an important role in language understanding for dialog systems by identifying the relationships between entities extracted from user utterances. Additionally, effective dependency parsing can elucidate differences in language structure and usage for discourse analysis of human-human versus human-machine dialogs. However, models trained on datasets based on news articles and web data do not perform well on spoken human-machine dialog, and currently available annotation schemes do not adapt well to dialog data. Therefore, we propose the Spoken Conversation Universal Dependencies (SCUD) annotation scheme that extends the Universal Dependencies (UD) (Nivre et al., 2016) guidelines to spoken human-machine dialogs. We also provide ConvBank, a conversation dataset between humans and an open-domain conversational dialog system with SCUD annotation. Finally, to demonstrate the utility of the dataset, we train a dependency parser on the ConvBank dataset. We demonstrate that by pre-training a dependency parser on a set of larger public datasets and fine-tuning on ConvBank data, we achieved the best result, 85.05% unlabeled and 77.82% labeled attachment accuracy.</td><td></td><td>Sam Davidson   Dian Yu   Zhou Yu</td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.05391&#39;]">Towards Knowledge-Based Recommender Dialog System</a></td><td></td><td><a href="https://github.com/THUDM/KBRD">https://github.com/THUDM/KBRD</a></td><td><a href="https://arxiv.org/pdf/1908.05391">https://arxiv.org/pdf/1908.05391</a></td><td>In this paper, we propose a novel end-to-end framework called KBRD, which stands for Knowledge-Based Recommender Dialog System. It integrates the recommender system and the dialog generation system. The dialog system can enhance the performance of the recommendation system by introducing knowledge-grounded information about usersâ€™ preferences, and the recommender system can improve that of the dialog generation system by providing recommendation-aware vocabulary bias. Experimental results demonstrate that our proposed model has significant advantages over the baselines in both the evaluation of dialog generation and recommendation. A series of analyses show that the two systems can bring mutual benefits to each other, and the introduced knowledge contributes to both their performances.</td><td>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸º KBRD çš„æ–°å‹ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œå®ƒä»£è¡¨åŸºäºçŸ¥è¯†çš„æ¨èå¯¹è¯ç³»ç»Ÿã€‚å®ƒé›†æˆäº†æ¨èç³»ç»Ÿå’Œå¯¹è¯ç”Ÿæˆç³»ç»Ÿã€‚å¯¹è¯ç³»ç»Ÿå¯ä»¥é€šè¿‡å¼•å…¥å…³äºç”¨æˆ·åå¥½çš„åŸºäºçŸ¥è¯†çš„ä¿¡æ¯æ¥æé«˜æ¨èç³»ç»Ÿçš„æ€§èƒ½ï¼Œæ¨èç³»ç»Ÿå¯ä»¥é€šè¿‡æä¾›æ¨èæ„ŸçŸ¥è¯æ±‡åå·®æ¥æ”¹è¿›å¯¹è¯ç”Ÿæˆç³»ç»Ÿçš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ¨¡å‹åœ¨å¯¹è¯ç”Ÿæˆå’Œæ¨èçš„è¯„ä¼°æ–¹é¢å‡ä¼˜äºåŸºçº¿ã€‚ä¸€ç³»åˆ—åˆ†æè¡¨æ˜ï¼Œè¿™ä¸¤ä¸ªç³»ç»Ÿå¯ä»¥äº’æƒ äº’åˆ©ï¼Œæ‰€å¼•å…¥çš„çŸ¥è¯†å¯¹ä¸¤è€…çš„æ€§èƒ½éƒ½æœ‰è´¡çŒ®ã€‚</td><td>Qibin Chen   Junyang Lin   Yichang Zhang   Ming Ding   Yukuo Cen   Hongxia Yang   Jie Tang</td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.00610&#39;]">DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic Knowledge Graphs</a></td><td></td><td><a href="https://github.com/Pascalson/DyKGChat">https://github.com/Pascalson/DyKGChat</a></td><td><a href="https://arxiv.org/pdf/1910.00610">https://arxiv.org/pdf/1910.00610</a></td><td>Data-driven, knowledge-grounded neural conversation models are capable of generating more informative responses. However, these models have not yet demonstrated that they can zero-shot adapt to updated, unseen knowledge graphs. This paper proposes a new task about how to apply dynamic knowledge graphs in neural conversation model and presents a novel TV series conversation corpus (DyKgChat) for the task. Our new task and corpus aids in understanding the influence of dynamic knowledge graphs on responses generation. Also, we propose a preliminary model that selects an output from two networks at each time step: a sequence-to-sequence model (Seq2Seq) and a multi-hop reasoning model, in order to support dynamic knowledge graphs. To benchmark this new task and evaluate the capability of adaptation, we introduce several evaluation metrics and the experiments show that our proposed approach outperforms previous knowledge-grounded conversation models. The proposed corpus and model can motivate the future research directions.</td><td>æ•°æ®é©±åŠ¨ã€ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„ç¥ç»å¯¹è¯æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ›´å¤šä¿¡æ¯å“åº”ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å°šæœªè¯æ˜å®ƒä»¬å¯ä»¥é›¶æ ·æœ¬é€‚åº”æ›´æ–°çš„ã€çœ‹ä¸è§çš„çŸ¥è¯†å›¾ã€‚æœ¬æ–‡æå‡ºäº†æœ‰å…³å¦‚ä½•åœ¨ç¥ç»ä¼šè¯æ¨¡å‹å’Œä»»åŠ¡æå‡ºäº†ä¸€ç§æ–°çš„ç”µè§†è¿ç»­å‰§è°ˆè¯æ–‡é›†ï¼ˆDyKgChatï¼‰åº”ç”¨åŠ¨æ€çŸ¥è¯†å›¾æ–°ä»»åŠ¡ã€‚æˆ‘ä»¬çš„æ–°ä»»åŠ¡å’Œè¯­æ–™åº“æœ‰åŠ©äºç†è§£åŠ¨æ€çŸ¥è¯†å›¾å¯¹å“åº”ç”Ÿæˆçš„å½±å“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåˆæ­¥çš„æ¨¡å‹ï¼Œå…¶é€‰æ‹©ä»ä¸¤ä¸ªç½‘ç»œçš„è¾“å‡ºåœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ï¼šä¸€ä¸ªåºåˆ—åˆ°åºåˆ—æ¨¡å‹ï¼ˆSeq2Seqï¼‰å’Œå¤šè·³æ¨ç†æ¨¡å‹ä¸­ï¼Œä¸ºäº†æ”¯æŒåŠ¨æ€çŸ¥è¯†çš„æ›²çº¿å›¾ã€‚ä¸ºäº†å¯¹è¿™é¡¹æ–°ä»»åŠ¡è¿›è¡ŒåŸºå‡†æµ‹è¯•å¹¶è¯„ä¼°é€‚åº”èƒ½åŠ›ï¼Œæˆ‘ä»¬å¼•å…¥äº†å‡ ä¸ªè¯„ä¼°æŒ‡æ ‡ï¼Œå®éªŒè¡¨æ˜æˆ‘ä»¬æå‡ºçš„æ–¹æ³•ä¼˜äºä»¥å‰çš„åŸºäºçŸ¥è¯†çš„å¯¹è¯æ¨¡å‹ã€‚æ‰€æå‡ºçš„è¯­æ–™åº“å’Œæ¨¡å‹å¯ä»¥æ¿€åŠ±æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚</td><td>Yi-Lin Tuan   Yun-Nung Chen   Hung-yi Lee</td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01388&#39;]">How to Build User Simulators to Train RL-based Dialog Systems</a></td><td></td><td><a href="https://github.com/wyshi/user-simulator">https://github.com/wyshi/user-simulator</a></td><td><a href="https://arxiv.org/pdf/1909.01388">https://arxiv.org/pdf/1909.01388</a></td><td>User simulators are essential for training reinforcement learning (RL) based dialog models. The performance of the simulator directly impacts the RL policy. However, building a good user simulator that models real user behaviors is challenging. We propose a method of standardizing user simulator building that can be used by the community to compare dialog system quality using the same set of user simulators fairly. We present implementations of six user simulators trained with different dialog planning and generation methods. We then calculate a set of automatic metrics to evaluate the quality of these simulators both directly and indirectly. We also ask human users to assess the simulators directly and indirectly by rating the simulated dialogs and interacting with the trained systems. This paper presents a comprehensive evaluation framework for user simulator study and provides a better understanding of the pros and cons of different user simulators, as well as their impacts on the trained systems.</td><td>ç”¨æˆ·æ¨¡æ‹Ÿå™¨å¯¹äºè®­ç»ƒåŸºäºå¼ºåŒ–å­¦ä¹  (RL) çš„å¯¹è¯æ¨¡å‹è‡³å…³é‡è¦ã€‚æ¨¡æ‹Ÿå™¨çš„æ€§èƒ½ç›´æ¥å½±å“ RL ç­–ç•¥ã€‚ç„¶è€Œï¼Œæ„å»ºä¸€ä¸ªå¥½çš„ç”¨æˆ·æ¨¡æ‹Ÿå™¨æ¥æ¨¡æ‹ŸçœŸå®çš„ç”¨æˆ·è¡Œä¸ºæ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ ‡å‡†åŒ–ç”¨æˆ·æ¨¡æ‹Ÿå™¨æ„å»ºçš„æ–¹æ³•ï¼Œç¤¾åŒºå¯ä»¥ä½¿ç”¨è¯¥æ–¹æ³•æ¥å…¬å¹³åœ°æ¯”è¾ƒä½¿ç”¨åŒä¸€ç»„ç”¨æˆ·æ¨¡æ‹Ÿå™¨çš„å¯¹è¯ç³»ç»Ÿè´¨é‡ã€‚æˆ‘ä»¬å±•ç¤ºäº†ä½¿ç”¨ä¸åŒå¯¹è¯è§„åˆ’å’Œç”Ÿæˆæ–¹æ³•è®­ç»ƒçš„å…­ä¸ªç”¨æˆ·æ¨¡æ‹Ÿå™¨çš„å®ç°ã€‚ç„¶åæˆ‘ä»¬è®¡ç®—ä¸€ç»„è‡ªåŠ¨æŒ‡æ ‡æ¥ç›´æ¥å’Œé—´æ¥è¯„ä¼°è¿™äº›æ¨¡æ‹Ÿå™¨çš„è´¨é‡ã€‚æˆ‘ä»¬è¿˜è¦æ±‚äººç±»ç”¨æˆ·é€šè¿‡å¯¹æ¨¡æ‹Ÿå¯¹è¯è¿›è¡Œè¯„çº§å¹¶ä¸è®­ç»ƒæœ‰ç´ çš„ç³»ç»Ÿäº¤äº’æ¥ç›´æ¥æˆ–é—´æ¥è¯„ä¼°æ¨¡æ‹Ÿå™¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºç”¨æˆ·æ¨¡æ‹Ÿå™¨ç ”ç©¶çš„ç»¼åˆè¯„ä¼°æ¡†æ¶ï¼Œå¹¶æ›´å¥½åœ°äº†è§£ä¸åŒç”¨æˆ·æ¨¡æ‹Ÿå™¨çš„ä¼˜ç¼ºç‚¹ï¼Œä»¥åŠå®ƒä»¬å¯¹è®­ç»ƒç³»ç»Ÿçš„å½±å“ã€‚</td><td>Weiyan Shi   Kun Qian   Xuewei Wang   Zhou Yu</td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09368&#39;]">Dual Attention Networks for Visual Reference Resolution in Visual Dialog</a></td><td></td><td><a href="https://github.com/gicheonkang/DAN-VisDial">https://github.com/gicheonkang/DAN-VisDial</a></td><td><a href="https://arxiv.org/pdf/1902.09368">https://arxiv.org/pdf/1902.09368</a></td><td>Visual dialog (VisDial) is a task which requires an AI agent to answer a series of questions grounded in an image. Unlike in visual question answering (VQA), the series of questions should be able to capture a temporal context from a dialog history and exploit visually-grounded information. A problem called visual reference resolution involves these challenges, requiring the agent to resolve ambiguous references in a given question and find the references in a given image. In this paper, we propose Dual Attention Networks (DAN) for visual reference resolution. DAN consists of two kinds of attention networks, REFER and FIND. Specifically, REFER module learns latent relationships between a given question and a dialog history by employing a self-attention mechanism. FIND module takes image features and reference-aware representations (i.e., the output of REFER module) as input, and performs visual grounding via bottom-up attention mechanism. We qualitatively and quantitatively evaluate our model on VisDial v1.0 and v0.9 datasets, showing that DAN outperforms the previous state-of-the-art model by a significant margin.</td><td>è§†è§‰å¯¹è¯ (VisDial) æ˜¯ä¸€é¡¹éœ€è¦ AI ä»£ç†å›ç­”åŸºäºå›¾åƒçš„ä¸€ç³»åˆ—é—®é¢˜çš„ä»»åŠ¡ã€‚ä¸è§†è§‰é—®ç­” (VQA) ä¸åŒï¼Œè¿™ä¸€ç³»åˆ—é—®é¢˜åº”è¯¥èƒ½å¤Ÿä»å¯¹è¯å†å²ä¸­æ•è·æ—¶é—´ä¸Šä¸‹æ–‡å¹¶åˆ©ç”¨åŸºäºè§†è§‰çš„ä¿¡æ¯ã€‚ç§°ä¸ºè§†è§‰å‚è€ƒè§£æçš„é—®é¢˜æ¶‰åŠè¿™äº›æŒ‘æˆ˜ï¼Œéœ€è¦ä»£ç†è§£å†³ç»™å®šé—®é¢˜ä¸­çš„æ¨¡ç³Šå‚è€ƒå¹¶åœ¨ç»™å®šå›¾åƒä¸­æ‰¾åˆ°å‚è€ƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºè§†è§‰å‚è€ƒåˆ†è¾¨ç‡çš„åŒæ³¨æ„åŠ›ç½‘ç»œï¼ˆDANï¼‰ã€‚ DAN ç”±ä¸¤ç§æ³¨æ„åŠ›ç½‘ç»œç»„æˆï¼ŒREFER å’Œ FINDã€‚å…·ä½“æ¥è¯´ï¼ŒREFER æ¨¡å—é€šè¿‡é‡‡ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¥å­¦ä¹ ç»™å®šé—®é¢˜å’Œå¯¹è¯å†å²ä¹‹é—´çš„æ½œåœ¨å…³ç³»ã€‚ FIND æ¨¡å—ä»¥å›¾åƒç‰¹å¾å’Œå‚è€ƒæ„ŸçŸ¥è¡¨ç¤ºï¼ˆå³ REFER æ¨¡å—çš„è¾“å‡ºï¼‰ä½œä¸ºè¾“å…¥ï¼Œå¹¶é€šè¿‡è‡ªä¸‹è€Œä¸Šçš„æ³¨æ„åŠ›æœºåˆ¶æ‰§è¡Œè§†è§‰æ¥åœ°ã€‚æˆ‘ä»¬åœ¨ VisDial v1.0 å’Œ v0.9 æ•°æ®é›†ä¸Šå®šæ€§å’Œå®šé‡åœ°è¯„ä¼°äº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œè¡¨æ˜ DAN çš„æ€§èƒ½æ˜æ˜¾ä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›æ¨¡å‹ã€‚</td><td>Gi-Cheon Kang   Jaeseo Lim   Byoung-Tak Zhang</td></tr><tr><td>16</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11487&#39;]">Dialog Intent Induction with Deep Multi-View Clustering</a></td><td></td><td><a href="https://github.com/asappresearch/dialog-intent-induction">https://github.com/asappresearch/dialog-intent-induction</a></td><td><a href="https://arxiv.org/pdf/1908.11487">https://arxiv.org/pdf/1908.11487</a></td><td>We introduce the dialog intent induction task and present a novel deep multi-view clustering approach to tackle the problem. Dialog intent induction aims at discovering user intents from user query utterances in human-human conversations such as dialogs between customer support agents and customers. Motivated by the intuition that a dialog intent is not only expressed in the user query utterance but also captured in the rest of the dialog, we split a conversation into two independent views and exploit multi-view clustering techniques for inducing the dialog intent. In particular, we propose alternating-view k-means (AV-KMEANS) for joint multi-view representation learning and clustering analysis. The key innovation is that the instance-view representations are updated iteratively by predicting the cluster assignment obtained from the alternative view, so that the multi-view representations of the instances lead to similar cluster assignments. Experiments on two public datasets show that AV-KMEANS can induce better dialog intent clusters than state-of-the-art unsupervised representation learning methods and standard multi-view clustering approaches.</td><td>æˆ‘ä»¬ä»‹ç»äº†å¯¹è¯æ„å›¾å½’çº³ä»»åŠ¡ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ·±åº¦å¤šè§†å›¾èšç±»æ–¹æ³•æ¥è§£å†³è¯¥é—®é¢˜ã€‚å¯¹è¯æ„å›¾å½’çº³æ—¨åœ¨ä»äººä¸äººå¯¹è¯ï¼ˆä¾‹å¦‚å®¢æˆ·æ”¯æŒä»£ç†å’Œå®¢æˆ·ä¹‹é—´çš„å¯¹è¯ï¼‰ä¸­çš„ç”¨æˆ·æŸ¥è¯¢è¯è¯­ä¸­å‘ç°ç”¨æˆ·æ„å›¾ã€‚å—å¯¹è¯æ„å›¾ä¸ä»…åœ¨ç”¨æˆ·æŸ¥è¯¢è¯è¯­ä¸­è¡¨è¾¾è€Œä¸”è¿˜åœ¨å¯¹è¯çš„å…¶ä½™éƒ¨åˆ†ä¸­è¡¨è¾¾çš„ç›´è§‰çš„å¯å‘ï¼Œæˆ‘ä»¬å°†å¯¹è¯åˆ†æˆä¸¤ä¸ªç‹¬ç«‹çš„è§†å›¾ï¼Œå¹¶åˆ©ç”¨å¤šè§†å›¾èšç±»æŠ€æœ¯æ¥è¯±å¯¼å¯¹è¯æ„å›¾ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬æå‡ºäº†äº¤æ›¿è§†å›¾ k-means (AV-KMEANS) ç”¨äºè”åˆå¤šè§†å›¾è¡¨ç¤ºå­¦ä¹ å’Œèšç±»åˆ†æã€‚å…³é”®åˆ›æ–°æ˜¯é€šè¿‡é¢„æµ‹ä»æ›¿ä»£è§†å›¾è·å¾—çš„é›†ç¾¤åˆ†é…æ¥è¿­ä»£æ›´æ–°å®ä¾‹è§†å›¾è¡¨ç¤ºï¼Œä»¥ä¾¿å®ä¾‹çš„å¤šè§†å›¾è¡¨ç¤ºå¯¼è‡´ç›¸ä¼¼çš„é›†ç¾¤åˆ†é…ã€‚åœ¨ä¸¤ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ— ç›‘ç£è¡¨ç¤ºå­¦ä¹ æ–¹æ³•å’Œæ ‡å‡†å¤šè§†å›¾èšç±»æ–¹æ³•ç›¸æ¯”ï¼ŒAV-KMEANS å¯ä»¥è¯±å¯¼æ›´å¥½çš„å¯¹è¯æ„å›¾èšç±»ã€‚</td><td>Hugh Perkins   Yi Yang</td></tr><tr><td>17</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.05069&#39;]">Multi-Task Learning for Conversational Question Answering over a Large-Scale Knowledge Base</a></td><td></td><td><a href="https://github.com/taoshen58/MaSP">https://github.com/taoshen58/MaSP</a></td><td><a href="https://arxiv.org/pdf/1910.05069">https://arxiv.org/pdf/1910.05069</a></td><td>We consider the problem of conversational question answering over a large-scale knowledge base. To handle huge entity vocabulary of a large-scale knowledge base, recent neural semantic parsing based approaches usually decompose the task into several subtasks and then solve them sequentially, which leads to following issues: 1) errors in earlier subtasks will be propagated and negatively affect downstream ones; and 2) each subtask cannot naturally share supervision signals with others. To tackle these issues, we propose an innovative multi-task learning framework where a pointer-equipped semantic parsing model is designed to resolve coreference in conversations, and naturally empower joint learning with a novel type-aware entity detection model. The proposed framework thus enables shared supervisions and alleviates the effect of error propagation. Experiments on a large-scale conversational question answering dataset containing 1.6M question answering pairs over 12.8M entities show that the proposed framework improves overall F1 score from 67% to 79% compared with previous state-of-the-art work.</td><td>æˆ‘ä»¬è€ƒè™‘åœ¨å¤§è§„æ¨¡çŸ¥è¯†åº“ä¸Šè¿›è¡Œå¯¹è¯å¼é—®ç­”çš„é—®é¢˜ã€‚ä¸ºäº†å¤„ç†å¤§è§„æ¨¡çŸ¥è¯†åº“çš„åºå¤§å®ä½“è¯æ±‡è¡¨ï¼Œæœ€è¿‘çš„åŸºäºç¥ç»è¯­ä¹‰è§£æçš„æ–¹æ³•é€šå¸¸å°†ä»»åŠ¡åˆ†è§£ä¸ºå‡ ä¸ªå­ä»»åŠ¡ï¼Œç„¶åä¾æ¬¡è§£å†³å®ƒä»¬ï¼Œè¿™å¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š1ï¼‰æ—©æœŸå­ä»»åŠ¡ä¸­çš„é”™è¯¯å°†è¢«ä¼ æ’­å¹¶äº§ç”Ÿè´Ÿé¢å½±å“ä¸‹æ¸¸çš„ï¼› 2ï¼‰æ¯ä¸ªå­ä»»åŠ¡ä¸èƒ½è‡ªç„¶åœ°ä¸å…¶ä»–äººå…±äº«ç›‘ç£ä¿¡å·ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ›æ–°çš„å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œå…¶ä¸­è®¾è®¡äº†ä¸€ä¸ªé…å¤‡æŒ‡é’ˆçš„è¯­ä¹‰è§£ææ¨¡å‹æ¥è§£å†³å¯¹è¯ä¸­çš„å…±æŒ‡é—®é¢˜ï¼Œå¹¶è‡ªç„¶åœ°é€šè¿‡ä¸€ç§æ–°é¢–çš„ç±»å‹æ„ŸçŸ¥å®ä½“æ£€æµ‹æ¨¡å‹æ¥æˆæƒè”åˆå­¦ä¹ ã€‚å› æ­¤ï¼Œæ‰€æå‡ºçš„æ¡†æ¶èƒ½å¤Ÿå®ç°å…±äº«ç›‘ç£å¹¶å‡è½»é”™è¯¯ä¼ æ’­çš„å½±å“ã€‚åœ¨åŒ…å«è¶…è¿‡ 1280 ä¸‡ä¸ªå®ä½“çš„ 160 ä¸‡ä¸ªé—®ç­”å¯¹çš„å¤§è§„æ¨¡ä¼šè¯é—®ç­”æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸ä¹‹å‰çš„æœ€å…ˆè¿›å·¥ä½œç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ¡†æ¶å°†æ•´ä½“ F1 åˆ†æ•°ä» 67% æé«˜åˆ° 79%ã€‚</td><td>Tao Shen   Xiubo Geng   Tao Qin   Daya Guo   Duyu Tang   Nan Duan   Guodong Long   Daxin Jiang</td></tr></tbody></table></div><h3 id="NAACL-1"><a href="#NAACL-1" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.04898&#39;]">Open-Domain Question Answering Goes Conversational via Question Rewriting</a></td><td></td><td><a href="https://github.com/apple/ml-qrecc">https://github.com/apple/ml-qrecc</a></td><td><a href="https://arxiv.org/pdf/2010.04898">https://arxiv.org/pdf/2010.04898</a></td><td>We introduce a new dataset for Question Rewriting in Conversational Context (QReCC), which contains 14K conversations with 80K question-answer pairs. The task in QReCC is to find answers to conversational questions within a collection of 10M web pages (split into 54M passages). Answers to questions in the same conversation may be distributed across several web pages. QReCC provides annotations that allow us to train and evaluate individual subtasks of question rewriting, passage retrieval and reading comprehension required for the end-to-end conversational question answering (QA) task. We report the effectiveness of a strong baseline approach that combines the state-of-the-art model for question rewriting, and competitive models for open-domain QA. Our results set the first baseline for the QReCC dataset with F1 of 19.10, compared to the human upper bound of 75.45, indicating the difficulty of the setup and a large room for improvement.</td><td></td><td>Raviteja Anantha   Svitlana Vakulenko   Zhucheng Tu   Shayne Longpre   Stephen Pulman   Srinivas Chappidi</td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.00783&#39;]">Action-Based Conversations Dataset: A Corpus for Building More In-Depth Task- Oriented Dialogue Systems</a></td><td></td><td><a href="https://github.com/asappresearch/abcd">https://github.com/asappresearch/abcd</a></td><td><a href="https://arxiv.org/pdf/2104.00783">https://arxiv.org/pdf/2104.00783</a></td><td>Existing goal-oriented dialogue datasets focus mainly on identifying slots and values. However, customer support interactions in reality often involve agents following multi-step procedures derived from explicitly-defined company policies as well. To study customer service dialogue systems in more realistic settings, we introduce the Action-Based Conversations Dataset (ABCD), a fully-labeled dataset with over 10K human-to-human dialogues containing 55 distinct user intents requiring unique sequences of actions constrained by policies to achieve task success. We propose two additional dialog tasks, Action State Tracking and Cascading Dialogue Success, and establish a series of baselines involving large-scale, pre-trained language models on this dataset. Empirical results demonstrate that while more sophisticated networks outperform simpler models, a considerable gap (50.8% absolute accuracy) still exists to reach human-level performance on ABCD.</td><td>ç°æœ‰çš„é¢å‘ç›®æ ‡çš„å¯¹è¯æ•°æ®é›†ä¸»è¦ä¾§é‡äºè¯†åˆ«æ§½å’Œå€¼ã€‚ç„¶è€Œï¼Œç°å®ä¸­çš„å®¢æˆ·æ”¯æŒäº¤äº’é€šå¸¸ä¹Ÿæ¶‰åŠä»£ç†éµå¾ªæºè‡ªæ˜ç¡®å®šä¹‰çš„å…¬å¸æ”¿ç­–çš„å¤šæ­¥éª¤ç¨‹åºã€‚ä¸ºäº†åœ¨æ›´ç°å®çš„ç¯å¢ƒä¸­ç ”ç©¶å®¢æˆ·æœåŠ¡å¯¹è¯ç³»ç»Ÿï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºåŠ¨ä½œçš„å¯¹è¯æ•°æ®é›† (ABCD)ï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œå…¨æ ‡è®°çš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«è¶…è¿‡ 10K äººä¸äººä¹‹é—´çš„å¯¹è¯ï¼Œå…¶ä¸­åŒ…å« 55 ä¸ªä¸åŒçš„ç”¨æˆ·æ„å›¾ï¼Œéœ€è¦å—ç­–ç•¥çº¦æŸçš„ç‹¬ç‰¹åŠ¨ä½œåºåˆ—ä»¥å®ç°ä»»åŠ¡æˆåŠŸã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ä¸ªé¢å¤–çš„å¯¹è¯ä»»åŠ¡ï¼ŒAction State Tracking å’Œ Cascading Dialogue Successï¼Œå¹¶åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šå»ºç«‹äº†ä¸€ç³»åˆ—æ¶‰åŠå¤§è§„æ¨¡ã€é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„åŸºçº¿ã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œè™½ç„¶æ›´å¤æ‚çš„ç½‘ç»œä¼˜äºæ›´ç®€å•çš„æ¨¡å‹ï¼Œä½†åœ¨ ABCD ä¸Šè¾¾åˆ°äººç±»æ°´å¹³çš„è¡¨ç°ä»ç„¶å­˜åœ¨ç›¸å½“å¤§çš„å·®è·ï¼ˆ50.8% çš„ç»å¯¹å‡†ç¡®ç‡ï¼‰ã€‚</td><td>Derek Chen   Howard Chen   Yi Yang   Alex Lin   Zhou Yu</td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.11230&#39;]">Self-Supervised Contrastive Learning for Efficient User Satisfaction Prediction in Conversational Agents</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.11230">https://arxiv.org/pdf/2010.11230</a></td><td>Turn-level user satisfaction is one of the most important performance metrics for conversational agents. It can be used to monitor the agentâ€™s performance and provide insights about defective user experiences. Moreover, a powerful satisfaction model can be used as an objective function that a conversational agent continuously optimizes for. While end-to-end deep learning has shown promising results, having access to a large number of reliable annotated samples required by these methods remains challenging. In a large-scale conversational system, there is a growing number of newly developed skills, making the traditional data collection, annotation, and modeling process impractical due to the required annotation costs as well as the turnaround times. In this paper, we suggest a self-supervised contrastive learning approach that leverages the pool of unlabeled data to learn user-agent interactions. We show that the pre-trained models using the self-supervised objective are transferable to the user satisfaction prediction. In addition, we propose a novel few-shot transfer learning approach that ensures better transferability for very small sample sizes. The suggested few-shot method does not require any inner loop optimization process and is scalable to very large datasets and complex models. Based on our experiments using real-world data from a large-scale commercial system, the suggested approach is able to significantly reduce the required number of annotations, while improving the generalization on unseen out-of-domain skills.</td><td>å›åˆçº§ç”¨æˆ·æ»¡æ„åº¦æ˜¯ä¼šè¯ä»£ç†æœ€é‡è¦çš„æ€§èƒ½æŒ‡æ ‡ä¹‹ä¸€ã€‚å®ƒå¯ç”¨äºç›‘æ§ä»£ç†çš„æ€§èƒ½å¹¶æä¾›æœ‰å…³æœ‰ç¼ºé™·çš„ç”¨æˆ·ä½“éªŒçš„è§è§£ã€‚æ­¤å¤–ï¼Œå¼ºå¤§çš„æ»¡æ„åº¦æ¨¡å‹å¯ä»¥ç”¨ä½œå¯¹è¯ä»£ç†ä¸æ–­ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°ã€‚è™½ç„¶ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ å·²æ˜¾ç¤ºå‡ºæœ‰å¸Œæœ›çš„ç»“æœï¼Œä½†è®¿é—®è¿™äº›æ–¹æ³•æ‰€éœ€çš„å¤§é‡å¯é çš„å¸¦æ³¨é‡Šçš„æ ·æœ¬ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨å¤§å‹å¯¹è¯ç³»ç»Ÿä¸­ï¼Œæ–°å¼€å‘çš„æŠ€èƒ½è¶Šæ¥è¶Šå¤šï¼Œç”±äºæ‰€éœ€çš„æ³¨é‡Šæˆæœ¬å’Œå‘¨è½¬æ—¶é—´ï¼Œä½¿å¾—ä¼ ç»Ÿçš„æ•°æ®æ”¶é›†ã€æ³¨é‡Šå’Œå»ºæ¨¡è¿‡ç¨‹å˜å¾—ä¸åˆ‡å®é™…ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªç›‘ç£å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æœªæ ‡è®°æ•°æ®æ± æ¥å­¦ä¹ ç”¨æˆ·-ä»£ç†äº¤äº’ã€‚æˆ‘ä»¬è¡¨æ˜ä½¿ç”¨è‡ªç›‘ç£ç›®æ ‡çš„é¢„è®­ç»ƒæ¨¡å‹å¯è½¬ç§»åˆ°ç”¨æˆ·æ»¡æ„åº¦é¢„æµ‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å°‘æ ·æœ¬è¿ç§»å­¦ä¹ æ–¹æ³•ï¼Œå¯ç¡®ä¿å¯¹éå¸¸å°çš„æ ·æœ¬é‡å…·æœ‰æ›´å¥½çš„è¿ç§»èƒ½åŠ›ã€‚å»ºè®®çš„å°æ ·æœ¬æ–¹æ³•ä¸éœ€è¦ä»»ä½•å†…å¾ªç¯ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¹¶ä¸”å¯æ‰©å±•åˆ°éå¸¸å¤§çš„æ•°æ®é›†å’Œå¤æ‚æ¨¡å‹ã€‚åŸºäºæˆ‘ä»¬ä½¿ç”¨æ¥è‡ªå¤§è§„æ¨¡å•†ä¸šç³»ç»Ÿçš„çœŸå®ä¸–ç•Œæ•°æ®çš„å®éªŒï¼Œæ‰€å»ºè®®çš„æ–¹æ³•èƒ½å¤Ÿæ˜¾ç€å‡å°‘æ‰€éœ€çš„æ³¨é‡Šæ•°é‡ï¼ŒåŒæ—¶æé«˜å¯¹çœ‹ä¸è§çš„åŸŸå¤–æŠ€èƒ½çš„æ³›åŒ–ã€‚</td><td>Mohammad Kachuee   Hao Yuan   Young-Bum Kim   Sungjin Lee</td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.07831&#39;]">Human-like informative conversations: Better acknowledgements using conditional mutual information</a></td><td></td><td><a href="https://github.com/AshwinParanjape/human-like-informative-conversations">https://github.com/AshwinParanjape/human-like-informative-conversations</a></td><td><a href="https://arxiv.org/pdf/2104.07831">https://arxiv.org/pdf/2104.07831</a></td><td>This work aims to build a dialogue agent that can weave new factual content into conversations as naturally as humans. We draw insights from linguistic principles of conversational analysis and annotate human-human conversations from the Switchboard Dialog Act Corpus to examine humans strategies for acknowledgement, transition, detail selection and presentation. When current chatbots (explicitly provided with new factual content) introduce facts into a conversation, their generated responses do not acknowledge the prior turns. This is because models trained with two contexts - new factual content and conversational history - generate responses that are non-specific w.r.t. one of the contexts, typically the conversational history. We show that specificity w.r.t. conversational history is better captured by Pointwise Conditional Mutual Information ($\text{pcmi}_h$) than by the established use of Pointwise Mutual Information ($\text{pmi}$). Our proposed method, Fused-PCMI, trades off $\text{pmi}$ for $\text{pcmi}_h$ and is preferred by humans for overall quality over the Max-PMI baseline 60% of the time. Human evaluators also judge responses with higher $\text{pcmi}_h$ better at acknowledgement 74% of the time. The results demonstrate that systems mimicking human conversational traits (in this case acknowledgement) improve overall quality and more broadly illustrate the utility of linguistic principles in improving dialogue agents.</td><td>è¿™é¡¹å·¥ä½œæ—¨åœ¨æ„å»ºä¸€ä¸ªå¯¹è¯ä»£ç†ï¼Œå¯ä»¥åƒäººç±»ä¸€æ ·è‡ªç„¶åœ°å°†æ–°çš„äº‹å®å†…å®¹ç¼–ç»‡åˆ°å¯¹è¯ä¸­ã€‚æˆ‘ä»¬ä»å¯¹è¯åˆ†æçš„è¯­è¨€åŸåˆ™ä¸­æ±²å–è§è§£ï¼Œå¹¶ä» Switchboard Dialog Act Corpus ä¸­æ³¨é‡Šäººä¸äººçš„å¯¹è¯ï¼Œä»¥æ£€æŸ¥äººç±»åœ¨ç¡®è®¤ã€è½¬æ¢ã€ç»†èŠ‚é€‰æ‹©å’Œå‘ˆç°æ–¹é¢çš„ç­–ç•¥ã€‚å½“å½“å‰çš„èŠå¤©æœºå™¨äººï¼ˆæ˜ç¡®æä¾›æ–°çš„äº‹å®å†…å®¹ï¼‰å°†äº‹å®å¼•å…¥å¯¹è¯æ—¶ï¼Œå®ƒä»¬ç”Ÿæˆçš„å“åº”ä¸ä¼šç¡®è®¤å…ˆå‰çš„è½¬å˜ã€‚è¿™æ˜¯å› ä¸ºåœ¨ä¸¤ä¸ªä¸Šä¸‹æ–‡ï¼ˆæ–°çš„äº‹å®å†…å®¹å’Œå¯¹è¯å†å²ï¼‰ä¸­è®­ç»ƒçš„æ¨¡å‹ä¼šç”Ÿæˆéç‰¹å®š w.r.t. çš„å“åº”ã€‚ä¸Šä¸‹æ–‡ä¹‹ä¸€ï¼Œé€šå¸¸æ˜¯å¯¹è¯å†å²ã€‚æˆ‘ä»¬å±•ç¤ºäº†è¿™ç§ç‰¹å¼‚æ€§ w.r.t. Pointwise Conditional Mutual Information ($\text{pcmi}_h$) æ¯”ä½¿ç”¨ Pointwise Mutual Information ($\text{pmi}$) æ›´å¥½åœ°æ•è·ä¼šè¯å†å²ã€‚æˆ‘ä»¬æå‡ºçš„æ–¹æ³•ï¼ŒFused-PCMIï¼Œç”¨ $\text{pmi}$ æ¢å– $\text{pcmi}_h$ï¼Œå¹¶ä¸”åœ¨ 60% çš„æ—¶é—´é‡Œï¼Œäººä»¬æ›´å–œæ¬¢åœ¨ Max-PMI åŸºçº¿ä¸Šçš„æ•´ä½“è´¨é‡ã€‚äººç±»è¯„ä¼°è€…åœ¨ 74% çš„æ—¶é—´é‡Œä¹Ÿèƒ½æ›´å¥½åœ°åˆ¤æ–­å…·æœ‰è¾ƒé«˜ $\text{pcmi}_h$ çš„å“åº”ã€‚ç»“æœè¡¨æ˜ï¼Œæ¨¡ä»¿äººç±»å¯¹è¯ç‰¹å¾ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯ç¡®è®¤ï¼‰çš„ç³»ç»Ÿæé«˜äº†æ•´ä½“è´¨é‡ï¼Œå¹¶æ›´å¹¿æ³›åœ°è¯´æ˜äº†è¯­è¨€åŸåˆ™åœ¨æ”¹è¿›å¯¹è¯ä»£ç†æ–¹é¢çš„æ•ˆç”¨ã€‚</td><td>Ashwin Paranjape   Christopher D. Manning</td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2102.02191&#39;]">DiSCoL: Toward Engaging Dialogue Systems through Conversational Line Guided Response Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2102.02191">https://arxiv.org/pdf/2102.02191</a></td><td>Having engaging and informative conversations with users is the utmost goal for open-domain conversational systems. Recent advances in transformer-based language models and their applications to dialogue systems have succeeded to generate fluent and human-like responses. However, they still lack control over the generation process towards producing contentful responses and achieving engaging conversations. To achieve this goal, we present \textbf{DiSCoL} (\textbf{Di}alogue \textbf{S}ystems through \textbf{Co}versational \textbf{L}ine guided response generation). DiSCoL is an open-domain dialogue system that leverages conversational lines (briefly \textbf{convlines}) as controllable and informative content-planning elements to guide the generation model produce engaging and informative responses. Two primary modules in DiSCoLâ€™s pipeline are conditional generators trained for 1) predicting relevant and informative convlines for dialogue contexts and 2) generating high-quality responses conditioned on the predicted convlines. Users can also change the returned convlines to \textit{control} the direction of the conversations towards topics that are more interesting for them. Through automatic and human evaluations, we demonstrate the efficiency of the convlines in producing engaging conversations.</td><td>ä¸ç”¨æˆ·è¿›è¡Œå¼•äººå…¥èƒœä¸”ä¿¡æ¯ä¸°å¯Œçš„å¯¹è¯æ˜¯å¼€æ”¾åŸŸå¯¹è¯ç³»ç»Ÿçš„æœ€å¤§ç›®æ ‡ã€‚åŸºäºè½¬æ¢å™¨çš„è¯­è¨€æ¨¡å‹åŠå…¶åœ¨å¯¹è¯ç³»ç»Ÿä¸­çš„åº”ç”¨çš„æœ€æ–°è¿›å±•å·²ç»æˆåŠŸåœ°äº§ç”Ÿäº†æµç•…å’Œç±»ä¼¼äººç±»çš„å“åº”ã€‚ç„¶è€Œï¼Œä»–ä»¬ä»ç„¶ç¼ºä¹å¯¹ç”Ÿæˆå†…å®¹çš„å“åº”å’Œå®ç°å¼•äººå…¥èƒœçš„å¯¹è¯çš„ç”Ÿæˆè¿‡ç¨‹çš„æ§åˆ¶ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬æå‡ºäº† \textbf{DiSCoL}ï¼ˆ\textbf{Di}alogue \textbf{S}ystems through \textbf{Co}versational \textbf{L}ine å¼•å¯¼å“åº”ç”Ÿæˆï¼‰ã€‚ DiSCoL æ˜¯ä¸€ä¸ªå¼€æ”¾åŸŸå¯¹è¯ç³»ç»Ÿï¼Œå®ƒåˆ©ç”¨å¯¹è¯çº¿ï¼ˆç®€ç§° \textbf{convlines}ï¼‰ä½œä¸ºå¯æ§å’Œä¿¡æ¯ä¸°å¯Œçš„å†…å®¹è§„åˆ’å…ƒç´ æ¥æŒ‡å¯¼ç”Ÿæˆæ¨¡å‹äº§ç”Ÿå¼•äººå…¥èƒœå’Œä¿¡æ¯ä¸°å¯Œçš„å“åº”ã€‚ DiSCoL ç®¡é“ä¸­çš„ä¸¤ä¸ªä¸»è¦æ¨¡å—æ˜¯æ¡ä»¶ç”Ÿæˆå™¨ï¼Œç”¨äº 1) é¢„æµ‹å¯¹è¯ä¸Šä¸‹æ–‡çš„ç›¸å…³å’Œä¿¡æ¯ä¸°å¯Œçš„ convlines å’Œ 2) ç”Ÿæˆä»¥é¢„æµ‹çš„ convlines ä¸ºæ¡ä»¶çš„é«˜è´¨é‡å“åº”ã€‚ç”¨æˆ·è¿˜å¯ä»¥å°†è¿”å›çš„ convlines æ›´æ”¹ä¸º \textit{control} å°†å¯¹è¯çš„æ–¹å‘è½¬å‘å¯¹ä»–ä»¬æ›´æ„Ÿå…´è¶£çš„ä¸»é¢˜ã€‚é€šè¿‡è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°ï¼Œæˆ‘ä»¬å±•ç¤ºäº† convlines åœ¨äº§ç”Ÿå¼•äººå…¥èƒœçš„å¯¹è¯æ–¹é¢çš„æ•ˆç‡ã€‚</td><td>Sarik Ghazarian   Zixi Liu   Tuhin Chakrabarty   Xuezhe Ma   Aram Galstyan   Nanyun Peng</td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12757&#39;]">Adding Chit-Chat to Enhance Task-Oriented Dialogues</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12757">https://arxiv.org/pdf/2010.12757</a></td><td>Existing dialogue corpora and models are typically designed under two disjoint motives: while task-oriented systems focus on achieving functional goals (e.g., booking hotels), open-domain chatbots aim at making socially engaging conversations. In this work, we propose to integrate both types of systems by Adding Chit-Chat to ENhance Task-ORiented dialogues (ACCENTOR), with the goal of making virtual assistant conversations more engaging and interactive. Specifically, we propose a Human &lt;-&gt; AI collaborative data collection approach for generating diverse chit-chat responses to augment task-oriented dialogues with minimal annotation effort. We then present our new chit-chat-based annotations to 23.8K dialogues from two popular task-oriented datasets (Schema-Guided Dialogue and MultiWOZ 2.1) and demonstrate their advantage over the originals via human evaluation. Lastly, we propose three new models for adding chit-chat to task-oriented dialogues, explicitly trained to predict user goals and to generate contextually relevant chit-chat responses. Automatic and human evaluations show that, compared with the state-of-the-art task-oriented baseline, our models can code-switch between task and chit-chat to be more engaging, interesting, knowledgeable, and humanlike, while maintaining competitive task performance.</td><td>ç°æœ‰çš„å¯¹è¯è¯­æ–™åº“å’Œæ¨¡å‹é€šå¸¸æ˜¯åœ¨ä¸¤ä¸ªä¸ç›¸äº¤çš„åŠ¨æœºä¸‹è®¾è®¡çš„ï¼šé¢å‘ä»»åŠ¡çš„ç³»ç»Ÿä¸“æ³¨äºå®ç°åŠŸèƒ½ç›®æ ‡ï¼ˆä¾‹å¦‚ï¼Œé¢„è®¢é…’åº—ï¼‰ï¼Œè€Œå¼€æ”¾åŸŸèŠå¤©æœºå™¨äººæ—¨åœ¨è¿›è¡Œç¤¾äº¤äº’åŠ¨ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å»ºè®®é€šè¿‡å°† Chit-Chat æ·»åŠ åˆ°å¢å¼ºé¢å‘ä»»åŠ¡çš„å¯¹è¯ (ACCENTOR) æ¥é›†æˆä¸¤ç§ç±»å‹çš„ç³»ç»Ÿï¼Œç›®çš„æ˜¯ä½¿è™šæ‹ŸåŠ©æ‰‹å¯¹è¯æ›´å…·å¸å¼•åŠ›å’Œäº’åŠ¨æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ Human &lt;-&gt; AI åä½œæ•°æ®æ”¶é›†æ–¹æ³•ï¼Œç”¨äºç”Ÿæˆå„ç§é—²èŠå“åº”ï¼Œä»¥æœ€å°‘çš„æ³¨é‡Šå·¥ä½œæ¥å¢å¼ºé¢å‘ä»»åŠ¡çš„å¯¹è¯ã€‚ç„¶åï¼Œæˆ‘ä»¬å‘æ¥è‡ªä¸¤ä¸ªæµè¡Œçš„é¢å‘ä»»åŠ¡çš„æ•°æ®é›†ï¼ˆSchema-Guided Dialogue å’Œ MultiWOZ 2.1ï¼‰çš„ 23.8K å¯¹è¯å±•ç¤ºäº†æˆ‘ä»¬æ–°çš„åŸºäºé—²èŠçš„æ³¨é‡Šï¼Œå¹¶é€šè¿‡äººå·¥è¯„ä¼°è¯æ˜äº†å®ƒä»¬ç›¸å¯¹äºåŸå§‹æ•°æ®çš„ä¼˜åŠ¿ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰ä¸ªæ–°æ¨¡å‹ï¼Œç”¨äºå°†é—²èŠæ·»åŠ åˆ°é¢å‘ä»»åŠ¡çš„å¯¹è¯ä¸­ï¼Œç»è¿‡æ˜ç¡®è®­ç»ƒä»¥é¢„æµ‹ç”¨æˆ·ç›®æ ‡å¹¶ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„é—²èŠå“åº”ã€‚è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°è¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„é¢å‘ä»»åŠ¡çš„åŸºçº¿ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥åœ¨ä»»åŠ¡å’Œé—²èŠä¹‹é—´è¿›è¡Œä»£ç åˆ‡æ¢ï¼Œä½¿å…¶æ›´å…·å¸å¼•åŠ›ã€æœ‰è¶£ã€çŸ¥è¯†æ¸Šåšå’Œäººæ€§åŒ–ï¼ŒåŒæ—¶ä¿æŒç«äº‰æ€§ä»»åŠ¡è¡¨ç°ã€‚</td><td>Kai Sun   Seungwhan Moon   Paul Crook   Stephen Roller   Becka Silvert   Bing Liu   Zhiguang Wang   Honglei Liu   Eunjoon Cho   Claire Cardie</td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.10663&#39;]">Fast and Scalable Dialogue State Tracking with Explicit Modular Decomposition</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.10663">https://arxiv.org/pdf/2004.10663</a></td><td>We present a fast and scalable architecture called Explicit Modular Decomposition (EMD), in which we incorporate both classification-based and extraction-based methods and design four modules (for classification and sequence labelling) to jointly extract dialogue states. Experimental results based on the MultiWoz 2.0 dataset validates the superiority of our proposed model in terms of both complexity and scalability when compared to the state-of-the-art methods, especially in the scenario of multi-domain dialogues entangled with many turns of utterances.</td><td>æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸ºæ˜¾å¼æ¨¡å—åŒ–åˆ†è§£ (EMD) çš„å¿«é€Ÿä¸”å¯æ‰©å±•çš„æ¶æ„ï¼Œå…¶ä¸­æˆ‘ä»¬ç»“åˆäº†åŸºäºåˆ†ç±»å’ŒåŸºäºæå–çš„æ–¹æ³•ï¼Œå¹¶è®¾è®¡äº†å››ä¸ªæ¨¡å—ï¼ˆç”¨äºåˆ†ç±»å’Œåºåˆ—æ ‡è®°ï¼‰æ¥è”åˆæå–å¯¹è¯çŠ¶æ€ã€‚ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒåŸºäº MultiWoz 2.0 æ•°æ®é›†çš„å®éªŒç»“æœéªŒè¯äº†æˆ‘ä»¬æå‡ºçš„æ¨¡å‹åœ¨å¤æ‚æ€§å’Œå¯æ‰©å±•æ€§æ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¤šåŸŸå¯¹è¯ä¸å¤šè½®è¯è¯­çº ç¼ çš„æƒ…å†µä¸‹.</td><td>Dingmin Wang   Chenghua Lin   Li Zhong   Kam-Fai Wong</td></tr><tr><td>8</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1810.13327&#39;]">Cross-lingual Transfer Learning for Multilingual Task Oriented Dialog</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1810.13327">https://arxiv.org/pdf/1810.13327</a></td><td>One of the first steps in the utterance interpretation pipeline of many task-oriented conversational AI systems is to identify user intents and the corresponding slots. Since data collection for machine learning models for this task is time-consuming, it is desirable to make use of existing data in a high-resource language to train models in low-resource languages. However, development of such models has largely been hindered by the lack of multilingual training data. In this paper, we present a new data set of 57k annotated utterances in English (43k), Spanish (8.6k) and Thai (5k) across the domains weather, alarm, and reminder. We use this data set to evaluate three different cross-lingual transfer methods: (1) translating the training data, (2) using cross-lingual pre-trained embeddings, and (3) a novel method of using a multilingual machine translation encoder as contextual word representations. We find that given several hundred training examples in the the target language, the latter two methods outperform translating the training data. Further, in very low-resource settings, multilingual contextual word representations give better results than using cross-lingual static embeddings. We also compare the cross-lingual methods to using monolingual resources in the form of contextual ELMo representations and find that given just small amounts of target language data, this method outperforms all cross-lingual methods, which highlights the need for more sophisticated cross-lingual methods.</td><td></td><td>Sebastian Schuster   Sonal Gupta   Rushin Shah   Mike Lewis</td></tr><tr><td>9</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.03371&#39;]">Evaluating Coherence in Dialogue Systems using Entailment</a></td><td></td><td><a href="https://github.com/nouhadziri/DialogEntailment">https://github.com/nouhadziri/DialogEntailment</a></td><td><a href="https://arxiv.org/pdf/1904.03371">https://arxiv.org/pdf/1904.03371</a></td><td>Evaluating open-domain dialogue systems is difficult due to the diversity of possible correct answers. Automatic metrics such as BLEU correlate weakly with human annotations, resulting in a significant bias across different models and datasets. Some researchers resort to human judgment experimentation for assessing response quality, which is expensive, time consuming, and not scalable. Moreover, judges tend to evaluate a small number of dialogues, meaning that minor differences in evaluation configuration may lead to dissimilar results. In this paper, we present interpretable metrics for evaluating topic coherence by making use of distributed sentence representations. Furthermore, we introduce calculable approximations of human judgment based on conversational coherence by adopting state-of-the-art entailment techniques. Results show that our metrics can be used as a surrogate for human judgment, making it easy to evaluate dialogue systems on large-scale datasets and allowing an unbiased estimate for the quality of the responses.</td><td>ç”±äºå¯èƒ½æ­£ç¡®ç­”æ¡ˆçš„å¤šæ ·æ€§ï¼Œè¯„ä¼°å¼€æ”¾åŸŸå¯¹è¯ç³»ç»Ÿå¾ˆå›°éš¾ã€‚ BLEU ç­‰è‡ªåŠ¨æŒ‡æ ‡ä¸äººå·¥æ³¨é‡Šçš„ç›¸å…³æ€§è¾ƒå¼±ï¼Œå¯¼è‡´ä¸åŒæ¨¡å‹å’Œæ•°æ®é›†ä¹‹é—´å­˜åœ¨æ˜¾ç€åå·®ã€‚ä¸€äº›ç ”ç©¶äººå‘˜é‡‡ç”¨äººå·¥åˆ¤æ–­å®éªŒæ¥è¯„ä¼°å“åº”è´¨é‡ï¼Œè¿™æ˜¯æ˜‚è´µã€è€—æ—¶ä¸”ä¸å¯æ‰©å±•çš„ã€‚æ­¤å¤–ï¼Œè¯„å§”å€¾å‘äºè¯„ä»·å°‘é‡å¯¹è¯ï¼Œè¿™æ„å‘³ç€è¯„ä»·é…ç½®çš„å¾®å°å·®å¼‚å¯èƒ½å¯¼è‡´ä¸åŒçš„ç»“æœã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨åˆ†å¸ƒå¼å¥å­è¡¨ç¤ºï¼Œæå‡ºäº†ç”¨äºè¯„ä¼°ä¸»é¢˜è¿è´¯æ€§çš„å¯è§£é‡ŠæŒ‡æ ‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡é‡‡ç”¨æœ€å…ˆè¿›çš„è•´å«æŠ€æœ¯ï¼ŒåŸºäºå¯¹è¯è¿è´¯æ€§å¼•å…¥äº†äººç±»åˆ¤æ–­çš„å¯è®¡ç®—è¿‘ä¼¼å€¼ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æŒ‡æ ‡å¯ä»¥ç”¨ä½œäººç±»åˆ¤æ–­çš„æ›¿ä»£å“ï¼Œä»è€Œå¯ä»¥è½»æ¾è¯„ä¼°å¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„å¯¹è¯ç³»ç»Ÿï¼Œå¹¶å…è®¸å¯¹å“åº”è´¨é‡è¿›è¡Œæ— åä¼°è®¡ã€‚</td><td>Nouha Dziri   Ehsan Kamalloo   Kory W. Mathewson   Osmar Zaiane</td></tr></tbody></table></div><h3 id="COLING-1"><a href="#COLING-1" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2012.04080&#39;]">A Taxonomy of Empathetic Response Intents in Human Social Conversations</a></td><td></td><td><a href="https://github.com/anuradha1992/EmpatheticIntents">https://github.com/anuradha1992/EmpatheticIntents</a></td><td><a href="https://arxiv.org/pdf/2012.04080">https://arxiv.org/pdf/2012.04080</a></td><td>Open-domain conversational agents or chatbots are becoming increasingly popular in the natural language processing community. One of the challenges is enabling them to converse in an empathetic manner. Current neural response generation methods rely solely on end-to-end learning from large scale conversation data to generate dialogues. This approach can produce socially unacceptable responses due to the lack of large-scale quality data used to train the neural models. However, recent work has shown the promise of combining dialogue act/intent modelling and neural response generation. This hybrid method improves the response quality of chatbots and makes them more controllable and interpretable. A key element in dialog intent modelling is the development of a taxonomy. Inspired by this idea, we have manually labeled 500 response intents using a subset of a sizeable empathetic dialogue dataset (25K dialogues). Our goal is to produce a large-scale taxonomy for empathetic response intents. Furthermore, using lexical and machine learning methods, we automatically analysed both speaker and listener utterances of the entire dataset with identified response intents and 32 emotion categories. Finally, we use information visualization methods to summarize emotional dialogue exchange patterns and their temporal progression. These results reveal novel and important empathy patterns in human-human open-domain conversations and can serve as heuristics for hybrid approaches.</td><td>å¼€æ”¾åŸŸå¯¹è¯ä»£ç†æˆ–èŠå¤©æœºå™¨äººåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ç¤¾åŒºä¸­å˜å¾—è¶Šæ¥è¶Šæµè¡Œã€‚æŒ‘æˆ˜ä¹‹ä¸€æ˜¯ä½¿ä»–ä»¬èƒ½å¤Ÿä»¥å–„è§£äººæ„çš„æ–¹å¼äº¤è°ˆã€‚å½“å‰çš„ç¥ç»å“åº”ç”Ÿæˆæ–¹æ³•ä»…ä¾èµ–äºä»å¤§è§„æ¨¡å¯¹è¯æ•°æ®ä¸­è¿›è¡Œç«¯åˆ°ç«¯å­¦ä¹ æ¥ç”Ÿæˆå¯¹è¯ã€‚ç”±äºç¼ºä¹ç”¨äºè®­ç»ƒç¥ç»æ¨¡å‹çš„å¤§è§„æ¨¡è´¨é‡æ•°æ®ï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¼šäº§ç”Ÿç¤¾ä¼šä¸Šæ— æ³•æ¥å—çš„ååº”ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„å·¥ä½œæ˜¾ç¤ºäº†å°†å¯¹è¯è¡Œä¸º/æ„å›¾å»ºæ¨¡å’Œç¥ç»ååº”ç”Ÿæˆç›¸ç»“åˆçš„å‰æ™¯ã€‚è¿™ç§æ··åˆæ–¹æ³•æé«˜äº†èŠå¤©æœºå™¨äººçš„å“åº”è´¨é‡ï¼Œå¹¶ä½¿å®ƒä»¬æ›´åŠ å¯æ§å’Œå¯è§£é‡Šã€‚å¯¹è¯æ„å›¾å»ºæ¨¡çš„ä¸€ä¸ªå…³é”®è¦ç´ æ˜¯åˆ†ç±»æ³•çš„å¼€å‘ã€‚å—è¿™ä¸ªæƒ³æ³•çš„å¯å‘ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç›¸å½“å¤§çš„ç§»æƒ…å¯¹è¯æ•°æ®é›†ï¼ˆ25K å¯¹è¯ï¼‰çš„å­é›†æ‰‹åŠ¨æ ‡è®°äº† 500 ä¸ªå“åº”æ„å›¾ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä¸ºç§»æƒ…ååº”æ„å›¾ç”Ÿæˆå¤§è§„æ¨¡åˆ†ç±»æ³•ã€‚æ­¤å¤–ï¼Œä½¿ç”¨è¯æ±‡å’Œæœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œæˆ‘ä»¬è‡ªåŠ¨åˆ†æäº†æ•´ä¸ªæ•°æ®é›†çš„è¯´è¯è€…å’Œå¬è€…çš„è¯è¯­ï¼Œå¹¶ç¡®å®šäº†å“åº”æ„å›¾å’Œ 32 ç§æƒ…æ„Ÿç±»åˆ«ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¿¡æ¯å¯è§†åŒ–æ–¹æ³•æ¥æ€»ç»“æƒ…æ„Ÿå¯¹è¯äº¤æµæ¨¡å¼åŠå…¶æ—¶é—´è¿›å±•ã€‚è¿™äº›ç»“æœæ­ç¤ºäº†äººä¸äººå¼€æ”¾åŸŸå¯¹è¯ä¸­æ–°é¢–è€Œé‡è¦çš„ç§»æƒ…æ¨¡å¼ï¼Œå¯ä»¥ä½œä¸ºæ··åˆæ–¹æ³•çš„å¯å‘å¼æ–¹æ³•ã€‚</td><td>Anuradha Welivita   Pearl Pu</td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2105.10606&#39;]">CEREC: A Corpus for Entity Resolution in Email Conversations</a></td><td></td><td><a href="https://github.com/paragdakle/emailcoref">https://github.com/paragdakle/emailcoref</a></td><td><a href="https://arxiv.org/pdf/2105.10606">https://arxiv.org/pdf/2105.10606</a></td><td>We present the first large scale corpus for entity resolution in email conversations (CEREC). The corpus consists of 6001 email threads from the Enron Email Corpus containing 36,448 email messages and 60,383 entity coreference chains. The annotation is carried out as a two-step process with minimal manual effort. Experiments are carried out for evaluating different features and performance of four baselines on the created corpus. For the task of mention identification and coreference resolution, a best performance of 59.2 F1 is reported, highlighting the room for improvement. An in-depth qualitative and quantitative error analysis is presented to understand the limitations of the baselines considered.</td><td>æˆ‘ä»¬å±•ç¤ºäº†ç¬¬ä¸€ä¸ªç”¨äºç”µå­é‚®ä»¶å¯¹è¯ä¸­å®ä½“è§£æçš„å¤§è§„æ¨¡è¯­æ–™åº“ (CEREC)ã€‚è¯¥è¯­æ–™åº“ç”±æ¥è‡ªå®‰ç„¶ç”µå­é‚®ä»¶è¯­æ–™åº“çš„ 6001 ä¸ªç”µå­é‚®ä»¶çº¿ç¨‹ç»„æˆï¼Œå…¶ä¸­åŒ…å« 36,448 å°ç”µå­é‚®ä»¶å’Œ 60,383 ä¸ªå®ä½“å…±æŒ‡é“¾ã€‚æ³¨é‡Šä½œä¸ºä¸¤æ­¥è¿‡ç¨‹æ‰§è¡Œï¼Œæ‰‹åŠ¨æ“ä½œæœ€å°‘ã€‚è¿›è¡Œå®éªŒä»¥è¯„ä¼°å››ä¸ªåŸºçº¿åœ¨åˆ›å»ºçš„è¯­æ–™åº“ä¸Šçš„ä¸åŒç‰¹å¾å’Œæ€§èƒ½ã€‚å¯¹äºæåŠè¯†åˆ«å’Œå…±æŒ‡è§£æçš„ä»»åŠ¡ï¼ŒæŠ¥å‘Šäº† 59.2 F1 çš„æœ€ä½³æ€§èƒ½ï¼Œçªå‡ºäº†æ”¹è¿›çš„ç©ºé—´ã€‚æä¾›äº†æ·±å…¥çš„å®šæ€§å’Œå®šé‡è¯¯å·®åˆ†æï¼Œä»¥äº†è§£æ‰€è€ƒè™‘åŸºçº¿çš„å±€é™æ€§ã€‚</td><td>Parag Pravin Dakle   Dan I. Moldovan</td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.00671&#39;]">Conversational Machine Comprehension: a Literature Review</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2006.00671">https://arxiv.org/pdf/2006.00671</a></td><td>Conversational Machine Comprehension (CMC), a research track in conversational AI, expects the machine to understand an open-domain natural language text and thereafter engage in a multi-turn conversation to answer questions related to the text. While most of the research in Machine Reading Comprehension (MRC) revolves around single-turn question answering (QA), multi-turn CMC has recently gained prominence, thanks to the advancement in natural language understanding via neural language models such as BERT and the introduction of large-scale conversational datasets such as CoQA and QuAC. The rise in interest has, however, led to a flurry of concurrent publications, each with a different yet structurally similar modeling approach and an inconsistent view of the surrounding literature. With the volume of model submissions to conversational datasets increasing every year, there exists a need to consolidate the scattered knowledge in this domain to streamline future research. This literature review attempts at providing a holistic overview of CMC with an emphasis on the common trends across recently published models, specifically in their approach to tackling conversational history. The review synthesizes a generic framework for CMC models while highlighting the differences in recent approaches and intends to serve as a compendium of CMC for future researchers.</td><td>Conversational Machine Comprehension (CMC) æ˜¯ä¼šè¯ AI çš„ä¸€ä¸ªç ”ç©¶æ–¹å‘ï¼Œå®ƒå¸Œæœ›æœºå™¨èƒ½å¤Ÿç†è§£å¼€æ”¾é¢†åŸŸçš„è‡ªç„¶è¯­è¨€æ–‡æœ¬ï¼Œç„¶åè¿›è¡Œå¤šè½®å¯¹è¯ä»¥å›ç­”ä¸æ–‡æœ¬ç›¸å…³çš„é—®é¢˜ã€‚è™½ç„¶æœºå™¨é˜…è¯»ç†è§£ (MRC) çš„å¤§éƒ¨åˆ†ç ”ç©¶éƒ½å›´ç»•å•è½®é—®ç­” (QA) å±•å¼€ï¼Œä½†ç”±äºé€šè¿‡ BERT ç­‰ç¥ç»è¯­è¨€æ¨¡å‹å’Œä»‹ç»å¤§è§„æ¨¡ä¼šè¯æ•°æ®é›†ï¼Œå¦‚ CoQA å’Œ QuACã€‚ç„¶è€Œï¼Œå…´è¶£çš„å¢åŠ å¯¼è‡´äº†å¤§é‡å¹¶å‘å‡ºç‰ˆç‰©ï¼Œæ¯ä¸€ç§éƒ½æœ‰ä¸åŒä½†ç»“æ„ç›¸ä¼¼çš„å»ºæ¨¡æ–¹æ³•å’Œå¯¹å‘¨å›´æ–‡çŒ®çš„ä¸ä¸€è‡´çœ‹æ³•ã€‚éšç€ä¼šè¯æ•°æ®é›†çš„æ¨¡å‹æäº¤é‡é€å¹´å¢åŠ ï¼Œéœ€è¦æ•´åˆè¯¥é¢†åŸŸçš„é›¶æ•£çŸ¥è¯†ä»¥ç®€åŒ–æœªæ¥çš„ç ”ç©¶ã€‚è¿™ç¯‡æ–‡çŒ®ç»¼è¿°è¯•å›¾æä¾› CMC çš„æ•´ä½“æ¦‚è¿°ï¼Œé‡ç‚¹æ˜¯æœ€è¿‘å‘å¸ƒçš„æ¨¡å‹çš„å…±åŒè¶‹åŠ¿ï¼Œç‰¹åˆ«æ˜¯å®ƒä»¬å¤„ç†å¯¹è¯å†å²çš„æ–¹æ³•ã€‚è¯¥è¯„è®ºç»¼åˆäº† CMC æ¨¡å‹çš„é€šç”¨æ¡†æ¶ï¼ŒåŒæ—¶çªå‡ºäº†æœ€è¿‘æ–¹æ³•çš„å·®å¼‚ï¼Œå¹¶æ‰“ç®—ä½œä¸ºæœªæ¥ç ”ç©¶äººå‘˜çš„ CMC çº²è¦ã€‚</td><td>Somil Gupta   Bhanu Pratap Singh Rawat   Hong Yu</td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00615&#39;]">Improving Conversational Question Answering Systems after Deployment using Feedback-Weighted Learning</a></td><td></td><td><a href="https://github.com/jjacampos/FeedbackWeightedLearning">https://github.com/jjacampos/FeedbackWeightedLearning</a></td><td><a href="https://arxiv.org/pdf/2011.00615">https://arxiv.org/pdf/2011.00615</a></td><td>The interaction of conversational systems with users poses an exciting opportunity for improving them after deployment, but little evidence has been provided of its feasibility. In most applications, users are not able to provide the correct answer to the system, but they are able to provide binary (correct, incorrect) feedback. In this paper we propose feedback-weighted learning based on importance sampling to improve upon an initial supervised system using binary user feedback. We perform simulated experiments on document classification (for development) and Conversational Question Answering datasets like QuAC and DoQA, where binary user feedback is derived from gold annotations. The results show that our method is able to improve over the initial supervised system, getting close to a fully-supervised system that has access to the same labeled examples in in-domain experiments (QuAC), and even matching in out-of-domain experiments (DoQA). Our work opens the prospect to exploit interactions with real users and improve conversational systems after deployment.</td><td>å¯¹è¯ç³»ç»Ÿä¸ç”¨æˆ·çš„äº¤äº’ä¸ºéƒ¨ç½²åæ”¹è¿›å®ƒä»¬æä¾›äº†ä¸€ä¸ªä»¤äººå…´å¥‹çš„æœºä¼šï¼Œä½†å‡ ä¹æ²¡æœ‰æä¾›å…¶å¯è¡Œæ€§çš„è¯æ®ã€‚åœ¨å¤§å¤šæ•°åº”ç”¨ä¸­ï¼Œç”¨æˆ·æ— æ³•å‘ç³»ç»Ÿæä¾›æ­£ç¡®ç­”æ¡ˆï¼Œä½†ä»–ä»¬èƒ½å¤Ÿæä¾›äºŒå…ƒï¼ˆæ­£ç¡®ã€ä¸æ­£ç¡®ï¼‰åé¦ˆã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºé‡è¦æ€§é‡‡æ ·çš„åé¦ˆåŠ æƒå­¦ä¹ ï¼Œä»¥æ”¹è¿›ä½¿ç”¨äºŒå…ƒç”¨æˆ·åé¦ˆçš„åˆå§‹ç›‘ç£ç³»ç»Ÿã€‚æˆ‘ä»¬å¯¹æ–‡æ¡£åˆ†ç±»ï¼ˆç”¨äºå¼€å‘ï¼‰å’Œå¯¹è¯å¼é—®ç­”æ•°æ®é›†ï¼ˆå¦‚ QuAC å’Œ DoQAï¼‰è¿›è¡Œæ¨¡æ‹Ÿå®éªŒï¼Œå…¶ä¸­äºŒè¿›åˆ¶ç”¨æˆ·åé¦ˆæ¥è‡ªé»„é‡‘æ³¨é‡Šã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿæ”¹è¿›åˆå§‹ç›‘ç£ç³»ç»Ÿï¼Œæ¥è¿‘å®Œå…¨ç›‘ç£ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿå¯ä»¥åœ¨åŸŸå†…å®éªŒ (QuAC) ä¸­è®¿é—®ç›¸åŒçš„æ ‡è®°ç¤ºä¾‹ï¼Œç”šè‡³å¯ä»¥åœ¨åŸŸå¤–è¿›è¡ŒåŒ¹é…å®éªŒï¼ˆDoQAï¼‰ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼€è¾Ÿäº†åˆ©ç”¨ä¸çœŸå®ç”¨æˆ·çš„äº¤äº’å¹¶åœ¨éƒ¨ç½²åæ”¹è¿›å¯¹è¯ç³»ç»Ÿçš„å‰æ™¯ã€‚</td><td>Jon Ander Campos   Kyunghyun Cho   Arantxa Otegi   Aitor Soroa   Gorka Azkune   Eneko Agirre</td></tr><tr><td>5</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04125&#39;]">Towards Topic-Guided Conversational Recommender System</a></td><td></td><td><a href="https://github.com/RUCAIBox/TG-ReDial">https://github.com/RUCAIBox/TG-ReDial</a></td><td><a href="https://arxiv.org/pdf/2010.04125">https://arxiv.org/pdf/2010.04125</a></td><td>Conversational recommender systems (CRS) aim to recommend high-quality items to users through interactive conversations. To develop an effective CRS, the support of high-quality datasets is essential. Existing CRS datasets mainly focus on immediate requests from users, while lack proactive guidance to the recommendation scenario. In this paper, we contribute a new CRS dataset named \textbf{TG-ReDial} (\textbf{Re}commendation through \textbf{T}opic-\textbf{G}uided \textbf{Dial}og). Our dataset has two major features. First, it incorporates topic threads to enforce natural semantic transitions towards the recommendation scenario. Second, it is created in a semi-automatic way, hence human annotation is more reasonable and controllable. Based on TG-ReDial, we present the task of topic-guided conversational recommendation, and propose an effective approach to this task. Extensive experiments have demonstrated the effectiveness of our approach on three sub-tasks, namely topic prediction, item recommendation and response generation. TG-ReDial is available at <a href="https://github.com/RUCAIBox/TG-ReDial">https://github.com/RUCAIBox/TG-ReDial</a>.</td><td>ä¼šè¯æ¨èç³»ç»Ÿï¼ˆCRSï¼‰æ—¨åœ¨é€šè¿‡äº¤äº’å¼ä¼šè¯å‘ç”¨æˆ·æ¨èé«˜è´¨é‡çš„é¡¹ç›®ã€‚è¦å¼€å‘æœ‰æ•ˆçš„ CRSï¼Œé«˜è´¨é‡æ•°æ®é›†çš„æ”¯æŒå¿…ä¸å¯å°‘ã€‚ç°æœ‰çš„ CRS æ•°æ®é›†ä¸»è¦å…³æ³¨ç”¨æˆ·çš„å³æ—¶è¯·æ±‚ï¼Œè€Œç¼ºä¹å¯¹æ¨èåœºæ™¯çš„ä¸»åŠ¨æŒ‡å¯¼ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è´¡çŒ®äº†ä¸€ä¸ªåä¸º \textbf{TG-ReDial} çš„æ–° CRS æ•°æ®é›†ï¼ˆ\textbf{Re}commendation through \textbf{T}opic-\textbf{G}uided \textbf{Dial}ogï¼‰ã€‚æˆ‘ä»¬çš„æ•°æ®é›†æœ‰ä¸¤ä¸ªä¸»è¦ç‰¹å¾ã€‚é¦–å…ˆï¼Œå®ƒç»“åˆäº†ä¸»é¢˜çº¿ç¨‹æ¥å¼ºåˆ¶å‘æ¨èåœºæ™¯è¿›è¡Œè‡ªç„¶è¯­ä¹‰è½¬æ¢ã€‚å…¶æ¬¡ï¼Œé‡‡ç”¨åŠè‡ªåŠ¨æ–¹å¼åˆ›å»ºï¼Œäººå·¥æ ‡æ³¨æ›´åŠ åˆç†å¯æ§ã€‚åŸºäºTG-ReDialï¼Œæˆ‘ä»¬æå‡ºäº†ä¸»é¢˜å¼•å¯¼çš„å¯¹è¯æ¨èä»»åŠ¡ï¼Œå¹¶æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•æ¥å®Œæˆè¿™é¡¹ä»»åŠ¡ã€‚å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰ä¸ªå­ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œå³ä¸»é¢˜é¢„æµ‹ã€é¡¹ç›®æ¨èå’Œå“åº”ç”Ÿæˆã€‚ TG-ReDial å¯åœ¨ <a href="https://github.com/RUCAIBox/TG-ReDial">https://github.com/RUCAIBox/TG-ReDial</a> è·å¾—ã€‚</td><td>Kun Zhou   Yuanhang Zhou   Wayne Xin Zhao   Xiaoke Wang   Ji-Rong Wen</td></tr><tr><td>6</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00483&#39;]">Deconstruct to Reconstruct a Configurable Evaluation Metric for Open-Domain Dialogue Systems</a></td><td></td><td><a href="https://github.com/vitouphy/usl_dialogue_metric">https://github.com/vitouphy/usl_dialogue_metric</a></td><td><a href="https://arxiv.org/pdf/2011.00483">https://arxiv.org/pdf/2011.00483</a></td><td>Many automatic evaluation metrics have been proposed to score the overall quality of a response in open-domain dialogue. Generally, the overall quality is comprised of various aspects, such as relevancy, specificity, and empathy, and the importance of each aspect differs according to the task. For instance, specificity is mandatory in a food-ordering dialogue task, whereas fluency is preferred in a language-teaching dialogue system. However, existing metrics are not designed to cope with such flexibility. For example, BLEU score fundamentally relies only on word overlapping, whereas BERTScore relies on semantic similarity between reference and candidate response. Thus, they are not guaranteed to capture the required aspects, i.e., specificity. To design a metric that is flexible to a task, we first propose making these qualities manageable by grouping them into three groups: understandability, sensibleness, and likability, where likability is a combination of qualities that are essential for a task. We also propose a simple method to composite metrics of each aspect to obtain a single metric called USL-H, which stands for Understandability, Sensibleness, and Likability in Hierarchy. We demonstrated that USL-H score achieves good correlations with human judgment and maintains its configurability towards different aspects and metrics.</td><td>å·²ç»æå‡ºäº†è®¸å¤šè‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡æ¥å¯¹å¼€æ”¾åŸŸå¯¹è¯ä¸­å“åº”çš„æ•´ä½“è´¨é‡è¿›è¡Œè¯„åˆ†ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæ•´ä½“ç´ è´¨ç”±ç›¸å…³æ€§ã€ç‰¹å¼‚æ€§ã€åŒç†å¿ƒç­‰å¤šä¸ªæ–¹é¢ç»„æˆï¼Œæ¯ä¸ªæ–¹é¢çš„é‡è¦æ€§å› ä»»åŠ¡è€Œå¼‚ã€‚ä¾‹å¦‚ï¼Œåœ¨è®¢é¤å¯¹è¯ä»»åŠ¡ä¸­ï¼Œç‰¹å®šæ€§æ˜¯å¼ºåˆ¶æ€§çš„ï¼Œè€Œåœ¨è¯­è¨€æ•™å­¦å¯¹è¯ç³»ç»Ÿä¸­ï¼Œæµç•…æ€§æ˜¯é¦–é€‰ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æŒ‡æ ‡å¹¶ä¸æ˜¯ä¸ºäº†åº”å¯¹è¿™ç§çµæ´»æ€§è€Œè®¾è®¡çš„ã€‚ä¾‹å¦‚ï¼ŒBLEU åˆ†æ•°ä»æ ¹æœ¬ä¸Šåªä¾èµ–äºå•è¯é‡å ï¼Œè€Œ BERTScore ä¾èµ–äºå‚è€ƒå’Œå€™é€‰å“åº”ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼æ€§ã€‚å› æ­¤ï¼Œå®ƒä»¬ä¸èƒ½ä¿è¯æ•è·æ‰€éœ€çš„æ–¹é¢ï¼Œå³ç‰¹å¼‚æ€§ã€‚ä¸ºäº†è®¾è®¡ä¸€ä¸ªå¯¹ä»»åŠ¡çµæ´»çš„åº¦é‡ï¼Œæˆ‘ä»¬é¦–å…ˆå»ºè®®é€šè¿‡å°†è¿™äº›å“è´¨åˆ†ä¸ºä¸‰ç»„æ¥ä½¿è¿™äº›å“è´¨æ˜“äºç®¡ç†ï¼šå¯ç†è§£æ€§ã€åˆç†æ€§å’Œå¯çˆ±æ€§ï¼Œå…¶ä¸­å¯çˆ±æ€§æ˜¯ä»»åŠ¡å¿…ä¸å¯å°‘çš„å“è´¨çš„ç»„åˆã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§ç®€å•çš„æ–¹æ³•æ¥ç»„åˆæ¯ä¸ªæ–¹é¢çš„æŒ‡æ ‡ï¼Œä»¥è·å¾—ä¸€ä¸ªç§°ä¸º USL-H çš„å•ä¸€æŒ‡æ ‡ï¼Œå®ƒä»£è¡¨å±‚æ¬¡ç»“æ„ä¸­çš„å¯ç†è§£æ€§ã€æ•æ„Ÿæ€§å’Œå¯çˆ±æ€§ã€‚æˆ‘ä»¬è¯æ˜ USL-H åˆ†æ•°ä¸äººç±»åˆ¤æ–­å…·æœ‰è‰¯å¥½çš„ç›¸å…³æ€§ï¼Œå¹¶ä¿æŒå…¶å¯¹ä¸åŒæ–¹é¢å’ŒæŒ‡æ ‡çš„å¯é…ç½®æ€§ã€‚</td><td>Vitou Phy   Yang Zhao   Akiko Aizawa</td></tr><tr><td>7</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00564&#39;]">Recent Neural Methods on Slot Filling and Intent Classification for Task-Oriented Dialogue Systems: A Survey</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00564">https://arxiv.org/pdf/2011.00564</a></td><td>In recent years, fostered by deep learning technologies and by the high demand for conversational AI, various approaches have been proposed that address the capacity to elicit and understand userâ€™s needs in task-oriented dialogue systems. We focus on two core tasks, slot filling (SF) and intent classification (IC), and survey how neural-based models have rapidly evolved to address natural language understanding in dialogue systems. We introduce three neural architectures: independent model, which model SF and IC separately, joint models, which exploit the mutual benefit of the two tasks simultaneously, and transfer learning models, that scale the model to new domains. We discuss the current state of the research in SF and IC and highlight challenges that still require attention.</td><td>è¿‘å¹´æ¥ï¼Œåœ¨æ·±åº¦å­¦ä¹ æŠ€æœ¯å’Œå¯¹å¯¹è¯å¼ AI çš„é«˜éœ€æ±‚çš„æ¨åŠ¨ä¸‹ï¼Œå·²ç»æå‡ºäº†å„ç§æ–¹æ³•æ¥è§£å†³åœ¨é¢å‘ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿä¸­å¼•å‘å’Œç†è§£ç”¨æˆ·éœ€æ±‚çš„èƒ½åŠ›ã€‚æˆ‘ä»¬ä¸“æ³¨äºä¸¤ä¸ªæ ¸å¿ƒä»»åŠ¡ï¼Œæ§½å¡«å…… (SF) å’Œæ„å›¾åˆ†ç±» (IC)ï¼Œå¹¶è°ƒæŸ¥åŸºäºç¥ç»çš„æ¨¡å‹å¦‚ä½•å¿«é€Ÿå‘å±•ä»¥è§£å†³å¯¹è¯ç³»ç»Ÿä¸­çš„è‡ªç„¶è¯­è¨€ç†è§£é—®é¢˜ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸‰ç§ç¥ç»æ¶æ„ï¼šç‹¬ç«‹æ¨¡å‹ï¼Œåˆ†åˆ«å¯¹ SF å’Œ IC è¿›è¡Œå»ºæ¨¡ï¼Œè”åˆæ¨¡å‹ï¼ŒåŒæ—¶åˆ©ç”¨ä¸¤ä¸ªä»»åŠ¡çš„äº’åˆ©ï¼Œä»¥åŠè¿ç§»å­¦ä¹ æ¨¡å‹ï¼Œå°†æ¨¡å‹æ‰©å±•åˆ°æ–°é¢†åŸŸã€‚æˆ‘ä»¬è®¨è®ºäº† SF å’Œ IC çš„ç ”ç©¶ç°çŠ¶ï¼Œå¹¶å¼ºè°ƒäº†ä»ç„¶éœ€è¦å…³æ³¨çš„æŒ‘æˆ˜ã€‚</td><td>Samuel Louvan   Bernardo Magnini</td></tr></tbody></table></div><h2 id="æ–‡æœ¬ç”Ÿæˆ"><a href="#æ–‡æœ¬ç”Ÿæˆ" class="headerlink" title="æ–‡æœ¬ç”Ÿæˆ"></a>æ–‡æœ¬ç”Ÿæˆ</h2><h3 id="ACL-2"><a href="#ACL-2" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.03432&#39;]">Generalising Multilingual Concept-to-Text NLG with Language Agnostic Delexicalisation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.03432">https://arxiv.org/pdf/2105.03432</a></td><td>Concept-to-text Natural Language Generation is the task of expressing an input meaning representation in natural language. Previous approaches in this task have been able to generalise to rare or unseen instances by relying on a delexicalisation of the input. However, this often requires that the input appears verbatim in the output text. This poses challenges in multilingual settings, where the task expands to generate the output text in multiple languages given the same input. In this paper, we explore the application of multilingual models in concept-to-text and propose Language Agnostic Delexicalisation, a novel delexicalisation method that uses multilingual pretrained embeddings, and employs a character-level post-editing model to inflect words in their correct form during relexicalisation. Our experiments across five datasets and five languages show that multilingual models outperform monolingual models in concept-to-text and that our framework outperforms previous approaches, especially for low resource languages.</td><td>æ¦‚å¿µåˆ°æ–‡æœ¬çš„è‡ªç„¶è¯­è¨€ç”Ÿæˆæ˜¯ç”¨è‡ªç„¶è¯­è¨€è¡¨è¾¾è¾“å…¥æ„ä¹‰è¡¨ç¤ºçš„ä»»åŠ¡ã€‚æ­¤ä»»åŠ¡ä¸­çš„å…ˆå‰æ–¹æ³•å·²ç»èƒ½å¤Ÿé€šè¿‡ä¾èµ–äºè¾“å…¥çš„å»è¯æ³•åŒ–æ¥æ¨å¹¿åˆ°ç½•è§æˆ–çœ‹ä¸è§çš„å®ä¾‹ã€‚ä½†æ˜¯ï¼Œè¿™é€šå¸¸è¦æ±‚è¾“å…¥åœ¨è¾“å‡ºæ–‡æœ¬ä¸­é€å­—æ˜¾ç¤ºã€‚è¿™ç»™å¤šè¯­è¨€è®¾ç½®å¸¦æ¥äº†æŒ‘æˆ˜ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»»åŠ¡æ‰©å±•ä¸ºåœ¨ç»™å®šç›¸åŒè¾“å…¥çš„æƒ…å†µä¸‹ä»¥å¤šç§è¯­è¨€ç”Ÿæˆè¾“å‡ºæ–‡æœ¬ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å¤šè¯­è¨€æ¨¡å‹åœ¨æ¦‚å¿µåˆ°æ–‡æœ¬ä¸­çš„åº”ç”¨ï¼Œå¹¶æå‡ºäº† Language Agnostic Delexicalisationï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„ delexicalisation æ–¹æ³•ï¼Œå®ƒä½¿ç”¨å¤šè¯­è¨€é¢„è®­ç»ƒåµŒå…¥ï¼Œå¹¶é‡‡ç”¨å­—ç¬¦çº§åç¼–è¾‘æ¨¡å‹ä»¥æ­£ç¡®çš„å½¢å¼å¯¹å•è¯è¿›è¡Œå˜å½¢åœ¨è¯æ³•åŒ–è¿‡ç¨‹ä¸­ã€‚æˆ‘ä»¬å¯¹äº”ä¸ªæ•°æ®é›†å’Œäº”ç§è¯­è¨€çš„å®éªŒè¡¨æ˜ï¼Œå¤šè¯­è¨€æ¨¡å‹åœ¨æ¦‚å¿µåˆ°æ–‡æœ¬æ–¹é¢ä¼˜äºå•è¯­æ¨¡å‹ï¼Œå¹¶ä¸”æˆ‘ä»¬çš„æ¡†æ¶ä¼˜äºä»¥å‰çš„æ–¹æ³•ï¼Œå°¤å…¶æ˜¯å¯¹äºä½èµ„æºè¯­è¨€ã€‚</td><td>Giulio Zhou   Gerasimos Lampouras</td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00190&#39;]">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2101.00190">https://arxiv.org/pdf/2101.00190</a></td><td>Fine-tuning is the de facto way to leverage large pretrained language models to perform downstream tasks. However, it modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen, but optimizes a small continuous task-specific vector (called the prefix). Prefix-tuning draws inspiration from prompting, allowing subsequent tokens to attend to this prefix as if it were â€œvirtual tokensâ€. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We find that by learning only 0.1\% of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics unseen during training.</td><td>å¾®è°ƒæ˜¯åˆ©ç”¨å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹æ‰§è¡Œä¸‹æ¸¸ä»»åŠ¡çš„äº‹å®ä¸Šçš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œå®ƒä¿®æ”¹äº†æ‰€æœ‰è¯­è¨€æ¨¡å‹å‚æ•°ï¼Œå› æ­¤éœ€è¦ä¸ºæ¯ä¸ªä»»åŠ¡å­˜å‚¨ä¸€ä¸ªå®Œæ•´çš„å‰¯æœ¬ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å‰ç¼€è°ƒæ•´ï¼Œè¿™æ˜¯è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡å¾®è°ƒçš„è½»é‡çº§æ›¿ä»£æ–¹æ¡ˆï¼Œå®ƒä¿æŒè¯­è¨€æ¨¡å‹å‚æ•°å†»ç»“ï¼Œä½†ä¼˜åŒ–äº†ä¸€ä¸ªå°çš„è¿ç»­ä»»åŠ¡ç‰¹å®šå‘é‡ï¼ˆç§°ä¸ºå‰ç¼€ï¼‰ã€‚å‰ç¼€è°ƒæ•´ä»æç¤ºä¸­æ±²å–çµæ„Ÿï¼Œå…è®¸åç»­æ ‡è®°å…³æ³¨è¿™ä¸ªå‰ç¼€ï¼Œå°±å¥½åƒå®ƒæ˜¯â€œè™šæ‹Ÿæ ‡è®°â€ä¸€æ ·ã€‚æˆ‘ä»¬å°†å‰ç¼€è°ƒæ•´åº”ç”¨äº GPT-2 ä»¥ç”Ÿæˆè¡¨æ ¼åˆ°æ–‡æœ¬ï¼Œå¹¶åº”ç”¨äº BART ä»¥è¿›è¡Œæ±‡æ€»ã€‚æˆ‘ä»¬å‘ç°ï¼Œé€šè¿‡ä»…å­¦ä¹  0.1% çš„å‚æ•°ï¼Œå‰ç¼€è°ƒæ•´åœ¨å…¨æ•°æ®è®¾ç½®ä¸­è·å¾—äº†å¯æ¯”çš„æ€§èƒ½ï¼Œåœ¨ä½æ•°æ®è®¾ç½®ä¸­ä¼˜äºå¾®è°ƒï¼Œå¹¶ä¸”å¯ä»¥æ›´å¥½åœ°å¤–æ¨åˆ°åœ¨è®­ç»ƒæœŸé—´æœªè§è¿‡çš„ä¸»é¢˜çš„ç¤ºä¾‹ã€‚</td><td>Xiang Lisa Li   Percy Liang</td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00288&#39;]">Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models</a></td><td></td><td><a href="https://github.com/tongshuangwu/polyjuice">https://github.com/tongshuangwu/polyjuice</a></td><td><a href="https://arxiv.org/pdf/2101.00288">https://arxiv.org/pdf/2101.00288</a></td><td>While counterfactual examples are useful for analysis and training of NLP models, current generation methods either rely on manual labor to create very few counterfactuals, or only instantiate limited types of perturbations such as paraphrases or word substitutions. We present Polyjuice, a general-purpose counterfactual generator that allows for control over perturbation types and locations, trained by finetuning GPT-2 on multiple datasets of paired sentences. We show that Polyjuice produces diverse sets of realistic counterfactuals, which in turn are useful in various distinct applications: improving training and evaluation on three different tasks (with around 70% less annotation effort than manual generation), augmenting state-of-the-art explanation techniques, and supporting systematic counterfactual error analysis by revealing behaviors easily missed by human experts.</td><td>è™½ç„¶åäº‹å®ç¤ºä¾‹å¯¹äº NLP æ¨¡å‹çš„åˆ†æå’Œè®­ç»ƒå¾ˆæœ‰ç”¨ï¼Œä½†å½“å‰çš„ç”Ÿæˆæ–¹æ³•è¦ä¹ˆä¾é æ‰‹å·¥åŠ³åŠ¨æ¥åˆ›å»ºå¾ˆå°‘çš„åäº‹å®ï¼Œè¦ä¹ˆä»…å®ä¾‹åŒ–æœ‰é™ç±»å‹çš„æ‰°åŠ¨ï¼Œä¾‹å¦‚é‡Šä¹‰æˆ–å•è¯æ›¿æ¢ã€‚æˆ‘ä»¬å±•ç¤ºäº† Polyjuiceï¼Œä¸€ç§é€šç”¨çš„åäº‹å®ç”Ÿæˆå™¨ï¼Œå…è®¸æ§åˆ¶æ‰°åŠ¨ç±»å‹å’Œä½ç½®ï¼Œé€šè¿‡åœ¨å¤šä¸ªæˆå¯¹å¥å­æ•°æ®é›†ä¸Šå¾®è°ƒ GPT-2 è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬å±•ç¤ºäº† Polyjuice äº§ç”Ÿäº†å¤šç§çœŸå®çš„åäº‹å®ï¼Œè¿™äº›åäº‹å®åè¿‡æ¥åˆå¯ç”¨äºå„ç§ä¸åŒçš„åº”ç”¨ï¼šæ”¹è¿›å¯¹ä¸‰ä¸ªä¸åŒä»»åŠ¡çš„è®­ç»ƒå’Œè¯„ä¼°ï¼ˆæ¯”æ‰‹åŠ¨ç”Ÿæˆå‡å°‘å¤§çº¦ 70% çš„æ³¨é‡Šå·¥ä½œï¼‰ï¼Œå¢å¼ºæœ€å…ˆè¿›çš„æŠ€æœ¯è§£é‡ŠæŠ€æœ¯ï¼Œå¹¶é€šè¿‡æ­ç¤ºäººç±»ä¸“å®¶å®¹æ˜“é—æ¼çš„è¡Œä¸ºæ¥æ”¯æŒç³»ç»Ÿçš„åäº‹å®é”™è¯¯åˆ†æã€‚</td><td>Tongshuang Wu   Marco Tulio Ribeiro   Jeffrey Heer   Daniel S. Weld</td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15786&#39;]">Conditional Generation of Temporally-ordered Event Sequences</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15786">https://arxiv.org/pdf/2012.15786</a></td><td>Models of narrative schema knowledge have proven useful for a range of event-related tasks, but they typically do not capture the temporal relationships between events. We propose a single model that addresses both temporal ordering, sorting given events into the order they occurred, and event infilling, predicting new events which fit into an existing temporally-ordered sequence. We use a BART-based conditional generation model that can capture both temporality and common event co-occurrence, meaning it can be flexibly applied to different tasks in this space. Our model is trained as a denoising autoencoder: we take temporally-ordered event sequences, shuffle them, delete some events, and then attempt to recover the original event sequence. This task teaches the model to make inferences given incomplete knowledge about the events in an underlying scenario. On the temporal ordering task, we show that our model is able to unscramble event sequences from existing datasets without access to explicitly labeled temporal training data, outperforming both a BERT-based pairwise model and a BERT-based pointer network. On event infilling, human evaluation shows that our model is able to generate events that fit better temporally into the input events when compared to GPT-2 story completion models.</td><td></td><td>Shih-Ting Lin   Nathanael Chambers   Greg Durrett</td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06471&#39;]">Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.06471">https://arxiv.org/pdf/2106.06471</a></td><td>Medical report generation is one of the most challenging tasks in medical image analysis. Although existing approaches have achieved promising results, they either require a predefined template database in order to retrieve sentences or ignore the hierarchical nature of medical report generation. To address these issues, we propose MedWriter that incorporates a novel hierarchical retrieval mechanism to automatically extract both report and sentence-level templates for clinically accurate report generation. MedWriter first employs the Visual-Language Retrieval~(VLR) module to retrieve the most relevant reports for the given images. To guarantee the logical coherence between sentences, the Language-Language Retrieval~(LLR) module is introduced to retrieve relevant sentences based on the previous generated description. At last, a language decoder fuses image features and features from retrieved reports and sentences to generate meaningful medical reports. We verified the effectiveness of our model by automatic evaluation and human evaluation on two datasets, i.e., Open-I and MIMIC-CXR.</td><td>åŒ»å­¦æŠ¥å‘Šç”Ÿæˆæ˜¯åŒ»å­¦å›¾åƒåˆ†æä¸­æœ€å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¹‹ä¸€ã€‚å°½ç®¡ç°æœ‰æ–¹æ³•å·²ç»å–å¾—äº†å¯å–œçš„æˆæœï¼Œä½†å®ƒä»¬è¦ä¹ˆéœ€è¦ä¸€ä¸ªé¢„å®šä¹‰çš„æ¨¡æ¿æ•°æ®åº“æ¥æ£€ç´¢å¥å­ï¼Œè¦ä¹ˆå¿½ç•¥åŒ»ç–—æŠ¥å‘Šç”Ÿæˆçš„å±‚æ¬¡æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† MedWriterï¼Œå®ƒç»“åˆäº†ä¸€ç§æ–°é¢–çš„åˆ†å±‚æ£€ç´¢æœºåˆ¶ï¼Œå¯ä»¥è‡ªåŠ¨æå–æŠ¥å‘Šå’Œå¥å­çº§æ¨¡æ¿ï¼Œä»¥ç”Ÿæˆä¸´åºŠå‡†ç¡®çš„æŠ¥å‘Šã€‚ MedWriter é¦–å…ˆä½¿ç”¨ Visual-Language Retrieval~(VLR) æ¨¡å—æ¥æ£€ç´¢ç»™å®šå›¾åƒçš„æœ€ç›¸å…³æŠ¥å‘Šã€‚ä¸ºäº†ä¿è¯å¥å­ä¹‹é—´çš„é€»è¾‘è¿è´¯æ€§ï¼Œå¼•å…¥äº†Language-Language Retrieval~(LLR)æ¨¡å—ï¼Œæ ¹æ®ä¹‹å‰ç”Ÿæˆçš„æè¿°æ£€ç´¢ç›¸å…³å¥å­ã€‚æœ€åï¼Œè¯­è¨€è§£ç å™¨å°†å›¾åƒç‰¹å¾ä¸æ£€ç´¢åˆ°çš„æŠ¥å‘Šå’Œå¥å­çš„ç‰¹å¾èåˆï¼Œä»¥ç”Ÿæˆæœ‰æ„ä¹‰çš„åŒ»å­¦æŠ¥å‘Šã€‚æˆ‘ä»¬é€šè¿‡å¯¹ä¸¤ä¸ªæ•°æ®é›†ï¼ˆå³ Open-I å’Œ MIMIC-CXRï¼‰çš„è‡ªåŠ¨è¯„ä¼°å’Œäººå·¥è¯„ä¼°æ¥éªŒè¯æˆ‘ä»¬æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚</td><td>Xingyi Yang   Muchao Ye   Quanzeng You   Fenglong Ma</td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.15053&#39;]">Factorising Meaning and Form for Intent-Preserving Paraphrasing</a></td><td></td><td><a href="https://github.com/tomhosking/separator">https://github.com/tomhosking/separator</a></td><td><a href="https://arxiv.org/pdf/2105.15053">https://arxiv.org/pdf/2105.15053</a></td><td>We propose a method for generating paraphrases of English questions that retain the original intent but use a different surface form. Our model combines a careful choice of training objective with a principled information bottleneck, to induce a latent encoding space that disentangles meaning and form. We train an encoder-decoder model to reconstruct a question from a paraphrase with the same meaning and an exemplar with the same surface form, leading to separated encoding spaces. We use a Vector-Quantized Variational Autoencoder to represent the surface form as a set of discrete latent variables, allowing us to use a classifier to select a different surface form at test time. Crucially, our method does not require access to an external source of target exemplars. Extensive experiments and a human evaluation show that we are able to generate paraphrases with a better tradeoff between semantic preservation and syntactic novelty compared to previous methods.</td><td>æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”Ÿæˆä¿ç•™åŸå§‹æ„å›¾ä½†ä½¿ç”¨ä¸åŒè¡¨é¢å½¢å¼çš„è‹±è¯­é—®é¢˜é‡Šä¹‰çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ¨¡å‹å°†ç²¾å¿ƒé€‰æ‹©çš„è®­ç»ƒç›®æ ‡ä¸åŸåˆ™æ€§çš„ä¿¡æ¯ç“¶é¢ˆç›¸ç»“åˆï¼Œä»¥è¯±å¯¼æ½œåœ¨çš„ç¼–ç ç©ºé—´ï¼Œå°†æ„ä¹‰å’Œå½¢å¼åˆ†å¼€ã€‚æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ï¼Œä»¥ä»å…·æœ‰ç›¸åŒå«ä¹‰çš„é‡Šä¹‰å’Œå…·æœ‰ç›¸åŒè¡¨é¢å½¢å¼çš„ç¤ºä¾‹ä¸­é‡å»ºé—®é¢˜ï¼Œä»è€Œå¯¼è‡´åˆ†ç¦»çš„ç¼–ç ç©ºé—´ã€‚æˆ‘ä»¬ä½¿ç”¨çŸ¢é‡é‡åŒ–å˜åˆ†è‡ªç¼–ç å™¨å°†è¡¨é¢å½¢å¼è¡¨ç¤ºä¸ºä¸€ç»„ç¦»æ•£çš„æ½œåœ¨å˜é‡ï¼Œå…è®¸æˆ‘ä»¬åœ¨æµ‹è¯•æ—¶ä½¿ç”¨åˆ†ç±»å™¨é€‰æ‹©ä¸åŒçš„è¡¨é¢å½¢å¼ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦è®¿é—®ç›®æ ‡ç¤ºä¾‹çš„å¤–éƒ¨æºã€‚å¹¿æ³›çš„å®éªŒå’Œäººå·¥è¯„ä¼°è¡¨æ˜ï¼Œä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬èƒ½å¤Ÿç”Ÿæˆåœ¨è¯­ä¹‰ä¿ç•™å’Œå¥æ³•æ–°é¢–æ€§ä¹‹é—´å…·æœ‰æ›´å¥½æƒè¡¡çš„é‡Šä¹‰ã€‚</td><td>Tom Hosking   Mirella Lapata</td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00210&#39;]">Improving Formality Style Transfer with Context-Aware Rule Injection</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.00210">https://arxiv.org/pdf/2106.00210</a></td><td>Models pre-trained on large-scale regular text corpora often do not work well for user-generated data where the language styles differ significantly from the mainstream text. Here we present Context-Aware Rule Injection (CARI), an innovative method for formality style transfer (FST). CARI injects multiple rules into an end-to-end BERT-based encoder and decoder model. It learns to select optimal rules based on context. The intrinsic evaluation showed that CARI achieved the new highest performance on the FST benchmark dataset. Our extrinsic evaluation showed that CARI can greatly improve the regular pre-trained modelsâ€™ performance on several tweet sentiment analysis tasks.</td><td>åœ¨å¤§è§„æ¨¡å¸¸è§„æ–‡æœ¬è¯­æ–™åº“ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹é€šå¸¸ä¸é€‚ç”¨äºè¯­è¨€é£æ ¼ä¸ä¸»æµæ–‡æœ¬æ˜¾ç€ä¸åŒçš„ç”¨æˆ·ç”Ÿæˆæ•°æ®ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æå‡ºäº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥è§„åˆ™æ³¨å…¥ (CARI)ï¼Œè¿™æ˜¯ä¸€ç§å½¢å¼é£æ ¼è½¬ç§» (FST) çš„åˆ›æ–°æ–¹æ³•ã€‚ CARI å°†å¤šä¸ªè§„åˆ™æ³¨å…¥åŸºäºç«¯åˆ°ç«¯ BERT çš„ç¼–ç å™¨å’Œè§£ç å™¨æ¨¡å‹ã€‚å®ƒå­¦ä¹ æ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©æœ€ä½³è§„åˆ™ã€‚å†…åœ¨è¯„ä¼°è¡¨æ˜ï¼ŒCARI åœ¨ FST åŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æ–°çš„æœ€é«˜æ€§èƒ½ã€‚æˆ‘ä»¬çš„å¤–éƒ¨è¯„ä¼°è¡¨æ˜ï¼ŒCARI å¯ä»¥æå¤§åœ°æé«˜å¸¸è§„é¢„è®­ç»ƒæ¨¡å‹åœ¨å¤šé¡¹æ¨æ–‡æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</td><td>Zonghai Yao   Hong Yu</td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.01875&#39;]">DeepRapper: Neural Rap Generation with Rhyme and Rhythm Modeling</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2107.01875">https://arxiv.org/pdf/2107.01875</a></td><td>Rap generation, which aims to produce lyrics and corresponding singing beats, needs to model both rhymes and rhythms. Previous works for rap generation focused on rhyming lyrics but ignored rhythmic beats, which are important for rap performance. In this paper, we develop DeepRapper, a Transformer-based rap generation system that can model both rhymes and rhythms. Since there is no available rap dataset with rhythmic beats, we develop a data mining pipeline to collect a large-scale rap dataset, which includes a large number of rap songs with aligned lyrics and rhythmic beats. Second, we design a Transformer-based autoregressive language model which carefully models rhymes and rhythms. Specifically, we generate lyrics in the reverse order with rhyme representation and constraint for rhyme enhancement and insert a beat symbol into lyrics for rhythm/beat modeling. To our knowledge, DeepRapper is the first system to generate rap with both rhymes and rhythms. Both objective and subjective evaluations demonstrate that DeepRapper generates creative and high-quality raps with rhymes and rhythms. Code will be released on GitHub.</td><td>Rap ç”Ÿæˆæ—¨åœ¨ç”Ÿæˆæ­Œè¯å’Œç›¸åº”çš„æ­Œå”±èŠ‚æ‹ï¼Œéœ€è¦å¯¹éŸµå¾‹å’ŒèŠ‚å¥è¿›è¡Œå»ºæ¨¡ã€‚ä»¥å‰çš„è¯´å”±åˆ›ä½œä¸“æ³¨äºæŠ¼éŸµæ­Œè¯ï¼Œä½†å¿½ç•¥äº†å¯¹è¯´å”±è¡¨æ¼”å¾ˆé‡è¦çš„èŠ‚å¥èŠ‚æ‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº† DeepRapperï¼Œè¿™æ˜¯ä¸€ç§åŸºäº Transformer çš„è¯´å”±ç”Ÿæˆç³»ç»Ÿï¼Œå¯ä»¥å¯¹éŸµå¾‹å’ŒèŠ‚å¥è¿›è¡Œå»ºæ¨¡ã€‚ç”±äºæ²¡æœ‰å¯ç”¨çš„æœ‰èŠ‚å¥èŠ‚æ‹çš„è¯´å”±æ•°æ®é›†ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªæ•°æ®æŒ–æ˜ç®¡é“æ¥æ”¶é›†å¤§è§„æ¨¡çš„è¯´å”±æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬å¤§é‡å…·æœ‰å¯¹é½æ­Œè¯å’ŒèŠ‚å¥èŠ‚æ‹çš„è¯´å”±æ­Œæ›²ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåŸºäº Transformer çš„è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼Œå®ƒä»”ç»†åœ°å¯¹éŸµå¾‹å’ŒèŠ‚å¥è¿›è¡Œå»ºæ¨¡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä»¥ç›¸åçš„é¡ºåºç”Ÿæˆå¸¦æœ‰éŸµå¾‹è¡¨ç¤ºå’ŒéŸµå¾‹å¢å¼ºçº¦æŸçš„æ­Œè¯ï¼Œå¹¶åœ¨æ­Œè¯ä¸­æ’å…¥èŠ‚æ‹ç¬¦å·ä»¥è¿›è¡ŒèŠ‚å¥/èŠ‚æ‹å»ºæ¨¡ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒDeepRapper æ˜¯ç¬¬ä¸€ä¸ªåŒæ—¶ç”ŸæˆéŸµå¾‹å’ŒèŠ‚å¥çš„è¯´å”±ç³»ç»Ÿã€‚å®¢è§‚å’Œä¸»è§‚çš„è¯„ä»·éƒ½è¡¨æ˜ï¼ŒDeepRapper èƒ½å¤Ÿåˆ›ä½œå‡ºå…·æœ‰éŸµå¾‹å’ŒèŠ‚å¥æ„Ÿçš„åˆ›é€ æ€§å’Œé«˜è´¨é‡çš„è¯´å”±ã€‚ä»£ç å°†åœ¨ GitHub ä¸Šå‘å¸ƒã€‚</td><td>Lanqing Xue   Kaitao Song   Duocai Wu   Xu Tan   Nevin L. Zhang   Tao Qin   Wei-Qiang Zhang   Tie-Yan Liu</td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15329&#39;]">Generating Landmark Navigation Instructions from Maps as a Graph-to-Text Problem</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15329">https://arxiv.org/pdf/2012.15329</a></td><td>Car-focused navigation services are based on turns and distances of named streets, whereas navigation instructions naturally used by humans are centered around physical objects called landmarks. We present a neural model that takes OpenStreetMap representations as input and learns to generate navigation instructions that contain visible and salient landmarks from human natural language instructions. Routes on the map are encoded in a location- and rotation-invariant graph representation that is decoded into natural language instructions. Our work is based on a novel dataset of 7,672 crowd-sourced instances that have been verified by human navigation in Street View. Our evaluation shows that the navigation instructions generated by our system have similar properties as human-generated instructions, and lead to successful human navigation in Street View.</td><td>ä»¥æ±½è½¦ä¸ºä¸­å¿ƒçš„å¯¼èˆªæœåŠ¡åŸºäºå‘½åè¡—é“çš„è½¬å¼¯å’Œè·ç¦»ï¼Œè€Œäººç±»è‡ªç„¶ä½¿ç”¨çš„å¯¼èˆªæŒ‡ä»¤åˆ™ä»¥ç§°ä¸ºåœ°æ ‡çš„ç‰©ç†å¯¹è±¡ä¸ºä¸­å¿ƒã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç¥ç»æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å°† OpenStreetMap è¡¨ç¤ºä½œä¸ºè¾“å…¥ï¼Œå¹¶å­¦ä¹ ç”ŸæˆåŒ…å«æ¥è‡ªäººç±»è‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„å¯è§å’Œæ˜¾ç€åœ°æ ‡çš„å¯¼èˆªæŒ‡ä»¤ã€‚åœ°å›¾ä¸Šçš„è·¯çº¿ä»¥ä½ç½®å’Œæ—‹è½¬ä¸å˜çš„å›¾å½¢è¡¨ç¤ºè¿›è¡Œç¼–ç ï¼Œè¯¥å›¾å½¢è¡¨ç¤ºè¢«è§£ç ä¸ºè‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚æˆ‘ä»¬çš„å·¥ä½œåŸºäºä¸€ä¸ªåŒ…å« 7,672 ä¸ªä¼—åŒ…å®ä¾‹çš„æ–°æ•°æ®é›†ï¼Œè¿™äº›å®ä¾‹å·²é€šè¿‡è¡—æ™¯ä¸­çš„äººå·¥å¯¼èˆªè¿›è¡ŒéªŒè¯ã€‚æˆ‘ä»¬çš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬ç³»ç»Ÿç”Ÿæˆçš„å¯¼èˆªæŒ‡ä»¤ä¸äººå·¥ç”Ÿæˆçš„æŒ‡ä»¤å…·æœ‰ç›¸ä¼¼çš„ç‰¹æ€§ï¼Œå¹¶å¯¼è‡´è¡—æ™¯ä¸­çš„äººå·¥å¯¼èˆªæˆåŠŸã€‚</td><td>Raphael Schumann   Stefan Riezler</td></tr><tr><td>10</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.11134&#39;]">One2Set: Generating Diverse Keyphrases as a Set</a></td><td></td><td><a href="https://github.com/jiacheng-ye/kg_one2set">https://github.com/jiacheng-ye/kg_one2set</a></td><td><a href="https://arxiv.org/pdf/2105.11134">https://arxiv.org/pdf/2105.11134</a></td><td>Recently, the sequence-to-sequence models have made remarkable progress on the task of keyphrase generation (KG) by concatenating multiple keyphrases in a predefined order as a target sequence during training. However, the keyphrases are inherently an unordered set rather than an ordered sequence. Imposing a predefined order will introduce wrong bias during training, which can highly penalize shifts in the order between keyphrases. In this work, we propose a new training paradigm One2Set without predefining an order to concatenate the keyphrases. To fit this paradigm, we propose a novel model that utilizes a fixed set of learned control codes as conditions to generate a set of keyphrases in parallel. To solve the problem that there is no correspondence between each prediction and target during training, we propose a $K$-step target assignment mechanism via bipartite matching, which greatly increases the diversity and reduces the duplication ratio of generated keyphrases. The experimental results on multiple benchmarks demonstrate that our approach significantly outperforms the state-of-the-art methods.</td><td>æœ€è¿‘ï¼Œåºåˆ—åˆ°åºåˆ—æ¨¡å‹é€šè¿‡åœ¨è®­ç»ƒæœŸé—´ä»¥é¢„å®šä¹‰çš„é¡ºåºè¿æ¥å¤šä¸ªå…³é”®çŸ­è¯­ä½œä¸ºç›®æ ‡åºåˆ—ï¼Œåœ¨å…³é”®çŸ­è¯­ç”Ÿæˆ (KG) ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾ç€è¿›å±•ã€‚ç„¶è€Œï¼Œå…³é”®çŸ­è¯­æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªæ— åºçš„é›†åˆï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæœ‰åºçš„åºåˆ—ã€‚å¼ºåŠ é¢„å®šä¹‰çš„é¡ºåºä¼šåœ¨è®­ç»ƒæœŸé—´å¼•å…¥é”™è¯¯çš„åå·®ï¼Œè¿™ä¼šä¸¥é‡å½±å“å…³é”®çŸ­è¯­ä¹‹é—´çš„é¡ºåºå˜åŒ–ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒèŒƒå¼ One2Setï¼Œè€Œæ— éœ€é¢„å…ˆå®šä¹‰è¿æ¥å…³é”®çŸ­è¯­çš„é¡ºåºã€‚ä¸ºäº†é€‚åº”è¿™ç§èŒƒå¼ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨ä¸€ç»„å›ºå®šçš„å­¦ä¹ æ§åˆ¶ä»£ç ä½œä¸ºæ¡ä»¶æ¥å¹¶è¡Œç”Ÿæˆä¸€ç»„å…³é”®çŸ­è¯­ã€‚ä¸ºäº†è§£å†³è®­ç»ƒè¿‡ç¨‹ä¸­æ¯ä¸ªé¢„æµ‹å’Œç›®æ ‡ä¹‹é—´æ²¡æœ‰å¯¹åº”å…³ç³»çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šè¿‡äºŒéƒ¨åŒ¹é…çš„$K$-stepç›®æ ‡åˆ†é…æœºåˆ¶ï¼Œå¤§å¤§å¢åŠ äº†å¤šæ ·æ€§å¹¶å‡å°‘äº†ç”Ÿæˆçš„å…³é”®çŸ­è¯­çš„é‡å¤ç‡ã€‚å¤šä¸ªåŸºå‡†çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜æ˜¾ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</td><td>Jiacheng Ye   Tao Gui   Yichao Luo   Yige Xu   Qi Zhang</td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03829&#39;]">Distilling Knowledge Learned in BERT for Text Generation</a></td><td></td><td><a href="https://github.com/ChenRocks/Distill-BERT-Textgen">https://github.com/ChenRocks/Distill-BERT-Textgen</a></td><td><a href="https://arxiv.org/pdf/1911.03829">https://arxiv.org/pdf/1911.03829</a></td><td>Large-scale pre-trained language model such as BERT has achieved great success in language understanding tasks. However, it remains an open question how to utilize BERT for language generation. In this paper, we present a novel approach, Conditional Masked Language Modeling (C-MLM), to enable the finetuning of BERT on target generation tasks. The finetuned BERT (teacher) is exploited as extra supervision to improve conventional Seq2Seq models (student) for better text generation performance. By leveraging BERTâ€™s idiosyncratic bidirectional nature, distilling knowledge learned in BERT can encourage auto-regressive Seq2Seq models to plan ahead, imposing global sequence-level supervision for coherent text generation. Experiments show that the proposed approach significantly outperforms strong Transformer baselines on multiple language generation tasks such as machine translation and text summarization. Our proposed model also achieves new state of the art on IWSLT German-English and English-Vietnamese MT datasets. Code is available at <a href="https://github.com/ChenRocks/Distill-BERT-Textgen">https://github.com/ChenRocks/Distill-BERT-Textgen</a>.</td><td>BERT ç­‰å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åœ¨è¯­è¨€ç†è§£ä»»åŠ¡ä¸­å–å¾—äº†å·¨å¤§æˆåŠŸã€‚ç„¶è€Œï¼Œå¦‚ä½•åˆ©ç”¨ BERT è¿›è¡Œè¯­è¨€ç”Ÿæˆä»ç„¶æ˜¯ä¸€ä¸ªæ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œå³æ¡ä»¶æ©ç è¯­è¨€å»ºæ¨¡ (C-MLM)ï¼Œä»¥å®ç° BERT åœ¨ç›®æ ‡ç”Ÿæˆä»»åŠ¡ä¸Šçš„å¾®è°ƒã€‚å¾®è°ƒçš„ BERTï¼ˆæ•™å¸ˆï¼‰è¢«ç”¨ä½œé¢å¤–çš„ç›‘ç£æ¥æ”¹è¿›ä¼ ç»Ÿçš„ Seq2Seq æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰ä»¥è·å¾—æ›´å¥½çš„æ–‡æœ¬ç”Ÿæˆæ€§èƒ½ã€‚é€šè¿‡åˆ©ç”¨ BERT çš„ç‰¹æ®ŠåŒå‘æ€§è´¨ï¼Œæç‚¼åœ¨ BERT ä¸­å­¦åˆ°çš„çŸ¥è¯†å¯ä»¥é¼“åŠ±è‡ªå›å½’ Seq2Seq æ¨¡å‹æå‰è®¡åˆ’ï¼Œä¸ºè¿è´¯æ–‡æœ¬ç”Ÿæˆæ–½åŠ å…¨å±€åºåˆ—çº§ç›‘ç£ã€‚å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨æœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬æ‘˜è¦ç­‰å¤šè¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸Šæ˜æ˜¾ä¼˜äºå¼º Transformer åŸºçº¿ã€‚æˆ‘ä»¬æå‡ºçš„æ¨¡å‹è¿˜åœ¨ IWSLT å¾·è¯­-è‹±è¯­å’Œè‹±è¯­-è¶Šå—è¯­ MT æ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€æ–°çš„æŠ€æœ¯æ°´å¹³ã€‚ä»£ç å¯åœ¨ <a href="https://github.com/ChenRocks/Distill-BERT-Textgen">https://github.com/ChenRocks/Distill-BERT-Textgen</a> è·å¾—ã€‚</td><td>Yen-Chun Chen   Zhe Gan   Yu Cheng   Jingzhou Liu   Jingjing Liu</td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.08022&#39;]">Rigid Formats Controlled Text Generation</a></td><td></td><td><a href="https://github.com/lipiji/SongNet">https://github.com/lipiji/SongNet</a></td><td><a href="https://arxiv.org/pdf/2004.08022">https://arxiv.org/pdf/2004.08022</a></td><td>Neural text generation has made tremendous progress in various tasks. One common characteristic of most of the tasks is that the texts are not restricted to some rigid formats when generating. However, we may confront some special text paradigms such as Lyrics (assume the music score is given), Sonnet, SongCi (classical Chinese poetry of the Song dynasty), etc. The typical characteristics of these texts are in three folds: (1) They must comply fully with the rigid predefined formats. (2) They must obey some rhyming schemes. (3) Although they are restricted to some formats, the sentence integrity must be guaranteed. To the best of our knowledge, text generation based on the predefined rigid formats has not been well investigated. Therefore, we propose a simple and elegant framework named SongNet to tackle this problem. The backbone of the framework is a Transformer-based auto-regressive language model. Sets of symbols are tailor-designed to improve the modeling performance especially on format, rhyme, and sentence integrity. We improve the attention mechanism to impel the model to capture some future information on the format. A pre-training and fine-tuning framework is designed to further improve the generation quality. Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates significantly better results in terms of both automatic metrics and the human evaluation.</td><td>ç¥ç»æ–‡æœ¬ç”Ÿæˆåœ¨å„ç§ä»»åŠ¡ä¸­å–å¾—äº†å·¨å¤§çš„è¿›æ­¥ã€‚å¤§å¤šæ•°ä»»åŠ¡çš„ä¸€ä¸ªå…±åŒç‰¹å¾æ˜¯æ–‡æœ¬åœ¨ç”Ÿæˆæ—¶ä¸å—æŸäº›ä¸¥æ ¼æ ¼å¼çš„é™åˆ¶ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šé‡åˆ°ä¸€äº›ç‰¹æ®Šçš„æ–‡æœ¬èŒƒå¼ï¼Œä¾‹å¦‚æ­Œè¯ï¼ˆå‡è®¾ç»™å®šä¹è°±ï¼‰ã€åå››è¡Œè¯—ã€å®‹è¯ï¼ˆå®‹ä»£ä¸­å›½å¤å…¸è¯—æ­Œï¼‰ç­‰ã€‚è¿™äº›æ–‡æœ¬çš„å…¸å‹ç‰¹å¾æœ‰ä¸‰æ–¹é¢ï¼šï¼ˆ1ï¼‰å®ƒä»¬å¿…é¡»å®Œå…¨ç¬¦åˆä¸¥æ ¼çš„é¢„å®šä¹‰æ ¼å¼ã€‚ (2) ä»–ä»¬å¿…é¡»éµå®ˆä¸€äº›æŠ¼éŸµæ–¹æ¡ˆã€‚ (3) è™½ç„¶é™äºæŸäº›æ ¼å¼ï¼Œä½†å¿…é¡»ä¿è¯å¥å­çš„å®Œæ•´æ€§ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒåŸºäºé¢„å®šä¹‰çš„åˆšæ€§æ ¼å¼çš„æ–‡æœ¬ç”Ÿæˆå°šæœªå¾—åˆ°å¾ˆå¥½çš„ç ”ç©¶ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç®€å•è€Œä¼˜é›…çš„æ¡†æ¶ SongNet æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¯¥æ¡†æ¶çš„ä¸»å¹²æ˜¯ä¸€ä¸ªåŸºäº Transformer çš„è‡ªå›å½’è¯­è¨€æ¨¡å‹ã€‚ç¬¦å·é›†æ˜¯é‡èº«å®šåˆ¶çš„ï¼Œä»¥æé«˜å»ºæ¨¡æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨æ ¼å¼ã€éŸµå¾‹å’Œå¥å­å®Œæ•´æ€§æ–¹é¢ã€‚æˆ‘ä»¬æ”¹è¿›äº†æ³¨æ„åŠ›æœºåˆ¶ä»¥ä¿ƒä½¿æ¨¡å‹æ•è·æœ‰å…³æ ¼å¼çš„ä¸€äº›æœªæ¥ä¿¡æ¯ã€‚é¢„è®­ç»ƒå’Œå¾®è°ƒæ¡†æ¶æ—¨åœ¨è¿›ä¸€æ­¥æé«˜ç”Ÿæˆè´¨é‡ã€‚åœ¨ä¸¤ä¸ªæ”¶é›†çš„è¯­æ–™åº“ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ¡†æ¶åœ¨è‡ªåŠ¨åº¦é‡å’Œäººå·¥è¯„ä¼°æ–¹é¢éƒ½äº§ç”Ÿäº†æ˜æ˜¾æ›´å¥½çš„ç»“æœã€‚</td><td>Piji Li   Haisong Zhang   Xiaojiang Liu   Shuming Shi</td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.12704&#39;]">Semantic Graphs for Generating Deep Questions</a></td><td></td><td><a href="https://github.com/WING-NUS/SG-Deep-Question-Generation">https://github.com/WING-NUS/SG-Deep-Question-Generation</a></td><td><a href="https://arxiv.org/pdf/2004.12704">https://arxiv.org/pdf/2004.12704</a></td><td>This paper proposes the problem of Deep Question Generation (DQG), which aims to generate complex questions that require reasoning over multiple pieces of information of the input passage. In order to capture the global structure of the document and facilitate reasoning, we propose a novel framework which first constructs a semantic-level graph for the input document and then encodes the semantic graph by introducing an attention-based GGNN (Att-GGNN). Afterwards, we fuse the document-level and graph-level representations to perform joint training of content selection and question decoding. On the HotpotQA deep-question centric dataset, our model greatly improves performance over questions requiring reasoning over multiple facts, leading to state-of-the-art performance. The code is publicly available at <a href="https://github.com/WING-NUS/SG-Deep-Question-Generation">https://github.com/WING-NUS/SG-Deep-Question-Generation</a>.</td><td>æœ¬æ–‡æå‡ºäº†æ·±åº¦é—®é¢˜ç”Ÿæˆ (DQG) é—®é¢˜ï¼Œæ—¨åœ¨ç”Ÿæˆéœ€è¦å¯¹è¾“å…¥æ®µè½çš„å¤šæ¡ä¿¡æ¯è¿›è¡Œæ¨ç†çš„å¤æ‚é—®é¢˜ã€‚ä¸ºäº†æ•è·æ–‡æ¡£çš„å…¨å±€ç»“æ„å¹¶ä¿ƒè¿›æ¨ç†ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é¦–å…ˆä¸ºè¾“å…¥æ–‡æ¡£æ„å»ºè¯­ä¹‰çº§å›¾ï¼Œç„¶åé€šè¿‡å¼•å…¥åŸºäºæ³¨æ„åŠ›çš„ GGNNï¼ˆAtt-GGNNï¼‰å¯¹è¯­ä¹‰å›¾è¿›è¡Œç¼–ç ã€‚ä¹‹åï¼Œæˆ‘ä»¬èåˆæ–‡æ¡£çº§å’Œå›¾å½¢çº§è¡¨ç¤ºæ¥æ‰§è¡Œå†…å®¹é€‰æ‹©å’Œé—®é¢˜è§£ç çš„è”åˆè®­ç»ƒã€‚åœ¨ HotpotQA ä»¥æ·±åº¦é—®é¢˜ä¸ºä¸­å¿ƒçš„æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¤§å¤§æé«˜äº†éœ€è¦å¯¹å¤šä¸ªäº‹å®è¿›è¡Œæ¨ç†çš„é—®é¢˜çš„æ€§èƒ½ï¼Œä»è€Œè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¯¥ä»£ç å¯åœ¨ <a href="https://github.com/WING-NUS/SG-Deep-Question-Generation">https://github.com/WING-NUS/SG-Deep-Question-Generation</a> ä¸Šå…¬å¼€è·å¾—ã€‚</td><td>Liangming Pan   Yuxi Xie   Yansong Feng   Tat-Seng Chua   Min-Yen Kan</td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14257&#39;]">Politeness Transfer: A Tag and Generate Approach</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14257">https://arxiv.org/pdf/2004.14257</a></td><td>This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the meaning. We also provide a dataset of more than 1.39 instances automatically labeled for politeness to encourage benchmark evaluations on this new task. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For politeness as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for grammaticality, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at <a href="https://github.com/tag-and-generate">https://github.com/tag-and-generate</a>.</td><td>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç¤¼è²Œè½¬ç§»çš„æ–°ä»»åŠ¡ï¼Œå³åœ¨ä¿ç•™æ„ä¹‰çš„åŒæ—¶å°†éç¤¼è²Œå¥å­è½¬æ¢ä¸ºç¤¼è²Œå¥å­ã€‚æˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªåŒ…å«è¶…è¿‡ 1.39 ä¸ªè‡ªåŠ¨æ ‡è®°ç¤¼è²Œçš„å®ä¾‹çš„æ•°æ®é›†ï¼Œä»¥é¼“åŠ±å¯¹è¿™é¡¹æ–°ä»»åŠ¡è¿›è¡ŒåŸºå‡†è¯„ä¼°ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ ‡ç­¾å¹¶ç”Ÿæˆäº†è¯†åˆ«é£æ ¼å±æ€§çš„ç®¡é“ï¼Œéšååœ¨ä¿ç•™å¤§éƒ¨åˆ†æºå†…å®¹çš„åŒæ—¶ä»¥ç›®æ ‡é£æ ¼ç”Ÿæˆäº†ä¸€ä¸ªå¥å­ã€‚å¯¹äºç¤¼è²Œä»¥åŠå…¶ä»–äº”ä¸ªè½¬ç§»ä»»åŠ¡ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å†…å®¹ä¿å­˜çš„è‡ªåŠ¨åº¦é‡æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨æ ·å¼è½¬ç§»å‡†ç¡®æ€§æ–¹é¢å…·æœ‰å¯æ¯”æˆ–æ›´å¥½çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨è¯­æ³•æ–¹é¢è¶…è¶Šäº†ç°æœ‰çš„äººç±»è¯„ä¼°æ–¹æ³•ï¼Œè¿™æ„å‘³ç€åœ¨æ‰€æœ‰å…­ç§é£æ ¼è¿ç§»ä»»åŠ¡ä¸­çš„ä¿ç•™å’Œè¿ç§»å‡†ç¡®æ€§ã€‚æ•°æ®å’Œä»£ç ä½äº <a href="https://github.com/tag-and-generateã€‚">https://github.com/tag-and-generateã€‚</a></td><td>Aman Madaan   Amrith Setlur   Tanmay Parekh   Barnabas Poczos   Graham Neubig   Yiming Yang   Ruslan Salakhutdinov   Alan W Black   Shrimai Prabhumoye</td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.09123&#39;]">GPT-too: A language-model-first approach for AMR-to-text generation</a></td><td></td><td><a href="https://github.com/IBM/GPT-too-AMR2text">https://github.com/IBM/GPT-too-AMR2text</a></td><td><a href="https://arxiv.org/pdf/2005.09123">https://arxiv.org/pdf/2005.09123</a></td><td>Meaning Representations (AMRs) are broad-coverage sentence-level semantic graphs. Existing approaches to generating text from AMR have focused on training sequence-to-sequence or graph-to-sequence models on AMR annotated data only. In this paper, we propose an alternative approach that combines a strong pre-trained language model with cycle consistency-based re-scoring. Despite the simplicity of the approach, our experimental results show these models outperform all previous techniques on the English LDC2017T10dataset, including the recent use of transformer architectures. In addition to the standard evaluation metrics, we provide human evaluation experiments that further substantiate the strength of our approach.</td><td>å«ä¹‰è¡¨ç¤ºï¼ˆAMRï¼‰æ˜¯å¹¿æ³›è¦†ç›–çš„å¥å­çº§è¯­ä¹‰å›¾ã€‚ç°æœ‰çš„ä» AMR ç”Ÿæˆæ–‡æœ¬çš„æ–¹æ³•ä¾§é‡äºä»…åœ¨ AMR æ³¨é‡Šæ•°æ®ä¸Šè®­ç»ƒåºåˆ—åˆ°åºåˆ—æˆ–å›¾åˆ°åºåˆ—æ¨¡å‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›¿ä»£æ–¹æ³•ï¼Œå°†å¼ºå¤§çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸åŸºäºå¾ªç¯ä¸€è‡´æ€§çš„é‡æ–°è¯„åˆ†ç›¸ç»“åˆã€‚å°½ç®¡è¯¥æ–¹æ³•å¾ˆç®€å•ï¼Œä½†æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™äº›æ¨¡å‹åœ¨è‹±å›½ LDC2017T10 æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºä¹‹å‰çš„æ‰€æœ‰æŠ€æœ¯ï¼ŒåŒ…æ‹¬æœ€è¿‘ä½¿ç”¨çš„å˜å‹å™¨æ¶æ„ã€‚é™¤äº†æ ‡å‡†çš„è¯„ä¼°æŒ‡æ ‡å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†äººå·¥è¯„ä¼°å®éªŒï¼Œè¿›ä¸€æ­¥è¯å®äº†æˆ‘ä»¬æ–¹æ³•çš„ä¼˜åŠ¿ã€‚</td><td>Manuel Mager   Ramon Fernandez Astudillo   Tahira Naseem   Md Arafat Sultan   Young-Suk Lee   Radu Florian   Salim Roukos</td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.04560&#39;]">Posterior Control of Blackbox Generation</a></td><td></td><td><a href="https://github.com/XiangLi1999/PosteriorControl-NLG">https://github.com/XiangLi1999/PosteriorControl-NLG</a></td><td><a href="https://arxiv.org/pdf/2005.04560">https://arxiv.org/pdf/2005.04560</a></td><td>Text generation often requires high-precision output that obeys task-specific rules. This fine-grained control is difficult to enforce with off-the-shelf deep learning models. In this work, we consider augmenting neural generation models with discrete control states learned through a structured latent-variable approach. Under this formulation, task-specific knowledge can be encoded through a range of rich, posterior constraints that are effectively trained into the model. This approach allows users to ground internal model decisions based on prior knowledge, without sacrificing the representational power of neural generative models. Experiments consider applications of this approach for text generation. We find that this method improves over standard benchmarks, while also providing fine-grained control.</td><td>æ–‡æœ¬ç”Ÿæˆé€šå¸¸éœ€è¦éµå®ˆç‰¹å®šä»»åŠ¡è§„åˆ™çš„é«˜ç²¾åº¦è¾“å‡ºã€‚è¿™ç§ç»†ç²’åº¦çš„æ§åˆ¶å¾ˆéš¾ç”¨ç°æˆçš„æ·±åº¦å­¦ä¹ æ¨¡å‹æ¥å®æ–½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘ä½¿ç”¨é€šè¿‡ç»“æ„åŒ–æ½œåœ¨å˜é‡æ–¹æ³•å­¦ä¹ çš„ç¦»æ•£æ§åˆ¶çŠ¶æ€æ¥å¢å¼ºç¥ç»ç”Ÿæˆæ¨¡å‹ã€‚åœ¨è¿™ä¸ªå…¬å¼ä¸‹ï¼Œç‰¹å®šä»»åŠ¡çš„çŸ¥è¯†å¯ä»¥é€šè¿‡ä¸€ç³»åˆ—ä¸°å¯Œçš„åéªŒçº¦æŸè¿›è¡Œç¼–ç ï¼Œè¿™äº›çº¦æŸè¢«æœ‰æ•ˆåœ°è®­ç»ƒåˆ°æ¨¡å‹ä¸­ã€‚è¿™ç§æ–¹æ³•å…è®¸ç”¨æˆ·åŸºäºå…ˆéªŒçŸ¥è¯†è¿›è¡Œå†…éƒ¨æ¨¡å‹å†³ç­–ï¼Œè€Œä¸ä¼šç‰ºç‰²ç¥ç»ç”Ÿæˆæ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›ã€‚å®éªŒè€ƒè™‘äº†è¿™ç§æ–¹æ³•åœ¨æ–‡æœ¬ç”Ÿæˆä¸­çš„åº”ç”¨ã€‚æˆ‘ä»¬å‘ç°è¿™ç§æ–¹æ³•æ¯”æ ‡å‡†åŸºå‡†æœ‰æ‰€æ”¹è¿›ï¼ŒåŒæ—¶è¿˜æä¾›äº†ç»†ç²’åº¦çš„æ§åˆ¶ã€‚</td><td>Xiang Lisa Li   Alexander M. Rush</td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.07522&#39;]">Parallel Data Augmentation for Formality Style Transfer</a></td><td></td><td><a href="https://github.com/lancopku/Augmented_Data_for_FST">https://github.com/lancopku/Augmented_Data_for_FST</a></td><td><a href="https://arxiv.org/pdf/2005.07522">https://arxiv.org/pdf/2005.07522</a></td><td>The main barrier to progress in the task of Formality Style Transfer is the inadequacy of training data. In this paper, we study how to augment parallel data and propose novel and simple data augmentation methods for this task to obtain useful sentence pairs with easily accessible models and systems. Experiments demonstrate that our augmented parallel data largely helps improve formality style transfer when it is used to pre-train the model, leading to the state-of-the-art results in the GYAFC benchmark dataset.</td><td>å½¢å¼é£æ ¼è¿ç§»ä»»åŠ¡è¿›å±•çš„ä¸»è¦éšœç¢æ˜¯è®­ç»ƒæ•°æ®çš„ä¸è¶³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶å¦‚ä½•å¢å¼ºå¹¶è¡Œæ•°æ®å¹¶ä¸ºæ­¤ä»»åŠ¡æå‡ºæ–°é¢–ä¸”ç®€å•çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œä»¥è·å¾—å…·æœ‰æ˜“äºè®¿é—®çš„æ¨¡å‹å’Œç³»ç»Ÿçš„æœ‰ç”¨å¥å­å¯¹ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„å¢å¼ºå¹¶è¡Œæ•°æ®åœ¨ç”¨äºé¢„è®­ç»ƒæ¨¡å‹æ—¶åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæœ‰åŠ©äºæ”¹è¿›å½¢å¼é£æ ¼è½¬ç§»ï¼Œä»è€Œåœ¨ GYAFC åŸºå‡†æ•°æ®é›†ä¸­è·å¾—æœ€å…ˆè¿›çš„ç»“æœã€‚</td><td>Yi Zhang   Tao Ge   Xu Sun</td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.01096&#39;]">Neural Data-to-Text Generation via Jointly Learning the Segmentation and Correspondence</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.01096">https://arxiv.org/pdf/2005.01096</a></td><td>The neural attention model has achieved great success in data-to-text generation tasks. Though usually excelling at producing fluent text, it suffers from the problem of information missing, repetition and â€œhallucinationâ€. Due to the black-box nature of the neural attention architecture, avoiding these problems in a systematic way is non-trivial. To address this concern, we propose to explicitly segment target text into fragment units and align them with their data correspondences. The segmentation and correspondence are jointly learned as latent variables without any human annotations. We further impose a soft statistical constraint to regularize the segmental granularity. The resulting architecture maintains the same expressive power as neural attention models, while being able to generate fully interpretable outputs with several times less computational cost. On both E2E and WebNLG benchmarks, we show the proposed model consistently outperforms its neural attention counterparts.</td><td></td><td>Xiaoyu Shen   Ernie Chang   Hui Su   Jie Zhou   Dietrich Klakow</td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.13461&#39;]">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1910.13461">https://arxiv.org/pdf/1910.13461</a></td><td>We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and many other more recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of the original sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa with comparable training resources on GLUE and SQuAD, achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 6 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also report ablation experiments that replicate other pretraining schemes within the BART framework, to better measure which factors most influence end-task performance.</td><td>æˆ‘ä»¬æå‡ºäº† BARTï¼Œä¸€ç§ç”¨äºé¢„è®­ç»ƒåºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„å»å™ªè‡ªåŠ¨ç¼–ç å™¨ã€‚ BART é€šè¿‡ (1) ä½¿ç”¨ä»»æ„å™ªå£°å‡½æ•°ç ´åæ–‡æœ¬å’Œ (2) å­¦ä¹ æ¨¡å‹æ¥é‡å»ºåŸå§‹æ–‡æœ¬è¿›è¡Œè®­ç»ƒã€‚å®ƒä½¿ç”¨æ ‡å‡†çš„åŸºäº Transformer çš„ç¥ç»æœºå™¨ç¿»è¯‘æ¶æ„ï¼Œå°½ç®¡å®ƒå¾ˆç®€å•ï¼Œä½†å¯ä»¥çœ‹ä½œæ˜¯å¯¹ BERTï¼ˆç”±äºåŒå‘ç¼–ç å™¨ï¼‰ã€GPTï¼ˆå¸¦æœ‰ä»å·¦åˆ°å³çš„è§£ç å™¨ï¼‰å’Œè®¸å¤šå…¶ä»–æœ€è¿‘çš„é¢„è®­ç»ƒæ–¹æ¡ˆçš„æ³›åŒ–.æˆ‘ä»¬è¯„ä¼°äº†è®¸å¤šå™ªå£°æ–¹æ³•ï¼Œé€šè¿‡éšæœºæ‰“ä¹±åŸå§‹å¥å­çš„é¡ºåºå’Œä½¿ç”¨æ–°é¢–çš„å¡«å……æ–¹æ¡ˆæ¥æ‰¾åˆ°æœ€ä½³æ€§èƒ½ï¼Œå…¶ä¸­æ–‡æœ¬çš„è·¨åº¦è¢«æ›¿æ¢ä¸ºå•ä¸ªæ©ç æ ‡è®°ã€‚ BART åœ¨é’ˆå¯¹æ–‡æœ¬ç”Ÿæˆè¿›è¡Œå¾®è°ƒæ—¶ç‰¹åˆ«æœ‰æ•ˆï¼Œä½†ä¹Ÿé€‚ç”¨äºç†è§£ä»»åŠ¡ã€‚å®ƒå°† RoBERTa çš„æ€§èƒ½ä¸ GLUE å’Œ SQuAD ä¸Šçš„å¯æ¯”è®­ç»ƒèµ„æºç›¸åŒ¹é…ï¼Œåœ¨ä¸€ç³»åˆ—æŠ½è±¡å¯¹è¯ã€é—®ç­”å’Œæ€»ç»“ä»»åŠ¡ä¸Šå–å¾—äº†æœ€æ–°çš„æœ€æ–°æˆæœï¼Œå¢ç›Šé«˜è¾¾ 6 ROUGEã€‚ BART è¿˜ä¸ºæœºå™¨ç¿»è¯‘æä¾›äº†æ¯”åå‘ç¿»è¯‘ç³»ç»Ÿå¢åŠ  1.1 BLEU çš„èƒ½åŠ›ï¼Œå¹¶ä¸”åªè¿›è¡Œäº†ç›®æ ‡è¯­è¨€é¢„è®­ç»ƒã€‚æˆ‘ä»¬è¿˜æŠ¥å‘Šäº†åœ¨ BART æ¡†æ¶å†…å¤åˆ¶å…¶ä»–é¢„è®­ç»ƒæ–¹æ¡ˆçš„æ¶ˆèå®éªŒï¼Œä»¥æ›´å¥½åœ°è¡¡é‡å“ªäº›å› ç´ å¯¹æœ€ç»ˆä»»åŠ¡æ€§èƒ½å½±å“æœ€å¤§ã€‚</td><td>Mike Lewis   Yinhan Liu   Naman Goyal   Marjan Ghazvininejad   Abdelrahman Mohamed   Omer Levy   Ves Stoyanov   Luke Zettlemoyer</td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03882&#39;]">Pre-train and Plug-in: Flexible Conditional Text Generation with Variational Auto- Encoders</a></td><td></td><td><a href="https://github.com/WHUIR/PPVAE">https://github.com/WHUIR/PPVAE</a></td><td><a href="https://arxiv.org/pdf/1911.03882">https://arxiv.org/pdf/1911.03882</a></td><td>Conditional Text Generation has drawn much attention as a topic of Natural Language Generation (NLG) which provides the possibility for humans to control the properties of generated contents. Current conditional generation models cannot handle emerging conditions due to their joint end-to-end learning fashion. When a new condition added, these techniques require full retraining. In this paper, we present a new framework named Pre-train and Plug-in Variational Auto-Encoder (PPVAE) towards flexible conditional text generation. PPVAE decouples the text generation module from the condition representation module to allow â€œone-to-manyâ€ conditional generation. When a fresh condition emerges, only a lightweight network needs to be trained and works as a plug-in for PPVAE, which is efficient and desirable for real-world applications. Extensive experiments demonstrate the superiority of PPVAE against the existing alternatives with better conditionality and diversity but less training effort.</td><td>æ¡ä»¶æ–‡æœ¬ç”Ÿæˆä½œä¸ºè‡ªç„¶è¯­è¨€ç”Ÿæˆ (NLG) çš„ä¸€ä¸ªä¸»é¢˜å¤‡å—å…³æ³¨ï¼Œå®ƒä¸ºäººç±»æä¾›äº†æ§åˆ¶ç”Ÿæˆå†…å®¹å±æ€§çš„å¯èƒ½æ€§ã€‚ç”±äºå®ƒä»¬çš„è”åˆç«¯åˆ°ç«¯å­¦ä¹ æ–¹å¼ï¼Œå½“å‰çš„æ¡ä»¶ç”Ÿæˆæ¨¡å‹æ— æ³•å¤„ç†æ–°å‡ºç°çš„æ¡ä»¶ã€‚å½“æ·»åŠ æ–°æ¡ä»¶æ—¶ï¼Œè¿™äº›æŠ€æœ¯éœ€è¦å®Œå…¨é‡æ–°è®­ç»ƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåä¸º Pre-train and Plug-in Variational Auto-Encoder (PPVAE) çš„æ–°æ¡†æ¶ï¼Œç”¨äºçµæ´»çš„æ¡ä»¶æ–‡æœ¬ç”Ÿæˆã€‚ PPVAE å°†æ–‡æœ¬ç”Ÿæˆæ¨¡å—ä¸æ¡ä»¶è¡¨ç¤ºæ¨¡å—åˆ†ç¦»ï¼Œä»¥å…è®¸â€œä¸€å¯¹å¤šâ€æ¡ä»¶ç”Ÿæˆã€‚å½“æ–°çš„æ¡ä»¶å‡ºç°æ—¶ï¼Œåªéœ€è¦è®­ç»ƒä¸€ä¸ªè½»é‡çº§ç½‘ç»œï¼Œå¹¶ä½œä¸º PPVAE çš„æ’ä»¶å·¥ä½œï¼Œè¿™å¯¹äºç°å®ä¸–ç•Œçš„åº”ç”¨æ˜¯æœ‰æ•ˆçš„å’Œå¯å–çš„ã€‚å¤§é‡å®éªŒè¯æ˜äº† PPVAE ç›¸å¯¹äºç°æœ‰æ›¿ä»£æ–¹æ¡ˆçš„ä¼˜è¶Šæ€§ï¼Œå…·æœ‰æ›´å¥½çš„æ¡ä»¶å’Œå¤šæ ·æ€§ï¼Œä½†è®­ç»ƒå·¥ä½œé‡æ›´å°‘ã€‚</td><td>Yu Duan   Canwen Xu   Jiaxin Pei   Jialong Han   Chenliang Li</td></tr><tr><td>21</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1909.10158&#39;]">Two Birds, One Stone: A Simple, Unified Model for Text Generation from Structured and Unstructured Data</a></td><td></td><td><a href="https://github.com/h-shahidi/2birds-gen">https://github.com/h-shahidi/2birds-gen</a></td><td><a href="https://arxiv.org/pdf/1909.10158">https://arxiv.org/pdf/1909.10158</a></td><td>A number of researchers have recently questioned the necessity of increasingly complex neural network (NN) architectures. In particular, several recent papers have shown that simpler, properly tuned models are at least competitive across several NLP tasks. In this work, we show that this is also the case for text generation from structured and unstructured data. We consider neural table-to-text generation and neural question generation (NQG) tasks for text generation from structured and unstructured data, respectively. Table-to-text generation aims to generate a description based on a given table, and NQG is the task of generating a question from a given passage where the generated question can be answered by a certain sub-span of the passage using NN models. Experimental results demonstrate that a basic attention-based seq2seq model trained with the exponential moving average technique achieves the state of the art in both tasks. Code is available at <a href="https://github.com/h-shahidi/2birds-gen">https://github.com/h-shahidi/2birds-gen</a>.</td><td>è®¸å¤šç ”ç©¶äººå‘˜æœ€è¿‘è´¨ç–‘æ—¥ç›Šå¤æ‚çš„ç¥ç»ç½‘ç»œ (NN) æ¶æ„çš„å¿…è¦æ€§ã€‚ç‰¹åˆ«æ˜¯ï¼Œæœ€è¿‘çš„å‡ ç¯‡è®ºæ–‡è¡¨æ˜ï¼Œæ›´ç®€å•ã€ç»è¿‡é€‚å½“è°ƒæ•´çš„æ¨¡å‹è‡³å°‘åœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸­å…·æœ‰ç«äº‰åŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜è¿™ä¹Ÿæ˜¯ä»ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®ç”Ÿæˆæ–‡æœ¬çš„æƒ…å†µã€‚æˆ‘ä»¬åˆ†åˆ«è€ƒè™‘ä»ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®ç”Ÿæˆæ–‡æœ¬çš„ç¥ç»è¡¨æ ¼åˆ°æ–‡æœ¬ç”Ÿæˆå’Œç¥ç»é—®é¢˜ç”Ÿæˆ (NQG) ä»»åŠ¡ã€‚è¡¨åˆ°æ–‡æœ¬ç”Ÿæˆæ—¨åœ¨åŸºäºç»™å®šçš„è¡¨ç”Ÿæˆæè¿°ï¼Œè€Œ NQG æ˜¯ä»ç»™å®šçš„æ®µè½ä¸­ç”Ÿæˆé—®é¢˜çš„ä»»åŠ¡ï¼Œå…¶ä¸­ç”Ÿæˆçš„é—®é¢˜å¯ä»¥ä½¿ç”¨ NN æ¨¡å‹é€šè¿‡æ®µè½çš„æŸä¸ªå­è·¨åº¦æ¥å›ç­”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡æŠ€æœ¯è®­ç»ƒçš„åŸºäºæ³¨æ„åŠ›çš„åŸºæœ¬ seq2seq æ¨¡å‹åœ¨è¿™ä¸¤ä¸ªä»»åŠ¡ä¸­éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ã€‚ä»£ç å¯åœ¨ <a href="https://github.com/h-shahidi/2birds-gen">https://github.com/h-shahidi/2birds-gen</a> è·å¾—ã€‚</td><td>Hamidreza Shahidi   Ming Li   Jimmy Lin</td></tr><tr><td>22</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.02247&#39;]">Unsupervised Opinion Summarization as Copycat-Review Generation</a></td><td></td><td><a href="https://github.com/ixlan/CopyCat-abstractive-opinion-summarizer">https://github.com/ixlan/CopyCat-abstractive-opinion-summarizer</a></td><td><a href="https://arxiv.org/pdf/1911.02247">https://arxiv.org/pdf/1911.02247</a></td><td>Opinion summarization is the task of automatically creating summaries that reflect subjective information expressed in multiple documents, such as product reviews. While the majority of previous work has focused on the extractive setting, i.e., selecting fragments from input reviews to produce a summary, we let the model generate novel sentences and hence produce abstractive summaries. Recent progress in summarization has seen the development of supervised models which rely on large quantities of document-summary pairs. Since such training data is expensive to acquire, we instead consider the unsupervised setting, in other words, we do not use any summaries in training. We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the â€œamount of noveltyâ€ going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, when generating summaries, we force the novelty to be minimal, and produce a text reflecting consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder model. Both individual reviews and the products they correspond to are associated with stochastic latent codes, and the review generator (â€œdecoderâ€) has direct access to the text of input reviews through the pointer-generator mechanism. Experiments on Amazon and Yelp datasets, show that setting at test time the reviewâ€™s latent code to its mean, allows the model to produce fluent and coherent summaries reflecting common opinions.</td><td>æ„è§æ‘˜è¦æ˜¯è‡ªåŠ¨åˆ›å»ºåæ˜ åœ¨å¤šä¸ªæ–‡æ¡£ä¸­è¡¨è¾¾çš„ä¸»è§‚ä¿¡æ¯ï¼ˆä¾‹å¦‚äº§å“è¯„è®ºï¼‰çš„æ‘˜è¦çš„ä»»åŠ¡ã€‚è™½ç„¶ä»¥å‰çš„å¤§éƒ¨åˆ†å·¥ä½œéƒ½é›†ä¸­åœ¨æå–è®¾ç½®ä¸Šï¼Œå³ä»è¾“å…¥è¯„è®ºä¸­é€‰æ‹©ç‰‡æ®µä»¥ç”Ÿæˆæ‘˜è¦ï¼Œä½†æˆ‘ä»¬è®©æ¨¡å‹ç”Ÿæˆæ–°é¢–çš„å¥å­ï¼Œä»è€Œç”ŸæˆæŠ½è±¡æ‘˜è¦ã€‚æ‘˜è¦çš„æœ€æ–°è¿›å±•è§è¯äº†ä¾èµ–å¤§é‡æ–‡æ¡£æ‘˜è¦å¯¹çš„ç›‘ç£æ¨¡å‹çš„å‘å±•ã€‚ç”±äºè·å–æ­¤ç±»è®­ç»ƒæ•°æ®çš„æˆæœ¬å¾ˆé«˜ï¼Œå› æ­¤æˆ‘ä»¬è½¬è€Œè€ƒè™‘æ— ç›‘ç£è®¾ç½®ï¼Œæ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒä¸­ä¸ä½¿ç”¨ä»»ä½•æ‘˜è¦ã€‚æˆ‘ä»¬ä¸ºè¯„è®ºé›†åˆå®šä¹‰äº†ä¸€ä¸ªç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨äº†ä¸€ç§ç›´è§‰ï¼Œå³åœ¨ç»™å®šä¸€ç»„äº§å“çš„å…¶ä»–è¯„è®ºç”Ÿæˆæ–°è¯„è®ºæ—¶ï¼Œæˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿæ§åˆ¶è¿›å…¥æ–°è¯„è®ºçš„â€œæ–°é¢–æ€§â€ï¼Œæˆ–è€…ç­‰æ•ˆåœ°ï¼Œæ”¹å˜å®ƒåç¦»è¾“å…¥çš„ç¨‹åº¦ã€‚åœ¨æµ‹è¯•æ—¶ï¼Œåœ¨ç”Ÿæˆæ‘˜è¦æ—¶ï¼Œæˆ‘ä»¬å°†æ–°é¢–æ€§é™è‡³æœ€ä½ï¼Œå¹¶ç”Ÿæˆåæ˜ å…±è¯†æ„è§çš„æ–‡æœ¬ã€‚æˆ‘ä»¬é€šè¿‡å®šä¹‰åˆ†å±‚å˜åˆ†è‡ªç¼–ç å™¨æ¨¡å‹æ¥æ•æ‰è¿™ç§ç›´è§‰ã€‚ä¸ªäººè¯„è®ºå’Œå®ƒä»¬å¯¹åº”çš„äº§å“éƒ½ä¸éšæœºæ½œåœ¨ä»£ç ç›¸å…³è”ï¼Œè¯„è®ºç”Ÿæˆå™¨ï¼ˆâ€œè§£ç å™¨â€ï¼‰å¯ä»¥é€šè¿‡æŒ‡é’ˆç”Ÿæˆå™¨æœºåˆ¶ç›´æ¥è®¿é—®è¾“å…¥è¯„è®ºçš„æ–‡æœ¬ã€‚åœ¨ Amazon å’Œ Yelp æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåœ¨æµ‹è¯•æ—¶å°†è¯„è®ºçš„æ½œåœ¨ä»£ç è®¾ç½®ä¸ºå…¶å¹³å‡å€¼ï¼Œå…è®¸æ¨¡å‹ç”Ÿæˆåæ˜ å…±åŒæ„è§çš„æµç•…å’Œè¿è´¯çš„æ‘˜è¦ã€‚</td><td>Arthur BraÅ¾inskas   Mirella Lapata   Ivan Titov</td></tr><tr><td>23</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.08101&#39;]">Evidence-Aware Inferential Text Generation with Vector Quantised Variational AutoEncoder</a></td><td></td><td><a href="https://github.com/microsoft/EA-VQ-VAE">https://github.com/microsoft/EA-VQ-VAE</a></td><td><a href="https://arxiv.org/pdf/2006.08101">https://arxiv.org/pdf/2006.08101</a></td><td>Generating inferential texts about an event in different perspectives requires reasoning over different contexts that the event occurs. Existing works usually ignore the context that is not explicitly provided, resulting in a context-independent semantic representation that struggles to support the generation. To address this, we propose an approach that automatically finds evidence for an event from a large text corpus, and leverages the evidence to guide the generation of inferential texts. Our approach works in an encoder-decoder manner and is equipped with a Vector Quantised-Variational Autoencoder, where the encoder outputs representations from a distribution over discrete variables. Such discrete representations enable automatically selecting relevant evidence, which not only facilitates evidence-aware generation, but also provides a natural way to uncover rationales behind the generation. Our approach provides state-of-the-art performance on both Event2Mind and ATOMIC datasets. More importantly, we find that with discrete representations, our model selectively uses evidence to generate different inferential texts.</td><td>ä»ä¸åŒè§’åº¦ç”Ÿæˆå…³äºäº‹ä»¶çš„æ¨ç†æ–‡æœ¬éœ€è¦å¯¹äº‹ä»¶å‘ç”Ÿçš„ä¸åŒä¸Šä¸‹æ–‡è¿›è¡Œæ¨ç†ã€‚ç°æœ‰ä½œå“é€šå¸¸ä¼šå¿½ç•¥æœªæ˜ç¡®æä¾›çš„ä¸Šä¸‹æ–‡ï¼Œä»è€Œå¯¼è‡´éš¾ä»¥æ”¯æŒç”Ÿæˆçš„ä¸Šä¸‹æ–‡æ— å…³è¯­ä¹‰è¡¨ç¤ºã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»å¤§å‹æ–‡æœ¬è¯­æ–™åº“ä¸­è‡ªåŠ¨å¯»æ‰¾äº‹ä»¶è¯æ®çš„æ–¹æ³•ï¼Œå¹¶åˆ©ç”¨è¿™äº›è¯æ®æ¥æŒ‡å¯¼æ¨ç†æ–‡æœ¬çš„ç”Ÿæˆã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»¥ç¼–ç å™¨-è§£ç å™¨çš„æ–¹å¼å·¥ä½œï¼Œå¹¶é…å¤‡äº†çŸ¢é‡é‡åŒ–å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼Œå…¶ä¸­ç¼–ç å™¨è¾“å‡ºç¦»æ•£å˜é‡åˆ†å¸ƒçš„è¡¨ç¤ºã€‚è¿™ç§ç¦»æ•£è¡¨ç¤ºèƒ½å¤Ÿè‡ªåŠ¨é€‰æ‹©ç›¸å…³è¯æ®ï¼Œè¿™ä¸ä»…æœ‰åˆ©äºè¯æ®æ„è¯†çš„ç”Ÿæˆï¼Œè€Œä¸”è¿˜æä¾›äº†ä¸€ç§è‡ªç„¶çš„æ–¹å¼æ¥æ­ç¤ºç”ŸæˆèƒŒåçš„åŸºæœ¬åŸç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ Event2Mind å’Œ ATOMIC æ•°æ®é›†ä¸Šéƒ½æä¾›äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°å¯¹äºç¦»æ•£è¡¨ç¤ºï¼Œæˆ‘ä»¬çš„æ¨¡å‹æœ‰é€‰æ‹©åœ°ä½¿ç”¨è¯æ®æ¥ç”Ÿæˆä¸åŒçš„æ¨ç†æ–‡æœ¬ã€‚</td><td>Daya Guo   Duyu Tang   Nan Duan   Jian Yin   Daxin Jiang   Ming Zhou</td></tr><tr><td>24</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04696&#39;]">BLEURT: Learning Robust Metrics for Text Generation</a></td><td></td><td><a href="https://github.com/google-research/bleurt">https://github.com/google-research/bleurt</a></td><td><a href="https://arxiv.org/pdf/2004.04696">https://arxiv.org/pdf/2004.04696</a></td><td>Text generation has made significant advances in the last few years. Yet, evaluation metrics have lagged behind, as the most popular choices (e.g., BLEU and ROUGE) may correlate poorly with human judgments. We propose BLEURT, a learned evaluation metric based on BERT that can model human judgments with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize. BLEURT provides state-of-the-art results on the last three years of the WMT Metrics shared task and the WebNLG Competition dataset. In contrast to a vanilla BERT-based approach, it yields superior results even when the training data is scarce and out-of-distribution.</td><td>æ–‡æœ¬ç”Ÿæˆåœ¨è¿‡å»å‡ å¹´ä¸­å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œè¯„ä¼°æŒ‡æ ‡å·²ç»è½åï¼Œå› ä¸ºæœ€æµè¡Œçš„é€‰æ‹©ï¼ˆä¾‹å¦‚ï¼ŒBLEU å’Œ ROUGEï¼‰å¯èƒ½ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§å¾ˆå·®ã€‚æˆ‘ä»¬æå‡ºäº† BLEURTï¼Œè¿™æ˜¯ä¸€ç§åŸºäº BERT çš„å­¦ä¹ è¯„ä¼°æŒ‡æ ‡ï¼Œå¯ä»¥ç”¨å‡ åƒä¸ªå¯èƒ½æœ‰åè§çš„è®­ç»ƒç¤ºä¾‹å¯¹äººç±»åˆ¤æ–­è¿›è¡Œå»ºæ¨¡ã€‚æˆ‘ä»¬æ–¹æ³•çš„ä¸€ä¸ªå…³é”®æ–¹é¢æ˜¯ä¸€ç§æ–°é¢–çš„é¢„è®­ç»ƒæ–¹æ¡ˆï¼Œå®ƒä½¿ç”¨æ•°ç™¾ä¸‡ä¸ªåˆæˆç¤ºä¾‹æ¥å¸®åŠ©æ¨¡å‹æ³›åŒ–ã€‚ BLEURT æä¾›äº†è¿‡å»ä¸‰å¹´ WMT æŒ‡æ ‡å…±äº«ä»»åŠ¡å’Œ WebNLG ç«èµ›æ•°æ®é›†çš„æœ€æ–°ç»“æœã€‚ä¸åŸºäº BERT çš„æ™®é€šæ–¹æ³•ç›¸æ¯”ï¼Œå³ä½¿è®­ç»ƒæ•°æ®ç¨€ç¼ºä¸”åˆ†å¸ƒä¸å‡æ—¶ï¼Œå®ƒä¹Ÿèƒ½äº§ç”Ÿå‡ºè‰²çš„ç»“æœã€‚</td><td>Thibault Sellam   Dipanjan Das   Ankur P. Parikh</td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01834&#39;]">Automatic Generation of High Quality CCGbanks for Parser Domain Adaptation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.01834">https://arxiv.org/pdf/1906.01834</a></td><td>We propose a new domain adaptation method for Combinatory Categorial Grammar (CCG) parsing, based on the idea of automatic generation of CCG corpora exploiting cheaper resources of dependency trees. Our solution is conceptually simple, and not relying on a specific parser architecture, making it applicable to the current best-performing parsers. We conduct extensive parsing experiments with detailed discussion; on top of existing benchmark datasets on (1) biomedical texts and (2) question sentences, we create experimental datasets of (3) speech conversation and (4) math problems. When applied to the proposed method, an off-the-shelf CCG parser shows significant performance gains, improving from 90.7% to 96.6% on speech conversation, and from 88.5% to 96.8% on math problems.</td><td>æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºç»„åˆåˆ†ç±»è¯­æ³•ï¼ˆCCGï¼‰è§£æçš„æ–°åŸŸé€‚åº”æ–¹æ³•ï¼ŒåŸºäºåˆ©ç”¨ä¾èµ–æ ‘çš„æ›´ä¾¿å®œèµ„æºè‡ªåŠ¨ç”Ÿæˆ CCG è¯­æ–™åº“çš„æ€æƒ³ã€‚æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆåœ¨æ¦‚å¿µä¸Šå¾ˆç®€å•ï¼Œä¸ä¾èµ–äºç‰¹å®šçš„è§£æå™¨æ¶æ„ï¼Œä½¿å…¶é€‚ç”¨äºå½“å‰æ€§èƒ½æœ€ä½³çš„è§£æå™¨ã€‚æˆ‘ä»¬è¿›è¡Œäº†å¹¿æ³›çš„è§£æå®éªŒå¹¶è¿›è¡Œäº†è¯¦ç»†çš„è®¨è®ºï¼›åœ¨ (1) ç”Ÿç‰©åŒ»å­¦æ–‡æœ¬å’Œ (2) é—®é¢˜å¥å­çš„ç°æœ‰åŸºå‡†æ•°æ®é›†ä¹‹ä¸Šï¼Œæˆ‘ä»¬åˆ›å»ºäº† (3) è¯­éŸ³å¯¹è¯å’Œ (4) æ•°å­¦é—®é¢˜çš„å®éªŒæ•°æ®é›†ã€‚å½“åº”ç”¨äºæ‰€æå‡ºçš„æ–¹æ³•æ—¶ï¼Œç°æˆçš„ CCG è§£æå™¨æ˜¾ç¤ºå‡ºæ˜¾ç€çš„æ€§èƒ½æå‡ï¼Œè¯­éŸ³å¯¹è¯ä» 90.7% æé«˜åˆ° 96.6%ï¼Œæ•°å­¦é—®é¢˜ä» 88.5% æé«˜åˆ° 96.8%ã€‚</td><td>Masashi Yoshikawa   Hiroshi Noji   Koji Mineshima   Daisuke Bekki</td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.07870&#39;]">PaperRobot: Incremental Draft Generation of Scientific Ideas</a></td><td></td><td><a href="https://github.com/EagleW/PaperRobot">https://github.com/EagleW/PaperRobot</a></td><td><a href="https://arxiv.org/pdf/1905.07870">https://arxiv.org/pdf/1905.07870</a></td><td>We present a PaperRobot who performs as an automatic research assistant by (1) conducting deep understanding of a large collection of human-written papers in a target domain and constructing comprehensive background knowledge graphs (KGs); (2) creating new ideas by predicting links from the background KGs, by combining graph attention and contextual text attention; (3) incrementally writing some key elements of a new paper based on memory-attention networks: from the input title along with predicted related entities to generate a paper abstract, from the abstract to generate conclusion and future work, and finally from future work to generate a title for a follow-on paper. Turing Tests, where a biomedical domain expert is asked to compare a system output and a human-authored string, show PaperRobot generated abstracts, conclusion and future work sections, and new titles are chosen over human-written ones up to 30%, 24% and 12% of the time, respectively.</td><td>æˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ª PaperRobotï¼Œå®ƒé€šè¿‡ï¼ˆ1ï¼‰å¯¹ç›®æ ‡é¢†åŸŸçš„å¤§é‡äººå·¥è®ºæ–‡è¿›è¡Œæ·±å…¥ç†è§£å¹¶æ„å»ºå…¨é¢çš„èƒŒæ™¯çŸ¥è¯†å›¾ï¼ˆKGï¼‰ï¼› (2) é€šè¿‡ç»“åˆå›¾æ³¨æ„åŠ›å’Œä¸Šä¸‹æ–‡æ–‡æœ¬æ³¨æ„åŠ›ä»èƒŒæ™¯çŸ¥è¯†å›¾è°±ä¸­é¢„æµ‹é“¾æ¥æ¥åˆ›é€ æ–°çš„æƒ³æ³•ï¼› (3) å¢é‡ç¼–å†™åŸºäºè®°å¿†æ³¨æ„åŠ›ç½‘ç»œçš„æ–°è®ºæ–‡çš„ä¸€äº›å…³é”®å…ƒç´ ï¼šä»è¾“å…¥æ ‡é¢˜å’Œé¢„æµ‹çš„ç›¸å…³å®ä½“ç”Ÿæˆè®ºæ–‡æ‘˜è¦ï¼Œä»æ‘˜è¦ç”Ÿæˆç»“è®ºå’Œæœªæ¥å·¥ä½œï¼Œæœ€åä»æœªæ¥å·¥ä½œåˆ°ä¸ºåç»­è®ºæ–‡ç”Ÿæˆæ ‡é¢˜ã€‚å›¾çµæµ‹è¯•ï¼Œè¦æ±‚ç”Ÿç‰©åŒ»å­¦é¢†åŸŸä¸“å®¶æ¯”è¾ƒç³»ç»Ÿè¾“å‡ºå’Œäººå·¥ç¼–å†™çš„å­—ç¬¦ä¸²ï¼Œæ˜¾ç¤º PaperRobot ç”Ÿæˆçš„æ‘˜è¦ã€ç»“è®ºå’Œæœªæ¥å·¥ä½œéƒ¨åˆ†ï¼Œå¹¶ä¸”é€‰æ‹©æ–°æ ‡é¢˜è€Œä¸æ˜¯äººå·¥ç¼–å†™çš„æ ‡é¢˜é«˜è¾¾ 30% å’Œ 24%å’Œ 12% çš„æ—¶é—´ï¼Œåˆ†åˆ«ã€‚</td><td>Qingyun Wang   Lifu Huang   Zhiying Jiang   Kevin Knight   Heng Ji   Mohit Bansal   Yi Luan</td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03221&#39;]">Data-to-text Generation with Entity Modeling</a></td><td></td><td><a href="https://github.com/ratishsp/data2text-entity-py">https://github.com/ratishsp/data2text-entity-py</a></td><td><a href="https://arxiv.org/pdf/1906.03221">https://arxiv.org/pdf/1906.03221</a></td><td>Recent approaches to data-to-text generation have shown great promise thanks to the use of large-scale datasets and the application of neural network architectures which are trained end-to-end. These models rely on representation learning to select content appropriately, structure it coherently, and verbalize it grammatically, treating entities as nothing more than vocabulary tokens. In this work we propose an entity-centric neural architecture for data-to-text generation. Our model creates entity-specific representations which are dynamically updated. Text is generated conditioned on the data input and entity memory representations using hierarchical attention at each time step. We present experiments on the RotoWire benchmark and a (five times larger) new dataset on the baseball domain which we create. Our results show that the proposed model outperforms competitive baselines in automatic and human evaluation.</td><td>ç”±äºå¤§è§„æ¨¡æ•°æ®é›†çš„ä½¿ç”¨å’Œç«¯åˆ°ç«¯è®­ç»ƒçš„ç¥ç»ç½‘ç»œæ¶æ„çš„åº”ç”¨ï¼Œæœ€è¿‘çš„æ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆæ–¹æ³•æ˜¾ç¤ºå‡ºäº†å·¨å¤§çš„å¸Œæœ›ã€‚è¿™äº›æ¨¡å‹ä¾é è¡¨ç¤ºå­¦ä¹ æ¥é€‚å½“åœ°é€‰æ‹©å†…å®¹ã€è¿è´¯åœ°æ„å»ºå†…å®¹å¹¶æŒ‰è¯­æ³•è¡¨è¾¾ï¼Œå°†å®ä½“è§†ä¸ºè¯æ±‡æ ‡è®°ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»¥å®ä½“ä¸ºä¸­å¿ƒçš„ç¥ç»æ¶æ„ï¼Œç”¨äºæ•°æ®åˆ°æ–‡æœ¬çš„ç”Ÿæˆã€‚æˆ‘ä»¬çš„æ¨¡å‹åˆ›å»ºäº†åŠ¨æ€æ›´æ–°çš„ç‰¹å®šäºå®ä½“çš„è¡¨ç¤ºã€‚æ–‡æœ¬æ˜¯æ ¹æ®æ•°æ®è¾“å…¥å’Œå®ä½“å†…å­˜è¡¨ç¤ºåœ¨æ¯ä¸ªæ—¶é—´æ­¥ä½¿ç”¨åˆ†å±‚æ³¨æ„åŠ›ç”Ÿæˆçš„ã€‚æˆ‘ä»¬å±•ç¤ºäº† RotoWire åŸºå‡†æµ‹è¯•å’Œæˆ‘ä»¬åˆ›å»ºçš„æ£’çƒåŸŸä¸Šçš„ï¼ˆå¤§äº”å€ï¼‰æ–°æ•°æ®é›†ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¨¡å‹åœ¨è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°ä¸­ä¼˜äºç«äº‰åŸºçº¿ã€‚</td><td>Ratish Puduppully   Li Dong   Mirella Lapata</td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.03067&#39;]">Key Fact as Pivot: A Two-Stage Model for Low Resource Table-to-Text Generation</a></td><td></td><td><a href="https://github.com/lancopku/Pivot">https://github.com/lancopku/Pivot</a></td><td><a href="https://arxiv.org/pdf/1908.03067">https://arxiv.org/pdf/1908.03067</a></td><td>Table-to-text generation aims to translate the structured data into the unstructured text. Most existing methods adopt the encoder-decoder framework to learn the transformation, which requires large-scale training samples. However, the lack of large parallel data is a major practical problem for many domains. In this work, we consider the scenario of low resource table-to-text generation, where only limited parallel data is available. We propose a novel model to separate the generation into two stages: key fact prediction and surface realization. It first predicts the key facts from the tables, and then generates the text with the key facts. The training of key fact prediction needs much fewer annotated data, while surface realization can be trained with pseudo parallel corpus. We evaluate our model on a biography generation dataset. Our model can achieve $27.34$ BLEU score with only $1,000$ parallel data, while the baseline model only obtain the performance of $9.71$ BLEU score.</td><td>è¡¨åˆ°æ–‡æœ¬ç”Ÿæˆæ—¨åœ¨å°†ç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸ºéç»“æ„åŒ–æ–‡æœ¬ã€‚å¤§å¤šæ•°ç°æœ‰æ–¹æ³•é‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶æ¥å­¦ä¹ è½¬æ¢ï¼Œè¿™éœ€è¦å¤§è§„æ¨¡çš„è®­ç»ƒæ ·æœ¬ã€‚ç„¶è€Œï¼Œç¼ºä¹å¤§å‹å¹¶è¡Œæ•°æ®æ˜¯è®¸å¤šé¢†åŸŸçš„ä¸»è¦å®é™…é—®é¢˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘äº†ä½èµ„æºè¡¨åˆ°æ–‡æœ¬ç”Ÿæˆçš„åœºæ™¯ï¼Œå…¶ä¸­åªæœ‰æœ‰é™çš„å¹¶è¡Œæ•°æ®å¯ç”¨ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¨¡å‹ï¼Œå°†ç”Ÿæˆåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šå…³é”®äº‹å®é¢„æµ‹å’Œè¡¨é¢å®ç°ã€‚å®ƒé¦–å…ˆä»è¡¨æ ¼ä¸­é¢„æµ‹å…³é”®äº‹å®ï¼Œç„¶åç”¨å…³é”®äº‹å®ç”Ÿæˆæ–‡æœ¬ã€‚å…³é”®äº‹å®é¢„æµ‹çš„è®­ç»ƒéœ€è¦æ›´å°‘çš„æ ‡æ³¨æ•°æ®ï¼Œè€Œè¡¨é¢å®ç°å¯ä»¥ç”¨ä¼ªå¹³è¡Œè¯­æ–™åº“è®­ç»ƒã€‚æˆ‘ä»¬åœ¨ä¼ è®°ç”Ÿæˆæ•°æ®é›†ä¸Šè¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¨¡å‹åªéœ€ 1,000 ç¾å…ƒçš„å¹¶è¡Œæ•°æ®å³å¯è·å¾— 27.34 ç¾å…ƒçš„ BLEU åˆ†æ•°ï¼Œè€ŒåŸºå‡†æ¨¡å‹ä»…è·å¾— 9.71 ç¾å…ƒçš„ BLEU åˆ†æ•°ã€‚</td><td>Shuming Ma   Pengcheng Yang   Tianyu Liu   Peng Li   Jie Zhou   Xu Sun</td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.12667&#39;]">Reinforced Dynamic Reasoning for Conversational Question Generation</a></td><td></td><td><a href="https://github.com/ZJULearning/ReDR">https://github.com/ZJULearning/ReDR</a></td><td><a href="https://arxiv.org/pdf/1907.12667">https://arxiv.org/pdf/1907.12667</a></td><td>This paper investigates a new task named Conversational Question Generation (CQG) which is to generate a question based on a passage and a conversation history (i.e., previous turns of question-answer pairs). CQG is a crucial task for developing intelligent agents that can drive question-answering style conversations or test user understanding of a given passage. Towards that end, we propose a new approach named Reinforced Dynamic Reasoning (ReDR) network, which is based on the general encoder-decoder framework but incorporates a reasoning procedure in a dynamic manner to better understand what has been asked and what to ask next about the passage. To encourage producing meaningful questions, we leverage a popular question answering (QA) model to provide feedback and fine-tune the question generator using a reinforcement learning mechanism. Empirical results on the recently released CoQA dataset demonstrate the effectiveness of our method in comparison with various baselines and model variants. Moreover, to show the applicability of our method, we also apply it to create multi-turn question-answering conversations for passages in SQuAD.</td><td></td><td>Boyuan Pan   Hao Li   Ziyu Yao   Deng Cai   Huan Sun</td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.04106&#39;]">Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</a></td><td></td><td><a href="https://github.com/kenchan0226/keyphrase-generation-rl">https://github.com/kenchan0226/keyphrase-generation-rl</a></td><td><a href="https://arxiv.org/pdf/1906.04106">https://arxiv.org/pdf/1906.04106</a></td><td>Generating keyphrases that summarize the main points of a document is a fundamental task in natural language processing. Although existing generative models are capable of predicting multiple keyphrases for an input document as well as determining the number of keyphrases to generate, they still suffer from the problem of generating too few keyphrases. To address this problem, we propose a reinforcement learning (RL) approach for keyphrase generation, with an adaptive reward function that encourages a model to generate both sufficient and accurate keyphrases. Furthermore, we introduce a new evaluation method that incorporates name variations of the ground-truth keyphrases using the Wikipedia knowledge base. Thus, our evaluation method can more robustly evaluate the quality of predicted keyphrases. Extensive experiments on five real-world datasets of different scales demonstrate that our RL approach consistently and significantly improves the performance of the state-of-the-art generative models with both conventional and new evaluation methods.</td><td>ç”Ÿæˆæ€»ç»“æ–‡æ¡£è¦ç‚¹çš„å…³é”®çŸ­è¯­æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ä¸€é¡¹åŸºæœ¬ä»»åŠ¡ã€‚å°½ç®¡ç°æœ‰çš„ç”Ÿæˆæ¨¡å‹èƒ½å¤Ÿé¢„æµ‹è¾“å…¥æ–‡æ¡£çš„å¤šä¸ªå…³é”®çŸ­è¯­ä»¥åŠç¡®å®šè¦ç”Ÿæˆçš„å…³é”®çŸ­è¯­çš„æ•°é‡ï¼Œä½†å®ƒä»¬ä»ç„¶å­˜åœ¨ç”Ÿæˆçš„å…³é”®çŸ­è¯­å¤ªå°‘çš„é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºç”Ÿæˆå…³é”®çŸ­è¯­çš„å¼ºåŒ–å­¦ä¹  (RL) æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…·æœ‰è‡ªé€‚åº”å¥–åŠ±åŠŸèƒ½ï¼Œå¯ä»¥é¼“åŠ±æ¨¡å‹ç”Ÿæˆè¶³å¤Ÿä¸”å‡†ç¡®çš„å…³é”®çŸ­è¯­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ç»´åŸºç™¾ç§‘çŸ¥è¯†åº“ç»“åˆäº†çœŸå®å…³é”®è¯çš„åç§°å˜ä½“ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„è¯„ä¼°æ–¹æ³•å¯ä»¥æ›´ç¨³å¥åœ°è¯„ä¼°é¢„æµ‹çš„å…³é”®çŸ­è¯­çš„è´¨é‡ã€‚å¯¹äº”ä¸ªä¸åŒè§„æ¨¡çš„çœŸå®ä¸–ç•Œæ•°æ®é›†è¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ RL æ–¹æ³•é€šè¿‡ä¼ ç»Ÿå’Œæ–°çš„è¯„ä¼°æ–¹æ³•ä¸€è‡´ä¸”æ˜¾ç€åœ°æé«˜äº†æœ€å…ˆè¿›çš„ç”Ÿæˆæ¨¡å‹çš„æ€§èƒ½ã€‚</td><td>Hou Pong Chan   Wang Chen   Lu Wang   Irwin King</td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03889&#39;]">Topic-Aware Neural Keyphrase Generation for Social Media Language</a></td><td></td><td><a href="https://github.com/yuewang-cuhk/TAKG">https://github.com/yuewang-cuhk/TAKG</a></td><td><a href="https://arxiv.org/pdf/1906.03889">https://arxiv.org/pdf/1906.03889</a></td><td>A huge volume of user-generated content is daily produced on social media. To facilitate automatic language understanding, we study keyphrase prediction, distilling salient information from massive posts. While most existing methods extract words from source posts to form keyphrases, we propose a sequence-to-sequence (seq2seq) based neural keyphrase generation framework, enabling absent keyphrases to be created. Moreover, our model, being topic-aware, allows joint modeling of corpus-level latent topic representations, which helps alleviate the data sparsity that widely exhibited in social media language. Experiments on three datasets collected from English and Chinese social media platforms show that our model significantly outperforms both extraction and generation models that do not exploit latent topics. Further discussions show that our model learns meaningful topics, which interprets its superiority in social media keyphrase generation.</td><td></td><td>Yue Wang   Jing Li   Hou Pong Chan   Irwin King   Michael R. Lyu   Shuming Shi</td></tr><tr><td>32</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03717&#39;]">Argument Generation with Retrieval, Planning, and Realization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.03717">https://arxiv.org/pdf/1906.03717</a></td><td>Automatic argument generation is an appealing but challenging task. In this paper, we study the specific problem of counter-argument generation, and present a novel framework, CANDELA. It consists of a powerful retrieval system and a novel two-step generation model, where a text planning decoder first decides on the main talking points and a proper language style for each sentence, then a content realization decoder reflects the decisions and constructs an informative paragraph-level argument. Furthermore, our generation model is empowered by a retrieval system indexed with 12 million articles collected from Wikipedia and popular English news media, which provides access to high-quality content with diversity. Automatic evaluation on a large-scale dataset collected from Reddit shows that our model yields significantly higher BLEU, ROUGE, and METEOR scores than the state-of-the-art and non-trivial comparisons. Human evaluation further indicates that our system arguments are more appropriate for refutation and richer in content.</td><td>è‡ªåŠ¨å‚æ•°ç”Ÿæˆæ˜¯ä¸€é¡¹æœ‰å¸å¼•åŠ›ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†åè®ºç‚¹ç”Ÿæˆçš„å…·ä½“é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ CANDELAã€‚å®ƒç”±ä¸€ä¸ªå¼ºå¤§çš„æ£€ç´¢ç³»ç»Ÿå’Œä¸€ä¸ªæ–°é¢–çš„ä¸¤æ­¥ç”Ÿæˆæ¨¡å‹ç»„æˆï¼Œå…¶ä¸­æ–‡æœ¬è§„åˆ’è§£ç å™¨é¦–å…ˆå†³å®šæ¯ä¸ªå¥å­çš„ä¸»è¦è°ˆè¯ç‚¹å’Œé€‚å½“çš„è¯­è¨€é£æ ¼ï¼Œç„¶åå†…å®¹å®ç°è§£ç å™¨åæ˜ å†³å®šå¹¶æ„å»ºä¿¡æ¯æ®µè½- çº§åˆ«çš„è®ºç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç”Ÿæˆæ¨¡å‹ç”±ä¸€ä¸ªæ£€ç´¢ç³»ç»Ÿæä¾›æ”¯æŒï¼Œè¯¥æ£€ç´¢ç³»ç»Ÿç´¢å¼•äº†ä»ç»´åŸºç™¾ç§‘å’Œæµè¡Œè‹±è¯­æ–°é—»åª’ä½“æ”¶é›†çš„ 1200 ä¸‡ç¯‡æ–‡ç« ï¼Œå¯æä¾›å¯¹é«˜è´¨é‡å†…å®¹çš„è®¿é—®ã€‚å¯¹ä» Reddit æ”¶é›†çš„å¤§è§„æ¨¡æ•°æ®é›†çš„è‡ªåŠ¨è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹äº§ç”Ÿçš„ BLEUã€ROUGE å’Œ METEOR åˆ†æ•°æ˜æ˜¾é«˜äºæœ€å…ˆè¿›çš„å’Œéå¹³å‡¡çš„æ¯”è¾ƒã€‚äººå·¥è¯„ä¼°è¿›ä¸€æ­¥è¡¨æ˜ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿè®ºç‚¹æ›´é€‚åˆåé©³ï¼Œå†…å®¹æ›´ä¸°å¯Œã€‚</td><td>Xinyu Hua   Zhe Hu   Lu Wang</td></tr><tr><td>33</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.12866&#39;]">Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</a></td><td></td><td><a href="https://github.com/wenhuchen/HDSA-Dialog">https://github.com/wenhuchen/HDSA-Dialog</a></td><td><a href="https://arxiv.org/pdf/1905.12866">https://arxiv.org/pdf/1905.12866</a></td><td>Semantically controlled neural response generation on limited-domain has achieved great performance. However, moving towards multi-domain large-scale scenarios are shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the graph. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the large-scale Multi-Domain-WOZ dataset, our model can yield a significant improvement over the baselines on various automatic and human evaluation metrics.</td><td>åœ¨æœ‰é™åŸŸä¸Šè¯­ä¹‰æ§åˆ¶çš„ç¥ç»å“åº”ç”Ÿæˆå·²ç»å–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç”±äºè¯­ä¹‰è¾“å…¥çš„å¯èƒ½ç»„åˆéšç€åŸŸçš„æ•°é‡å‘ˆæŒ‡æ•°å¢é•¿ï¼Œå› æ­¤è½¬å‘å¤šåŸŸå¤§è§„æ¨¡åœºæ™¯æ˜¯å¾ˆå›°éš¾çš„ã€‚ä¸ºäº†ç¼“è§£è¿™ç§å¯æ‰©å±•æ€§é—®é¢˜ï¼Œæˆ‘ä»¬åˆ©ç”¨å¯¹è¯è¡Œä¸ºçš„ç»“æ„æ¥æ„å»ºå¤šå±‚åˆ†å±‚å›¾ï¼Œå…¶ä¸­æ¯ä¸ªè¡Œä¸ºåœ¨å›¾ä¸Šè¡¨ç¤ºä¸ºä»æ ¹åˆ°å¶çš„è·¯çº¿ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™ç§å…ˆéªŒå›¾ç»“æ„ä½œä¸ºå½’çº³åç½®æ¥æ„å»ºåˆ†å±‚è§£ç¼ ç»“çš„è‡ªæ³¨æ„åŠ›ç½‘ç»œï¼Œåœ¨å…¶ä¸­æˆ‘ä»¬è§£å¼€æ³¨æ„åŠ›å¤´ä»¥æ¨¡æ‹Ÿå¯¹è¯è¡Œä¸ºå›¾ä¸Šçš„æŒ‡å®šèŠ‚ç‚¹ã€‚é€šè¿‡åœ¨æ¯ä¸€å±‚æ¿€æ´»ä¸åŒçš„ï¼ˆè§£å¼€çš„ï¼‰å¤´ï¼Œå¯ä»¥ç»„åˆåœ°å¯¹è®¸å¤šå¯¹è¯è¡Œä¸ºè¯­ä¹‰è¿›è¡Œå»ºæ¨¡ä»¥æ§åˆ¶ç¥ç»å“åº”çš„ç”Ÿæˆã€‚åœ¨å¤§è§„æ¨¡å¤šåŸŸ WOZ æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥åœ¨å„ç§è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°æŒ‡æ ‡çš„åŸºçº¿ä¸Šäº§ç”Ÿæ˜¾ç€æ”¹è¿›ã€‚</td><td>Wenhu Chen   Jianshu Chen   Pengda Qin   Xifeng Yan   William Yang Wang</td></tr><tr><td>34</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01231&#39;]">Coherent Comments Generation for Chinese Articles with a Graph-to-Sequence Model</a></td><td></td><td><a href="https://github.com/lancopku/Graph-to-seq-comment-generation">https://github.com/lancopku/Graph-to-seq-comment-generation</a></td><td><a href="https://arxiv.org/pdf/1906.01231">https://arxiv.org/pdf/1906.01231</a></td><td>Automatic article commenting is helpful in encouraging user engagement and interaction on online news platforms. However, the news documents are usually too long for traditional encoder-decoder based models, which often results in general and irrelevant comments. In this paper, we propose to generate comments with a graph-to-sequence model that models the input news as a topic interaction graph. By organizing the article into graph structure, our model can better understand the internal structure of the article and the connection between topics, which makes it better able to understand the story. We collect and release a large scale news-comment corpus from a popular Chinese online news platform Tencent Kuaibao. Extensive experiment results show that our model can generate much more coherent and informative comments compared with several strong baseline models.</td><td>è‡ªåŠ¨æ–‡ç« è¯„è®ºæœ‰åŠ©äºé¼“åŠ±ç”¨æˆ·åœ¨åœ¨çº¿æ–°é—»å¹³å°ä¸Šå‚ä¸å’Œäº’åŠ¨ã€‚ç„¶è€Œï¼Œå¯¹äºä¼ ç»Ÿçš„åŸºäºç¼–ç å™¨-è§£ç å™¨çš„æ¨¡å‹æ¥è¯´ï¼Œæ–°é—»æ–‡æ¡£é€šå¸¸å¤ªé•¿ï¼Œè¿™é€šå¸¸ä¼šå¯¼è‡´ä¸€èˆ¬å’Œä¸ç›¸å…³çš„è¯„è®ºã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨å›¾åˆ°åºåˆ—æ¨¡å‹ç”Ÿæˆè¯„è®ºï¼Œè¯¥æ¨¡å‹å°†è¾“å…¥æ–°é—»å»ºæ¨¡ä¸ºä¸»é¢˜äº¤äº’å›¾ã€‚é€šè¿‡å°†æ–‡ç« ç»„ç»‡æˆå›¾ç»“æ„ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£æ–‡ç« çš„å†…éƒ¨ç»“æ„å’Œä¸»é¢˜ä¹‹é—´çš„è”ç³»ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£æ•…äº‹ã€‚æˆ‘ä»¬ä»ä¸­å›½æµè¡Œçš„åœ¨çº¿æ–°é—»å¹³å°è…¾è®¯å¿«æŠ¥æ”¶é›†å¹¶å‘å¸ƒäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„æ–°é—»è¯„è®ºè¯­æ–™åº“ã€‚å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸å‡ ä¸ªå¼ºå¤§çš„åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥ç”Ÿæˆæ›´åŠ è¿è´¯å’Œä¿¡æ¯ä¸°å¯Œçš„è¯„è®ºã€‚</td><td>Wei Li   Jingjing Xu   Yancheng He   Shengli Yan   Yunfang Wu   Xu sun</td></tr><tr><td>35</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.02525&#39;]">Cross-Lingual Training for Automatic Question Generation</a></td><td></td><td><a href="https://github.com/vishwajeet93/clqg">https://github.com/vishwajeet93/clqg</a></td><td><a href="https://arxiv.org/pdf/1906.02525">https://arxiv.org/pdf/1906.02525</a></td><td>Automatic question generation (QG) is a challenging problem in natural language understanding. QG systems are typically built assuming access to a large number of training instances where each instance is a question and its corresponding answer. For a new language, such training instances are hard to obtain making the QG problem even more challenging. Using this as our motivation, we study the reuse of an available large QG dataset in a secondary language (e.g. English) to learn a QG model for a primary language (e.g. Hindi) of interest. For the primary language, we assume access to a large amount of monolingual text but only a small QG dataset. We propose a cross-lingual QG model which uses the following training regime: (i) Unsupervised pretraining of language models in both primary and secondary languages and (ii) joint supervised training for QG in both languages. We demonstrate the efficacy of our proposed approach using two different primary languages, Hindi and Chinese. We also create and release a new question answering dataset for Hindi consisting of 6555 sentences.</td><td>è‡ªåŠ¨é—®é¢˜ç”Ÿæˆï¼ˆQGï¼‰æ˜¯è‡ªç„¶è¯­è¨€ç†è§£ä¸­çš„ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚ QG ç³»ç»Ÿé€šå¸¸å‡è®¾è®¿é—®å¤§é‡è®­ç»ƒå®ä¾‹è€Œæ„å»ºï¼Œå…¶ä¸­æ¯ä¸ªå®ä¾‹éƒ½æ˜¯ä¸€ä¸ªé—®é¢˜åŠå…¶ç›¸åº”çš„ç­”æ¡ˆã€‚å¯¹äºä¸€ç§æ–°è¯­è¨€ï¼Œå¾ˆéš¾è·å¾—è¿™æ ·çš„è®­ç»ƒå®ä¾‹ï¼Œè¿™ä½¿å¾— QG é—®é¢˜æ›´å…·æŒ‘æˆ˜æ€§ã€‚ä»¥æ­¤ä¸ºåŠ¨æœºï¼Œæˆ‘ä»¬ç ”ç©¶äº†åœ¨ç¬¬äºŒè¯­è¨€ï¼ˆä¾‹å¦‚è‹±è¯­ï¼‰ä¸­é‡ç”¨å¯ç”¨çš„å¤§å‹ QG æ•°æ®é›†æ¥å­¦ä¹ æ„Ÿå…´è¶£çš„ä¸»è¦è¯­è¨€ï¼ˆä¾‹å¦‚å°åœ°è¯­ï¼‰çš„ QG æ¨¡å‹ã€‚å¯¹äºä¸»è¦è¯­è¨€ï¼Œæˆ‘ä»¬å‡è®¾å¯ä»¥è®¿é—®å¤§é‡å•è¯­æ–‡æœ¬ï¼Œä½†åªèƒ½è®¿é—®ä¸€ä¸ªå°çš„ QG æ•°æ®é›†ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§è·¨è¯­è¨€ QG æ¨¡å‹ï¼Œå®ƒä½¿ç”¨ä»¥ä¸‹è®­ç»ƒæœºåˆ¶ï¼šï¼ˆiï¼‰ä¸»è¦å’Œæ¬¡è¦è¯­è¨€çš„è¯­è¨€æ¨¡å‹çš„æ— ç›‘ç£é¢„è®­ç»ƒå’Œï¼ˆiiï¼‰ä¸¤ç§è¯­è¨€çš„ QG è”åˆç›‘ç£è®­ç»ƒã€‚æˆ‘ä»¬ä½¿ç”¨ä¸¤ç§ä¸åŒçš„ä¸»è¦è¯­è¨€å°åœ°è¯­å’Œä¸­æ–‡è¯æ˜äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬è¿˜ä¸ºå°åœ°è¯­åˆ›å»ºå¹¶å‘å¸ƒäº†ä¸€ä¸ªæ–°çš„é—®ç­”æ•°æ®é›†ï¼Œç”± 6555 ä¸ªå¥å­ç»„æˆã€‚</td><td>Vishwajeet Kumar   Nitish Joshi   Arijit Mukherjee   Ganesh Ramakrishnan   Preethi Jyothi</td></tr><tr><td>36</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.00756&#39;]">Graph Neural Networks with Generated Parameters for Relation Extraction</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.00756">https://arxiv.org/pdf/1902.00756</a></td><td>Recently, progress has been made towards improving relational reasoning in machine learning field. Among existing models, graph neural networks (GNNs) is one of the most effective approaches for multi-hop relational reasoning. In fact, multi-hop relational reasoning is indispensable in many natural language processing tasks such as relation extraction. In this paper, we propose to generate the parameters of graph neural networks (GP-GNNs) according to natural language sentences, which enables GNNs to process relational reasoning on unstructured text inputs. We verify GP-GNNs in relation extraction from text. Experimental results on a human-annotated dataset and two distantly supervised datasets show that our model achieves significant improvements compared to baselines. We also perform a qualitative analysis to demonstrate that our model could discover more accurate relations by multi-hop relational reasoning.</td><td>æœ€è¿‘ï¼Œåœ¨æ”¹è¿›æœºå™¨å­¦ä¹ é¢†åŸŸçš„å…³ç³»æ¨ç†æ–¹é¢å–å¾—äº†è¿›å±•ã€‚åœ¨ç°æœ‰æ¨¡å‹ä¸­ï¼Œå›¾ç¥ç»ç½‘ç»œ (GNN) æ˜¯å¤šè·³å…³ç³»æ¨ç†æœ€æœ‰æ•ˆçš„æ–¹æ³•ä¹‹ä¸€ã€‚äº‹å®ä¸Šï¼Œåœ¨å…³ç³»æŠ½å–ç­‰å¾ˆå¤šè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œå¤šè·³å…³ç³»æ¨ç†æ˜¯å¿…ä¸å¯å°‘çš„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å»ºè®®æ ¹æ®è‡ªç„¶è¯­è¨€å¥å­ç”Ÿæˆå›¾ç¥ç»ç½‘ç»œ (GP-GNN) çš„å‚æ•°ï¼Œè¿™ä½¿ GNN èƒ½å¤Ÿå¤„ç†éç»“æ„åŒ–æ–‡æœ¬è¾“å…¥çš„å…³ç³»æ¨ç†ã€‚æˆ‘ä»¬åœ¨ä»æ–‡æœ¬ä¸­æå–å…³ç³»ä¸­éªŒè¯äº† GP-GNNã€‚åœ¨äººå·¥æ³¨é‡Šæ•°æ®é›†å’Œä¸¤ä¸ªè¿œç¨‹ç›‘ç£æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å–å¾—äº†æ˜¾ç€çš„æ”¹è¿›ã€‚æˆ‘ä»¬è¿˜è¿›è¡Œäº†å®šæ€§åˆ†æï¼Œä»¥è¯æ˜æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥é€šè¿‡å¤šè·³å…³ç³»æ¨ç†å‘ç°æ›´å‡†ç¡®çš„å…³ç³»ã€‚</td><td>Hao Zhu   Yankai Lin   Zhiyuan Liu   Jie Fu   Tat-seng Chua   Maosong Sun</td></tr><tr><td>37</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.09699&#39;]">Learning to Select, Track, and Generate for Data-to-Text</a></td><td></td><td><a href="https://github.com/aistairc/rotowire-modified">https://github.com/aistairc/rotowire-modified</a></td><td><a href="https://arxiv.org/pdf/1907.09699">https://arxiv.org/pdf/1907.09699</a></td><td>We propose a data-to-text generation model with two modules, one for tracking and the other for text generation. Our tracking module selects and keeps track of salient information and memorizes which record has been mentioned. Our generation module generates a summary conditioned on the state of tracking module. Our model is considered to simulate the human-like writing process that gradually selects the information by determining the intermediate variables while writing the summary. In addition, we also explore the effectiveness of the writer information for generation. Experimental results show that our model outperforms existing models in all evaluation metrics even without writer information. Incorporating writer information further improves the performance, contributing to content planning and surface realization.</td><td>æˆ‘ä»¬æå‡ºäº†ä¸€ç§å…·æœ‰ä¸¤ä¸ªæ¨¡å—çš„æ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œä¸€ä¸ªç”¨äºè·Ÿè¸ªï¼Œå¦ä¸€ä¸ªç”¨äºæ–‡æœ¬ç”Ÿæˆã€‚æˆ‘ä»¬çš„è·Ÿè¸ªæ¨¡å—é€‰æ‹©å¹¶è·Ÿè¸ªæ˜¾ç€ä¿¡æ¯å¹¶è®°ä½æåˆ°çš„è®°å½•ã€‚æˆ‘ä»¬çš„ç”Ÿæˆæ¨¡å—æ ¹æ®è·Ÿè¸ªæ¨¡å—çš„çŠ¶æ€ç”Ÿæˆæ‘˜è¦ã€‚æˆ‘ä»¬çš„æ¨¡å‹è¢«è®¤ä¸ºæ˜¯æ¨¡æ‹Ÿç±»äººçš„å†™ä½œè¿‡ç¨‹ï¼Œé€šè¿‡åœ¨æ’°å†™æ‘˜è¦æ—¶ç¡®å®šä¸­é—´å˜é‡æ¥é€æ­¥é€‰æ‹©ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢ç´¢äº†ä½œè€…ä¿¡æ¯å¯¹ç”Ÿæˆçš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿æ²¡æœ‰ä½œè€…ä¿¡æ¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºç°æœ‰æ¨¡å‹ã€‚ç»“åˆä½œè€…ä¿¡æ¯è¿›ä¸€æ­¥æé«˜äº†æ€§èƒ½ï¼Œæœ‰åŠ©äºå†…å®¹è§„åˆ’å’Œè¡¨é¢å®ç°ã€‚</td><td>Hayate Iso   Yui Uehara   Tatsuya Ishigaki   Hiroshi Noji   Eiji Aramaki   Ichiro Kobayashi   Yusuke Miyao   Naoaki Okazaki   Hiroya Takamura</td></tr><tr><td>38</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.08540&#39;]">Predicting Human Activities from User-Generated Content</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1907.08540">https://arxiv.org/pdf/1907.08540</a></td><td>The activities we do are linked to our interests, personality, political preferences, and decisions we make about the future. In this paper, we explore the task of predicting human activities from user-generated content. We collect a dataset containing instances of social media users writing about a range of everyday activities. We then use a state-of-the-art sentence embedding framework tailored to recognize the semantics of human activities and perform an automatic clustering of these activities. We train a neural network model to make predictions about which clusters contain activities that were performed by a given user based on the text of their previous posts and self-description. Additionally, we explore the degree to which incorporating inferred user traits into our model helps with this prediction task.</td><td>æˆ‘ä»¬æ‰€åšçš„æ´»åŠ¨ä¸æˆ‘ä»¬çš„å…´è¶£ã€ä¸ªæ€§ã€æ”¿æ²»åå¥½ä»¥åŠæˆ‘ä»¬å¯¹æœªæ¥æ‰€åšçš„å†³å®šæœ‰å…³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†ä»ç”¨æˆ·ç”Ÿæˆçš„å†…å®¹ä¸­é¢„æµ‹äººç±»æ´»åŠ¨çš„ä»»åŠ¡ã€‚æˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ç¤¾äº¤åª’ä½“ç”¨æˆ·æ’°å†™çš„ä¸€ç³»åˆ—æ—¥å¸¸æ´»åŠ¨çš„å®ä¾‹ã€‚ç„¶åæˆ‘ä»¬ä½¿ç”¨æœ€å…ˆè¿›çš„å¥å­åµŒå…¥æ¡†æ¶æ¥è¯†åˆ«äººç±»æ´»åŠ¨çš„è¯­ä¹‰å¹¶æ‰§è¡Œè¿™äº›æ´»åŠ¨çš„è‡ªåŠ¨èšç±»ã€‚æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œä»¥æ ¹æ®ç»™å®šç”¨æˆ·ä¹‹å‰å¸–å­çš„æ–‡æœ¬å’Œè‡ªæˆ‘æè¿°æ¥é¢„æµ‹å“ªäº›é›†ç¾¤åŒ…å«ç”±ç»™å®šç”¨æˆ·æ‰§è¡Œçš„æ´»åŠ¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å°†æ¨æ–­çš„ç”¨æˆ·ç‰¹å¾åˆå¹¶åˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­æœ‰åŠ©äºæ­¤é¢„æµ‹ä»»åŠ¡çš„ç¨‹åº¦ã€‚</td><td>Steven R. Wilson   Rada Mihalcea</td></tr></tbody></table></div><h3 id="EMNLP-2"><a href="#EMNLP-2" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12328&#39;]">Few-shot Natural Language Generation for Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/pengbaolin/SC-GPT">https://github.com/pengbaolin/SC-GPT</a></td><td><a href="https://arxiv.org/pdf/2002.12328">https://arxiv.org/pdf/2002.12328</a></td><td>As a crucial component in task-oriented dialog systems, the Natural Language Generation (NLG) module converts a dialog act represented in a semantic form into a response in natural language. The success of traditional template-based or statistical models typically relies on heavily annotated data, which is infeasible for new domains. Therefore, it is pivotal for an NLG system to generalize well with limited labelled data in real applications. To this end, we present FewShotWoz, the first NLG benchmark to simulate the few-shot learning setting in task-oriented dialog systems. Further, we develop the SC-GPT model. It is pre-trained on a large set of annotated NLG corpus to acquire the controllable generation ability, and fine-tuned with only a few domain-specific labels to adapt to new domains. Experiments on FewShotWoz and the large Multi-Domain-WOZ datasets show that the proposed SC-GPT significantly outperforms existing methods, measured by various automatic metrics and human evaluations.</td><td>ä½œä¸ºé¢å‘ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿä¸­çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œè‡ªç„¶è¯­è¨€ç”Ÿæˆ (NLG) æ¨¡å—å°†ä»¥è¯­ä¹‰å½¢å¼è¡¨ç¤ºçš„å¯¹è¯è¡Œä¸ºè½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€çš„å“åº”ã€‚ä¼ ç»Ÿçš„åŸºäºæ¨¡æ¿æˆ–ç»Ÿè®¡æ¨¡å‹çš„æˆåŠŸé€šå¸¸ä¾èµ–äºå¤§é‡æ³¨é‡Šçš„æ•°æ®ï¼Œè¿™å¯¹äºæ–°é¢†åŸŸæ˜¯ä¸å¯è¡Œçš„ã€‚å› æ­¤ï¼ŒNLG ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­åˆ©ç”¨æœ‰é™çš„æ ‡è®°æ•°æ®å¾ˆå¥½åœ°æ³›åŒ–æ˜¯è‡³å…³é‡è¦çš„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†FewShotWozï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåœ¨é¢å‘ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿä¸­æ¨¡æ‹Ÿå°æ ·æœ¬å­¦ä¹ è®¾ç½®çš„NLG åŸºå‡†æµ‹è¯•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº† SC-GPT æ¨¡å‹ã€‚å®ƒåœ¨å¤§é‡å¸¦æ³¨é‡Šçš„ NLG è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒä»¥è·å¾—å¯æ§ç”Ÿæˆèƒ½åŠ›ï¼Œå¹¶ä»…ä½¿ç”¨å°‘æ•°ç‰¹å®šé¢†åŸŸçš„æ ‡ç­¾è¿›è¡Œå¾®è°ƒä»¥é€‚åº”æ–°é¢†åŸŸã€‚åœ¨FewShotWoz å’Œå¤§å‹Multi-Domain-WOZ æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„SC-GPT æ˜¾ç€ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œé€šè¿‡å„ç§è‡ªåŠ¨æŒ‡æ ‡å’Œäººå·¥è¯„ä¼°æ¥è¡¡é‡ã€‚</td><td>Baolin Peng   Chenguang Zhu   Chunyuan Li   Xiujun Li   Jinchao Li   Michael Zeng   Jianfeng Gao</td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03587&#39;]">How Decoding Strategies Affect the Verifiability of Generated Text</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1911.03587">https://arxiv.org/pdf/1911.03587</a></td><td>Recent progress in pre-trained language models led to systems that are able to generate text of an increasingly high quality. While several works have investigated the fluency and grammatical correctness of such models, it is still unclear to which extent the generated text is consistent with factual world knowledge. Here, we go beyond fluency and also investigate the verifiability of text generated by state-of-the-art pre-trained language models. A generated sentence is verifiable if it can be corroborated or disproved by Wikipedia, and we find that the verifiability of generated text strongly depends on the decoding strategy. In particular, we discover a tradeoff between factuality (i.e., the ability of generating Wikipedia corroborated text) and repetitiveness. While decoding strategies such as top-k and nucleus sampling lead to less repetitive generations, they also produce less verifiable text. Based on these finding, we introduce a simple and effective decoding strategy which, in comparison to previously used decoding strategies, produces less repetitive and more verifiable text.</td><td>é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æœ€æ–°è¿›å±•å¯¼è‡´ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆè´¨é‡è¶Šæ¥è¶Šé«˜çš„æ–‡æœ¬ã€‚è™½ç„¶æœ‰å‡ é¡¹å·¥ä½œè°ƒæŸ¥äº†æ­¤ç±»æ¨¡å‹çš„æµç•…æ€§å’Œè¯­æ³•æ­£ç¡®æ€§ï¼Œä½†ä»ä¸æ¸…æ¥šç”Ÿæˆçš„æ–‡æœ¬åœ¨å¤šå¤§ç¨‹åº¦ä¸Šä¸äº‹å®ä¸–ç•ŒçŸ¥è¯†ä¸€è‡´ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è¶…è¶Šäº†æµç•…æ€§ï¼Œè¿˜ç ”ç©¶äº†ç”±æœ€å…ˆè¿›çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬çš„å¯éªŒè¯æ€§ã€‚å¦‚æœç”Ÿæˆçš„å¥å­å¯ä»¥è¢«ç»´åŸºç™¾ç§‘è¯å®æˆ–åé©³ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯å¯éªŒè¯çš„ï¼Œæˆ‘ä»¬å‘ç°ç”Ÿæˆæ–‡æœ¬çš„å¯éªŒè¯æ€§åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºè§£ç ç­–ç•¥ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å‘ç°äº†äº‹å®æ€§ï¼ˆå³ç”Ÿæˆç»´åŸºç™¾ç§‘ç¡®è¯æ–‡æœ¬çš„èƒ½åŠ›ï¼‰å’Œé‡å¤æ€§ä¹‹é—´çš„æƒè¡¡ã€‚è™½ç„¶è¯¸å¦‚ top-k å’Œæ ¸é‡‡æ ·ä¹‹ç±»çš„è§£ç ç­–ç•¥ä¼šå‡å°‘é‡å¤ç”Ÿæˆï¼Œä½†å®ƒä»¬ä¹Ÿä¼šäº§ç”Ÿè¾ƒå°‘çš„å¯éªŒè¯æ–‡æœ¬ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„è§£ç ç­–ç•¥ï¼Œä¸ä»¥å‰ä½¿ç”¨çš„è§£ç ç­–ç•¥ç›¸æ¯”ï¼Œè¯¥ç­–ç•¥äº§ç”Ÿçš„æ–‡æœ¬é‡å¤æ€§æ›´ä½ä¸”å¯éªŒè¯æ€§æ›´é«˜ã€‚</td><td>Luca Massarelli   Fabio Petroni   Aleksandra Piktus   Myle Ott   Tim RocktÃ¤schel   Vassilis Plachouras   Fabrizio Silvestri   Sebastian Riedel</td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14983&#39;]">Control, Generate, Augment: A Scalable Framework for Multi-Attribute Text Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14983">https://arxiv.org/pdf/2004.14983</a></td><td>We introduce CGA, a conditional VAE architecture, to control, generate, and augment text. CGA is able to generate natural English sentences controlling multiple semantic and syntactic attributes by combining adversarial learning with a context-aware loss and a cyclical word dropout routine. We demonstrate the value of the individual model components in an ablation study. The scalability of our approach is ensured through a single discriminator, independently of the number of attributes. We show high quality, diversity and attribute control in the generated sentences through a series of automatic and human assessments. As the main application of our work, we test the potential of this new NLG model in a data augmentation scenario. In a downstream NLP task, the sentences generated by our CGA model show significant improvements over a strong baseline, and a classification performance often comparable to adding same amount of additional real data.</td><td>æˆ‘ä»¬å¼•å…¥äº† CGAï¼Œä¸€ç§æœ‰æ¡ä»¶çš„ VAE æ¶æ„ï¼Œæ¥æ§åˆ¶ã€ç”Ÿæˆå’Œå¢åŠ æ–‡æœ¬ã€‚ CGA èƒ½å¤Ÿé€šè¿‡å°†å¯¹æŠ—æ€§å­¦ä¹ ä¸ä¸Šä¸‹æ–‡æ„ŸçŸ¥æŸå¤±å’Œå¾ªç¯è¯ä¸¢å¤±ä¾‹ç¨‹ç›¸ç»“åˆï¼Œç”Ÿæˆæ§åˆ¶å¤šä¸ªè¯­ä¹‰å’Œå¥æ³•å±æ€§çš„è‡ªç„¶è‹±è¯­å¥å­ã€‚æˆ‘ä»¬åœ¨æ¶ˆèç ”ç©¶ä¸­å±•ç¤ºäº†å„ä¸ªæ¨¡å‹ç»„ä»¶çš„ä»·å€¼ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„å¯æ‰©å±•æ€§æ˜¯é€šè¿‡å•ä¸ªé‰´åˆ«å™¨æ¥ç¡®ä¿çš„ï¼Œä¸å±æ€§çš„æ•°é‡æ— å…³ã€‚æˆ‘ä»¬é€šè¿‡ä¸€ç³»åˆ—è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°åœ¨ç”Ÿæˆçš„å¥å­ä¸­å±•ç¤ºäº†é«˜è´¨é‡ã€å¤šæ ·æ€§å’Œå±æ€§æ§åˆ¶ã€‚ä½œä¸ºæˆ‘ä»¬å·¥ä½œçš„ä¸»è¦åº”ç”¨ï¼Œæˆ‘ä»¬åœ¨æ•°æ®å¢å¼ºåœºæ™¯ä¸­æµ‹è¯•äº†è¿™ç§æ–°çš„ NLG æ¨¡å‹çš„æ½œåŠ›ã€‚åœ¨ä¸‹æ¸¸ NLP ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬çš„ CGA æ¨¡å‹ç”Ÿæˆçš„å¥å­åœ¨å¼ºå¤§çš„åŸºçº¿ä¸Šæ˜¾ç¤ºå‡ºæ˜¾ç€çš„æ”¹è¿›ï¼Œå¹¶ä¸”åˆ†ç±»æ€§èƒ½é€šå¸¸ä¸æ·»åŠ ç›¸åŒæ•°é‡çš„é¢å¤–çœŸå®æ•°æ®ç›¸å½“ã€‚</td><td>Giuseppe Russo   Nora Hollenstein   Claudiu Musat   Ce Zhang</td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.07576&#39;]">Pretrained Language Models for Dialogue Generation with Multiple Input Sources</a></td><td></td><td><a href="https://github.com/caoyu-noob/Multi-GPT2">https://github.com/caoyu-noob/Multi-GPT2</a></td><td><a href="https://arxiv.org/pdf/2010.07576">https://arxiv.org/pdf/2010.07576</a></td><td>Large-scale pretrained language models have achieved outstanding performance on natural language understanding tasks. However, it is still under investigating how to apply them to dialogue generation tasks, especially those with responses conditioned on multiple sources. Previous work simply concatenates all input sources or averages information from different input sources. In this work, we study dialogue models with multiple input sources adapted from the pretrained language model GPT2. We explore various methods to fuse multiple separate attention information corresponding to different sources. Our experimental results show that proper fusion methods deliver higher relevance with dialogue history than simple fusion baselines.</td><td>å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ä¸Šå–å¾—äº†å‡ºè‰²çš„è¡¨ç°ã€‚ç„¶è€Œï¼Œå®ƒä»åœ¨ç ”ç©¶å¦‚ä½•å°†å®ƒä»¬åº”ç”¨äºå¯¹è¯ç”Ÿæˆä»»åŠ¡ï¼Œå°¤å…¶æ˜¯é‚£äº›ä»¥å¤šä¸ªæ¥æºä¸ºæ¡ä»¶çš„å“åº”ã€‚ä»¥å‰çš„å·¥ä½œåªæ˜¯è¿æ¥æ‰€æœ‰è¾“å…¥æºæˆ–å¹³å‡æ¥è‡ªä¸åŒè¾“å…¥æºçš„ä¿¡æ¯ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä»é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ GPT2 æ”¹ç¼–è€Œæ¥çš„å…·æœ‰å¤šä¸ªè¾“å…¥æºçš„å¯¹è¯æ¨¡å‹ã€‚æˆ‘ä»¬æ¢ç´¢äº†å„ç§æ–¹æ³•æ¥èåˆå¯¹åº”äºä¸åŒæ¥æºçš„å¤šä¸ªå•ç‹¬çš„æ³¨æ„åŠ›ä¿¡æ¯ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç®€å•çš„èåˆåŸºçº¿ç›¸æ¯”ï¼Œé€‚å½“çš„èåˆæ–¹æ³•ä¸å¯¹è¯å†å²çš„ç›¸å…³æ€§æ›´é«˜ã€‚</td><td>Yu Cao   Wei Bi   Meng Fang   Dacheng Tao</td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14579&#39;]">Logic2Text: High-Fidelity Natural Language Generation from Logical Forms</a></td><td></td><td><a href="https://github.com/czyssrs/Logic2Text">https://github.com/czyssrs/Logic2Text</a></td><td><a href="https://arxiv.org/pdf/2004.14579">https://arxiv.org/pdf/2004.14579</a></td><td>Previous works on Natural Language Generation (NLG) from structured data have primarily focused on surface-level descriptions of record sequences. However, for complex structured data, e.g., multi-row tables, it is often desirable for an NLG system to describe interesting facts from logical inferences across records. If only provided with the table, it is hard for existing models to produce controllable and high-fidelity logical generations. In this work, we formulate logical level NLG as generation from logical forms in order to obtain controllable, high-fidelity, and faithful generations. We present a new large-scale dataset, \textsc{Logic2Text}, with 10,753 descriptions involving common logic types paired with the underlying logical forms. The logical forms show diversified graph structure of free schema, which poses great challenges on the modelâ€™s ability to understand the semantics. We experiment on (1) Fully-supervised training with the full datasets, and (2) Few-shot setting, provided with hundreds of paired examples; We compare several popular generation models and analyze their performances. We hope our dataset can encourage research towards building an advanced NLG system capable of natural, faithful, and human-like generation. The dataset and code are available at <a href="https://github.com/czyssrs/Logic2Text">https://github.com/czyssrs/Logic2Text</a>.</td><td>ä»¥å‰ä»ç»“æ„åŒ–æ•°æ®ä¸­ç”Ÿæˆè‡ªç„¶è¯­è¨€ (NLG) çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨è®°å½•åºåˆ—çš„è¡¨é¢çº§æè¿°ä¸Šã€‚ç„¶è€Œï¼Œå¯¹äºå¤æ‚çš„ç»“æ„åŒ–æ•°æ®ï¼Œä¾‹å¦‚å¤šè¡Œè¡¨ï¼ŒNLG ç³»ç»Ÿé€šå¸¸å¸Œæœ›é€šè¿‡è·¨è®°å½•çš„é€»è¾‘æ¨ç†æ¥æè¿°æœ‰è¶£çš„äº‹å®ã€‚å¦‚æœåªæä¾›è¡¨æ ¼ï¼Œç°æœ‰æ¨¡å‹å¾ˆéš¾äº§ç”Ÿå¯æ§ä¸”é«˜ä¿çœŸçš„é€»è¾‘ä»£ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å°†é€»è¾‘å±‚æ¬¡ NLG åˆ¶å®šä¸ºé€»è¾‘å½¢å¼çš„ä»£ï¼Œä»¥è·å¾—å¯æ§ã€é«˜ä¿çœŸå’Œå¿ å®çš„ä»£ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„å¤§è§„æ¨¡æ•°æ®é›† \textsc{Logic2Text}ï¼Œå…¶ä¸­åŒ…å« 10,753 ä¸ªæè¿°ï¼Œæ¶‰åŠä¸åº•å±‚é€»è¾‘å½¢å¼é…å¯¹çš„å¸¸è§é€»è¾‘ç±»å‹ã€‚é€»è¾‘å½¢å¼è¡¨ç°å‡ºè‡ªç”±æ¨¡å¼çš„å¤šæ ·åŒ–å›¾ç»“æ„ï¼Œè¿™å¯¹æ¨¡å‹çš„è¯­ä¹‰ç†è§£èƒ½åŠ›æå‡ºäº†å¾ˆå¤§çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬å¯¹ (1) ä½¿ç”¨å®Œæ•´æ•°æ®é›†è¿›è¡Œå…¨ç›‘ç£è®­ç»ƒï¼Œä»¥åŠ (2) å°æ ·æœ¬è®¾ç½®è¿›è¡Œå®éªŒï¼Œæä¾›æ•°ç™¾ä¸ªé…å¯¹ç¤ºä¾‹ï¼›æˆ‘ä»¬æ¯”è¾ƒäº†å‡ ç§æµè¡Œçš„ç”Ÿæˆæ¨¡å‹å¹¶åˆ†æäº†å®ƒä»¬çš„æ€§èƒ½ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ•°æ®é›†èƒ½å¤Ÿé¼“åŠ±ç ”ç©¶å»ºç«‹ä¸€ä¸ªèƒ½å¤Ÿè‡ªç„¶ã€å¿ å®å’Œç±»äººç”Ÿæˆçš„å…ˆè¿› NLG ç³»ç»Ÿã€‚æ•°æ®é›†å’Œä»£ç å¯ä» <a href="https://github.com/czyssrs/Logic2Text">https://github.com/czyssrs/Logic2Text</a> è·å¾—ã€‚</td><td>Zhiyu Chen   Wenhu Chen   Hanwen Zha   Xiyou Zhou   Yunkai Zhang   Sairam Sundaresan   William Yang Wang</td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.10056&#39;]">Composed Variational Natural Language Generation for Few-shot Intents</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.10056">https://arxiv.org/pdf/2009.10056</a></td><td>In this paper, we focus on generating training examples for few-shot intents in the realistic imbalanced scenario. To build connections between existing many-shot intents and few-shot intents, we consider an intent as a combination of a domain and an action, and propose a composed variational natural language generator (CLANG), a transformer-based conditional variational autoencoder. CLANG utilizes two latent variables to represent the utterances corresponding to two different independent parts (domain and action) in the intent, and the latent variables are composed together to generate natural examples. Additionally, to improve the generator learning, we adopt the contrastive regularization loss that contrasts the in-class with the out-of-class utterance generation given the intent. To evaluate the quality of the generated utterances, experiments are conducted on the generalized few-shot intent detection task. Empirical results show that our proposed model achieves state-of-the-art performances on two real-world intent detection datasets.</td><td>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸“æ³¨äºä¸ºç°å®ä¸å¹³è¡¡åœºæ™¯ä¸­çš„å°æ ·æœ¬æ„å›¾ç”Ÿæˆè®­ç»ƒç¤ºä¾‹ã€‚ä¸ºäº†åœ¨ç°æœ‰çš„å¤šæ ·æœ¬æ„å›¾å’Œå°‘æ ·æœ¬æ„å›¾ä¹‹é—´å»ºç«‹è”ç³»ï¼Œæˆ‘ä»¬å°†æ„å›¾è§†ä¸ºåŸŸå’ŒåŠ¨ä½œçš„ç»„åˆï¼Œå¹¶æå‡ºäº†ä¸€ç§ç»„åˆå˜åˆ†è‡ªç„¶è¯­è¨€ç”Ÿæˆå™¨ (CLANG)ï¼Œä¸€ç§åŸºäºè½¬æ¢å™¨çš„æ¡ä»¶å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ã€‚ CLANG åˆ©ç”¨ä¸¤ä¸ªæ½œåœ¨å˜é‡æ¥è¡¨ç¤ºæ„å›¾ä¸­ä¸¤ä¸ªä¸åŒç‹¬ç«‹éƒ¨åˆ†ï¼ˆé¢†åŸŸå’ŒåŠ¨ä½œï¼‰å¯¹åº”çš„è¯è¯­ï¼Œå¹¶å°†æ½œåœ¨å˜é‡ç»„åˆåœ¨ä¸€èµ·ä»¥ç”Ÿæˆè‡ªç„¶ç¤ºä¾‹ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ”¹è¿›ç”Ÿæˆå™¨å­¦ä¹ ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å¯¹æ¯”æ­£åˆ™åŒ–æŸå¤±ï¼Œå°†ç»™å®šæ„å›¾çš„è¯¾å ‚å†…è¯è¯­ç”Ÿæˆä¸è¯¾å ‚å¤–è¯è¯­ç”Ÿæˆè¿›è¡Œå¯¹æ¯”ã€‚ä¸ºäº†è¯„ä¼°ç”Ÿæˆçš„è¯è¯­çš„è´¨é‡ï¼Œå¯¹å¹¿ä¹‰çš„å°æ ·æœ¬æ„å›¾æ£€æµ‹ä»»åŠ¡è¿›è¡Œäº†å®éªŒã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ¨¡å‹åœ¨ä¸¤ä¸ªçœŸå®ä¸–ç•Œçš„æ„å›¾æ£€æµ‹æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</td><td>Congying Xia   Caiming Xiong   Philip Yu   Richard Socher</td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.00910&#39;]">Continual Learning for Natural Language Generation in Task-oriented Dialog Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.00910">https://arxiv.org/pdf/2010.00910</a></td><td>Natural language generation (NLG) is an essential component of task-oriented dialog systems. Despite the recent success of neural approaches for NLG, they are typically developed in an offline manner for particular domains. To better fit real-life applications where new data come in a stream, we study NLG in a â€œcontinual learningâ€ setting to expand its knowledge to new domains or functionalities incrementally. The major challenge towards this goal is catastrophic forgetting, meaning that a continually trained model tends to forget the knowledge it has learned before. To this end, we propose a method called ARPER (Adaptively Regularized Prioritized Exemplar Replay) by replaying prioritized historical exemplars, together with an adaptive regularization technique based on ElasticWeight Consolidation. Extensive experiments to continually learn new domains and intents are conducted on MultiWoZ-2.0 to benchmark ARPER with a wide range of techniques. Empirical results demonstrate that ARPER significantly outperforms other methods by effectively mitigating the detrimental catastrophic forgetting issue.</td><td>è‡ªç„¶è¯­è¨€ç”Ÿæˆ (NLG) æ˜¯é¢å‘ä»»åŠ¡çš„å¯¹è¯ç³»ç»Ÿçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚å°½ç®¡æœ€è¿‘ NLG çš„ç¥ç»æ–¹æ³•å–å¾—äº†æˆåŠŸï¼Œä½†å®ƒä»¬é€šå¸¸æ˜¯é’ˆå¯¹ç‰¹å®šé¢†åŸŸä»¥ç¦»çº¿æ–¹å¼å¼€å‘çš„ã€‚ä¸ºäº†æ›´å¥½åœ°é€‚åº”æ–°æ•°æ®æµå…¥çš„ç°å®ç”Ÿæ´»åº”ç”¨ç¨‹åºï¼Œæˆ‘ä»¬åœ¨â€œæŒç»­å­¦ä¹ â€è®¾ç½®ä¸­ç ”ç©¶ NLGï¼Œä»¥é€æ­¥å°†å…¶çŸ¥è¯†æ‰©å±•åˆ°æ–°çš„é¢†åŸŸæˆ–åŠŸèƒ½ã€‚å®ç°è¿™ä¸€ç›®æ ‡çš„ä¸»è¦æŒ‘æˆ˜æ˜¯ç¾éš¾æ€§é—å¿˜ï¼Œè¿™æ„å‘³ç€ä¸æ–­è®­ç»ƒçš„æ¨¡å‹å¾€å¾€ä¼šå¿˜è®°å®ƒä¹‹å‰å­¦åˆ°çš„çŸ¥è¯†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸º ARPERï¼ˆAdaptively Regularized Prioritized Exemplar Replayï¼‰çš„æ–¹æ³•ï¼Œé€šè¿‡é‡æ”¾ä¼˜å…ˆçš„å†å²æ ·æœ¬ï¼Œä»¥åŠåŸºäº ElasticWeight Consolidation çš„è‡ªé€‚åº”æ­£åˆ™åŒ–æŠ€æœ¯ã€‚åœ¨ MultiWoZ-2.0 ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒä»¥ä¸æ–­å­¦ä¹ æ–°çš„é¢†åŸŸå’Œæ„å›¾ï¼Œä»¥ä½¿ç”¨å„ç§æŠ€æœ¯å¯¹ ARPER è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚å®è¯ç»“æœè¡¨æ˜ï¼ŒARPER é€šè¿‡æœ‰æ•ˆå‡è½»æœ‰å®³çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜æ˜¾ç€ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</td><td>Fei Mi   Liangwei Chen   Mengjie Zhao   Minlie Huang   Boi Faltings</td></tr><tr><td>8</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04246&#39;]">Dual Inference for Improving Language Understanding and Generation</a></td><td></td><td><a href="https://github.com/MiuLab/DuaLUG">https://github.com/MiuLab/DuaLUG</a></td><td><a href="https://arxiv.org/pdf/2010.04246">https://arxiv.org/pdf/2010.04246</a></td><td>Natural language understanding (NLU) and Natural language generation (NLG) tasks hold a strong dual relationship, where NLU aims at predicting semantic labels based on natural language utterances and NLG does the opposite. The prior work mainly focused on exploiting the duality in model training in order to obtain the models with better performance. However, regarding the fast-growing scale of models in the current NLP area, sometimes we may have difficulty retraining whole NLU and NLG models. To better address the issue, this paper proposes to leverage the duality in the inference stage without the need of retraining. The experiments on three benchmark datasets demonstrate the effectiveness of the proposed method in both NLU and NLG, providing the great potential of practical usage.</td><td>è‡ªç„¶è¯­è¨€ç†è§£ (NLU) å’Œè‡ªç„¶è¯­è¨€ç”Ÿæˆ (NLG) ä»»åŠ¡å…·æœ‰å¾ˆå¼ºçš„åŒé‡å…³ç³»ï¼Œå…¶ä¸­ NLU æ—¨åœ¨æ ¹æ®è‡ªç„¶è¯­è¨€è¡¨è¾¾é¢„æµ‹è¯­ä¹‰æ ‡ç­¾ï¼Œè€Œ NLG åˆ™ç›¸åã€‚å…ˆå‰çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨åˆ©ç”¨æ¨¡å‹è®­ç»ƒä¸­çš„äºŒå…ƒæ€§ä»¥è·å¾—æ€§èƒ½æ›´å¥½çš„æ¨¡å‹ã€‚ç„¶è€Œï¼Œå¯¹äºå½“å‰ NLP é¢†åŸŸå¿«é€Ÿå¢é•¿çš„æ¨¡å‹è§„æ¨¡ï¼Œæœ‰æ—¶æˆ‘ä»¬å¯èƒ½éš¾ä»¥é‡æ–°è®­ç»ƒæ•´ä¸ª NLU å’Œ NLG æ¨¡å‹ã€‚ä¸ºäº†æ›´å¥½åœ°è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡å»ºè®®åœ¨æ¨ç†é˜¶æ®µåˆ©ç”¨äºŒå…ƒæ€§ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•åœ¨ NLU å’Œ NLG ä¸­çš„æœ‰æ•ˆæ€§ï¼Œæä¾›äº†å·¨å¤§çš„å®é™…ä½¿ç”¨æ½œåŠ›ã€‚</td><td>Shang-Yu Su   Yung-Sung Chuang   Yun-Nung Chen</td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.09022&#39;]">Neural data-to-text generation: A comparison between pipeline and end- to-end architectures</a></td><td></td><td><a href="https://github.com/ThiagoCF05/webnlg">https://github.com/ThiagoCF05/webnlg</a></td><td><a href="https://arxiv.org/pdf/1908.09022">https://arxiv.org/pdf/1908.09022</a></td><td>Traditionally, most data-to-text applications have been designed using a modular pipeline architecture, in which non-linguistic input data is converted into natural language through several intermediate transformations. In contrast, recent neural models for data-to-text generation have been proposed as end-to-end approaches, where the non-linguistic input is rendered in natural language with much less explicit intermediate representations in-between. This study introduces a systematic comparison between neural pipeline and end-to-end data-to-text approaches for the generation of text from RDF triples. Both architectures were implemented making use of state-of-the art deep learning methods as the encoder-decoder Gated-Recurrent Units (GRU) and Transformer. Automatic and human evaluations together with a qualitative analysis suggest that having explicit intermediate steps in the generation process results in better texts than the ones generated by end-to-end approaches. Moreover, the pipeline models generalize better to unseen inputs. Data and code are publicly available.</td><td>ä¼ ç»Ÿä¸Šï¼Œå¤§å¤šæ•°æ•°æ®åˆ°æ–‡æœ¬åº”ç”¨ç¨‹åºéƒ½æ˜¯ä½¿ç”¨æ¨¡å—åŒ–ç®¡é“æ¶æ„è®¾è®¡çš„ï¼Œå…¶ä¸­éè¯­è¨€è¾“å…¥æ•°æ®é€šè¿‡å‡ ä¸ªä¸­é—´è½¬æ¢è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæœ€è¿‘ç”¨äºæ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆçš„ç¥ç»æ¨¡å‹å·²è¢«æå‡ºä½œä¸ºç«¯åˆ°ç«¯æ–¹æ³•ï¼Œå…¶ä¸­éè¯­è¨€è¾“å…¥ä»¥è‡ªç„¶è¯­è¨€å‘ˆç°ï¼Œä¸­é—´çš„ä¸­é—´è¡¨ç¤ºè¦å°‘å¾—å¤šã€‚æœ¬ç ”ç©¶ä»‹ç»äº†ç¥ç»ç®¡é“å’Œç«¯åˆ°ç«¯æ•°æ®åˆ°æ–‡æœ¬æ–¹æ³•ä¹‹é—´çš„ç³»ç»Ÿæ¯”è¾ƒï¼Œç”¨äºä» RDF ä¸‰å…ƒç»„ç”Ÿæˆæ–‡æœ¬ã€‚è¿™ä¸¤ç§æ¶æ„éƒ½æ˜¯åˆ©ç”¨æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ä½œä¸ºç¼–ç å™¨-è§£ç å™¨é—¨æ§å¾ªç¯å•å…ƒ (GRU) å’Œè½¬æ¢å™¨æ¥å®ç°çš„ã€‚è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°ä»¥åŠå®šæ€§åˆ†æè¡¨æ˜ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å…·æœ‰æ˜ç¡®çš„ä¸­é—´æ­¥éª¤ä¼šäº§ç”Ÿæ¯”ç«¯åˆ°ç«¯æ–¹æ³•ç”Ÿæˆçš„æ–‡æœ¬æ›´å¥½çš„æ–‡æœ¬ã€‚æ­¤å¤–ï¼Œç®¡é“æ¨¡å‹å¯ä»¥æ›´å¥½åœ°æ³›åŒ–åˆ°çœ‹ä¸è§çš„è¾“å…¥ã€‚æ•°æ®å’Œä»£ç æ˜¯å…¬å¼€çš„ã€‚</td><td>Thiago Castro Ferreira   Chris van der Lee   Emiel van Miltenburg   Emiel Krahmer</td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.02622&#39;]">MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.02622">https://arxiv.org/pdf/1909.02622</a></td><td>A robust evaluation metric has a profound impact on the development of text generation systems. A desirable metric compares system output against references based on their semantics rather than surface forms. In this paper we investigate strategies to encode system and reference texts to devise a metric that shows a high correlation with human judgment of text quality. We validate our new metric, namely MoverScore, on a number of text generation tasks including summarization, machine translation, image captioning, and data-to-text generation, where the outputs are produced by a variety of neural and non-neural systems. Our findings suggest that metrics combining contextualized representations with a distance measure perform the best. Such metrics also demonstrate strong generalization capability across tasks. For ease-of-use we make our metrics available as web service.</td><td>ä¸€ä¸ªå¼ºå¤§çš„è¯„ä¼°æŒ‡æ ‡å¯¹æ–‡æœ¬ç”Ÿæˆç³»ç»Ÿçš„å‘å±•æœ‰ç€æ·±è¿œçš„å½±å“ã€‚ç†æƒ³çš„åº¦é‡æ ¹æ®è¯­ä¹‰è€Œä¸æ˜¯è¡¨é¢å½¢å¼å°†ç³»ç»Ÿè¾“å‡ºä¸å¼•ç”¨è¿›è¡Œæ¯”è¾ƒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¯¹ç³»ç»Ÿå’Œå‚è€ƒæ–‡æœ¬è¿›è¡Œç¼–ç çš„ç­–ç•¥ï¼Œä»¥è®¾è®¡å‡ºä¸äººç±»å¯¹æ–‡æœ¬è´¨é‡çš„åˆ¤æ–­é«˜åº¦ç›¸å…³çš„åº¦é‡ã€‚æˆ‘ä»¬åœ¨è®¸å¤šæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ–°æŒ‡æ ‡ï¼Œå³ MoverScoreï¼ŒåŒ…æ‹¬æ‘˜è¦ã€æœºå™¨ç¿»è¯‘ã€å›¾åƒå­—å¹•å’Œæ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆï¼Œå…¶ä¸­è¾“å‡ºç”±å„ç§ç¥ç»å’Œéç¥ç»ç³»ç»Ÿç”Ÿæˆã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå°†ä¸Šä¸‹æ–‡è¡¨ç¤ºä¸è·ç¦»åº¦é‡ç›¸ç»“åˆçš„æŒ‡æ ‡è¡¨ç°æœ€ä½³ã€‚è¿™äº›æŒ‡æ ‡è¿˜å±•ç¤ºäº†è·¨ä»»åŠ¡çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†ä¾¿äºä½¿ç”¨ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„æŒ‡æ ‡ä½œä¸º Web æœåŠ¡æä¾›ã€‚</td><td>Wei Zhao   Maxime Peyrard   Fei Liu   Yang Gao   Christian M. Meyer   Steffen Eger</td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.04453&#39;]">Select and Attend: Towards Controllable Content Selection in Text Generation</a></td><td></td><td><a href="https://github.com/chin-gyou/controllable-selection">https://github.com/chin-gyou/controllable-selection</a></td><td><a href="https://arxiv.org/pdf/1909.04453">https://arxiv.org/pdf/1909.04453</a></td><td>Many text generation tasks naturally contain two steps: content selection and surface realization. Current neural encoder-decoder models conflate both steps into a black-box architecture. As a result, the content to be described in the text cannot be explicitly controlled. This paper tackles this problem by decoupling content selection from the decoder. The decoupled content selection is human interpretable, whose value can be manually manipulated to control the content of generated text. The model can be trained end-to-end without human annotations by maximizing a lower bound of the marginal likelihood. We further propose an effective way to trade-off between performance and controllability with a single adjustable hyperparameter. In both data-to-text and headline generation tasks, our model achieves promising results, paving the way for controllable content selection in text generation.</td><td>è®¸å¤šæ–‡æœ¬ç”Ÿæˆä»»åŠ¡è‡ªç„¶åŒ…å«ä¸¤ä¸ªæ­¥éª¤ï¼šå†…å®¹é€‰æ‹©å’Œè¡¨é¢å®ç°ã€‚å½“å‰çš„ç¥ç»ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹å°†è¿™ä¸¤ä¸ªæ­¥éª¤åˆå¹¶ä¸ºä¸€ä¸ªé»‘ç›’æ¶æ„ã€‚å› æ­¤ï¼Œæ— æ³•æ˜ç¡®æ§åˆ¶æ–‡æœ¬ä¸­è¦æè¿°çš„å†…å®¹ã€‚æœ¬æ–‡é€šè¿‡å°†å†…å®¹é€‰æ‹©ä¸è§£ç å™¨è§£è€¦æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è§£è€¦çš„å†…å®¹é€‰æ‹©æ˜¯äººç±»å¯è§£é‡Šçš„ï¼Œå…¶å€¼å¯ä»¥æ‰‹åŠ¨æ“ä½œä»¥æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å†…å®¹ã€‚é€šè¿‡æœ€å¤§åŒ–è¾¹é™…ä¼¼ç„¶çš„ä¸‹é™ï¼Œå¯ä»¥åœ¨æ²¡æœ‰äººå·¥æ³¨é‡Šçš„æƒ…å†µä¸‹ç«¯åˆ°ç«¯åœ°è®­ç»ƒæ¨¡å‹ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥é€šè¿‡å•ä¸ªå¯è°ƒè¶…å‚æ•°åœ¨æ€§èƒ½å’Œå¯æ§æ€§ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚åœ¨æ•°æ®åˆ°æ–‡æœ¬å’Œæ ‡é¢˜ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å–å¾—äº†å¯å–œçš„ç»“æœï¼Œä¸ºæ–‡æœ¬ç”Ÿæˆä¸­çš„å¯æ§å†…å®¹é€‰æ‹©é“ºå¹³äº†é“è·¯ã€‚</td><td>Xiaoyu Shen   Jun Suzuki   Kentaro Inui   Hui Su   Dietrich Klakow   Satoshi Sekine</td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.10245&#39;]">Knowledge Aware Conversation Generation with Explainable Reasoning over Augmented Graphs</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research/tree/master/NLP/EMNLP2019-AKGCM">https://github.com/PaddlePaddle/Research/tree/master/NLP/EMNLP2019-AKGCM</a></td><td><a href="https://arxiv.org/pdf/1903.10245">https://arxiv.org/pdf/1903.10245</a></td><td>Two types of knowledge, triples from knowledge graphs and texts from documents, have been studied for knowledge aware open-domain conversation generation, in which graph paths can narrow down vertex candidates for knowledge selection decision, and texts can provide rich information for response generation. Fusion of a knowledge graph and texts might yield mutually reinforcing advantages, but there is less study on that. To address this challenge, we propose a knowledge aware chatting machine with three components, an augmented knowledge graph with both triples and texts, knowledge selector, and knowledge aware response generator. For knowledge selection on the graph, we formulate it as a problem of multi-hop graph reasoning to effectively capture conversation flow, which is more explainable and flexible in comparison with previous work. To fully leverage long text information that differentiates our graph from others, we improve a state of the art reasoning algorithm with machine reading comprehension technology. We demonstrate the effectiveness of our system on two datasets in comparison with state-of-the-art models.</td><td>å·²ç»ç ”ç©¶äº†ä¸¤ç§ç±»å‹çš„çŸ¥è¯†ï¼ŒçŸ¥è¯†å›¾è°±ä¸­çš„ä¸‰å…ƒç»„å’Œæ–‡æ¡£ä¸­çš„æ–‡æœ¬ï¼Œç”¨äºçŸ¥è¯†æ„ŸçŸ¥å¼€æ”¾åŸŸå¯¹è¯ç”Ÿæˆï¼Œå…¶ä¸­å›¾è·¯å¾„å¯ä»¥ç¼©å°çŸ¥è¯†é€‰æ‹©å†³ç­–çš„é¡¶ç‚¹å€™é€‰ï¼Œæ–‡æœ¬å¯ä»¥ä¸ºå“åº”ç”Ÿæˆæä¾›ä¸°å¯Œçš„ä¿¡æ¯ã€‚çŸ¥è¯†å›¾è°±å’Œæ–‡æœ¬çš„èåˆå¯èƒ½ä¼šäº§ç”Ÿç›¸è¾…ç›¸æˆçš„ä¼˜åŠ¿ï¼Œä½†å¯¹æ­¤çš„ç ”ç©¶è¾ƒå°‘ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å…·æœ‰ä¸‰ä¸ªç»„ä»¶çš„çŸ¥è¯†æ„ŸçŸ¥èŠå¤©æœºï¼Œä¸€ä¸ªå…·æœ‰ä¸‰å…ƒç»„å’Œæ–‡æœ¬çš„å¢å¼ºçŸ¥è¯†å›¾ï¼ŒçŸ¥è¯†é€‰æ‹©å™¨å’ŒçŸ¥è¯†æ„ŸçŸ¥å“åº”ç”Ÿæˆå™¨ã€‚å¯¹äºå›¾ä¸Šçš„çŸ¥è¯†é€‰æ‹©ï¼Œæˆ‘ä»¬å°†å…¶è¡¨è¿°ä¸ºå¤šè·³å›¾æ¨ç†é—®é¢˜ï¼Œä»¥æœ‰æ•ˆæ•è·å¯¹è¯æµï¼Œä¸ä»¥å‰çš„å·¥ä½œç›¸æ¯”ï¼Œå®ƒæ›´å…·å¯è§£é‡Šæ€§å’Œçµæ´»æ€§ã€‚ä¸ºäº†å……åˆ†åˆ©ç”¨å°†æˆ‘ä»¬çš„å›¾ä¸å…¶ä»–å›¾åŒºåˆ†å¼€æ¥çš„é•¿æ–‡æœ¬ä¿¡æ¯ï¼Œæˆ‘ä»¬ä½¿ç”¨æœºå™¨é˜…è¯»ç†è§£æŠ€æœ¯æ”¹è¿›äº†æœ€å…ˆè¿›çš„æ¨ç†ç®—æ³•ã€‚ä¸æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸æ¯”ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„ç³»ç»Ÿåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§ã€‚</td><td>Zhibin Liu   Zheng-Yu Niu   Hua Wu   Haifeng Wang</td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11658&#39;]">Autoregressive Text Generation Beyond Feedback Loops</a></td><td></td><td><a href="https://github.com/schmiflo/crf-generation">https://github.com/schmiflo/crf-generation</a></td><td><a href="https://arxiv.org/pdf/1908.11658">https://arxiv.org/pdf/1908.11658</a></td><td>Autoregressive state transitions, where predictions are conditioned on past predictions, are the predominant choice for both deterministic and stochastic sequential models. However, autoregressive feedback exposes the evolution of the hidden state trajectory to potential biases from well-known train-test discrepancies. In this paper, we combine a latent state space model with a CRF observation model. We argue that such autoregressive observation models form an interesting middle ground that expresses local correlations on the word level but keeps the state evolution non-autoregressive. On unconditional sentence generation we show performance improvements compared to RNN and GAN baselines while avoiding some prototypical failure modes of autoregressive models.</td><td>è‡ªå›å½’çŠ¶æ€è½¬æ¢ï¼Œå…¶ä¸­é¢„æµ‹ä»¥è¿‡å»çš„é¢„æµ‹ä¸ºæ¡ä»¶ï¼Œæ˜¯ç¡®å®šæ€§å’Œéšæœºåºåˆ—æ¨¡å‹çš„ä¸»è¦é€‰æ‹©ã€‚ç„¶è€Œï¼Œè‡ªå›å½’åé¦ˆå°†éšè—çŠ¶æ€è½¨è¿¹çš„æ¼”å˜æš´éœ²äºä¼—æ‰€å‘¨çŸ¥çš„è®­ç»ƒæµ‹è¯•å·®å¼‚çš„æ½œåœ¨åå·®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ½œåœ¨çŠ¶æ€ç©ºé—´æ¨¡å‹ä¸ CRF è§‚å¯Ÿæ¨¡å‹ç›¸ç»“åˆã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œè¿™ç§è‡ªå›å½’è§‚å¯Ÿæ¨¡å‹å½¢æˆäº†ä¸€ä¸ªæœ‰è¶£çš„ä¸­é—´ç«‹åœºï¼Œå®ƒåœ¨å•è¯çº§åˆ«ä¸Šè¡¨è¾¾äº†å±€éƒ¨ç›¸å…³æ€§ï¼Œä½†ä¿æŒçŠ¶æ€æ¼”åŒ–éè‡ªå›å½’ã€‚åœ¨æ— æ¡ä»¶å¥å­ç”Ÿæˆæ–¹é¢ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸ RNN å’Œ GAN åŸºçº¿ç›¸æ¯”çš„æ€§èƒ½æ”¹è¿›ï¼ŒåŒæ—¶é¿å…äº†è‡ªå›å½’æ¨¡å‹çš„ä¸€äº›åŸå‹æ•…éšœæ¨¡å¼ã€‚</td><td>Florian Schmidt   Stephan Mandt   Thomas Hofmann</td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.07195&#39;]">ARAML: A Stable Adversarial Training Framework for Text Generation</a></td><td></td><td><a href="https://github.com/kepei1106/ARAML">https://github.com/kepei1106/ARAML</a></td><td><a href="https://arxiv.org/pdf/1908.07195">https://arxiv.org/pdf/1908.07195</a></td><td>Most of the existing generative adversarial networks (GAN) for text generation suffer from the instability of reinforcement learning training algorithms such as policy gradient, leading to unstable performance. To tackle this problem, we propose a novel framework called Adversarial Reward Augmented Maximum Likelihood (ARAML). During adversarial training, the discriminator assigns rewards to samples which are acquired from a stationary distribution near the data rather than the generatorâ€™s distribution. The generator is optimized with maximum likelihood estimation augmented by the discriminatorâ€™s rewards instead of policy gradient. Experiments show that our model can outperform state-of-the-art text GANs with a more stable training process.</td><td>å¤§å¤šæ•°ç°æœ‰çš„ç”¨äºæ–‡æœ¬ç”Ÿæˆçš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰éƒ½å—åˆ°å¼ºåŒ–å­¦ä¹ è®­ç»ƒç®—æ³•ï¼ˆå¦‚ç­–ç•¥æ¢¯åº¦ï¼‰çš„ä¸ç¨³å®šæ€§çš„å½±å“ï¼Œå¯¼è‡´æ€§èƒ½ä¸ç¨³å®šã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸ºå¯¹æŠ—æ€§å¥–åŠ±å¢å¼ºæœ€å¤§ä¼¼ç„¶ï¼ˆARAMLï¼‰çš„æ–°æ¡†æ¶ã€‚åœ¨å¯¹æŠ—æ€§è®­ç»ƒæœŸé—´ï¼Œé‰´åˆ«å™¨å°†å¥–åŠ±åˆ†é…ç»™ä»æ•°æ®é™„è¿‘çš„å¹³ç¨³åˆ†å¸ƒè€Œä¸æ˜¯ç”Ÿæˆå™¨çš„åˆ†å¸ƒä¸­è·å¾—çš„æ ·æœ¬ã€‚ç”Ÿæˆå™¨é€šè¿‡æœ€å¤§ä¼¼ç„¶ä¼°è®¡è¿›è¡Œä¼˜åŒ–ï¼Œç”±é‰´åˆ«å™¨çš„å¥–åŠ±è€Œä¸æ˜¯ç­–ç•¥æ¢¯åº¦æ¥å¢å¼ºã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥é€šè¿‡æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹è¶…è¶Šæœ€å…ˆè¿›çš„æ–‡æœ¬ GANã€‚</td><td>Pei Ke   Fei Huang   Minlie Huang   Xiaoyan Zhu</td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1901.00398&#39;]">Judge the Judges: A Large-Scale Evaluation Study of Neural Language Models for Online Review Generation</a></td><td></td><td><a href="https://github.com/Crista23/JudgeTheJudges">https://github.com/Crista23/JudgeTheJudges</a></td><td><a href="https://arxiv.org/pdf/1901.00398">https://arxiv.org/pdf/1901.00398</a></td><td>We conduct a large-scale, systematic study to evaluate the existing evaluation methods for natural language generation in the context of generating online product reviews. We compare human-based evaluators with a variety of automated evaluation procedures, including discriminative evaluators that measure how well machine-generated text can be distinguished from human-written text, as well as word overlap metrics that assess how similar the generated text compares to human-written references. We determine to what extent these different evaluators agree on the ranking of a dozen of state-of-the-art generators for online product reviews. We find that human evaluators do not correlate well with discriminative evaluators, leaving a bigger question of whether adversarial accuracy is the correct objective for natural language generation. In general, distinguishing machine-generated text is challenging even for human evaluators, and human decisions correlate better with lexical overlaps. We find lexical diversity an intriguing metric that is indicative of the assessments of different evaluators. A post-experiment survey of participants provides insights into how to evaluate and improve the quality of natural language generation systems.</td><td>æˆ‘ä»¬è¿›è¡Œäº†å¤§è§„æ¨¡ã€ç³»ç»Ÿçš„ç ”ç©¶ï¼Œä»¥åœ¨ç”Ÿæˆåœ¨çº¿äº§å“è¯„è®ºçš„èƒŒæ™¯ä¸‹è¯„ä¼°ç°æœ‰çš„è‡ªç„¶è¯­è¨€ç”Ÿæˆè¯„ä¼°æ–¹æ³•ã€‚æˆ‘ä»¬å°†åŸºäºäººç±»çš„è¯„ä¼°å™¨ä¸å„ç§è‡ªåŠ¨è¯„ä¼°ç¨‹åºè¿›è¡Œæ¯”è¾ƒï¼ŒåŒ…æ‹¬è¡¡é‡æœºå™¨ç”Ÿæˆçš„æ–‡æœ¬ä¸äººç±»ç¼–å†™çš„æ–‡æœ¬çš„åŒºåˆ†ç¨‹åº¦çš„åˆ¤åˆ«è¯„ä¼°å™¨ï¼Œä»¥åŠè¯„ä¼°ç”Ÿæˆçš„æ–‡æœ¬ä¸äººç±»çš„ç›¸ä¼¼ç¨‹åº¦çš„å•è¯é‡å æŒ‡æ ‡- ä¹¦é¢å‚è€ƒã€‚æˆ‘ä»¬ç¡®å®šè¿™äº›ä¸åŒçš„è¯„ä¼°è€…åœ¨å¤šå¤§ç¨‹åº¦ä¸ŠåŒæ„åœ¨çº¿äº§å“è¯„è®ºçš„åå‡ ä¸ªæœ€å…ˆè¿›çš„ç”Ÿæˆå™¨çš„æ’åã€‚æˆ‘ä»¬å‘ç°äººç±»è¯„ä¼°è€…ä¸åˆ¤åˆ«æ€§è¯„ä¼°è€…çš„ç›¸å…³æ€§ä¸ä½³ï¼Œè¿™ç•™ä¸‹äº†ä¸€ä¸ªæ›´å¤§çš„é—®é¢˜ï¼Œå³å¯¹æŠ—æ€§å‡†ç¡®æ€§æ˜¯å¦æ˜¯è‡ªç„¶è¯­è¨€ç”Ÿæˆçš„æ­£ç¡®ç›®æ ‡ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå³ä½¿å¯¹äºäººç±»è¯„ä¼°è€…æ¥è¯´ï¼ŒåŒºåˆ†æœºå™¨ç”Ÿæˆçš„æ–‡æœ¬ä¹Ÿæ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œè€Œäººç±»å†³ç­–ä¸è¯æ±‡é‡å çš„ç›¸å…³æ€§æ›´å¥½ã€‚æˆ‘ä»¬å‘ç°è¯æ±‡å¤šæ ·æ€§æ˜¯ä¸€ä¸ªæœ‰è¶£çš„æŒ‡æ ‡ï¼Œå®ƒè¡¨æ˜ä¸åŒè¯„ä¼°è€…çš„è¯„ä¼°ã€‚å¯¹å‚ä¸è€…çš„å®éªŒåè°ƒæŸ¥æä¾›äº†æœ‰å…³å¦‚ä½•è¯„ä¼°å’Œæé«˜è‡ªç„¶è¯­è¨€ç”Ÿæˆç³»ç»Ÿè´¨é‡çš„è§è§£ã€‚</td><td>Cristina Garbacea   Samuel Carton   Shiyan Yan   Qiaozhu Mei</td></tr></tbody></table></div><h3 id="NAACL-2"><a href="#NAACL-2" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2005.00054&#39;]">APo-VAE: Text Generation in Hyperbolic Space</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.00054">https://arxiv.org/pdf/2005.00054</a></td><td>Natural language often exhibits inherent hierarchical structure ingrained with complex syntax and semantics. However, most state-of-the-art deep generative models learn embeddings only in Euclidean vector space, without accounting for this structural property of language. In this paper, we investigate text generation in a hyperbolic latent space to learn continuous hierarchical representations. An Adversarial Poincare Variational Autoencoder (APo-VAE) is presented, where both the prior and variational posterior of latent variables are defined over a Poincare ball via wrapped normal distributions. By adopting the primal-dual formulation of KL divergence, an adversarial learning procedure is introduced to empower robust model training. Extensive experiments in language modeling and dialog-response generation tasks demonstrate the winning effectiveness of the proposed APo-VAE model over VAEs in Euclidean latent space, thanks to its superb capabilities in capturing latent language hierarchies in hyperbolic space.</td><td>è‡ªç„¶è¯­è¨€é€šå¸¸è¡¨ç°å‡ºæ ¹æ·±è’‚å›ºçš„å¤æ‚è¯­æ³•å’Œè¯­ä¹‰çš„å›ºæœ‰å±‚æ¬¡ç»“æ„ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æœ€å…ˆè¿›çš„æ·±åº¦ç”Ÿæˆæ¨¡å‹ä»…åœ¨æ¬§å‡ é‡Œå¾—å‘é‡ç©ºé—´ä¸­å­¦ä¹ åµŒå…¥ï¼Œè€Œæ²¡æœ‰è€ƒè™‘è¯­è¨€çš„è¿™ç§ç»“æ„ç‰¹æ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†åŒæ›²æ½œåœ¨ç©ºé—´ä¸­çš„æ–‡æœ¬ç”Ÿæˆï¼Œä»¥å­¦ä¹ è¿ç»­çš„åˆ†å±‚è¡¨ç¤ºã€‚æå‡ºäº†å¯¹æŠ—æ€§åºåŠ è±å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ (APo-VAE)ï¼Œå…¶ä¸­æ½œåœ¨å˜é‡çš„å…ˆéªŒå’Œå˜åˆ†åéªŒéƒ½é€šè¿‡åŒ…è£¹æ­£æ€åˆ†å¸ƒåœ¨åºåŠ è±çƒä¸Šå®šä¹‰ã€‚é€šè¿‡é‡‡ç”¨ KL æ•£åº¦çš„åŸå§‹å¯¹å¶å…¬å¼ï¼Œå¼•å…¥äº†å¯¹æŠ—æ€§å­¦ä¹ ç¨‹åºä»¥å¢å¼ºç¨³å¥çš„æ¨¡å‹è®­ç»ƒã€‚è¯­è¨€å»ºæ¨¡å’Œå¯¹è¯å“åº”ç”Ÿæˆä»»åŠ¡ä¸­çš„å¤§é‡å®éªŒè¯æ˜äº†æ‰€æå‡ºçš„ APo-VAE æ¨¡å‹åœ¨æ¬§å‡ é‡Œå¾·æ½œåœ¨ç©ºé—´ä¸­çš„ VAE ä¸Šçš„è·èƒœæœ‰æ•ˆæ€§ï¼Œè¿™è¦å½’åŠŸäºå…¶åœ¨åŒæ›²çº¿ç©ºé—´ä¸­æ•è·æ½œåœ¨è¯­è¨€å±‚æ¬¡ç»“æ„çš„å“è¶Šèƒ½åŠ›ã€‚</td><td>Shuyang Dai   Zhe Gan   Yu Cheng   Chenyang Tao   Lawrence Carin   Jingjing Liu</td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05218&#39;]">FUDGE: Controlled Text Generation With Future Discriminators</a></td><td></td><td><a href="https://github.com/yangkevin2/naacl-2021-fudge-controlled-generation">https://github.com/yangkevin2/naacl-2021-fudge-controlled-generation</a></td><td><a href="https://arxiv.org/pdf/2104.05218">https://arxiv.org/pdf/2104.05218</a></td><td>We propose Future Discriminators for Generation (FUDGE), a flexible and modular method for controlled text generation. Given a pre-existing model G for generating text from a distribution of interest, FUDGE enables conditioning on a desired attribute a (for example, formality) while requiring access only to Gâ€™s output logits. FUDGE learns an attribute predictor operating on a partial sequence, and uses this predictorâ€™s outputs to adjust Gâ€™s original probabilities. We show that FUDGE models terms corresponding to a Bayesian decomposition of the conditional distribution of G given attribute a. Moreover, FUDGE can easily compose predictors for multiple desired attributes. We evaluate FUDGE on three tasks â€” couplet completion in poetry, topic control in language generation, and formality change in machine translation â€” and observe gains in all three tasks.</td><td>æˆ‘ä»¬æå‡ºäº†æœªæ¥ç”Ÿæˆåˆ¤åˆ«å™¨ï¼ˆFUDGEï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºå—æ§æ–‡æœ¬ç”Ÿæˆçš„çµæ´»ä¸”æ¨¡å—åŒ–çš„æ–¹æ³•ã€‚ç»™å®šä¸€ä¸ªç”¨äºä»æ„Ÿå…´è¶£çš„åˆ†å¸ƒç”Ÿæˆæ–‡æœ¬çš„é¢„å…ˆå­˜åœ¨çš„æ¨¡å‹ Gï¼ŒFUDGE å¯ä»¥å¯¹æ‰€éœ€çš„å±æ€§ aï¼ˆä¾‹å¦‚å½¢å¼ï¼‰è¿›è¡Œè°ƒèŠ‚ï¼ŒåŒæ—¶åªéœ€è¦è®¿é—® G çš„è¾“å‡º logitsã€‚ FUDGE å­¦ä¹ å¯¹éƒ¨åˆ†åºåˆ—è¿›è¡Œæ“ä½œçš„å±æ€§é¢„æµ‹å™¨ï¼Œå¹¶ä½¿ç”¨è¯¥é¢„æµ‹å™¨çš„è¾“å‡ºæ¥è°ƒæ•´ G çš„åŸå§‹æ¦‚ç‡ã€‚æˆ‘ä»¬å±•ç¤ºäº† FUDGE æ¨¡å‹é¡¹å¯¹åº”äºç»™å®šå±æ€§ a çš„ G çš„æ¡ä»¶åˆ†å¸ƒçš„è´å¶æ–¯åˆ†è§£ã€‚æ­¤å¤–ï¼ŒFUDGE å¯ä»¥è½»æ¾åœ°ä¸ºå¤šä¸ªæ‰€éœ€å±æ€§ç»„åˆé¢„æµ‹å™¨ã€‚æˆ‘ä»¬åœ¨ä¸‰é¡¹ä»»åŠ¡ä¸Šè¯„ä¼° FUDGEâ€”â€”è¯—æ­Œä¸­çš„å¯¹è”å®Œæˆã€è¯­è¨€ç”Ÿæˆä¸­çš„ä¸»é¢˜æ§åˆ¶å’Œæœºå™¨ç¿»è¯‘ä¸­çš„å½¢å¼å˜åŒ–â€”â€”å¹¶è§‚å¯Ÿæ‰€æœ‰ä¸‰é¡¹ä»»åŠ¡çš„æ”¶ç›Šã€‚</td><td>Kevin Yang   Dan Klein</td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12884&#39;]">NeuroLogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12884">https://arxiv.org/pdf/2010.12884</a></td><td>Conditional text generation often requires lexical constraints, i.e., which words should or shouldnâ€™t be included in the output text. While the dominant recipe for conditional text generation has been large-scale pretrained language models that are finetuned on the task-specific training data, such models do not learn to follow the underlying constraints reliably, even when supervised with large amounts of task-specific examples.</td><td></td><td></td></tr><tr><td>We propose NeuroLogic Decoding, a simple yet effective algorithm that enables neural language models â€” supervised or not â€” to generate fluent text while satisfying complex lexical constraints. Our approach is powerful yet efficient. It handles any set of lexical constraints that is expressible under predicate logic, while its asymptotic runtime is equivalent to conventional beam search.</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Empirical results on four benchmarks show that NeuroLogic Decoding outperforms previous approaches, including algorithms that handle a subset of our constraints. Moreover, we find that unsupervised models with NeuroLogic Decoding often outperform supervised models with conventional decoding, even when the latter is based on considerably larger networks. Our results suggest the limit of large-scale neural networks for fine-grained controllable generation and the promise of inference-time algorithms.</td><td>æ¡ä»¶æ–‡æœ¬ç”Ÿæˆé€šå¸¸éœ€è¦è¯æ³•çº¦æŸï¼Œå³å“ªäº›è¯åº”è¯¥æˆ–ä¸åº”è¯¥åŒ…å«åœ¨è¾“å‡ºæ–‡æœ¬ä¸­ã€‚è™½ç„¶æ¡ä»¶æ–‡æœ¬ç”Ÿæˆçš„ä¸»è¦æ–¹æ³•æ˜¯åœ¨ç‰¹å®šä»»åŠ¡çš„è®­ç»ƒæ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒçš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä½†è¿™äº›æ¨¡å‹å¹¶ä¸èƒ½å¯é åœ°å­¦ä¹ éµå¾ªæ½œåœ¨çš„çº¦æŸï¼Œå³ä½¿åœ¨æœ‰å¤§é‡ç‰¹å®šä»»åŠ¡ç¤ºä¾‹çš„ç›‘ç£ä¸‹.</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>æˆ‘ä»¬æå‡ºäº† NeuroLogic Decodingï¼Œè¿™æ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ç®—æ³•ï¼Œå®ƒä½¿ç¥ç»è¯­è¨€æ¨¡å‹ï¼ˆæ— è®ºæ˜¯å¦å—ç›‘ç£ï¼‰éƒ½èƒ½ç”Ÿæˆæµç•…çš„æ–‡æœ¬ï¼ŒåŒæ—¶æ»¡è¶³å¤æ‚çš„è¯æ±‡çº¦æŸã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼ºå¤§è€Œé«˜æ•ˆã€‚å®ƒå¤„ç†åœ¨è°“è¯é€»è¾‘ä¸‹å¯è¡¨è¾¾çš„ä»»ä½•è¯æ³•çº¦æŸé›†ï¼Œè€Œå…¶æ¸è¿‘è¿è¡Œæ—¶ç­‰æ•ˆäºä¼ ç»Ÿçš„æ³¢æŸæœç´¢ã€‚</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>å››ä¸ªåŸºå‡†çš„å®è¯ç»“æœè¡¨æ˜ï¼Œç¥ç»é€»è¾‘è§£ç ä¼˜äºä»¥å‰çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å¤„ç†æˆ‘ä»¬çš„çº¦æŸå­é›†çš„ç®—æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ä½¿ç”¨ NeuroLogic Decoding çš„æ— ç›‘ç£æ¨¡å‹é€šå¸¸ä¼˜äºä½¿ç”¨ä¼ ç»Ÿè§£ç çš„ç›‘ç£æ¨¡å‹ï¼Œå³ä½¿åè€…åŸºäºç›¸å½“å¤§çš„ç½‘ç»œã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå¤§è§„æ¨¡ç¥ç»ç½‘ç»œå¯¹ç»†ç²’åº¦å¯æ§ç”Ÿæˆçš„é™åˆ¶å’Œæ¨ç†æ—¶é—´ç®—æ³•çš„å‰æ™¯ã€‚</td><td>Ximing Lu   Peter West   Rowan Zellers   Ronan Le Bras   Chandra Bhagavatula   Yejin Choi</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05801&#39;]">Plot-guided Adversarial Example Construction for Evaluating Open-domain Story Generation</a></td><td></td><td><a href="https://github.com/PlusLabNLP/Plot-guided-Coherence-Evaluation">https://github.com/PlusLabNLP/Plot-guided-Coherence-Evaluation</a></td><td><a href="https://arxiv.org/pdf/2104.05801">https://arxiv.org/pdf/2104.05801</a></td><td>With the recent advances of open-domain story generation, the lack of reliable automatic evaluation metrics becomes an increasingly imperative issue that hinders the fast development of story generation. According to conducted researches in this regard, learnable evaluation metrics have promised more accurate assessments by having higher correlations with human judgments. A critical bottleneck of obtaining a reliable learnable evaluation metric is the lack of high-quality training data for classifiers to efficiently distinguish plausible and implausible machine-generated stories. Previous works relied on \textit{heuristically manipulated} plausible examples to mimic possible system drawbacks such as repetition, contradiction, or irrelevant content in the text level, which can be \textit{unnatural} and \textit{oversimplify} the characteristics of implausible machine-generated stories. We propose to tackle these issues by generating a more comprehensive set of implausible stories using {\em plots}, which are structured representations of controllable factors used to generate stories. Since these plots are compact and structured, it is easier to manipulate them to generate text with targeted undesirable properties, while at the same time maintain the grammatical correctness and naturalness of the generated sentences. To improve the quality of generated implausible stories, we further apply the adversarial filtering procedure presented by \citet{zellers2018swag} to select a more nuanced set of implausible texts. Experiments show that the evaluation metrics trained on our generated data result in more reliable automatic assessments that correlate remarkably better with human judgments compared to the baselines.</td><td>éšç€å¼€æ”¾åŸŸæ•…äº‹ç”Ÿæˆçš„æœ€æ–°è¿›å±•ï¼Œç¼ºä¹å¯é çš„è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡æˆä¸ºé˜»ç¢æ•…äº‹ç”Ÿæˆå¿«é€Ÿå‘å±•çš„æ—¥ç›Šç´§è¿«çš„é—®é¢˜ã€‚æ ¹æ®åœ¨è¿™æ–¹é¢è¿›è¡Œçš„ç ”ç©¶ï¼Œå¯å­¦ä¹ çš„è¯„ä¼°æŒ‡æ ‡é€šè¿‡ä¸äººç±»åˆ¤æ–­å…·æœ‰æ›´é«˜çš„ç›¸å…³æ€§ï¼Œæœ‰æœ›å®ç°æ›´å‡†ç¡®çš„è¯„ä¼°ã€‚è·å¾—å¯é çš„å¯å­¦ä¹ è¯„ä¼°æŒ‡æ ‡çš„ä¸€ä¸ªå…³é”®ç“¶é¢ˆæ˜¯ç¼ºä¹ç”¨äºåˆ†ç±»å™¨çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼Œä»¥æœ‰æ•ˆåŒºåˆ†æœºå™¨ç”Ÿæˆçš„å¯ä¿¡å’Œä¸å¯ä¿¡çš„æ•…äº‹ã€‚ä»¥å‰çš„å·¥ä½œä¾é \textit{å¯å‘å¼æ“ä½œ}ä¼¼æ˜¯è€Œéçš„ä¾‹å­æ¥æ¨¡ä»¿å¯èƒ½çš„ç³»ç»Ÿç¼ºé™·ï¼Œä¾‹å¦‚æ–‡æœ¬çº§åˆ«çš„é‡å¤ã€çŸ›ç›¾æˆ–ä¸ç›¸å…³çš„å†…å®¹ï¼Œè¿™äº›å¯èƒ½æ˜¯\textit{unnatural}å’Œ\textit{oversimplify}éš¾ä»¥ç½®ä¿¡çš„æœºå™¨çš„ç‰¹å¾-ç”Ÿæˆçš„æ•…äº‹ã€‚æˆ‘ä»¬å»ºè®®é€šè¿‡ä½¿ç”¨ {\em plots} ç”Ÿæˆä¸€ç»„æ›´å…¨é¢çš„éš¾ä»¥ç½®ä¿¡çš„æ•…äº‹æ¥è§£å†³è¿™äº›é—®é¢˜ï¼Œè¿™äº›æ•…äº‹æ˜¯ç”¨äºç”Ÿæˆæ•…äº‹çš„å¯æ§å› ç´ çš„ç»“æ„åŒ–è¡¨ç¤ºã€‚ç”±äºè¿™äº›æƒ…èŠ‚ç´§å‡‘ä¸”ç»“æ„åŒ–ï¼Œå› æ­¤æ›´å®¹æ˜“æ“çºµå®ƒä»¬ä»¥ç”Ÿæˆå…·æœ‰é’ˆå¯¹æ€§çš„ä¸è‰¯å±æ€§çš„æ–‡æœ¬ï¼ŒåŒæ—¶ä¿æŒç”Ÿæˆçš„å¥å­çš„è¯­æ³•æ­£ç¡®æ€§å’Œè‡ªç„¶æ€§ã€‚ä¸ºäº†æé«˜ç”Ÿæˆçš„éš¾ä»¥ç½®ä¿¡çš„æ•…äº‹çš„è´¨é‡ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥åº”ç”¨äº†\citet{zellers2018swag} æå‡ºçš„å¯¹æŠ—æ€§è¿‡æ»¤ç¨‹åºæ¥é€‰æ‹©ä¸€ç»„æ›´ç»†å¾®çš„éš¾ä»¥ç½®ä¿¡çš„æ–‡æœ¬ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨æˆ‘ä»¬ç”Ÿæˆçš„æ•°æ®ä¸Šè®­ç»ƒçš„è¯„ä¼°æŒ‡æ ‡ä¼šäº§ç”Ÿæ›´å¯é çš„è‡ªåŠ¨è¯„ä¼°ï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼Œä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§æ˜æ˜¾æ›´å¥½ã€‚</td><td>Sarik Ghazarian   Zixi Liu   Akash SM   Ralph Weischedel   Aram Galstyan   Nanyun Peng</td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2006.15720&#39;]">Progressive Generation of Long Text with Pretrained Language Models</a></td><td></td><td><a href="https://github.com/tanyuqian/progressive-generation">https://github.com/tanyuqian/progressive-generation</a></td><td><a href="https://arxiv.org/pdf/2006.15720">https://arxiv.org/pdf/2006.15720</a></td><td>Large-scale language models (LMs) pretrained on massive corpora of text, such as GPT-2, are powerful open-domain text generators. However, as our systematic examination reveals, it is still challenging for such models to generate coherent long passages of text (e.g., 1000 tokens), especially when the models are fine-tuned to the target domain on a small corpus. Previous planning-then-generation methods also fall short of producing such long text in various domains. To overcome the limitations, we propose a simple but effective method of generating text in a progressive manner, inspired by generating images from low to high resolution. Our method first produces domain-specific content keywords and then progressively refines them into complete passages in multiple stages. The simple design allows our approach to take advantage of pretrained LMs at each stage and effectively adapt to any target domain given only a small set of examples. We conduct a comprehensive empirical study with a broad set of evaluation metrics, and show that our approach significantly improves upon the fine-tuned large LMs and various planning-then-generation methods in terms of quality and sample efficiency. Human evaluation also validates that our model generations are more coherent.</td><td>åœ¨å¤§é‡æ–‡æœ¬è¯­æ–™åº“ï¼ˆä¾‹å¦‚ GPT-2ï¼‰ä¸Šé¢„è®­ç»ƒçš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ (LM) æ˜¯å¼ºå¤§çš„å¼€æ”¾åŸŸæ–‡æœ¬ç”Ÿæˆå™¨ã€‚ç„¶è€Œï¼Œæ­£å¦‚æˆ‘ä»¬çš„ç³»ç»Ÿæ£€æŸ¥æ‰€æ­ç¤ºçš„é‚£æ ·ï¼Œè¿™äº›æ¨¡å‹ç”Ÿæˆè¿è´¯çš„é•¿æ–‡æœ¬æ®µè½ï¼ˆä¾‹å¦‚ 1000 ä¸ªæ ‡è®°ï¼‰ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯å½“æ¨¡å‹åœ¨å°å‹è¯­æ–™åº“ä¸Šé’ˆå¯¹ç›®æ ‡åŸŸè¿›è¡Œå¾®è°ƒæ—¶ã€‚ä»¥å‰çš„è§„åˆ’ç„¶åç”Ÿæˆæ–¹æ³•ä¹Ÿæ— æ³•åœ¨å„ä¸ªé¢†åŸŸç”Ÿæˆå¦‚æ­¤é•¿çš„æ–‡æœ¬ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»¥æ¸è¿›æ–¹å¼ç”Ÿæˆæ–‡æœ¬çš„ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå…¶çµæ„Ÿæ¥è‡ªäºç”Ÿæˆä»ä½åˆ†è¾¨ç‡åˆ°é«˜åˆ†è¾¨ç‡çš„å›¾åƒã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆç”Ÿæˆç‰¹å®šé¢†åŸŸçš„å†…å®¹å…³é”®å­—ï¼Œç„¶ååœ¨å¤šä¸ªé˜¶æ®µé€æ­¥å°†å®ƒä»¬ç»†åŒ–ä¸ºå®Œæ•´çš„æ®µè½ã€‚ç®€å•çš„è®¾è®¡ä½¿æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿåœ¨æ¯ä¸ªé˜¶æ®µåˆ©ç”¨é¢„è®­ç»ƒçš„ LMï¼Œå¹¶æœ‰æ•ˆåœ°é€‚åº”ä»»ä½•ä»…ç»™å®šä¸€å°éƒ¨åˆ†ç¤ºä¾‹çš„ç›®æ ‡åŸŸã€‚æˆ‘ä»¬ä½¿ç”¨å¹¿æ³›çš„è¯„ä¼°æŒ‡æ ‡è¿›è¡Œäº†å…¨é¢çš„å®è¯ç ”ç©¶ï¼Œå¹¶è¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨è´¨é‡å’Œæ ·æœ¬æ•ˆç‡æ–¹é¢æ˜¾ç€æ”¹è¿›äº†å¾®è°ƒçš„å¤§å‹ LM å’Œå„ç§è§„åˆ’ç„¶åç”Ÿæˆæ–¹æ³•ã€‚äººå·¥è¯„ä¼°è¿˜éªŒè¯äº†æˆ‘ä»¬çš„æ¨¡å‹ç”Ÿæˆæ›´åŠ è¿è´¯ã€‚</td><td>Bowen Tan   Zichao Yang   Maruan AI-Shedivat   Eric P. Xing   Zhiting Hu</td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.02484&#39;]">OodGAN: Generative Adversarial Network for Out-of-Domain Data Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.02484">https://arxiv.org/pdf/2104.02484</a></td><td>Detecting an Out-of-Domain (OOD) utterance is crucial for a robust dialog system. Most dialog systems are trained on a pool of annotated OOD data to achieve this goal. However, collecting the annotated OOD data for a given domain is an expensive process. To mitigate this issue, previous works have proposed generative adversarial networks (GAN) based models to generate OOD data for a given domain automatically. However, these proposed models do not work directly with the text. They work with the textâ€™s latent space instead, enforcing these models to include components responsible for encoding text into latent space and decoding it back, such as auto-encoder. These components increase the model complexity, making it difficult to train. We propose OodGAN, a sequential generative adversarial network (SeqGAN) based model for OOD data generation. Our proposed model works directly on the text and hence eliminates the need to include an auto-encoder. OOD data generated using OodGAN model outperforms state-of-the-art in OOD detection metrics for ROSTD (67% relative improvement in FPR 0.95) and OSQ datasets (28% relative improvement in FPR 0.95) (Zheng et al., 2020).</td><td>æ£€æµ‹åŸŸå¤– (OOD) è¯è¯­å¯¹äºå¼ºå¤§çš„å¯¹è¯ç³»ç»Ÿè‡³å…³é‡è¦ã€‚å¤§å¤šæ•°å¯¹è¯ç³»ç»Ÿéƒ½åœ¨å¸¦æ³¨é‡Šçš„ OOD æ•°æ®æ± ä¸Šè¿›è¡Œè®­ç»ƒä»¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚ä½†æ˜¯ï¼Œä¸ºç»™å®šåŸŸæ”¶é›†å¸¦æ³¨é‡Šçš„ OOD æ•°æ®æ˜¯ä¸€ä¸ªæ˜‚è´µçš„è¿‡ç¨‹ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œä»¥å‰çš„å·¥ä½œæå‡ºäº†åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) çš„æ¨¡å‹æ¥è‡ªåŠ¨ç”Ÿæˆç»™å®šåŸŸçš„ OOD æ•°æ®ã€‚ç„¶è€Œï¼Œè¿™äº›æè®®çš„æ¨¡å‹å¹¶ä¸ç›´æ¥ä¸æ–‡æœ¬ä¸€èµ·å·¥ä½œã€‚ç›¸åï¼Œå®ƒä»¬ä½¿ç”¨æ–‡æœ¬çš„æ½œåœ¨ç©ºé—´ï¼Œå¼ºåˆ¶è¿™äº›æ¨¡å‹åŒ…å«è´Ÿè´£å°†æ–‡æœ¬ç¼–ç åˆ°æ½œåœ¨ç©ºé—´å¹¶å°†å…¶è§£ç å›æ¥çš„ç»„ä»¶ï¼Œä¾‹å¦‚è‡ªåŠ¨ç¼–ç å™¨ã€‚è¿™äº›ç»„ä»¶å¢åŠ äº†æ¨¡å‹çš„å¤æ‚æ€§ï¼Œä½¿å…¶éš¾ä»¥è®­ç»ƒã€‚æˆ‘ä»¬æå‡ºäº† OodGANï¼Œè¿™æ˜¯ä¸€ç§åŸºäºåºåˆ—ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (SeqGAN) çš„æ¨¡å‹ï¼Œç”¨äºç”Ÿæˆ OOD æ•°æ®ã€‚æˆ‘ä»¬æå‡ºçš„æ¨¡å‹ç›´æ¥ä½œç”¨äºæ–‡æœ¬ï¼Œå› æ­¤ä¸éœ€è¦åŒ…å«è‡ªåŠ¨ç¼–ç å™¨ã€‚ä½¿ç”¨ OodGAN æ¨¡å‹ç”Ÿæˆçš„ OOD æ•°æ®åœ¨ ROSTDï¼ˆFPR 0.95 çš„ç›¸å¯¹æ”¹è¿› 67%ï¼‰å’Œ OSQ æ•°æ®é›†ï¼ˆFPR 0.95 çš„ç›¸å¯¹æ”¹è¿› 28%ï¼‰ï¼ˆZheng ç­‰äººï¼Œ2020ï¼‰çš„ OOD æ£€æµ‹æŒ‡æ ‡æ–¹é¢ä¼˜äºæœ€æ–°æŠ€æœ¯ã€‚</td><td>Petr Marek   Vishal Ishwar Naik   Vincent Auvray   Anuj Goyal</td></tr><tr><td>7</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.11205&#39;]">Jointly Optimizing Diversity and Relevance in Neural Response Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.11205">https://arxiv.org/pdf/1902.11205</a></td><td>Although recent neural conversation models have shown great potential, they often generate bland and generic responses. While various approaches have been explored to diversify the output of the conversation model, the improvement often comes at the cost of decreased relevance. In this paper, we propose a SpaceFusion model to jointly optimize diversity and relevance that essentially fuses the latent space of a sequence-to-sequence model and that of an autoencoder model by leveraging novel regularization terms. As a result, our approach induces a latent space in which the distance and direction from the predicted response vector roughly match the relevance and diversity, respectively. This property also lends itself well to an intuitive visualization of the latent space. Both automatic and human evaluation results demonstrate that the proposed approach brings significant improvement compared to strong baselines in both diversity and relevance.</td><td>å°½ç®¡æœ€è¿‘çš„ç¥ç»å¯¹è¯æ¨¡å‹æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†å®ƒä»¬é€šå¸¸ä¼šäº§ç”Ÿå¹³æ·¡è€Œä¸€èˆ¬çš„ååº”ã€‚è™½ç„¶å·²ç»æ¢ç´¢äº†å„ç§æ–¹æ³•æ¥ä½¿å¯¹è¯æ¨¡å‹çš„è¾“å‡ºå¤šæ ·åŒ–ï¼Œä½†æ”¹è¿›é€šå¸¸ä»¥é™ä½ç›¸å…³æ€§ä¸ºä»£ä»·ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ SpaceFusion æ¨¡å‹æ¥è”åˆä¼˜åŒ–å¤šæ ·æ€§å’Œç›¸å…³æ€§ï¼Œè¯¥æ¨¡å‹é€šè¿‡åˆ©ç”¨æ–°çš„æ­£åˆ™åŒ–é¡¹åŸºæœ¬ä¸Šèåˆäº†åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„æ½œåœ¨ç©ºé—´å’Œè‡ªåŠ¨ç¼–ç å™¨æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ã€‚ç»“æœï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªæ½œåœ¨ç©ºé—´ï¼Œå…¶ä¸­ä¸é¢„æµ‹å“åº”å‘é‡çš„è·ç¦»å’Œæ–¹å‘åˆ†åˆ«å¤§è‡´åŒ¹é…ç›¸å…³æ€§å’Œå¤šæ ·æ€§ã€‚æ­¤å±æ€§ä¹Ÿéå¸¸é€‚åˆæ½œåœ¨ç©ºé—´çš„ç›´è§‚å¯è§†åŒ–ã€‚è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°ç»“æœéƒ½è¡¨æ˜ï¼Œä¸å¤šæ ·æ€§å’Œç›¸å…³æ€§çš„å¼ºå¤§åŸºçº¿ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å¸¦æ¥äº†æ˜¾ç€çš„æ”¹è¿›ã€‚</td><td>Xiang Gao   Sungjin Lee   Yizhe Zhang   Chris Brockett   Michel Galley   Jianfeng Gao   Bill Dolan</td></tr><tr><td>8</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.11564&#39;]">Neural Text Generation from Rich Semantic Representations</a></td><td></td><td><a href="https://github.com/shlurbee/dmrs-text-generation-naacl2019">https://github.com/shlurbee/dmrs-text-generation-naacl2019</a></td><td><a href="https://arxiv.org/pdf/1904.11564">https://arxiv.org/pdf/1904.11564</a></td><td>We propose neural models to generate high-quality text from structured representations based on Minimal Recursion Semantics (MRS). MRS is a rich semantic representation that encodes more precise semantic detail than other representations such as Abstract Meaning Representation (AMR). We show that a sequence-to-sequence model that maps a linearization of Dependency MRS, a graph-based representation of MRS, to English text can achieve a BLEU score of 66.11 when trained on gold data. The performance can be improved further using a high-precision, broad coverage grammar-based parser to generate a large silver training corpus, achieving a final BLEU score of 77.17 on the full test set, and 83.37 on the subset of test data most closely matching the silver data domain. Our results suggest that MRS-based representations are a good choice for applications that need both structured semantics and the ability to produce natural language text as output.</td><td>æˆ‘ä»¬æå‡ºç¥ç»æ¨¡å‹ï¼Œä»åŸºäºæœ€å°é€’å½’è¯­ä¹‰ (MRS) çš„ç»“æ„åŒ–è¡¨ç¤ºç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬ã€‚ MRS æ˜¯ä¸€ç§ä¸°å¯Œçš„è¯­ä¹‰è¡¨ç¤ºï¼Œä¸æŠ½è±¡å«ä¹‰è¡¨ç¤º (AMR) ç­‰å…¶ä»–è¡¨ç¤ºç›¸æ¯”ï¼Œå®ƒç¼–ç äº†æ›´ç²¾ç¡®çš„è¯­ä¹‰ç»†èŠ‚ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œå½“å¯¹é»„é‡‘æ•°æ®è¿›è¡Œè®­ç»ƒæ—¶ï¼Œå°†ä¾èµ–å…³ç³» MRSï¼ˆä¸€ç§åŸºäºå›¾å½¢çš„ MRS è¡¨ç¤ºï¼‰çš„çº¿æ€§åŒ–æ˜ å°„åˆ°è‹±æ–‡æ–‡æœ¬çš„åºåˆ—åˆ°åºåˆ—æ¨¡å‹å¯ä»¥è¾¾åˆ° 66.11 çš„ BLEU åˆ†æ•°ã€‚ä½¿ç”¨é«˜ç²¾åº¦ã€è¦†ç›–é¢å¹¿çš„åŸºäºè¯­æ³•çš„è§£æå™¨ç”Ÿæˆå¤§å‹é“¶è‰²è®­ç»ƒè¯­æ–™åº“ï¼Œå¯ä»¥è¿›ä¸€æ­¥æé«˜æ€§èƒ½ï¼Œåœ¨å®Œæ•´æµ‹è¯•é›†ä¸Šè·å¾— 77.17 çš„æœ€ç»ˆ BLEU åˆ†æ•°ï¼Œåœ¨æœ€åŒ¹é…çš„æµ‹è¯•æ•°æ®å­é›†ä¸Šè·å¾— 83.37 åˆ†é“¶è‰²æ•°æ®åŸŸã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå¯¹äºæ—¢éœ€è¦ç»“æ„åŒ–è¯­ä¹‰åˆéœ€è¦ç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ä½œä¸ºè¾“å‡ºçš„åº”ç”¨ç¨‹åºï¼ŒåŸºäº MRS çš„è¡¨ç¤ºæ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚</td><td>Valerie Hajdik   Jan Buys   Michael W. Goodman   Emily M. Bender</td></tr><tr><td>9</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.02342&#39;]">Text Generation from Knowledge Graphs with Graph Transformers</a></td><td></td><td><a href="https://github.com/rikdz/GraphWriter">https://github.com/rikdz/GraphWriter</a></td><td><a href="https://arxiv.org/pdf/1904.02342">https://arxiv.org/pdf/1904.02342</a></td><td>Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.</td><td>ç”Ÿæˆè¡¨è¾¾è·¨è¶Šå¤šä¸ªå¥å­çš„å¤æ‚æƒ³æ³•çš„æ–‡æœ¬éœ€è¦å¯¹å…¶å†…å®¹è¿›è¡Œç»“æ„åŒ–è¡¨ç¤ºï¼ˆæ–‡æ¡£è®¡åˆ’ï¼‰ï¼Œä½†è¿™äº›è¡¨ç¤ºæ‰‹åŠ¨ç”Ÿæˆçš„æˆæœ¬é«˜å¾—ä»¤äººæœ›è€Œå´æ­¥ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è§£å†³äº†ä»ä¿¡æ¯æå–ç³»ç»Ÿçš„è¾“å‡ºï¼Œå°¤å…¶æ˜¯çŸ¥è¯†å›¾è°±ä¸­ç”Ÿæˆè¿è´¯çš„å¤šå¥æ–‡æœ¬çš„é—®é¢˜ã€‚å›¾å½¢çŸ¥è¯†è¡¨ç¤ºåœ¨è®¡ç®—ä¸­æ— å¤„ä¸åœ¨ï¼Œä½†ç”±äºå…¶éå±‚æ¬¡æ€§ã€é•¿è·ç¦»ä¾èµ–çš„å´©æºƒå’Œç»“æ„å¤šæ ·æ€§ï¼Œå¯¹æ–‡æœ¬ç”ŸæˆæŠ€æœ¯æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„å›¾è½¬æ¢ç¼–ç å™¨ï¼Œå®ƒå¯ä»¥åˆ©ç”¨æ­¤ç±»çŸ¥è¯†å›¾çš„å…³ç³»ç»“æ„ï¼Œè€Œæ— éœ€æ–½åŠ çº¿æ€§åŒ–æˆ–åˆ†å±‚çº¦æŸã€‚ç»“åˆåˆ°ç¼–ç å™¨ - è§£ç å™¨è®¾ç½®ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„å¯è®­ç»ƒç³»ç»Ÿï¼Œç”¨äºæˆ‘ä»¬åº”ç”¨äºç§‘å­¦æ–‡æœ¬é¢†åŸŸçš„å›¾åˆ°æ–‡æœ¬ç”Ÿæˆã€‚è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æŠ€æœ¯äº§ç”Ÿäº†æ›´å¤šä¿¡æ¯æ–‡æœ¬ï¼Œä¸ç«äº‰æ€§ç¼–ç å™¨ - è§£ç å™¨æ–¹æ³•ç›¸æ¯”ï¼Œè¿™äº›æ–‡æœ¬è¡¨ç°å‡ºæ›´å¥½çš„æ–‡æ¡£ç»“æ„ã€‚</td><td>Rik Koncel-Kedziorski   Dhanush Bekal   Yi Luan   Mirella Lapata   Hannaneh Hajishirzi</td></tr><tr><td>10</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.04428&#39;]">Text Generation with Exemplar-based Adaptive Decoding</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.04428">https://arxiv.org/pdf/1904.04428</a></td><td>We propose a novel conditioned text generation model. It draws inspiration from traditional template-based text generation techniques, where the source provides the content (i.e., what to say), and the template influences how to say it. Building on the successful encoder-decoder paradigm, it first encodes the content representation from the given input text; to produce the output, it retrieves exemplar text from the training data as â€œsoft templates,â€ which are then used to construct an exemplar-specific decoder. We evaluate the proposed model on abstractive text summarization and data-to-text generation. Empirical results show that this model achieves strong performance and outperforms comparable baselines.</td><td>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡ä»¶æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ã€‚å®ƒä»ä¼ ç»Ÿçš„åŸºäºæ¨¡æ¿çš„æ–‡æœ¬ç”ŸæˆæŠ€æœ¯ä¸­æ±²å–çµæ„Ÿï¼Œå…¶ä¸­æºæä¾›å†…å®¹ï¼ˆå³è¯´ä»€ä¹ˆï¼‰ï¼Œè€Œæ¨¡æ¿å½±å“å¦‚ä½•è¯´ã€‚åŸºäºæˆåŠŸçš„ç¼–ç å™¨-è§£ç å™¨èŒƒä¾‹ï¼Œå®ƒé¦–å…ˆå¯¹ç»™å®šè¾“å…¥æ–‡æœ¬çš„å†…å®¹è¡¨ç¤ºè¿›è¡Œç¼–ç ï¼›ä¸ºäº†äº§ç”Ÿè¾“å‡ºï¼Œå®ƒä»è®­ç»ƒæ•°æ®ä¸­æ£€ç´¢ç¤ºä¾‹æ–‡æœ¬ä½œä¸ºâ€œè½¯æ¨¡æ¿â€ï¼Œç„¶åç”¨äºæ„å»ºç‰¹å®šäºç¤ºä¾‹çš„è§£ç å™¨ã€‚æˆ‘ä»¬åœ¨æŠ½è±¡æ–‡æœ¬æ‘˜è¦å’Œæ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆæ–¹é¢è¯„ä¼°äº†æ‰€æå‡ºçš„æ¨¡å‹ã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹å®ç°äº†å¼ºå¤§çš„æ€§èƒ½å¹¶ä¼˜äºå¯æ¯”è¾ƒçš„åŸºçº¿ã€‚</td><td>Hao Peng   Ankur P. Parikh   Manaal Faruqui   Bhuwan Dhingra   Dipanjan Das</td></tr><tr><td>11</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1809.01694&#39;]">Accelerated Reinforcement Learning for Sentence Generation by Vocabulary Prediction</a></td><td></td><td><a href="https://github.com/hassyGo/NLG-RL">https://github.com/hassyGo/NLG-RL</a></td><td><a href="https://arxiv.org/pdf/1809.01694">https://arxiv.org/pdf/1809.01694</a></td><td>A major obstacle in reinforcement learning-based sentence generation is the large action space whose size is equal to the vocabulary size of the target-side language. To improve the efficiency of reinforcement learning, we present a novel approach for reducing the action space based on dynamic vocabulary prediction. Our method first predicts a fixed-size small vocabulary for each input to generate its target sentence. The input-specific vocabularies are then used at supervised and reinforcement learning steps, and also at test time. In our experiments on six machine translation and two image captioning datasets, our method achieves faster reinforcement learning ($\sim$2.7x faster) with less GPU memory ($\sim$2.3x less) than the full-vocabulary counterpart. The reinforcement learning with our method consistently leads to significant improvement of BLEU scores, and the scores are equal to or better than those of baselines using the full vocabularies, with faster decoding time ($\sim$3x faster) on CPUs.</td><td>åŸºäºå¼ºåŒ–å­¦ä¹ çš„å¥å­ç”Ÿæˆçš„ä¸€ä¸ªä¸»è¦éšœç¢æ˜¯å¤§çš„åŠ¨ä½œç©ºé—´ï¼Œå…¶å¤§å°ç­‰äºç›®æ ‡æ–¹è¯­è¨€çš„è¯æ±‡é‡ã€‚ä¸ºäº†æé«˜å¼ºåŒ–å­¦ä¹ çš„æ•ˆç‡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºåŠ¨æ€è¯æ±‡é¢„æµ‹æ¥å‡å°‘åŠ¨ä½œç©ºé—´çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆä¸ºæ¯ä¸ªè¾“å…¥é¢„æµ‹ä¸€ä¸ªå›ºå®šå¤§å°çš„å°è¯æ±‡è¡¨ä»¥ç”Ÿæˆå…¶ç›®æ ‡å¥å­ã€‚ç„¶ååœ¨ç›‘ç£å’Œå¼ºåŒ–å­¦ä¹ æ­¥éª¤ä»¥åŠæµ‹è¯•æ—¶ä½¿ç”¨ç‰¹å®šäºè¾“å…¥çš„è¯æ±‡è¡¨ã€‚åœ¨æˆ‘ä»¬å¯¹å…­ä¸ªæœºå™¨ç¿»è¯‘å’Œä¸¤ä¸ªå›¾åƒå­—å¹•æ•°æ®é›†çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†æ›´å¿«çš„å¼ºåŒ–å­¦ä¹ ï¼ˆ$\sim$2.7x å¿«ï¼‰ï¼Œè€Œ GPU å†…å­˜æ›´å°‘ï¼ˆ$\sim$2.3xï¼‰æ¯”å…¨è¯æ±‡å¯¹åº”ç‰©å°‘ã€‚ä½¿ç”¨æˆ‘ä»¬çš„æ–¹æ³•è¿›è¡Œçš„å¼ºåŒ–å­¦ä¹ å§‹ç»ˆå¯¼è‡´ BLEU åˆ†æ•°çš„æ˜¾ç€æé«˜ï¼Œå¹¶ä¸”åˆ†æ•°ç­‰äºæˆ–ä¼˜äºä½¿ç”¨å®Œæ•´è¯æ±‡è¡¨çš„åŸºçº¿çš„åˆ†æ•°ï¼Œå¹¶ä¸”åœ¨ CPU ä¸Šå…·æœ‰æ›´å¿«çš„è§£ç æ—¶é—´ï¼ˆ$\sim$3x å¿«ï¼‰ã€‚</td><td>Kazuma Hashimoto   Yoshimasa Tsuruoka</td></tr><tr><td>12</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.09722&#39;]">Pre-trained language model representations for language generation</a></td><td></td><td><a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></td><td><a href="https://arxiv.org/pdf/1903.09722">https://arxiv.org/pdf/1903.09722</a></td><td>Pre-trained language model representations have been successful in a wide range of language understanding tasks. In this paper, we examine different strategies to integrate pre-trained representations into sequence to sequence models and apply it to neural machine translation and abstractive summarization. We find that pre-trained representations are most effective when added to the encoder network which slows inference by only 14%. Our experiments in machine translation show gains of up to 5.3 BLEU in a simulated resource-poor setup. While returns diminish with more labeled data, we still observe improvements when millions of sentence-pairs are available. Finally, on abstractive summarization we achieve a new state of the art on the full text version of CNN/DailyMail.</td><td>é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹è¡¨ç¤ºå·²åœ¨å¹¿æ³›çš„è¯­è¨€ç†è§£ä»»åŠ¡ä¸­å–å¾—æˆåŠŸã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å°†é¢„è®­ç»ƒè¡¨ç¤ºé›†æˆåˆ°åºåˆ—åˆ°åºåˆ—æ¨¡å‹ä¸­çš„ä¸åŒç­–ç•¥ï¼Œå¹¶å°†å…¶åº”ç”¨äºç¥ç»æœºå™¨ç¿»è¯‘å’ŒæŠ½è±¡æ‘˜è¦ã€‚æˆ‘ä»¬å‘ç°ï¼Œå°†é¢„è®­ç»ƒçš„è¡¨ç¤ºæ·»åŠ åˆ°ç¼–ç å™¨ç½‘ç»œæ—¶æœ€æœ‰æ•ˆï¼Œä»…å°†æ¨ç†é€Ÿåº¦é™ä½ 14%ã€‚æˆ‘ä»¬çš„æœºå™¨ç¿»è¯‘å®éªŒè¡¨æ˜ï¼Œåœ¨æ¨¡æ‹Ÿèµ„æºåŒ®ä¹çš„è®¾ç½®ä¸­ï¼Œå¢ç›Šé«˜è¾¾ 5.3 BLEUã€‚è™½ç„¶å›æŠ¥éšç€æ›´å¤šæ ‡è®°æ•°æ®è€Œå‡å°‘ï¼Œä½†å½“æœ‰æ•°ç™¾ä¸‡ä¸ªå¥å­å¯¹å¯ç”¨æ—¶ï¼Œæˆ‘ä»¬ä»ç„¶è§‚å¯Ÿåˆ°æ”¹è¿›ã€‚æœ€åï¼Œåœ¨æŠ½è±¡æ‘˜è¦æ–¹é¢ï¼Œæˆ‘ä»¬åœ¨ CNN/DailyMail çš„å…¨æ–‡ç‰ˆæœ¬ä¸Šå®ç°äº†æœ€æ–°çš„æŠ€æœ¯æ°´å¹³ã€‚</td><td>Sergey Edunov   Alexei Baevski   Michael Auli</td></tr><tr><td>13</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.01301&#39;]">Pragmatically Informative Text Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.01301">https://arxiv.org/pdf/1904.01301</a></td><td>We improve the informativeness of models for conditional text generation using techniques from computational pragmatics. These techniques formulate language production as a game between speakers and listeners, in which a speaker should generate output text that a listener can use to correctly identify the original input that the text describes. While such approaches are widely used in cognitive science and grounded language learning, they have received less attention for more standard language generation tasks. We consider two pragmatic modeling methods for text generation: one where pragmatics is imposed by information preservation, and another where pragmatics is imposed by explicit modeling of distractors. We find that these methods improve the performance of strong existing systems for abstractive summarization and generation from structured meaning representations.</td><td>æˆ‘ä»¬ä½¿ç”¨è®¡ç®—è¯­ç”¨å­¦çš„æŠ€æœ¯æé«˜äº†æ¡ä»¶æ–‡æœ¬ç”Ÿæˆæ¨¡å‹çš„ä¿¡æ¯é‡ã€‚è¿™äº›æŠ€æœ¯å°†è¯­è¨€ç”Ÿæˆè¡¨è¿°ä¸ºè¯´è¯è€…å’Œå¬è€…ä¹‹é—´çš„æ¸¸æˆï¼Œå…¶ä¸­è¯´è¯è€…åº”è¯¥ç”Ÿæˆè¾“å‡ºæ–‡æœ¬ï¼Œå¬è€…å¯ä»¥ä½¿ç”¨è¯¥è¾“å‡ºæ–‡æœ¬æ¥æ­£ç¡®è¯†åˆ«æ–‡æœ¬æè¿°çš„åŸå§‹è¾“å…¥ã€‚è™½ç„¶è¿™äº›æ–¹æ³•å¹¿æ³›ç”¨äºè®¤çŸ¥ç§‘å­¦å’ŒåŸºç¡€è¯­è¨€å­¦ä¹ ï¼Œä½†å®ƒä»¬åœ¨æ›´æ ‡å‡†çš„è¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸­å—åˆ°çš„å…³æ³¨è¾ƒå°‘ã€‚æˆ‘ä»¬è€ƒè™‘äº†ä¸¤ç§ç”¨äºæ–‡æœ¬ç”Ÿæˆçš„è¯­ç”¨å»ºæ¨¡æ–¹æ³•ï¼šä¸€ç§æ˜¯é€šè¿‡ä¿¡æ¯ä¿å­˜æ¥æ–½åŠ è¯­ç”¨ï¼Œå¦ä¸€ç§æ˜¯é€šè¿‡å¹²æ‰°é¡¹çš„æ˜¾å¼å»ºæ¨¡æ¥æ–½åŠ è¯­ç”¨ã€‚æˆ‘ä»¬å‘ç°è¿™äº›æ–¹æ³•æé«˜äº†å¼ºå¤§çš„ç°æœ‰ç³»ç»Ÿçš„æ€§èƒ½ï¼Œç”¨äºä»ç»“æ„åŒ–å«ä¹‰è¡¨ç¤ºä¸­è¿›è¡ŒæŠ½è±¡æ‘˜è¦å’Œç”Ÿæˆã€‚</td><td>Sheng Shen   Daniel Fried   Jacob Andreas   Dan Klein</td></tr><tr><td>14</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1806.08462&#39;]">Stochastic Wasserstein Autoencoder for Probabilistic Sentence Generation</a></td><td></td><td><a href="https://github.com/HareeshBahuleyan/probabilistic_nlg">https://github.com/HareeshBahuleyan/probabilistic_nlg</a></td><td><a href="https://arxiv.org/pdf/1806.08462">https://arxiv.org/pdf/1806.08462</a></td><td>The variational autoencoder (VAE) imposes a probabilistic distribution (typically Gaussian) on the latent space and penalizes the Kullbackâ€”Leibler (KL) divergence between the posterior and prior. In NLP, VAEs are extremely difficult to train due to the problem of KL collapsing to zero. One has to implement various heuristics such as KL weight annealing and word dropout in a carefully engineered manner to successfully train a VAE for text. In this paper, we propose to use the Wasserstein autoencoder (WAE) for probabilistic sentence generation, where the encoder could be either stochastic or deterministic. We show theoretically and empirically that, in the original WAE, the stochastically encoded Gaussian distribution tends to become a Dirac-delta function, and we propose a variant of WAE that encourages the stochasticity of the encoder. Experimental results show that the latent space learned by WAE exhibits properties of continuity and smoothness as in VAEs, while simultaneously achieving much higher BLEU scores for sentence reconstruction.</td><td></td><td>Hareesh Bahuleyan   Lili Mou   Hao Zhou   Olga Vechtomova</td></tr></tbody></table></div><h3 id="COLING-2"><a href="#COLING-2" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.04000&#39;, &#39;https://arxiv.org/abs/1911.03587&#39;, &#39;https://arxiv.org/abs/1704.06851&#39;]">Affective Text Generation</a></td><td></td><td><a href="https://github.com/ishikasingh/Affective-text-gen">https://github.com/ishikasingh/Affective-text-gen</a></td><td><a href="https://arxiv.org/pdf/2011.04000">https://arxiv.org/pdf/2011.04000</a></td><td>Human use language not just to convey information but also to express their inner feelings and mental states. In this work, we adapt the state-of-the-art language generation models to generate affective (emotional) text. We posit a model capable of generating affect-driven and topic-focused sentences without losing grammatical correctness as the affect intensity increases. We propose to incorporate emotion as prior for the probabilistic state-of-the-art text generation model such as GPT-2. The model gives a user the flexibility to control the category and intensity of emotion as well as the topic of the generated text. Previous attempts at modelling fine-grained emotions fall out on grammatical correctness at extreme intensities, but our model is resilient to this and delivers robust results at all intensities. We conduct automated evaluations and human studies to test the performance of our model and provide a detailed comparison of the results with other models. In all evaluations, our model outperforms existing affective text generation models.</td><td>äººç±»ä½¿ç”¨è¯­è¨€ä¸ä»…æ˜¯ä¸ºäº†ä¼ è¾¾ä¿¡æ¯ï¼Œä¹Ÿæ˜¯ä¸ºäº†è¡¨è¾¾å†…å¿ƒçš„æ„Ÿå—å’Œå¿ƒç†çŠ¶æ€ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨æœ€å…ˆè¿›çš„è¯­è¨€ç”Ÿæˆæ¨¡å‹æ¥ç”Ÿæˆæƒ…æ„Ÿï¼ˆæƒ…æ„Ÿï¼‰æ–‡æœ¬ã€‚æˆ‘ä»¬å‡è®¾ä¸€ä¸ªæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæƒ…æ„Ÿé©±åŠ¨å’Œä»¥ä¸»é¢˜ä¸ºä¸­å¿ƒçš„å¥å­ï¼Œè€Œä¸ä¼šéšç€æƒ…æ„Ÿå¼ºåº¦çš„å¢åŠ è€Œå¤±å»è¯­æ³•æ­£ç¡®æ€§ã€‚æˆ‘ä»¬å»ºè®®å°†æƒ…æ„Ÿä½œä¸ºå…ˆéªŒçš„æ¦‚ç‡çŠ¶æ€æœ€å…ˆè¿›çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œä¾‹å¦‚ GPT-2ã€‚è¯¥æ¨¡å‹ä½¿ç”¨æˆ·å¯ä»¥çµæ´»åœ°æ§åˆ¶æƒ…ç»ªçš„ç±»åˆ«å’Œå¼ºåº¦ä»¥åŠç”Ÿæˆæ–‡æœ¬çš„ä¸»é¢˜ã€‚ä¹‹å‰å¯¹ç»†ç²’åº¦æƒ…ç»ªå»ºæ¨¡çš„å°è¯•åœ¨æç«¯å¼ºåº¦ä¸‹çš„è¯­æ³•æ­£ç¡®æ€§å¤±è´¥ï¼Œä½†æˆ‘ä»¬çš„æ¨¡å‹å¯¹æ­¤å…·æœ‰å¼¹æ€§ï¼Œå¹¶åœ¨æ‰€æœ‰å¼ºåº¦ä¸‹éƒ½èƒ½æä¾›ç¨³å¥çš„ç»“æœã€‚æˆ‘ä»¬è¿›è¡Œè‡ªåŠ¨è¯„ä¼°å’Œäººä½“ç ”ç©¶æ¥æµ‹è¯•æˆ‘ä»¬æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶æä¾›ä¸å…¶ä»–æ¨¡å‹çš„ç»“æœçš„è¯¦ç»†æ¯”è¾ƒã€‚åœ¨æ‰€æœ‰è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¼˜äºç°æœ‰çš„æƒ…æ„Ÿæ–‡æœ¬ç”Ÿæˆæ¨¡å‹ã€‚</td><td>Ishika Singh   Ahsan Barkati   Tushar Goswamy   Ashutosh Modi   Luca Massarelli   Fabio Petroni   Aleksandra Piktus   Myle Ott   Tim RocktÃ¤schel   Vassilis Plachouras   Fabrizio Silvestri   Sebastian Riedel   Sayan Ghosh   Mathieu Chollet   Eugene Laksana   Louis-Philippe Morency   Stefan Scherer</td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.13588&#39;]">Curious Case of Language Generation Evaluation Metrics: A Cautionary Tale</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.13588">https://arxiv.org/pdf/2010.13588</a></td><td>Automatic evaluation of language generation systems is a well-studied problem in Natural Language Processing. While novel metrics are proposed every year, a few popular metrics remain as the de facto metrics to evaluate tasks such as image captioning and machine translation, despite their known limitations. This is partly due to ease of use, and partly because researchers expect to see them and know how to interpret them. In this paper, we urge the community for more careful consideration of how they automatically evaluate their models by demonstrating important failure cases on multiple datasets, language pairs and tasks. Our experiments show that metrics (i) usually prefer system outputs to human-authored texts, (ii) can be insensitive to correct translations of rare words, (iii) can yield surprisingly high scores when given a single sentence as system output for the entire test set.</td><td>è¯­è¨€ç”Ÿæˆç³»ç»Ÿçš„è‡ªåŠ¨è¯„ä¼°æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ä¸€ä¸ªç»è¿‡å……åˆ†ç ”ç©¶çš„é—®é¢˜ã€‚è™½ç„¶æ¯å¹´éƒ½ä¼šæå‡ºæ–°çš„æŒ‡æ ‡ï¼Œä½†ä¸€äº›æµè¡Œçš„æŒ‡æ ‡ä»ç„¶æ˜¯è¯„ä¼°å›¾åƒå­—å¹•å’Œæœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡çš„å®é™…æŒ‡æ ‡ï¼Œå°½ç®¡å®ƒä»¬æœ‰å·²çŸ¥çš„å±€é™æ€§ã€‚è¿™éƒ¨åˆ†æ˜¯ç”±äºæ˜“äºä½¿ç”¨ï¼Œéƒ¨åˆ†æ˜¯å› ä¸ºç ”ç©¶äººå‘˜å¸Œæœ›çœ‹åˆ°å®ƒä»¬å¹¶çŸ¥é“å¦‚ä½•è§£é‡Šå®ƒä»¬ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ•¦ä¿ƒç¤¾åŒºæ›´ä»”ç»†åœ°è€ƒè™‘ä»–ä»¬å¦‚ä½•é€šè¿‡åœ¨å¤šä¸ªæ•°æ®é›†ã€è¯­è¨€å¯¹å’Œä»»åŠ¡ä¸Šå±•ç¤ºé‡è¦çš„å¤±è´¥æ¡ˆä¾‹æ¥è‡ªåŠ¨è¯„ä¼°ä»–ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒæŒ‡æ ‡ (i) é€šå¸¸æ›´å–œæ¬¢ç³»ç»Ÿè¾“å‡ºè€Œä¸æ˜¯äººå·¥ç¼–å†™çš„æ–‡æœ¬ï¼Œ(ii) å¯èƒ½å¯¹ç¨€æœ‰å•è¯çš„æ­£ç¡®ç¿»è¯‘ä¸æ•æ„Ÿï¼Œ(iii) å½“å°†å•ä¸ªå¥å­ä½œä¸ºæ•´ä¸ªç³»ç»Ÿçš„è¾“å‡ºæ—¶ï¼Œå¯ä»¥äº§ç”Ÿä»¤äººæƒŠè®¶çš„é«˜åˆ†æµ‹è¯•é›†ã€‚</td><td>Ozan Caglayan   Pranava Madhyastha   Lucia Specia</td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2012.04332&#39;]">Facts2Story: Controlling Text Generation by Key Facts</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.04332">https://arxiv.org/pdf/2012.04332</a></td><td>Recent advancements in self-attention neural network architectures have raised the bar for open-ended text generation. Yet, while current methods are capable of producing a coherent text which is several hundred words long, attaining control over the content that is being generated â€” as well as evaluating it â€” are still open questions. We propose a controlled generation task which is based on expanding a sequence of facts, expressed in natural language, into a longer narrative. We introduce human-based evaluation metrics for this task, as well as a method for deriving a large training dataset. We evaluate three methods on this task, based on fine-tuning pre-trained models. We show that while auto-regressive, unidirectional Language Models such as GPT2 produce better fluency, they struggle to adhere to the requested facts. We propose a plan-and-cloze model (using fine-tuned XLNet) which produces competitive fluency while adhering to the requested content.</td><td>è‡ªæ³¨æ„åŠ›ç¥ç»ç½‘ç»œæ¶æ„çš„æœ€æ–°è¿›å±•æé«˜äº†å¼€æ”¾å¼æ–‡æœ¬ç”Ÿæˆçš„é—¨æ§›ã€‚ç„¶è€Œï¼Œè™½ç„¶å½“å‰çš„æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå‡ ç™¾å­—é•¿çš„è¿è´¯æ–‡æœ¬ï¼Œä½†å¯¹æ­£åœ¨ç”Ÿæˆçš„å†…å®¹è¿›è¡Œæ§åˆ¶â€”â€”ä»¥åŠå¯¹å…¶è¿›è¡Œè¯„ä¼°â€”â€”ä»ç„¶æ˜¯æ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå—æ§ç”Ÿæˆä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡åŸºäºå°†ç”¨è‡ªç„¶è¯­è¨€è¡¨è¾¾çš„ä¸€ç³»åˆ—äº‹å®æ‰©å±•ä¸ºæ›´é•¿çš„å™è¿°ã€‚æˆ‘ä»¬ä¸ºæ­¤ä»»åŠ¡å¼•å…¥äº†åŸºäºäººç±»çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥åŠä¸€ç§ç”¨äºå¯¼å‡ºå¤§å‹è®­ç»ƒæ•°æ®é›†çš„æ–¹æ³•ã€‚æˆ‘ä»¬åŸºäºå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¯„ä¼°äº†é’ˆå¯¹æ­¤ä»»åŠ¡çš„ä¸‰ç§æ–¹æ³•ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œè™½ç„¶ GPT2 ç­‰è‡ªå›å½’ã€å•å‘è¯­è¨€æ¨¡å‹äº§ç”Ÿæ›´å¥½çš„æµç•…æ€§ï¼Œä½†å®ƒä»¬éš¾ä»¥åšæŒè¦æ±‚çš„äº‹å®ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè®¡åˆ’å’Œå®Œå½¢å¡«ç©ºæ¨¡å‹ï¼ˆä½¿ç”¨å¾®è°ƒçš„ XLNetï¼‰ï¼Œè¯¥æ¨¡å‹åœ¨åšæŒè¦æ±‚çš„å†…å®¹çš„åŒæ—¶äº§ç”Ÿæœ‰ç«äº‰åŠ›çš„æµç•…åº¦ã€‚</td><td>Eyal Orbach   Yoav Goldberg</td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00592&#39;]">Vec2Sent: Probing Sentence Embeddings with Natural Language Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00592">https://arxiv.org/pdf/2011.00592</a></td><td>We introspect black-box sentence embeddings by conditionally generating from them with the objective to retrieve the underlying discrete sentence. We perceive of this as a new unsupervised probing task and show that it correlates well with downstream task performance. We also illustrate how the language generated from different encoders differs. We apply our approach to generate sentence analogies from sentence embeddings.</td><td>æˆ‘ä»¬é€šè¿‡æœ‰æ¡ä»¶åœ°ç”Ÿæˆé»‘ç›’å¥å­åµŒå…¥æ¥å†…çœé»‘ç›’å¥å­åµŒå…¥ï¼Œç›®çš„æ˜¯æ£€ç´¢æ½œåœ¨çš„ç¦»æ•£å¥å­ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯ä¸€é¡¹æ–°çš„æ— ç›‘ç£æ¢æµ‹ä»»åŠ¡ï¼Œå¹¶è¡¨æ˜å®ƒä¸ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ç›¸å…³æ€§å¾ˆå¥½ã€‚æˆ‘ä»¬è¿˜è¯´æ˜äº†ä»ä¸åŒç¼–ç å™¨ç”Ÿæˆçš„è¯­è¨€æœ‰ä½•ä¸åŒã€‚æˆ‘ä»¬åº”ç”¨æˆ‘ä»¬çš„æ–¹æ³•ä»å¥å­åµŒå…¥ç”Ÿæˆå¥å­ç±»æ¯”ã€‚</td><td>Martin Kerscher   Steffen Eger</td></tr></tbody></table></div><h2 id="æ‘˜è¦"><a href="#æ‘˜è¦" class="headerlink" title="æ‘˜è¦"></a>æ‘˜è¦</h2><h3 id="ACL-3"><a href="#ACL-3" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.13648&#39;]">Cross-Lingual Abstractive Summarization with Limited Parallel Resources</a></td><td></td><td><a href="https://github.com/WoodenWhite/MCLAS">https://github.com/WoodenWhite/MCLAS</a></td><td><a href="https://arxiv.org/pdf/2105.13648">https://arxiv.org/pdf/2105.13648</a></td><td>Parallel cross-lingual summarization data is scarce, requiring models to better use the limited available cross-lingual resources. Existing methods to do so often adopt sequence-to-sequence networks with multi-task frameworks. Such approaches apply multiple decoders, each of which is utilized for a specific task. However, these independent decoders share no parameters, hence fail to capture the relationships between the discrete phrases of summaries in different languages, breaking the connections in order to transfer the knowledge of the high-resource languages to low-resource languages. To bridge these connections, we propose a novel Multi-Task framework for Cross-Lingual Abstractive Summarization (MCLAS) in a low-resource setting. Employing one unified decoder to generate the sequential concatenation of monolingual and cross-lingual summaries, MCLAS makes the monolingual summarization task a prerequisite of the cross-lingual summarization (CLS) task. In this way, the shared decoder learns interactions involving alignments and summary patterns across languages, which encourages attaining knowledge transfer. Experiments on two CLS datasets demonstrate that our model significantly outperforms three baseline models in both low-resource and full-dataset scenarios. Moreover, in-depth analysis on the generated summaries and attention heads verifies that interactions are learned well using MCLAS, which benefits the CLS task under limited parallel resources.</td><td>å¹¶è¡Œçš„è·¨è¯­è¨€æ‘˜è¦æ•°æ®ç¨€ç¼ºï¼Œéœ€è¦æ¨¡å‹æ›´å¥½åœ°åˆ©ç”¨æœ‰é™çš„å¯ç”¨è·¨è¯­è¨€èµ„æºã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸é‡‡ç”¨å…·æœ‰å¤šä»»åŠ¡æ¡†æ¶çš„åºåˆ—åˆ°åºåˆ—ç½‘ç»œã€‚æ­¤ç±»æ–¹æ³•åº”ç”¨å¤šä¸ªè§£ç å™¨ï¼Œæ¯ä¸ªè§£ç å™¨ç”¨äºç‰¹å®šä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™äº›ç‹¬ç«‹çš„è§£ç å™¨æ²¡æœ‰å…±äº«å‚æ•°ï¼Œå› æ­¤æ— æ³•æ•æ‰ä¸åŒè¯­è¨€æ‘˜è¦çš„ç¦»æ•£çŸ­è¯­ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œæ‰“ç ´äº†è”ç³»ï¼Œä»¥å°†é«˜èµ„æºè¯­è¨€çš„çŸ¥è¯†è½¬ç§»åˆ°ä½èµ„æºè¯­è¨€ã€‚ä¸ºäº†å¼¥åˆè¿™äº›è”ç³»ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¤šä»»åŠ¡æ¡†æ¶ï¼Œç”¨äºåœ¨ä½èµ„æºç¯å¢ƒä¸­è¿›è¡Œè·¨è¯­è¨€æŠ½è±¡æ‘˜è¦ï¼ˆMCLASï¼‰ã€‚ MCLAS é‡‡ç”¨ä¸€ä¸ªç»Ÿä¸€çš„è§£ç å™¨æ¥ç”Ÿæˆå•è¯­å’Œè·¨è¯­è¨€æ‘˜è¦çš„é¡ºåºè¿æ¥ï¼Œä½¿å•è¯­æ‘˜è¦ä»»åŠ¡æˆä¸ºè·¨è¯­è¨€æ‘˜è¦ (CLS) ä»»åŠ¡çš„å…ˆå†³æ¡ä»¶ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå…±äº«è§£ç å™¨å­¦ä¹ æ¶‰åŠè·¨è¯­è¨€å¯¹é½å’Œæ‘˜è¦æ¨¡å¼çš„äº¤äº’ï¼Œä»è€Œé¼“åŠ±å®ç°çŸ¥è¯†è½¬ç§»ã€‚åœ¨ä¸¤ä¸ª CLS æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ä½èµ„æºå’Œå…¨æ•°æ®é›†åœºæ™¯ä¸­éƒ½æ˜æ˜¾ä¼˜äºä¸‰ä¸ªåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œå¯¹ç”Ÿæˆçš„æ‘˜è¦å’Œæ³¨æ„åŠ›å¤´çš„æ·±å…¥åˆ†æéªŒè¯äº†ä½¿ç”¨ MCLAS å¯ä»¥å¾ˆå¥½åœ°å­¦ä¹ äº¤äº’ï¼Œè¿™æœ‰åˆ©äºæœ‰é™å¹¶è¡Œèµ„æºä¸‹çš„ CLS ä»»åŠ¡ã€‚</td><td>Yu Bai   Yang Gao   Heyan Huang</td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.04623&#39;]">Improving Factual Consistency of Abstractive Summarization via Question Answering</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.04623">https://arxiv.org/pdf/2105.04623</a></td><td>A commonly observed problem with the state-of-the art abstractive summarization models is that the generated summaries can be factually inconsistent with the input documents. The fact that automatic summarization may produce plausible-sounding yet inaccurate summaries is a major concern that limits its wide application. In this paper we present an approach to address factual consistency in summarization. We first propose an efficient automatic evaluation metric to measure factual consistency; next, we propose a novel learning algorithm that maximizes the proposed metric during model training. Through extensive experiments, we confirm that our method is effective in improving factual consistency and even overall quality of the summaries, as judged by both automatic metrics and human evaluation.</td><td>æœ€å…ˆè¿›çš„æŠ½è±¡æ‘˜è¦æ¨¡å‹çš„ä¸€ä¸ªå¸¸è§é—®é¢˜æ˜¯ç”Ÿæˆçš„æ‘˜è¦å¯èƒ½ä¸è¾“å…¥æ–‡æ¡£å®é™…ä¸Šä¸ä¸€è‡´ã€‚è‡ªåŠ¨æ‘˜è¦å¯èƒ½ä¼šäº§ç”Ÿçœ‹ä¼¼åˆç†ä½†ä¸å‡†ç¡®çš„æ‘˜è¦ï¼Œè¿™ä¸€äº‹å®æ˜¯é™åˆ¶å…¶å¹¿æ³›åº”ç”¨çš„ä¸»è¦é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è§£å†³æ‘˜è¦ä¸­äº‹å®ä¸€è‡´æ€§çš„æ–¹æ³•ã€‚æˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡äº‹å®ä¸€è‡´æ€§ï¼›æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å­¦ä¹ ç®—æ³•ï¼Œå¯ä»¥åœ¨æ¨¡å‹è®­ç»ƒæœŸé—´æœ€å¤§åŒ–æå‡ºçš„åº¦é‡ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬ç¡®è®¤æˆ‘ä»¬çš„æ–¹æ³•åœ¨æé«˜äº‹å®ä¸€è‡´æ€§ç”šè‡³æ‘˜è¦çš„æ•´ä½“è´¨é‡æ–¹é¢æ˜¯æœ‰æ•ˆçš„ï¼Œè¿™é€šè¿‡è‡ªåŠ¨æŒ‡æ ‡å’Œäººå·¥è¯„ä¼°æ¥åˆ¤æ–­ã€‚</td><td>Feng Nan   Cicero Nogueira dos Santos   Henghui Zhu   Patrick Ng   Kathleen McKeown   Ramesh Nallapati   Dejiao Zhang   Zhiguo Wang   Andrew O. Arnold   Bing Xiang</td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.03801&#39;]">Long-Span Summarization via Local Attention and Content Selection</a></td><td></td><td><a href="https://github.com/potsawee/longsum0">https://github.com/potsawee/longsum0</a></td><td><a href="https://arxiv.org/pdf/2105.03801">https://arxiv.org/pdf/2105.03801</a></td><td>Transformer-based models have achieved state-of-the-art results in a wide range of natural language processing (NLP) tasks including document summarization. Typically these systems are trained by fine-tuning a large pre-trained model to the target task. One issue with these transformer-based models is that they do not scale well in terms of memory and compute requirements as the input length grows. Thus, for long document summarization, it can be challenging to train or fine-tune these models. In this work, we exploit large pre-trained transformer-based models and address long-span dependencies in abstractive summarization using two methods: local self-attention; and explicit content selection. These approaches are compared on a range of network configurations. Experiments are carried out on standard long-span summarization tasks, including Spotify Podcast, arXiv, and PubMed datasets. We demonstrate that by combining these methods, we can achieve state-of-the-art results on all three tasks in the ROUGE scores. Moreover, without a large-scale GPU card, our approach can achieve comparable or better results than existing approaches.</td><td>åŸºäº Transformer çš„æ¨¡å‹åœ¨åŒ…æ‹¬æ–‡æ¡£æ‘˜è¦åœ¨å†…çš„å„ç§è‡ªç„¶è¯­è¨€å¤„ç† (NLP) ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚é€šå¸¸ï¼Œè¿™äº›ç³»ç»Ÿæ˜¯é€šè¿‡é’ˆå¯¹ç›®æ ‡ä»»åŠ¡å¯¹å¤§å‹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒæ¥è®­ç»ƒçš„ã€‚è¿™äº›åŸºäºè½¬æ¢å™¨çš„æ¨¡å‹çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œéšç€è¾“å…¥é•¿åº¦çš„å¢åŠ ï¼Œå®ƒä»¬åœ¨å†…å­˜å’Œè®¡ç®—è¦æ±‚æ–¹é¢ä¸èƒ½å¾ˆå¥½åœ°æ‰©å±•ã€‚å› æ­¤ï¼Œå¯¹äºé•¿æ–‡æ¡£æ‘˜è¦ï¼Œè®­ç»ƒæˆ–å¾®è°ƒè¿™äº›æ¨¡å‹å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨å¤§å‹é¢„è®­ç»ƒçš„åŸºäº Transformer çš„æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ä¸¤ç§æ–¹æ³•è§£å†³æŠ½è±¡æ‘˜è¦ä¸­çš„é•¿è·¨åº¦ä¾èµ–æ€§ï¼šå±€éƒ¨è‡ªæ³¨æ„åŠ›ï¼›å’Œæ˜ç¡®çš„å†…å®¹é€‰æ‹©ã€‚è¿™äº›æ–¹æ³•åœ¨ä¸€ç³»åˆ—ç½‘ç»œé…ç½®ä¸Šè¿›è¡Œäº†æ¯”è¾ƒã€‚å®éªŒæ˜¯åœ¨æ ‡å‡†çš„å¤§è·¨åº¦æ‘˜è¦ä»»åŠ¡ä¸Šè¿›è¡Œçš„ï¼ŒåŒ…æ‹¬ Spotify Podcastã€arXiv å’Œ PubMed æ•°æ®é›†ã€‚æˆ‘ä»¬è¯æ˜ï¼Œé€šè¿‡ç»“åˆè¿™äº›æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ ROUGE åˆ†æ•°ä¸­çš„æ‰€æœ‰ä¸‰ä¸ªä»»åŠ¡ä¸Šè·å¾—æœ€å…ˆè¿›çš„ç»“æœã€‚æ­¤å¤–ï¼Œåœ¨æ²¡æœ‰å¤§è§„æ¨¡ GPU å¡çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥è·å¾—ä¸ç°æœ‰æ–¹æ³•ç›¸å½“æˆ–æ›´å¥½çš„ç»“æœã€‚</td><td>Potsawee Manakul   Mark J. F. Gales</td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.15135&#39;]">TWAG: A Topic-Guided Wikipedia Abstract Generator</a></td><td></td><td><a href="https://github.com/THU-KEG/TWAG">https://github.com/THU-KEG/TWAG</a></td><td><a href="https://arxiv.org/pdf/2106.15135">https://arxiv.org/pdf/2106.15135</a></td><td>Wikipedia abstract generation aims to distill a Wikipedia abstract from web sources and has met significant success by adopting multi-document summarization techniques. However, previous works generally view the abstract as plain text, ignoring the fact that it is a description of a certain entity and can be decomposed into different topics. In this paper, we propose a two-stage model TWAG that guides the abstract generation with topical information. First, we detect the topic of each input paragraph with a classifier trained on existing Wikipedia articles to divide input documents into different topics. Then, we predict the topic distribution of each abstract sentence, and decode the sentence from topic-aware representations with a Pointer-Generator network. We evaluate our model on the WikiCatSum dataset, and the results show that \modelnames outperforms various existing baselines and is capable of generating comprehensive abstracts. Our code and dataset can be accessed at \url{<a href="https://github.com/THU-KEG/TWAG}">https://github.com/THU-KEG/TWAG}</a></td><td>ç»´åŸºç™¾ç§‘æ‘˜è¦ç”Ÿæˆæ—¨åœ¨ä»ç½‘ç»œèµ„æºä¸­æå–ç»´åŸºç™¾ç§‘æ‘˜è¦ï¼Œå¹¶é€šè¿‡é‡‡ç”¨å¤šæ–‡æ¡£æ‘˜è¦æŠ€æœ¯å–å¾—äº†é‡å¤§æˆåŠŸã€‚ç„¶è€Œï¼Œä»¥å‰çš„å·¥ä½œä¸€èˆ¬å°†æ‘˜è¦è§†ä¸ºçº¯æ–‡æœ¬ï¼Œå¿½ç•¥äº†å®ƒæ˜¯å¯¹æŸä¸ªå®ä½“çš„æè¿°ï¼Œå¯ä»¥åˆ†è§£ä¸ºä¸åŒä¸»é¢˜çš„äº‹å®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µæ¨¡å‹ TWAGï¼Œå®ƒç”¨ä¸»é¢˜ä¿¡æ¯æŒ‡å¯¼æŠ½è±¡ç”Ÿæˆã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨åœ¨ç°æœ‰ç»´åŸºç™¾ç§‘æ–‡ç« ä¸Šè®­ç»ƒçš„åˆ†ç±»å™¨æ£€æµ‹æ¯ä¸ªè¾“å…¥æ®µè½çš„ä¸»é¢˜ï¼Œä»¥å°†è¾“å…¥æ–‡æ¡£åˆ’åˆ†ä¸ºä¸åŒçš„ä¸»é¢˜ã€‚ç„¶åï¼Œæˆ‘ä»¬é¢„æµ‹æ¯ä¸ªæŠ½è±¡å¥å­çš„ä¸»é¢˜åˆ†å¸ƒï¼Œå¹¶ä½¿ç”¨æŒ‡é’ˆç”Ÿæˆå™¨ç½‘ç»œä»ä¸»é¢˜æ„ŸçŸ¥è¡¨ç¤ºä¸­è§£ç å¥å­ã€‚æˆ‘ä»¬åœ¨ WikiCatSum æ•°æ®é›†ä¸Šè¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ï¼Œç»“æœè¡¨æ˜ \modelnames ä¼˜äºå„ç§ç°æœ‰çš„åŸºçº¿ï¼Œå¹¶ä¸”èƒ½å¤Ÿç”Ÿæˆå…¨é¢çš„æ‘˜è¦ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯ä»¥åœ¨ \url{<a href="https://github.com/THU-KEG/TWAG}">https://github.com/THU-KEG/TWAG}</a> è®¿é—®</td><td>Fangwei Zhu   Shangqing Tu   Jiaxin Shi   Juanzi Li   Lei Hou   Tong Cui</td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.12544&#39;]">Language Model as an Annotator: Exploring DialoGPT for Dialogue Summarization</a></td><td></td><td><a href="https://github.com/xcfcode/PLM_annotator">https://github.com/xcfcode/PLM_annotator</a></td><td><a href="https://arxiv.org/pdf/2105.12544">https://arxiv.org/pdf/2105.12544</a></td><td>Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities. However, these features are obtained via open-domain toolkits that are dialog-agnostic or heavily relied on human annotations. In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT. We apply DialoGPT to label three types of features on two dialogue summarization datasets, SAMSum and AMI, and employ pre-trained and non pre-trained models as our summarizes. Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset.</td><td></td><td>Xiachong Feng   Xiaocheng Feng   Libo Qin   Bing Qin   Ting Liu</td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.12041&#39;]">BASS: Boosting Abstractive Summarization with Unified Semantic Graph</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.12041">https://arxiv.org/pdf/2105.12041</a></td><td>Abstractive summarization for long-document or multi-document remains challenging for the Seq2Seq architecture, as Seq2Seq is not good at analyzing long-distance relations in text. In this paper, we present BASS, a novel framework for Boosting Abstractive Summarization based on a unified Semantic graph, which aggregates co-referent phrases distributing across a long range of context and conveys rich relations between phrases. Further, a graph-based encoder-decoder model is proposed to improve both the document representation and summary generation process by leveraging the graph structure. Specifically, several graph augmentation methods are designed to encode both the explicit and implicit relations in the text while the graph-propagation attention mechanism is developed in the decoder to select salient content into the summary. Empirical results show that the proposed architecture brings substantial improvements for both long-document and multi-document summarization tasks.</td><td>é•¿æ–‡æ¡£æˆ–å¤šæ–‡æ¡£çš„æŠ½è±¡æ‘˜è¦å¯¹äº Seq2Seq æ¶æ„ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸º Seq2Seq ä¸æ“…é•¿åˆ†ææ–‡æœ¬ä¸­çš„é•¿è·ç¦»å…³ç³»ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† BASSï¼Œè¿™æ˜¯ä¸€ç§åŸºäºç»Ÿä¸€è¯­ä¹‰å›¾çš„å¢å¼ºæŠ½è±¡æ‘˜è¦çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èšåˆäº†åˆ†å¸ƒåœ¨å¹¿æ³›ä¸Šä¸‹æ–‡ä¸­çš„å…±åŒæŒ‡æ¶‰çŸ­è¯­ï¼Œå¹¶ä¼ è¾¾äº†çŸ­è¯­ä¹‹é—´çš„ä¸°å¯Œå…³ç³»ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå›¾çš„ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ï¼Œä»¥é€šè¿‡åˆ©ç”¨å›¾ç»“æ„æ¥æ”¹è¿›æ–‡æ¡£è¡¨ç¤ºå’Œæ‘˜è¦ç”Ÿæˆè¿‡ç¨‹ã€‚å…·ä½“æ¥è¯´ï¼Œè®¾è®¡äº†å‡ ç§å›¾å¢å¼ºæ–¹æ³•æ¥å¯¹æ–‡æœ¬ä¸­çš„æ˜¾å¼å’Œéšå¼å…³ç³»è¿›è¡Œç¼–ç ï¼ŒåŒæ—¶åœ¨è§£ç å™¨ä¸­å¼€å‘å›¾ä¼ æ’­æ³¨æ„æœºåˆ¶ä»¥å°†æ˜¾ç€å†…å®¹é€‰æ‹©åˆ°æ‘˜è¦ä¸­ã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¶æ„ä¸ºé•¿æ–‡æ¡£å’Œå¤šæ–‡æ¡£æ‘˜è¦ä»»åŠ¡å¸¦æ¥äº†å®è´¨æ€§çš„æ”¹è¿›ã€‚</td><td>Wenhao Wu   Wei Li   Xinyan Xiao   Jiachen Liu   Ziqiang Cao   Sujian Li   Hua Wu   Haifeng Wang</td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.11921&#39;]">Focus Attention: Promoting Faithfulness and Diversity in Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.11921">https://arxiv.org/pdf/2105.11921</a></td><td>Professional summaries are written with document-level information, such as the theme of the document, in mind. This is in contrast with most seq2seq decoders which simultaneously learn to focus on salient content, while deciding what to generate, at each decoding step. With the motivation to narrow this gap, we introduce Focus Attention Mechanism, a simple yet effective method to encourage decoders to proactively generate tokens that are similar or topical to the input document. Further, we propose a Focus Sampling method to enable generation of diverse summaries, an area currently understudied in summarization. When evaluated on the BBC extreme summarization task, two state-of-the-art models augmented with Focus Attention generate summaries that are closer to the target and more faithful to their input documents, outperforming their vanilla counterparts on \rouge and multiple faithfulness measures. We also empirically demonstrate that Focus Sampling is more effective in generating diverse and faithful summaries than top-$k$ or nucleus sampling-based decoding methods.</td><td>ä¸“ä¸šæ‘˜è¦æ˜¯ç”¨æ–‡æ¡£çº§åˆ«çš„ä¿¡æ¯ç¼–å†™çš„ï¼Œä¾‹å¦‚æ–‡æ¡£çš„ä¸»é¢˜ã€‚è¿™ä¸å¤§å¤šæ•° seq2seq è§£ç å™¨å½¢æˆå¯¹æ¯”ï¼Œåè€…åœ¨æ¯ä¸ªè§£ç æ­¥éª¤ä¸­åŒæ—¶å­¦ä¹ å…³æ³¨æ˜¾ç€å†…å®¹ï¼ŒåŒæ—¶å†³å®šç”Ÿæˆä»€ä¹ˆã€‚ä¸ºäº†ç¼©å°è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç„¦ç‚¹æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥é¼“åŠ±è§£ç å™¨ä¸»åŠ¨ç”Ÿæˆä¸è¾“å…¥æ–‡æ¡£ç›¸ä¼¼æˆ–ä¸»é¢˜çš„æ ‡è®°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç„¦ç‚¹æŠ½æ ·æ–¹æ³•ï¼Œä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„æ‘˜è¦ï¼Œè¿™æ˜¯ç›®å‰åœ¨æ‘˜è¦ä¸­ç ”ç©¶ä¸è¶³çš„é¢†åŸŸã€‚å½“åœ¨ BBC æç«¯æ‘˜è¦ä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°æ—¶ï¼Œä¸¤ä¸ªæœ€å…ˆè¿›çš„æ¨¡å‹å¢å¼ºäº† Focus Attention ç”Ÿæˆçš„æ‘˜è¦æ›´æ¥è¿‘ç›®æ ‡ï¼Œæ›´å¿ å®äºä»–ä»¬çš„è¾“å…¥æ–‡æ¡£ï¼Œåœ¨ \rouge å’Œå¤šé‡å¿ å®åº¦åº¦é‡ä¸Šä¼˜äºæ™®é€šæ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å‡­ç»éªŒè¯æ˜ï¼Œç„¦ç‚¹é‡‡æ ·åœ¨ç”Ÿæˆå¤šæ ·åŒ–å’Œå¿ å®çš„æ‘˜è¦æ–¹é¢æ¯”åŸºäº top-$k$ æˆ–æ ¸é‡‡æ ·çš„è§£ç æ–¹æ³•æ›´æœ‰æ•ˆã€‚</td><td>Rahul Aralikatte   Shashi Narayan   Joshua Maynez   Sascha Rothe   Ryan McDonald</td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.14774&#39;]">Generating Query Focused Summaries from Query-Free Resources</a></td><td></td><td><a href="https://github.com/yumoxu/marge">https://github.com/yumoxu/marge</a></td><td><a href="https://arxiv.org/pdf/2012.14774">https://arxiv.org/pdf/2012.14774</a></td><td>The availability of large-scale datasets has driven the development of neural models that create generic summaries from single or multiple documents. In this work we consider query focused summarization (QFS), a task for which training data in the form of queries, documents, and summaries is not readily available. We propose to decompose QFS into (1) query modeling (i.e., finding supportive evidence within a set of documents for a query) and (2) conditional language modeling (i.e., summary generation). We introduce MaRGE, a Masked ROUGE Regression framework for evidence estimation and ranking which relies on a unified representation for summaries and queries, so that summaries in generic data can be converted into proxy queries for learning a query model. Experiments across QFS benchmarks and query types show that our model achieves state-of-the-art performance despite learning from weak supervision.</td><td>å¤§è§„æ¨¡æ•°æ®é›†çš„å¯ç”¨æ€§æ¨åŠ¨äº†ç¥ç»æ¨¡å‹çš„å‘å±•ï¼Œè¯¥æ¨¡å‹ä»å•ä¸ªæˆ–å¤šä¸ªæ–‡æ¡£åˆ›å»ºé€šç”¨æ‘˜è¦ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘ä»¥æŸ¥è¯¢ä¸ºä¸­å¿ƒçš„æ‘˜è¦ (QFS)ï¼Œè¿™æ˜¯ä¸€é¡¹ä¸å®¹æ˜“è·å¾—æŸ¥è¯¢ã€æ–‡æ¡£å’Œæ‘˜è¦å½¢å¼çš„è®­ç»ƒæ•°æ®çš„ä»»åŠ¡ã€‚æˆ‘ä»¬å»ºè®®å°† QFS åˆ†è§£ä¸º (1) æŸ¥è¯¢å»ºæ¨¡ï¼ˆå³åœ¨ä¸€ç»„æ–‡æ¡£ä¸­ä¸ºæŸ¥è¯¢æ‰¾åˆ°æ”¯æŒè¯æ®ï¼‰å’Œï¼ˆ2ï¼‰æ¡ä»¶è¯­è¨€å»ºæ¨¡ï¼ˆå³æ‘˜è¦ç”Ÿæˆï¼‰ã€‚æˆ‘ä»¬å¼•å…¥äº† MaRGEï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè¯æ®ä¼°è®¡å’Œæ’åºçš„ Masked ROUGE å›å½’æ¡†æ¶ï¼Œå®ƒä¾èµ–äºæ‘˜è¦å’ŒæŸ¥è¯¢çš„ç»Ÿä¸€è¡¨ç¤ºï¼Œå› æ­¤å¯ä»¥å°†é€šç”¨æ•°æ®ä¸­çš„æ‘˜è¦è½¬æ¢ä¸ºä»£ç†æŸ¥è¯¢ä»¥å­¦ä¹ æŸ¥è¯¢æ¨¡å‹ã€‚è·¨ QFS åŸºå‡†æµ‹è¯•å’ŒæŸ¥è¯¢ç±»å‹çš„å®éªŒè¡¨æ˜ï¼Œå°½ç®¡ä»å¼±ç›‘ç£ä¸­å­¦ä¹ ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä»å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</td><td>Yumo Xu   Mirella Lapata</td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00829&#39;]">ConvoSumm: Conversation Summarization Benchmark and Improved Abstractive Summarization with Argument Mining</a></td><td></td><td><a href="https://github.com/Yale-LILY/ConvoSumm">https://github.com/Yale-LILY/ConvoSumm</a></td><td><a href="https://arxiv.org/pdf/2106.00829">https://arxiv.org/pdf/2106.00829</a></td><td>While online conversations can cover a vast amount of information in many different formats, abstractive text summarization has primarily focused on modeling solely news articles. This research gap is due, in part, to the lack of standardized datasets for summarizing online discussions. To address this gap, we design annotation protocols motivated by an issuesâ€”viewpointsâ€”assertions framework to crowdsource four new datasets on diverse online conversation forms of news comments, discussion forums, community question answering forums, and email threads. We benchmark state-of-the-art models on our datasets and analyze characteristics associated with the data. To create a comprehensive benchmark, we also evaluate these models on widely-used conversation summarization datasets to establish strong baselines in this domain. Furthermore, we incorporate argument mining through graph construction to directly model the issues, viewpoints, and assertions present in a conversation and filter noisy input, showing comparable or improved results according to automatic and human evaluations.</td><td>è™½ç„¶åœ¨çº¿å¯¹è¯å¯ä»¥æ¶µç›–å¤šç§ä¸åŒæ ¼å¼çš„å¤§é‡ä¿¡æ¯ï¼Œä½†æŠ½è±¡æ–‡æœ¬æ‘˜è¦ä¸»è¦ä¾§é‡äºå¯¹æ–°é—»æ–‡ç« è¿›è¡Œå»ºæ¨¡ã€‚è¿™ç§ç ”ç©¶å·®è·éƒ¨åˆ†æ˜¯ç”±äºç¼ºä¹ç”¨äºæ€»ç»“åœ¨çº¿è®¨è®ºçš„æ ‡å‡†åŒ–æ•°æ®é›†ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬è®¾è®¡äº†ç”±é—®é¢˜-è§‚ç‚¹-æ–­è¨€æ¡†æ¶é©±åŠ¨çš„æ³¨é‡Šåè®®ï¼Œä»¥ä¼—åŒ…æ–°é—»è¯„è®ºã€è®¨è®ºè®ºå›ã€ç¤¾åŒºé—®ç­”è®ºå›å’Œç”µå­é‚®ä»¶çº¿ç¨‹ç­‰å„ç§åœ¨çº¿å¯¹è¯å½¢å¼çš„å››ä¸ªæ–°æ•°æ®é›†ã€‚æˆ‘ä»¬åœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸Šå¯¹æœ€å…ˆè¿›çš„æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•å¹¶åˆ†æä¸æ•°æ®ç›¸å…³çš„ç‰¹å¾ã€‚ä¸ºäº†åˆ›å»ºä¸€ä¸ªå…¨é¢çš„åŸºå‡†ï¼Œæˆ‘ä»¬è¿˜åœ¨å¹¿æ³›ä½¿ç”¨çš„å¯¹è¯æ‘˜è¦æ•°æ®é›†ä¸Šè¯„ä¼°è¿™äº›æ¨¡å‹ï¼Œä»¥åœ¨è¯¥é¢†åŸŸå»ºç«‹å¼ºå¤§çš„åŸºçº¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å›¾æ„å»ºç»“åˆå‚æ•°æŒ–æ˜ï¼Œç›´æ¥å¯¹å¯¹è¯ä¸­å­˜åœ¨çš„é—®é¢˜ã€è§‚ç‚¹å’Œæ–­è¨€è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶è¿‡æ»¤å˜ˆæ‚çš„è¾“å…¥ï¼Œæ ¹æ®è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°æ˜¾ç¤ºå¯æ¯”è¾ƒæˆ–æ”¹è¿›çš„ç»“æœã€‚</td><td>Alexander R. Fabbri   Faiaz Rahman   Imad Rizvi   Borui Wang   Haoran Li   Yashar Mehdad   Dragomir Radev</td></tr><tr><td>10</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00661&#39;]">On Faithfulness and Factuality in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/google-research-datasets/xsum_hallucination_annotations">https://github.com/google-research-datasets/xsum_hallucination_annotations</a></td><td><a href="https://arxiv.org/pdf/2005.00661">https://arxiv.org/pdf/2005.00661</a></td><td>It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as language modeling and story generation. In this paper we have analyzed limitations of these models for abstractive document summarization and found that these models are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with faithfulness than standard metrics, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria.</td><td>ä¼—æ‰€å‘¨çŸ¥ï¼Œç¥ç»æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ä¸­çš„æ ‡å‡†ä¼¼ç„¶è®­ç»ƒå’Œè¿‘ä¼¼è§£ç ç›®æ ‡ä¼šå¯¼è‡´å¯¹è¯­è¨€å»ºæ¨¡å’Œæ•…äº‹ç”Ÿæˆç­‰å¼€æ”¾å¼ä»»åŠ¡çš„å“åº”è¾ƒå°‘ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åˆ†æäº†è¿™äº›æ¨¡å‹åœ¨æŠ½è±¡æ–‡æ¡£æ‘˜è¦æ–¹é¢çš„å±€é™æ€§ï¼Œå‘ç°è¿™äº›æ¨¡å‹å¾ˆå®¹æ˜“å‡ºç°å¯¹è¾“å…¥æ–‡æ¡£ä¸å¿ å®çš„å¹»è§‰å†…å®¹ã€‚æˆ‘ä»¬å¯¹å‡ ä¸ªç¥ç»æŠ½è±¡æ‘˜è¦ç³»ç»Ÿè¿›è¡Œäº†å¤§è§„æ¨¡çš„äººå·¥è¯„ä¼°ï¼Œä»¥æ›´å¥½åœ°äº†è§£å®ƒä»¬äº§ç”Ÿçš„å¹»è§‰ç±»å‹ã€‚æˆ‘ä»¬çš„äººå·¥æ³¨é‡Šè€…åœ¨æ‰€æœ‰æ¨¡å‹ç”Ÿæˆçš„æ‘˜è¦ä¸­å‘ç°äº†å¤§é‡å¹»è§‰å†…å®¹ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„åˆ†æç¡®å®è¡¨æ˜ï¼Œé¢„è®­ç»ƒæ¨¡å‹ä¸ä»…åœ¨åŸå§‹æŒ‡æ ‡ï¼ˆå³ ROUGEï¼‰æ–¹é¢æ˜¯æ›´å¥½çš„æ€»ç»“å™¨ï¼Œè€Œä¸”åœ¨ç”Ÿæˆäººç±»è¯„ä¼°çš„å¿ å®å’Œäº‹å®æ‘˜è¦æ–¹é¢ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¡¨æ˜ï¼Œä¸æ ‡å‡†åº¦é‡ç›¸æ¯”ï¼Œæ–‡æœ¬è•´æ¶µåº¦é‡ä¸å¿ è¯šåº¦çš„ç›¸å…³æ€§æ›´å¥½ï¼Œè¿™å¯èƒ½ä¼šå¼•é¢†è‡ªåŠ¨è¯„ä¼°åº¦é‡ä»¥åŠè®­ç»ƒå’Œè§£ç æ ‡å‡†çš„å‘å±•ã€‚</td><td>Joshua Maynez   Shashi Narayan   Bernd Bohnet   Ryan McDonald</td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.03754&#39;]">FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/esdurmus/summary-faithfulness">https://github.com/esdurmus/summary-faithfulness</a></td><td><a href="https://arxiv.org/pdf/2005.03754">https://arxiv.org/pdf/2005.03754</a></td><td>Neural abstractive summarization models are prone to generate content inconsistent with the source document, i.e. unfaithful. Existing automatic metrics do not capture such mistakes effectively. We tackle the problem of evaluating faithfulness of a generated summary given its source document. We first collected human annotations of faithfulness for outputs from numerous models on two datasets. We find that current models exhibit a trade-off between abstractiveness and faithfulness: outputs with less word overlap with the source document are more likely to be unfaithful. Next, we propose an automatic question answering (QA) based metric for faithfulness, FEQA, which leverages recent advances in reading comprehension. Given question-answer pairs generated from the summary, a QA model extracts answers from the document; non-matched answers indicate unfaithful information in the summary. Among metrics based on word overlap, embedding similarity, and learned language understanding models, our QA-based metric has significantly higher correlation with human faithfulness scores, especially on highly abstractive summaries.</td><td>ç¥ç»æŠ½è±¡æ‘˜è¦æ¨¡å‹å®¹æ˜“ç”Ÿæˆä¸æºæ–‡æ¡£ä¸ä¸€è‡´çš„å†…å®¹ï¼Œå³ä¸å¿ å®çš„ã€‚ç°æœ‰çš„è‡ªåŠ¨æŒ‡æ ‡ä¸èƒ½æœ‰æ•ˆåœ°æ•æ‰æ­¤ç±»é”™è¯¯ã€‚æˆ‘ä»¬è§£å†³äº†åœ¨ç»™å®šæºæ–‡ä»¶çš„æƒ…å†µä¸‹è¯„ä¼°ç”Ÿæˆæ‘˜è¦çš„å¿ å®åº¦çš„é—®é¢˜ã€‚æˆ‘ä»¬é¦–å…ˆä»ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„ä¼—å¤šæ¨¡å‹ä¸­æ”¶é›†äº†äººç±»å¿ å®åº¦çš„äººå·¥æ³¨é‡Šã€‚æˆ‘ä»¬å‘ç°å½“å‰çš„æ¨¡å‹è¡¨ç°å‡ºæŠ½è±¡æ€§å’Œå¿ å®æ€§ä¹‹é—´çš„æƒè¡¡ï¼šä¸æºæ–‡æ¡£çš„å•è¯é‡å è¾ƒå°‘çš„è¾“å‡ºæ›´æœ‰å¯èƒ½æ˜¯ä¸å¿ å®çš„ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè‡ªåŠ¨é—®ç­” (QA) çš„å¿ è¯šåº¦æŒ‡æ ‡ï¼ŒFEQAï¼Œå®ƒåˆ©ç”¨äº†é˜…è¯»ç†è§£æ–¹é¢çš„æœ€æ–°è¿›å±•ã€‚ç»™å®šä»æ‘˜è¦ç”Ÿæˆçš„é—®ç­”å¯¹ï¼ŒQA æ¨¡å‹ä»æ–‡æ¡£ä¸­æå–ç­”æ¡ˆï¼›ä¸åŒ¹é…çš„ç­”æ¡ˆè¡¨ç¤ºæ‘˜è¦ä¸­çš„ä¿¡æ¯ä¸çœŸå®ã€‚åœ¨åŸºäºå•è¯é‡å ã€åµŒå…¥ç›¸ä¼¼æ€§å’Œå­¦ä¹ è¯­è¨€ç†è§£æ¨¡å‹çš„æŒ‡æ ‡ä¸­ï¼Œæˆ‘ä»¬åŸºäº QA çš„æŒ‡æ ‡ä¸äººç±»å¿ è¯šåº¦å¾—åˆ†çš„ç›¸å…³æ€§æ˜¾ç€æ›´é«˜ï¼Œå°¤å…¶æ˜¯åœ¨é«˜åº¦æŠ½è±¡çš„æ‘˜è¦ä¸Šã€‚</td><td>Esin Durmus   He He   Mona Diab</td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00661&#39;]">On Faithfulness and Factuality in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/google-research-datasets/xsum_hallucination_annotations">https://github.com/google-research-datasets/xsum_hallucination_annotations</a></td><td><a href="https://arxiv.org/pdf/2005.00661">https://arxiv.org/pdf/2005.00661</a></td><td>It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as language modeling and story generation. In this paper we have analyzed limitations of these models for abstractive document summarization and found that these models are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with faithfulness than standard metrics, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria.</td><td>ä¼—æ‰€å‘¨çŸ¥ï¼Œç¥ç»æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ä¸­çš„æ ‡å‡†ä¼¼ç„¶è®­ç»ƒå’Œè¿‘ä¼¼è§£ç ç›®æ ‡ä¼šå¯¼è‡´å¯¹è¯­è¨€å»ºæ¨¡å’Œæ•…äº‹ç”Ÿæˆç­‰å¼€æ”¾å¼ä»»åŠ¡çš„å“åº”è¾ƒå°‘ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åˆ†æäº†è¿™äº›æ¨¡å‹åœ¨æŠ½è±¡æ–‡æ¡£æ‘˜è¦æ–¹é¢çš„å±€é™æ€§ï¼Œå‘ç°è¿™äº›æ¨¡å‹å¾ˆå®¹æ˜“å‡ºç°å¯¹è¾“å…¥æ–‡æ¡£ä¸å¿ å®çš„å¹»è§‰å†…å®¹ã€‚æˆ‘ä»¬å¯¹å‡ ä¸ªç¥ç»æŠ½è±¡æ‘˜è¦ç³»ç»Ÿè¿›è¡Œäº†å¤§è§„æ¨¡çš„äººå·¥è¯„ä¼°ï¼Œä»¥æ›´å¥½åœ°äº†è§£å®ƒä»¬äº§ç”Ÿçš„å¹»è§‰ç±»å‹ã€‚æˆ‘ä»¬çš„äººå·¥æ³¨é‡Šè€…åœ¨æ‰€æœ‰æ¨¡å‹ç”Ÿæˆçš„æ‘˜è¦ä¸­å‘ç°äº†å¤§é‡å¹»è§‰å†…å®¹ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„åˆ†æç¡®å®è¡¨æ˜ï¼Œé¢„è®­ç»ƒæ¨¡å‹ä¸ä»…åœ¨åŸå§‹æŒ‡æ ‡ï¼ˆå³ ROUGEï¼‰æ–¹é¢æ˜¯æ›´å¥½çš„æ€»ç»“å™¨ï¼Œè€Œä¸”åœ¨ç”Ÿæˆäººç±»è¯„ä¼°çš„å¿ å®å’Œäº‹å®æ‘˜è¦æ–¹é¢ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¡¨æ˜ï¼Œä¸æ ‡å‡†åº¦é‡ç›¸æ¯”ï¼Œæ–‡æœ¬è•´æ¶µåº¦é‡ä¸å¿ è¯šåº¦çš„ç›¸å…³æ€§æ›´å¥½ï¼Œè¿™å¯èƒ½ä¼šå¼•é¢†è‡ªåŠ¨è¯„ä¼°åº¦é‡ä»¥åŠè®­ç»ƒå’Œè§£ç æ ‡å‡†çš„å‘å±•ã€‚</td><td>Joshua Maynez   Shashi Narayan   Bernd Bohnet   Ryan McDonald</td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.01159&#39;]">Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward</a></td><td></td><td><a href="https://github.com/luyang-huang96/GraphAugmentedSum">https://github.com/luyang-huang96/GraphAugmentedSum</a></td><td><a href="https://arxiv.org/pdf/2005.01159">https://arxiv.org/pdf/2005.01159</a></td><td>Sequence-to-sequence models for abstractive summarization have been studied extensively, yet the generated summaries commonly suffer from fabricated content, and are often found to be near-extractive. We argue that, to address these issues, the summarizer should acquire semantic interpretation over input, e.g., via structured representation, to allow the generation of more informative summaries. In this paper, we present ASGARD, a novel framework for Abstractive Summarization with Graph-Augmentation and semantic-driven RewarD. We propose the use of dual encodersâ€”-a sequential document encoder and a graph-structured encoderâ€”-to maintain the global context and local characteristics of entities, complementing each other. We further design a reward based on a multiple choice cloze test to drive the model to better capture entity interactions. Results show that our models produce significantly higher ROUGE scores than a variant without knowledge graph as input on both New York Times and CNN/Daily Mail datasets. We also obtain better or comparable performance compared to systems that are fine-tuned from large pretrained language models. Human judges further rate our model outputs as more informative and containing fewer unfaithful errors.</td><td>ç”¨äºæŠ½è±¡æ‘˜è¦çš„åºåˆ—åˆ°åºåˆ—æ¨¡å‹å·²è¢«å¹¿æ³›ç ”ç©¶ï¼Œä½†ç”Ÿæˆçš„æ‘˜è¦é€šå¸¸å—åˆ°æé€ çš„å†…å®¹çš„å½±å“ï¼Œå¹¶ä¸”ç»å¸¸è¢«å‘ç°æ¥è¿‘äºæå–ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæ‘˜è¦å™¨åº”è¯¥è·å¾—å¯¹è¾“å…¥çš„è¯­ä¹‰è§£é‡Šï¼Œä¾‹å¦‚ï¼Œé€šè¿‡ç»“æ„åŒ–è¡¨ç¤ºï¼Œä»¥å…è®¸ç”Ÿæˆæ›´å¤šä¿¡æ¯æ‘˜è¦ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† ASGARDï¼Œè¿™æ˜¯ä¸€ç§å…·æœ‰å›¾å¢å¼ºå’Œè¯­ä¹‰é©±åŠ¨çš„ RewarD çš„æŠ½è±¡æ‘˜è¦æ¡†æ¶ã€‚æˆ‘ä»¬å»ºè®®ä½¿ç”¨åŒç¼–ç å™¨â€”â€”é¡ºåºæ–‡æ¡£ç¼–ç å™¨å’Œå›¾ç»“æ„ç¼–ç å™¨â€”â€”æ¥ç»´æŠ¤å®ä½“çš„å…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨ç‰¹å¾ï¼Œç›¸äº’è¡¥å……ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è®¾è®¡äº†åŸºäºå¤šé¡¹é€‰æ‹©å®Œå½¢å¡«ç©ºæµ‹è¯•çš„å¥–åŠ±ï¼Œä»¥é©±åŠ¨æ¨¡å‹æ›´å¥½åœ°æ•è·å®ä½“äº¤äº’ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨çº½çº¦æ—¶æŠ¥å’Œ CNN/æ¯æ—¥é‚®æŠ¥æ•°æ®é›†ä¸Šäº§ç”Ÿçš„ ROUGE åˆ†æ•°æ˜æ˜¾é«˜äºæ²¡æœ‰çŸ¥è¯†å›¾ä½œä¸ºè¾“å…¥çš„å˜ä½“ã€‚ä¸ä»å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å¾®è°ƒçš„ç³»ç»Ÿç›¸æ¯”ï¼Œæˆ‘ä»¬è¿˜è·å¾—äº†æ›´å¥½æˆ–ç›¸å½“çš„æ€§èƒ½ã€‚äººç±»æ³•å®˜è¿›ä¸€æ­¥è¯„ä»·æˆ‘ä»¬çš„æ¨¡å‹è¾“å‡ºä¿¡æ¯æ›´å¤šï¼ŒåŒ…å«æ›´å°‘çš„ä¸å¿ å®é”™è¯¯ã€‚</td><td>Luyang Huang   Lingfei Wu   Lu Wang</td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2105.05361&#39;]">The Summary Loop: Learning to Write Abstractive Summaries Without Examples</a></td><td></td><td><a href="https://github.com/cannylab/summary_loop">https://github.com/cannylab/summary_loop</a></td><td><a href="https://arxiv.org/pdf/2105.05361">https://arxiv.org/pdf/2105.05361</a></td><td>This work presents a new approach to unsupervised abstractive summarization based on maximizing a combination of coverage and fluency for a given length constraint. It introduces a novel method that encourages the inclusion of key terms from the original document into the summary: key terms are masked out of the original document and must be filled in by a coverage model using the current generated summary. A novel unsupervised training procedure leverages this coverage model along with a fluency model to generate and score summaries. When tested on popular news summarization datasets, the method outperforms previous unsupervised methods by more than 2 R-1 points, and approaches results of competitive supervised methods. Our model attains higher levels of abstraction with copied passages roughly two times shorter than prior work, and learns to compress and merge sentences without supervision.</td><td>è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„æ— ç›‘ç£æŠ½è±¡æ‘˜è¦æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŸºäºåœ¨ç»™å®šé•¿åº¦çº¦æŸä¸‹æœ€å¤§åŒ–è¦†ç›–ç‡å’Œæµç•…åº¦çš„ç»„åˆã€‚å®ƒå¼•å…¥äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé¼“åŠ±å°†åŸå§‹æ–‡æ¡£ä¸­çš„å…³é”®æœ¯è¯­åŒ…å«åœ¨æ‘˜è¦ä¸­ï¼šå…³é”®æœ¯è¯­ä»åŸå§‹æ–‡æ¡£ä¸­è¢«å±è”½ï¼Œå¹¶ä¸”å¿…é¡»ç”±ä½¿ç”¨å½“å‰ç”Ÿæˆçš„æ‘˜è¦çš„è¦†ç›–æ¨¡å‹å¡«å……ã€‚ä¸€ç§æ–°é¢–çš„æ— ç›‘ç£è®­ç»ƒç¨‹åºåˆ©ç”¨æ­¤è¦†ç›–æ¨¡å‹å’Œæµç•…æ€§æ¨¡å‹æ¥ç”Ÿæˆå’Œè¯„åˆ†æ‘˜è¦ã€‚åœ¨æµè¡Œçš„æ–°é—»æ‘˜è¦æ•°æ®é›†ä¸Šè¿›è¡Œæµ‹è¯•æ—¶ï¼Œè¯¥æ–¹æ³•æ¯”ä»¥å‰çš„æ— ç›‘ç£æ–¹æ³•é«˜å‡º 2 ä¸ª R-1 ç‚¹ä»¥ä¸Šï¼Œå¹¶ä¸”æ¥è¿‘ç«äº‰æ€§ç›‘ç£æ–¹æ³•çš„ç»“æœã€‚æˆ‘ä»¬çš„æ¨¡å‹é€šè¿‡å¤åˆ¶çš„æ®µè½æ¯”ä»¥å‰çš„å·¥ä½œçŸ­å¤§çº¦ä¸¤å€ï¼Œè·å¾—äº†æ›´é«˜çš„æŠ½è±¡æ°´å¹³ï¼Œå¹¶å­¦ä¼šäº†åœ¨æ²¡æœ‰ç›‘ç£çš„æƒ…å†µä¸‹å‹ç¼©å’Œåˆå¹¶å¥å­ã€‚</td><td>Philippe Laban   Andrew Hsi   John Canny   Marti A. Hearst</td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.10043&#39;]">Leveraging Graph to Improve Abstractive Multi-Document Summarization</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research">https://github.com/PaddlePaddle/Research</a></td><td><a href="https://arxiv.org/pdf/2005.10043">https://arxiv.org/pdf/2005.10043</a></td><td>Graphs that capture relations between textual units have great benefits for detecting salient information from multiple documents and generating overall coherent summaries. In this paper, we develop a neural abstractive multi-document summarization (MDS) model which can leverage well-known graph representations of documents such as similarity graph and discourse graph, to more effectively process multiple input documents and produce abstractive summaries. Our model utilizes graphs to encode documents in order to capture cross-document relations, which is crucial to summarizing long documents. Our model can also take advantage of graphs to guide the summary generation process, which is beneficial for generating coherent and concise summaries. Furthermore, pre-trained language models can be easily combined with our model, which further improve the summarization performance significantly. Empirical results on the WikiSum and MultiNews dataset show that the proposed architecture brings substantial improvements over several strong baselines.</td><td>æ•è·æ–‡æœ¬å•å…ƒä¹‹é—´å…³ç³»çš„å›¾å¯¹äºä»å¤šä¸ªæ–‡æ¡£ä¸­æ£€æµ‹æ˜¾ç€ä¿¡æ¯å’Œç”Ÿæˆæ•´ä½“è¿è´¯çš„æ‘˜è¦æœ‰å¾ˆå¤§çš„å¥½å¤„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§ç¥ç»æŠ½è±¡å¤šæ–‡æ¡£æ‘˜è¦ (MDS) æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åˆ©ç”¨ä¼—æ‰€å‘¨çŸ¥çš„æ–‡æ¡£å›¾è¡¨ç¤ºï¼ˆä¾‹å¦‚ç›¸ä¼¼å›¾å’Œè¯è¯­å›¾ï¼‰æ¥æ›´æœ‰æ•ˆåœ°å¤„ç†å¤šä¸ªè¾“å…¥æ–‡æ¡£å¹¶ç”ŸæˆæŠ½è±¡æ‘˜è¦ã€‚æˆ‘ä»¬çš„æ¨¡å‹åˆ©ç”¨å›¾å¯¹æ–‡æ¡£è¿›è¡Œç¼–ç ä»¥æ•è·è·¨æ–‡æ¡£å…³ç³»ï¼Œè¿™å¯¹äºæ€»ç»“é•¿æ–‡æ¡£è‡³å…³é‡è¦ã€‚æˆ‘ä»¬çš„æ¨¡å‹è¿˜å¯ä»¥åˆ©ç”¨å›¾æ¥æŒ‡å¯¼æ‘˜è¦ç”Ÿæˆè¿‡ç¨‹ï¼Œè¿™æœ‰åˆ©äºç”Ÿæˆè¿è´¯ç®€æ´çš„æ‘˜è¦ã€‚æ­¤å¤–ï¼Œé¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹å¯ä»¥å¾ˆå®¹æ˜“åœ°ä¸æˆ‘ä»¬çš„æ¨¡å‹ç»“åˆï¼Œè¿™è¿›ä¸€æ­¥æ˜¾ç€æé«˜äº†æ‘˜è¦æ€§èƒ½ã€‚ WikiSum å’Œ MultiNews æ•°æ®é›†ä¸Šçš„å®è¯ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¶æ„æ¯”å‡ ä¸ªå¼ºå¤§çš„åŸºçº¿å¸¦æ¥äº†å®è´¨æ€§çš„æ”¹è¿›ã€‚</td><td>Wei Li   Xinyan Xiao   Jiachen Liu   Hua Wu   Haifeng Wang   Junping Du</td></tr><tr><td>16</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00077&#39;]">Scoring Sentence Singletons and Pairs for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/ucfnlp/summarization-sing-pair-mix">https://github.com/ucfnlp/summarization-sing-pair-mix</a></td><td><a href="https://arxiv.org/pdf/1906.00077">https://arxiv.org/pdf/1906.00077</a></td><td>When writing a summary, humans tend to choose content from one or two sentences and merge them into a single summary sentence. However, the mechanisms behind the selection of one or multiple source sentences remain poorly understood. Sentence fusion assumes multi-sentence input; yet sentence selection methods only work with single sentences and not combinations of them. There is thus a crucial gap between sentence selection and fusion to support summarizing by both compressing single sentences and fusing pairs. This paper attempts to bridge the gap by ranking sentence singletons and pairs together in a unified space. Our proposed framework attempts to model human methodology by selecting either a single sentence or a pair of sentences, then compressing or fusing the sentence(s) to produce a summary sentence. We conduct extensive experiments on both single- and multi-document summarization datasets and report findings on sentence selection and abstraction.</td><td>åœ¨æ’°å†™æ‘˜è¦æ—¶ï¼Œäººä»¬å€¾å‘äºä»ä¸€ä¸¤ä¸ªå¥å­ä¸­é€‰æ‹©å†…å®¹å¹¶å°†å®ƒä»¬åˆå¹¶ä¸ºä¸€ä¸ªæ‘˜è¦å¥å­ã€‚ç„¶è€Œï¼Œé€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæºå¥å­èƒŒåçš„æœºåˆ¶ä»ç„¶çŸ¥ä¹‹ç”šå°‘ã€‚å¥å­èåˆå‡è®¾å¤šå¥è¾“å…¥ï¼›ç„¶è€Œï¼Œå¥å­é€‰æ‹©æ–¹æ³•ä»…é€‚ç”¨äºå•ä¸ªå¥å­ï¼Œè€Œä¸é€‚ç”¨äºå®ƒä»¬çš„ç»„åˆã€‚å› æ­¤ï¼Œåœ¨å¥å­é€‰æ‹©å’Œèåˆä¹‹é—´å­˜åœ¨ä¸€ä¸ªå…³é”®çš„å·®è·ï¼Œä»¥æ”¯æŒé€šè¿‡å‹ç¼©å•ä¸ªå¥å­å’Œèåˆå¯¹æ¥è¿›è¡Œæ€»ç»“ã€‚æœ¬æ–‡è¯•å›¾é€šè¿‡åœ¨ç»Ÿä¸€ç©ºé—´ä¸­å¯¹å¥å­å•ä¾‹å’Œå¥å­å¯¹è¿›è¡Œæ’åºæ¥å¼¥åˆè¿™ä¸€å·®è·ã€‚æˆ‘ä»¬æå‡ºçš„æ¡†æ¶è¯•å›¾é€šè¿‡é€‰æ‹©å•ä¸ªå¥å­æˆ–ä¸€å¯¹å¥å­æ¥æ¨¡æ‹Ÿäººç±»æ–¹æ³•ï¼Œç„¶åå‹ç¼©æˆ–èåˆå¥å­ä»¥ç”Ÿæˆæ‘˜è¦å¥å­ã€‚æˆ‘ä»¬å¯¹å•æ–‡æ¡£å’Œå¤šæ–‡æ¡£æ‘˜è¦æ•°æ®é›†è¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œå¹¶æŠ¥å‘Šäº†å…³äºå¥å­é€‰æ‹©å’ŒæŠ½è±¡çš„å‘ç°ã€‚</td><td>Logan Lebanoff   Kaiqiang Song   Franck Dernoncourt   Doo Soon Kim   Seokhwan Kim   Walter Chang   Fei Liu</td></tr></tbody></table></div><h3 id="EMNLP-3"><a href="#EMNLP-3" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.02016&#39;]">A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining</a></td><td></td><td><a href="https://github.com/microsoft/HMNet">https://github.com/microsoft/HMNet</a></td><td><a href="https://arxiv.org/pdf/2004.02016">https://arxiv.org/pdf/2004.02016</a></td><td>With the abundance of automatic meeting transcripts, meeting summarization is of great interest to both participants and other parties. Traditional methods of summarizing meetings depend on complex multi-step pipelines that make joint optimization intractable. Meanwhile, there are a handful of deep neural models for text summarization and dialogue systems. However, the semantic structure and styles of meeting transcripts are quite different from articles and conversations. In this paper, we propose a novel abstractive summary network that adapts to the meeting scenario. We design a hierarchical structure to accommodate long meeting transcripts and a role vector to depict the difference among speakers. Furthermore, due to the inadequacy of meeting summary data, we pretrain the model on large-scale news summary data. Empirical results show that our model outperforms previous approaches in both automatic metrics and human evaluation. For example, on ICSI dataset, the ROUGE-1 score increases from 34.66% to 46.28%.</td><td>ç”±äºæœ‰å¤§é‡çš„è‡ªåŠ¨ä¼šè®®è®°å½•ï¼Œä¼šè®®æ‘˜è¦å¯¹å‚ä¸è€…å’Œå…¶ä»–å„æ–¹éƒ½éå¸¸æ„Ÿå…´è¶£ã€‚æ€»ç»“ä¼šè®®çš„ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºå¤æ‚çš„å¤šæ­¥éª¤ç®¡é“ï¼Œè¿™ä½¿å¾—è”åˆä¼˜åŒ–å˜å¾—éš¾ä»¥å¤„ç†ã€‚åŒæ—¶ï¼Œè¿˜æœ‰ä¸€äº›ç”¨äºæ–‡æœ¬æ‘˜è¦å’Œå¯¹è¯ç³»ç»Ÿçš„æ·±åº¦ç¥ç»æ¨¡å‹ã€‚ç„¶è€Œï¼Œä¼šè®®è®°å½•çš„è¯­ä¹‰ç»“æ„å’Œé£æ ¼ä¸æ–‡ç« å’Œå¯¹è¯æœ‰å¾ˆå¤§ä¸åŒã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é€‚ç”¨äºä¼šè®®åœºæ™¯çš„æ–°å‹æŠ½è±¡æ‘˜è¦ç½‘ç»œã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå±‚æ¬¡ç»“æ„æ¥å®¹çº³é•¿ä¼šè®®è®°å½•å’Œä¸€ä¸ªè§’è‰²å‘é‡æ¥æè¿°æ¼”è®²è€…ä¹‹é—´çš„å·®å¼‚ã€‚æ­¤å¤–ï¼Œç”±äºä¼šè®®æ‘˜è¦æ•°æ®ä¸è¶³ï¼Œæˆ‘ä»¬åœ¨å¤§è§„æ¨¡æ–°é—»æ‘˜è¦æ•°æ®ä¸Šé¢„è®­ç»ƒæ¨¡å‹ã€‚å®è¯ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨è‡ªåŠ¨åº¦é‡å’Œäººå·¥è¯„ä¼°æ–¹é¢éƒ½ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨ ICSI æ•°æ®é›†ä¸Šï¼ŒROUGE-1 åˆ†æ•°ä» 34.66% å¢åŠ åˆ° 46.28%ã€‚</td><td>Chenguang Zhu   Ruochen Xu   Michael Zeng   Xuedong Huang</td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13983&#39;]">Conditional Neural Generation using Sub-Aspect Functions for Extractive News Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.13983">https://arxiv.org/pdf/2004.13983</a></td><td>Much progress has been made in text summarization, fueled by neural architectures using large-scale training corpora. However, in the news domain, neural models easily overfit by leveraging position-related features due to the prevalence of the inverted pyramid writing style. In addition, there is an unmet need to generate a variety of summaries for different users. In this paper, we propose a neural framework that can flexibly control summary generation by introducing a set of sub-aspect functions (i.e. importance, diversity, position). These sub-aspect functions are regulated by a set of control codes to decide which sub-aspect to focus on during summary generation. We demonstrate that extracted summaries with minimal position bias is comparable with those generated by standard models that take advantage of position preference. We also show that news summaries generated with a focus on diversity can be more preferred by human raters. These results suggest that a more flexible neural summarization framework providing more control options could be desirable in tailoring to different user preferences, which is useful since it is often impractical to articulate such preferences for different applications a priori.</td><td>åœ¨ä½¿ç”¨å¤§è§„æ¨¡è®­ç»ƒè¯­æ–™åº“çš„ç¥ç»æ¶æ„çš„æ¨åŠ¨ä¸‹ï¼Œæ–‡æœ¬æ‘˜è¦å–å¾—äº†å¾ˆå¤§è¿›å±•ã€‚ç„¶è€Œï¼Œåœ¨æ–°é—»é¢†åŸŸï¼Œç”±äºå€’é‡‘å­—å¡”å†™ä½œé£æ ¼çš„ç››è¡Œï¼Œç¥ç»æ¨¡å‹å¾ˆå®¹æ˜“é€šè¿‡åˆ©ç”¨ä¸ä½ç½®ç›¸å…³çš„ç‰¹å¾æ¥è¿‡åº¦æ‹Ÿåˆã€‚æ­¤å¤–ï¼Œè¿˜å­˜åœ¨ä¸ºä¸åŒç”¨æˆ·ç”Ÿæˆå„ç§æ‘˜è¦çš„éœ€æ±‚æœªå¾—åˆ°æ»¡è¶³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç¥ç»æ¡†æ¶ï¼Œå¯ä»¥é€šè¿‡å¼•å…¥ä¸€ç»„å­æ–¹é¢å‡½æ•°ï¼ˆå³é‡è¦æ€§ã€å¤šæ ·æ€§ã€ä½ç½®ï¼‰æ¥çµæ´»æ§åˆ¶æ‘˜è¦ç”Ÿæˆã€‚è¿™äº›å­æ–¹é¢åŠŸèƒ½ç”±ä¸€ç»„æ§åˆ¶ä»£ç è°ƒèŠ‚ï¼Œä»¥å†³å®šåœ¨æ‘˜è¦ç”ŸæˆæœŸé—´å…³æ³¨å“ªä¸ªå­æ–¹é¢ã€‚æˆ‘ä»¬è¯æ˜äº†å…·æœ‰æœ€å°ä½ç½®åå·®çš„æå–æ‘˜è¦ä¸åˆ©ç”¨ä½ç½®åå¥½çš„æ ‡å‡†æ¨¡å‹ç”Ÿæˆçš„æ‘˜è¦å…·æœ‰å¯æ¯”æ€§ã€‚æˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œäººå·¥è¯„ä¼°è€…å¯èƒ½æ›´å–œæ¬¢ä»¥å¤šæ ·æ€§ä¸ºé‡ç‚¹ç”Ÿæˆçš„æ–°é—»æ‘˜è¦ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œåœ¨é’ˆå¯¹ä¸åŒçš„ç”¨æˆ·åå¥½è¿›è¡Œå®šåˆ¶æ—¶ï¼Œå¯èƒ½éœ€è¦æä¾›æ›´å¤šæ§åˆ¶é€‰é¡¹çš„æ›´çµæ´»çš„ç¥ç»æ‘˜è¦æ¡†æ¶ï¼Œè¿™å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå…ˆéªŒåœ°é˜æ˜ä¸åŒåº”ç”¨ç¨‹åºçš„æ­¤ç±»åå¥½é€šå¸¸æ˜¯ä¸åˆ‡å®é™…çš„ã€‚</td><td>Zhengyuan Liu   Ke Shi   Nancy F. Chen</td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.08242&#39;]">Unsupervised Extractive Summarization by Pre-training Hierarchical Transformers</a></td><td></td><td><a href="https://github.com/xssstory/STAS">https://github.com/xssstory/STAS</a></td><td><a href="https://arxiv.org/pdf/2010.08242">https://arxiv.org/pdf/2010.08242</a></td><td>Unsupervised extractive document summarization aims to select important sentences from a document without using labeled summaries during training. Existing methods are mostly graph-based with sentences as nodes and edge weights measured by sentence similarities. In this work, we find that transformer attentions can be used to rank sentences for unsupervised extractive summarization. Specifically, we first pre-train a hierarchical transformer model using unlabeled documents only. Then we propose a method to rank sentences using sentence-level self-attentions and pre-training objectives. Experiments on CNN/DailyMail and New York Times datasets show our model achieves state-of-the-art performance on unsupervised summarization. We also find in experiments that our model is less dependent on sentence positions. When using a linear combination of our model and a recent unsupervised model explicitly modeling sentence positions, we obtain even better results.</td><td>æ— ç›‘ç£æå–æ–‡æ¡£æ‘˜è¦æ—¨åœ¨åœ¨è®­ç»ƒæœŸé—´ä¸ä½¿ç”¨æ ‡è®°æ‘˜è¦ä»æ–‡æ¡£ä¸­é€‰æ‹©é‡è¦å¥å­ã€‚ç°æœ‰çš„æ–¹æ³•å¤§å¤šæ˜¯åŸºäºå›¾çš„ï¼Œä»¥å¥å­ä¸ºèŠ‚ç‚¹ï¼Œè¾¹æƒé‡ç”±å¥å­ç›¸ä¼¼åº¦è¡¡é‡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å‘ç° Transformer attention å¯ç”¨äºå¯¹æ— ç›‘ç£æå–æ‘˜è¦çš„å¥å­è¿›è¡Œæ’åã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆä»…ä½¿ç”¨æœªæ ‡è®°çš„æ–‡æ¡£é¢„è®­ç»ƒåˆ†å±‚è½¬æ¢å™¨æ¨¡å‹ã€‚ç„¶åæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä½¿ç”¨å¥å­çº§è‡ªæˆ‘æ³¨æ„å’Œé¢„è®­ç»ƒç›®æ ‡å¯¹å¥å­è¿›è¡Œæ’åºçš„æ–¹æ³•ã€‚åœ¨ CNN/DailyMail å’Œçº½çº¦æ—¶æŠ¥æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨æ— ç›‘ç£æ‘˜è¦æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬è¿˜åœ¨å®éªŒä¸­å‘ç°æˆ‘ä»¬çš„æ¨¡å‹å¯¹å¥å­ä½ç½®çš„ä¾èµ–æ€§è¾ƒå°ã€‚å½“ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹å’Œæœ€è¿‘çš„æ— ç›‘ç£æ¨¡å‹çš„çº¿æ€§ç»„åˆæ˜¾å¼å»ºæ¨¡å¥å­ä½ç½®æ—¶ï¼Œæˆ‘ä»¬è·å¾—äº†æ›´å¥½çš„ç»“æœã€‚</td><td>Shusheng Xu   Xingxing Zhang   Yi Wu   Furu Wei   Ming Zhou</td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.01786&#39;]">Corpora Evaluation and System Bias detection in Multi Document Summarization</a></td><td></td><td><a href="https://github.com/LCS2-IIITD/summarization_bias">https://github.com/LCS2-IIITD/summarization_bias</a></td><td><a href="https://arxiv.org/pdf/2010.01786">https://arxiv.org/pdf/2010.01786</a></td><td>Multi-document summarization (MDS) is the task of reflecting key points from any set of documents into a concise text paragraph. In the past, it has been used to aggregate news, tweets, product reviews, etc. from various sources. Owing to no standard definition of the task, we encounter a plethora of datasets with varying levels of overlap and conflict between participating documents. There is also no standard regarding what constitutes summary information in MDS. Adding to the challenge is the fact that new systems report results on a set of chosen datasets, which might not correlate with their performance on the other datasets. In this paper, we study this heterogeneous task with the help of a few widely used MDS corpora and a suite of state-of-the-art models. We make an attempt to quantify the quality of summarization corpus and prescribe a list of points to consider while proposing a new MDS corpus. Next, we analyze the reason behind the absence of an MDS system which achieves superior performance across all corpora. We then observe the extent to which system metrics are influenced, and bias is propagated due to corpus properties. The scripts to reproduce the experiments in this work are available at <a href="https://github.com/LCS2-IIITD/summarization_bias.git">https://github.com/LCS2-IIITD/summarization_bias.git</a>.</td><td></td><td>Alvin Dey   Tanya Chowdhury   Yash Kumar Atri   Tanmoy Chakraborty</td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.05139&#39;]">An Empirical Study of Cross-Dataset Evaluation for Neural Summarization Systems</a></td><td></td><td><a href="https://github.com/zide05/CDEvalSumm">https://github.com/zide05/CDEvalSumm</a></td><td><a href="https://arxiv.org/pdf/2010.05139">https://arxiv.org/pdf/2010.05139</a></td><td>Neural network-based models augmented with unsupervised pre-trained knowledge have achieved impressive performance on text summarization. However, most existing evaluation methods are limited to an in-domain setting, where summarizers are trained and evaluated on the same dataset. We argue that this approach can narrow our understanding of the generalization ability for different summarization systems. In this paper, we perform an in-depth analysis of characteristics of different datasets and investigate the performance of different summarization models under a cross-dataset setting, in which a summarizer trained on one corpus will be evaluated on a range of out-of-domain corpora. A comprehensive study of 11 representative summarization systems on 5 datasets from different domains reveals the effect of model architectures and generation ways (i.e. abstractive and extractive) on model generalization ability. Further, experimental results shed light on the limitations of existing summarizers. Brief introduction and supplementary code can be found in <a href="https://github.com/zide05/CDEvalSumm">https://github.com/zide05/CDEvalSumm</a>.</td><td></td><td>Yiran Chen   Pengfei Liu   Ming Zhong   Zi-Yi Dou   Danqing Wang   Xipeng Qiu   Xuanjing Huang</td></tr><tr><td>6</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.13114&#39;]">Contrastive Attention Mechanism for Abstractive Sentence Summarization</a></td><td></td><td><a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td><a href="https://arxiv.org/pdf/1910.13114">https://arxiv.org/pdf/1910.13114</a></td><td>We propose a contrastive attention mechanism to extend the sequence-to-sequence framework for abstractive sentence summarization task, which aims to generate a brief summary of a given source sentence. The proposed contrastive attention mechanism accommodates two categories of attention: one is the conventional attention that attends to relevant parts of the source sentence, the other is the opponent attention that attends to irrelevant or less relevant parts of the source sentence. Both attentions are trained in an opposite way so that the contribution from the conventional attention is encouraged and the contribution from the opponent attention is discouraged through a novel softmax and softmin functionality. Experiments on benchmark datasets show that, the proposed contrastive attention mechanism is more focused on the relevant parts for the summary than the conventional attention mechanism, and greatly advances the state-of-the-art performance on the abstractive sentence summarization task. We release the code at <a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td>æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯¹æ¯”æ³¨æ„æœºåˆ¶æ¥æ‰©å±•æŠ½è±¡å¥å­æ‘˜è¦ä»»åŠ¡çš„åºåˆ—åˆ°åºåˆ—æ¡†æ¶ï¼Œæ—¨åœ¨ç”Ÿæˆç»™å®šæºå¥å­çš„ç®€çŸ­æ‘˜è¦ã€‚æ‰€æå‡ºçš„å¯¹æ¯”æ³¨æ„åŠ›æœºåˆ¶åŒ…å«ä¸¤ç±»æ³¨æ„åŠ›ï¼šä¸€ç§æ˜¯å…³æ³¨æºå¥ç›¸å…³éƒ¨åˆ†çš„å¸¸è§„æ³¨æ„åŠ›ï¼Œå¦ä¸€ç§æ˜¯å…³æ³¨æºå¥ä¸­ä¸ç›¸å…³æˆ–ä¸å¤ªç›¸å…³éƒ¨åˆ†çš„å¯¹æ‰‹æ³¨æ„åŠ›ã€‚ä¸¤ç§æ³¨æ„åŠ›éƒ½ä»¥ç›¸åçš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œä»è€Œé€šè¿‡æ–°é¢–çš„ softmax å’Œ softmin åŠŸèƒ½é¼“åŠ±ä¼ ç»Ÿæ³¨æ„åŠ›çš„è´¡çŒ®ï¼Œå¹¶é˜»æ­¢å¯¹æ‰‹æ³¨æ„åŠ›çš„è´¡çŒ®ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„å¯¹æ¯”æ³¨æ„æœºåˆ¶æ¯”ä¼ ç»Ÿçš„æ³¨æ„æœºåˆ¶æ›´å…³æ³¨æ‘˜è¦çš„ç›¸å…³éƒ¨åˆ†ï¼Œå¹¶ä¸”å¤§å¤§æé«˜äº†æŠ½è±¡å¥å­æ‘˜è¦ä»»åŠ¡çš„æœ€æ–°æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨ <a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a> å‘å¸ƒä»£ç </td><td>Xiangyu Duan   Hoongfei Yu   Mingming Yin   Min Zhang   Weihua Luo   Yue Zhang</td></tr><tr><td>7</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.08486&#39;]">Concept Pointer Network for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/wprojectsn/codes">https://github.com/wprojectsn/codes</a></td><td><a href="https://arxiv.org/pdf/1910.08486">https://arxiv.org/pdf/1910.08486</a></td><td>A quality abstractive summary should not only copy salient source texts as summaries but should also tend to generate new conceptual words to express concrete details. Inspired by the popular pointer generator sequence-to-sequence model, this paper presents a concept pointer network for improving these aspects of abstractive summarization. The network leverages knowledge-based, context-aware conceptualizations to derive an extended set of candidate concepts. The model then points to the most appropriate choice using both the concept set and original source text. This joint approach generates abstractive summaries with higher-level semantic concepts. The training model is also optimized in a way that adapts to different data, which is based on a novel method of distantly-supervised learning guided by reference summaries and testing set. Overall, the proposed approach provides statistically significant improvements over several state-of-the-art models on both the DUC-2004 and Gigaword datasets. A human evaluation of the modelâ€™s abstractive abilities also supports the quality of the summaries produced within this framework.</td><td>é«˜è´¨é‡çš„æŠ½è±¡æ‘˜è¦ä¸ä»…åº”è¯¥å¤åˆ¶çªå‡ºçš„æºæ–‡æœ¬ä½œä¸ºæ‘˜è¦ï¼Œè¿˜åº”è¯¥å€¾å‘äºç”Ÿæˆæ–°çš„æ¦‚å¿µè¯æ¥è¡¨è¾¾å…·ä½“ç»†èŠ‚ã€‚å—æµè¡Œçš„æŒ‡é’ˆç”Ÿæˆå™¨åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ¦‚å¿µæŒ‡é’ˆç½‘ç»œï¼Œç”¨äºæ”¹è¿›æŠ½è±¡æ‘˜è¦çš„è¿™äº›æ–¹é¢ã€‚è¯¥ç½‘ç»œåˆ©ç”¨åŸºäºçŸ¥è¯†çš„ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ¦‚å¿µåŒ–æ¥æ¨å¯¼å‡ºä¸€ç»„æ‰©å±•çš„å€™é€‰æ¦‚å¿µã€‚ç„¶åï¼Œæ¨¡å‹ä½¿ç”¨æ¦‚å¿µé›†å’ŒåŸå§‹æºæ–‡æœ¬æŒ‡å‡ºæœ€åˆé€‚çš„é€‰æ‹©ã€‚è¿™ç§è”åˆæ–¹æ³•ç”Ÿæˆå…·æœ‰æ›´é«˜çº§åˆ«è¯­ä¹‰æ¦‚å¿µçš„æŠ½è±¡æ‘˜è¦ã€‚è®­ç»ƒæ¨¡å‹ä¹Ÿä»¥é€‚åº”ä¸åŒæ•°æ®çš„æ–¹å¼è¿›è¡Œäº†ä¼˜åŒ–ï¼Œè¿™æ˜¯åŸºäºä¸€ç§ä»¥å‚è€ƒæ‘˜è¦å’Œæµ‹è¯•é›†ä¸ºæŒ‡å¯¼çš„è¿œç¨‹ç›‘ç£å­¦ä¹ çš„æ–°æ–¹æ³•ã€‚æ€»ä½“è€Œè¨€ï¼Œä¸ DUC-2004 å’Œ Gigaword æ•°æ®é›†ä¸Šçš„å‡ ä¸ªæœ€å…ˆè¿›æ¨¡å‹ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨ç»Ÿè®¡ä¸Šæœ‰æ˜¾ç€æ”¹è¿›ã€‚å¯¹æ¨¡å‹æŠ½è±¡èƒ½åŠ›çš„äººå·¥è¯„ä¼°ä¹Ÿæ”¯æŒåœ¨è¯¥æ¡†æ¶å†…ç”Ÿæˆçš„æ‘˜è¦çš„è´¨é‡ã€‚</td><td>Wang Wenbo   Gao Yang   Huang Heyan   Zhou Yuxiang</td></tr><tr><td>8</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.13114&#39;]">Contrastive Attention Mechanism for Abstractive Sentence Summarization</a></td><td></td><td><a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td><a href="https://arxiv.org/pdf/1910.13114">https://arxiv.org/pdf/1910.13114</a></td><td>We propose a contrastive attention mechanism to extend the sequence-to-sequence framework for abstractive sentence summarization task, which aims to generate a brief summary of a given source sentence. The proposed contrastive attention mechanism accommodates two categories of attention: one is the conventional attention that attends to relevant parts of the source sentence, the other is the opponent attention that attends to irrelevant or less relevant parts of the source sentence. Both attentions are trained in an opposite way so that the contribution from the conventional attention is encouraged and the contribution from the opponent attention is discouraged through a novel softmax and softmin functionality. Experiments on benchmark datasets show that, the proposed contrastive attention mechanism is more focused on the relevant parts for the summary than the conventional attention mechanism, and greatly advances the state-of-the-art performance on the abstractive sentence summarization task. We release the code at <a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td>æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯¹æ¯”æ³¨æ„æœºåˆ¶æ¥æ‰©å±•æŠ½è±¡å¥å­æ‘˜è¦ä»»åŠ¡çš„åºåˆ—åˆ°åºåˆ—æ¡†æ¶ï¼Œæ—¨åœ¨ç”Ÿæˆç»™å®šæºå¥å­çš„ç®€çŸ­æ‘˜è¦ã€‚æ‰€æå‡ºçš„å¯¹æ¯”æ³¨æ„åŠ›æœºåˆ¶åŒ…å«ä¸¤ç±»æ³¨æ„åŠ›ï¼šä¸€ç§æ˜¯å…³æ³¨æºå¥ç›¸å…³éƒ¨åˆ†çš„å¸¸è§„æ³¨æ„åŠ›ï¼Œå¦ä¸€ç§æ˜¯å…³æ³¨æºå¥ä¸­ä¸ç›¸å…³æˆ–ä¸å¤ªç›¸å…³éƒ¨åˆ†çš„å¯¹æ‰‹æ³¨æ„åŠ›ã€‚ä¸¤ç§æ³¨æ„åŠ›éƒ½ä»¥ç›¸åçš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œä»è€Œé€šè¿‡æ–°é¢–çš„ softmax å’Œ softmin åŠŸèƒ½é¼“åŠ±ä¼ ç»Ÿæ³¨æ„åŠ›çš„è´¡çŒ®ï¼Œå¹¶é˜»æ­¢å¯¹æ‰‹æ³¨æ„åŠ›çš„è´¡çŒ®ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„å¯¹æ¯”æ³¨æ„æœºåˆ¶æ¯”ä¼ ç»Ÿçš„æ³¨æ„æœºåˆ¶æ›´å…³æ³¨æ‘˜è¦çš„ç›¸å…³éƒ¨åˆ†ï¼Œå¹¶ä¸”å¤§å¤§æé«˜äº†æŠ½è±¡å¥å­æ‘˜è¦ä»»åŠ¡çš„æœ€æ–°æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨ <a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a> å‘å¸ƒä»£ç </td><td>Xiangyu Duan   Hoongfei Yu   Mingming Yin   Min Zhang   Weihua Luo   Yue Zhang</td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.00863&#39;]">Neural Extractive Text Summarization with Syntactic Compression</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.00863">https://arxiv.org/pdf/1902.00863</a></td><td>Recent neural network approaches to summarization are largely either selection-based extraction or generation-based abstraction. In this work, we present a neural model for single-document summarization based on joint extraction and syntactic compression. Our model chooses sentences from the document, identifies possible compressions based on constituency parses, and scores those compressions with a neural model to produce the final summary. For learning, we construct oracle extractive-compressive summaries, then learn both of our components jointly with this supervision. Experimental results on the CNN/Daily Mail and New York Times datasets show that our model achieves strong performance (comparable to state-of-the-art systems) as evaluated by ROUGE. Moreover, our approach outperforms an off-the-shelf compression module, and human and manual evaluation shows that our modelâ€™s output generally remains grammatical.</td><td>æœ€è¿‘çš„ç¥ç»ç½‘ç»œæ€»ç»“æ–¹æ³•ä¸»è¦æ˜¯åŸºäºé€‰æ‹©çš„æå–æˆ–åŸºäºç”Ÿæˆçš„æŠ½è±¡ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè”åˆæå–å’Œå¥æ³•å‹ç¼©çš„å•æ–‡æ¡£æ‘˜è¦ç¥ç»æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¨¡å‹ä»æ–‡æ¡£ä¸­é€‰æ‹©å¥å­ï¼Œæ ¹æ®é€‰åŒºè§£æè¯†åˆ«å¯èƒ½çš„å‹ç¼©ï¼Œå¹¶ä½¿ç”¨ç¥ç»æ¨¡å‹å¯¹è¿™äº›å‹ç¼©è¿›è¡Œè¯„åˆ†ä»¥ç”Ÿæˆæœ€ç»ˆæ‘˜è¦ã€‚å¯¹äºå­¦ä¹ ï¼Œæˆ‘ä»¬æ„å»º oracle æå–å‹ç¼©æ‘˜è¦ï¼Œç„¶ååœ¨æ­¤ç›‘ç£ä¸‹å…±åŒå­¦ä¹ æˆ‘ä»¬çš„ä¸¤ä¸ªç»„ä»¶ã€‚åœ¨ CNN/Daily Mail å’Œçº½çº¦æ—¶æŠ¥æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹è·å¾—äº† ROUGE è¯„ä¼°çš„å¼ºå¤§æ€§èƒ½ï¼ˆå¯ä¸æœ€å…ˆè¿›çš„ç³»ç»Ÿç›¸åª²ç¾ï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æˆçš„å‹ç¼©æ¨¡å—ï¼Œäººå·¥å’Œäººå·¥è¯„ä¼°è¡¨æ˜æˆ‘ä»¬æ¨¡å‹çš„è¾“å‡ºé€šå¸¸ä¿æŒè¯­æ³•ã€‚</td><td>Jiacheng Xu   Greg Durrett</td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.08345&#39;]">Text Summarization with Pretrained Encoders</a></td><td></td><td><a href="https://github.com/nlpyang/PreSumm">https://github.com/nlpyang/PreSumm</a></td><td><a href="https://arxiv.org/pdf/1908.08345">https://arxiv.org/pdf/1908.08345</a></td><td>Bidirectional Encoder Representations from Transformers (BERT) represents the latest incarnation of pretrained language models which have recently advanced a wide range of natural language processing tasks. In this paper, we showcase how BERT can be usefully applied in text summarization and propose a general framework for both extractive and abstractive models. We introduce a novel document-level encoder based on BERT which is able to express the semantics of a document and obtain representations for its sentences. Our extractive model is built on top of this encoder by stacking several inter-sentence Transformer layers. For abstractive summarization, we propose a new fine-tuning schedule which adopts different optimizers for the encoder and the decoder as a means of alleviating the mismatch between the two (the former is pretrained while the latter is not). We also demonstrate that a two-staged fine-tuning approach can further boost the quality of the generated summaries. Experiments on three datasets show that our model achieves state-of-the-art results across the board in both extractive and abstractive settings. Our code is available at <a href="https://github.com/nlpyang/PreSumm">https://github.com/nlpyang/PreSumm</a></td><td>Transformers çš„åŒå‘ç¼–ç å™¨è¡¨ç¤º (BERT) ä»£è¡¨äº†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æœ€æ–°åŒ–èº«ï¼Œè¿™äº›æ¨¡å‹æœ€è¿‘æ¨è¿›äº†å¹¿æ³›çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº† BERT å¦‚ä½•æœ‰æ•ˆåœ°åº”ç”¨äºæ–‡æœ¬æ‘˜è¦ï¼Œå¹¶ä¸ºæå–å’ŒæŠ½è±¡æ¨¡å‹æå‡ºäº†ä¸€ä¸ªé€šç”¨æ¡†æ¶ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäº BERT çš„æ–°å‹æ–‡æ¡£çº§ç¼–ç å™¨ï¼Œå®ƒèƒ½å¤Ÿè¡¨è¾¾æ–‡æ¡£çš„è¯­ä¹‰å¹¶è·å¾—å…¶å¥å­çš„è¡¨ç¤ºã€‚æˆ‘ä»¬çš„æå–æ¨¡å‹å»ºç«‹åœ¨è¿™ä¸ªç¼–ç å™¨ä¹‹ä¸Šï¼Œé€šè¿‡å †å å‡ ä¸ªå¥é—´ Transformer å±‚ã€‚å¯¹äºæŠ½è±¡æ‘˜è¦ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒè®¡åˆ’ï¼Œå®ƒå¯¹ç¼–ç å™¨å’Œè§£ç å™¨é‡‡ç”¨ä¸åŒçš„ä¼˜åŒ–å™¨ä½œä¸ºå‡è½»ä¸¤è€…ä¹‹é—´ä¸åŒ¹é…çš„æ‰‹æ®µï¼ˆå‰è€…æ˜¯é¢„è®­ç»ƒçš„ï¼Œè€Œåè€…ä¸æ˜¯ï¼‰ã€‚æˆ‘ä»¬è¿˜è¯æ˜äº†ä¸¤é˜¶æ®µå¾®è°ƒæ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æé«˜ç”Ÿæˆæ‘˜è¦çš„è´¨é‡ã€‚åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨æå–å’ŒæŠ½è±¡è®¾ç½®ä¸­éƒ½å–å¾—äº†å…¨é¢çš„æœ€æ–°ç»“æœã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ <a href="https://github.com/nlpyang/PreSumm">https://github.com/nlpyang/PreSumm</a> è·å¾—</td><td>Yang Liu   Mirella Lapata</td></tr></tbody></table></div><h3 id="NAACL-3"><a href="#NAACL-3" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.08014&#39;]">GSum: A General Framework for Guided Neural Abstractive Summarization</a></td><td></td><td><a href="https://github.com/neulab/guided_summarization">https://github.com/neulab/guided_summarization</a></td><td><a href="https://arxiv.org/pdf/2010.08014">https://arxiv.org/pdf/2010.08014</a></td><td>Neural abstractive summarization models are flexible and can produce coherent summaries, but they are sometimes unfaithful and can be difficult to control. While previous studies attempt to provide different types of guidance to control the output and increase faithfulness, it is not clear how these strategies compare and contrast to each other. In this paper, we propose a general and extensible guided summarization framework (GSum) that can effectively take different kinds of external guidance as input, and we perform experiments across several different varieties. Experiments demonstrate that this model is effective, achieving state-of-the-art performance according to ROUGE on 4 popular summarization datasets when using highlighted sentences as guidance. In addition, we show that our guided model can generate more faithful summaries and demonstrate how different types of guidance generate qualitatively different summaries, lending a degree of controllability to the learned models.</td><td>ç¥ç»æŠ½è±¡æ‘˜è¦æ¨¡å‹å¾ˆçµæ´»ï¼Œå¯ä»¥äº§ç”Ÿè¿è´¯çš„æ‘˜è¦ï¼Œä½†å®ƒä»¬æœ‰æ—¶ä¸å¯é å¹¶ä¸”éš¾ä»¥æ§åˆ¶ã€‚è™½ç„¶ä»¥å‰çš„ç ”ç©¶è¯•å›¾æä¾›ä¸åŒç±»å‹çš„æŒ‡å¯¼æ¥æ§åˆ¶è¾“å‡ºå’Œå¢åŠ å¿ è¯šåº¦ï¼Œä½†å°šä¸æ¸…æ¥šè¿™äº›ç­–ç•¥å¦‚ä½•ç›¸äº’æ¯”è¾ƒå’Œå¯¹æ¯”ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªé€šç”¨ä¸”å¯æ‰©å±•çš„å¼•å¯¼å¼æ€»ç»“æ¡†æ¶ï¼ˆGSumï¼‰ï¼Œå®ƒå¯ä»¥æœ‰æ•ˆåœ°å°†ä¸åŒç§ç±»çš„å¤–éƒ¨å¼•å¯¼ä½œä¸ºè¾“å…¥ï¼Œå¹¶åœ¨å‡ ä¸ªä¸åŒçš„å“ç§ä¸Šè¿›è¡Œå®éªŒã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹æ˜¯æœ‰æ•ˆçš„ï¼Œåœ¨ä½¿ç”¨çªå‡ºæ˜¾ç¤ºçš„å¥å­ä½œä¸ºæŒ‡å¯¼æ—¶ï¼Œæ ¹æ® ROUGE åœ¨ 4 ä¸ªæµè¡Œçš„æ‘˜è¦æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„å¼•å¯¼æ¨¡å‹å¯ä»¥ç”Ÿæˆæ›´å¿ å®çš„æ‘˜è¦ï¼Œå¹¶å±•ç¤ºä¸åŒç±»å‹çš„å¼•å¯¼å¦‚ä½•ç”Ÿæˆè´¨é‡ä¸åŒçš„æ‘˜è¦ï¼Œä»è€Œä¸ºå­¦ä¹ æ¨¡å‹æä¾›ä¸€å®šç¨‹åº¦çš„å¯æ§æ€§ã€‚</td><td>Zi-Yi Dou   Pengfei Liu   Hiroaki Hayashi   Zhengbao Jiang   Graham Neubig</td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12836&#39;]">Improving Zero and Few-Shot Abstractive Summarization with Intermediate Fine- tuning and Data Augmentation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12836">https://arxiv.org/pdf/2010.12836</a></td><td>Models pretrained with self-supervised objectives on large text corpora achieve state-of-the-art performance on English text summarization tasks. However, these models are typically fine-tuned on hundreds of thousands of data points, an infeasible requirement when applying summarization to new, niche domains. In this work, we introduce a novel and generalizable method, called WikiTransfer, for fine-tuning pretrained models for summarization in an unsupervised, dataset-specific manner. WikiTransfer fine-tunes pretrained models on pseudo-summaries, produced from generic Wikipedia data, which contain characteristics of the target dataset, such as the length and level of abstraction of the desired summaries. WikiTransfer models achieve state-of-the-art, zero-shot abstractive summarization performance on the CNN-DailyMail dataset and demonstrate the effectiveness of our approach on three additional diverse datasets. These models are more robust to noisy data and also achieve better or comparable few-shot performance using 10 and 100 training examples when compared to few-shot transfer from other summarization datasets. To further boost performance, we employ data augmentation via round-trip translation as well as introduce a regularization term for improved few-shot transfer. To understand the role of dataset aspects in transfer performance and the quality of the resulting output summaries, we further study the effect of the components of our unsupervised fine-tuning data and analyze few-shot performance using both automatic and human evaluation.</td><td>åœ¨å¤§å‹æ–‡æœ¬è¯­æ–™åº“ä¸Šä½¿ç”¨è‡ªç›‘ç£ç›®æ ‡è¿›è¡Œé¢„è®­ç»ƒçš„æ¨¡å‹åœ¨è‹±è¯­æ–‡æœ¬æ‘˜è¦ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹é€šå¸¸ä¼šåœ¨æ•°åä¸‡ä¸ªæ•°æ®ç‚¹ä¸Šè¿›è¡Œå¾®è°ƒï¼Œè¿™åœ¨å°†æ±‡æ€»åº”ç”¨äºæ–°çš„åˆ©åŸºé¢†åŸŸæ—¶æ˜¯ä¸å¯è¡Œçš„ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–ä¸”å¯æ¨å¹¿çš„æ–¹æ³•ï¼Œç§°ä¸º WikiTransferï¼Œç”¨äºå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ï¼Œä»¥æ— ç›‘ç£çš„ã€ç‰¹å®šäºæ•°æ®é›†çš„æ–¹å¼è¿›è¡Œæ±‡æ€»ã€‚ WikiTransfer å¾®è°ƒä¼ªæ‘˜è¦ä¸Šçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹ç”±é€šç”¨ç»´åŸºç™¾ç§‘æ•°æ®ç”Ÿæˆï¼Œå…¶ä¸­åŒ…å«ç›®æ ‡æ•°æ®é›†çš„ç‰¹å¾ï¼Œä¾‹å¦‚æ‰€éœ€æ‘˜è¦çš„é•¿åº¦å’ŒæŠ½è±¡çº§åˆ«ã€‚ WikiTransfer æ¨¡å‹åœ¨ CNN-DailyMail æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æŠ½è±¡æ‘˜è¦æ€§èƒ½ï¼Œå¹¶è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¦å¤–ä¸‰ä¸ªä¸åŒæ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§ã€‚ä¸æ¥è‡ªå…¶ä»–æ‘˜è¦æ•°æ®é›†çš„å°æ ·æœ¬ä¼ è¾“ç›¸æ¯”ï¼Œè¿™äº›æ¨¡å‹å¯¹å˜ˆæ‚çš„æ•°æ®æ›´åŠ ç¨³å¥ï¼Œå¹¶ä¸”ä½¿ç”¨ 10 å’Œ 100 ä¸ªè®­ç»ƒç¤ºä¾‹ä¹Ÿèƒ½å®ç°æ›´å¥½æˆ–å¯æ¯”çš„å°æ ·æœ¬æ€§èƒ½ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æ€§èƒ½ï¼Œæˆ‘ä»¬é€šè¿‡å¾€è¿”ç¿»è¯‘ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œå¹¶å¼•å…¥äº†ä¸€ä¸ªæ­£åˆ™åŒ–é¡¹æ¥æ”¹è¿›å°æ ·æœ¬ä¼ è¾“ã€‚ä¸ºäº†äº†è§£æ•°æ®é›†æ–¹é¢åœ¨ä¼ è¾“æ€§èƒ½å’Œç»“æœè¾“å‡ºæ‘˜è¦è´¨é‡ä¸­çš„ä½œç”¨ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥ç ”ç©¶äº†æ— ç›‘ç£å¾®è°ƒæ•°æ®ç»„ä»¶çš„å½±å“ï¼Œå¹¶ä½¿ç”¨è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°åˆ†æäº†å°æ ·æœ¬æ€§èƒ½ã€‚</td><td>Alexander R. Fabbri   Simeng Han   Haoyuan Li   Haoran Li   Marjan Ghazvininejad   Shafiq Joty   Dragomir Radev   Yashar Mehdad</td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.08400&#39;]">Structure-Aware Abstractive Conversation Summarization via Discourse and Action Graphs</a></td><td></td><td><a href="https://github.com/GT-SALT/Structure-Aware-BART">https://github.com/GT-SALT/Structure-Aware-BART</a></td><td><a href="https://arxiv.org/pdf/2104.08400">https://arxiv.org/pdf/2104.08400</a></td><td>Abstractive conversation summarization has received much attention recently. However, these generated summaries often suffer from insufficient, redundant, or incorrect content, largely due to the unstructured and complex characteristics of human-human interactions. To this end, we propose to explicitly model the rich structures in conversations for more precise and accurate conversation summarization, by first incorporating discourse relations between utterances and action triples (â€œwho-doing-whatâ€) in utterances through structured graphs to better encode conversations, and then designing a multi-granularity decoder to generate summaries by combining all levels of information. Experiments show that our proposed models outperform state-of-the-art methods and generalize well in other domains in terms of both automatic evaluations and human judgments. We have publicly released our code at <a href="https://github.com/GT-SALT/Structure-Aware-BART">https://github.com/GT-SALT/Structure-Aware-BART</a>.</td><td></td><td>Jiaao Chen   Diyi Yang</td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.11332&#39;]">AdaptSum: Towards Low-Resource Domain Adaptation for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/TysonYu/AdaptSum">https://github.com/TysonYu/AdaptSum</a></td><td><a href="https://arxiv.org/pdf/2103.11332">https://arxiv.org/pdf/2103.11332</a></td><td>State-of-the-art abstractive summarization models generally rely on extensive labeled data, which lowers their generalization ability on domains where such data are not available. In this paper, we present a study of domain adaptation for the abstractive summarization task across six diverse target domains in a low-resource setting. Specifically, we investigate the second phase of pre-training on large-scale generative models under three different settings: 1) source domain pre-training; 2) domain-adaptive pre-training; and 3) task-adaptive pre-training. Experiments show that the effectiveness of pre-training is correlated with the similarity between the pre-training data and the target domain task. Moreover, we find that continuing pre-training could lead to the pre-trained modelâ€™s catastrophic forgetting, and a learning method with less forgetting can alleviate this issue. Furthermore, results illustrate that a huge gap still exists between the low-resource and high-resource settings, which highlights the need for more advanced domain adaptation methods for the abstractive summarization task.</td><td>æœ€å…ˆè¿›çš„æŠ½è±¡æ‘˜è¦æ¨¡å‹é€šå¸¸ä¾èµ–äºå¹¿æ³›çš„æ ‡è®°æ•°æ®ï¼Œè¿™é™ä½äº†å®ƒä»¬åœ¨è¿™äº›æ•°æ®ä¸å¯ç”¨çš„åŸŸä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†åœ¨ä½èµ„æºç¯å¢ƒä¸­è·¨å…­ä¸ªä¸åŒç›®æ ‡åŸŸçš„æŠ½è±¡æ‘˜è¦ä»»åŠ¡çš„åŸŸé€‚åº”ç ”ç©¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç ”ç©¶äº†åœ¨ä¸‰ç§ä¸åŒè®¾ç½®ä¸‹å¯¹å¤§è§„æ¨¡ç”Ÿæˆæ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒçš„ç¬¬äºŒé˜¶æ®µï¼š1ï¼‰æºåŸŸé¢„è®­ç»ƒï¼› 2ï¼‰é¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒï¼› 3) ä»»åŠ¡è‡ªé€‚åº”é¢„è®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼Œé¢„è®­ç»ƒçš„æœ‰æ•ˆæ€§ä¸é¢„è®­ç»ƒæ•°æ®ä¸ç›®æ ‡åŸŸä»»åŠ¡ä¹‹é—´çš„ç›¸ä¼¼æ€§ç›¸å…³ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ç»§ç»­é¢„è®­ç»ƒå¯èƒ½å¯¼è‡´é¢„è®­ç»ƒæ¨¡å‹çš„ç¾éš¾æ€§é—å¿˜ï¼Œè€Œå‡å°‘é—å¿˜çš„å­¦ä¹ æ–¹æ³•å¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ã€‚æ­¤å¤–ï¼Œç»“æœè¡¨æ˜ä½èµ„æºå’Œé«˜èµ„æºè®¾ç½®ä¹‹é—´ä»ç„¶å­˜åœ¨å·¨å¤§å·®è·ï¼Œè¿™çªå‡ºäº†æŠ½è±¡æ‘˜è¦ä»»åŠ¡éœ€è¦æ›´é«˜çº§çš„åŸŸé€‚åº”æ–¹æ³•ã€‚</td><td>Tiezheng Yu   Zihan Liu   Pascale Fung</td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.01726&#39;]">A New Approach to Overgenerating and Scoring Abstractive Summaries</a></td><td></td><td><a href="https://github.com/ucfnlp/varying-length-summ">https://github.com/ucfnlp/varying-length-summ</a></td><td><a href="https://arxiv.org/pdf/2104.01726">https://arxiv.org/pdf/2104.01726</a></td><td>We propose a new approach to generate multiple variants of the target summary with diverse content and varying lengths, then score and select admissible ones according to usersâ€™ needs. Abstractive summarizers trained on single reference summaries may struggle to produce outputs that achieve multiple desirable properties, i.e., capturing the most important information, being faithful to the original, grammatical and fluent. In this paper, we propose a two-staged strategy to generate a diverse set of candidate summaries from the source text in stage one, then score and select admissible ones in stage two. Importantly, our generator gives a precise control over the length of the summary, which is especially well-suited when space is limited. Our selectors are designed to predict the optimal summary length and put special emphasis on faithfulness to the original text. Both stages can be effectively trained, optimized and evaluated. Our experiments on benchmark summarization datasets suggest that this paradigm can achieve state-of-the-art performance.</td><td>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•æ¥ç”Ÿæˆå…·æœ‰ä¸åŒå†…å®¹å’Œä¸åŒé•¿åº¦çš„ç›®æ ‡æ‘˜è¦çš„å¤šä¸ªå˜ä½“ï¼Œç„¶åæ ¹æ®ç”¨æˆ·çš„éœ€æ±‚è¯„åˆ†å¹¶é€‰æ‹©å¯æ¥å—çš„å˜ä½“ã€‚åœ¨å•ä¸€å‚è€ƒæ‘˜è¦ä¸Šè®­ç»ƒçš„æŠ½è±¡æ‘˜è¦è€…å¯èƒ½éš¾ä»¥äº§ç”Ÿå®ç°å¤šç§ç†æƒ³å±æ€§çš„è¾“å‡ºï¼Œå³æ•è·æœ€é‡è¦çš„ä¿¡æ¯ã€å¿ å®äºåŸæ–‡ã€è¯­æ³•å’Œæµåˆ©ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„ç­–ç•¥ï¼Œåœ¨ç¬¬ä¸€é˜¶æ®µä»æºæ–‡æœ¬ç”Ÿæˆä¸€ç»„ä¸åŒçš„å€™é€‰æ‘˜è¦ï¼Œç„¶ååœ¨ç¬¬äºŒé˜¶æ®µè¯„åˆ†å¹¶é€‰æ‹©å¯æ¥å—çš„æ‘˜è¦ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ç”Ÿæˆå™¨å¯ä»¥ç²¾ç¡®æ§åˆ¶æ‘˜è¦çš„é•¿åº¦ï¼Œè¿™å°¤å…¶é€‚ç”¨äºç©ºé—´æœ‰é™çš„æƒ…å†µã€‚æˆ‘ä»¬çš„é€‰æ‹©å™¨æ—¨åœ¨é¢„æµ‹æœ€ä½³æ‘˜è¦é•¿åº¦ï¼Œå¹¶ç‰¹åˆ«å¼ºè°ƒå¯¹åŸæ–‡çš„å¿ å®åº¦ã€‚è¿™ä¸¤ä¸ªé˜¶æ®µéƒ½å¯ä»¥æœ‰æ•ˆåœ°è®­ç»ƒã€ä¼˜åŒ–å’Œè¯„ä¼°ã€‚æˆ‘ä»¬åœ¨åŸºå‡†æ‘˜è¦æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¿™ç§èŒƒå¼å¯ä»¥å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</td><td>Kaiqiang Song   Bingqing Wang   Zhe Feng   Fei Liu</td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.09061&#39;]">Improving Faithfulness in Abstractive Summarization with Contrast Candidate Generation and Selection</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.09061">https://arxiv.org/pdf/2104.09061</a></td><td>Despite significant progress in neural abstractive summarization, recent studies have shown that the current models are prone to generating summaries that are unfaithful to the original context. To address the issue, we study contrast candidate generation and selection as a model-agnostic post-processing technique to correct the extrinsic hallucinations (i.e. information not present in the source text) in unfaithful summaries. We learn a discriminative correction model by generating alternative candidate summaries where named entities and quantities in the generated summary are replaced with ones with compatible semantic types from the source document. This model is then used to select the best candidate as the final output summary. Our experiments and analysis across a number of neural summarization systems show that our proposed method is effective in identifying and correcting extrinsic hallucinations. We analyze the typical hallucination phenomenon by different types of neural summarization systems, in hope to provide insights for future work on the direction.</td><td>å°½ç®¡åœ¨ç¥ç»æŠ½è±¡æ‘˜è¦æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œå½“å‰çš„æ¨¡å‹å®¹æ˜“ç”Ÿæˆä¸åŸå§‹ä¸Šä¸‹æ–‡ä¸ç›¸ç¬¦çš„æ‘˜è¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¯¹æ¯”å€™é€‰ç”Ÿæˆå’Œé€‰æ‹©ä½œä¸ºä¸€ç§ä¸æ¨¡å‹æ— å…³çš„åå¤„ç†æŠ€æœ¯ï¼Œä»¥çº æ­£ä¸å¯é æ‘˜è¦ä¸­çš„å¤–åœ¨å¹»è§‰ï¼ˆå³æºæ–‡æœ¬ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯ï¼‰ã€‚æˆ‘ä»¬é€šè¿‡ç”Ÿæˆæ›¿ä»£å€™é€‰æ‘˜è¦æ¥å­¦ä¹ åˆ¤åˆ«æ ¡æ­£æ¨¡å‹ï¼Œå…¶ä¸­ç”Ÿæˆçš„æ‘˜è¦ä¸­çš„å‘½åå®ä½“å’Œæ•°é‡è¢«æ›¿æ¢ä¸ºæºæ–‡æ¡£ä¸­å…·æœ‰å…¼å®¹è¯­ä¹‰ç±»å‹çš„å®ä½“å’Œæ•°é‡ã€‚ç„¶åä½¿ç”¨è¯¥æ¨¡å‹é€‰æ‹©æœ€ä½³å€™é€‰è€…ä½œä¸ºæœ€ç»ˆè¾“å‡ºæ‘˜è¦ã€‚æˆ‘ä»¬å¯¹è®¸å¤šç¥ç»æ‘˜è¦ç³»ç»Ÿçš„å®éªŒå’Œåˆ†æè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨è¯†åˆ«å’Œçº æ­£å¤–åœ¨å¹»è§‰æ–¹é¢æ˜¯æœ‰æ•ˆçš„ã€‚æˆ‘ä»¬é€šè¿‡ä¸åŒç±»å‹çš„ç¥ç»æ‘˜è¦ç³»ç»Ÿåˆ†æäº†å…¸å‹çš„å¹»è§‰ç°è±¡ï¼Œå¸Œæœ›ä¸ºæœªæ¥çš„æ–¹å‘å·¥ä½œæä¾›è§è§£ã€‚</td><td>Sihao Chen   Fan Zhang   Kazoo Sone   Dan Roth</td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.01317&#39;]">Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/jiangycTarheel/TPT-Summ">https://github.com/jiangycTarheel/TPT-Summ</a></td><td><a href="https://arxiv.org/pdf/2106.01317">https://arxiv.org/pdf/2106.01317</a></td><td>Abstractive summarization, the task of generating a concise summary of input documents, requires: (1) reasoning over the source document to determine the salient pieces of information scattered across the long document, and (2) composing a cohesive text by reconstructing these salient facts into a shorter summary that faithfully reflects the complex relations connecting these facts. In this paper, we adapt TP-TRANSFORMER (Schlag et al., 2019), an architecture that enriches the original Transformer (Vaswani et al., 2017) with the explicitly compositional Tensor Product Representation (TPR), for the task of abstractive summarization. The key feature of our model is a structural bias that we introduce by encoding two separate representations for each token to represent the syntactic structure (with role vectors) and semantic content (with filler vectors) separately. The model then binds the role and filler vectors into the TPR as the layer output. We argue that the structured intermediate representations enable the model to take better control of the contents (salient facts) and structures (the syntax that connects the facts) when generating the summary. Empirically, we show that our TP-TRANSFORMER outperforms the Transformer and the original TP-TRANSFORMER significantly on several abstractive summarization datasets based on both automatic and human evaluations. On several syntactic and semantic probing tasks, we demonstrate the emergent structural information in the role vectors and improved syntactic interpretability in the TPR layer outputs. Code and models are available at <a href="https://github.com/jiangycTarheel/TPT-Summ">https://github.com/jiangycTarheel/TPT-Summ</a>.</td><td>æŠ½è±¡æ‘˜è¦ï¼Œå³ç”Ÿæˆè¾“å…¥æ–‡æ¡£çš„ç®€æ˜æ‘˜è¦çš„ä»»åŠ¡ï¼Œéœ€è¦ï¼š(1) å¯¹æºæ–‡æ¡£è¿›è¡Œæ¨ç†ä»¥ç¡®å®šæ•£å¸ƒåœ¨é•¿æ–‡æ¡£ä¸­çš„æ˜¾ç€ä¿¡æ¯ï¼Œä»¥åŠ (2) é€šè¿‡é‡æ„è¿™äº›æ˜¾ç€äº‹å®æ¥ç»„æˆä¸€ä¸ªæœ‰å‡èšåŠ›çš„æ–‡æœ¬æˆä¸€ä¸ªç®€çŸ­çš„æ€»ç»“ï¼Œå¿ å®åœ°åæ˜ äº†è¿æ¥è¿™äº›äº‹å®çš„å¤æ‚å…³ç³»ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº† TP-TRANSFORMER (Schlag et al., 2019)ï¼Œä¸€ç§ç”¨æ˜¾å¼ç»„åˆå¼ é‡ç§¯è¡¨ç¤º (TPR) ä¸°å¯ŒåŸå§‹ Transformer (Vaswani et al., 2017) çš„æ¶æ„ï¼Œç”¨äºæŠ½è±¡æ€»ç»“çš„ä»»åŠ¡.æˆ‘ä»¬æ¨¡å‹çš„å…³é”®ç‰¹å¾æ˜¯ç»“æ„åå·®ï¼Œæˆ‘ä»¬é€šè¿‡ä¸ºæ¯ä¸ªæ ‡è®°ç¼–ç ä¸¤ä¸ªå•ç‹¬çš„è¡¨ç¤ºæ¥åˆ†åˆ«è¡¨ç¤ºå¥æ³•ç»“æ„ï¼ˆä½¿ç”¨è§’è‰²å‘é‡ï¼‰å’Œè¯­ä¹‰å†…å®¹ï¼ˆä½¿ç”¨å¡«å……å‘é‡ï¼‰æ¥å¼•å…¥ç»“æ„åå·®ã€‚ç„¶åæ¨¡å‹å°†è§’è‰²å’Œå¡«å……å‘é‡ç»‘å®šåˆ° TPR ä½œä¸ºå±‚è¾“å‡ºã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œç»“æ„åŒ–çš„ä¸­é—´è¡¨ç¤ºä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨ç”Ÿæˆæ‘˜è¦æ—¶æ›´å¥½åœ°æ§åˆ¶å†…å®¹ï¼ˆæ˜¾ç€äº‹å®ï¼‰å’Œç»“æ„ï¼ˆè¿æ¥äº‹å®çš„è¯­æ³•ï¼‰ã€‚æ ¹æ®ç»éªŒï¼Œæˆ‘ä»¬è¡¨æ˜æˆ‘ä»¬çš„ TP-TRANSFORMER åœ¨åŸºäºè‡ªåŠ¨å’Œäººå·¥è¯„ä¼°çš„å‡ ä¸ªæŠ½è±¡æ‘˜è¦æ•°æ®é›†ä¸Šæ˜¾ç€ä¼˜äº Transformer å’ŒåŸå§‹ TP-TRANSFORMERã€‚åœ¨å‡ ä¸ªå¥æ³•å’Œè¯­ä¹‰æ¢æµ‹ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è§’è‰²å‘é‡ä¸­çš„ç´§æ€¥ç»“æ„ä¿¡æ¯å’Œ TPR å±‚è¾“å‡ºä¸­æ”¹è¿›çš„å¥æ³•å¯è§£é‡Šæ€§ã€‚ä»£ç å’Œæ¨¡å‹å¯åœ¨ <a href="https://github.com/jiangycTarheel/TPT-Summ">https://github.com/jiangycTarheel/TPT-Summ</a> è·å¾—ã€‚</td><td>Yichen Jiang   Asli Celikyilmaz   Paul Smolensky   Paul Soulos   Sudha Rao   Hamid Palangi   Roland Fernandez   Caitlin Smith   Mohit Bansal   Jianfeng Gao</td></tr><tr><td>8</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.02205&#39;]">Attention Head Masking for Inference Time Content Selection in Abstractive Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.02205">https://arxiv.org/pdf/2104.02205</a></td><td>How can we effectively inform content selection in Transformer-based abstractive summarization models? In this work, we present a simple-yet-effective attention head masking technique, which is applied on encoder-decoder attentions to pinpoint salient content at inference time. Using attention head masking, we are able to reveal the relation between encoder-decoder attentions and content selection behaviors of summarization models. We then demonstrate its effectiveness on three document summarization datasets based on both in-domain and cross-domain settings. Importantly, our models outperform prior state-of-the-art models on CNN/Daily Mail and New York Times datasets. Moreover, our inference-time masking technique is also data-efficient, requiring only 20% of the training samples to outperform BART fine-tuned on the full CNN/DailyMail dataset.</td><td>æˆ‘ä»¬å¦‚ä½•åœ¨åŸºäº Transformer çš„æŠ½è±¡æ‘˜è¦æ¨¡å‹ä¸­æœ‰æ•ˆåœ°å‘ŠçŸ¥å†…å®¹é€‰æ‹©ï¼Ÿåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ³¨æ„åŠ›å¤´æ©è”½æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯åº”ç”¨äºç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›ä»¥åœ¨æ¨ç†æ—¶ç²¾ç¡®å®šä½æ˜¾ç€å†…å®¹ã€‚ä½¿ç”¨æ³¨æ„åŠ›å¤´å±è”½ï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ­ç¤ºç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›ä¸æ‘˜è¦æ¨¡å‹çš„å†…å®¹é€‰æ‹©è¡Œä¸ºä¹‹é—´çš„å…³ç³»ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨åŸºäºåŸŸå†…å’Œè·¨åŸŸè®¾ç½®çš„ä¸‰ä¸ªæ–‡æ¡£æ‘˜è¦æ•°æ®é›†ä¸Šè¯æ˜äº†å®ƒçš„æœ‰æ•ˆæ€§ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ CNN/ã€Šæ¯æ—¥é‚®æŠ¥ã€‹å’Œã€Šçº½çº¦æ—¶æŠ¥ã€‹æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå…ˆå‰æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨ç†æ—¶é—´å±è”½æŠ€æœ¯ä¹Ÿæ˜¯æ•°æ®é«˜æ•ˆçš„ï¼Œåªéœ€è¦ 20% çš„è®­ç»ƒæ ·æœ¬å°±å¯ä»¥èƒœè¿‡åœ¨å®Œæ•´çš„ CNN/DailyMail æ•°æ®é›†ä¸Šå¾®è°ƒçš„ BARTã€‚</td><td>Shuyang Cao   Lu Wang</td></tr><tr><td>9</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.13346&#39;]">Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics</a></td><td></td><td><a href="https://github.com/artidoro/frank">https://github.com/artidoro/frank</a></td><td><a href="https://arxiv.org/pdf/2104.13346">https://arxiv.org/pdf/2104.13346</a></td><td>Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights into the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets. Through these annotations, we identify the proportion of different categories of factual errors in various summarization models and benchmark factuality metrics, showing their correlation with human judgment as well as their specific strengths and weaknesses.</td><td>ç°ä»£æ‘˜è¦æ¨¡å‹ç”Ÿæˆé«˜åº¦æµç•…ä½†é€šå¸¸å®é™…ä¸Šä¸å¯é çš„è¾“å‡ºã€‚è¿™å¼•å‘äº†å¤§é‡è¯•å›¾è¡¡é‡è‡ªåŠ¨ç”Ÿæˆçš„æ‘˜è¦çš„çœŸå®æ€§çš„æŒ‡æ ‡ã€‚ç”±äºç¼ºä¹å…±åŒçš„åŸºå‡†ï¼Œè¿™äº›æŒ‡æ ‡æ— æ³•è¿›è¡Œæ¯”è¾ƒã€‚æ­¤å¤–ï¼Œæ‰€æœ‰è¿™äº›æ–¹æ³•éƒ½å°†äº‹å®æ€§è§†ä¸ºä¸€ä¸ªäºŒå…ƒæ¦‚å¿µï¼Œæ— æ³•æ›´æ·±å…¥åœ°äº†è§£ä¸åŒç³»ç»Ÿé€ æˆçš„å„ç§ä¸ä¸€è‡´ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§äº‹å®é”™è¯¯çš„ç±»å‹å­¦ï¼Œå¹¶ä½¿ç”¨å®ƒä» CNN/DM å’Œ XSum æ•°æ®é›†çš„æœ€å…ˆè¿›çš„æ‘˜è¦ç³»ç»Ÿä¸­æ”¶é›†ç”Ÿæˆçš„æ‘˜è¦çš„äººå·¥æ³¨é‡Šã€‚é€šè¿‡è¿™äº›æ³¨é‡Šï¼Œæˆ‘ä»¬ç¡®å®šäº†å„ç§æ‘˜è¦æ¨¡å‹å’ŒåŸºå‡†äº‹å®æ€§æŒ‡æ ‡ä¸­ä¸åŒç±»åˆ«çš„äº‹å®é”™è¯¯çš„æ¯”ä¾‹ï¼Œæ˜¾ç¤ºäº†å®ƒä»¬ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§ä»¥åŠå®ƒä»¬çš„å…·ä½“ä¼˜åŠ¿å’ŒåŠ£åŠ¿ã€‚</td><td>Artidoro Pagnoni   Vidhisha Balachandran   Yulia Tsvetkov</td></tr></tbody></table></div><h3 id="COLING-3"><a href="#COLING-3" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>åºå·</th><th>ä¼šè®®/æœŸåˆŠ</th><th>è®ºæ–‡</th><th>ä¸»è¦æŠ€æœ¯</th><th>ä»£ç </th><th>è®ºæ–‡ä¸‹è½½åœ°å€</th><th>æ‘˜è¦</th><th>æ‘˜è¦ç¿»è¯‘</th><th>ä½œè€…</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00692&#39;]">How Domain Terminology Affects Meeting Summarization Performance</a></td><td></td><td><a href="https://github.com/ucfnlp/meeting-domain-terminology">https://github.com/ucfnlp/meeting-domain-terminology</a></td><td><a href="https://arxiv.org/pdf/2011.00692">https://arxiv.org/pdf/2011.00692</a></td><td>Meetings are essential to modern organizations. Numerous meetings are held and recorded daily, more than can ever be comprehended. A meeting summarization system that identifies salient utterances from the transcripts to automatically generate meeting minutes can help. It empowers users to rapidly search and sift through large meeting collections. To date, the impact of domain terminology on the performance of meeting summarization remains understudied, despite that meetings are rich with domain knowledge. In this paper, we create gold-standard annotations for domain terminology on a sizable meeting corpus; they are known as jargon terms. We then analyze the performance of a meeting summarization system with and without jargon terms. Our findings reveal that domain terminology can have a substantial impact on summarization performance. We publicly release all domain terminology to advance research in meeting summarization.</td><td></td><td>Jia Jin Koay   Alexander Roustai   Xiaojin Dai   Dillon Burns   Alec Kerrigan   Fei Liu</td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.09739&#39;]">Fact-level Extractive Summarization with Hierarchical Graph Mask on BERT</a></td><td></td><td><a href="https://github.com/Ruifeng-paper/FactExsum-coling2020">https://github.com/Ruifeng-paper/FactExsum-coling2020</a></td><td><a href="https://arxiv.org/pdf/2011.09739">https://arxiv.org/pdf/2011.09739</a></td><td>Most current extractive summarization models generate summaries by selecting salient sentences. However, one of the problems with sentence-level extractive summarization is that there exists a gap between the human-written gold summary and the oracle sentence labels. In this paper, we propose to extract fact-level semantic units for better extractive summarization. We also introduce a hierarchical structure, which incorporates the multi-level of granularities of the textual information into the model. In addition, we incorporate our model with BERT using a hierarchical graph mask. This allows us to combine BERTâ€™s ability in natural language understanding and the structural information without increasing the scale of the model. Experiments on the CNN/DaliyMail dataset show that our model achieves state-of-the-art results.</td><td>å¤§å¤šæ•°å½“å‰çš„æå–æ‘˜è¦æ¨¡å‹é€šè¿‡é€‰æ‹©æ˜¾ç€å¥å­æ¥ç”Ÿæˆæ‘˜è¦ã€‚ç„¶è€Œï¼Œå¥å­çº§æå–æ‘˜è¦çš„é—®é¢˜ä¹‹ä¸€æ˜¯äººå·¥ç¼–å†™çš„é»„é‡‘æ‘˜è¦ä¸oracleå¥å­æ ‡ç­¾ä¹‹é—´å­˜åœ¨å·®è·ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å»ºè®®æå–äº‹å®çº§åˆ«çš„è¯­ä¹‰å•å…ƒä»¥æ›´å¥½åœ°æå–æ‘˜è¦ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§å±‚æ¬¡ç»“æ„ï¼Œå®ƒå°†æ–‡æœ¬ä¿¡æ¯çš„å¤šçº§ç²’åº¦åˆå¹¶åˆ°æ¨¡å‹ä¸­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨åˆ†å±‚å›¾æ©ç å°†æˆ‘ä»¬çš„æ¨¡å‹ä¸ BERT ç»“åˆèµ·æ¥ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨ä¸å¢åŠ æ¨¡å‹è§„æ¨¡çš„æƒ…å†µä¸‹ï¼Œå°† BERT åœ¨è‡ªç„¶è¯­è¨€ç†è§£æ–¹é¢çš„èƒ½åŠ›ä¸ç»“æ„ä¿¡æ¯ç»“åˆèµ·æ¥ã€‚åœ¨ CNN/DaliyMail æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</td><td>Ruifeng Yuan   Zili Wang   Wenjie Li</td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.01421&#39;]">WSL-DS: Weakly Supervised Learning with Distant Supervision for Query Focused Multi-Document Abstractive Summarization</a></td><td></td><td><a href="https://github.com/tahmedge/WSL-DS-COLING-2020">https://github.com/tahmedge/WSL-DS-COLING-2020</a></td><td><a href="https://arxiv.org/pdf/2011.01421">https://arxiv.org/pdf/2011.01421</a></td><td>In the Query Focused Multi-Document Summarization (QF-MDS) task, a set of documents and a query are given where the goal is to generate a summary from these documents based on the given query. However, one major challenge for this task is the lack of availability of labeled training datasets. To overcome this issue, in this paper, we propose a novel weakly supervised learning approach via utilizing distant supervision. In particular, we use datasets similar to the target dataset as the training data where we leverage pre-trained sentence similarity models to generate the weak reference summary of each individual document in a document set from the multi-document gold reference summaries. Then, we iteratively train our summarization model on each single-document to alleviate the computational complexity issue that occurs while training neural summarization models in multiple documents (i.e., long sequences) at once. Experimental results in Document Understanding Conferences (DUC) datasets show that our proposed approach sets a new state-of-the-art result in terms of various evaluation metrics.</td><td>åœ¨ Query Focused Multi-Document Summarization (QF-MDS) ä»»åŠ¡ä¸­ï¼Œç»™å‡ºäº†ä¸€ç»„æ–‡æ¡£å’Œä¸€ä¸ªæŸ¥è¯¢ï¼Œå…¶ç›®æ ‡æ˜¯æ ¹æ®ç»™å®šçš„æŸ¥è¯¢ä»è¿™äº›æ–‡æ¡£ä¸­ç”Ÿæˆæ‘˜è¦ã€‚ç„¶è€Œï¼Œè¿™é¡¹ä»»åŠ¡çš„ä¸€ä¸ªä¸»è¦æŒ‘æˆ˜æ˜¯ç¼ºä¹æ ‡è®°çš„è®­ç»ƒæ•°æ®é›†ã€‚ä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨è¿œç¨‹ç›‘ç£çš„æ–°å‹å¼±ç›‘ç£å­¦ä¹ æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸ç›®æ ‡æ•°æ®é›†ç›¸ä¼¼çš„æ•°æ®é›†ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬åˆ©ç”¨é¢„è®­ç»ƒçš„å¥å­ç›¸ä¼¼æ€§æ¨¡å‹ä»å¤šæ–‡æ¡£é»„é‡‘å‚è€ƒæ‘˜è¦ä¸­ç”Ÿæˆæ–‡æ¡£é›†ä¸­æ¯ä¸ªå•ç‹¬æ–‡æ¡£çš„å¼±å‚è€ƒæ‘˜è¦ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨æ¯ä¸ªå•æ–‡æ¡£ä¸Šè¿­ä»£è®­ç»ƒæˆ‘ä»¬çš„æ‘˜è¦æ¨¡å‹ï¼Œä»¥å‡è½»åœ¨ä¸€æ¬¡åœ¨å¤šä¸ªæ–‡æ¡£ï¼ˆå³é•¿åºåˆ—ï¼‰ä¸­è®­ç»ƒç¥ç»æ‘˜è¦æ¨¡å‹æ—¶å‡ºç°çš„è®¡ç®—å¤æ‚æ€§é—®é¢˜ã€‚æ–‡æ¡£ç†è§£ä¼šè®® (DUC) æ•°æ®é›†ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨å„ç§è¯„ä¼°æŒ‡æ ‡æ–¹é¢å–å¾—äº†æ–°çš„æœ€æ–°æˆæœã€‚</td><td>Md Tahmid Rahman Laskar   Enamul Hoque   Jimmy Xiangji Huang</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> arxiv </tag>
            
            <tag> ACL </tag>
            
            <tag> NAACL </tag>
            
            <tag> EMNLP </tag>
            
            <tag> COLING </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdownä¸å¸¸ç”¨æ•°å­¦ç¬¦å·è¯­æ³•</title>
      <link href="/2021/08/10/Markdown%E4%B8%8D%E5%B8%B8%E7%94%A8%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7%E8%AF%AD%E6%B3%95/"/>
      <url>/2021/08/10/Markdown%E4%B8%8D%E5%B8%B8%E7%94%A8%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7%E8%AF%AD%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="Markdownä¸å¸¸ç”¨æ•°å­¦ç¬¦å·è¯­æ³•"><a href="#Markdownä¸å¸¸ç”¨æ•°å­¦ç¬¦å·è¯­æ³•" class="headerlink" title="Markdownä¸å¸¸ç”¨æ•°å­¦ç¬¦å·è¯­æ³•"></a>Markdownä¸å¸¸ç”¨æ•°å­¦ç¬¦å·è¯­æ³•</h1><blockquote><p>å‚è€ƒèµ„æ–™ï¼š</p><ul><li><p><a href="https://blog.csdn.net/LB_yifeng/article/details/83302697">https://blog.csdn.net/LB_yifeng/article/details/83302697</a></p></li><li><p><a href="https://blog.csdn.net/qq_18150255/article/details/88040858?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-0.pc_relevant_baidujshouduan&amp;spm=1001.2101.3001.4242">https://blog.csdn.net/qq_18150255/article/details/88040858?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-0.pc_relevant_baidujshouduan&amp;spm=1001.2101.3001.4242</a></p></li></ul></blockquote><h2 id="è¿ç®—ç¬¦"><a href="#è¿ç®—ç¬¦" class="headerlink" title="è¿ç®—ç¬¦"></a>è¿ç®—ç¬¦</h2><div class="table-container"><table><thead><tr><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th></tr></thead><tbody><tr><td style="text-align:center">Â±</td><td style="text-align:center">\pm</td><td style="text-align:center">â‹…</td><td style="text-align:center">\cdot</td><td style="text-align:center">â‰ˆ</td><td style="text-align:center">\approx</td></tr><tr><td style="text-align:center">âˆ“</td><td style="text-align:center">\mp</td><td style="text-align:center">â‰ </td><td style="text-align:center">\nep</td><td style="text-align:center">$\ldots$</td><td style="text-align:center">\ldots</td></tr><tr><td style="text-align:center">$\bigotimes$</td><td style="text-align:center">\bigotimes</td><td style="text-align:center">$\bigoplus$</td><td style="text-align:center">\bigoplusâ€‹</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$\prod$</td><td style="text-align:center">\prod</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table></div><h2 id="å¸Œè…Šå­—æ¯"><a href="#å¸Œè…Šå­—æ¯" class="headerlink" title="å¸Œè…Šå­—æ¯"></a>å¸Œè…Šå­—æ¯</h2><div class="table-container"><table><thead><tr><th style="text-align:center">ç¬¦å·</th><th>è¯­æ³•</th><th>ç¬¦å·</th><th>è¯­æ³•</th><th>ç¬¦å·</th><th>è¯­æ³•</th></tr></thead><tbody><tr><td style="text-align:center">Î±</td><td>\alphaÎ±</td><td>Î²</td><td>\beta</td><td>Î³</td><td>\gammaÎ³</td></tr><tr><td style="text-align:center">Ï</td><td>\rhoÏ</td><td>Î»</td><td>\lambda</td><td>Î¼</td><td>\mu</td></tr><tr><td style="text-align:center">Î¾</td><td>\xi</td><td>Ï‰</td><td>\omega</td><td>Ïµ</td><td>\epsilon</td></tr><tr><td style="text-align:center">Ï†</td><td>\varphi</td><td>Î´</td><td>\delta</td><td></td></tr></tbody></table></div><h2 id="å‘é‡"><a href="#å‘é‡" class="headerlink" title="å‘é‡"></a>å‘é‡</h2><div class="table-container"><table><thead><tr><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th></tr></thead><tbody><tr><td style="text-align:center">$\hat{a}$</td><td style="text-align:center">\hat{a}</td><td style="text-align:center">$\vec{a}$</td><td style="text-align:center">\vec{a}</td><td style="text-align:center">$\overrightarrow{AB}$</td><td style="text-align:center">\overrightarrow{AB}</td></tr></tbody></table></div><h2 id="ç®­å¤´ç¬¦å·"><a href="#ç®­å¤´ç¬¦å·" class="headerlink" title="ç®­å¤´ç¬¦å·"></a>ç®­å¤´ç¬¦å·</h2><div class="table-container"><table><thead><tr><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th></tr></thead><tbody><tr><td style="text-align:center">$\rightarrow$</td><td style="text-align:center">\rightarrow</td><td style="text-align:center">$\Leftarrow$</td><td style="text-align:center">\Leftarrow</td><td style="text-align:center">$\Longrightarrow$</td><td style="text-align:center">\Longrightarrow</td></tr></tbody></table></div><h2 id="ç§¯åˆ†"><a href="#ç§¯åˆ†" class="headerlink" title="ç§¯åˆ†"></a>ç§¯åˆ†</h2><div class="table-container"><table><thead><tr><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th></tr></thead><tbody><tr><td style="text-align:center">$\partial$</td><td style="text-align:center">\partial</td><td style="text-align:center">$\iint$</td><td style="text-align:center">\iint</td><td style="text-align:center">$\int$</td><td style="text-align:center">\int</td></tr></tbody></table></div><h2 id="å…¬å¼"><a href="#å…¬å¼" class="headerlink" title="å…¬å¼"></a>å…¬å¼</h2><div class="table-container"><table><thead><tr><th style="text-align:center">ç¬¦å·</th><th style="text-align:center">è¯­æ³•</th></tr></thead><tbody><tr><td style="text-align:center">$\sum_{k=1}^{n}f(k)$</td><td style="text-align:center">\sum_{k=1}^{n}f(k)</td></tr><tr><td style="text-align:center">$\prod_{k=1}^{n}f(k)$</td><td style="text-align:center">\prod_{k=1}^{n}f(k)</td></tr><tr><td style="text-align:center">$\lim_{n\to\infty}k^{-1}=0$</td><td style="text-align:center">\lim_{n\to\infty}k^{-1}=0</td></tr><tr><td style="text-align:center">$\int_{a}^{b}f(x)dx$</td><td style="text-align:center">\int_{a}^{b}f(x)dx</td></tr><tr><td style="text-align:center">${n\choose m}$</td><td style="text-align:center">{n\choose m}</td></tr><tr><td style="text-align:center">$f(x) = \left{ \begin{array}{lr} x^2 &amp; : x &lt; 0\  x^3 &amp; : x \ge 0  \end{array}\right.$</td><td style="text-align:center">f(x) =   \begin{array}{lr}    x^2 &amp; : x &lt; 0\    x^3 &amp; : x \ge 0  \end{array}</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> Latex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>arxivè®ºæ–‡æ•´ç†å·¥å…·</title>
      <link href="/2021/08/10/arxiv%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86%E5%B7%A5%E5%85%B7/"/>
      <url>/2021/08/10/arxiv%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<h1 id="arxivè®ºæ–‡æ•´ç†å·¥å…·"><a href="#arxivè®ºæ–‡æ•´ç†å·¥å…·" class="headerlink" title="arxivè®ºæ–‡æ•´ç†å·¥å…·"></a>arxivè®ºæ–‡æ•´ç†å·¥å…·</h1><p>å¯ä»¥è‡ªåŠ¨ä»arxivè·å–å„å¤§é¡¶ä¼šè®ºæ–‡ </p><ul><li>è‡ªåŠ¨ä¸‹è½½è®ºæ–‡ </li><li>æ‘˜è¦æå– </li><li>æ‘˜è¦ç¿»è¯‘ </li><li>ä»£ç è·å–</li><li>æ•´ç†å¯¼å‡ºpdf</li></ul><h2 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h2><blockquote><p>å¿…é¡»ä¿®æ”¹å˜é‡ file_name = â€˜papers.txtâ€™</p><p>papers.txtä¸ºéœ€è¦æ•´ç†çš„è®ºæ–‡å</p></blockquote><ul><li><p>papers.txtæ ‡å‡†æ ¼å¼</p><blockquote><p>ç¬¬ä¸€åˆ—ä¸ºè®ºæ–‡åˆ†ç±» ç¬¬äºŒåˆ—ä¸ºè®ºæ–‡å å…¶ä½™å¯ç©º</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">| --------- | ------------------------------------------------------------ | -------- | ---- | -------- |</span><br><span class="line">|           |                                                              |          |      |          |</span><br><span class="line">|           |                                                              |          |      |          |</span><br><span class="line">| ACL2020   | Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation |          |      |          |</span><br><span class="line">| ACL2020   | Simultaneous Translation Policies: From Fixed to Adaptive    |          |      |          |</span><br><span class="line">| ACL2020   | Multiscale Collaborative Deep Models for Neural Machine Translation |          |      |          |</span><br><span class="line">| ACL2020   | Character-Level Translation with Self-attention              |          |      |          |</span><br><span class="line">| ACL2020   | Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation |          |      |          |</span><br><span class="line">| ACL2020   | ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation |          |      |          |</span><br><span class="line">| ACL2020   | Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation |          |      |          |</span><br><span class="line">| ACL2020   | Variational Neural Machine Translation with Normalizing Flows |          |      |          |</span><br></pre></td></tr></table></figure><ul><li>å…·ä½“å®ç°</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br></pre></td><td class="code"><pre><span class="line">import html</span><br><span class="line">import json</span><br><span class="line">import os</span><br><span class="line">import random</span><br><span class="line">import re</span><br><span class="line">import time</span><br><span class="line">import urllib.request</span><br><span class="line">from urllib import parse</span><br><span class="line"></span><br><span class="line">import chardet</span><br><span class="line">import requests</span><br><span class="line">from lxml import etree</span><br><span class="line">from tqdm import tqdm</span><br><span class="line"></span><br><span class="line"># title = &#x27;Diversifying Dialogue Generation with Non-Conversational Text&#x27;</span><br><span class="line">file_name = &#x27;source_paper/COLING_æ‘˜è¦.txt&#x27;</span><br><span class="line">output_file_name = &#x27;COLING_æ‘˜è¦&#x27;</span><br><span class="line">download_path = &#x27;downloads/&#x27;</span><br><span class="line">GOOGLE_TRANSLATE_URL = &#x27;http://translate.google.cn/m?q=%s&amp;tl=%s&amp;sl=%s&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># è¯»å–è®ºæ–‡ç›®å½•æ–‡ä»¶</span><br><span class="line">def get_paper_name(file_name_fun):</span><br><span class="line">    paper_name_fun = []</span><br><span class="line">    # è®ºæ–‡ ä¼šè®®/æœŸåˆŠ</span><br><span class="line">    paper_class_fun = []</span><br><span class="line">    with open(file_name_fun, &#x27;r&#x27;) as f:</span><br><span class="line">        file_info = f.readlines()</span><br><span class="line">    for i in file_info:</span><br><span class="line">        temp_read = str(i.split(&#x27;|&#x27;)[2]).replace(&#x27; &#x27;, &#x27;&#x27;)</span><br><span class="line">        # print(temp_read)</span><br><span class="line">        if not (temp_read.__contains__(&#x27;---&#x27;) or temp_read.__eq__(&#x27;&#x27;)):</span><br><span class="line">            paper_name_fun.append(i.split(&#x27;|&#x27;)[2].strip())</span><br><span class="line">            paper_class_fun.append(i.split(&#x27;|&#x27;)[1].strip())</span><br><span class="line">    print(&#x27;è¯»å–åˆ° &#x27; + str(len(paper_name_fun)) + &#x27; ç¯‡è®ºæ–‡&#x27;)</span><br><span class="line">    return paper_name_fun, paper_class_fun</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># æ ¹æ®è®ºæ–‡åä»arxivè·å–è®ºæ–‡ä¸‹è½½é“¾æ¥</span><br><span class="line"># è·å–ä½œè€…ä¿¡æ¯</span><br><span class="line"># è·å–æ‘˜è¦</span><br><span class="line"># ç¿»è¯‘æ‘˜è¦</span><br><span class="line">def get_paper_urls_authors_abstract(title_fun):</span><br><span class="line">    url = &#x27;https://arxiv.org/search/?query=&#x27; + title_fun.replace(&#x27; &#x27;,</span><br><span class="line">                                                                 &#x27;+&#x27;) + &#x27;&amp;searchtype=title&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&#x27;</span><br><span class="line">    try:</span><br><span class="line">        # time.sleep(1)</span><br><span class="line">        html_fun = urllib.request.urlopen(url).read().decode(&#x27;utf-8&#x27;)</span><br><span class="line">        # time.sleep(1)</span><br><span class="line"></span><br><span class="line">        dom = etree.HTML(html_fun, etree.HTMLParser(encoding=&#x27;utf-8&#x27;))</span><br><span class="line">        # title = dom.xpath(&#x27;//*[@id=&quot;main-container&quot;]/div[2]/ol/li/p[1]/span/text()&#x27;)  # è®ºæ–‡å</span><br><span class="line">        paper_url_fun = dom.xpath(&#x27;//*[@id=&quot;main-container&quot;]/div[2]/ol/li/div/p/a/@href&#x27;)</span><br><span class="line">        # åˆ¤æ–­è®ºæ–‡æ˜¯å¦å¯æ£€ç´¢</span><br><span class="line">        if len(paper_url_fun) != 0:</span><br><span class="line">            download_url_fun = dom.xpath(&#x27;//*[@id=&quot;main-container&quot;]/div[2]/ol/li/div/p/span/a[1]/@href&#x27;)</span><br><span class="line">            author_fun_temp = dom.xpath(&#x27;//*[@id=&quot;main-container&quot;]/div[2]/ol/li/p[2]/a/text()&#x27;)</span><br><span class="line">            author_fun = &#x27;&#x27;</span><br><span class="line">            for i in author_fun_temp:</span><br><span class="line">                author_fun = author_fun + &quot;   &quot; + i</span><br><span class="line">            author_fun = author_fun.strip()</span><br><span class="line">            abstract_fun_temp = dom.xpath(&#x27;//*[@id=&quot;main-container&quot;]/div[2]/ol/li/p[3]/span[3]/text()&#x27;)</span><br><span class="line">            abstract_fun = str(abstract_fun_temp[0]).strip()</span><br><span class="line">            abstract_translate_fun = translate(abstract_fun, &quot;en&quot;, &quot;zh-CN&quot;)</span><br><span class="line">            return title_fun, paper_url_fun, download_url_fun, author_fun, abstract_fun, abstract_translate_fun</span><br><span class="line">        else:</span><br><span class="line">            print(&#x27;\nè®ºæ–‡ä¸å¯æ£€ç´¢ï¼ï¼ï¼&#x27;)</span><br><span class="line">            return &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;</span><br><span class="line">    except:</span><br><span class="line">        return &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ä¸‹è½½è®ºæ–‡</span><br><span class="line">def download_paper(download_path_fun, download_url_fun, title_fun):</span><br><span class="line">    temp_download_url = tqdm(download_url_fun)</span><br><span class="line">    # if not os.path.exists(download_path_fun + file_name.split(&#x27;.&#x27;)[0]):</span><br><span class="line">    #     os.makedirs(download_path_fun + file_name.split(&#x27;.&#x27;)[0])</span><br><span class="line">    # download_path_fun = download_path_fun + file_name.split(&#x27;.&#x27;)[0] + &#x27;/&#x27;</span><br><span class="line">    for url in temp_download_url:</span><br><span class="line">        if not str(url).__eq__(&#x27;&#x27;):</span><br><span class="line">            temp_download_url.set_description(&quot;\næ­£åœ¨ä¸‹è½½ï¼š %s&quot; % url[0])</span><br><span class="line">            r = requests.get(url[0])</span><br><span class="line">            while r.status_code == 403:</span><br><span class="line">                time.sleep(500 + random.uniform(0, 500))</span><br><span class="line">                r = requests.get(url[0])</span><br><span class="line">            with open(download_path_fun + str(title_fun[download_url_fun.index(url)]) + &#x27;.pdf&#x27;, &quot;wb&quot;) as f:</span><br><span class="line">                f.write(r.content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># è·å–å®˜æ–¹githubä»£ç </span><br><span class="line">def get_github_code(paper_url_fun):</span><br><span class="line">    temp_paper_url_fun = tqdm(paper_url_fun)</span><br><span class="line">    for url in temp_paper_url_fun:</span><br><span class="line">        if not str(url).__eq__(&#x27;&#x27;):</span><br><span class="line">            temp_paper_url_fun.set_description(&quot;\næ­£åœ¨è·å–ä»£ç ï¼š %s&quot; % url[0])</span><br><span class="line">            url = &#x27;https://arxiv.paperswithcode.com/api/v0/repos-and-datasets/&#x27; + url[0].split(&#x27;/&#x27;)[-1]</span><br><span class="line">            rq = requests.get(url)</span><br><span class="line">            rq.encoding = chardet.detect(rq.content)[&#x27;encoding&#x27;]</span><br><span class="line">            try:</span><br><span class="line">                code = json.loads(rq.text)[&#x27;code&#x27;][&#x27;official&#x27;][&#x27;url&#x27;]</span><br><span class="line">            except:</span><br><span class="line">                code = &#x27;&#x27;</span><br><span class="line">            github_code.append(code)</span><br><span class="line">        else:</span><br><span class="line">            github_code.append(&#x27;&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ç¿»è¯‘æ‘˜è¦</span><br><span class="line">def translate(text, text_language=&quot;auto&quot;, to_language=&quot;auto&quot;):</span><br><span class="line">    text = parse.quote(text)</span><br><span class="line">    url = GOOGLE_TRANSLATE_URL % (text, to_language, text_language)</span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    data = response.text</span><br><span class="line">    expr = r&#x27;(?s)class=&quot;(?:t0|result-container)&quot;&gt;(.*?)&lt;&#x27;</span><br><span class="line">    result = re.findall(expr, data)</span><br><span class="line">    if len(result) == 0:</span><br><span class="line">        return &quot;&quot;</span><br><span class="line"></span><br><span class="line">    return html.unescape(result[0])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># å¯¼å‡ºmdæ–‡ä»¶</span><br><span class="line">def save_md(out_file_fun, title_fun, paper_class_fun, paper_url_fun, download_url_fun, github_code_fun):</span><br><span class="line">    exclude_paper = 0</span><br><span class="line">    with open(out_file_fun, &#x27;w+&#x27;) as f:</span><br><span class="line">        f.writelines(&#x27;| åºå· | ä¼šè®®/æœŸåˆŠ | è®ºæ–‡ | ä¸»è¦æŠ€æœ¯ | ä»£ç  | è®ºæ–‡ä¸‹è½½åœ°å€ | æ‘˜è¦ | æ‘˜è¦ç¿»è¯‘ | ä½œè€… |\n&#x27;)</span><br><span class="line">        f.writelines(&#x27;| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n&#x27;)</span><br><span class="line">        for i in range(len(title_fun)):</span><br><span class="line">            if not str(title_fun[i]).__eq__(&#x27;&#x27;):</span><br><span class="line">                if str(download_url_fun[i]).__eq__(&#x27;&#x27;):</span><br><span class="line">                    download_url_fun[i] = [&#x27;&#x27;]</span><br><span class="line">                md_str = &#x27;| &#x27; + str(i + 1 - exclude_paper) + &#x27; | &#x27; + str(paper_class_fun[i]) + &#x27; | [&#x27; + str(</span><br><span class="line">                    title_fun[i]) + &#x27;](&#x27; + str(</span><br><span class="line">                    paper_url_fun[i]) + &#x27;) |      | &#x27; + str(</span><br><span class="line">                    github_code_fun[i]) + &#x27; | &#x27; + str(download_url_fun[i][0]) + &#x27; | &#x27; + str(abstract[i]) + &#x27; | &#x27; + str(</span><br><span class="line">                    abstract_translate[i]) + &#x27; | &#x27; + str(author[i]) + &#x27; |\n&#x27;</span><br><span class="line">                f.writelines(md_str)</span><br><span class="line">            else:</span><br><span class="line">                exclude_paper += 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_md_simple(out_file_fun, title_fun, paper_class_fun, paper_url_fun, download_url_fun, github_code_fun):</span><br><span class="line">    exclude_paper = 0</span><br><span class="line">    with open(out_file_fun, &#x27;w+&#x27;) as f:</span><br><span class="line">        f.writelines(&#x27;| åºå· | ä¼šè®®/æœŸåˆŠ | è®ºæ–‡ | ä¸»è¦æŠ€æœ¯ | ä»£ç  | è®ºæ–‡ä¸‹è½½åœ°å€ |\n&#x27;)</span><br><span class="line">        f.writelines(&#x27;| --- | --- | --- | --- | --- | --- |\n&#x27;)</span><br><span class="line">        for i in range(len(title_fun)):</span><br><span class="line">            if not str(title_fun[i]).__eq__(&#x27;&#x27;):</span><br><span class="line">                if str(download_url_fun[i]).__eq__(&#x27;&#x27;):</span><br><span class="line">                    download_url_fun[i] = [&#x27;&#x27;]</span><br><span class="line">                md_str = &#x27;| &#x27; + str(i + 1 - exclude_paper) + &#x27; | &#x27; + str(paper_class_fun[i]) + &#x27; | [&#x27; + str(</span><br><span class="line">                    title_fun[i]) + &#x27;](&#x27; + str(</span><br><span class="line">                    paper_url_fun[i]) + &#x27;) |      | &#x27; + str(</span><br><span class="line">                    github_code_fun[i]) + &#x27; | &#x27; + str(download_url_fun[i][0]) + &#x27; |\n&#x27;</span><br><span class="line">                f.writelines(md_str)</span><br><span class="line">            else:</span><br><span class="line">                exclude_paper += 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    # main</span><br><span class="line">    out_file_dir = &#x27;data/&#x27; + output_file_name + &#x27;/&#x27;</span><br><span class="line">    out_file = out_file_dir + output_file_name + &#x27;.md&#x27;</span><br><span class="line">    out_file_simple = out_file_dir + output_file_name + &#x27;_simple.md&#x27;</span><br><span class="line">    download_path = download_path + output_file_name + &#x27;/&#x27;</span><br><span class="line">    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹</span><br><span class="line">    if not os.path.exists(out_file_dir):</span><br><span class="line">        os.makedirs(out_file_dir)</span><br><span class="line">    if not os.path.exists(download_path):</span><br><span class="line">        os.makedirs(download_path)</span><br><span class="line">    title = []</span><br><span class="line">    paper_url = []</span><br><span class="line">    download_url = []</span><br><span class="line">    github_code = []</span><br><span class="line">    author = []</span><br><span class="line">    abstract = []</span><br><span class="line">    abstract_translate = []</span><br><span class="line">    print(&#x27;\nè¯»å–è®ºæ–‡ç›®å½•æ–‡ä»¶&#x27;)</span><br><span class="line"></span><br><span class="line">    temp_file_name, paper_class = get_paper_name(file_name)</span><br><span class="line">    temp_file_name = tqdm(temp_file_name)</span><br><span class="line">    print(&#x27;\næ ¹æ®è®ºæ–‡åä»arxivè·å–è®ºæ–‡é“¾æ¥ ä½œè€…ä¿¡æ¯ æ‘˜è¦ æ‘˜è¦ç¿»è¯‘&#x27;)</span><br><span class="line">    for title_name in temp_file_name:</span><br><span class="line">        temp_file_name.set_description(&quot;\næ­£åœ¨è·å–ï¼š %s&quot; % title_name)</span><br><span class="line">        time.sleep(1)</span><br><span class="line">        paper_urls = get_paper_urls_authors_abstract(title_name)</span><br><span class="line">        title.append(paper_urls[0])</span><br><span class="line">        paper_url.append(paper_urls[1])</span><br><span class="line">        download_url.append(paper_urls[2])</span><br><span class="line">        author.append(paper_urls[3])</span><br><span class="line">        abstract.append(paper_urls[4])</span><br><span class="line">        abstract_translate.append(paper_urls[5])</span><br><span class="line">    # ä¸‹è½½è®ºæ–‡</span><br><span class="line">    print(&#x27;\nä¸‹è½½è®ºæ–‡&#x27;)</span><br><span class="line">    download_paper(download_path, download_url, title)</span><br><span class="line">    print(&#x27;\nè·å–githubä»£ç &#x27;)</span><br><span class="line">    get_github_code(paper_url)</span><br><span class="line">    # ä¿å­˜md</span><br><span class="line">    print(&#x27;\nå¯¼å‡ºmdæ–‡ä»¶&#x27;)</span><br><span class="line">    # æ›´æ–°æ–‡ä»¶ä¿å­˜åœ°å€</span><br><span class="line"></span><br><span class="line">    save_md(out_file, title, paper_class, paper_url, download_url, github_code)</span><br><span class="line">    print(out_file)</span><br><span class="line">    # ä¸ä¿å­˜ æ‘˜è¦ æ‘˜è¦ç¿»è¯‘ ä½œè€…ä¿¡æ¯</span><br><span class="line">    save_md_simple(out_file_simple, title, paper_class, paper_url, download_url, github_code)</span><br><span class="line">    print(out_file_simple)</span><br><span class="line"></span><br><span class="line">    print(&#x27;\nè¿›ç¨‹ç»“æŸ!&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> arxiv </tag>
            
            <tag> çˆ¬è™« </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cheap and Good Simple and Effective Data Augmentation for Low Resource Machine Reading</title>
      <link href="/2021/08/06/Cheap%20and%20Good%20Simple%20and%20Effective%20Data%20Augmentation%20for%20Low%20Resource%20Machine%20Reading/"/>
      <url>/2021/08/06/Cheap%20and%20Good%20Simple%20and%20Effective%20Data%20Augmentation%20for%20Low%20Resource%20Machine%20Reading/</url>
      
        <content type="html"><![CDATA[<h1 id="Cheap-and-Good-Simple-and-Effective-Data-Augmentation-for-Low-Resource-Machine-Reading"><a href="#Cheap-and-Good-Simple-and-Effective-Data-Augmentation-for-Low-Resource-Machine-Reading" class="headerlink" title="Cheap and Good Simple and Effective Data Augmentation for Low Resource Machine Reading"></a>Cheap and Good Simple and Effective Data Augmentation for Low Resource Machine Reading</h1><blockquote><p> <a href="https://arxiv.org/abs/2106.04134">è®ºæ–‡ï¼šhttps://arxiv.org/abs/2106.04134</a></p><p> <a href="https://github.com/vanh17/techqa">ä»£ç ï¼šhttps://github.com/vanh17/techqa</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>ä¸ºä½èµ„æºæœºå™¨é˜…è¯»ç†è§£æå‡ºäº†ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„æ•°æ®å¢å¼ºç­–ç•¥ã€‚é¦–å…ˆåœ¨åŒ…å«æ­£ç¡®ç­”æ¡ˆçš„è¿‘ä¼¼ä¸Šä¸‹æ–‡çš„å¢å¼ºæ•°æ®ä¸Šå¯¹MRCç³»ç»Ÿçš„ç­”æ¡ˆæå–ç»„ä»¶è¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åå†å¯¹å‡†ç¡®ç­”æ¡ˆçš„è·¨åº¦è¿›è¡Œè®­ç»ƒã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>ä¸æ˜¯ç›´æ¥åœ¨è®­ç»ƒæœŸé—´æä¾›çš„ç­”æ¡ˆè·¨åº¦ä¸Šè®­ç»ƒç¥ç»ç½‘ç»œï¼Œè€Œæ˜¯å…ˆå¯¹å…¶è¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥ç¡®å®šç­”æ¡ˆå‡ºç°çš„å¤§è‡´èŒƒå›´ã€‚ç„¶åï¼Œä»¥ä¸¤ç§ä¸åŒçš„æ–¹å¼ä½¿ç”¨è¿™ä¸ªé¢„è®­ç»ƒçš„ç¥ç»æ¨¡å‹ã€‚é¦–å…ˆï¼Œåœ¨è®­ç»ƒä¹‹å‰ï¼Œç”¨è¿™ä¸ªæ¨¡å‹çš„æƒé‡æ¥åˆå§‹åŒ–ç­”æ¡ˆæå–æ¨¡å‹ï¼Œè€Œä¸æ˜¯ä»å¤´å¼€å§‹ã€‚ç¬¬äºŒï¼Œåœ¨æ¨ç†æ—¶ï¼Œå°†é¢„è®­ç»ƒçš„æ¨¡å‹ä½œä¸ºä¸€ä¸ªé¢å¤–çš„æ–‡æ¡£æ£€ç´¢ç»„ä»¶æ¥ä½¿ç”¨ï¼šåªå…³æ³¨é‚£äº›åŒ…å«è¢«ç¡®å®šä¸ºå¯èƒ½åŒ…å«ç­”æ¡ˆçš„æ–‡æ¡£ã€‚</p><p><strong>ä¸»è¦è´¡çŒ®ï¼š</strong></p><ul><li>ä¸ºMRC QAå¼•å…¥äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ•°æ®å¢å¼ºæ–¹æ³•ã€‚é€šè¿‡äººä¸ºåœ°ç§»åŠ¨è®­ç»ƒåˆ†åŒºä¸­ç­”æ¡ˆè·¨åº¦çš„è¾¹ç•Œæ¥äº§ç”Ÿé¢å¤–çš„è®­ç»ƒæ•°æ®ï¼Œå¹¶åœ¨è¿™äº›æ•°æ®ä¸Šé¢„è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œä»¥ç¡®å®šç­”æ¡ˆå¯èƒ½å‡ºç°çš„å¤§è‡´èŒƒå›´ã€‚</li><li>ä½¿ç”¨ä¸¤ç§ä¸åŒçš„ç­–ç•¥æ¥åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œé¦–å…ˆï¼Œå°†å…¶çŸ¥è¯†è½¬ç§»åˆ°ç­”æ¡ˆæå–æ¨¡å‹ä¸­ï¼Œç”¨å…¶å­¦åˆ°çš„æƒé‡è¿›è¡Œåˆå§‹åŒ–ï¼›å…¶æ¬¡ï¼Œåœ¨æ¨ç†æ—¶ï¼Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ ¹æ®æ–‡æ¡£åŒ…å«ç­”æ¡ˆä¸Šä¸‹æ–‡çš„å¯èƒ½æ€§è¿›è¡Œæ’åºï¼Œå¹¶åœ¨å¾—åˆ†æœ€é«˜çš„æ–‡æ¡£ä¸­æå–ç­”æ¡ˆã€‚</li><li>å°†è¿‘ä¼¼çš„RCçŸ¥è¯†ç”¨äºæ–‡æ¡£æ£€ç´¢å’Œç­”æ¡ˆæå–ï¼Œå¯ä»¥å¤§å¤§æ”¹å–„åœ¨ä½èµ„æºRCä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</li></ul><p><strong>æ¨¡å‹ç»“æ„ï¼š</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210804222659.png" alt="image-20210804222659187"></p><h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><blockquote><p>é¢„è®­ç»ƒ the BERT-MRC model    </p></blockquote><ul><li>é¦–å…ˆç”¨æ¦‚ç‡å¯¹ç­”æ¡ˆè¿›è¡ŒæŠ½æ ·ï¼ŒæŠ½å–å‡ºéœ€è¦ç”¨æ¥æ•°æ®å¢å¼ºçš„ç‰‡æ®µã€‚</li><li>å¯¹äºé€‰ä¸­çš„ç­”æ¡ˆç‰‡æ®µï¼Œé€šè¿‡å°†æ­£ç¡®çš„ç­”æ¡ˆè·¨åº¦å‘å·¦æˆ–å‘å³ç§»åŠ¨dä¸ªå­—ç¬¦æ¥äº§ç”Ÿnä¸ªé¢å¤–çš„æ¨¡ç³Šç­”æ¡ˆè·¨åº¦ã€‚æ¯ä¸ªç”Ÿæˆçš„ç­”æ¡ˆè·¨åº¦éƒ½æˆä¸ºä¸€ä¸ªæ–°çš„positive training data pointã€‚</li><li>ç”¨å¢åŠ çš„è®­ç»ƒæ•°æ®æ„å»ºæ–°çš„è®­ç»ƒæ•°æ®artificial dataï¼Œè®­ç»ƒæ¨¡å‹ä»¥æŠ½å–ç­”æ¡ˆè¿‘ä¼¼èŒƒå›´ã€‚</li></ul><h3 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h3><p>ç»§ç»­åœ¨åŸå§‹ç­”æ¡ˆè·¨åº¦ï¼ˆæ²¡æœ‰å¢å¼ºçš„æ•°æ®é›†ï¼‰ä¸Šè¿›ä¸€æ­¥è®­ç»ƒçš„BERT-MRCæ¨¡å‹æ¥è½¬ç§»è¿™ç§è¿‘ä¼¼ç­”æ¡ˆè¾¹ç•Œçš„çŸ¥è¯†ã€‚ç”±æ­¤äº§ç”Ÿè®­ç»ƒçš„æ¨¡å‹æ˜¯ç”¨äºå®Œæ•´ä»»åŠ¡ä¸­ç­”æ¡ˆè·¨åº¦é¢„æµ‹çš„æœ€ç»ˆæ¨¡å‹ã€‚</p><h3 id="Document-Retrieval"><a href="#Document-Retrieval" class="headerlink" title="Document Retrieval"></a>Document Retrieval</h3><p>é‡‡ç”¨åœ¨å¢å¼ºçš„æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹æ¥top-k scoreç­”æ¡ˆè·¨åº¦ï¼Œå¹¶åªä¿ç•™ä¸è¿™äº›ç­”æ¡ˆè·¨åº¦ç›¸å…³çš„æ–‡æ¡£ã€‚æä¾›ä¸€ä¸ªæ›´å°ä½†æ›´ç›¸å…³çš„å€™é€‰æ–‡æ¡£é›†ï¼Œå¯ä»¥å¤§å¤§æ”¹å–„AEçš„æ€§èƒ½ã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><blockquote><p>TechQA ä¸€ä¸ªå¤æ‚çš„ã€ä½èµ„æºçš„MRCä»»åŠ¡ã€‚</p><p>PolicyQA ä¸€ä¸ªå®ç”¨ä½†è§„æ¨¡é€‚ä¸­çš„QAæ•°æ®é›†ï¼Œä¹ŸåŒ…å«é•¿çš„ç­”æ¡ˆè·¨åº¦ã€‚</p></blockquote><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210805213308.png" alt="image-20210805213308533"></p><ul><li>æ•°æ®å¢å¼ºæœ‰åŠ©äºTechQAçš„æ–‡æ¡£æ£€ç´¢ä»»åŠ¡ã€‚</li><li>ä¸åŸºçº¿æ¨¡å‹(OBB)ç›¸æ¯”ï¼Œâ€æ•°æ®å¢å¼º â€œæ¨¡å‹ï¼Œâ€æ•°æ®å¢å¼º+è¿ç§»å­¦ä¹  â€œæ¨¡å‹çš„DRAåˆ†æ•°å¤§å¹…æé«˜ã€‚</li><li>ä¸ºäº†è¿›ä¸€æ­¥åˆ†ææ•°æ®å¢å¼ºå¯¹æ–‡æ¡£æ£€ç´¢çš„å½±å“ï¼ŒæŠŠ â€œæ•°æ®å¢å¼º â€œæ¨¡å‹æ£€ç´¢åˆ°çš„æ–‡æ¡£ä½œä¸ºè¾“å…¥åˆ°BERT Largeçš„OBLåŸºçº¿ä¸­ã€‚è¯æ˜ç”±æ•°æ®å¢å¼ºæ¨¡å‹æ£€ç´¢çš„å€™é€‰æ–‡æ¡£å¯ä»¥æé«˜å¤–éƒ¨ç‹¬ç«‹æ¨¡å‹çš„æ–‡æ¡£æ£€ç´¢æ€§èƒ½ã€‚</li></ul><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><ul><li>ç­”æ¡ˆæ£€ç´¢é˜¶æ®µï¼šæ•°æ®å¢å¼ºç­–ç•¥èƒ½å¤Ÿæ•æ‰åˆ°ç­”æ¡ˆå‡ºç°çš„æ›´å¤§èŒƒå›´ã€‚</li><li>ç­”æ¡ˆæå–é˜¶æ®µï¼šé¢å¤–çš„è®­ç»ƒæ•°æ®ï¼Œå¸®åŠ©æå–æ¨¡å‹ç¼©å°å…¶æœç´¢ç©ºé—´ã€‚</li></ul><p>å®éªŒè¯æ˜ï¼Œé€šè¿‡æä¾›æ›´å¤§çš„ç­”æ¡ˆèŒƒå›´å’Œé¢å¤–çš„è®­ç»ƒæ•°æ®ï¼ˆå³ç”Ÿæˆäººå·¥è®­ç»ƒæ•°æ®ç‚¹ï¼‰ï¼Œå¯ä»¥æ”¹å–„æ–‡æ¡£æ£€ç´¢å’Œç­”æ¡ˆæå–çš„æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¤§å¤§æ”¹å–„äº†åŸºäºBERTçš„æ£€ç´¢å™¨å’Œç­”æ¡ˆæå–å™¨åœ¨TechQAä¸Šçš„è¡¨ç°ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> DAMa </tag>
            
            <tag> Low-Resource </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tensorflowæ¨¡å‹ä¿å­˜ä¸åŠ è½½</title>
      <link href="/2021/08/05/Tensorflow%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD/"/>
      <url>/2021/08/05/Tensorflow%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<h1 id="Tensorflowæ¨¡å‹ä¿å­˜ä¸åŠ è½½"><a href="#Tensorflowæ¨¡å‹ä¿å­˜ä¸åŠ è½½" class="headerlink" title="Tensorflowæ¨¡å‹ä¿å­˜ä¸åŠ è½½"></a>Tensorflowæ¨¡å‹ä¿å­˜ä¸åŠ è½½</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>]=<span class="string">&#x27;2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    x is a simple image, not a batch</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x,y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">batchsz = <span class="number">128</span></span><br><span class="line">(x, y), (x_val, y_val) = datasets.mnist.load_data()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;datasets:&#x27;</span>, x.shape, y.shape, x.<span class="built_in">min</span>(), x.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">db = tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line">db = db.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">60000</span>).batch(batchsz)</span><br><span class="line">ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">ds_val = ds_val.<span class="built_in">map</span>(preprocess).batch(batchsz) </span><br><span class="line"></span><br><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(db))</span><br><span class="line"><span class="built_in">print</span>(sample[<span class="number">0</span>].shape, sample[<span class="number">1</span>].shape)</span><br></pre></td></tr></table></figure><pre><code>datasets: (60000, 28, 28) (60000,) 0 255(128, 784) (128, 10)</code></pre><h2 id="1-ä¿å­˜æƒå€¼"><a href="#1-ä¿å­˜æƒå€¼" class="headerlink" title="1.ä¿å­˜æƒå€¼"></a>1.ä¿å­˜æƒå€¼</h2><p>æ¨¡å‹åˆ›å»º</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================dense (Dense)                multiple                  200960    _________________________________________________________________dense_1 (Dense)              multiple                  32896     _________________________________________________________________dense_2 (Dense)              multiple                  8256      _________________________________________________________________dense_3 (Dense)              multiple                  2080      _________________________________________________________________dense_4 (Dense)              multiple                  330       =================================================================Total params: 244,522Trainable params: 244,522Non-trainable params: 0_________________________________________________________________</code></pre><p>æ¨¡å‹è®­ç»ƒ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">network.fit(db, epochs=<span class="number">3</span>, validation_data=ds_val, validation_freq=<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>Epoch 1/3469/469 [==============================] - 10s 22ms/step - loss: 0.2594 - accuracy: 0.9232Epoch 2/3469/469 [==============================] - 12s 25ms/step - loss: 0.1406 - accuracy: 0.9619 - val_loss: 0.1288 - val_accuracy: 0.9629Epoch 3/3469/469 [==============================] - 9s 20ms/step - loss: 0.1076 - accuracy: 0.970379/79 [==============================] - 3s 39ms/step - loss: 0.1237 - accuracy: 0.9689[0.12368294241494805, 0.9689]</code></pre><p>ä¿å­˜æƒå€¼ åˆ é™¤ä¹‹å‰åˆ›å»ºçš„ç½‘ç»œ</p><blockquote><p>network.save_weights</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">network.save_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;saved weights.&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> network</span><br></pre></td></tr></table></figure><pre><code>saved weights.</code></pre><p>åˆ›å»ºä¸ä¹‹å‰ç»“æ„ç›¸åŒçš„ç½‘ç»œ å¹¶åŠ è½½ä¿å­˜çš„æƒå€¼</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>åŠ è½½æƒå€¼ è¯„ä¼°ç½‘ç»œæ•ˆæœ</p><blockquote><p>network.load_weights</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">network.load_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;loaded weights!&#x27;</span>)</span><br><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>loaded weights!79/79 [==============================] - 3s 40ms/step - loss: 0.1237 - accuracy: 0.9689[0.12368294241494805, 0.9689]</code></pre><h2 id="2-ä¿å­˜æ¨¡å‹"><a href="#2-ä¿å­˜æ¨¡å‹" class="headerlink" title="2.ä¿å­˜æ¨¡å‹"></a>2.ä¿å­˜æ¨¡å‹</h2><blockquote><p>ä¿å­˜æ¨¡å‹çš„æ‰€æœ‰ä¿¡æ¯ æ•ˆç‡è¾ƒä½ é‡æ–°åŠ è½½å‰æ— éœ€åˆ›å»ºä¸ä¹‹å‰ç»“æ„ç›¸åŒçš„ç½‘ç»œ</p></blockquote><p>æ¨¡å‹åˆ›å»º&amp;è®­ç»ƒ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">network.fit(db, epochs=<span class="number">2</span>, validation_data=ds_val, validation_freq=<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential_2&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================dense_10 (Dense)             multiple                  200960    _________________________________________________________________dense_11 (Dense)             multiple                  32896     _________________________________________________________________dense_12 (Dense)             multiple                  8256      _________________________________________________________________dense_13 (Dense)             multiple                  2080      _________________________________________________________________dense_14 (Dense)             multiple                  330       =================================================================Total params: 244,522Trainable params: 244,522Non-trainable params: 0_________________________________________________________________Epoch 1/2469/469 [==============================] - 11s 23ms/step - loss: 0.2920 - accuracy: 0.9103Epoch 2/2469/469 [==============================] - 13s 28ms/step - loss: 0.1434 - accuracy: 0.9591 - val_loss: 0.1399 - val_accuracy: 0.963679/79 [==============================] - 4s 46ms/step - loss: 0.1399 - accuracy: 0.9636[0.1399224520914398, 0.9636]</code></pre><p>ä¿å­˜æ¨¡å‹æ‰€æœ‰ä¿¡æ¯</p><blockquote><p>network.save</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">network.save(<span class="string">&#x27;model.h5&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;saved total model.&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> network</span><br></pre></td></tr></table></figure><pre><code>saved total model.</code></pre><p>åŠ è½½æ¨¡å‹ è¯„ä¼°æ•ˆæœ</p><blockquote><p>tf.keras.models.load_model</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;loaded model from file.&#x27;</span>)</span><br><span class="line">network = tf.keras.models.load_model(<span class="string">&#x27;model.h5&#x27;</span>)</span><br><span class="line">                                     </span><br><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>loaded model from file.WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.79/79 [==============================] - 3s 35ms/step - loss: 0.1399 - accuracy: 0.9636[0.1399224520914398, 0.9636]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow.keras.layers keras.Model è‡ªå®šä¹‰å±‚åº”ç”¨</title>
      <link href="/2021/08/05/tensorflow.keras.layers%20keras.Model%20%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82%E5%BA%94%E7%94%A8/"/>
      <url>/2021/08/05/tensorflow.keras.layers%20keras.Model%20%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="tensorflow-keras-layers-keras-Model-è‡ªå®šä¹‰å±‚åº”ç”¨"><a href="#tensorflow-keras-layers-keras-Model-è‡ªå®šä¹‰å±‚åº”ç”¨" class="headerlink" title="tensorflow.keras.layers keras.Model è‡ªå®šä¹‰å±‚åº”ç”¨"></a>tensorflow.keras.layers keras.Model è‡ªå®šä¹‰å±‚åº”ç”¨</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span>    tensorflow <span class="keyword">import</span> keras</span><br></pre></td></tr></table></figure><p>æ•°æ®é¢„å¤„ç†</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    x is a simple image, not a batch</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x,y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">è‡ªå®šä¹‰Layer</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDense</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inp_dim, outp_dim</span>):</span></span><br><span class="line"><span class="built_in">super</span>(MyDense, self).__init__()</span><br><span class="line"></span><br><span class="line">self.kernel = self.add_weight(<span class="string">&#x27;w&#x27;</span>, [inp_dim, outp_dim])</span><br><span class="line">self.bias = self.add_weight(<span class="string">&#x27;b&#x27;</span>, [outp_dim])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">out = inputs @ self.kernel + self.bias</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> out </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>è‡ªå®šä¹‰Model</p><blockquote><p>ç»§æ‰¿keras.Modelå¯ä½¿ç”¨complie fit ç­‰æ–¹æ³•</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line"><span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line">        <span class="comment"># è‡ªå®šä¹‰5å±‚ç½‘ç»œ</span></span><br><span class="line">self.fc1 = MyDense(<span class="number">28</span>*<span class="number">28</span>, <span class="number">256</span>)</span><br><span class="line">self.fc2 = MyDense(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">self.fc3 = MyDense(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">self.fc4 = MyDense(<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">self.fc5 = MyDense(<span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># å®šä¹‰ç½‘ç»œä¼ æ’­è¿‡ç¨‹</span></span><br><span class="line">x = self.fc1(inputs)</span><br><span class="line">x = tf.nn.relu(x)</span><br><span class="line">x = self.fc2(x)</span><br><span class="line">x = tf.nn.relu(x)</span><br><span class="line">x = self.fc3(x)</span><br><span class="line">x = tf.nn.relu(x)</span><br><span class="line">x = self.fc4(x)</span><br><span class="line">x = tf.nn.relu(x)</span><br><span class="line">x = self.fc5(x) </span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">batchsz = <span class="number">128</span></span><br><span class="line">(x, y), (x_val, y_val) = datasets.mnist.load_data()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;datasets:&#x27;</span>, x.shape, y.shape, x.<span class="built_in">min</span>(), x.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">db = tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line">db = db.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">60000</span>).batch(batchsz)</span><br><span class="line">ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">ds_val = ds_val.<span class="built_in">map</span>(preprocess).batch(batchsz) </span><br><span class="line"></span><br><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(db))</span><br><span class="line"><span class="built_in">print</span>(sample[<span class="number">0</span>].shape, sample[<span class="number">1</span>].shape)</span><br></pre></td></tr></table></figure><pre><code>datasets: (60000, 28, 28) (60000,) 0 255(128, 784) (128, 10)</code></pre><p>åˆ›å»ºæ¨¡å‹</p><blockquote><p>summary()å¿…é¡»åœ¨fit æˆ– buildä¹‹åä½¿ç”¨</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">network = MyModel()</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line"><span class="comment"># summary()å¿…é¡»åœ¨fit æˆ– buildä¹‹åä½¿ç”¨</span></span><br><span class="line">network.summary()</span><br><span class="line"></span><br><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">network.fit(db, epochs=<span class="number">5</span>, validation_data=ds_val,</span><br><span class="line">              validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;my_model_8&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================my_dense_40 (MyDense)        multiple                  200960    _________________________________________________________________my_dense_41 (MyDense)        multiple                  32896     _________________________________________________________________my_dense_42 (MyDense)        multiple                  8256      _________________________________________________________________my_dense_43 (MyDense)        multiple                  2080      _________________________________________________________________my_dense_44 (MyDense)        multiple                  330       =================================================================Total params: 244,522Trainable params: 244,522Non-trainable params: 0_________________________________________________________________Epoch 1/5469/469 [==============================] - 10s 22ms/step - loss: 0.3078 - accuracy: 0.9076Epoch 2/5469/469 [==============================] - 13s 28ms/step - loss: 0.1409 - accuracy: 0.9600 - val_loss: 0.1318 - val_accuracy: 0.9641Epoch 3/5469/469 [==============================] - 13s 27ms/step - loss: 0.1125 - accuracy: 0.9680Epoch 4/5469/469 [==============================] - 16s 35ms/step - loss: 0.0984 - accuracy: 0.9724 - val_loss: 0.1196 - val_accuracy: 0.9673Epoch 5/5469/469 [==============================] - 15s 32ms/step - loss: 0.0875 - accuracy: 0.976079/79 [==============================] - 3s 33ms/step - loss: 0.1224 - accuracy: 0.9704[0.12237951139141393, 0.9704]</code></pre><p>æ¨¡å‹é¢„æµ‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(ds_val))</span><br><span class="line">x = sample[<span class="number">0</span>]</span><br><span class="line">y = sample[<span class="number">1</span>] <span class="comment"># one-hot</span></span><br><span class="line">pred = network.predict(x) <span class="comment"># [b, 10]</span></span><br><span class="line"><span class="comment"># convert back to number </span></span><br><span class="line">y = tf.argmax(y, axis=<span class="number">1</span>)</span><br><span class="line">pred = tf.argmax(pred, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pred)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)tf.Tensor([7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)</code></pre>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow.keras.Model compile fit evaluateåº”ç”¨</title>
      <link href="/2021/08/04/tensorflow.keras%20compile%20fit%20evaluate%E5%BA%94%E7%94%A8/"/>
      <url>/2021/08/04/tensorflow.keras%20compile%20fit%20evaluate%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="tensorflow-keras-Model-compile-fit-evaluateåº”ç”¨"><a href="#tensorflow-keras-Model-compile-fit-evaluateåº”ç”¨" class="headerlink" title="tensorflow.keras.Model compile fit evaluateåº”ç”¨"></a>tensorflow.keras.Model compile fit evaluateåº”ç”¨</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br></pre></td></tr></table></figure><p>æ•°æ®é¢„å¤„ç†</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    x is a simple image, not a batch</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x,y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">batchsz = <span class="number">128</span></span><br><span class="line">(x, y), (x_val, y_val) = datasets.mnist.load_data()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;datasets:&#x27;</span>, x.shape, y.shape, x.<span class="built_in">min</span>(), x.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">db = tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line"><span class="comment"># ä½¿ç”¨preprocesså‡½æ•°å¤„ç†æ•°æ®é›†</span></span><br><span class="line">db = db.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">60000</span>).batch(batchsz)</span><br><span class="line"></span><br><span class="line">ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">ds_val = ds_val.<span class="built_in">map</span>(preprocess).batch(batchsz) </span><br><span class="line"></span><br><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(db))</span><br><span class="line"><span class="built_in">print</span>(sample[<span class="number">0</span>].shape, sample[<span class="number">1</span>].shape)</span><br></pre></td></tr></table></figure><pre><code>datasets: (60000, 28, 28) (60000,) 0 255(128, 784) (128, 10)</code></pre><p>æ¨¡å‹æ„å»º</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential_2&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================dense_10 (Dense)             multiple                  200960    _________________________________________________________________dense_11 (Dense)             multiple                  32896     _________________________________________________________________dense_12 (Dense)             multiple                  8256      _________________________________________________________________dense_13 (Dense)             multiple                  2080      _________________________________________________________________dense_14 (Dense)             multiple                  330       =================================================================Total params: 244,522Trainable params: 244,522Non-trainable params: 0_________________________________________________________________</code></pre><p>ä½¿ç”¨compileè®¾ç½®æ¨¡å‹çš„ä¼˜åŒ–å™¨ï¼ŒæŸå¤±å‡½æ•°ï¼Œmetrics</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>] <span class="comment"># accuracyç”¨æ¥è®¡ç®—å‡†ç¡®åº¦</span></span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>ä½¿ç”¨fité…ç½®æ¨¡å‹çš„è®­ç»ƒæ•°æ®é›†ï¼Œè®­ç»ƒè½®æ¬¡ï¼ŒéªŒè¯æ•°æ®é›†ï¼ŒéªŒè¯é¢‘æ¬¡</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.fit(db, epochs=<span class="number">5</span>, validation_data=ds_val, validation_freq=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><pre><code>Epoch 1/5469/469 [==============================] - 11s 24ms/step - loss: 0.2834 - accuracy: 0.9153Epoch 2/5469/469 [==============================] - 12s 27ms/step - loss: 0.1356 - accuracy: 0.9628 - val_loss: 0.1399 - val_accuracy: 0.9614Epoch 3/5469/469 [==============================] - 9s 19ms/step - loss: 0.1134 - accuracy: 0.9696Epoch 4/5469/469 [==============================] - 12s 26ms/step - loss: 0.1001 - accuracy: 0.9736 - val_loss: 0.1208 - val_accuracy: 0.9685Epoch 5/5469/469 [==============================] - 10s 21ms/step - loss: 0.0846 - accuracy: 0.9773&lt;tensorflow.python.keras.callbacks.History at 0x7f893e44de90&gt;</code></pre><p>ä½¿ç”¨evaluateè¯„ä¼°æ¨¡å‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>79/79 [==============================] - 3s 36ms/step - loss: 0.1085 - accuracy: 0.9738[0.10845260255486716, 0.9738]</code></pre><p>ä½¿ç”¨predicté¢„æµ‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(ds_val))</span><br><span class="line">x = sample[<span class="number">0</span>]</span><br><span class="line">y = sample[<span class="number">1</span>] <span class="comment"># one-hot</span></span><br><span class="line">pred = network.predict(x) <span class="comment"># [b, 10]</span></span><br><span class="line"><span class="comment"># convert back to number </span></span><br><span class="line">y = tf.argmax(y, axis=<span class="number">1</span>)</span><br><span class="line">pred = tf.argmax(pred, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pred)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)tf.Tensor([7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)</code></pre>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow.keras metricsåº”ç”¨</title>
      <link href="/2021/08/04/tensorflow.keras%20metrics%E5%BA%94%E7%94%A8/"/>
      <url>/2021/08/04/tensorflow.keras%20metrics%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="tensorflow-keras-metricsåº”ç”¨"><a href="#tensorflow-keras-metricsåº”ç”¨" class="headerlink" title="tensorflow.keras metricsåº”ç”¨"></a>tensorflow.keras metricsåº”ç”¨</h1><blockquote><p>ä¸ä½¿ç”¨metricså®ç°çš„åšå®¢å‚è€ƒï¼š</p></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210804195738.png" alt="image-20210804195738825"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br></pre></td></tr></table></figure><p>æ›´æ”¹æ•°æ®ç±»å‹å¹¶å½’ä¸€åŒ–</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">x, y</span>):</span></span><br><span class="line"></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x,y</span><br></pre></td></tr></table></figure><p>åŠ è½½æ•°æ®é›†å¹¶è¿›è¡Œé¢„å¤„ç†</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">batchsz = <span class="number">128</span></span><br><span class="line">(x, y), (x_val, y_val) = datasets.mnist.load_data()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;datasets:&#x27;</span>, x.shape, y.shape, x.<span class="built_in">min</span>(), x.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line">db = tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line">db = db.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">60000</span>).batch(batchsz).repeat(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">ds_val = ds_val.<span class="built_in">map</span>(preprocess).batch(batchsz) </span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>datasets: (60000, 28, 28) (60000,) 0 255</code></pre><p>æ„å»ºæ¨¡å‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary() <span class="comment"># æ‰“å°æ¨¡å‹è¯¦ç»†ä¿¡æ¯</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¼˜åŒ–å™¨</span></span><br><span class="line">optimizer = optimizers.Adam(lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================dense (Dense)                multiple                  200960    _________________________________________________________________dense_1 (Dense)              multiple                  32896     _________________________________________________________________dense_2 (Dense)              multiple                  8256      _________________________________________________________________dense_3 (Dense)              multiple                  2080      _________________________________________________________________dense_4 (Dense)              multiple                  330       =================================================================Total params: 244,522Trainable params: 244,522Non-trainable params: 0_________________________________________________________________</code></pre><p>æ¨¡å‹è®­ç»ƒå¹¶åº”ç”¨metrics</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä½¿ç”¨metricsè®¡ç®—å‡†ç¡®ç‡å’Œlossçš„å‡å€¼</span></span><br><span class="line">acc_meter = metrics.Accuracy()</span><br><span class="line">loss_meter = metrics.Mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step, (x,y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(db):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        <span class="comment"># [b, 28, 28] =&gt; [b, 784]</span></span><br><span class="line">        x = tf.reshape(x, (-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">        <span class="comment"># [b, 784] =&gt; [b, 10]</span></span><br><span class="line">        out = network(x)</span><br><span class="line">        <span class="comment"># [b] =&gt; [b, 10]</span></span><br><span class="line">        y_onehot = tf.one_hot(y, depth=<span class="number">10</span>) </span><br><span class="line">        <span class="comment"># [b]</span></span><br><span class="line">        <span class="comment"># ä½¿ç”¨äº¤å‰ç†µæŸå¤±</span></span><br><span class="line">        <span class="comment"># from_logits=Trueç¡®ä¿æ•°æ®ç¨³å®šæ€§ outå¿…é¡»æ˜¯ç½‘ç»œç›´æ¥è¾“å‡ºçš„ç»“æœï¼Œä¸ç»è¿‡æ¿€æ´»å‡½æ•°</span></span><br><span class="line">        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=<span class="literal">True</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># æ·»åŠ loss</span></span><br><span class="line">        loss_meter.update_state(loss)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># æ¢¯åº¦æ›´æ–° åå‘ä¼ æ’­</span></span><br><span class="line">    grads = tape.gradient(loss, network.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(<span class="built_in">zip</span>(grads, network.trainable_variables))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(step, <span class="string">&#x27;loss_meter:&#x27;</span>,loss_meter.result().numpy(),<span class="string">&#x27;  loss:&#x27;</span>, loss,) </span><br><span class="line">        <span class="comment"># ä¸‹ä¸€è½®è®¡ç®—æ—¶åº”æ¸…é›¶</span></span><br><span class="line">        loss_meter.reset_states()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># evaluate</span></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">        total, total_correct = <span class="number">0.</span>, <span class="number">0</span></span><br><span class="line">        <span class="comment"># ä½¿ç”¨å‰æ¸…ç©ºå†å²çŠ¶æ€</span></span><br><span class="line">        acc_meter.reset_states()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step1, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(ds_val): </span><br><span class="line">            <span class="comment"># [b, 28, 28] =&gt; [b, 784]</span></span><br><span class="line">            x = tf.reshape(x, (-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">            <span class="comment"># [b, 784] =&gt; [b, 10]</span></span><br><span class="line">            out = network(x) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># [b, 10] =&gt; [b] </span></span><br><span class="line">            pred = tf.argmax(out, axis=<span class="number">1</span>) </span><br><span class="line">            pred = tf.cast(pred, dtype=tf.int32)</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># æ–¹æ³•ä¸€</span></span><br><span class="line">            <span class="comment"># bool type </span></span><br><span class="line">            correct = tf.equal(pred, y)</span><br><span class="line">            <span class="comment"># bool tensor =&gt; int tensor =&gt; numpy</span></span><br><span class="line">            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()</span><br><span class="line">            total += x.shape[<span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># æ–¹æ³•äºŒ</span></span><br><span class="line">            acc_meter.update_state(y, pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(step, <span class="string">&#x27;Evaluate Acc:&#x27;</span>, total_correct/total, acc_meter.result().numpy())</span><br></pre></td></tr></table></figure><pre><code>0 loss_meter: 0.0147538865   loss: tf.Tensor(0.0147538865, shape=(), dtype=float32)78 Evaluate Acc: 0.9743 0.9743100 loss_meter: 0.04805827   loss: tf.Tensor(0.041749448, shape=(), dtype=float32)200 loss_meter: 0.053051163   loss: tf.Tensor(0.0131300185, shape=(), dtype=float32)300 loss_meter: 0.07365899   loss: tf.Tensor(0.0278976, shape=(), dtype=float32)400 loss_meter: 0.07007911   loss: tf.Tensor(0.05961611, shape=(), dtype=float32)500 loss_meter: 0.059413455   loss: tf.Tensor(0.04578472, shape=(), dtype=float32)78 Evaluate Acc: 0.976 0.976600 loss_meter: 0.045514174   loss: tf.Tensor(0.1006662, shape=(), dtype=float32)700 loss_meter: 0.05224053   loss: tf.Tensor(0.061094068, shape=(), dtype=float32)800 loss_meter: 0.06696898   loss: tf.Tensor(0.08473669, shape=(), dtype=float32)900 loss_meter: 0.06490257   loss: tf.Tensor(0.05812662, shape=(), dtype=float32)1000 loss_meter: 0.056545332   loss: tf.Tensor(0.10347018, shape=(), dtype=float32)78 Evaluate Acc: 0.9745 0.97451100 loss_meter: 0.0515905   loss: tf.Tensor(0.045466803, shape=(), dtype=float32)1200 loss_meter: 0.06225908   loss: tf.Tensor(0.046285823, shape=(), dtype=float32)1300 loss_meter: 0.057779107   loss: tf.Tensor(0.05366286, shape=(), dtype=float32)1400 loss_meter: 0.06661249   loss: tf.Tensor(0.10940219, shape=(), dtype=float32)1500 loss_meter: 0.059498344   loss: tf.Tensor(0.05784896, shape=(), dtype=float32)78 Evaluate Acc: 0.974 0.9741600 loss_meter: 0.06252271   loss: tf.Tensor(0.0287047, shape=(), dtype=float32)1700 loss_meter: 0.060016934   loss: tf.Tensor(0.006867729, shape=(), dtype=float32)1800 loss_meter: 0.05751593   loss: tf.Tensor(0.13693535, shape=(), dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Top-kå‡†ç¡®ç‡</title>
      <link href="/2021/08/02/Top-k%E5%87%86%E7%A1%AE%E7%8E%87/"/>
      <url>/2021/08/02/Top-k%E5%87%86%E7%A1%AE%E7%8E%87/</url>
      
        <content type="html"><![CDATA[<h1 id="Top-kå‡†ç¡®ç‡"><a href="#Top-kå‡†ç¡®ç‡" class="headerlink" title="Top-kå‡†ç¡®ç‡"></a>Top-kå‡†ç¡®ç‡</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span>  os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span> <span class="comment">#é™åˆ¶æ§åˆ¶å°æ‰“å°æ—¥å¿—çº§åˆ«</span></span><br><span class="line">tf.random.set_seed(<span class="number">2467</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">output, target, topk=(<span class="params"><span class="number">1</span>,</span>)</span>):</span></span><br><span class="line">    <span class="comment"># output [10,6]</span></span><br><span class="line">    maxk = <span class="built_in">max</span>(topk)</span><br><span class="line">    batch_size = target.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    pred = tf.math.top_k(output, maxk).indices <span class="comment"># å‰Kä¸ªæœ€å¤§å€¼çš„ç´¢å¼• [10,maxk]</span></span><br><span class="line"><span class="comment">#     print(&#x27;æ¯è¡Œtop-6 æœ€å¤§å€¼&#x27;,tf.math.top_k(output, maxk).values)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;æ¯è¡Œtop-6 æœ€å¤§å€¼ä¸‹æ ‡&#x27;</span>,tf.math.top_k(output, maxk).indices)</span><br><span class="line">    pred = tf.transpose(pred, perm=[<span class="number">1</span>, <span class="number">0</span>]) <span class="comment"># è½¬ç½® [maxk,10] æ–¹ä¾¿ç»Ÿè®¡æ¯”è¾ƒ</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;è½¬ç½® æ¯è¡Œtop-6 æœ€å¤§å€¼ä¸‹æ ‡&#x27;</span>,pred)</span><br><span class="line">    </span><br><span class="line">    target_ = tf.broadcast_to(target, pred.shape) <span class="comment"># target [10]å¹¿æ’­æˆç›¸åŒçš„å½¢çŠ¶ [maxk,10]</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;å‡†ç¡®å€¼&#x27;</span>,target_)</span><br><span class="line">    correct = tf.equal(pred, target_)</span><br><span class="line">    <span class="built_in">print</span>(correct)</span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> topk:</span><br><span class="line">        <span class="comment"># åˆ†åˆ«è®¡ç®—top-1 åˆ° top-kçš„å‡†ç¡®ç‡</span></span><br><span class="line">        correct_k = tf.cast(tf.reshape(correct[:k], [-<span class="number">1</span>]), dtype=tf.float32)</span><br><span class="line">        <span class="comment"># å±•æˆè¡Œç»Ÿè®¡1çš„ä¸ªæ•°</span></span><br><span class="line">        correct_k = tf.reduce_sum(correct_k)</span><br><span class="line">        acc = <span class="built_in">float</span>(correct_k* (<span class="number">100.0</span> / batch_size) )</span><br><span class="line">        res.append(acc)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">output = tf.random.normal([<span class="number">10</span>, <span class="number">6</span>])</span><br><span class="line">output = tf.math.softmax(output, axis=<span class="number">1</span>)  <span class="comment"># ä½¿å¾—æ¯è¡Œæ¦‚ç‡ä¹‹å’Œä¸º1</span></span><br><span class="line">target = tf.random.uniform([<span class="number">10</span>], maxval=<span class="number">6</span>, dtype=tf.int32) <span class="comment"># ç”Ÿæˆ6ç±»æ ·æœ¬ å› æ­¤top-6å‡†ç¡®ç‡ä¸€å®šä¸º100%</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;prob:&#x27;</span>, output.numpy())</span><br><span class="line"></span><br><span class="line">pred = tf.argmax(output, axis=<span class="number">1</span>) <span class="comment"># argmax() æ¯è¡Œæœ€å¤§å€¼çš„ç´¢å¼•</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;pred:&#x27;</span>, pred.numpy())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;label:&#x27;</span>, target.numpy())</span><br><span class="line"></span><br><span class="line">acc = accuracy(output, target, topk=(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\ntop-1-6 acc:&#x27;</span>, acc)</span><br></pre></td></tr></table></figure><pre><code>prob: [[0.22184627 0.1221462  0.07409586 0.34996933 0.07511458 0.15682773] [0.14504947 0.04924896 0.21993972 0.07217006 0.08854685 0.42504498] [0.1542809  0.14255568 0.07593964 0.09910513 0.395387   0.13273162] [0.16668463 0.11025342 0.11436021 0.03997175 0.28128707 0.28744298] [0.05896802 0.02670637 0.3851833  0.13821954 0.27897805 0.11194469] [0.16363983 0.24467127 0.08584066 0.08326607 0.3861453  0.03643688] [0.28560603 0.22363636 0.06274495 0.26323685 0.03589749 0.12887837] [0.38431036 0.09477527 0.1130109  0.0730463  0.15465215 0.18020503] [0.05116006 0.15413527 0.16139452 0.32532734 0.14692572 0.16105707] [0.10868432 0.05033949 0.30445468 0.13251573 0.3949189  0.00908681]]pred: [3 5 4 5 2 4 0 0 3 4]label: [1 3 5 2 1 0 4 4 1 1]æ¯è¡Œtop-6 æœ€å¤§å€¼ä¸‹æ ‡ tf.Tensor([[3 0 5 1 4 2] [5 2 0 4 3 1] [4 0 1 5 3 2] [5 4 0 2 1 3] [2 4 3 5 0 1] [4 1 0 2 3 5] [0 3 1 5 2 4] [0 5 4 2 1 3] [3 2 5 1 4 0] [4 2 3 0 1 5]], shape=(10, 6), dtype=int32)è½¬ç½® æ¯è¡Œtop-6 æœ€å¤§å€¼ä¸‹æ ‡ tf.Tensor([[3 5 4 5 2 4 0 0 3 4] [0 2 0 4 4 1 3 5 2 2] [5 0 1 0 3 0 1 4 5 3] [1 4 5 2 5 2 5 2 1 0] [4 3 3 1 0 3 2 1 4 1] [2 1 2 3 1 5 4 3 0 5]], shape=(6, 10), dtype=int32)å‡†ç¡®å€¼ tf.Tensor([[1 3 5 2 1 0 4 4 1 1] [1 3 5 2 1 0 4 4 1 1] [1 3 5 2 1 0 4 4 1 1] [1 3 5 2 1 0 4 4 1 1] [1 3 5 2 1 0 4 4 1 1] [1 3 5 2 1 0 4 4 1 1]], shape=(6, 10), dtype=int32)tf.Tensor([[False False False False False False False False False False] [False False False False False False False False False False] [False False False False False  True False  True False False] [ True False  True  True False False False False  True False] [False  True False False False False False False False  True] [False False False False  True False  True False False False]], shape=(6, 10), dtype=bool)top-1-6 acc: [0.0, 0.0, 20.0, 60.0, 80.0, 100.0]</code></pre>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pythonæ±‚è§£å›å½’é—®é¢˜</title>
      <link href="/2021/08/01/Python%E6%B1%82%E8%A7%A3%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/"/>
      <url>/2021/08/01/Python%E6%B1%82%E8%A7%A3%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="Pythonæ±‚è§£å›å½’é—®é¢˜"><a href="#Pythonæ±‚è§£å›å½’é—®é¢˜" class="headerlink" title="Pythonæ±‚è§£å›å½’é—®é¢˜"></a>Pythonæ±‚è§£å›å½’é—®é¢˜</h1><p>y=wx+b</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è®¡ç®—ç»™å®š(w,b)çš„å¹³å‡è¯¯å·®</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_error_for_line_given_points</span>(<span class="params">b, w, points</span>):</span></span><br><span class="line">    totalError = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(points)):</span><br><span class="line">        x = points[i, <span class="number">0</span>]</span><br><span class="line">        y = points[i, <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># computer mean-squared-error</span></span><br><span class="line">        totalError += (y - (w * x + b)) ** <span class="number">2</span></span><br><span class="line">    <span class="comment"># average loss for each point</span></span><br><span class="line">    <span class="keyword">return</span> totalError / <span class="built_in">float</span>(<span class="built_in">len</span>(points))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_gradient</span>(<span class="params">b_current, w_current, points, learningRate</span>):</span></span><br><span class="line">    b_gradient = <span class="number">0</span></span><br><span class="line">    w_gradient = <span class="number">0</span></span><br><span class="line">    N = <span class="built_in">float</span>(<span class="built_in">len</span>(points))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(points)):</span><br><span class="line">        x = points[i, <span class="number">0</span>]</span><br><span class="line">        y = points[i, <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># æ±‚å¯¼æ•° é™¤Nå–å¹³å‡å€¼</span></span><br><span class="line">        <span class="comment"># grad_b = 2(wx+b-y)</span></span><br><span class="line">        b_gradient += (<span class="number">2</span>/N) * ((w_current * x + b_current) - y)</span><br><span class="line">        <span class="comment"># grad_w = 2(wx+b-y)*x</span></span><br><span class="line">        w_gradient += (<span class="number">2</span>/N) * x * ((w_current * x + b_current) - y)</span><br><span class="line">    <span class="comment"># update b&#x27; w&#x27; </span></span><br><span class="line">    <span class="comment"># æ¢¯åº¦æŒ‡å‘æå¤§å€¼æ–¹å‘ å› æ­¤åæ–¹å‘æ›´æ–°æ¢¯åº¦</span></span><br><span class="line">    new_b = b_current - (learningRate * b_gradient)</span><br><span class="line">    new_w = w_current - (learningRate * w_gradient)</span><br><span class="line">    temploss = compute_error_for_line_given_points(new_b, new_w, points)</span><br><span class="line">    loss.append(temploss)</span><br><span class="line">    <span class="keyword">return</span> [new_b, new_w]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent_runner</span>(<span class="params">points, starting_b, starting_w, learning_rate, num_iterations</span>):</span></span><br><span class="line">    b = starting_b</span><br><span class="line">    w = starting_w</span><br><span class="line">    <span class="comment"># update for several times</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">        b, w = step_gradient(b, w, np.array(points), learning_rate)</span><br><span class="line">    <span class="keyword">return</span> [b, w]</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span>():</span></span><br><span class="line">    points = np.genfromtxt(<span class="string">&quot;data.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>)</span><br><span class="line">    learning_rate = <span class="number">0.0001</span></span><br><span class="line">    initial_b = <span class="number">0</span> <span class="comment"># initial y-intercept guess</span></span><br><span class="line">    initial_w = <span class="number">0</span> <span class="comment"># initial slope guess</span></span><br><span class="line">    num_iterations = <span class="number">1000</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Starting gradient descent at b = &#123;0&#125;, w = &#123;1&#125;, error = &#123;2&#125;&quot;</span></span><br><span class="line">          .<span class="built_in">format</span>(initial_b, initial_w,</span><br><span class="line">                  compute_error_for_line_given_points(initial_b, initial_w, points))</span><br><span class="line">          )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Running...&quot;</span>)</span><br><span class="line">    [b, w] = gradient_descent_runner(points, initial_b, initial_w, learning_rate, num_iterations)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;After &#123;0&#125; iterations b = &#123;1&#125;, w = &#123;2&#125;, error = &#123;3&#125;&quot;</span>.</span><br><span class="line">          <span class="built_in">format</span>(num_iterations, b, w,</span><br><span class="line">                 compute_error_for_line_given_points(b, w, points))</span><br><span class="line">          )</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss = []</span><br><span class="line">run()</span><br></pre></td></tr></table></figure><pre><code>Starting gradient descent at b = 0, w = 0, error = 5565.107834483211Running...After 1000 iterations b = 0.08893651993741346, w = 1.4777440851894448, error = 112.61481011613473</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(loss))]</span><br><span class="line">plt.plot(x,loss)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7f82b2c8bd90&gt;]</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210801104603.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlowå®ç°æ‰‹å†™æ•°å­—è¯†åˆ«</title>
      <link href="/2021/08/01/TensorFlow%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
      <url>/2021/08/01/TensorFlow%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="TensorFlowå®ç°æ‰‹å†™æ•°å­—è¯†åˆ«"><a href="#TensorFlowå®ç°æ‰‹å†™æ•°å­—è¯†åˆ«" class="headerlink" title="TensorFlowå®ç°æ‰‹å†™æ•°å­—è¯†åˆ«"></a>TensorFlowå®ç°æ‰‹å†™æ•°å­—è¯†åˆ«</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># è®¾ç½®GPUä½¿ç”¨æ–¹å¼</span></span><br><span class="line"><span class="comment"># è·å–GPUåˆ—è¡¨</span></span><br><span class="line">gpus = tf.config.experimental.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(gpus)</span><br><span class="line"><span class="keyword">if</span> gpus:</span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># è®¾ç½®GPUä¸ºå¢é•¿å¼å ç”¨</span></span><br><span class="line">    <span class="keyword">for</span> gpu <span class="keyword">in</span> gpus:</span><br><span class="line">      tf.config.experimental.set_memory_growth(gpu, <span class="literal">True</span>) </span><br><span class="line">  <span class="keyword">except</span> RuntimeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="comment"># æ‰“å°å¼‚å¸¸</span></span><br><span class="line">    <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure><pre><code>[]</code></pre><p>åŠ è½½æ•°æ®é›†</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(xs, ys),_ = datasets.mnist.load_data() <span class="comment">#è‡ªåŠ¨ä¸‹è½½</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;datasets:&#x27;</span>, xs.shape, ys.shape, xs.<span class="built_in">min</span>(), xs.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">xs = tf.convert_to_tensor(xs, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">db = tf.data.Dataset.from_tensor_slices((xs,ys))  </span><br><span class="line">db = db.batch(batch_size).repeat(<span class="number">30</span>) <span class="comment">#å°†æ•°æ®é›†åˆ†éš”æˆbatch_sizeä¸ªbatch  repeat(30)ä»£è¡¨è®­ç»ƒ30è½®</span></span><br></pre></td></tr></table></figure><pre><code>datasets: (60000, 28, 28) (60000,) 0 255</code></pre><p>æ¨¡å‹æ„å»º</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Dense å…¨è¿æ¥å±‚</span></span><br><span class="line">model = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>), </span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">model.build(input_shape=(<span class="number">4</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">model.summary() <span class="comment">#æ‰“å°æ¨¡å‹ä¿¡æ¯</span></span><br><span class="line"></span><br><span class="line">optimizer = optimizers.SGD(lr=<span class="number">0.01</span>)</span><br><span class="line">acc_meter = metrics.Accuracy()</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential_3&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================dense_9 (Dense)              multiple                  200960    _________________________________________________________________dense_10 (Dense)             multiple                  32896     _________________________________________________________________dense_11 (Dense)             multiple                  1290      =================================================================Total params: 235,146Trainable params: 235,146Non-trainable params: 0_________________________________________________________________</code></pre><p>æ¨¡å‹è®­ç»ƒ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">total_acc = []</span><br><span class="line">total_loss = []</span><br><span class="line"><span class="keyword">for</span> step, (x,y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(db):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        <span class="comment"># æ‰“å¹³æ“ä½œï¼Œ[b, 28, 28] =&gt; [b, 784]</span></span><br><span class="line">        x = tf.reshape(x, (-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">        <span class="comment"># Step1. å¾—åˆ°æ¨¡å‹è¾“å‡ºoutput [b, 784] =&gt; [b, 10]</span></span><br><span class="line">        out = model(x)</span><br><span class="line">        <span class="comment"># [b] =&gt; [b, 10]</span></span><br><span class="line">        y_onehot = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">        <span class="comment"># è®¡ç®—å·®çš„å¹³æ–¹å’Œï¼Œ[b, 10]</span></span><br><span class="line">        loss = tf.square(out-y_onehot)</span><br><span class="line">        <span class="comment"># è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„å¹³å‡è¯¯å·®ï¼Œ[b]</span></span><br><span class="line">        loss = tf.reduce_sum(loss) / x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    acc_meter.update_state(tf.argmax(out, axis=<span class="number">1</span>), y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ›´æ–°æ¢¯åº¦</span></span><br><span class="line">    grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(<span class="built_in">zip</span>(grads, model.trainable_variables))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">200</span>==<span class="number">0</span>:</span><br><span class="line">        total_acc.append(acc_meter.result().numpy())</span><br><span class="line">        total_loss.append(<span class="built_in">float</span>(loss))</span><br><span class="line">        <span class="built_in">print</span>(step, <span class="string">&#x27;loss:&#x27;</span>, <span class="built_in">float</span>(loss), <span class="string">&#x27;acc:&#x27;</span>, acc_meter.result().numpy())</span><br><span class="line">        acc_meter.reset_states()</span><br></pre></td></tr></table></figure><pre><code>0 loss: 0.15352573990821838 acc: 0.95457846200 loss: 0.1597624123096466 acc: 0.95765626400 loss: 0.1545962393283844 acc: 0.9475600 loss: 0.1637483835220337 acc: 0.94578123800 loss: 0.15958964824676514 acc: 0.94765631000 loss: 0.20374062657356262 acc: 0.940781241200 loss: 0.18700677156448364 acc: 0.949218751400 loss: 0.15020117163658142 acc: 0.951406241600 loss: 0.14052757620811462 acc: 0.94218751800 loss: 0.15347686409950256 acc: 0.951093732000 loss: 0.15199950337409973 acc: 0.9652200 loss: 0.08358028531074524 acc: 0.953906242400 loss: 0.16466480493545532 acc: 0.954843762600 loss: 0.14589539170265198 acc: 0.9543752800 loss: 0.10357476770877838 acc: 0.952031253000 loss: 0.1552669256925583 acc: 0.951093733200 loss: 0.13997772336006165 acc: 0.956406243400 loss: 0.10184890031814575 acc: 0.95046883600 loss: 0.0966319739818573 acc: 0.9506253800 loss: 0.14316204190254211 acc: 0.96609384000 loss: 0.14158621430397034 acc: 0.96609384200 loss: 0.11101004481315613 acc: 0.95593754400 loss: 0.10630815476179123 acc: 0.960468774600 loss: 0.1794758141040802 acc: 0.954843764800 loss: 0.10882129520177841 acc: 0.95578125000 loss: 0.11497728526592255 acc: 0.961255200 loss: 0.20665663480758667 acc: 0.95593755400 loss: 0.22054731845855713 acc: 0.953906245600 loss: 0.08281977474689484 acc: 0.968281275800 loss: 0.1415213942527771 acc: 0.96968756000 loss: 0.10287574678659439 acc: 0.962343756200 loss: 0.14125148952007294 acc: 0.9593756400 loss: 0.0872105211019516 acc: 0.962968776600 loss: 0.09639552235603333 acc: 0.958906236800 loss: 0.09451914578676224 acc: 0.962031257000 loss: 0.09597232937812805 acc: 0.965156267200 loss: 0.27553442120552063 acc: 0.953906247400 loss: 0.11118196696043015 acc: 0.96359377600 loss: 0.13853389024734497 acc: 0.97421877800 loss: 0.0864826887845993 acc: 0.967656258000 loss: 0.12683367729187012 acc: 0.96578138200 loss: 0.0835743099451065 acc: 0.966718738400 loss: 0.07526201754808426 acc: 0.962031258600 loss: 0.08792373538017273 acc: 0.96343758800 loss: 0.1303400695323944 acc: 0.966259000 loss: 0.11500948667526245 acc: 0.96156259200 loss: 0.07716777920722961 acc: 0.962031259400 loss: 0.06136278063058853 acc: 0.97406259600 loss: 0.16090892255306244 acc: 0.973759800 loss: 0.050481319427490234 acc: 0.9679687610000 loss: 0.12725922465324402 acc: 0.967812510200 loss: 0.10010596364736557 acc: 0.965312510400 loss: 0.12236626446247101 acc: 0.96437510600 loss: 0.06595691293478012 acc: 0.9701562510800 loss: 0.16140709817409515 acc: 0.9673437511000 loss: 0.07903225719928741 acc: 0.9614062311200 loss: 0.09545521438121796 acc: 0.9707812711400 loss: 0.08132430166006088 acc: 0.9757812611600 loss: 0.14214324951171875 acc: 0.970312511800 loss: 0.0826168805360794 acc: 0.9692187312000 loss: 0.07449790835380554 acc: 0.9687512200 loss: 0.052427180111408234 acc: 0.968437512400 loss: 0.10587689280509949 acc: 0.9698437512600 loss: 0.14333687722682953 acc: 0.9692187312800 loss: 0.1134927049279213 acc: 0.966406213000 loss: 0.07688809186220169 acc: 0.9687513200 loss: 0.1413525640964508 acc: 0.976718713400 loss: 0.09582379460334778 acc: 0.9748437413600 loss: 0.10331477224826813 acc: 0.9704687613800 loss: 0.1101207584142685 acc: 0.97187514000 loss: 0.05487038940191269 acc: 0.9687514200 loss: 0.1763731837272644 acc: 0.971562514400 loss: 0.08923567831516266 acc: 0.97062514600 loss: 0.14577150344848633 acc: 0.9695312414800 loss: 0.07163411378860474 acc: 0.96687515000 loss: 0.09502746164798737 acc: 0.9782812615200 loss: 0.08452443033456802 acc: 0.9762515400 loss: 0.09686124324798584 acc: 0.9732812615600 loss: 0.0802001953125 acc: 0.9729687615800 loss: 0.10131652653217316 acc: 0.972812516000 loss: 0.12712924182415009 acc: 0.9701562516200 loss: 0.10623563826084137 acc: 0.97312516400 loss: 0.07512909919023514 acc: 0.9748437416600 loss: 0.08629828691482544 acc: 0.967516800 loss: 0.09165250509977341 acc: 0.9732812617000 loss: 0.08541638404130936 acc: 0.979687517200 loss: 0.03573321923613548 acc: 0.973906317400 loss: 0.08292931318283081 acc: 0.9751562517600 loss: 0.09117152541875839 acc: 0.974687517800 loss: 0.055078715085983276 acc: 0.9726562518000 loss: 0.07413016259670258 acc: 0.974218718200 loss: 0.10115832090377808 acc: 0.974218718400 loss: 0.06299661844968796 acc: 0.972812518600 loss: 0.056077420711517334 acc: 0.9704687618800 loss: 0.08558100461959839 acc: 0.9785937719000 loss: 0.0742747038602829 acc: 0.980312519200 loss: 0.06931197643280029 acc: 0.973437519400 loss: 0.07148833572864532 acc: 0.976718719600 loss: 0.11700235307216644 acc: 0.973906319800 loss: 0.06992246210575104 acc: 0.973593820000 loss: 0.05687614157795906 acc: 0.975937520200 loss: 0.14907342195510864 acc: 0.9745312320400 loss: 0.1653566211462021 acc: 0.9726562520600 loss: 0.03767940402030945 acc: 0.979531220800 loss: 0.07523676753044128 acc: 0.979218721000 loss: 0.07417837530374527 acc: 0.976562521200 loss: 0.08299359679222107 acc: 0.976406321400 loss: 0.04976201429963112 acc: 0.9776562521600 loss: 0.04690690338611603 acc: 0.97521800 loss: 0.04981674998998642 acc: 0.974687522000 loss: 0.0513470321893692 acc: 0.9782812622200 loss: 0.22548101842403412 acc: 0.97187522400 loss: 0.07231388241052628 acc: 0.9762522600 loss: 0.09100791811943054 acc: 0.982812522800 loss: 0.06141120195388794 acc: 0.9779687523000 loss: 0.0918603241443634 acc: 0.979531223200 loss: 0.04934592917561531 acc: 0.9779687523400 loss: 0.046293482184410095 acc: 0.9757812623600 loss: 0.055974338203668594 acc: 0.9754687523800 loss: 0.10047663748264313 acc: 0.9770312324000 loss: 0.0761006623506546 acc: 0.976562524200 loss: 0.03693201392889023 acc: 0.974218724400 loss: 0.03466993570327759 acc: 0.982187524600 loss: 0.10374853014945984 acc: 0.98187524800 loss: 0.026225175708532333 acc: 0.9825000 loss: 0.10136633366346359 acc: 0.978437525200 loss: 0.07362035661935806 acc: 0.97812525400 loss: 0.10292142629623413 acc: 0.9745312325600 loss: 0.03838391602039337 acc: 0.978437525800 loss: 0.1306307017803192 acc: 0.979062526000 loss: 0.056037187576293945 acc: 0.9754687526200 loss: 0.06480588018894196 acc: 0.980312526400 loss: 0.0460970476269722 acc: 0.9826562426600 loss: 0.11328999698162079 acc: 0.9807812626800 loss: 0.052961524575948715 acc: 0.980937527000 loss: 0.046149395406246185 acc: 0.978437527200 loss: 0.03660104423761368 acc: 0.9785937727400 loss: 0.07231131196022034 acc: 0.9779687527600 loss: 0.0969608873128891 acc: 0.9785937727800 loss: 0.07953917980194092 acc: 0.97812528000 loss: 0.05938175320625305 acc: 0.9776562528200 loss: 0.10404374450445175 acc: 0.98437528400 loss: 0.07486425340175629 acc: 0.9832812528600 loss: 0.06746675819158554 acc: 0.9807812628800 loss: 0.10037437081336975 acc: 0.9807812629000 loss: 0.04371890425682068 acc: 0.979062529200 loss: 0.1544964462518692 acc: 0.9798437429400 loss: 0.06675610691308975 acc: 0.979531229600 loss: 0.11682221293449402 acc: 0.9804687529800 loss: 0.055132970213890076 acc: 0.9776562530000 loss: 0.06676920503377914 acc: 0.984531230200 loss: 0.061399221420288086 acc: 0.98437530400 loss: 0.0784747451543808 acc: 0.98187530600 loss: 0.05704239010810852 acc: 0.98187530800 loss: 0.06897450983524323 acc: 0.9807812631000 loss: 0.09554265439510345 acc: 0.979218731200 loss: 0.07846721261739731 acc: 0.9798437431400 loss: 0.05001729726791382 acc: 0.982812531600 loss: 0.06418764591217041 acc: 0.97812531800 loss: 0.06677256524562836 acc: 0.9807812632000 loss: 0.06099291145801544 acc: 0.9860937632200 loss: 0.02437475323677063 acc: 0.982532400 loss: 0.054472584277391434 acc: 0.9829687532600 loss: 0.07025627791881561 acc: 0.982187532800 loss: 0.043403904885053635 acc: 0.98062533000 loss: 0.05405097454786301 acc: 0.981718833200 loss: 0.07893810421228409 acc: 0.981406333400 loss: 0.04618637263774872 acc: 0.981562533600 loss: 0.03955160081386566 acc: 0.978437533800 loss: 0.06573085486888885 acc: 0.98534000 loss: 0.05302225425839424 acc: 0.985937534200 loss: 0.04989982396364212 acc: 0.982812534400 loss: 0.06038925424218178 acc: 0.983437534600 loss: 0.08686563372612 acc: 0.9823437334800 loss: 0.05421433597803116 acc: 0.980937535000 loss: 0.04355776682496071 acc: 0.982812535200 loss: 0.12376898527145386 acc: 0.9812535400 loss: 0.12621557712554932 acc: 0.9807812635600 loss: 0.025318723171949387 acc: 0.98535800 loss: 0.047489866614341736 acc: 0.984218836000 loss: 0.06456907093524933 acc: 0.9839062736200 loss: 0.05885958671569824 acc: 0.984218836400 loss: 0.038796693086624146 acc: 0.983437536600 loss: 0.028620203956961632 acc: 0.982031236800 loss: 0.03317582234740257 acc: 0.981406337000 loss: 0.03372523933649063 acc: 0.983437537200 loss: 0.18894273042678833 acc: 0.9785937737400 loss: 0.06384888291358948 acc: 0.9823437337600 loss: 0.07211901247501373 acc: 0.987031237800 loss: 0.05046132951974869 acc: 0.984687538000 loss: 0.07783858478069305 acc: 0.98562538200 loss: 0.03523237258195877 acc: 0.984687538400 loss: 0.03408464789390564 acc: 0.982187538600 loss: 0.044989801943302155 acc: 0.982812538800 loss: 0.07720053195953369 acc: 0.9829687539000 loss: 0.05239255353808403 acc: 0.981718839200 loss: 0.026881976053118706 acc: 0.9807812639400 loss: 0.022131649777293205 acc: 0.9860937639600 loss: 0.0717465877532959 acc: 0.986562539800 loss: 0.020211482420563698 acc: 0.9848437340000 loss: 0.09074624627828598 acc: 0.98540200 loss: 0.05809881165623665 acc: 0.9851562440400 loss: 0.08850902318954468 acc: 0.98187540600 loss: 0.02669745683670044 acc: 0.984218840800 loss: 0.11308488249778748 acc: 0.983437541000 loss: 0.0438566729426384 acc: 0.980937541200 loss: 0.04586176574230194 acc: 0.984687541400 loss: 0.036804813891649246 acc: 0.9862541600 loss: 0.09279486536979675 acc: 0.9854687541800 loss: 0.03883099555969238 acc: 0.986718842000 loss: 0.033931516110897064 acc: 0.98542200 loss: 0.03281283751130104 acc: 0.984062542400 loss: 0.05394122377038002 acc: 0.983437542600 loss: 0.0685659870505333 acc: 0.98312542800 loss: 0.058388061821460724 acc: 0.9832812543000 loss: 0.05259823054075241 acc: 0.982543200 loss: 0.0837898999452591 acc: 0.98687543400 loss: 0.06377860903739929 acc: 0.987031243600 loss: 0.04784414917230606 acc: 0.9864062743800 loss: 0.08819957822561264 acc: 0.9864062744000 loss: 0.033343978226184845 acc: 0.9839062744200 loss: 0.1391856074333191 acc: 0.9860937644400 loss: 0.05300295725464821 acc: 0.9848437344600 loss: 0.1040736585855484 acc: 0.9835937644800 loss: 0.041021399199962616 acc: 0.981718845000 loss: 0.050329744815826416 acc: 0.988437545200 loss: 0.04664241150021553 acc: 0.987187545400 loss: 0.06599676609039307 acc: 0.9864062745600 loss: 0.04718659818172455 acc: 0.9876562445800 loss: 0.04680747911334038 acc: 0.9860937646000 loss: 0.0784095823764801 acc: 0.984531246200 loss: 0.062429361045360565 acc: 0.9862546400 loss: 0.03825797885656357 acc: 0.98546600 loss: 0.04770933836698532 acc: 0.98312546800 loss: 0.05306899920105934 acc: 0.98562547000 loss: 0.0469331368803978 acc: 0.9879687447200 loss: 0.018814777955412865 acc: 0.986718847400 loss: 0.04082533344626427 acc: 0.98812547600 loss: 0.05882826820015907 acc: 0.9864062747800 loss: 0.035880930721759796 acc: 0.9860937648000 loss: 0.04324483126401901 acc: 0.9864062748200 loss: 0.06581659615039825 acc: 0.9851562448400 loss: 0.038081344217061996 acc: 0.985312548600 loss: 0.032461464405059814 acc: 0.9829687548800 loss: 0.05362715572118759 acc: 0.9879687449000 loss: 0.04097782447934151 acc: 0.98937549200 loss: 0.038341302424669266 acc: 0.986718849400 loss: 0.05667734891176224 acc: 0.987187549600 loss: 0.06505107134580612 acc: 0.9862549800 loss: 0.048090700060129166 acc: 0.986718850000 loss: 0.038220785558223724 acc: 0.98687550200 loss: 0.10568118095397949 acc: 0.98550400 loss: 0.10147371888160706 acc: 0.98550600 loss: 0.02043035626411438 acc: 0.9889062650800 loss: 0.03445787355303764 acc: 0.987187551000 loss: 0.05728784203529358 acc: 0.987187551200 loss: 0.04533722251653671 acc: 0.9879687451400 loss: 0.03492813929915428 acc: 0.98812551600 loss: 0.020884167402982712 acc: 0.98687551800 loss: 0.025441624224185944 acc: 0.98562552000 loss: 0.026575148105621338 acc: 0.9864062752200 loss: 0.16384227573871613 acc: 0.984218852400 loss: 0.05616907402873039 acc: 0.986718852600 loss: 0.059886958450078964 acc: 0.9889062652800 loss: 0.04272538423538208 acc: 0.9879687453000 loss: 0.06959083676338196 acc: 0.988437553200 loss: 0.026869554072618484 acc: 0.987812553400 loss: 0.027034994214773178 acc: 0.9864062753600 loss: 0.03967958688735962 acc: 0.9879687453800 loss: 0.060415420681238174 acc: 0.9854687554000 loss: 0.03867259994149208 acc: 0.9864062754200 loss: 0.021209895610809326 acc: 0.984531254400 loss: 0.017180444672703743 acc: 0.989218854600 loss: 0.0526532307267189 acc: 0.9889062654800 loss: 0.015818050131201744 acc: 0.987812555000 loss: 0.08110405504703522 acc: 0.9885937655200 loss: 0.04867621138691902 acc: 0.988437555400 loss: 0.07329011708498001 acc: 0.986718855600 loss: 0.0186185110360384 acc: 0.987555800 loss: 0.09356825053691864 acc: 0.9864062756000 loss: 0.034789077937603 acc: 0.9848437356200 loss: 0.03775575011968613 acc: 0.9878125</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(total_loss))]</span><br><span class="line">plt.plot(x,total_loss)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7f8643ca4290&gt;]</code></pre><p>â€‹<br><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210801143549.png" alt="png"><br>â€‹    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(total_acc))]</span><br><span class="line">plt.plot(x,total_acc)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7f8643e6c2d0&gt;]</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210801143559.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlowå­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰TensorFlowåŸºç¡€</title>
      <link href="/2021/07/31/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89TensorFlow%E5%9F%BA%E7%A1%80/"/>
      <url>/2021/07/31/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89TensorFlow%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="TensorFlowå­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰TensorFlowåŸºç¡€"><a href="#TensorFlowå­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰TensorFlowåŸºç¡€" class="headerlink" title="TensorFlowå­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰TensorFlowåŸºç¡€"></a>TensorFlowå­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰TensorFlowåŸºç¡€</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras <span class="keyword">as</span> keras</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras.layers <span class="keyword">as</span> layers</span><br><span class="line"></span><br><span class="line"><span class="comment"># physical_devices = tf.config.experimental.list_physical_devices(&#x27;GPU&#x27;)</span></span><br><span class="line"><span class="comment"># assert len(physical_devices) &gt; 0, &quot;Not enough GPU hardware devices available&quot;</span></span><br><span class="line"><span class="comment"># tf.config.experimental.set_memory_growth(physical_devices[0], True)</span></span><br></pre></td></tr></table></figure><h2 id="æ•°æ®ç±»å‹"><a href="#æ•°æ®ç±»å‹" class="headerlink" title="æ•°æ®ç±»å‹"></a>æ•°æ®ç±»å‹</h2><h3 id="æ•°å€¼ç±»å‹"><a href="#æ•°å€¼ç±»å‹" class="headerlink" title="æ•°å€¼ç±»å‹"></a>æ•°å€¼ç±»å‹</h3><p>æ ‡é‡åœ¨ TensorFlow æ˜¯å¦‚ä½•åˆ›å»ºçš„</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python è¯­è¨€æ–¹å¼åˆ›å»ºæ ‡é‡</span></span><br><span class="line">a = <span class="number">1.2</span> </span><br><span class="line"><span class="comment"># TF æ–¹å¼åˆ›å»ºæ ‡é‡</span></span><br><span class="line">aa = tf.constant(<span class="number">1.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">type</span>(a), <span class="built_in">type</span>(aa), tf.is_tensor(aa)</span><br></pre></td></tr></table></figure><pre><code>(float, tensorflow.python.framework.ops.EagerTensor, True)</code></pre><p>å¦‚æœè¦ä½¿ç”¨ TensorFlow æä¾›çš„åŠŸèƒ½å‡½æ•°ï¼Œ é¡»é€šè¿‡ TensorFlow è§„å®šçš„æ–¹å¼å»åˆ›å»ºå¼ é‡ï¼Œè€Œä¸èƒ½ä½¿ç”¨ Python è¯­è¨€çš„æ ‡å‡†å˜é‡åˆ›å»ºæ–¹å¼ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([<span class="number">1</span>,<span class="number">2.</span>,<span class="number">3.3</span>])</span><br><span class="line"><span class="comment"># æ‰“å° TF å¼ é‡çš„ç›¸å…³ä¿¡æ¯                </span></span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=1, shape=(3,), dtype=float32, numpy=array([1. , 2. , 3.3], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å°† TF å¼ é‡çš„æ•°æ®å¯¼å‡ºä¸º numpy æ•°ç»„æ ¼å¼</span></span><br><span class="line">x.numpy() </span><br></pre></td></tr></table></figure><pre><code>array([1. , 2. , 3.3], dtype=float32)</code></pre><p>ä¸æ ‡é‡ä¸åŒï¼Œå‘é‡çš„å®šä¹‰é¡»é€šè¿‡ List å®¹å™¨ä¼ ç»™ tf.constant()å‡½æ•°ã€‚</p><p>åˆ›å»ºä¸€ä¸ªå…ƒç´ çš„å‘é‡ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºä¸€ä¸ªå…ƒç´ çš„å‘é‡</span></span><br><span class="line">a = tf.constant([<span class="number">1.2</span>]) </span><br><span class="line">a, a.shape</span><br></pre></td></tr></table></figure><pre><code>(&lt;tf.Tensor: id=2, shape=(1,), dtype=float32, numpy=array([1.2], dtype=float32)&gt;, TensorShape([1]))</code></pre><p>åˆ›å»º 3 ä¸ªå…ƒç´ çš„å‘é‡ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># åˆ›å»º 3 ä¸ªå…ƒç´ çš„å‘é‡</span></span><br><span class="line">a = tf.constant([<span class="number">1</span>,<span class="number">2</span>, <span class="number">3.</span>])</span><br><span class="line">a, a.shape</span><br></pre></td></tr></table></figure><pre><code>(&lt;tf.Tensor: id=3, shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)&gt;, TensorShape([3]))</code></pre><p>å®šä¹‰çŸ©é˜µ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º 2 è¡Œ 2 åˆ—çš„çŸ©é˜µ</span></span><br><span class="line">a = tf.constant([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]) </span><br><span class="line">a, a.shape</span><br></pre></td></tr></table></figure><pre><code>(&lt;tf.Tensor: id=4, shape=(2, 2), dtype=int32, numpy= array([[1, 2],        [3, 4]], dtype=int32)&gt;, TensorShape([2, 2]))</code></pre><p>ä¸‰ç»´å¼ é‡å¯ä»¥å®šä¹‰ä¸ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º 3 ç»´å¼ é‡</span></span><br><span class="line">tf.constant([[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]],[[<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>]]]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=5, shape=(2, 2, 2), dtype=int32, numpy=array([[[1, 2],        [3, 4]],       [[5, 6],        [7, 8]]], dtype=int32)&gt;</code></pre><p>é€šè¿‡ä¼ å…¥å­—ç¬¦ä¸²å¯¹è±¡å³å¯åˆ›å»ºå­—ç¬¦ä¸²ç±»å‹çš„å¼ é‡</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºå­—ç¬¦ä¸²</span></span><br><span class="line">a = tf.constant(<span class="string">&#x27;Hello, Deep Learning.&#x27;</span>) </span><br><span class="line">a</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=6, shape=(), dtype=string, numpy=b&#39;Hello, Deep Learning.&#39;&gt;</code></pre><h3 id="å­—ç¬¦ä¸²ç±»å‹"><a href="#å­—ç¬¦ä¸²ç±»å‹" class="headerlink" title="å­—ç¬¦ä¸²ç±»å‹"></a>å­—ç¬¦ä¸²ç±»å‹</h3><p>é€šè¿‡ä¼ å…¥å­—ç¬¦ä¸²å¯¹è±¡å³å¯åˆ›å»ºå­—ç¬¦ä¸²ç±»å‹çš„å¼ é‡</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºå­—ç¬¦ä¸²</span></span><br><span class="line">a = tf.constant(<span class="string">&#x27;Hello, Deep Learning.&#x27;</span>) </span><br><span class="line">a</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=7, shape=(), dtype=string, numpy=b&#39;Hello, Deep Learning.&#39;&gt;</code></pre><p>åœ¨ tf.strings æ¨¡å—ä¸­ï¼Œæä¾›äº†å¸¸è§çš„å­—ç¬¦ä¸²ç±»å‹çš„å·¥å…·å‡½æ•°ï¼Œå¦‚å°å†™åŒ– lower()ã€ æ‹¼æ¥<br>join()ã€ é•¿åº¦ length()ã€ åˆ‡åˆ† split()ç­‰ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å°å†™åŒ–å­—ç¬¦ä¸²</span></span><br><span class="line">tf.strings.lower(a) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=8, shape=(), dtype=string, numpy=b&#39;hello, deep learning.&#39;&gt;</code></pre><h3 id="å¸ƒå°”ç±»å‹"><a href="#å¸ƒå°”ç±»å‹" class="headerlink" title="å¸ƒå°”ç±»å‹"></a>å¸ƒå°”ç±»å‹</h3><p>å¸ƒå°”ç±»å‹çš„å¼ é‡åªéœ€è¦ä¼ å…¥ Python è¯­è¨€çš„å¸ƒå°”ç±»å‹æ•°æ®ï¼Œè½¬æ¢æˆ TensorFlow å†…éƒ¨å¸ƒå°”å‹å³å¯ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºå¸ƒå°”ç±»å‹æ ‡é‡</span></span><br><span class="line">tf.constant(<span class="literal">True</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=9, shape=(), dtype=bool, numpy=True&gt;</code></pre><p>åˆ›å»ºå¸ƒå°”ç±»å‹çš„å‘é‡</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># åˆ›å»ºå¸ƒå°”ç±»å‹å‘é‡</span></span><br><span class="line">tf.constant([<span class="literal">True</span>, <span class="literal">False</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=10, shape=(2,), dtype=bool, numpy=array([ True, False])&gt;</code></pre><p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ TensorFlow çš„å¸ƒå°”ç±»å‹å’Œ Python è¯­è¨€çš„å¸ƒå°”ç±»å‹å¹¶ä¸ç­‰ä»·ï¼Œä¸èƒ½é€šç”¨</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º TF å¸ƒå°”å¼ é‡</span></span><br><span class="line">a = tf.constant(<span class="literal">True</span>) </span><br><span class="line"><span class="comment"># TF å¸ƒå°”ç±»å‹å¼ é‡ä¸ python å¸ƒå°”ç±»å‹æ¯”è¾ƒ</span></span><br><span class="line"><span class="built_in">print</span>(a <span class="keyword">is</span> <span class="literal">True</span>) </span><br><span class="line"><span class="comment"># ä»…æ•°å€¼æ¯”è¾ƒ</span></span><br><span class="line"><span class="built_in">print</span>(a == <span class="literal">True</span>) </span><br></pre></td></tr></table></figure><pre><code>Falsetf.Tensor(True, shape=(), dtype=bool)</code></pre><h2 id="æ•°å€¼ç²¾åº¦"><a href="#æ•°å€¼ç²¾åº¦" class="headerlink" title="æ•°å€¼ç²¾åº¦"></a>æ•°å€¼ç²¾åº¦</h2><p>åœ¨åˆ›å»ºå¼ é‡æ—¶ï¼Œå¯ä»¥æŒ‡å®šå¼ é‡çš„ä¿å­˜ç²¾åº¦</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºæŒ‡å®šç²¾åº¦çš„å¼ é‡</span></span><br><span class="line">tf.constant(<span class="number">123456789</span>, dtype=tf.int16)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=14, shape=(), dtype=int16, numpy=-13035&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.constant(<span class="number">123456789</span>, dtype=tf.int32)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=15, shape=(), dtype=int32, numpy=123456789&gt;</code></pre><p>å¯¹äºæµ®ç‚¹æ•°ï¼Œ é«˜ç²¾åº¦çš„å¼ é‡å¯ä»¥è¡¨ç¤ºæ›´ç²¾å‡†çš„æ•°æ®ï¼Œä¾‹å¦‚é‡‡ç”¨ tf.float32 ç²¾åº¦ä¿å­˜Ï€æ—¶ï¼Œå®é™…ä¿å­˜çš„æ•°æ®ä¸º 3.1415927</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># ä» numpy ä¸­å¯¼å…¥ pi å¸¸é‡</span></span><br><span class="line">np.pi </span><br><span class="line"><span class="comment"># 32 ä½</span></span><br><span class="line">tf.constant(np.pi, dtype=tf.float32) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=16, shape=(), dtype=float32, numpy=3.1415927&gt;</code></pre><p>å¦‚æœé‡‡ç”¨ tf.float64 ç²¾åº¦ä¿å­˜Ï€ï¼Œåˆ™èƒ½è·å¾—æ›´é«˜çš„ç²¾åº¦</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.constant(np.pi, dtype=tf.float64) <span class="comment"># 64 ä½</span></span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=17, shape=(), dtype=float64, numpy=3.141592653589793&gt;</code></pre><h3 id="è¯»å–ç²¾åº¦"><a href="#è¯»å–ç²¾åº¦" class="headerlink" title="è¯»å–ç²¾åº¦"></a>è¯»å–ç²¾åº¦</h3><p>é€šè¿‡è®¿é—®å¼ é‡çš„ dtype æˆå‘˜å±æ€§å¯ä»¥åˆ¤æ–­å¼ é‡çš„ä¿å­˜ç²¾åº¦</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(np.pi, dtype=tf.float16)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¯»å–åŸæœ‰å¼ é‡çš„æ•°å€¼ç²¾åº¦</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;before:&#x27;</span>,a.dtype) </span><br><span class="line"><span class="comment"># å¦‚æœç²¾åº¦ä¸ç¬¦åˆè¦æ±‚ï¼Œåˆ™è¿›è¡Œè½¬æ¢</span></span><br><span class="line"><span class="keyword">if</span> a.dtype != tf.float32: </span><br><span class="line">    <span class="comment"># tf.cast å‡½æ•°å¯ä»¥å®Œæˆç²¾åº¦è½¬æ¢</span></span><br><span class="line">    a = tf.cast(a,tf.float32) </span><br><span class="line"><span class="comment"># æ‰“å°è½¬æ¢åçš„ç²¾åº¦</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;after :&#x27;</span>,a.dtype) </span><br></pre></td></tr></table></figure><pre><code>before: &lt;dtype: &#39;float16&#39;&gt;after : &lt;dtype: &#39;float32&#39;&gt;</code></pre><h3 id="ç±»å‹è½¬æ¢"><a href="#ç±»å‹è½¬æ¢" class="headerlink" title="ç±»å‹è½¬æ¢"></a>ç±»å‹è½¬æ¢</h3><p>ç³»ç»Ÿçš„æ¯ä¸ªæ¨¡å—ä½¿ç”¨çš„æ•°æ®ç±»å‹ã€ æ•°å€¼ç²¾åº¦å¯èƒ½å„ä¸ç›¸åŒï¼Œ å¯¹äºä¸ç¬¦åˆè¦æ±‚çš„å¼ é‡çš„ç±»å‹åŠç²¾åº¦ï¼Œ éœ€è¦é€šè¿‡ tf.cast å‡½æ•°è¿›è¡Œè½¬æ¢</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º tf.float16 ä½ç²¾åº¦å¼ é‡</span></span><br><span class="line">a = tf.constant(np.pi, dtype=tf.float16) </span><br><span class="line"><span class="comment"># è½¬æ¢ä¸ºé«˜ç²¾åº¦å¼ é‡</span></span><br><span class="line">tf.cast(a, tf.double) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=21, shape=(), dtype=float64, numpy=3.140625&gt;</code></pre><p>è¿›è¡Œç±»å‹è½¬æ¢æ—¶ï¼Œéœ€è¦ä¿è¯è½¬æ¢æ“ä½œçš„åˆæ³•æ€§ï¼Œ ä¾‹å¦‚å°†é«˜ç²¾åº¦çš„å¼ é‡è½¬æ¢ä¸ºä½ç²¾åº¦çš„å¼ é‡æ—¶ï¼Œå¯èƒ½å‘ç”Ÿæ•°æ®æº¢å‡ºéšæ‚£ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(<span class="number">123456789</span>, dtype=tf.int32)</span><br><span class="line"><span class="comment"># è½¬æ¢ä¸ºä½ç²¾åº¦æ•´å‹</span></span><br><span class="line">tf.cast(a, tf.int16) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=23, shape=(), dtype=int16, numpy=-13035&gt;</code></pre><p>å¸ƒå°”ç±»å‹ä¸æ•´å‹ä¹‹é—´ç›¸äº’è½¬æ¢ä¹Ÿæ˜¯åˆæ³•çš„ï¼Œ æ˜¯æ¯”è¾ƒå¸¸è§çš„æ“ä½œ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="literal">True</span>, <span class="literal">False</span>])</span><br><span class="line"><span class="comment"># å¸ƒå°”ç±»å‹è½¬æ•´å‹</span></span><br><span class="line">tf.cast(a, tf.int32) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=25, shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)&gt;</code></pre><p>ä¸€èˆ¬é»˜è®¤ 0 è¡¨ç¤º Falseï¼Œ 1 è¡¨ç¤º Trueï¼Œåœ¨ TensorFlow ä¸­ï¼Œå°†é 0 æ•°å­—éƒ½è§†ä¸º Trueï¼Œ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="comment"># æ•´å‹è½¬å¸ƒå°”ç±»å‹</span></span><br><span class="line">tf.cast(a, tf.<span class="built_in">bool</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=27, shape=(4,), dtype=bool, numpy=array([ True, False,  True,  True])&gt;</code></pre><h2 id="å¾…ä¼˜åŒ–å¼ é‡"><a href="#å¾…ä¼˜åŒ–å¼ é‡" class="headerlink" title="å¾…ä¼˜åŒ–å¼ é‡"></a>å¾…ä¼˜åŒ–å¼ é‡</h2><p>TensorFlow å¢åŠ äº†ä¸€ç§ä¸“é—¨çš„æ•°æ®ç±»å‹æ¥æ”¯æŒæ¢¯åº¦ä¿¡æ¯çš„è®°å½•ï¼š tf.Variableã€‚ tf.Variable ç±»å‹åœ¨æ™®é€šçš„å¼ é‡ç±»å‹åŸºç¡€ä¸Šæ·»åŠ äº† nameï¼Œ trainable ç­‰å±æ€§æ¥æ”¯æŒè®¡ç®—å›¾çš„æ„å»ºã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º TF å¼ é‡</span></span><br><span class="line">a = tf.constant([-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]) </span><br><span class="line"><span class="comment"># è½¬æ¢ä¸º Variable ç±»å‹</span></span><br><span class="line">aa = tf.Variable(a) </span><br><span class="line"><span class="comment"># Variable ç±»å‹å¼ é‡çš„å±æ€§</span></span><br><span class="line">aa.name, aa.trainable </span><br></pre></td></tr></table></figure><pre><code>(&#39;Variable:0&#39;, True)</code></pre><p>name å±æ€§ç”¨äºå‘½åè®¡ç®—å›¾ä¸­çš„å˜é‡ï¼Œè¿™å¥—å‘½åä½“ç³»æ˜¯ TensorFlow å†…éƒ¨ç»´æŠ¤çš„ï¼Œ ä¸€èˆ¬ä¸éœ€è¦ç”¨æˆ·å…³æ³¨ name å±æ€§ï¼›<br>trainableå±æ€§è¡¨å¾å½“å‰å¼ é‡æ˜¯å¦éœ€è¦è¢«ä¼˜åŒ–ï¼Œåˆ›å»º Variable å¯¹è±¡æ—¶æ˜¯é»˜è®¤å¯ç”¨ä¼˜åŒ–æ ‡å¿—ï¼Œå¯ä»¥è®¾ç½®trainable=False æ¥è®¾ç½®å¼ é‡ä¸éœ€è¦ä¼˜åŒ–ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç›´æ¥åˆ›å»º Variable å¼ é‡</span></span><br><span class="line">tf.Variable([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Variable &#39;Variable:0&#39; shape=(2, 2) dtype=int32, numpy=array([[1, 2],       [3, 4]], dtype=int32)&gt;</code></pre><h2 id="åˆ›å»ºå¼ é‡"><a href="#åˆ›å»ºå¼ é‡" class="headerlink" title="åˆ›å»ºå¼ é‡"></a>åˆ›å»ºå¼ é‡</h2><h3 id="ä»æ•°ç»„ã€åˆ—è¡¨å¯¹è±¡åˆ›å»º"><a href="#ä»æ•°ç»„ã€åˆ—è¡¨å¯¹è±¡åˆ›å»º" class="headerlink" title="ä»æ•°ç»„ã€åˆ—è¡¨å¯¹è±¡åˆ›å»º"></a>ä»æ•°ç»„ã€åˆ—è¡¨å¯¹è±¡åˆ›å»º</h3><p>é€šè¿‡ tf.convert_to_tensor å‡½æ•°å¯ä»¥åˆ›å»ºæ–° Tensorï¼Œå¹¶å°†ä¿å­˜åœ¨ Python List å¯¹è±¡æˆ–è€…Numpy Array å¯¹è±¡ä¸­çš„æ•°æ®å¯¼å…¥åˆ°æ–° Tensor ä¸­ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä»åˆ—è¡¨åˆ›å»ºå¼ é‡</span></span><br><span class="line">tf.convert_to_tensor([<span class="number">1</span>,<span class="number">2.</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=44, shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä»æ•°ç»„ä¸­åˆ›å»ºå¼ é‡</span></span><br><span class="line">tf.convert_to_tensor(np.array([[<span class="number">1</span>,<span class="number">2.</span>],[<span class="number">3</span>,<span class="number">4</span>]])) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=45, shape=(2, 2), dtype=float64, numpy=array([[1., 2.],       [3., 4.]])&gt;</code></pre><h3 id="åˆ›å»ºå…¨0æˆ–å…¨1å¼ é‡"><a href="#åˆ›å»ºå…¨0æˆ–å…¨1å¼ é‡" class="headerlink" title="åˆ›å»ºå…¨0æˆ–å…¨1å¼ é‡"></a>åˆ›å»ºå…¨0æˆ–å…¨1å¼ é‡</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºå…¨ 0ï¼Œå…¨ 1 çš„æ ‡é‡</span></span><br><span class="line">tf.zeros([]),tf.ones([]) </span><br></pre></td></tr></table></figure><pre><code>(&lt;tf.Tensor: id=46, shape=(), dtype=float32, numpy=0.0&gt;, &lt;tf.Tensor: id=47, shape=(), dtype=float32, numpy=1.0&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºå…¨ 0ï¼Œå…¨ 1 çš„å‘é‡</span></span><br><span class="line">tf.zeros([<span class="number">1</span>]),tf.ones([<span class="number">1</span>]) </span><br></pre></td></tr></table></figure><pre><code>(&lt;tf.Tensor: id=50, shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)&gt;, &lt;tf.Tensor: id=53, shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)&gt;)</code></pre><p>åˆ›å»ºå…¨ 0 çš„çŸ©é˜µ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºå…¨ 0 çŸ©é˜µï¼ŒæŒ‡å®š shape ä¸º 2 è¡Œ 2 åˆ—</span></span><br><span class="line">tf.zeros([<span class="number">2</span>,<span class="number">2</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=56, shape=(2, 2), dtype=float32, numpy=array([[0., 0.],       [0., 0.]], dtype=float32)&gt;</code></pre><p>åˆ›å»ºå…¨ 1 çš„çŸ©é˜µ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºå…¨ 1 çŸ©é˜µï¼ŒæŒ‡å®š shape ä¸º 3 è¡Œ 2 åˆ—</span></span><br><span class="line">tf.ones([<span class="number">3</span>,<span class="number">2</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=59, shape=(3, 2), dtype=float32, numpy=array([[1., 1.],       [1., 1.],       [1., 1.]], dtype=float32)&gt;</code></pre><p>é€šè¿‡ tf.zeros_like, tf.ones_like å¯ä»¥æ–¹ä¾¿åœ°æ–°å»ºä¸æŸä¸ªå¼ é‡ shape ä¸€è‡´ï¼Œ ä¸”å†…å®¹ä¸ºå…¨ 0 æˆ–å…¨ 1 çš„å¼ é‡ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºä¸€ä¸ªçŸ©é˜µ</span></span><br><span class="line">a = tf.ones([<span class="number">2</span>,<span class="number">3</span>]) </span><br><span class="line"><span class="comment"># åˆ›å»ºä¸€ä¸ªä¸ a å½¢çŠ¶ç›¸åŒï¼Œä½†æ˜¯å…¨ 0 çš„æ–°çŸ©é˜µ</span></span><br><span class="line">tf.zeros_like(a) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=63, shape=(2, 3), dtype=float32, numpy=array([[0., 0., 0.],       [0., 0., 0.]], dtype=float32)&gt;</code></pre><p>åˆ›å»ºä¸å¼ é‡Aå½¢çŠ¶ä¸€æ ·çš„å…¨ 1 å¼ é‡</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºä¸€ä¸ªçŸ©é˜µ</span></span><br><span class="line">a = tf.zeros([<span class="number">3</span>,<span class="number">2</span>]) </span><br><span class="line"><span class="comment"># åˆ›å»ºä¸€ä¸ªä¸ a å½¢çŠ¶ç›¸åŒï¼Œä½†æ˜¯å…¨ 1 çš„æ–°çŸ©é˜µ</span></span><br><span class="line">tf.ones_like(a) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=69, shape=(3, 2), dtype=float32, numpy=array([[1., 1.],       [1., 1.],       [1., 1.]], dtype=float32)&gt;</code></pre><h3 id="åˆ›å»ºè‡ªå®šä¹‰æ•°å€¼å¼ é‡"><a href="#åˆ›å»ºè‡ªå®šä¹‰æ•°å€¼å¼ é‡" class="headerlink" title="åˆ›å»ºè‡ªå®šä¹‰æ•°å€¼å¼ é‡"></a>åˆ›å»ºè‡ªå®šä¹‰æ•°å€¼å¼ é‡</h3><p>é€šè¿‡ tf.fill(shape, value)å¯ä»¥åˆ›å»ºå…¨ä¸ºè‡ªå®šä¹‰æ•°å€¼ value çš„å¼ é‡ï¼Œå½¢çŠ¶ç”± shape å‚æ•°æŒ‡å®šã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º-1 çš„æ ‡é‡</span></span><br><span class="line">tf.fill([], -<span class="number">1</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=72, shape=(), dtype=int32, numpy=-1&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º-1 çš„å‘é‡</span></span><br><span class="line">tf.fill([<span class="number">1</span>], -<span class="number">1</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=75, shape=(1,), dtype=int32, numpy=array([-1], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º 2 è¡Œ 2 åˆ—ï¼Œå…ƒç´ å…¨ä¸º 99 çš„çŸ©é˜µ</span></span><br><span class="line">tf.fill([<span class="number">2</span>,<span class="number">2</span>], <span class="number">99</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=78, shape=(2, 2), dtype=int32, numpy=array([[99, 99],       [99, 99]], dtype=int32)&gt;</code></pre><h3 id="åˆ›å»ºå·²çŸ¥åˆ†å¸ƒçš„å¼ é‡"><a href="#åˆ›å»ºå·²çŸ¥åˆ†å¸ƒçš„å¼ é‡" class="headerlink" title="åˆ›å»ºå·²çŸ¥åˆ†å¸ƒçš„å¼ é‡"></a>åˆ›å»ºå·²çŸ¥åˆ†å¸ƒçš„å¼ é‡</h3><p>é€šè¿‡ tf.random.normal(shape, mean=0.0, stddev=1.0)å¯ä»¥åˆ›å»ºå½¢çŠ¶ä¸º shapeï¼Œå‡å€¼ä¸ºmeanï¼Œæ ‡å‡†å·®ä¸º stddev çš„æ­£æ€åˆ†å¸ƒ$\mathcal{N}(mean, stddev^2)$ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºæ ‡å‡†æ­£æ€åˆ†å¸ƒçš„å¼ é‡</span></span><br><span class="line">tf.random.normal([<span class="number">2</span>,<span class="number">2</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=84, shape=(2, 2), dtype=float32, numpy=array([[ 0.8372936 , -0.00487547],       [ 0.5917305 ,  0.9924748 ]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºå‡å€¼ä¸º 1ï¼Œæ ‡å‡†å·®ä¸º 2 çš„æ­£æ€åˆ†å¸ƒçš„å¼ é‡</span></span><br><span class="line">tf.random.normal([<span class="number">2</span>,<span class="number">2</span>], mean=<span class="number">1</span>,stddev=<span class="number">2</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=90, shape=(2, 2), dtype=float32, numpy=array([[1.6426632 , 0.9099915 ],       [1.7133203 , 0.14123482]], dtype=float32)&gt;</code></pre><p>é€šè¿‡ tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.float32)å¯ä»¥åˆ›å»ºé‡‡æ ·è‡ª[minval, maxval)åŒºé—´çš„å‡åŒ€åˆ†å¸ƒçš„å¼ é‡</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºé‡‡æ ·è‡ª[0,1)å‡åŒ€åˆ†å¸ƒçš„çŸ©é˜µ</span></span><br><span class="line">tf.random.uniform([<span class="number">3</span>,<span class="number">2</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=97, shape=(3, 2), dtype=float32, numpy=array([[0.80524087, 0.5057876 ],       [0.5653434 , 0.21946168],       [0.48825264, 0.09415054]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºé‡‡æ ·è‡ª[0,10)å‡åŒ€åˆ†å¸ƒçš„çŸ©é˜µ</span></span><br><span class="line">tf.random.uniform([<span class="number">2</span>,<span class="number">2</span>],maxval=<span class="number">10</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=104, shape=(2, 2), dtype=float32, numpy=array([[8.02882  , 9.814098 ],       [5.9886417, 1.3643861]], dtype=float32)&gt;</code></pre><p>å¦‚æœéœ€è¦å‡åŒ€é‡‡æ ·æ•´å½¢ç±»å‹çš„æ•°æ®ï¼Œå¿…é¡»æŒ‡å®šé‡‡æ ·åŒºé—´çš„æœ€å¤§å€¼ maxval å‚æ•°ï¼ŒåŒæ—¶æŒ‡å®šæ•°æ®ç±»å‹ä¸º tf.int*å‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºé‡‡æ ·è‡ª[0,100)å‡åŒ€åˆ†å¸ƒçš„æ•´å‹çŸ©é˜µ</span></span><br><span class="line">tf.random.uniform([<span class="number">2</span>,<span class="number">2</span>],maxval=<span class="number">100</span>,dtype=tf.int32)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=108, shape=(2, 2), dtype=int32, numpy=array([[ 5, 91],       [33, 20]], dtype=int32)&gt;</code></pre><h3 id="åˆ›å»ºåºåˆ—"><a href="#åˆ›å»ºåºåˆ—" class="headerlink" title="åˆ›å»ºåºåˆ—"></a>åˆ›å»ºåºåˆ—</h3><p>tf.range(limit, delta=1)å¯ä»¥åˆ›å»º[0, limit)ä¹‹é—´ï¼Œæ­¥é•¿ä¸º delta çš„æ•´å‹åºåˆ—ï¼Œä¸åŒ…å« limit æœ¬èº«ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0~10ï¼Œä¸åŒ…å« 10</span></span><br><span class="line">tf.<span class="built_in">range</span>(<span class="number">10</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=112, shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º 0~10ï¼Œæ­¥é•¿ä¸º 2 çš„æ•´å½¢åºåˆ—</span></span><br><span class="line">tf.<span class="built_in">range</span>(<span class="number">10</span>,delta=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=116, shape=(5,), dtype=int32, numpy=array([0, 2, 4, 6, 8], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>,delta=<span class="number">2</span>) <span class="comment"># 1~10</span></span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=120, shape=(5,), dtype=int32, numpy=array([1, 3, 5, 7, 9], dtype=int32)&gt;</code></pre><h2 id="å¼ é‡çš„å…¸å‹åº”ç”¨"><a href="#å¼ é‡çš„å…¸å‹åº”ç”¨" class="headerlink" title="å¼ é‡çš„å…¸å‹åº”ç”¨"></a>å¼ é‡çš„å…¸å‹åº”ç”¨</h2><h3 id="æ ‡é‡"><a href="#æ ‡é‡" class="headerlink" title="æ ‡é‡"></a>æ ‡é‡</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># éšæœºæ¨¡æ‹Ÿç½‘ç»œè¾“å‡º</span></span><br><span class="line">out = tf.random.uniform([<span class="number">4</span>,<span class="number">10</span>]) </span><br><span class="line"><span class="comment"># éšæœºæ„é€ æ ·æœ¬çœŸå®æ ‡ç­¾</span></span><br><span class="line">y = tf.constant([<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>]) </span><br><span class="line"><span class="comment"># one-hot ç¼–ç </span></span><br><span class="line">y = tf.one_hot(y, depth=<span class="number">10</span>) </span><br><span class="line"><span class="comment"># è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ MSE</span></span><br><span class="line">loss = tf.keras.losses.mse(y, out) </span><br><span class="line"><span class="comment"># å¹³å‡ MSE,loss åº”æ˜¯æ ‡é‡</span></span><br><span class="line">loss = tf.reduce_mean(loss) </span><br><span class="line"><span class="built_in">print</span>(loss)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor(0.26203847, shape=(), dtype=float32)</code></pre><ul><li>tf.reduce_mean()å‡½æ•°ç”¨äºè®¡ç®—å¼ é‡tensoræ²¿ç€æŒ‡å®šçš„æ•°è½´ï¼ˆtensorçš„æŸä¸€ç»´åº¦ï¼‰ä¸Šçš„çš„å¹³å‡å€¼ï¼Œä¸»è¦ç”¨ä½œé™ç»´æˆ–è€…è®¡ç®—tensorï¼ˆå›¾åƒï¼‰çš„å¹³å‡å€¼ã€‚</li></ul><h3 id="å‘é‡"><a href="#å‘é‡" class="headerlink" title="å‘é‡"></a>å‘é‡</h3><p>è€ƒè™‘ 2 ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„ç½‘ç»œå±‚ï¼Œ æˆ‘ä»¬åˆ›å»ºé•¿åº¦ä¸º 2 çš„åç½®å‘é‡bï¼Œå¹¶ç´¯åŠ åœ¨æ¯ä¸ªè¾“å‡ºèŠ‚ç‚¹ä¸Šï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># z=wx,æ¨¡æ‹Ÿè·å¾—æ¿€æ´»å‡½æ•°çš„è¾“å…¥ z</span></span><br><span class="line">z = tf.random.normal([<span class="number">4</span>,<span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(z)</span><br><span class="line"><span class="comment"># åˆ›å»ºåç½®å‘é‡</span></span><br><span class="line">b = tf.zeros([<span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># ç´¯åŠ ä¸Šåç½®å‘é‡</span></span><br><span class="line">z = z + b </span><br><span class="line">z</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([[ 0.8107377   1.2481661 ] [-0.9203342  -0.55204725] [ 0.944986    0.00977302] [ 0.65324616  0.9092525 ]], shape=(4, 2), dtype=float32)tf.Tensor([0. 0.], shape=(2,), dtype=float32)&lt;tf.Tensor: id=432714, shape=(4, 2), dtype=float32, numpy=array([[ 0.8107377 ,  1.2481661 ],       [-0.9203342 , -0.55204725],       [ 0.944986  ,  0.00977302],       [ 0.65324616,  0.9092525 ]], dtype=float32)&gt;</code></pre><p>åˆ›å»ºè¾“å…¥èŠ‚ç‚¹æ•°ä¸º 4ï¼Œè¾“å‡ºèŠ‚ç‚¹æ•°ä¸º 3 çš„çº¿æ€§å±‚ç½‘ç»œï¼Œé‚£ä¹ˆå®ƒçš„åç½®å‘é‡ b çš„é•¿åº¦åº”ä¸º 3</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºä¸€å±‚ Wx+bï¼Œè¾“å‡ºèŠ‚ç‚¹ä¸º 3</span></span><br><span class="line">fc = tf.keras.layers.Dense(<span class="number">3</span>) </span><br><span class="line"><span class="comment"># é€šè¿‡ build å‡½æ•°åˆ›å»º W,b å¼ é‡ï¼Œè¾“å…¥èŠ‚ç‚¹ä¸º 4</span></span><br><span class="line">fc.build(input_shape=(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment"># æŸ¥çœ‹åç½®å‘é‡</span></span><br><span class="line">fc.bias </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Variable &#39;bias:0&#39; shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)&gt;</code></pre><h3 id="çŸ©é˜µ"><a href="#çŸ©é˜µ" class="headerlink" title="çŸ©é˜µ"></a>çŸ©é˜µ</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2 ä¸ªæ ·æœ¬ï¼Œç‰¹å¾é•¿åº¦ä¸º 4 çš„å¼ é‡</span></span><br><span class="line">x = tf.random.normal([<span class="number">2</span>,<span class="number">4</span>]) </span><br><span class="line"><span class="comment"># å®šä¹‰ W å¼ é‡</span></span><br><span class="line">w = tf.ones([<span class="number">4</span>,<span class="number">3</span>])</span><br><span class="line"><span class="comment"># å®šä¹‰ b å¼ é‡</span></span><br><span class="line">b = tf.zeros([<span class="number">3</span>]) </span><br><span class="line"><span class="comment"># X@W+b è¿ç®—</span></span><br><span class="line">o = x@w+b </span><br><span class="line">o</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=184, shape=(2, 3), dtype=float32, numpy=array([[-5.028141  , -5.028141  , -5.028141  ],       [ 0.67261326,  0.67261326,  0.67261326]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰å…¨è¿æ¥å±‚çš„è¾“å‡ºèŠ‚ç‚¹ä¸º 3</span></span><br><span class="line">fc = tf.keras.layers.Dense(<span class="number">3</span>) </span><br><span class="line"><span class="comment"># å®šä¹‰å…¨è¿æ¥å±‚çš„è¾“å…¥èŠ‚ç‚¹ä¸º 4</span></span><br><span class="line">fc.build(input_shape=(<span class="number">2</span>,<span class="number">4</span>)) </span><br><span class="line"><span class="comment"># æŸ¥çœ‹æƒå€¼çŸ©é˜µ W</span></span><br><span class="line">fc.kernel </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Variable &#39;kernel:0&#39; shape=(4, 3) dtype=float32, numpy=array([[ 0.5571135 ,  0.40619254,  0.7768836 ],       [-0.61082566, -0.13341528, -0.90817606],       [-0.16371965, -0.00938004,  0.6606846 ],       [ 0.38958526, -0.87978166, -0.36103284]], dtype=float32)&gt;</code></pre><h3 id="ä¸‰ç»´å¼ é‡"><a href="#ä¸‰ç»´å¼ é‡" class="headerlink" title="ä¸‰ç»´å¼ é‡"></a>ä¸‰ç»´å¼ é‡</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è‡ªåŠ¨åŠ è½½ IMDB ç”µå½±è¯„ä»·æ•°æ®é›†</span></span><br><span class="line">(x_train,y_train),(x_test,y_test)=keras.datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># å°†å¥å­å¡«å……ã€æˆªæ–­ä¸ºç­‰é•¿ 80 ä¸ªå•è¯çš„å¥å­</span></span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train,maxlen=<span class="number">80</span>)</span><br><span class="line"><span class="built_in">print</span>(x_train[<span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">x_train.shape</span><br></pre></td></tr></table></figure><pre><code>/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/datasets/imdb.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray.  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/datasets/imdb.py:130: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray.  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])[[  15  256    4    2    7 3766    5  723   36   71   43  530  476   26   400  317   46    7    4    2 1029   13  104   88    4  381   15  297    98   32 2071   56   26  141    6  194 7486   18    4  226   22   21   134  476   26  480    5  144   30 5535   18   51   36   28  224   92    25  104    4  226   65   16   38 1334   88   12   16  283    5   16  4472  113  103   32   15   16 5345   19  178   32] [ 125   68    2 6853   15  349  165 4362   98    5    4  228    9   43     2 1157   15  299  120    5  120  174   11  220  175  136   50    9  4373  228 8255    5    2  656  245 2350    5    4 9837  131  152  491    18    2   32 7464 1212   14    9    6  371   78   22  625   64 1382     9    8  168  145   23    4 1690   15   16    4 1355    5   28    6    52  154  462   33   89   78  285   16  145   95]](25000, 80)</code></pre><p>å¯ä»¥çœ‹åˆ° x_train å¼ é‡çš„ shape ä¸º[25000,80]ï¼Œå…¶ä¸­ 25000 è¡¨ç¤ºå¥å­ä¸ªæ•°ï¼Œ 80 è¡¨ç¤ºæ¯ä¸ªå¥å­å…± 80 ä¸ªå•è¯ï¼Œæ¯ä¸ªå•è¯ä½¿ç”¨æ•°å­—ç¼–ç æ–¹å¼è¡¨ç¤ºã€‚</p><p>æˆ‘ä»¬é€šè¿‡ layers.Embedding å±‚å°†æ•°å­—ç¼–ç çš„å•è¯è½¬æ¢ä¸ºé•¿åº¦ä¸º 100 ä¸ªè¯å‘é‡ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºè¯å‘é‡ Embedding å±‚ç±»</span></span><br><span class="line">embedding = tf.keras.layers.Embedding(<span class="number">10000</span>, <span class="number">100</span>)</span><br><span class="line"><span class="comment"># å°†æ•°å­—ç¼–ç çš„å•è¯è½¬æ¢ä¸ºè¯å‘é‡</span></span><br><span class="line">out = embedding(x_train)</span><br><span class="line">out.shape</span><br></pre></td></tr></table></figure><pre><code>TensorShape([25000, 80, 100])</code></pre><p>å¯ä»¥çœ‹åˆ°ï¼Œç»è¿‡ Embedding å±‚ç¼–ç åï¼Œå¥å­å¼ é‡çš„ shape å˜ä¸º[25000,80,100]ï¼Œå…¶ä¸­ 100 è¡¨ç¤ºæ¯ä¸ªå•è¯ç¼–ç ä¸ºé•¿åº¦æ˜¯ 100 çš„å‘é‡ã€‚</p><h3 id="å››ç»´å¼ é‡"><a href="#å››ç»´å¼ é‡" class="headerlink" title="å››ç»´å¼ é‡"></a>å››ç»´å¼ é‡</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º 32x32 çš„å½©è‰²å›¾ç‰‡è¾“å…¥ï¼Œä¸ªæ•°ä¸º 4</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>])</span><br><span class="line"><span class="comment"># åˆ›å»ºå·ç§¯ç¥ç»ç½‘ç»œ</span></span><br><span class="line">layer = layers.Conv2D(<span class="number">16</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># å‰å‘è®¡ç®—</span></span><br><span class="line">out = layer(x) </span><br><span class="line"><span class="comment"># è¾“å‡ºå¤§å°</span></span><br><span class="line">out.shape </span><br></pre></td></tr></table></figure><pre><code>TensorShape([4, 30, 30, 16])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è®¿é—®å·ç§¯æ ¸å¼ é‡</span></span><br><span class="line">layer.kernel.shape </span><br></pre></td></tr></table></figure><pre><code>TensorShape([3, 3, 3, 16])</code></pre><h2 id="ç´¢å¼•ä¸åˆ‡ç‰‡"><a href="#ç´¢å¼•ä¸åˆ‡ç‰‡" class="headerlink" title="ç´¢å¼•ä¸åˆ‡ç‰‡"></a>ç´¢å¼•ä¸åˆ‡ç‰‡</h2><h3 id="ç´¢å¼•"><a href="#ç´¢å¼•" class="headerlink" title="ç´¢å¼•"></a>ç´¢å¼•</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»º4ç»´å¼ é‡</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>]) </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å–ç¬¬ 1 å¼ å›¾ç‰‡çš„æ•°æ®</span></span><br><span class="line">x[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=265, shape=(32, 32, 3), dtype=float32, numpy=array([[[ 2.2041936 , -1.9026781 ,  0.8702505 ],        [-1.2282028 , -0.33232537,  0.40958533],        [ 0.11558069, -0.95446974, -1.5603778 ],        ...,        [ 1.8689036 ,  1.3471965 ,  0.46157768],        [-0.04014067,  0.8095603 ,  1.0308311 ],        [-0.2001917 , -1.0876633 , -0.35982683]],       [[-0.6193978 , -1.1049955 , -0.06628878],        [ 0.5612249 ,  1.5542006 ,  0.6287516 ],        [ 0.34846973,  0.44159728,  0.8838649 ],        ...,        [-0.7220847 ,  0.67017406,  0.1659171 ],        [ 0.17958985, -0.65319884,  0.39171842],        [ 0.8067303 ,  0.43496   ,  0.2798552 ]],       [[-1.163977  , -0.06057478, -0.4857398 ],        [ 1.3414443 , -0.6038178 , -0.23302878],        [-2.0975337 ,  0.94285005, -0.27974698],        ...,        [-0.5631729 ,  1.0614241 , -0.3096405 ],        [-0.9624238 ,  1.3738877 , -1.8948269 ],        [ 1.132725  , -0.20089822, -1.7373965 ]],       ...,       [[-0.14071971, -0.5568062 ,  0.01075767],        [-1.7140628 ,  1.3289738 , -0.8903278 ],        [-1.0916421 , -0.3162519 , -1.249703  ],        ...,        [ 1.325685  ,  1.5440601 , -0.4913852 ],        [-1.3840119 ,  0.23958059, -0.20719068],        [ 0.877472  ,  1.3066201 , -1.4298698 ]],       [[ 0.3794225 ,  0.8216657 , -0.3639167 ],        [-1.4976484 , -1.0524081 , -1.302156  ],        [ 0.26988387,  0.34318095,  0.06246407],        ...,        [ 2.7228684 , -0.2831678 , -1.0059422 ],        [-0.7020755 , -1.4222299 ,  0.9356876 ],        [ 0.4152088 , -0.04397644, -0.73320246]],       [[ 0.65700305, -1.7467034 , -1.5898855 ],        [ 1.1514107 , -1.0907453 , -0.5877316 ],        [ 0.86260825, -0.59653807,  0.0976033 ],        ...,        [-0.04578071, -1.2980894 ,  0.9463795 ],        [-0.09251038,  0.25678882, -0.1819165 ],        [-0.36038232, -0.53460985,  1.2337509 ]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å–ç¬¬ 1 å¼ å›¾ç‰‡çš„ç¬¬ 2 è¡Œ</span></span><br><span class="line">x[<span class="number">0</span>][<span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=273, shape=(32, 3), dtype=float32, numpy=array([[-0.6193978 , -1.1049955 , -0.06628878],       [ 0.5612249 ,  1.5542006 ,  0.6287516 ],       [ 0.34846973,  0.44159728,  0.8838649 ],       [-0.66014725, -0.29447266, -0.8719525 ],       [-0.53212637,  0.6360704 ,  0.02135803],       [ 0.40355667,  0.14078747, -0.39829007],       [-1.3842081 ,  0.04412093, -0.91313547],       [-0.37355164, -2.0390503 , -0.50824887],       [-0.7682212 ,  1.4448624 , -0.37302288],       [ 0.13697726,  0.57252467, -1.0642116 ],       [-0.17128809,  0.7596571 ,  0.37190843],       [-0.8967074 , -0.18937345, -0.5372808 ],       [ 0.33156198, -0.66581064, -0.21653776],       [-0.11285859, -2.4033732 ,  0.0636418 ],       [-0.31247538, -0.8419992 ,  0.4025044 ],       [ 1.2428769 ,  0.34773824,  0.8888833 ],       [-1.5594406 , -0.0539138 ,  0.7797568 ],       [-0.5584576 ,  0.44812298, -0.26227227],       [-0.4017965 , -1.6668578 , -2.0081973 ],       [ 1.7921695 ,  1.1685921 , -0.537693  ],       [-0.16341975, -0.42829806,  0.09798718],       [ 0.49063244, -0.19753823,  0.28310525],       [ 0.73069364,  0.33411032,  0.06241602],       [ 0.1417386 ,  0.46909812,  0.90380406],       [-0.32593566, -0.98549616,  0.36107165],       [ 1.5818663 , -0.362372  ,  1.0220544 ],       [ 0.26198712, -1.6119221 ,  0.07946812],       [ 1.1173558 , -0.677369  ,  0.9825754 ],       [ 1.2875233 ,  0.2511964 ,  0.9508616 ],       [-0.7220847 ,  0.67017406,  0.1659171 ],       [ 0.17958985, -0.65319884,  0.39171842],       [ 0.8067303 ,  0.43496   ,  0.2798552 ]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å–ç¬¬ 1 å¼ å›¾ç‰‡ï¼Œç¬¬ 2 è¡Œï¼Œç¬¬ 3 åˆ—çš„æ•°æ®</span></span><br><span class="line">x[<span class="number">0</span>][<span class="number">1</span>][<span class="number">2</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=285, shape=(3,), dtype=float32, numpy=array([0.34846973, 0.44159728, 0.8838649 ], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å–ç¬¬ 3 å¼ å›¾ç‰‡ï¼Œç¬¬ 2 è¡Œï¼Œç¬¬ 1 åˆ—çš„åƒç´ ï¼Œ B é€šé“(ç¬¬ 2 ä¸ªé€šé“)é¢œè‰²å¼ºåº¦å€¼</span></span><br><span class="line">x[<span class="number">2</span>][<span class="number">1</span>][<span class="number">0</span>][<span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=301, shape=(), dtype=float32, numpy=-0.39595583&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å–ç¬¬ 2 å¼ å›¾ç‰‡ï¼Œç¬¬ 10 è¡Œï¼Œç¬¬ 3 åˆ—çš„æ•°æ®</span></span><br><span class="line">x[<span class="number">1</span>,<span class="number">9</span>,<span class="number">2</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=305, shape=(3,), dtype=float32, numpy=array([ 0.58523804,  0.50835484, -0.7443932 ], dtype=float32)&gt;</code></pre><h3 id="åˆ‡ç‰‡"><a href="#åˆ‡ç‰‡" class="headerlink" title="åˆ‡ç‰‡"></a>åˆ‡ç‰‡</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¯»å–ç¬¬ 2,3 å¼ å›¾ç‰‡</span></span><br><span class="line">x[<span class="number">1</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=309, shape=(2, 32, 32, 3), dtype=float32, numpy=array([[[[-2.4223676 ,  0.2596306 , -0.5293948 ],         [-0.3967986 ,  0.6624346 ,  0.41745508],         [ 1.5329486 ,  0.30801037,  0.54265577],         ...,         [-1.2883576 , -0.4979994 , -0.5336313 ],         [ 1.9402784 , -0.6301418 ,  1.2783034 ],         [ 0.689839  ,  1.1910218 , -1.9886026 ]],        [[-0.14839938, -0.34305233,  0.30521095],         [ 0.4915458 ,  0.29830953, -0.6410243 ],         [-0.3882759 , -0.1322335 ,  1.2989053 ],         ...,         [ 0.52465385, -1.5790194 ,  1.9075392 ],         [-0.8763953 ,  0.33148092, -1.2615253 ],         [-2.1037416 , -1.7750245 , -0.8264196 ]],        [[ 0.42436486, -2.744681  ,  0.68191504],         [-0.62411004,  1.1706539 ,  0.187509  ],         [ 0.60655576, -1.426237  ,  0.24151424],         ...,         [-1.3997802 ,  0.7346194 , -0.8587046 ],         [-0.04108864,  2.2934608 ,  0.23547095],         [ 2.0110242 ,  0.73926306,  0.20124955]],        ...,        [[ 1.0731583 , -0.3252651 ,  0.75498104],         [ 1.177519  , -0.5143665 , -0.90076303],         [ 0.47401938, -0.43510988, -0.01301517],         ...,         [-1.0437206 , -0.66972613, -0.97535443],         [-0.6570767 , -0.00988437,  0.32322738],         [-0.4847873 ,  0.40703028,  0.06685828]],        [[-1.5480559 ,  0.48287508, -1.4049336 ],         [-0.13378212,  0.5845828 , -0.05725988],         [ 2.9124444 , -1.2632277 ,  1.6553665 ],         ...,         [ 0.9075061 ,  1.5838726 ,  0.01311778],         [-1.538471  , -0.48859388, -0.18985108],         [ 0.7335186 , -0.23191583, -0.6732001 ]],        [[ 0.45795447, -1.0244572 ,  2.6291482 ],         [-0.11982027, -0.66913885,  0.39017648],         [-0.46456242, -1.7838262 ,  1.0729996 ],         ...,         [ 1.6933389 ,  1.4940627 ,  0.14956625],         [-1.2214607 , -0.03956367,  0.54512376],         [ 0.65640074,  1.2754624 , -1.4749504 ]]],</code></pre><p>â€‹<br>           [[[-0.90663576,  0.15839997,  0.32161254],<br>             [-0.9101076 , -0.1349041 ,  0.95145386],<br>             [ 0.378604  , -1.4983795 , -0.48038518],<br>             â€¦,<br>             [ 0.8427316 ,  1.3538293 , -0.21184391],<br>             [-0.30419785, -2.1156309 ,  0.59961736],<br>             [-1.1520345 ,  0.7595469 ,  0.30996034]],</p><pre><code>        [[-1.1446227 , -0.39595583,  0.05506114],         [ 1.1072568 , -0.14321956, -0.83200383],         [-0.12360169, -2.973433  , -0.9375662 ],         ...,         [-0.93852717,  0.16133627,  0.45352787],         [-0.66656876,  0.12624261, -0.7791581 ],         [ 2.5405667 ,  0.7748032 , -2.2527237 ]],        [[ 0.01577527,  1.0519909 , -1.3275864 ],         [ 0.83748966,  1.8404965 , -0.30619964],         [ 1.6023983 , -1.5017103 , -0.30663648],         ...,         [-0.8523438 , -0.3250353 ,  0.9320171 ],         [ 0.32578966, -0.22678792, -0.13579275],         [ 1.7109146 , -1.1671449 ,  0.06491743]],        ...,        [[ 0.44134948,  0.5566953 , -0.47516817],         [-1.2281955 , -0.27368283,  1.4019957 ],         [-0.7539954 , -0.2248977 , -1.0345727 ],         ...,         [-1.0997441 , -0.5867889 ,  0.24920598],         [-1.1366905 , -0.33894378,  1.2943493 ],         [ 0.866115  ,  0.09259874,  0.5898721 ]],        [[-1.042004  , -0.42821613,  0.2879594 ],         [-0.8600638 , -0.4365882 ,  0.82840854],         [ 0.76567596, -0.46973774, -1.0789526 ],         ...,         [-0.19796038,  0.558751  , -0.75277686],         [-0.60283434, -1.0192461 , -0.12388539],         [-0.5070267 ,  0.08337619, -1.4103692 ]],        [[ 0.9950036 , -1.3551532 ,  0.5169268 ],         [ 0.59422225, -0.87916857,  0.7648795 ],         [ 0.32365948, -1.6526997 , -1.1206408 ],         ...,         [ 0.05121538,  1.2883476 , -0.6445231 ],         [ 0.86587644,  0.9763926 , -0.08709614],         [ 1.4661231 , -1.8772072 ,  0.2751547 ]]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¯»å–ç¬¬ä¸€å¼ å›¾ç‰‡</span></span><br><span class="line">x[<span class="number">0</span>,::] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=313, shape=(32, 32, 3), dtype=float32, numpy=array([[[ 2.2041936 , -1.9026781 ,  0.8702505 ],        [-1.2282028 , -0.33232537,  0.40958533],        [ 0.11558069, -0.95446974, -1.5603778 ],        ...,        [ 1.8689036 ,  1.3471965 ,  0.46157768],        [-0.04014067,  0.8095603 ,  1.0308311 ],        [-0.2001917 , -1.0876633 , -0.35982683]],       [[-0.6193978 , -1.1049955 , -0.06628878],        [ 0.5612249 ,  1.5542006 ,  0.6287516 ],        [ 0.34846973,  0.44159728,  0.8838649 ],        ...,        [-0.7220847 ,  0.67017406,  0.1659171 ],        [ 0.17958985, -0.65319884,  0.39171842],        [ 0.8067303 ,  0.43496   ,  0.2798552 ]],       [[-1.163977  , -0.06057478, -0.4857398 ],        [ 1.3414443 , -0.6038178 , -0.23302878],        [-2.0975337 ,  0.94285005, -0.27974698],        ...,        [-0.5631729 ,  1.0614241 , -0.3096405 ],        [-0.9624238 ,  1.3738877 , -1.8948269 ],        [ 1.132725  , -0.20089822, -1.7373965 ]],       ...,       [[-0.14071971, -0.5568062 ,  0.01075767],        [-1.7140628 ,  1.3289738 , -0.8903278 ],        [-1.0916421 , -0.3162519 , -1.249703  ],        ...,        [ 1.325685  ,  1.5440601 , -0.4913852 ],        [-1.3840119 ,  0.23958059, -0.20719068],        [ 0.877472  ,  1.3066201 , -1.4298698 ]],       [[ 0.3794225 ,  0.8216657 , -0.3639167 ],        [-1.4976484 , -1.0524081 , -1.302156  ],        [ 0.26988387,  0.34318095,  0.06246407],        ...,        [ 2.7228684 , -0.2831678 , -1.0059422 ],        [-0.7020755 , -1.4222299 ,  0.9356876 ],        [ 0.4152088 , -0.04397644, -0.73320246]],       [[ 0.65700305, -1.7467034 , -1.5898855 ],        [ 1.1514107 , -1.0907453 , -0.5877316 ],        [ 0.86260825, -0.59653807,  0.0976033 ],        ...,        [-0.04578071, -1.2980894 ,  0.9463795 ],        [-0.09251038,  0.25678882, -0.1819165 ],        [-0.36038232, -0.53460985,  1.2337509 ]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[:,<span class="number">0</span>:<span class="number">28</span>:<span class="number">2</span>,<span class="number">0</span>:<span class="number">28</span>:<span class="number">2</span>,:]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=317, shape=(4, 14, 14, 3), dtype=float32, numpy=array([[[[ 2.2041936 , -1.9026781 ,  0.8702505 ],         [ 0.11558069, -0.95446974, -1.5603778 ],         [-0.10582599,  0.4360513 ,  0.37447408],         ...,         [-0.04653996,  1.6447414 ,  0.5684349 ],         [ 0.9232003 , -0.30295762, -0.33417934],         [-1.0266304 , -1.0249001 , -0.05951962]],        [[-1.163977  , -0.06057478, -0.4857398 ],         [-2.0975337 ,  0.94285005, -0.27974698],         [ 0.8568684 , -2.3641932 , -2.787721  ],         ...,         [-0.02272389,  0.7538776 ,  0.05307977],         [ 1.3103249 , -2.8305936 , -0.02025553],         [ 0.72770905, -0.2757186 , -1.2772908 ]],        [[-0.48045605,  0.7057281 ,  0.767962  ],         [ 1.4860299 , -1.2072684 , -2.6429942 ],         [-2.1154718 , -0.4968008 ,  0.40296978],         ...,         [ 0.6735097 , -0.37706473,  0.30742761],         [ 1.5466257 ,  0.01344285,  0.4478075 ],         [ 0.52647936,  0.3019742 , -0.04138045]],        ...,        [[ 0.06652974, -1.310362  ,  0.52491206],         [ 0.20300347,  0.4878598 ,  1.1967695 ],         [ 0.26188427, -1.1881219 , -0.8308305 ],         ...,         [-0.9027409 ,  0.49990463, -0.31936365],         [ 0.14605626,  1.6312102 ,  0.5990152 ],         [-0.22002122,  1.550344  ,  0.8017888 ]],        [[-1.8214884 ,  0.18888037, -0.7315172 ],         [ 1.1054498 ,  0.02177003, -0.80032647],         [ 0.832248  ,  0.30545396, -0.00517098],         ...,         [-0.8079335 , -1.0006244 ,  1.7094636 ],         [ 0.3665858 ,  0.12043276,  1.5349431 ],         [ 1.451506  ,  1.7146869 ,  1.1798096 ]],        [[-0.02927143, -0.662752  ,  1.7197117 ],         [-0.07830945,  0.19495389,  1.0558871 ],         [ 0.09200678, -2.0492928 , -1.149692  ],         ...,         [ 0.84948075, -0.7274614 , -0.6107158 ],         [-1.04149   , -0.8495479 ,  0.4960098 ],         [-0.00758181,  1.1287268 , -1.1791425 ]]],</code></pre><p>â€‹<br>           [[[-2.4223676 ,  0.2596306 , -0.5293948 ],<br>             [ 1.5329486 ,  0.30801037,  0.54265577],<br>             [-0.25038302, -1.505699  ,  0.22218615],<br>             â€¦,<br>             [ 1.8112099 , -0.4017005 ,  0.316382  ],<br>             [-0.18795913,  0.21327318,  0.13639478],<br>             [ 0.88907754, -1.068848  ,  0.49985337]],</p><pre><code>        [[ 0.42436486, -2.744681  ,  0.68191504],         [ 0.60655576, -1.426237  ,  0.24151424],         [ 0.83602005,  0.02829585, -0.19792575],         ...,         [-0.4921264 ,  0.47025818, -0.20402747],         [-0.19556889,  0.71231675, -1.1210784 ],         [-0.50484693,  0.29336897,  0.0850678 ]],        [[-0.3722062 ,  0.18532671,  1.7206814 ],         [-0.85221314,  0.557481  ,  1.8532947 ],         [-0.05675818, -0.56605554, -0.846615  ],         ...,         [ 0.0248818 , -1.263318  ,  1.0077718 ],         [ 1.1570826 ,  0.1613118 ,  0.20786911],         [-1.0473794 ,  1.0830846 ,  1.0416656 ]],        ...,        [[ 0.0331895 ,  1.7457578 , -0.35708535],         [ 1.0369142 , -0.62837493, -0.5342489 ],         [ 0.7757275 ,  0.535828  , -2.2308693 ],         ...,         [-0.9503758 , -1.3476964 ,  0.17882505],         [-0.25491032, -0.85506326, -2.003958  ],         [ 0.92684764, -0.4062368 , -1.5470201 ]],        [[-0.9265145 , -1.143782  , -0.9362721 ],         [ 0.9630645 ,  0.65629876,  1.1364145 ],         [ 2.0485058 , -0.6168327 ,  0.16756117],         ...,         [ 1.1698273 ,  2.6709888 , -0.45540768],         [-0.3581334 ,  1.1361488 ,  1.4096297 ],         [-0.03351761, -0.9961699 ,  0.81231606]],        [[ 0.26294824, -0.0122492 , -1.2524768 ],         [ 0.19943246,  0.7689961 ,  0.2076496 ],         [ 0.22466388,  0.8513927 , -0.12332796],         ...,         [ 0.13668203, -0.14629023, -0.49706447],         [ 1.6254246 ,  1.1169688 ,  0.69922197],         [ 0.38690066,  1.3984909 , -0.7125247 ]]],</code></pre><p>â€‹<br>           [[[-0.90663576,  0.15839997,  0.32161254],<br>             [ 0.378604  , -1.4983795 , -0.48038518],<br>             [-0.0130377 , -0.6399751 ,  0.7394333 ],<br>             â€¦,<br>             [-0.6753409 ,  0.01053149, -1.4270033 ],<br>             [ 1.1157323 , -0.5980183 ,  0.49497938],<br>             [ 1.4786468 , -0.4598702 , -0.08252096]],</p><pre><code>        [[ 0.01577527,  1.0519909 , -1.3275864 ],         [ 1.6023983 , -1.5017103 , -0.30663648],         [ 1.065943  ,  1.1778338 , -0.5005816 ],         ...,         [-1.4590057 ,  0.95748615,  1.4595517 ],         [ 0.9277145 ,  0.87606174,  0.69505954],         [-1.105703  , -0.0888804 , -0.15580973]],        [[-0.08234025,  1.0907137 , -2.2424757 ],         [-1.2051404 , -0.03379055,  0.74277437],         [ 0.24598132, -0.5550462 ,  0.8092795 ],         ...,         [-2.91178   ,  0.20674153,  0.40773728],         [-0.28130236, -1.4947956 ,  0.0447046 ],         [-1.4446735 , -0.08543364, -1.2267051 ]],        ...,        [[ 0.12023102,  1.2192281 ,  1.8644665 ],         [ 0.71077096, -0.407154  , -0.3728209 ],         [-1.4906154 ,  1.4894596 ,  2.1380718 ],         ...,         [ 0.1265301 , -0.46740493,  0.03761578],         [-0.7213555 , -0.2611885 ,  2.1900265 ],         [-0.32233417, -0.7339213 ,  1.4348257 ]],        [[ 0.15944216,  1.0575757 , -0.32219157],         [ 1.0994414 ,  0.89874107, -0.74534416],         [ 0.55564195,  0.22377524,  0.79618496],         ...,         [-1.1586384 , -0.5727887 ,  0.0525245 ],         [ 1.1248014 , -0.3213812 , -0.6321217 ],         [ 1.1729585 ,  0.6997143 , -1.1535952 ]],        [[ 0.1488529 , -0.5701219 ,  0.6574311 ],         [ 0.7145128 , -0.57302225,  0.7365589 ],         [-1.3955393 ,  0.2823049 , -0.25600722],         ...,         [-1.3540319 ,  0.27442855, -0.48966768],         [ 2.1693397 , -0.41355062, -0.1416041 ],         [-0.6702472 , -0.21834244,  0.3533043 ]]],</code></pre><p>â€‹<br>           [[[-1.2110972 , -0.9158722 ,  0.4041985 ],<br>             [-0.08361922,  0.46396288,  0.6809368 ],<br>             [-0.3673456 ,  0.902671  , -0.4238117 ],<br>             â€¦,<br>             [-1.4638704 ,  0.10005575,  0.33722964],<br>             [-0.5335524 , -0.07159513, -0.98311245],<br>             [ 0.35258508, -0.7577552 ,  0.00567928]],</p><pre><code>        [[ 0.8245692 ,  1.0927265 , -0.5207532 ],         [-0.1369488 , -0.3078722 , -1.3035924 ],         [-0.45273212, -0.2587627 , -0.85130745],         ...,         [ 1.0517457 , -1.6728585 , -0.07226256],         [ 0.68702376,  1.2428858 ,  0.93717146],         [-1.006323  , -0.5241735 ,  0.77420044]],        [[-0.51503855, -0.1137079 ,  0.52393454],         [-1.1306531 , -0.38302454, -0.16332257],         [ 1.2486451 ,  0.33851364,  0.2546582 ],         ...,         [ 1.7983892 , -1.6029406 ,  0.42837998],         [-0.44229293, -1.100362  ,  0.43953687],         [ 0.0773904 ,  0.14096828, -0.69741434]],        ...,        [[-1.687785  ,  0.19534737,  0.84400016],         [ 1.4822593 ,  0.51837   , -0.5977481 ],         [ 0.72277683, -0.84718037, -1.4383492 ],         ...,         [ 0.09861249,  2.7846844 ,  0.06162486],         [ 0.9868257 ,  0.8325828 , -1.0587668 ],         [ 1.9446942 , -0.40730464,  0.8500739 ]],        [[-1.3877448 , -0.56070095,  0.57353336],         [ 0.23248737, -0.5203832 , -0.26604426],         [ 0.22834507, -0.02200814,  0.56439346],         ...,         [-0.8777562 , -0.42350784, -0.05138672],         [-0.67386514,  0.6522291 , -0.8428607 ],         [-0.1801546 , -0.2436022 , -0.32848358]],        [[ 0.15476868, -1.3199596 , -1.1284592 ],         [ 2.1280808 ,  0.68520063,  0.5801554 ],         [ 0.4836316 , -0.4967644 , -0.5746127 ],         ...,         [-1.9212904 ,  0.39191443, -2.5196192 ],         [-0.04232699, -0.31231558, -1.8565068 ],         [-1.2433186 , -1.3967386 , -3.036623  ]]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è€ƒè™‘ä¸€ä¸ª 0~9 çš„ç®€å•åºåˆ—å‘é‡ï¼Œ é€†åºå–åˆ°ç¬¬ 1 å·å…ƒç´ ï¼Œä¸åŒ…å«ç¬¬ 1 å·</span></span><br><span class="line"><span class="comment"># åˆ›å»º 0~9 å‘é‡</span></span><br><span class="line">x = tf.<span class="built_in">range</span>(<span class="number">9</span>) </span><br><span class="line"><span class="comment"># ä» 8 å–åˆ° 0ï¼Œé€†åºï¼Œä¸åŒ…å« 0</span></span><br><span class="line">x[<span class="number">8</span>:<span class="number">0</span>:-<span class="number">1</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=325, shape=(8,), dtype=int32, numpy=array([8, 7, 6, 5, 4, 3, 2, 1], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é€†åºå…¨éƒ¨å…ƒç´ </span></span><br><span class="line">x[::-<span class="number">1</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=329, shape=(9,), dtype=int32, numpy=array([8, 7, 6, 5, 4, 3, 2, 1, 0], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é€†åºé—´éš”é‡‡æ ·</span></span><br><span class="line">x[::-<span class="number">2</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=333, shape=(5,), dtype=int32, numpy=array([8, 6, 4, 2, 0], dtype=int32)&gt;</code></pre><p>è¯»å–æ¯å¼ å›¾ç‰‡çš„æ‰€æœ‰é€šé“ï¼Œå…¶ä¸­è¡ŒæŒ‰ç€é€†åºéš”è¡Œé‡‡æ ·ï¼Œåˆ—æŒ‰ç€é€†åºéš”è¡Œé‡‡æ ·</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>])</span><br><span class="line"><span class="comment"># è¡Œã€åˆ—é€†åºé—´éš”é‡‡æ ·</span></span><br><span class="line">x[<span class="number">0</span>,::-<span class="number">2</span>,::-<span class="number">2</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=343, shape=(16, 16, 3), dtype=float32, numpy=array([[[ 1.32819211e+00, -1.52891368e-01, -2.68408567e-01],        [-1.74235809e+00,  5.97050309e-01, -2.14324856e+00],        [-1.28296447e+00,  6.17663026e-01,  1.12792604e-01],        [-2.07204247e+00, -1.18166316e+00, -8.19493711e-01],        [-1.47719014e+00, -7.35922277e-01, -3.67488146e-01],        [-3.82268518e-01,  8.88675451e-03,  1.29524207e+00],        [-3.21091980e-01,  2.21426225e+00,  9.91399765e-01],        [ 2.05135364e-02,  1.74879110e+00, -2.37907872e-01],        [-2.91886926e-01, -9.75054145e-01, -8.84131372e-01],        [-1.99409172e-01, -9.77180898e-02, -6.13150775e-01],        [-2.09669054e-01, -3.75757724e-01,  9.72125709e-01],        [ 8.99972498e-01, -1.29678416e+00, -1.20591462e+00],        [-1.59504545e+00,  1.60751998e+00,  1.36306405e-01],        [-1.19246662e+00, -1.64794803e+00,  1.45283183e-02],        [ 4.74597424e-01, -1.27889240e+00,  4.06340212e-02],        [-1.79539633e+00, -9.81691927e-02, -6.85885489e-01]],       [[-1.05812716e+00, -1.30784822e+00, -6.80017769e-01],        [ 3.65186512e-01, -3.48650187e-01, -1.54725778e+00],        [ 1.51886746e-01, -2.09844962e-01,  1.39984548e+00],        [-5.62044561e-01, -1.41484439e+00, -4.25017208e-01],        [-6.71886727e-02,  1.13901690e-01,  1.71582669e-01],        [ 1.66557586e+00, -9.23811913e-01, -1.95637453e+00],        [-6.33425772e-01, -2.03683758e+00, -5.52891195e-01],        [ 4.30578351e-01,  4.01591599e-01,  7.07811356e-01],        [ 7.40033031e-01,  7.59029865e-01, -4.48047101e-01],        [-4.86449093e-01, -7.00091779e-01,  5.79828203e-01],        [ 1.56244147e+00, -7.40261674e-01, -7.41748929e-01],        [-3.04721802e-01,  3.59575897e-01,  9.25536156e-01],        [ 9.93468523e-01,  9.88783717e-01,  9.81922805e-01],        [ 1.08223462e+00,  7.46599495e-01,  5.29822886e-01],        [ 3.31095785e-01, -4.47714269e-01, -4.05531228e-01],        [ 1.60369647e+00, -5.92184007e-01,  2.54667439e-02]],       [[-4.86227632e-01, -1.10030425e+00,  9.10474122e-01],        [-9.61585999e-01, -1.19987130e+00,  4.75821495e-01],        [ 2.26800650e-01, -4.53597531e-02,  4.84708756e-01],        [ 9.83571932e-02, -5.63235462e-01, -7.65108049e-01],        [-4.45220917e-01,  1.46985579e+00, -3.55396181e-01],        [-6.69205308e-01, -9.33043242e-01, -9.96201992e-01],        [ 7.35680684e-02,  5.58141649e-01, -5.32615781e-01],        [ 6.23787344e-01,  6.98106110e-01,  5.59944332e-01],        [ 1.89795434e-01,  5.20511985e-01,  3.45360667e-01],        [-5.39386809e-01,  7.92361617e-01,  7.72233069e-01],        [-1.37562764e+00, -7.65306532e-01,  1.22537184e+00],        [-9.93735671e-01, -2.28927445e+00, -3.30761880e-01],        [ 3.47521663e-01,  1.81813228e+00,  1.49911916e+00],        [-5.90717047e-03, -3.43079537e-01, -6.15450263e-01],        [ 6.11240566e-01,  6.44246340e-01, -7.47387826e-01],        [-3.00381750e-01,  3.15724164e-01,  1.64138222e+00]],       [[ 1.14825201e+00,  1.13074481e+00, -4.92495179e-01],        [ 2.25241870e-01, -5.84089123e-02,  9.25830454e-02],        [-1.82172522e-01, -9.57806230e-01, -3.77334505e-01],        [ 3.15930390e+00, -5.52801453e-02,  1.61293708e-02],        [ 4.44656760e-01,  1.07683194e+00,  9.81891006e-02],        [-1.31772089e+00,  1.09420873e-01,  1.52856982e+00],        [-2.39866480e-01, -6.98523045e-01, -1.24893987e+00],        [ 1.29468739e+00,  3.06010634e-01, -5.18583715e-01],        [-4.67290908e-01,  2.67672628e-01,  7.30149746e-02],        [-1.74860966e+00,  9.92399633e-01, -7.79615223e-01],        [ 2.40579620e-01,  2.39096731e-01, -1.05543458e+00],        [-2.80319154e-01, -3.87402582e+00,  5.01442015e-01],        [ 8.12131941e-01,  5.19016683e-01, -9.54104364e-01],        [ 1.14224434e+00,  6.78500652e-01, -1.34504056e+00],        [ 3.85929286e-01,  9.36694257e-03, -5.74368834e-01],        [-3.63719165e-01,  2.71460544e-02,  2.09300327e+00]],       [[-2.35270150e-02, -2.96098262e-01,  8.58490467e-01],        [-1.98163879e+00, -8.91919672e-01, -4.12080497e-01],        [ 2.83049166e-01, -3.09135169e-01, -1.37894654e+00],        [ 9.72408593e-01, -3.07032514e+00,  6.41499221e-01],        [-5.71825683e-01,  1.70615464e-01,  2.49677584e-01],        [-2.03208899e+00, -4.59082909e-02, -1.12768102e+00],        [-5.74081719e-01,  1.36184072e+00, -1.35754287e+00],        [-7.02018738e-01, -1.22644699e+00,  1.23843646e+00],        [-1.86847806e+00, -7.55038798e-01, -1.55198109e+00],        [ 1.59925127e+00, -1.77682626e+00, -4.47454542e-01],        [-8.89484346e-01,  4.06048335e-02, -2.12907586e-02],        [ 1.55495811e+00, -9.46091533e-01, -1.12370884e+00],        [-6.63149476e-01, -1.48054332e-01, -8.66370499e-01],        [-9.72609699e-01,  8.09224486e-01, -1.08757228e-01],        [-1.84078431e+00, -1.07596278e+00, -8.74609530e-01],        [ 9.88747358e-01,  9.55015272e-02, -2.35948014e+00]],       [[ 1.40270567e+00,  1.50841713e-01, -5.54310754e-02],        [ 2.03900361e+00, -2.81785190e-01,  4.42986637e-02],        [ 1.21783614e+00, -1.34693730e+00, -1.44243157e+00],        [ 5.76931775e-01,  1.62811887e+00,  6.39955223e-01],        [-1.74793065e+00,  2.07304955e-01, -2.25865468e-01],        [-4.15330142e-01, -1.55576670e+00, -1.13930893e+00],        [ 1.11974978e+00, -1.79331243e-01, -9.33242738e-01],        [-5.40467203e-01, -8.10507298e-01,  7.65565455e-01],        [-1.25150323e-01,  2.45413408e-01, -8.35556448e-01],        [-6.55914128e-01, -5.80529928e-01, -1.20343566e-01],        [-2.26229757e-01, -1.95507139e-01, -1.70554236e-01],        [-3.00912589e-01, -4.94531870e-01,  1.16584015e+00],        [ 4.59960520e-01,  6.07771397e-01,  4.26176339e-02],        [ 7.55990624e-01, -1.91223100e-02, -3.85362864e-01],        [-1.14951158e+00,  6.91074133e-01,  1.67067599e+00],        [-3.21438015e-01, -7.53839314e-02, -9.35887218e-01]],       [[ 5.47035635e-01, -5.23284450e-02,  4.02895719e-01],        [ 1.32033587e-01, -4.70424891e-01,  1.16757905e+00],        [ 3.76113653e-01,  1.76386505e-01, -1.63666332e+00],        [ 6.88591599e-01, -2.48966232e-01,  1.59020257e+00],        [-4.79439110e-01,  1.28868616e+00,  2.21981835e+00],        [ 5.40017374e-02,  6.91947281e-01,  1.94959357e-01],        [-9.36701447e-02,  3.91052485e-01, -4.17478114e-01],        [-1.12415302e+00,  1.05244577e-01, -8.60867977e-01],        [-3.53260577e-01,  8.07365239e-01,  1.98053196e-01],        [ 1.44271660e+00, -4.19594377e-01, -1.77386373e-01],        [ 1.36769521e+00, -1.38748944e+00,  5.03023248e-03],        [-2.43702188e-01, -1.36886001e+00,  4.11833525e-01],        [ 3.02441150e-01, -4.80698109e-01, -1.39226437e+00],        [ 2.36330613e-01,  1.66690373e+00,  2.00038359e-01],        [-1.22779334e+00, -1.39988613e+00, -3.50548536e-01],        [ 2.32266456e-01, -7.95637667e-01,  1.97104156e+00]],       [[-5.69649875e-01, -2.46080613e+00, -9.10816312e-01],        [-1.53168082e-01,  2.16495895e+00, -1.27430940e+00],        [-1.75009024e+00,  5.70950091e-01, -9.35105205e-01],        [-2.02183932e-01, -7.59766936e-01,  2.29213595e-01],        [-1.39746463e+00,  2.65763164e-01, -4.06110078e-01],        [-1.84702861e+00, -6.93249941e-01,  9.25590456e-01],        [ 1.45949423e-01, -4.35498893e-01,  1.90595949e+00],        [-3.57079446e-01, -1.51399589e+00, -9.99029800e-02],        [-9.42782313e-02,  1.21779490e+00,  3.88828933e-01],        [ 2.00789642e+00,  1.02215707e-02,  3.21455784e-02],        [ 1.45261729e+00, -8.86097327e-02, -6.89221799e-01],        [-2.26393327e-01,  6.15001380e-01, -1.28379261e+00],        [-2.23580487e-02,  9.74746525e-01, -9.66164768e-01],        [ 3.50023448e-01,  1.82733262e+00, -2.53733128e-01],        [-1.11022592e+00, -1.86617315e+00, -2.11713147e+00],        [ 2.80960530e-01, -4.51435268e-01,  1.90480697e+00]],       [[-2.77264547e+00,  9.57480609e-01,  6.22376800e-01],        [ 9.52174425e-01, -4.27199155e-01,  1.14266515e+00],        [ 8.86744082e-01, -6.22356236e-01, -5.81559777e-01],        [ 5.89285254e-01, -6.01863384e-01,  1.73346370e-01],        [ 1.54971564e+00, -8.13169956e-01,  1.47795677e+00],        [-4.01796371e-01, -1.46614432e+00,  1.30820823e+00],        [-2.98423506e-02,  1.06418443e+00, -4.78232026e-01],        [ 1.82253325e+00, -3.88808012e-01,  1.80159080e+00],        [ 1.64312124e-01,  1.27614602e-01, -1.71271533e-01],        [-1.74178255e+00,  9.71022546e-01,  1.55694091e+00],        [ 2.64798254e-01, -1.31978318e-01, -1.27089739e-01],        [-2.90385246e-01, -2.81607056e+00, -2.51615524e-01],        [ 1.50572884e+00,  1.02218115e+00,  1.16663694e-01],        [ 3.35120916e-01, -8.72932673e-01, -6.25664711e-01],        [-3.21538270e-01, -7.99890280e-01, -6.18392229e-01],        [ 3.06067228e+00, -1.26156688e-01,  1.18348384e+00]],       [[-5.11001945e-01,  1.37932420e+00, -3.48675430e-01],        [ 2.76659799e+00, -4.34706032e-01,  1.66739762e-01],        [-1.10698283e-01, -7.76158631e-01,  1.86271176e-01],        [ 1.22287059e+00,  8.22692811e-01,  7.54150748e-01],        [ 4.93106544e-01,  6.56304955e-01,  1.21033490e+00],        [ 3.89292389e-01,  1.74910271e+00,  4.62190390e-01],        [ 2.27324545e-01,  5.73735595e-01, -2.48087004e-01],        [-3.79279375e-01,  3.78067166e-01,  1.46806073e+00],        [ 2.30334461e-01, -1.67860663e+00, -7.74816453e-01],        [ 6.61772549e-01,  9.88777637e-01, -2.18693733e+00],        [ 1.29639733e+00, -2.89914489e-01, -6.09108448e-01],        [-5.62642634e-01,  1.12929857e+00,  1.78704515e-01],        [ 1.59194541e+00,  4.59247902e-02,  3.04074079e-01],        [-9.05971676e-02,  2.23558825e-02,  6.90295696e-01],        [-1.76028121e+00,  1.30459869e+00,  1.10061681e+00],        [ 5.74148335e-02,  1.37532806e+00, -5.93708098e-01]],       [[-5.62136054e-01,  1.11537382e-01,  1.86342442e+00],        [-7.76148736e-01, -8.18978250e-01,  1.35009933e+00],        [-4.34110254e-01, -5.29790819e-01, -6.76819623e-01],        [ 8.09686065e-01,  1.00224167e-01, -1.14079773e+00],        [ 6.72304094e-01,  8.45222652e-01,  8.68369520e-01],        [ 1.88847947e+00,  6.60299420e-01, -1.01915455e+00],        [ 4.52204853e-01, -7.47173548e-01, -1.01478136e+00],        [ 6.49616838e-01, -3.51152241e-01, -3.22207630e-01],        [-1.56287539e+00, -8.39486599e-01,  4.92055297e-01],        [ 1.12434494e+00, -4.15864557e-01,  2.98760504e-01],        [-4.64543775e-02,  5.32227039e-01,  5.67610443e-01],        [-2.64979064e-01,  5.11899471e-01, -5.91439664e-01],        [-1.96026877e-01,  1.25646031e+00, -2.65661448e-01],        [ 1.50221694e+00, -6.95784390e-01, -4.32838410e-01],        [-9.25149560e-01,  1.55666733e+00,  7.89082229e-01],        [ 1.03696835e+00,  1.14898336e+00,  2.37887636e-01]],       [[ 4.73943323e-01,  4.90469962e-01, -6.27518237e-01],        [-1.11759044e-01,  1.31907976e+00, -1.92628849e+00],        [-6.40158474e-01,  1.16672480e+00, -5.82574248e-01],        [ 1.82465971e-01,  5.98510027e-01, -1.54943538e+00],        [ 1.23925221e+00,  1.85171413e+00, -4.11800183e-02],        [ 5.96398175e-01, -5.77813566e-01,  2.84586579e-01],        [-2.33158922e+00,  4.85183299e-01, -6.45461261e-01],        [-1.00312984e+00,  3.38520497e-01, -2.68755138e-01],        [ 3.27760369e-01, -6.05535984e-01,  5.60963929e-01],        [ 4.49014939e-02,  1.46062136e+00, -2.22097754e+00],        [ 1.37192681e-01,  2.33995080e-01,  1.73316765e+00],        [-1.01195645e+00, -1.36518753e+00, -2.85154253e-01],        [ 7.14541018e-01, -7.50025034e-01,  1.12300861e+00],        [-9.05730128e-01, -2.49278724e-01,  8.21055114e-01],        [ 1.36068606e+00,  1.04029274e+00, -4.62492704e-01],        [-8.05677921e-02,  2.65979171e-01,  2.23054901e-01]],       [[-1.24165677e-01, -9.52346399e-02,  4.24239188e-01],        [ 5.64876080e-01, -1.03957675e-01, -5.80752552e-01],        [-2.28657699e+00, -8.04197013e-01,  4.47991550e-01],        [-3.88402313e-01,  4.04412657e-01, -1.15122008e+00],        [-2.26028576e-01,  4.98672754e-01,  1.82685316e-01],        [-1.02170885e-01, -7.63889849e-01,  2.21727896e+00],        [-1.21248543e+00, -1.18503594e+00, -1.04385889e+00],        [-6.25540912e-01,  1.21357477e+00, -1.37694407e+00],        [-1.06482141e-01,  1.24098301e+00,  4.69377786e-01],        [ 5.69198370e-01,  1.34320125e-01,  2.64150798e-01],        [-8.89743328e-01,  7.29027569e-01, -3.96091849e-01],        [-5.38439631e-01,  7.89792895e-01, -2.41921830e+00],        [ 1.78635567e-01,  6.26172364e-01,  1.26544416e+00],        [ 9.92504656e-01,  8.01704347e-01, -1.41732895e+00],        [ 3.73012841e-01, -3.74639213e-01, -1.93168428e-02],        [ 6.25086367e-01, -1.16802764e+00, -1.35501802e-01]],       [[ 7.90464222e-01,  3.84943634e-01,  1.34319830e+00],        [-1.04067123e+00,  1.20278490e+00, -9.86785233e-01],        [-2.10872635e-01, -2.94924617e-01,  2.18456030e+00],        [-1.25211585e+00, -4.26412076e-01,  3.85715276e-01],        [ 4.80433226e-01, -2.17810750e+00,  1.72025964e-01],        [-1.36507463e+00, -5.88170290e-01, -1.12746871e+00],        [ 4.61366147e-01,  8.17801833e-01,  2.02035308e+00],        [-2.33708096e+00,  2.93909404e-02,  5.49295485e-01],        [ 5.44144630e-01,  8.78731012e-01,  5.76293409e-01],        [-3.52834463e-01, -2.13488245e+00, -9.02048647e-02],        [-2.68439913e+00, -7.18059778e-01,  1.58271170e+00],        [ 7.84022629e-01,  1.80395007e-01,  9.44528505e-02],        [ 1.11435282e+00, -7.96168029e-01, -9.54501331e-01],        [ 1.08020775e-01,  4.66115266e-01,  1.13831210e+00],        [ 1.40373373e+00, -6.06358469e-01, -6.87408030e-01],        [-5.19226313e-01,  6.26494050e-01,  7.20157683e-01]],       [[-1.53032497e-01, -2.31825694e-01,  2.38443211e-01],        [ 1.17578602e+00,  8.96336198e-01,  1.00056005e+00],        [-8.06149364e-01,  1.67887485e+00,  1.31185651e+00],        [-4.14346933e-01,  9.25169349e-01, -8.90269935e-01],        [ 4.75324124e-01,  6.48465008e-02, -1.17474127e+00],        [ 8.11189532e-01,  4.58558321e-01, -1.89462161e+00],        [-8.52047384e-01, -1.95253909e+00, -1.18440950e+00],        [ 5.65351129e-01,  3.13308030e-01,  1.34290731e+00],        [-8.23011279e-01,  4.34110940e-01, -1.57076240e-01],        [-7.66083777e-01,  1.53549409e+00, -6.54839098e-01],        [ 1.29202247e-01,  6.42492482e-03,  9.93899703e-02],        [ 2.33376041e-01, -8.38140726e-01,  9.34675157e-01],        [-9.31392252e-01, -1.87041914e+00, -6.32766664e-01],        [-3.24939862e-02, -6.08937442e-01,  4.31290448e-01],        [-9.14271355e-01,  8.74976039e-01,  7.50481248e-01],        [ 1.18830375e-01,  1.08729470e+00,  1.97146928e+00]],       [[-9.39358115e-01, -1.37552381e-01,  1.66079611e-01],        [ 1.00940740e+00, -5.13267696e-01,  1.12969530e+00],        [ 2.46125221e+00, -1.14048445e+00, -7.83394337e-01],        [-1.23253345e+00,  1.30130267e+00, -1.51509032e-01],        [ 1.01419091e+00,  2.42352739e-01,  7.56354570e-01],        [ 7.67537236e-01,  9.57925975e-01, -1.85001838e+00],        [ 1.54104221e+00,  9.20635283e-01,  3.35547149e-01],        [ 8.05710435e-01, -7.26651132e-01,  3.50032095e-03],        [-2.14763775e-01, -1.70537174e+00,  9.35129881e-01],        [-5.43601632e-01, -6.72167778e-01, -9.50358927e-01],        [-8.49173665e-01, -1.43499419e-01, -9.19315442e-02],        [ 5.55126607e-01, -7.18098879e-01,  1.32945049e+00],        [-1.82561159e-01,  2.36541009e+00,  4.69969809e-01],        [ 7.36051142e-01,  8.05300534e-01,  4.18028831e-01],        [ 1.13606131e+00, -9.57732141e-01,  1.11834717e+00],        [-4.51551750e-02, -1.14675157e-01, -2.38522816e+00]]],      dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å– G é€šé“æ•°æ®</span></span><br><span class="line">x[:,:,:,<span class="number">1</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=347, shape=(4, 32, 32), dtype=float32, numpy=array([[[ 1.14909673e+00, -4.06459235e-02, -5.78127801e-01, ...,          1.55137196e-01,  7.60451019e-01,  9.85731423e-01],        [-1.13586128e+00, -1.14675157e-01,  1.63204148e-01, ...,         -5.13267696e-01, -1.18245673e+00, -1.37552381e-01],        [ 9.94689882e-01,  5.30135810e-01,  3.25026214e-01, ...,         -1.92351151e+00, -1.82740724e+00,  1.64374709e-01],        ...,        [-1.52717039e-01, -5.92184007e-01, -1.48266196e+00, ...,         -3.48650187e-01,  4.83299762e-01, -1.30784822e+00],        [-1.26717579e+00, -5.01342475e-01,  9.09223035e-02, ...,          2.43971795e-02,  5.13184786e-01,  6.98500574e-01],        [-8.86834741e-01, -9.81691927e-02,  7.17816591e-01, ...,          5.97050309e-01,  1.22520790e-01, -1.52891368e-01]],       [[ 5.27211905e-01,  5.10949850e-01,  6.68793380e-01, ...,          1.01723397e+00, -9.20990646e-01,  1.55521703e+00],        [ 5.97045481e-01, -1.12161386e+00,  1.01290178e+00, ...,         -1.12059198e-01,  1.63329244e+00,  9.03684914e-01],        [-3.70465130e-01,  1.35258186e+00,  1.91781148e-02, ...,          7.91784763e-01, -5.38403928e-01,  1.19437456e+00],        ...,        [-2.66319364e-02,  4.80187714e-01, -6.81482777e-02, ...,         -8.33781809e-02, -2.15396023e+00, -1.00828364e-01],        [-5.73343694e-01,  1.27166235e+00, -5.36300726e-02, ...,          6.65309191e-01,  1.02147615e+00,  7.86082864e-01],        [-6.50614142e-01,  8.00769866e-01, -3.60975653e-01, ...,          3.29060793e-01, -7.21324742e-01, -1.71777833e+00]],       [[-5.47546387e-01, -1.24894366e-01, -6.13053203e-01, ...,         -4.76122051e-01, -6.67316198e-01, -5.32188356e-01],        [ 7.25843370e-01,  1.25086391e+00,  6.61642969e-01, ...,         -1.11920547e+00,  8.22943971e-02,  8.71762872e-01],        [ 6.10169657e-02,  8.98746789e-01, -1.89981267e-01, ...,          1.32393092e-03,  7.66479552e-01,  4.74087834e-01],        ...,        [ 1.36904991e+00,  1.88162339e+00, -1.29588962e+00, ...,          2.02118421e+00,  2.84831226e-01, -8.29148889e-01],        [ 3.66007835e-01,  5.39520979e-01, -1.21468163e+00, ...,          1.26315391e+00, -1.57071245e+00,  3.33765388e-01],        [ 3.69738698e-01, -3.00485075e-01,  3.49693507e-01, ...,         -1.00170338e+00, -8.53059292e-01, -1.43128681e+00]],       [[ 9.08448339e-01, -7.05780163e-02, -5.45533061e-01, ...,          1.39675033e+00, -9.83740449e-01,  4.93973970e-01],        [-2.29770586e-01, -1.70520768e-01,  4.63991873e-02, ...,          1.25932079e-02,  2.69956380e-01, -2.21568316e-01],        [-1.71562707e+00, -2.53337473e-01,  1.14060119e-01, ...,          1.60762429e+00, -3.74208689e-01,  1.31152779e-01],        ...,        [ 6.35229349e-01, -3.34331602e-01, -2.70434052e-01, ...,         -4.81671304e-01, -1.03246319e+00,  1.72697484e+00],        [-3.85653168e-01, -3.87742639e-01, -7.38137007e-01, ...,         -4.67593260e-02,  8.60109150e-01,  4.53103155e-01],        [-3.68833989e-01,  6.17409274e-02,  2.55871916e+00, ...,         -7.19225705e-02, -1.25733685e+00,  6.05888307e-01]]],      dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¯»å–ç¬¬ 1~2 å¼ å›¾ç‰‡çš„ G/B é€šé“æ•°æ®</span></span><br><span class="line"><span class="comment"># é«˜å®½ç»´åº¦å…¨éƒ¨é‡‡é›†</span></span><br><span class="line">x[<span class="number">0</span>:<span class="number">2</span>,...,<span class="number">1</span>:] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=351, shape=(2, 32, 32, 2), dtype=float32, numpy=array([[[[ 1.1490967 ,  1.7380066 ],         [-0.04064592,  0.48029   ],         [-0.5781278 , -1.291669  ],         ...,         [ 0.1551372 ,  0.8534301 ],         [ 0.760451  ,  0.587535  ],         [ 0.9857314 ,  0.1369431 ]],        [[-1.1358613 , -0.06066316],         [-0.11467516, -2.3852282 ],         [ 0.16320415,  0.01811434],         ...,         [-0.5132677 ,  1.1296953 ],         [-1.1824567 ,  0.7329599 ],         [-0.13755238,  0.16607961]],        [[ 0.9946899 ,  0.48675606],         [ 0.5301358 , -1.0126823 ],         [ 0.3250262 , -0.6064818 ],         ...,         [-1.9235115 , -0.41639256],         [-1.8274072 , -0.5375008 ],         [ 0.16437471, -0.4204572 ]],        ...,        [[-0.15271704,  0.02707502],         [-0.592184  ,  0.02546674],         [-1.482662  , -1.4665922 ],         ...,         [-0.3486502 , -1.5472578 ],         [ 0.48329976, -2.0207098 ],         [-1.3078482 , -0.68001777]],        [[-1.2671758 ,  0.03466341],         [-0.5013425 ,  0.1263919 ],         [ 0.0909223 ,  0.29931667],         ...,         [ 0.02439718,  0.5069986 ],         [ 0.5131848 , -0.6002897 ],         [ 0.6985006 , -1.3119441 ]],        [[-0.88683474, -0.14877406],         [-0.09816919, -0.6858855 ],         [ 0.7178166 ,  0.44352156],         ...,         [ 0.5970503 , -2.1432486 ],         [ 0.12252079, -0.15961307],         [-0.15289137, -0.26840857]]],</code></pre><p>â€‹<br>           [[[ 0.5272119 ,  0.6869629 ],<br>             [ 0.51094985,  0.2770362 ],<br>             [ 0.6687934 , -1.4204    ],<br>             â€¦,<br>             [ 1.017234  ,  0.35187325],<br>             [-0.92099065, -0.585941  ],<br>             [ 1.555217  , -0.6104895 ]],</p><pre><code>        [[ 0.5970455 ,  0.7830326 ],         [-1.1216139 ,  0.16928901],         [ 1.0129018 ,  0.71436375],         ...,         [-0.1120592 ,  0.37095946],         [ 1.6332924 ,  0.4852164 ],         [ 0.9036849 ,  0.84450924]],        [[-0.37046513, -0.4693162 ],         [ 1.3525819 , -0.66847706],         [ 0.01917811, -0.40561342],         ...,         [ 0.79178476,  1.6169451 ],         [-0.5384039 , -2.6904156 ],         [ 1.1943746 ,  0.15126795]],        ...,        [[-0.02663194, -0.42372993],         [ 0.4801877 , -1.6053843 ],         [-0.06814828,  0.39376357],         ...,         [-0.08337818, -0.56289715],         [-2.1539602 ,  0.7823069 ],         [-0.10082836,  0.64499325]],        [[-0.5733437 ,  0.8600085 ],         [ 1.2716624 ,  1.4874613 ],         [-0.05363007, -1.5294101 ],         ...,         [ 0.6653092 ,  0.31750998],         [ 1.0214761 ,  0.22179288],         [ 0.78608286, -1.4824792 ]],        [[-0.65061414, -0.6899978 ],         [ 0.80076987, -1.4741213 ],         [-0.36097565, -0.48046836],         ...,         [ 0.3290608 , -1.5610422 ],         [-0.72132474,  0.18023647],         [-1.7177783 , -0.53801376]]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¯»å– R/G é€šé“æ•°æ®</span></span><br><span class="line"><span class="comment"># æ‰€æœ‰æ ·æœ¬ï¼Œæ‰€æœ‰é«˜ã€å®½çš„å‰ 2 ä¸ªé€šé“</span></span><br><span class="line">x[...,:<span class="number">2</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=359, shape=(4, 32, 32, 2), dtype=float32, numpy=array([[[[-1.30701756e+00,  1.14909673e+00],         [ 3.61870110e-01, -4.06459235e-02],         [ 6.26487672e-01, -5.78127801e-01],         ...,         [ 1.38576820e-01,  1.55137196e-01],         [-1.29257798e+00,  7.60451019e-01],         [-3.25585663e-01,  9.85731423e-01]],        [[-2.72432625e-01, -1.13586128e+00],         [-4.51551750e-02, -1.14675157e-01],         [-4.10570800e-01,  1.63204148e-01],         ...,         [ 1.00940740e+00, -5.13267696e-01],         [-1.04479229e+00, -1.18245673e+00],         [-9.39358115e-01, -1.37552381e-01]],        [[-1.14408398e+00,  9.94689882e-01],         [-2.45610863e-01,  5.30135810e-01],         [ 3.69893968e-01,  3.25026214e-01],         ...,         [ 1.47702467e+00, -1.92351151e+00],         [-8.77718687e-01, -1.82740724e+00],         [-1.90951622e+00,  1.64374709e-01]],        ...,        [[-8.38505983e-01, -1.52717039e-01],         [ 1.60369647e+00, -5.92184007e-01],         [ 2.45542109e-01, -1.48266196e+00],         ...,         [ 3.65186512e-01, -3.48650187e-01],         [-6.50465429e-01,  4.83299762e-01],         [-1.05812716e+00, -1.30784822e+00]],        [[ 7.95438468e-01, -1.26717579e+00],         [ 9.37338114e-01, -5.01342475e-01],         [-1.69611961e-01,  9.09223035e-02],         ...,         [ 1.64364791e+00,  2.43971795e-02],         [ 1.96424723e-01,  5.13184786e-01],         [ 8.26264262e-01,  6.98500574e-01]],        [[ 2.59421289e-01, -8.86834741e-01],         [-1.79539633e+00, -9.81691927e-02],         [ 3.78742844e-01,  7.17816591e-01],         ...,         [-1.74235809e+00,  5.97050309e-01],         [ 6.53830469e-01,  1.22520790e-01],         [ 1.32819211e+00, -1.52891368e-01]]],</code></pre><p>â€‹<br>           [[[-5.31493947e-02,  5.27211905e-01],<br>             [-8.06730747e-01,  5.10949850e-01],<br>             [ 1.84080076e+00,  6.68793380e-01],<br>             â€¦,<br>             [ 1.31973469e+00,  1.01723397e+00],<br>             [ 4.49128337e-02, -9.20990646e-01],<br>             [-1.32044387e+00,  1.55521703e+00]],</p><pre><code>        [[ 7.68865108e-01,  5.97045481e-01],         [-7.52771422e-02, -1.12161386e+00],         [ 1.21640265e+00,  1.01290178e+00],         ...,         [ 1.01818316e-01, -1.12059198e-01],         [ 1.12015426e+00,  1.63329244e+00],         [ 1.95406660e-01,  9.03684914e-01]],        [[-3.43454480e-02, -3.70465130e-01],         [-3.47994983e-01,  1.35258186e+00],         [ 1.07138467e+00,  1.91781148e-02],         ...,         [ 9.40576553e-01,  7.91784763e-01],         [ 5.54417372e-01, -5.38403928e-01],         [-1.44541347e+00,  1.19437456e+00]],        ...,        [[ 1.11028528e+00, -2.66319364e-02],         [-1.03816831e+00,  4.80187714e-01],         [ 5.60190491e-02, -6.81482777e-02],         ...,         [ 4.46985304e-01, -8.33781809e-02],         [-1.76779434e-01, -2.15396023e+00],         [-1.36233258e+00, -1.00828364e-01]],        [[ 1.25010625e-01, -5.73343694e-01],         [ 4.23534930e-01,  1.27166235e+00],         [ 6.20880544e-01, -5.36300726e-02],         ...,         [-4.97313976e-01,  6.65309191e-01],         [-6.49542287e-02,  1.02147615e+00],         [ 1.87847123e-01,  7.86082864e-01]],        [[-8.89460385e-01, -6.50614142e-01],         [ 6.55708909e-01,  8.00769866e-01],         [ 1.00335670e+00, -3.60975653e-01],         ...,         [-7.29620278e-01,  3.29060793e-01],         [ 2.53696367e-02, -7.21324742e-01],         [-4.38493162e-01, -1.71777833e+00]]],</code></pre><p>â€‹<br>           [[[-5.11693060e-01, -5.47546387e-01],<br>             [-2.56009412e+00, -1.24894366e-01],<br>             [-1.66868377e+00, -6.13053203e-01],<br>             â€¦,<br>             [-3.40102255e-01, -4.76122051e-01],<br>             [-2.68808216e-01, -6.67316198e-01],<br>             [ 1.95494068e+00, -5.32188356e-01]],</p><pre><code>        [[-6.79937303e-01,  7.25843370e-01],         [ 7.51152635e-01,  1.25086391e+00],         [ 1.31343961e+00,  6.61642969e-01],         ...,         [ 3.19355845e-01, -1.11920547e+00],         [-4.93650079e-01,  8.22943971e-02],         [ 1.77995250e-01,  8.71762872e-01]],        [[ 5.79456747e-01,  6.10169657e-02],         [-3.90781134e-01,  8.98746789e-01],         [-1.64386973e-01, -1.89981267e-01],         ...,         [ 1.72087538e+00,  1.32393092e-03],         [-1.03725746e-01,  7.66479552e-01],         [ 8.60096216e-01,  4.74087834e-01]],        ...,        [[ 2.98859119e-01,  1.36904991e+00],         [-1.31470454e+00,  1.88162339e+00],         [ 3.38255256e-01, -1.29588962e+00],         ...,         [ 4.79147226e-01,  2.02118421e+00],         [ 3.93357724e-01,  2.84831226e-01],         [-1.07760859e+00, -8.29148889e-01]],        [[-7.26247966e-01,  3.66007835e-01],         [ 6.38583839e-01,  5.39520979e-01],         [ 2.58788407e-01, -1.21468163e+00],         ...,         [ 3.30879092e-01,  1.26315391e+00],         [-9.85577762e-01, -1.57071245e+00],         [ 1.34247553e+00,  3.33765388e-01]],        [[ 3.28157872e-01,  3.69738698e-01],         [-4.69663978e-01, -3.00485075e-01],         [ 8.08599889e-01,  3.49693507e-01],         ...,         [ 1.20650291e-01, -1.00170338e+00],         [-1.25450063e+00, -8.53059292e-01],         [-5.60456105e-02, -1.43128681e+00]]],</code></pre><p>â€‹<br>           [[[ 6.02736592e-01,  9.08448339e-01],<br>             [ 1.45205522e+00, -7.05780163e-02],<br>             [ 1.12210441e+00, -5.45533061e-01],<br>             â€¦,<br>             [-1.61648536e+00,  1.39675033e+00],<br>             [ 3.89932483e-01, -9.83740449e-01],<br>             [-3.43187571e-01,  4.93973970e-01]],</p><pre><code>        [[-4.33481991e-01, -2.29770586e-01],         [ 4.20535475e-01, -1.70520768e-01],         [ 1.40664136e+00,  4.63991873e-02],         ...,         [ 3.30364525e-01,  1.25932079e-02],         [-5.44138372e-01,  2.69956380e-01],         [ 5.51277101e-01, -2.21568316e-01]],        [[-2.39359438e-01, -1.71562707e+00],         [ 8.63479078e-02, -2.53337473e-01],         [-5.11896372e-01,  1.14060119e-01],         ...,         [-7.51873851e-01,  1.60762429e+00],         [-1.85268188e+00, -3.74208689e-01],         [-4.49496716e-01,  1.31152779e-01]],        ...,        [[-1.24805138e-01,  6.35229349e-01],         [ 1.62983191e+00, -3.34331602e-01],         [-3.98483366e-01, -2.70434052e-01],         ...,         [ 2.51731694e-01, -4.81671304e-01],         [ 1.65011346e+00, -1.03246319e+00],         [-1.56109953e+00,  1.72697484e+00]],        [[ 3.73855352e-01, -3.85653168e-01],         [-1.18297446e+00, -3.87742639e-01],         [-5.74579597e-01, -7.38137007e-01],         ...,         [ 5.06586790e-01, -4.67593260e-02],         [ 4.67046916e-01,  8.60109150e-01],         [-8.88322115e-01,  4.53103155e-01]],        [[-1.47322047e+00, -3.68833989e-01],         [ 3.80937368e-01,  6.17409274e-02],         [-1.07242978e+00,  2.55871916e+00],         ...,         [ 1.02848232e+00, -7.19225705e-02],         [-1.13464808e+00, -1.25733685e+00],         [-6.02429748e-01,  6.05888307e-01]]]], dtype=float32)&gt;</code></pre><h2 id="ç»´åº¦å˜æ¢"><a href="#ç»´åº¦å˜æ¢" class="headerlink" title="ç»´åº¦å˜æ¢"></a>ç»´åº¦å˜æ¢</h2><h3 id="æ”¹å˜è§†å›¾"><a href="#æ”¹å˜è§†å›¾" class="headerlink" title="æ”¹å˜è§†å›¾"></a>æ”¹å˜è§†å›¾</h3><p>æˆ‘ä»¬é€šè¿‡ tf.range()æ¨¡æ‹Ÿç”Ÿæˆä¸€ä¸ªå‘é‡æ•°æ®ï¼Œå¹¶é€šè¿‡ tf.reshape è§†å›¾æ”¹å˜å‡½æ•°äº§ç”Ÿä¸åŒçš„è§†å›¾</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç”Ÿæˆå‘é‡</span></span><br><span class="line">x=tf.<span class="built_in">range</span>(<span class="number">96</span>)</span><br><span class="line"><span class="comment"># æ”¹å˜ x çš„è§†å›¾ï¼Œè·å¾— 4D å¼ é‡ï¼Œå­˜å‚¨å¹¶æœªæ”¹å˜</span></span><br><span class="line">x=tf.reshape(x,[<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">3</span>]) </span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=365, shape=(2, 4, 4, 3), dtype=int32, numpy=array([[[[ 0,  1,  2],         [ 3,  4,  5],         [ 6,  7,  8],         [ 9, 10, 11]],        [[12, 13, 14],         [15, 16, 17],         [18, 19, 20],         [21, 22, 23]],        [[24, 25, 26],         [27, 28, 29],         [30, 31, 32],         [33, 34, 35]],        [[36, 37, 38],         [39, 40, 41],         [42, 43, 44],         [45, 46, 47]]],</code></pre><p>â€‹<br>           [[[48, 49, 50],<br>             [51, 52, 53],<br>             [54, 55, 56],<br>             [57, 58, 59]],</p><pre><code>        [[60, 61, 62],         [63, 64, 65],         [66, 67, 68],         [69, 70, 71]],        [[72, 73, 74],         [75, 76, 77],         [78, 79, 80],         [81, 82, 83]],        [[84, 85, 86],         [87, 88, 89],         [90, 91, 92],         [93, 94, 95]]]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è·å–å¼ é‡çš„ç»´åº¦æ•°å’Œå½¢çŠ¶åˆ—è¡¨</span></span><br><span class="line">x.ndim,x.shape </span><br></pre></td></tr></table></figure><pre><code>(4, TensorShape([2, 4, 4, 3]))</code></pre><p>é€šè¿‡ tf.reshape(x, new_shape)ï¼Œå¯ä»¥å°†å¼ é‡çš„è§†å›¾ä»»æ„åœ°åˆæ³•æ”¹å˜</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reshape(x,[<span class="number">2</span>,-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=373, shape=(2, 48), dtype=int32, numpy=array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],       [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,        64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,        80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]],      dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reshape(x,[<span class="number">2</span>,<span class="number">4</span>,<span class="number">12</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=375, shape=(2, 4, 12), dtype=int32, numpy=array([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]],       [[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59],        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71],        [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83],        [84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reshape(x,[<span class="number">2</span>,-<span class="number">1</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=377, shape=(2, 16, 3), dtype=int32, numpy=array([[[ 0,  1,  2],        [ 3,  4,  5],        [ 6,  7,  8],        [ 9, 10, 11],        [12, 13, 14],        [15, 16, 17],        [18, 19, 20],        [21, 22, 23],        [24, 25, 26],        [27, 28, 29],        [30, 31, 32],        [33, 34, 35],        [36, 37, 38],        [39, 40, 41],        [42, 43, 44],        [45, 46, 47]],       [[48, 49, 50],        [51, 52, 53],        [54, 55, 56],        [57, 58, 59],        [60, 61, 62],        [63, 64, 65],        [66, 67, 68],        [69, 70, 71],        [72, 73, 74],        [75, 76, 77],        [78, 79, 80],        [81, 82, 83],        [84, 85, 86],        [87, 88, 89],        [90, 91, 92],        [93, 94, 95]]], dtype=int32)&gt;</code></pre><h3 id="å¢ã€åˆ ç»´åº¦"><a href="#å¢ã€åˆ ç»´åº¦" class="headerlink" title="å¢ã€åˆ ç»´åº¦"></a>å¢ã€åˆ ç»´åº¦</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># äº§ç”ŸçŸ©é˜µ</span></span><br><span class="line">x = tf.random.uniform([<span class="number">28</span>,<span class="number">28</span>],maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=381, shape=(28, 28), dtype=int32, numpy=array([[4, 1, 1, 5, 4, 1, 3, 5, 4, 0, 8, 8, 0, 1, 8, 6, 4, 9, 5, 1, 8, 0,        1, 3, 3, 5, 0, 4],       [5, 9, 2, 1, 8, 6, 3, 8, 6, 3, 6, 4, 7, 7, 5, 9, 2, 8, 4, 6, 6, 4,        9, 0, 5, 9, 9, 0],       [8, 0, 0, 1, 4, 2, 5, 8, 9, 3, 5, 7, 0, 1, 3, 6, 2, 0, 4, 7, 7, 5,        8, 2, 7, 8, 6, 0],       [9, 6, 4, 8, 5, 5, 7, 1, 2, 8, 6, 9, 5, 3, 3, 6, 5, 9, 4, 4, 1, 0,        5, 9, 3, 7, 1, 6],       [5, 8, 7, 4, 6, 5, 4, 5, 7, 5, 1, 3, 2, 2, 9, 0, 9, 5, 3, 3, 4, 9,        5, 1, 7, 0, 4, 6],       [9, 2, 6, 7, 5, 7, 9, 3, 1, 8, 2, 0, 0, 8, 2, 7, 2, 2, 1, 1, 7, 1,        9, 5, 2, 2, 6, 4],       [6, 4, 2, 2, 7, 2, 8, 0, 1, 5, 9, 5, 0, 8, 0, 3, 8, 6, 3, 7, 0, 5,        8, 1, 6, 1, 5, 4],       [3, 9, 2, 4, 1, 8, 1, 5, 7, 0, 0, 2, 9, 0, 5, 0, 5, 1, 7, 0, 5, 0,        1, 3, 2, 6, 3, 8],       [2, 9, 2, 6, 0, 4, 8, 7, 7, 4, 0, 3, 0, 9, 1, 6, 1, 8, 5, 2, 0, 6,        4, 0, 7, 5, 5, 9],       [4, 6, 8, 6, 5, 5, 8, 8, 2, 5, 1, 7, 0, 7, 7, 2, 3, 2, 5, 3, 3, 4,        4, 1, 2, 4, 7, 1],       [8, 3, 0, 5, 0, 4, 4, 0, 2, 1, 3, 0, 8, 8, 3, 0, 5, 8, 6, 4, 3, 2,        1, 4, 2, 4, 9, 5],       [4, 3, 1, 4, 7, 0, 4, 9, 3, 2, 5, 9, 2, 4, 1, 5, 5, 8, 0, 5, 0, 7,        0, 1, 0, 0, 2, 6],       [2, 4, 9, 9, 4, 2, 0, 0, 2, 5, 6, 0, 0, 9, 7, 3, 6, 2, 7, 3, 8, 8,        7, 2, 9, 9, 7, 3],       [2, 8, 8, 8, 5, 7, 7, 9, 1, 8, 6, 5, 4, 8, 4, 4, 4, 5, 6, 5, 8, 2,        5, 1, 1, 3, 5, 9],       [2, 3, 8, 5, 2, 1, 6, 9, 5, 9, 0, 5, 7, 5, 7, 8, 8, 0, 9, 9, 3, 0,        4, 3, 3, 3, 4, 5],       [9, 6, 3, 8, 8, 3, 6, 0, 3, 4, 1, 1, 2, 9, 8, 0, 5, 3, 0, 7, 0, 9,        2, 0, 8, 1, 1, 9],       [4, 8, 7, 0, 3, 6, 1, 7, 7, 9, 0, 1, 4, 6, 7, 0, 9, 5, 2, 2, 6, 5,        5, 0, 3, 1, 1, 7],       [9, 2, 4, 6, 0, 5, 8, 2, 2, 7, 7, 9, 1, 1, 9, 5, 5, 8, 0, 3, 8, 4,        2, 7, 0, 4, 2, 7],       [9, 2, 3, 7, 7, 6, 3, 7, 4, 6, 4, 8, 4, 9, 3, 3, 2, 4, 8, 4, 7, 6,        6, 2, 0, 7, 1, 9],       [6, 1, 2, 0, 2, 0, 0, 0, 5, 8, 7, 6, 9, 7, 9, 0, 6, 6, 6, 5, 3, 1,        3, 2, 3, 2, 3, 4],       [7, 4, 8, 9, 8, 3, 4, 0, 8, 0, 5, 2, 0, 3, 9, 8, 3, 8, 4, 2, 5, 3,        6, 1, 9, 8, 6, 5],       [6, 3, 1, 6, 4, 1, 8, 1, 6, 7, 2, 7, 1, 2, 8, 1, 4, 5, 0, 0, 4, 9,        9, 4, 6, 9, 7, 5],       [4, 0, 1, 1, 8, 7, 0, 8, 1, 2, 8, 6, 2, 1, 4, 6, 9, 2, 6, 9, 4, 0,        9, 0, 7, 9, 8, 4],       [2, 8, 3, 1, 9, 6, 1, 0, 0, 4, 5, 7, 1, 2, 3, 5, 9, 4, 7, 9, 5, 5,        8, 5, 0, 0, 5, 8],       [4, 6, 7, 6, 4, 1, 6, 8, 4, 2, 4, 5, 6, 1, 6, 6, 4, 2, 1, 1, 2, 6,        8, 3, 0, 0, 4, 0],       [6, 3, 3, 6, 8, 4, 6, 3, 6, 3, 8, 9, 7, 2, 2, 9, 0, 5, 7, 7, 2, 6,        3, 4, 6, 9, 4, 2],       [2, 7, 0, 8, 7, 0, 7, 8, 2, 2, 8, 3, 9, 6, 3, 0, 0, 5, 5, 7, 3, 9,        4, 7, 4, 4, 5, 0],       [3, 5, 7, 5, 4, 6, 8, 5, 9, 4, 7, 1, 6, 8, 0, 3, 1, 5, 2, 0, 3, 5,        9, 7, 6, 3, 3, 1]], dtype=int32)&gt;</code></pre><p>é€šè¿‡ tf.expand_dims(x, axis)å¯åœ¨æŒ‡å®šçš„ axis è½´å‰å¯ä»¥æ’å…¥ä¸€ä¸ªæ–°çš„ç»´åº¦</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># axis=2 è¡¨ç¤ºå®½ç»´åº¦åé¢çš„ä¸€ä¸ªç»´åº¦</span></span><br><span class="line">x = tf.expand_dims(x,axis=<span class="number">2</span>) </span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=383, shape=(28, 28, 1), dtype=int32, numpy=array([[[4],        [1],        [1],        [5],        [4],        [1],        [3],        [5],        [4],        [0],        [8],        [8],        [0],        [1],        [8],        [6],        [4],        [9],        [5],        [1],        [8],        [0],        [1],        [3],        [3],        [5],        [0],        [4]],       [[5],        [9],        [2],        [1],        [8],        [6],        [3],        [8],        [6],        [3],        [6],        [4],        [7],        [7],        [5],        [9],        [2],        [8],        [4],        [6],        [6],        [4],        [9],        [0],        [5],        [9],        [9],        [0]],       [[8],        [0],        [0],        [1],        [4],        [2],        [5],        [8],        [9],        [3],        [5],        [7],        [0],        [1],        [3],        [6],        [2],        [0],        [4],        [7],        [7],        [5],        [8],        [2],        [7],        [8],        [6],        [0]],       [[9],        [6],        [4],        [8],        [5],        [5],        [7],        [1],        [2],        [8],        [6],        [9],        [5],        [3],        [3],        [6],        [5],        [9],        [4],        [4],        [1],        [0],        [5],        [9],        [3],        [7],        [1],        [6]],       [[5],        [8],        [7],        [4],        [6],        [5],        [4],        [5],        [7],        [5],        [1],        [3],        [2],        [2],        [9],        [0],        [9],        [5],        [3],        [3],        [4],        [9],        [5],        [1],        [7],        [0],        [4],        [6]],       [[9],        [2],        [6],        [7],        [5],        [7],        [9],        [3],        [1],        [8],        [2],        [0],        [0],        [8],        [2],        [7],        [2],        [2],        [1],        [1],        [7],        [1],        [9],        [5],        [2],        [2],        [6],        [4]],       [[6],        [4],        [2],        [2],        [7],        [2],        [8],        [0],        [1],        [5],        [9],        [5],        [0],        [8],        [0],        [3],        [8],        [6],        [3],        [7],        [0],        [5],        [8],        [1],        [6],        [1],        [5],        [4]],       [[3],        [9],        [2],        [4],        [1],        [8],        [1],        [5],        [7],        [0],        [0],        [2],        [9],        [0],        [5],        [0],        [5],        [1],        [7],        [0],        [5],        [0],        [1],        [3],        [2],        [6],        [3],        [8]],       [[2],        [9],        [2],        [6],        [0],        [4],        [8],        [7],        [7],        [4],        [0],        [3],        [0],        [9],        [1],        [6],        [1],        [8],        [5],        [2],        [0],        [6],        [4],        [0],        [7],        [5],        [5],        [9]],       [[4],        [6],        [8],        [6],        [5],        [5],        [8],        [8],        [2],        [5],        [1],        [7],        [0],        [7],        [7],        [2],        [3],        [2],        [5],        [3],        [3],        [4],        [4],        [1],        [2],        [4],        [7],        [1]],       [[8],        [3],        [0],        [5],        [0],        [4],        [4],        [0],        [2],        [1],        [3],        [0],        [8],        [8],        [3],        [0],        [5],        [8],        [6],        [4],        [3],        [2],        [1],        [4],        [2],        [4],        [9],        [5]],       [[4],        [3],        [1],        [4],        [7],        [0],        [4],        [9],        [3],        [2],        [5],        [9],        [2],        [4],        [1],        [5],        [5],        [8],        [0],        [5],        [0],        [7],        [0],        [1],        [0],        [0],        [2],        [6]],       [[2],        [4],        [9],        [9],        [4],        [2],        [0],        [0],        [2],        [5],        [6],        [0],        [0],        [9],        [7],        [3],        [6],        [2],        [7],        [3],        [8],        [8],        [7],        [2],        [9],        [9],        [7],        [3]],       [[2],        [8],        [8],        [8],        [5],        [7],        [7],        [9],        [1],        [8],        [6],        [5],        [4],        [8],        [4],        [4],        [4],        [5],        [6],        [5],        [8],        [2],        [5],        [1],        [1],        [3],        [5],        [9]],       [[2],        [3],        [8],        [5],        [2],        [1],        [6],        [9],        [5],        [9],        [0],        [5],        [7],        [5],        [7],        [8],        [8],        [0],        [9],        [9],        [3],        [0],        [4],        [3],        [3],        [3],        [4],        [5]],       [[9],        [6],        [3],        [8],        [8],        [3],        [6],        [0],        [3],        [4],        [1],        [1],        [2],        [9],        [8],        [0],        [5],        [3],        [0],        [7],        [0],        [9],        [2],        [0],        [8],        [1],        [1],        [9]],       [[4],        [8],        [7],        [0],        [3],        [6],        [1],        [7],        [7],        [9],        [0],        [1],        [4],        [6],        [7],        [0],        [9],        [5],        [2],        [2],        [6],        [5],        [5],        [0],        [3],        [1],        [1],        [7]],       [[9],        [2],        [4],        [6],        [0],        [5],        [8],        [2],        [2],        [7],        [7],        [9],        [1],        [1],        [9],        [5],        [5],        [8],        [0],        [3],        [8],        [4],        [2],        [7],        [0],        [4],        [2],        [7]],       [[9],        [2],        [3],        [7],        [7],        [6],        [3],        [7],        [4],        [6],        [4],        [8],        [4],        [9],        [3],        [3],        [2],        [4],        [8],        [4],        [7],        [6],        [6],        [2],        [0],        [7],        [1],        [9]],       [[6],        [1],        [2],        [0],        [2],        [0],        [0],        [0],        [5],        [8],        [7],        [6],        [9],        [7],        [9],        [0],        [6],        [6],        [6],        [5],        [3],        [1],        [3],        [2],        [3],        [2],        [3],        [4]],       [[7],        [4],        [8],        [9],        [8],        [3],        [4],        [0],        [8],        [0],        [5],        [2],        [0],        [3],        [9],        [8],        [3],        [8],        [4],        [2],        [5],        [3],        [6],        [1],        [9],        [8],        [6],        [5]],       [[6],        [3],        [1],        [6],        [4],        [1],        [8],        [1],        [6],        [7],        [2],        [7],        [1],        [2],        [8],        [1],        [4],        [5],        [0],        [0],        [4],        [9],        [9],        [4],        [6],        [9],        [7],        [5]],       [[4],        [0],        [1],        [1],        [8],        [7],        [0],        [8],        [1],        [2],        [8],        [6],        [2],        [1],        [4],        [6],        [9],        [2],        [6],        [9],        [4],        [0],        [9],        [0],        [7],        [9],        [8],        [4]],       [[2],        [8],        [3],        [1],        [9],        [6],        [1],        [0],        [0],        [4],        [5],        [7],        [1],        [2],        [3],        [5],        [9],        [4],        [7],        [9],        [5],        [5],        [8],        [5],        [0],        [0],        [5],        [8]],       [[4],        [6],        [7],        [6],        [4],        [1],        [6],        [8],        [4],        [2],        [4],        [5],        [6],        [1],        [6],        [6],        [4],        [2],        [1],        [1],        [2],        [6],        [8],        [3],        [0],        [0],        [4],        [0]],       [[6],        [3],        [3],        [6],        [8],        [4],        [6],        [3],        [6],        [3],        [8],        [9],        [7],        [2],        [2],        [9],        [0],        [5],        [7],        [7],        [2],        [6],        [3],        [4],        [6],        [9],        [4],        [2]],       [[2],        [7],        [0],        [8],        [7],        [0],        [7],        [8],        [2],        [2],        [8],        [3],        [9],        [6],        [3],        [0],        [0],        [5],        [5],        [7],        [3],        [9],        [4],        [7],        [4],        [4],        [5],        [0]],       [[3],        [5],        [7],        [5],        [4],        [6],        [8],        [5],        [9],        [4],        [7],        [1],        [6],        [8],        [0],        [3],        [1],        [5],        [2],        [0],        [3],        [5],        [9],        [7],        [6],        [3],        [3],        [1]]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># äº§ç”ŸçŸ©é˜µ</span></span><br><span class="line">x = tf.random.uniform([<span class="number">28</span>,<span class="number">28</span>],maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432726, shape=(28, 28), dtype=int32, numpy=array([[5, 3, 3, 6, 9, 3, 0, 4, 1, 6, 3, 8, 7, 7, 5, 4, 0, 0, 8, 5, 2, 3,        6, 4, 4, 8, 8, 3],       [8, 4, 7, 9, 3, 6, 1, 7, 5, 9, 4, 9, 7, 4, 4, 8, 4, 9, 7, 9, 6, 1,        3, 5, 0, 2, 4, 2],       [3, 5, 5, 5, 7, 9, 5, 3, 6, 0, 7, 8, 0, 0, 4, 7, 8, 7, 4, 1, 9, 9,        2, 6, 6, 2, 0, 3],       [3, 5, 5, 2, 4, 0, 2, 5, 0, 2, 3, 2, 1, 0, 1, 4, 5, 3, 1, 9, 5, 3,        0, 5, 8, 1, 9, 4],       [6, 0, 1, 4, 0, 0, 7, 7, 0, 4, 3, 3, 3, 5, 2, 3, 5, 6, 4, 6, 4, 1,        3, 2, 8, 5, 8, 4],       [1, 2, 9, 3, 2, 3, 4, 4, 0, 0, 6, 6, 4, 0, 2, 7, 2, 2, 4, 2, 6, 0,        4, 0, 5, 5, 4, 5],       [3, 2, 6, 7, 7, 1, 0, 3, 3, 5, 5, 7, 8, 1, 6, 5, 5, 4, 3, 2, 9, 0,        0, 3, 7, 0, 0, 0],       [7, 7, 0, 7, 9, 8, 4, 5, 3, 7, 3, 3, 6, 1, 4, 8, 9, 2, 2, 8, 3, 1,        0, 9, 3, 3, 2, 4],       [9, 8, 8, 1, 4, 9, 3, 0, 5, 9, 6, 6, 8, 1, 4, 9, 8, 9, 8, 9, 3, 8,        7, 5, 8, 0, 3, 6],       [0, 8, 3, 1, 2, 1, 9, 4, 5, 0, 7, 1, 3, 5, 4, 4, 7, 3, 6, 5, 5, 6,        2, 0, 6, 1, 4, 8],       [4, 2, 6, 1, 7, 5, 6, 2, 4, 0, 9, 8, 0, 0, 0, 6, 8, 2, 3, 0, 0, 5,        6, 6, 9, 8, 4, 9],       [7, 3, 2, 5, 2, 5, 4, 3, 6, 4, 9, 2, 1, 7, 6, 4, 4, 5, 7, 7, 1, 6,        4, 0, 3, 6, 4, 8],       [1, 7, 6, 0, 4, 8, 0, 3, 0, 2, 0, 7, 0, 5, 6, 5, 3, 1, 4, 3, 8, 8,        8, 6, 7, 3, 1, 7],       [0, 8, 0, 5, 5, 2, 2, 5, 2, 1, 4, 4, 1, 4, 9, 4, 4, 1, 7, 1, 7, 7,        4, 1, 8, 2, 3, 2],       [5, 3, 5, 6, 6, 0, 9, 2, 9, 2, 8, 2, 1, 4, 0, 4, 7, 3, 0, 3, 8, 1,        5, 7, 5, 4, 6, 6],       [4, 7, 0, 1, 9, 6, 1, 1, 2, 1, 8, 2, 2, 9, 4, 7, 5, 1, 2, 4, 7, 5,        7, 6, 6, 4, 1, 5],       [4, 5, 7, 8, 2, 0, 5, 3, 4, 6, 3, 4, 5, 4, 9, 3, 6, 0, 2, 7, 1, 0,        1, 7, 2, 4, 4, 0],       [5, 3, 9, 1, 2, 4, 4, 8, 8, 2, 2, 1, 6, 4, 5, 2, 5, 0, 0, 1, 6, 4,        5, 9, 5, 8, 9, 5],       [6, 1, 1, 8, 9, 6, 8, 9, 9, 8, 2, 0, 9, 7, 9, 0, 9, 7, 0, 5, 3, 8,        0, 9, 1, 8, 9, 4],       [9, 1, 7, 3, 3, 7, 8, 3, 2, 2, 6, 3, 2, 1, 0, 5, 8, 2, 8, 4, 5, 5,        2, 9, 9, 6, 8, 3],       [0, 3, 8, 2, 5, 1, 6, 3, 5, 0, 2, 3, 9, 9, 4, 6, 1, 9, 3, 8, 7, 8,        8, 7, 2, 4, 4, 8],       [6, 7, 8, 6, 6, 6, 5, 2, 1, 8, 4, 7, 8, 9, 9, 4, 5, 2, 4, 7, 8, 5,        9, 3, 0, 0, 9, 1],       [7, 8, 4, 9, 4, 8, 9, 3, 5, 4, 8, 3, 7, 9, 2, 0, 2, 3, 8, 5, 6, 0,        4, 3, 6, 1, 6, 3],       [2, 4, 3, 9, 0, 2, 5, 9, 0, 0, 0, 3, 1, 2, 4, 3, 1, 4, 5, 7, 4, 3,        9, 6, 9, 3, 6, 6],       [3, 8, 6, 4, 0, 0, 3, 8, 1, 1, 5, 4, 8, 4, 8, 3, 3, 1, 1, 9, 6, 4,        9, 7, 6, 7, 3, 7],       [4, 3, 7, 5, 3, 4, 0, 4, 8, 2, 5, 1, 2, 8, 2, 6, 4, 7, 7, 6, 3, 5,        9, 6, 4, 2, 5, 9],       [4, 9, 2, 7, 8, 6, 1, 1, 9, 4, 1, 3, 1, 8, 6, 5, 3, 0, 2, 2, 3, 0,        3, 6, 9, 1, 2, 4],       [0, 7, 3, 6, 4, 2, 3, 7, 5, 0, 9, 5, 5, 2, 7, 5, 0, 3, 6, 8, 7, 3,        3, 6, 1, 2, 3, 6]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.expand_dims(x,axis=<span class="number">0</span>) <span class="comment"># é«˜ç»´åº¦ä¹‹å‰æ’å…¥æ–°ç»´åº¦</span></span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432728, shape=(1, 28, 28), dtype=int32, numpy=array([[[5, 3, 3, 6, 9, 3, 0, 4, 1, 6, 3, 8, 7, 7, 5, 4, 0, 0, 8, 5, 2,         3, 6, 4, 4, 8, 8, 3],        [8, 4, 7, 9, 3, 6, 1, 7, 5, 9, 4, 9, 7, 4, 4, 8, 4, 9, 7, 9, 6,         1, 3, 5, 0, 2, 4, 2],        [3, 5, 5, 5, 7, 9, 5, 3, 6, 0, 7, 8, 0, 0, 4, 7, 8, 7, 4, 1, 9,         9, 2, 6, 6, 2, 0, 3],        [3, 5, 5, 2, 4, 0, 2, 5, 0, 2, 3, 2, 1, 0, 1, 4, 5, 3, 1, 9, 5,         3, 0, 5, 8, 1, 9, 4],        [6, 0, 1, 4, 0, 0, 7, 7, 0, 4, 3, 3, 3, 5, 2, 3, 5, 6, 4, 6, 4,         1, 3, 2, 8, 5, 8, 4],        [1, 2, 9, 3, 2, 3, 4, 4, 0, 0, 6, 6, 4, 0, 2, 7, 2, 2, 4, 2, 6,         0, 4, 0, 5, 5, 4, 5],        [3, 2, 6, 7, 7, 1, 0, 3, 3, 5, 5, 7, 8, 1, 6, 5, 5, 4, 3, 2, 9,         0, 0, 3, 7, 0, 0, 0],        [7, 7, 0, 7, 9, 8, 4, 5, 3, 7, 3, 3, 6, 1, 4, 8, 9, 2, 2, 8, 3,         1, 0, 9, 3, 3, 2, 4],        [9, 8, 8, 1, 4, 9, 3, 0, 5, 9, 6, 6, 8, 1, 4, 9, 8, 9, 8, 9, 3,         8, 7, 5, 8, 0, 3, 6],        [0, 8, 3, 1, 2, 1, 9, 4, 5, 0, 7, 1, 3, 5, 4, 4, 7, 3, 6, 5, 5,         6, 2, 0, 6, 1, 4, 8],        [4, 2, 6, 1, 7, 5, 6, 2, 4, 0, 9, 8, 0, 0, 0, 6, 8, 2, 3, 0, 0,         5, 6, 6, 9, 8, 4, 9],        [7, 3, 2, 5, 2, 5, 4, 3, 6, 4, 9, 2, 1, 7, 6, 4, 4, 5, 7, 7, 1,         6, 4, 0, 3, 6, 4, 8],        [1, 7, 6, 0, 4, 8, 0, 3, 0, 2, 0, 7, 0, 5, 6, 5, 3, 1, 4, 3, 8,         8, 8, 6, 7, 3, 1, 7],        [0, 8, 0, 5, 5, 2, 2, 5, 2, 1, 4, 4, 1, 4, 9, 4, 4, 1, 7, 1, 7,         7, 4, 1, 8, 2, 3, 2],        [5, 3, 5, 6, 6, 0, 9, 2, 9, 2, 8, 2, 1, 4, 0, 4, 7, 3, 0, 3, 8,         1, 5, 7, 5, 4, 6, 6],        [4, 7, 0, 1, 9, 6, 1, 1, 2, 1, 8, 2, 2, 9, 4, 7, 5, 1, 2, 4, 7,         5, 7, 6, 6, 4, 1, 5],        [4, 5, 7, 8, 2, 0, 5, 3, 4, 6, 3, 4, 5, 4, 9, 3, 6, 0, 2, 7, 1,         0, 1, 7, 2, 4, 4, 0],        [5, 3, 9, 1, 2, 4, 4, 8, 8, 2, 2, 1, 6, 4, 5, 2, 5, 0, 0, 1, 6,         4, 5, 9, 5, 8, 9, 5],        [6, 1, 1, 8, 9, 6, 8, 9, 9, 8, 2, 0, 9, 7, 9, 0, 9, 7, 0, 5, 3,         8, 0, 9, 1, 8, 9, 4],        [9, 1, 7, 3, 3, 7, 8, 3, 2, 2, 6, 3, 2, 1, 0, 5, 8, 2, 8, 4, 5,         5, 2, 9, 9, 6, 8, 3],        [0, 3, 8, 2, 5, 1, 6, 3, 5, 0, 2, 3, 9, 9, 4, 6, 1, 9, 3, 8, 7,         8, 8, 7, 2, 4, 4, 8],        [6, 7, 8, 6, 6, 6, 5, 2, 1, 8, 4, 7, 8, 9, 9, 4, 5, 2, 4, 7, 8,         5, 9, 3, 0, 0, 9, 1],        [7, 8, 4, 9, 4, 8, 9, 3, 5, 4, 8, 3, 7, 9, 2, 0, 2, 3, 8, 5, 6,         0, 4, 3, 6, 1, 6, 3],        [2, 4, 3, 9, 0, 2, 5, 9, 0, 0, 0, 3, 1, 2, 4, 3, 1, 4, 5, 7, 4,         3, 9, 6, 9, 3, 6, 6],        [3, 8, 6, 4, 0, 0, 3, 8, 1, 1, 5, 4, 8, 4, 8, 3, 3, 1, 1, 9, 6,         4, 9, 7, 6, 7, 3, 7],        [4, 3, 7, 5, 3, 4, 0, 4, 8, 2, 5, 1, 2, 8, 2, 6, 4, 7, 7, 6, 3,         5, 9, 6, 4, 2, 5, 9],        [4, 9, 2, 7, 8, 6, 1, 1, 9, 4, 1, 3, 1, 8, 6, 5, 3, 0, 2, 2, 3,         0, 3, 6, 9, 1, 2, 4],        [0, 7, 3, 6, 4, 2, 3, 7, 5, 0, 9, 5, 5, 2, 7, 5, 0, 3, 6, 8, 7,         3, 3, 6, 1, 2, 3, 6]]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.squeeze(x, axis=<span class="number">0</span>) <span class="comment"># åˆ é™¤å›¾ç‰‡æ•°é‡ç»´åº¦</span></span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432729, shape=(28, 28), dtype=int32, numpy=array([[5, 3, 3, 6, 9, 3, 0, 4, 1, 6, 3, 8, 7, 7, 5, 4, 0, 0, 8, 5, 2, 3,        6, 4, 4, 8, 8, 3],       [8, 4, 7, 9, 3, 6, 1, 7, 5, 9, 4, 9, 7, 4, 4, 8, 4, 9, 7, 9, 6, 1,        3, 5, 0, 2, 4, 2],       [3, 5, 5, 5, 7, 9, 5, 3, 6, 0, 7, 8, 0, 0, 4, 7, 8, 7, 4, 1, 9, 9,        2, 6, 6, 2, 0, 3],       [3, 5, 5, 2, 4, 0, 2, 5, 0, 2, 3, 2, 1, 0, 1, 4, 5, 3, 1, 9, 5, 3,        0, 5, 8, 1, 9, 4],       [6, 0, 1, 4, 0, 0, 7, 7, 0, 4, 3, 3, 3, 5, 2, 3, 5, 6, 4, 6, 4, 1,        3, 2, 8, 5, 8, 4],       [1, 2, 9, 3, 2, 3, 4, 4, 0, 0, 6, 6, 4, 0, 2, 7, 2, 2, 4, 2, 6, 0,        4, 0, 5, 5, 4, 5],       [3, 2, 6, 7, 7, 1, 0, 3, 3, 5, 5, 7, 8, 1, 6, 5, 5, 4, 3, 2, 9, 0,        0, 3, 7, 0, 0, 0],       [7, 7, 0, 7, 9, 8, 4, 5, 3, 7, 3, 3, 6, 1, 4, 8, 9, 2, 2, 8, 3, 1,        0, 9, 3, 3, 2, 4],       [9, 8, 8, 1, 4, 9, 3, 0, 5, 9, 6, 6, 8, 1, 4, 9, 8, 9, 8, 9, 3, 8,        7, 5, 8, 0, 3, 6],       [0, 8, 3, 1, 2, 1, 9, 4, 5, 0, 7, 1, 3, 5, 4, 4, 7, 3, 6, 5, 5, 6,        2, 0, 6, 1, 4, 8],       [4, 2, 6, 1, 7, 5, 6, 2, 4, 0, 9, 8, 0, 0, 0, 6, 8, 2, 3, 0, 0, 5,        6, 6, 9, 8, 4, 9],       [7, 3, 2, 5, 2, 5, 4, 3, 6, 4, 9, 2, 1, 7, 6, 4, 4, 5, 7, 7, 1, 6,        4, 0, 3, 6, 4, 8],       [1, 7, 6, 0, 4, 8, 0, 3, 0, 2, 0, 7, 0, 5, 6, 5, 3, 1, 4, 3, 8, 8,        8, 6, 7, 3, 1, 7],       [0, 8, 0, 5, 5, 2, 2, 5, 2, 1, 4, 4, 1, 4, 9, 4, 4, 1, 7, 1, 7, 7,        4, 1, 8, 2, 3, 2],       [5, 3, 5, 6, 6, 0, 9, 2, 9, 2, 8, 2, 1, 4, 0, 4, 7, 3, 0, 3, 8, 1,        5, 7, 5, 4, 6, 6],       [4, 7, 0, 1, 9, 6, 1, 1, 2, 1, 8, 2, 2, 9, 4, 7, 5, 1, 2, 4, 7, 5,        7, 6, 6, 4, 1, 5],       [4, 5, 7, 8, 2, 0, 5, 3, 4, 6, 3, 4, 5, 4, 9, 3, 6, 0, 2, 7, 1, 0,        1, 7, 2, 4, 4, 0],       [5, 3, 9, 1, 2, 4, 4, 8, 8, 2, 2, 1, 6, 4, 5, 2, 5, 0, 0, 1, 6, 4,        5, 9, 5, 8, 9, 5],       [6, 1, 1, 8, 9, 6, 8, 9, 9, 8, 2, 0, 9, 7, 9, 0, 9, 7, 0, 5, 3, 8,        0, 9, 1, 8, 9, 4],       [9, 1, 7, 3, 3, 7, 8, 3, 2, 2, 6, 3, 2, 1, 0, 5, 8, 2, 8, 4, 5, 5,        2, 9, 9, 6, 8, 3],       [0, 3, 8, 2, 5, 1, 6, 3, 5, 0, 2, 3, 9, 9, 4, 6, 1, 9, 3, 8, 7, 8,        8, 7, 2, 4, 4, 8],       [6, 7, 8, 6, 6, 6, 5, 2, 1, 8, 4, 7, 8, 9, 9, 4, 5, 2, 4, 7, 8, 5,        9, 3, 0, 0, 9, 1],       [7, 8, 4, 9, 4, 8, 9, 3, 5, 4, 8, 3, 7, 9, 2, 0, 2, 3, 8, 5, 6, 0,        4, 3, 6, 1, 6, 3],       [2, 4, 3, 9, 0, 2, 5, 9, 0, 0, 0, 3, 1, 2, 4, 3, 1, 4, 5, 7, 4, 3,        9, 6, 9, 3, 6, 6],       [3, 8, 6, 4, 0, 0, 3, 8, 1, 1, 5, 4, 8, 4, 8, 3, 3, 1, 1, 9, 6, 4,        9, 7, 6, 7, 3, 7],       [4, 3, 7, 5, 3, 4, 0, 4, 8, 2, 5, 1, 2, 8, 2, 6, 4, 7, 7, 6, 3, 5,        9, 6, 4, 2, 5, 9],       [4, 9, 2, 7, 8, 6, 1, 1, 9, 4, 1, 3, 1, 8, 6, 5, 3, 0, 2, 2, 3, 0,        3, 6, 9, 1, 2, 4],       [0, 7, 3, 6, 4, 2, 3, 7, 5, 0, 9, 5, 5, 2, 7, 5, 0, 3, 6, 8, 7, 3,        3, 6, 1, 2, 3, 6]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.uniform([<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>],maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">tf.squeeze(x) <span class="comment"># åˆ é™¤æ‰€æœ‰é•¿åº¦ä¸º 1 çš„ç»´åº¦</span></span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=391, shape=(28, 28), dtype=int32, numpy=array([[3, 5, 3, 9, 7, 0, 0, 8, 3, 1, 4, 8, 5, 7, 8, 6, 9, 4, 1, 1, 5, 8,        6, 2, 8, 3, 5, 3],       [4, 8, 9, 7, 6, 0, 8, 7, 8, 3, 1, 3, 5, 9, 3, 6, 6, 2, 3, 1, 7, 6,        9, 6, 2, 7, 4, 2],       [5, 1, 2, 0, 3, 7, 5, 0, 7, 4, 7, 7, 5, 8, 9, 2, 2, 6, 7, 3, 8, 9,        4, 1, 6, 5, 4, 7],       [2, 5, 3, 4, 4, 7, 5, 5, 1, 1, 7, 0, 9, 8, 4, 3, 8, 6, 9, 3, 3, 2,        1, 2, 4, 4, 4, 7],       [9, 2, 3, 0, 3, 5, 4, 5, 8, 7, 0, 8, 6, 4, 9, 7, 1, 8, 3, 6, 5, 7,        0, 4, 4, 2, 6, 9],       [9, 3, 4, 4, 6, 8, 1, 7, 0, 8, 6, 0, 0, 2, 8, 3, 5, 0, 6, 6, 8, 4,        8, 9, 4, 0, 9, 4],       [3, 8, 5, 9, 4, 5, 1, 8, 5, 3, 5, 9, 7, 8, 9, 2, 8, 8, 5, 5, 5, 9,        1, 9, 3, 4, 4, 8],       [9, 5, 9, 4, 2, 0, 8, 1, 4, 2, 0, 3, 6, 9, 7, 6, 0, 5, 8, 9, 0, 8,        0, 0, 3, 1, 1, 7],       [4, 6, 9, 0, 6, 6, 7, 6, 2, 3, 1, 7, 8, 7, 8, 5, 2, 5, 4, 5, 1, 9,        9, 6, 6, 4, 4, 8],       [1, 4, 2, 6, 7, 8, 4, 9, 2, 7, 8, 8, 0, 7, 0, 3, 8, 2, 3, 1, 9, 2,        7, 9, 1, 1, 6, 7],       [0, 1, 7, 6, 4, 1, 4, 3, 0, 0, 7, 4, 7, 2, 6, 1, 3, 1, 8, 9, 1, 5,        7, 3, 4, 3, 4, 6],       [7, 7, 7, 3, 6, 6, 3, 6, 2, 8, 0, 3, 5, 5, 9, 1, 5, 0, 1, 8, 3, 9,        7, 6, 7, 8, 0, 9],       [3, 3, 9, 2, 4, 8, 1, 8, 8, 7, 5, 7, 4, 0, 1, 8, 5, 2, 9, 1, 1, 5,        7, 5, 4, 0, 5, 5],       [7, 9, 7, 1, 7, 7, 1, 5, 7, 1, 8, 3, 0, 5, 1, 9, 4, 0, 2, 4, 4, 4,        5, 1, 8, 0, 2, 8],       [8, 6, 4, 6, 5, 3, 3, 6, 7, 6, 1, 9, 0, 3, 6, 3, 9, 3, 0, 0, 4, 2,        5, 5, 7, 1, 2, 0],       [6, 7, 0, 4, 3, 2, 7, 8, 4, 4, 5, 8, 5, 0, 0, 4, 3, 4, 4, 9, 6, 6,        8, 8, 4, 9, 8, 7],       [1, 3, 5, 7, 6, 0, 2, 2, 1, 9, 8, 6, 6, 6, 0, 3, 6, 8, 9, 4, 0, 4,        4, 0, 8, 0, 8, 9],       [4, 6, 1, 4, 4, 8, 9, 7, 6, 8, 7, 9, 0, 8, 8, 3, 0, 5, 9, 8, 6, 6,        9, 6, 5, 1, 0, 9],       [0, 3, 1, 4, 2, 1, 2, 7, 6, 2, 1, 3, 0, 6, 6, 0, 7, 9, 5, 7, 7, 9,        7, 6, 9, 9, 2, 7],       [2, 8, 2, 1, 4, 4, 8, 8, 0, 3, 4, 6, 8, 2, 4, 5, 8, 3, 7, 5, 1, 6,        7, 5, 6, 3, 1, 2],       [4, 0, 7, 4, 0, 8, 3, 4, 9, 0, 0, 8, 9, 1, 1, 9, 7, 8, 9, 1, 9, 2,        0, 7, 3, 6, 6, 2],       [0, 4, 0, 9, 8, 3, 2, 5, 9, 1, 0, 2, 7, 9, 9, 7, 4, 5, 0, 0, 2, 7,        7, 2, 1, 7, 5, 3],       [9, 6, 3, 2, 6, 3, 1, 5, 1, 6, 6, 8, 9, 8, 3, 9, 6, 2, 8, 2, 3, 5,        9, 6, 8, 0, 9, 5],       [0, 3, 4, 7, 3, 5, 5, 0, 7, 3, 7, 7, 2, 1, 8, 4, 9, 7, 9, 1, 2, 5,        9, 7, 7, 7, 8, 0],       [6, 7, 3, 1, 2, 6, 4, 8, 5, 5, 4, 3, 7, 5, 4, 4, 1, 9, 6, 7, 6, 6,        5, 2, 4, 0, 3, 3],       [8, 8, 4, 5, 9, 3, 2, 7, 6, 5, 8, 4, 5, 4, 8, 3, 4, 6, 7, 3, 3, 4,        9, 8, 0, 4, 1, 2],       [5, 5, 9, 3, 6, 7, 4, 5, 2, 3, 4, 8, 0, 5, 3, 4, 1, 0, 3, 7, 6, 9,        3, 8, 9, 4, 9, 8],       [1, 4, 2, 1, 9, 3, 4, 7, 8, 1, 9, 3, 5, 8, 9, 4, 8, 3, 6, 9, 2, 1,        7, 7, 4, 4, 9, 3]], dtype=int32)&gt;</code></pre><h3 id="äº¤æ¢ç»´åº¦"><a href="#äº¤æ¢ç»´åº¦" class="headerlink" title="äº¤æ¢ç»´åº¦"></a>äº¤æ¢ç»´åº¦</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.uniform([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([[[[0.5282526  0.3555627  0.41090894 0.47944117]   [0.06685734 0.73899055 0.274917   0.786981  ]   [0.5963073  0.47864938 0.4129647  0.9002305 ]]  [[0.70865    0.46636987 0.76260746 0.23017025]   [0.2235589  0.3718114  0.8150687  0.30672145]   [0.78165174 0.63648796 0.61503696 0.35355854]]]], shape=(1, 2, 3, 4), dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># äº¤æ¢ç»´åº¦</span></span><br><span class="line">tf.transpose(x,perm=[<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432771, shape=(1, 4, 2, 3), dtype=float32, numpy=array([[[[0.5282526 , 0.06685734, 0.5963073 ],         [0.70865   , 0.2235589 , 0.78165174]],        [[0.3555627 , 0.73899055, 0.47864938],         [0.46636987, 0.3718114 , 0.63648796]],        [[0.41090894, 0.274917  , 0.4129647 ],         [0.76260746, 0.8150687 , 0.61503696]],        [[0.47944117, 0.786981  , 0.9002305 ],         [0.23017025, 0.30672145, 0.35355854]]]], dtype=float32)&gt;</code></pre><h3 id="å¤åˆ¶æ•°æ®"><a href="#å¤åˆ¶æ•°æ®" class="headerlink" title="å¤åˆ¶æ•°æ®"></a>å¤åˆ¶æ•°æ®</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºå‘é‡ b</span></span><br><span class="line">b = tf.constant([<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># æ’å…¥æ–°ç»´åº¦ï¼Œå˜æˆçŸ©é˜µ</span></span><br><span class="line">b = tf.expand_dims(b, axis=<span class="number">0</span>) </span><br><span class="line">b</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([1 2], shape=(2,), dtype=int32)&lt;tf.Tensor: id=432780, shape=(1, 2), dtype=int32, numpy=array([[1, 2]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ ·æœ¬è¡Œç»´åº¦ä¸Šå¤åˆ¶ä¸€ä»½</span></span><br><span class="line">b = tf.tile(b, multiples=[<span class="number">2</span>,<span class="number">1</span>]) </span><br><span class="line">b</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=412, shape=(2, 2), dtype=int32, numpy=array([[1, 2],       [1, 2]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.<span class="built_in">range</span>(<span class="number">4</span>)</span><br><span class="line"><span class="comment"># åˆ›å»º 2 è¡Œ 2 åˆ—çŸ©é˜µ</span></span><br><span class="line">x=tf.reshape(x,[<span class="number">2</span>,<span class="number">2</span>]) </span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432787, shape=(2, 2), dtype=int32, numpy=array([[0, 1],       [2, 3]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ—ç»´åº¦å¤åˆ¶ä¸€ä»½</span></span><br><span class="line">x = tf.tile(x,multiples=[<span class="number">1</span>,<span class="number">2</span>]) </span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432789, shape=(2, 4), dtype=int32, numpy=array([[0, 1, 0, 1],       [2, 3, 2, 3]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è¡Œç»´åº¦å¤åˆ¶ä¸€ä»½</span></span><br><span class="line">x = tf.tile(x,multiples=[<span class="number">2</span>,<span class="number">1</span>]) </span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432791, shape=(4, 4), dtype=int32, numpy=array([[0, 1, 0, 1],       [2, 3, 2, 3],       [0, 1, 0, 1],       [2, 3, 2, 3]], dtype=int32)&gt;</code></pre><h2 id="Broadcasting"><a href="#Broadcasting" class="headerlink" title="Broadcasting"></a>Broadcasting</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ›å»ºçŸ©é˜µ</span></span><br><span class="line">A = tf.random.normal([<span class="number">32</span>,<span class="number">1</span>]) </span><br><span class="line"><span class="comment"># æ‰©å±•ä¸º 4D å¼ é‡</span></span><br><span class="line">tf.broadcast_to(A, [<span class="number">2</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=430, shape=(2, 32, 32, 3), dtype=float32, numpy=array([[[[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        ...,        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]]],</code></pre><p>â€‹<br>           [[[ 0.04447514,  0.04447514,  0.04447514],<br>             [-0.8540972 , -0.8540972 , -0.8540972 ],<br>             [ 0.30159432,  0.30159432,  0.30159432],<br>             â€¦,<br>             [-0.84129137, -0.84129137, -0.84129137],<br>             [ 0.58230823,  0.58230823,  0.58230823],<br>             [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],</p><pre><code>        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        ...,        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">A = tf.random.normal([<span class="number">32</span>,<span class="number">2</span>])</span><br><span class="line"><span class="comment"># ä¸ç¬¦åˆ Broadcasting æ¡ä»¶</span></span><br><span class="line"><span class="keyword">try</span>: </span><br><span class="line">    tf.broadcast_to(A, [<span class="number">2</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">4</span>])</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure><pre><code>Incompatible shapes: [32,2] vs. [2,32,32,4] [Op:BroadcastTo]</code></pre><h2 id="æ•°å­¦è¿ç®—"><a href="#æ•°å­¦è¿ç®—" class="headerlink" title="æ•°å­¦è¿ç®—"></a>æ•°å­¦è¿ç®—</h2><h3 id="åŠ ã€å‡ã€ä¹˜ã€é™¤è¿ç®—"><a href="#åŠ ã€å‡ã€ä¹˜ã€é™¤è¿ç®—" class="headerlink" title="åŠ ã€å‡ã€ä¹˜ã€é™¤è¿ç®—"></a>åŠ ã€å‡ã€ä¹˜ã€é™¤è¿ç®—</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line">b = tf.constant(<span class="number">2</span>)</span><br><span class="line"><span class="comment"># æ•´é™¤è¿ç®—</span></span><br><span class="line">a//b </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=443, shape=(5,), dtype=int32, numpy=array([0, 0, 1, 1, 2], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä½™é™¤è¿ç®—</span></span><br><span class="line">a%b </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=444, shape=(5,), dtype=int32, numpy=array([0, 1, 0, 1, 0], dtype=int32)&gt;</code></pre><h3 id="ä¹˜æ–¹è¿ç®—"><a href="#ä¹˜æ–¹è¿ç®—" class="headerlink" title="ä¹˜æ–¹è¿ç®—"></a>ä¹˜æ–¹è¿ç®—</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.<span class="built_in">range</span>(<span class="number">4</span>)</span><br><span class="line"><span class="comment"># ä¹˜æ–¹è¿ç®—</span></span><br><span class="line">tf.<span class="built_in">pow</span>(x,<span class="number">3</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=450, shape=(4,), dtype=int32, numpy=array([ 0,  1,  8, 27], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¹˜æ–¹è¿ç®—ç¬¦</span></span><br><span class="line">x**<span class="number">2</span> </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=452, shape=(4,), dtype=int32, numpy=array([0, 1, 4, 9], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=tf.constant([<span class="number">1.</span>,<span class="number">4.</span>,<span class="number">9.</span>])</span><br><span class="line"><span class="comment"># å¹³æ–¹æ ¹</span></span><br><span class="line">x**(<span class="number">0.5</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=455, shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = tf.<span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># è½¬æ¢ä¸ºæµ®ç‚¹æ•°</span></span><br><span class="line">x = tf.cast(x, dtype=tf.float32) </span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># å¹³æ–¹</span></span><br><span class="line">x = tf.square(x) </span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)tf.Tensor([0. 1. 2. 3. 4.], shape=(5,), dtype=float32)tf.Tensor([ 0.  1.  4.  9. 16.], shape=(5,), dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¹³æ–¹æ ¹</span></span><br><span class="line">tf.sqrt(x) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432798, shape=(5,), dtype=float32, numpy=array([0.        , 0.99999994, 1.9999999 , 2.9999998 , 4.        ],      dtype=float32)&gt;</code></pre><h3 id="æŒ‡æ•°å’Œå¯¹æ•°è¿ç®—"><a href="#æŒ‡æ•°å’Œå¯¹æ•°è¿ç®—" class="headerlink" title="æŒ‡æ•°å’Œå¯¹æ•°è¿ç®—"></a>æŒ‡æ•°å’Œå¯¹æ•°è¿ç®—</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([<span class="number">1.</span>,<span class="number">2.</span>,<span class="number">3.</span>])</span><br><span class="line"><span class="comment"># æŒ‡æ•°è¿ç®—</span></span><br><span class="line"><span class="number">2</span>**x </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=465, shape=(3,), dtype=float32, numpy=array([2., 4., 8.], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è‡ªç„¶æŒ‡æ•°è¿ç®—</span></span><br><span class="line">tf.exp(<span class="number">1.</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=467, shape=(), dtype=float32, numpy=2.7182817&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.exp(<span class="number">3.</span>)</span><br><span class="line"><span class="comment"># å¯¹æ•°è¿ç®—</span></span><br><span class="line">tf.math.log(x) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=470, shape=(), dtype=float32, numpy=3.0&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([<span class="number">1.</span>,<span class="number">2.</span>])</span><br><span class="line">x = <span class="number">10</span>**x</span><br><span class="line"><span class="comment"># æ¢åº•å…¬å¼</span></span><br><span class="line">tf.math.log(x)/tf.math.log(<span class="number">10.</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=477, shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)&gt;</code></pre><h3 id="çŸ©é˜µç›¸ä¹˜è¿ç®—"><a href="#çŸ©é˜µç›¸ä¹˜è¿ç®—" class="headerlink" title="çŸ©é˜µç›¸ä¹˜è¿ç®—"></a>çŸ©é˜µç›¸ä¹˜è¿ç®—</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">32</span>])</span><br><span class="line">b = tf.random.normal([<span class="number">4</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">2</span>])</span><br><span class="line"><span class="comment"># æ‰¹é‡å½¢å¼çš„çŸ©é˜µç›¸ä¹˜</span></span><br><span class="line"><span class="built_in">print</span>(a@b)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([[[[ 2.93815994e+00  1.80159616e+00]   [-4.95495558e+00 -2.65059781e+00]   [ 6.36351776e+00  8.27180672e+00]   [-2.50184441e+00 -3.22499895e+00]   [-6.89737129e+00  6.43845701e+00]   [ 4.72115231e+00 -7.39528358e-01]   [-5.87444019e+00 -6.75603390e+00]   [ 8.61762238e+00  4.49309635e+00]   [ 3.18081021e+00 -1.84904563e+00]   [-5.71209073e-01  1.76863492e+00]   [-8.77548409e+00 -2.09427929e+00]   [ 6.11399221e+00  3.75506377e+00]   [-5.72681367e-01 -5.56786919e+00]   [ 1.03334942e+01 -6.21349716e+00]   [ 2.05781221e+00 -2.48031449e+00]   [-1.05474174e-01  1.17951145e+01]   [-8.32847595e+00  8.04420090e+00]   [ 1.10347319e+01 -7.15183640e+00]   [-1.10890408e+01  2.06656051e+00]   [ 2.04201794e+00 -1.72195137e-01]   [ 4.16003466e+00  2.92319274e+00]   [ 1.00829735e+01  3.50188327e+00]   [ 1.60061455e+01 -3.23914313e+00]   [-1.34949207e+00 -2.27372718e+00]   [ 1.16594486e+01 -1.30499089e+00]   [ 2.90008926e+00  6.59213543e+00]   [-3.04731274e+00 -1.17982030e-01]   [-6.25353050e+00 -1.59929824e+00]]  [[ 2.35922217e+00 -1.44711876e+00]   [-2.82181549e+00 -4.16362000e+00]   [-4.13206530e+00  1.96330786e-01]   [-1.13723636e+00 -1.90036798e+00]   [-1.42907238e+00  4.24102306e-01]   [ 1.01430655e+01  2.54081345e+00]   [-4.05478477e+00 -9.29689407e+00]   [ 1.36705666e+01  1.40576875e+00]   [-5.09379244e+00  4.66089153e+00]   [ 6.25803471e-02 -2.86052656e+00]   [-1.12946069e+00 -4.28373003e+00]   [ 5.32545996e+00  1.97562897e+00]   [ 7.16341162e+00  6.10791969e+00]   [-4.77171421e+00 -1.75261497e+00]   [-1.43213348e+01  5.44925928e+00]   [-2.13357735e+00 -2.74817157e+00]   [-6.38115454e+00  6.48117113e+00]   [-1.21313601e+01 -1.16765201e+00]   [-1.98863697e+00  1.22314978e+01]   [ 3.63174462e+00  5.20076323e+00]   [-1.05080090e+01  4.47047186e+00]   [ 8.52560043e+00 -3.26042938e+00]   [ 1.86961699e+00  1.04149675e+00]   [ 3.27967310e+00  4.52322531e+00]   [-1.08596125e+01  4.40047550e+00]   [ 3.30025196e+00 -3.57261777e-01]   [-4.17899323e+00 -5.29293346e+00]   [-6.29359818e+00  2.55025506e-01]]  [[ 2.79792500e+00 -1.14968262e+01]   [ 6.42120302e-01  8.60604167e-01]   [ 8.26789284e+00  9.11268139e+00]   [-1.24864876e+00 -1.29506755e+00]   [ 1.83019781e+00  1.32512970e+01]   [-4.38226223e+00  2.93613434e+00]   [-1.01948481e+01 -2.50259852e+00]   [-6.08818817e+00  5.71516156e-01]   [ 8.14604282e-01  8.74936581e-01]   [-9.27050591e-01  1.68381357e+00]   [-2.39078522e+00 -4.39953446e-01]   [-1.79722738e+00  2.44799304e+00]   [-6.19097829e-01  4.20792866e+00]   [-3.59187007e+00  2.05337834e+00]   [-2.02478099e+00  3.92844319e+00]   [-2.78609324e+00 -1.00785866e+01]   [ 1.35041237e-01  9.82832527e+00]   [ 3.77985573e+00 -2.92683578e+00]   [ 2.50951290e+00 -1.10158062e+00]   [-2.69217896e+00  7.27837420e+00]   [ 4.59399509e+00 -4.81438732e+00]   [ 9.01638508e+00  5.12754726e+00]   [ 5.19506645e+00 -2.35464978e+00]   [ 2.05791235e-01  3.24537897e+00]   [-6.17561936e-02  1.22012386e+01]   [ 8.34735334e-01  2.56306553e+00]   [-8.42908740e-01 -4.72223663e+00]   [ 7.59096265e-01 -8.70975971e-01]]]</code></pre><p>â€‹<br>     [[[-1.25730896e+01  1.73365784e+00]<br>       [-8.16483736e-01 -3.12521791e+00]<br>       [ 4.31258678e+00 -3.65629935e+00]<br>       [ 7.81925964e+00  2.67266393e+00]<br>       [-1.45902622e+00 -1.69710827e+00]<br>       [-4.97250271e+00  1.06699669e+00]<br>       [-1.15320644e+01  3.67050219e+00]<br>       [ 9.82042491e-01 -8.96060181e+00]<br>       [ 4.24584293e+00 -2.03312969e+00]<br>       [-8.90874267e-02 -2.19113445e+00]<br>       [ 7.03373575e+00  4.82089567e+00]<br>       [ 2.19787431e+00 -1.35815620e+00]<br>       [-4.33743429e+00 -2.77082419e+00]<br>       [-6.55539846e+00 -5.28619862e+00]<br>       [-4.10456562e+00  1.53431883e+01]<br>       [-6.97701550e+00  5.58186054e-01]<br>       [-4.06244993e+00 -1.29598303e+01]<br>       [ 1.80246496e+00 -2.77987790e+00]<br>       [-7.30259180e+00 -5.11505365e+00]<br>       [ 2.12593174e+00 -3.25598717e+00]<br>       [ 7.80677795e+00  1.99891090e-01]<br>       [ 8.46464539e+00  2.72348213e+00]<br>       [-2.32167172e+00  4.69824505e+00]<br>       [ 3.97749400e+00 -9.19138908e+00]<br>       [ 2.90814090e+00  1.26416731e+00]<br>       [-8.01068783e-01  5.13629675e+00]<br>       [-1.10610142e+01  4.88826132e+00]<br>       [-1.75804818e+00  1.23052418e+00]]</p><pre><code>  [[-5.49224281e+00 -1.18972950e+01]   [-1.71067417e+00 -7.94510078e+00]   [ 8.11289787e+00  2.97325039e+00]   [-6.18529272e+00 -1.07129316e+01]   [ 5.09897184e+00 -5.09968042e+00]   [-7.61364222e+00  5.40171003e+00]   [-6.47705889e+00 -1.68601739e+00]   [ 5.09246063e+00 -4.75051785e+00]   [-8.07900906e+00 -1.01351190e+00]   [-5.56266832e+00 -5.98014545e+00]   [-1.84528065e+00 -2.55948591e+00]   [ 1.63680077e-01 -4.52482510e+00]   [-6.17208385e+00  8.61810780e+00]   [ 2.54550838e+00  1.04630842e+01]   [ 6.78235245e+00  2.36592340e+00]   [ 5.33071947e+00  7.77984023e-01]   [ 1.59947419e+00  3.40054178e+00]   [ 9.72853303e-01  1.95867562e+00]   [-5.11668110e+00  9.07939816e+00]   [-9.91412735e+00  5.33779049e+00]   [ 6.93627453e+00  9.98051357e+00]   [-1.49268985e+00 -1.61656654e+00]   [ 6.77412367e+00  5.89341736e+00]   [-9.02515793e+00 -4.86350346e+00]   [-2.65398359e+00  6.53871584e+00]   [ 7.60008812e+00  2.23823214e+00]   [ 3.48978114e+00  7.77210045e+00]   [-1.89859509e+00  1.36791458e+01]]  [[ 6.16735172e+00 -3.06368208e+00]   [-6.22440147e+00  2.49987888e+00]   [ 1.23477805e+00 -9.58612680e-01]   [-6.32274055e+00 -3.50495398e-01]   [-2.37460756e+00  2.89988756e+00]   [ 6.76133537e+00 -4.97397709e+00]   [ 4.19915617e-01 -1.44209051e+00]   [-8.48055720e-01 -1.34412467e+00]   [ 1.47503817e+00 -4.57327032e+00]   [-8.83791351e+00  1.30507603e+01]   [ 5.04546928e+00  2.96709967e+00]   [ 1.21958218e+01 -3.70147228e-01]   [-9.32716131e-02  8.25912094e+00]   [-6.88422298e+00 -2.94276452e+00]   [-8.92567754e-01  7.48677373e-01]   [ 1.13859291e+01 -4.54786253e+00]   [ 4.14542294e+00  3.62407827e+00]   [-4.84375191e+00  7.60643148e+00]   [-3.99736214e+00  8.38322639e-01]   [ 8.50940418e+00 -3.18443274e+00]   [ 3.02693796e+00 -1.08982430e+01]   [ 5.94771481e+00  1.90185285e+00]   [ 1.79021060e-02  2.71560931e+00]   [ 1.28265166e+00  1.35003614e+00]   [-5.15541887e+00  3.48176098e+00]   [ 1.35739307e+01  1.13081062e+00]   [-1.13344326e+01  2.02814102e+00]   [-3.78427625e+00 -3.41797924e+00]]]</code></pre><p>â€‹<br>     [[[ 7.51625490e+00 -8.01126385e+00]<br>       [ 8.94779682e-01 -1.39191675e+00]<br>       [-6.38634396e+00 -7.54839706e+00]<br>       [ 5.90809202e+00 -4.73860931e+00]<br>       [ 2.89039660e+00 -5.74475765e-01]<br>       [-3.24619865e+00 -4.33766127e+00]<br>       [ 7.45817757e+00  8.72869968e+00]<br>       [ 1.70315895e+01 -1.43109741e+01]<br>       [ 6.71465302e+00  2.36530209e+00]<br>       [ 2.37234616e+00  9.54824162e+00]<br>       [ 1.24315548e+01 -8.32226753e-01]<br>       [ 1.15248704e+00  6.42775774e+00]<br>       [-2.05694604e+00 -5.29237223e+00]<br>       [ 1.06061993e+01  4.43905163e+00]<br>       [ 3.32259560e+00  2.86404061e+00]<br>       [-1.26070702e+00 -3.86716032e+00]<br>       [-7.17960167e+00 -5.47068119e+00]<br>       [ 6.13063002e+00 -1.27777729e+01]<br>       [-4.77525711e+00 -2.89896202e+00]<br>       [ 5.04258776e+00  1.05476036e+01]<br>       [-4.72102404e+00  4.53035545e+00]<br>       [ 8.30504322e+00 -6.72617435e+00]<br>       [ 1.51879632e+00 -7.57512569e+00]<br>       [ 5.25161076e+00 -6.00039482e+00]<br>       [-2.66712689e+00 -3.15567350e+00]<br>       [ 6.98167515e+00  1.21508999e+01]<br>       [-3.58145714e+00  1.01358452e+01]<br>       [-7.68432474e+00  6.27517796e+00]]</p><pre><code>  [[-3.85787821e+00  4.13319540e+00]   [ 4.08870316e+00  8.98323441e+00]   [ 2.88623333e-01  2.08936238e+00]   [-1.27303381e+01 -3.72204494e+00]   [-1.63620949e-01  4.14640725e-01]   [-9.77903843e+00 -9.83979321e+00]   [ 1.20987940e+01 -1.00569272e+00]   [-9.52555597e-01 -7.21974373e-01]   [-7.53700542e+00 -1.03328714e+01]   [ 3.82278275e+00  7.92873979e-01]   [ 1.62820339e+01  9.25348282e-01]   [-2.99300981e+00 -4.05044317e+00]   [-1.71284425e+00  3.32610369e-01]   [ 8.45957184e+00  3.01560092e+00]   [ 9.61618781e-01  4.84845543e+00]   [-5.04883003e+00 -4.64504576e+00]   [-4.88548994e-01  4.22385454e+00]   [-3.06538558e+00 -2.68467999e+00]   [ 1.44536438e+01 -1.67332339e+00]   [-1.20380235e+00 -3.01969767e-01]   [-1.25808067e+01 -1.83691287e+00]   [ 7.00172246e-01 -5.44080067e+00]   [ 3.71728969e+00 -6.50164127e+00]   [ 3.44825792e+00  2.27989483e+00]   [-1.16813726e+01  3.55064964e+00]   [-6.76289463e+00 -1.25415869e+01]   [ 1.86627662e+00  4.91928959e+00]   [ 2.37216616e+00 -3.23613596e+00]]  [[ 5.60678053e+00  6.07894707e+00]   [-6.23391962e+00 -1.82450306e+00]   [ 6.90571690e+00 -2.60890079e+00]   [ 3.98191905e+00 -2.60109711e+00]   [ 3.79411244e+00 -7.30271769e+00]   [-8.19082737e+00 -4.81762362e+00]   [ 1.01562176e+01 -9.18346643e-02]   [ 5.15106916e-01 -1.88746595e+00]   [-7.10526466e-01  4.75524092e+00]   [ 4.28777647e+00 -4.28609967e-01]   [ 2.94255161e+00 -2.76411390e+00]   [-5.01211119e+00 -1.35121047e-01]   [ 4.88255644e+00  7.48982000e+00]   [-2.94339252e+00 -1.49728453e+00]   [-5.28226614e-01  1.13798523e+01]   [-3.26653433e+00 -1.12711830e+01]   [ 6.92280245e+00  4.46824360e+00]   [-1.07686818e-02  5.99187469e+00]   [-2.30055904e+00 -2.35181737e+00]   [-1.86744165e+00 -9.12775040e-01]   [ 5.70386982e+00  2.56417489e+00]   [-4.37073708e-01 -4.62391090e+00]   [-8.43499756e+00  9.08772826e-01]   [-5.64418888e+00 -5.02650261e+00]   [ 3.92685270e+00 -5.31071186e+00]   [ 6.36297584e-01  2.63665223e+00]   [-7.71557522e+00  4.19800425e+00]   [ 3.64932895e+00  2.46329069e+00]]]</code></pre><p>â€‹<br>     [[[ 6.65752888e-01  3.40558529e-01]<br>       [ 4.08683634e+00  6.27357101e+00]<br>       [-2.77316380e+00  5.83889532e+00]<br>       [-2.01864777e+01 -8.63007069e+00]<br>       [ 4.85101509e+00  1.56102419e-01]<br>       [ 5.13551521e+00  7.00347781e-01]<br>       [ 4.66926765e+00  1.13918304e+01]<br>       [ 1.17937775e+01 -5.75443983e+00]<br>       [ 5.18499660e+00  2.47753906e+01]<br>       [-4.94616604e+00  1.09324312e+00]<br>       [ 7.08940148e-01  5.36628440e-02]<br>       [-6.22777748e+00 -6.08889389e+00]<br>       [ 8.21062326e-01  5.73018026e+00]<br>       [-1.01816578e+01 -5.96292210e+00]<br>       [-3.45601702e+00 -5.80823088e+00]<br>       [-7.81425619e+00 -1.54714165e+01]<br>       [ 6.15157843e+00  4.41321850e+00]<br>       [ 2.28190422e-02 -1.40392697e+00]<br>       [ 5.86180115e+00  2.66614532e+00]<br>       [-1.21994901e+00  6.87365246e+00]<br>       [ 7.62740707e+00 -1.52388859e+00]<br>       [-8.03575134e+00 -1.35383148e+01]<br>       [-1.75186968e+00 -1.95710063e+00]<br>       [-8.72407794e-01 -8.31413174e+00]<br>       [-1.38678074e+01 -3.35018563e+00]<br>       [ 1.02961273e+01  5.95636034e+00]<br>       [ 7.15158939e+00  9.47603941e-01]<br>       [ 3.59655428e+00 -3.57616353e+00]]</p><pre><code>  [[-7.15814590e+00 -1.73663855e-01]   [-5.33630848e+00  2.23019302e-01]   [-3.60880065e+00  1.16919529e+00]   [ 1.65422618e+00  3.21728516e+00]   [ 1.86843979e+00  1.13296022e+01]   [-6.71664524e+00  8.06290245e+00]   [-3.82262254e+00  4.57042742e+00]   [-7.61132431e+00  7.53255653e+00]   [ 1.63969231e+00 -1.19336343e+00]   [ 2.03410006e+00  5.48414516e+00]   [ 7.98875904e+00 -6.00354958e+00]   [ 5.37972260e+00 -3.13939238e+00]   [ 6.52196217e+00  5.99524212e+00]   [-3.65084100e+00  5.70605898e+00]   [ 5.66238022e+00 -4.25603628e-01]   [ 1.31335664e+00  3.34762931e-01]   [ 4.95460320e+00 -7.73174858e+00]   [-6.06322289e-02  7.14966822e+00]   [ 4.30868864e+00 -4.49330187e+00]   [ 3.00062609e+00 -3.45171928e+00]   [-8.88646841e-01  4.49364281e+00]   [-1.37166762e+00 -9.60632420e+00]   [ 2.72169065e+00 -2.02102685e+00]   [ 4.06615162e+00  2.21987987e+00]   [ 4.58932543e+00 -6.33985901e+00]   [-7.59764194e+00 -8.69492054e-01]   [ 6.72914386e-01  3.37907672e-02]   [-9.57373238e+00  4.29612064e+00]]  [[ 2.07057667e+00  2.49500203e+00]   [-2.39765930e+00  6.45140171e-01]   [ 9.70951462e+00  1.52998376e+00]   [ 9.77593803e+00  8.06670094e+00]   [ 8.35551929e+00  7.26291513e+00]   [-9.06231880e-01 -9.31769133e-01]   [-6.77584314e+00  3.27285552e+00]   [ 5.13162661e+00 -5.17782736e+00]   [-3.71608639e+00 -5.12819290e-01]   [ 1.48577709e+01 -2.64512122e-01]   [ 6.44747496e-01 -9.95941162e-02]   [ 1.04961805e+01 -3.98670554e+00]   [ 2.51394081e+00  1.80438447e+00]   [-5.59201813e+00  1.18733444e+01]   [-2.31048003e-01 -1.12039871e+01]   [-1.62683907e+01  2.02177715e+00]   [ 1.14540329e+01  2.30115056e-02]   [-1.10159683e+01 -3.24261713e+00]   [-1.33181334e+01 -8.00105953e+00]   [ 6.21838617e+00  8.89258957e+00]   [ 1.58339548e+00 -2.27107620e+00]   [-4.17989254e-01 -2.85755348e+00]   [-2.48508906e+00  9.64674568e+00]   [-1.08764257e+01  2.08483315e+00]   [ 9.77210236e+00  2.50418329e+00]   [-1.62253022e+00  1.67334347e+01]   [ 6.42501354e-01  2.53464675e+00]   [-1.12935200e+01  3.39891338e+00]]]], shape=(4, 3, 28, 2), dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(tf.matmul(a,b))</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([[[[ 2.93815994e+00  1.80159616e+00]   [-4.95495558e+00 -2.65059781e+00]   [ 6.36351776e+00  8.27180672e+00]   [-2.50184441e+00 -3.22499895e+00]   [-6.89737129e+00  6.43845701e+00]   [ 4.72115231e+00 -7.39528358e-01]   [-5.87444019e+00 -6.75603390e+00]   [ 8.61762238e+00  4.49309635e+00]   [ 3.18081021e+00 -1.84904563e+00]   [-5.71209073e-01  1.76863492e+00]   [-8.77548409e+00 -2.09427929e+00]   [ 6.11399221e+00  3.75506377e+00]   [-5.72681367e-01 -5.56786919e+00]   [ 1.03334942e+01 -6.21349716e+00]   [ 2.05781221e+00 -2.48031449e+00]   [-1.05474174e-01  1.17951145e+01]   [-8.32847595e+00  8.04420090e+00]   [ 1.10347319e+01 -7.15183640e+00]   [-1.10890408e+01  2.06656051e+00]   [ 2.04201794e+00 -1.72195137e-01]   [ 4.16003466e+00  2.92319274e+00]   [ 1.00829735e+01  3.50188327e+00]   [ 1.60061455e+01 -3.23914313e+00]   [-1.34949207e+00 -2.27372718e+00]   [ 1.16594486e+01 -1.30499089e+00]   [ 2.90008926e+00  6.59213543e+00]   [-3.04731274e+00 -1.17982030e-01]   [-6.25353050e+00 -1.59929824e+00]]  [[ 2.35922217e+00 -1.44711876e+00]   [-2.82181549e+00 -4.16362000e+00]   [-4.13206530e+00  1.96330786e-01]   [-1.13723636e+00 -1.90036798e+00]   [-1.42907238e+00  4.24102306e-01]   [ 1.01430655e+01  2.54081345e+00]   [-4.05478477e+00 -9.29689407e+00]   [ 1.36705666e+01  1.40576875e+00]   [-5.09379244e+00  4.66089153e+00]   [ 6.25803471e-02 -2.86052656e+00]   [-1.12946069e+00 -4.28373003e+00]   [ 5.32545996e+00  1.97562897e+00]   [ 7.16341162e+00  6.10791969e+00]   [-4.77171421e+00 -1.75261497e+00]   [-1.43213348e+01  5.44925928e+00]   [-2.13357735e+00 -2.74817157e+00]   [-6.38115454e+00  6.48117113e+00]   [-1.21313601e+01 -1.16765201e+00]   [-1.98863697e+00  1.22314978e+01]   [ 3.63174462e+00  5.20076323e+00]   [-1.05080090e+01  4.47047186e+00]   [ 8.52560043e+00 -3.26042938e+00]   [ 1.86961699e+00  1.04149675e+00]   [ 3.27967310e+00  4.52322531e+00]   [-1.08596125e+01  4.40047550e+00]   [ 3.30025196e+00 -3.57261777e-01]   [-4.17899323e+00 -5.29293346e+00]   [-6.29359818e+00  2.55025506e-01]]  [[ 2.79792500e+00 -1.14968262e+01]   [ 6.42120302e-01  8.60604167e-01]   [ 8.26789284e+00  9.11268139e+00]   [-1.24864876e+00 -1.29506755e+00]   [ 1.83019781e+00  1.32512970e+01]   [-4.38226223e+00  2.93613434e+00]   [-1.01948481e+01 -2.50259852e+00]   [-6.08818817e+00  5.71516156e-01]   [ 8.14604282e-01  8.74936581e-01]   [-9.27050591e-01  1.68381357e+00]   [-2.39078522e+00 -4.39953446e-01]   [-1.79722738e+00  2.44799304e+00]   [-6.19097829e-01  4.20792866e+00]   [-3.59187007e+00  2.05337834e+00]   [-2.02478099e+00  3.92844319e+00]   [-2.78609324e+00 -1.00785866e+01]   [ 1.35041237e-01  9.82832527e+00]   [ 3.77985573e+00 -2.92683578e+00]   [ 2.50951290e+00 -1.10158062e+00]   [-2.69217896e+00  7.27837420e+00]   [ 4.59399509e+00 -4.81438732e+00]   [ 9.01638508e+00  5.12754726e+00]   [ 5.19506645e+00 -2.35464978e+00]   [ 2.05791235e-01  3.24537897e+00]   [-6.17561936e-02  1.22012386e+01]   [ 8.34735334e-01  2.56306553e+00]   [-8.42908740e-01 -4.72223663e+00]   [ 7.59096265e-01 -8.70975971e-01]]]</code></pre><p>â€‹<br>     [[[-1.25730896e+01  1.73365784e+00]<br>       [-8.16483736e-01 -3.12521791e+00]<br>       [ 4.31258678e+00 -3.65629935e+00]<br>       [ 7.81925964e+00  2.67266393e+00]<br>       [-1.45902622e+00 -1.69710827e+00]<br>       [-4.97250271e+00  1.06699669e+00]<br>       [-1.15320644e+01  3.67050219e+00]<br>       [ 9.82042491e-01 -8.96060181e+00]<br>       [ 4.24584293e+00 -2.03312969e+00]<br>       [-8.90874267e-02 -2.19113445e+00]<br>       [ 7.03373575e+00  4.82089567e+00]<br>       [ 2.19787431e+00 -1.35815620e+00]<br>       [-4.33743429e+00 -2.77082419e+00]<br>       [-6.55539846e+00 -5.28619862e+00]<br>       [-4.10456562e+00  1.53431883e+01]<br>       [-6.97701550e+00  5.58186054e-01]<br>       [-4.06244993e+00 -1.29598303e+01]<br>       [ 1.80246496e+00 -2.77987790e+00]<br>       [-7.30259180e+00 -5.11505365e+00]<br>       [ 2.12593174e+00 -3.25598717e+00]<br>       [ 7.80677795e+00  1.99891090e-01]<br>       [ 8.46464539e+00  2.72348213e+00]<br>       [-2.32167172e+00  4.69824505e+00]<br>       [ 3.97749400e+00 -9.19138908e+00]<br>       [ 2.90814090e+00  1.26416731e+00]<br>       [-8.01068783e-01  5.13629675e+00]<br>       [-1.10610142e+01  4.88826132e+00]<br>       [-1.75804818e+00  1.23052418e+00]]</p><pre><code>  [[-5.49224281e+00 -1.18972950e+01]   [-1.71067417e+00 -7.94510078e+00]   [ 8.11289787e+00  2.97325039e+00]   [-6.18529272e+00 -1.07129316e+01]   [ 5.09897184e+00 -5.09968042e+00]   [-7.61364222e+00  5.40171003e+00]   [-6.47705889e+00 -1.68601739e+00]   [ 5.09246063e+00 -4.75051785e+00]   [-8.07900906e+00 -1.01351190e+00]   [-5.56266832e+00 -5.98014545e+00]   [-1.84528065e+00 -2.55948591e+00]   [ 1.63680077e-01 -4.52482510e+00]   [-6.17208385e+00  8.61810780e+00]   [ 2.54550838e+00  1.04630842e+01]   [ 6.78235245e+00  2.36592340e+00]   [ 5.33071947e+00  7.77984023e-01]   [ 1.59947419e+00  3.40054178e+00]   [ 9.72853303e-01  1.95867562e+00]   [-5.11668110e+00  9.07939816e+00]   [-9.91412735e+00  5.33779049e+00]   [ 6.93627453e+00  9.98051357e+00]   [-1.49268985e+00 -1.61656654e+00]   [ 6.77412367e+00  5.89341736e+00]   [-9.02515793e+00 -4.86350346e+00]   [-2.65398359e+00  6.53871584e+00]   [ 7.60008812e+00  2.23823214e+00]   [ 3.48978114e+00  7.77210045e+00]   [-1.89859509e+00  1.36791458e+01]]  [[ 6.16735172e+00 -3.06368208e+00]   [-6.22440147e+00  2.49987888e+00]   [ 1.23477805e+00 -9.58612680e-01]   [-6.32274055e+00 -3.50495398e-01]   [-2.37460756e+00  2.89988756e+00]   [ 6.76133537e+00 -4.97397709e+00]   [ 4.19915617e-01 -1.44209051e+00]   [-8.48055720e-01 -1.34412467e+00]   [ 1.47503817e+00 -4.57327032e+00]   [-8.83791351e+00  1.30507603e+01]   [ 5.04546928e+00  2.96709967e+00]   [ 1.21958218e+01 -3.70147228e-01]   [-9.32716131e-02  8.25912094e+00]   [-6.88422298e+00 -2.94276452e+00]   [-8.92567754e-01  7.48677373e-01]   [ 1.13859291e+01 -4.54786253e+00]   [ 4.14542294e+00  3.62407827e+00]   [-4.84375191e+00  7.60643148e+00]   [-3.99736214e+00  8.38322639e-01]   [ 8.50940418e+00 -3.18443274e+00]   [ 3.02693796e+00 -1.08982430e+01]   [ 5.94771481e+00  1.90185285e+00]   [ 1.79021060e-02  2.71560931e+00]   [ 1.28265166e+00  1.35003614e+00]   [-5.15541887e+00  3.48176098e+00]   [ 1.35739307e+01  1.13081062e+00]   [-1.13344326e+01  2.02814102e+00]   [-3.78427625e+00 -3.41797924e+00]]]</code></pre><p>â€‹<br>     [[[ 7.51625490e+00 -8.01126385e+00]<br>       [ 8.94779682e-01 -1.39191675e+00]<br>       [-6.38634396e+00 -7.54839706e+00]<br>       [ 5.90809202e+00 -4.73860931e+00]<br>       [ 2.89039660e+00 -5.74475765e-01]<br>       [-3.24619865e+00 -4.33766127e+00]<br>       [ 7.45817757e+00  8.72869968e+00]<br>       [ 1.70315895e+01 -1.43109741e+01]<br>       [ 6.71465302e+00  2.36530209e+00]<br>       [ 2.37234616e+00  9.54824162e+00]<br>       [ 1.24315548e+01 -8.32226753e-01]<br>       [ 1.15248704e+00  6.42775774e+00]<br>       [-2.05694604e+00 -5.29237223e+00]<br>       [ 1.06061993e+01  4.43905163e+00]<br>       [ 3.32259560e+00  2.86404061e+00]<br>       [-1.26070702e+00 -3.86716032e+00]<br>       [-7.17960167e+00 -5.47068119e+00]<br>       [ 6.13063002e+00 -1.27777729e+01]<br>       [-4.77525711e+00 -2.89896202e+00]<br>       [ 5.04258776e+00  1.05476036e+01]<br>       [-4.72102404e+00  4.53035545e+00]<br>       [ 8.30504322e+00 -6.72617435e+00]<br>       [ 1.51879632e+00 -7.57512569e+00]<br>       [ 5.25161076e+00 -6.00039482e+00]<br>       [-2.66712689e+00 -3.15567350e+00]<br>       [ 6.98167515e+00  1.21508999e+01]<br>       [-3.58145714e+00  1.01358452e+01]<br>       [-7.68432474e+00  6.27517796e+00]]</p><pre><code>  [[-3.85787821e+00  4.13319540e+00]   [ 4.08870316e+00  8.98323441e+00]   [ 2.88623333e-01  2.08936238e+00]   [-1.27303381e+01 -3.72204494e+00]   [-1.63620949e-01  4.14640725e-01]   [-9.77903843e+00 -9.83979321e+00]   [ 1.20987940e+01 -1.00569272e+00]   [-9.52555597e-01 -7.21974373e-01]   [-7.53700542e+00 -1.03328714e+01]   [ 3.82278275e+00  7.92873979e-01]   [ 1.62820339e+01  9.25348282e-01]   [-2.99300981e+00 -4.05044317e+00]   [-1.71284425e+00  3.32610369e-01]   [ 8.45957184e+00  3.01560092e+00]   [ 9.61618781e-01  4.84845543e+00]   [-5.04883003e+00 -4.64504576e+00]   [-4.88548994e-01  4.22385454e+00]   [-3.06538558e+00 -2.68467999e+00]   [ 1.44536438e+01 -1.67332339e+00]   [-1.20380235e+00 -3.01969767e-01]   [-1.25808067e+01 -1.83691287e+00]   [ 7.00172246e-01 -5.44080067e+00]   [ 3.71728969e+00 -6.50164127e+00]   [ 3.44825792e+00  2.27989483e+00]   [-1.16813726e+01  3.55064964e+00]   [-6.76289463e+00 -1.25415869e+01]   [ 1.86627662e+00  4.91928959e+00]   [ 2.37216616e+00 -3.23613596e+00]]  [[ 5.60678053e+00  6.07894707e+00]   [-6.23391962e+00 -1.82450306e+00]   [ 6.90571690e+00 -2.60890079e+00]   [ 3.98191905e+00 -2.60109711e+00]   [ 3.79411244e+00 -7.30271769e+00]   [-8.19082737e+00 -4.81762362e+00]   [ 1.01562176e+01 -9.18346643e-02]   [ 5.15106916e-01 -1.88746595e+00]   [-7.10526466e-01  4.75524092e+00]   [ 4.28777647e+00 -4.28609967e-01]   [ 2.94255161e+00 -2.76411390e+00]   [-5.01211119e+00 -1.35121047e-01]   [ 4.88255644e+00  7.48982000e+00]   [-2.94339252e+00 -1.49728453e+00]   [-5.28226614e-01  1.13798523e+01]   [-3.26653433e+00 -1.12711830e+01]   [ 6.92280245e+00  4.46824360e+00]   [-1.07686818e-02  5.99187469e+00]   [-2.30055904e+00 -2.35181737e+00]   [-1.86744165e+00 -9.12775040e-01]   [ 5.70386982e+00  2.56417489e+00]   [-4.37073708e-01 -4.62391090e+00]   [-8.43499756e+00  9.08772826e-01]   [-5.64418888e+00 -5.02650261e+00]   [ 3.92685270e+00 -5.31071186e+00]   [ 6.36297584e-01  2.63665223e+00]   [-7.71557522e+00  4.19800425e+00]   [ 3.64932895e+00  2.46329069e+00]]]</code></pre><p>â€‹<br>     [[[ 6.65752888e-01  3.40558529e-01]<br>       [ 4.08683634e+00  6.27357101e+00]<br>       [-2.77316380e+00  5.83889532e+00]<br>       [-2.01864777e+01 -8.63007069e+00]<br>       [ 4.85101509e+00  1.56102419e-01]<br>       [ 5.13551521e+00  7.00347781e-01]<br>       [ 4.66926765e+00  1.13918304e+01]<br>       [ 1.17937775e+01 -5.75443983e+00]<br>       [ 5.18499660e+00  2.47753906e+01]<br>       [-4.94616604e+00  1.09324312e+00]<br>       [ 7.08940148e-01  5.36628440e-02]<br>       [-6.22777748e+00 -6.08889389e+00]<br>       [ 8.21062326e-01  5.73018026e+00]<br>       [-1.01816578e+01 -5.96292210e+00]<br>       [-3.45601702e+00 -5.80823088e+00]<br>       [-7.81425619e+00 -1.54714165e+01]<br>       [ 6.15157843e+00  4.41321850e+00]<br>       [ 2.28190422e-02 -1.40392697e+00]<br>       [ 5.86180115e+00  2.66614532e+00]<br>       [-1.21994901e+00  6.87365246e+00]<br>       [ 7.62740707e+00 -1.52388859e+00]<br>       [-8.03575134e+00 -1.35383148e+01]<br>       [-1.75186968e+00 -1.95710063e+00]<br>       [-8.72407794e-01 -8.31413174e+00]<br>       [-1.38678074e+01 -3.35018563e+00]<br>       [ 1.02961273e+01  5.95636034e+00]<br>       [ 7.15158939e+00  9.47603941e-01]<br>       [ 3.59655428e+00 -3.57616353e+00]]</p><pre><code>  [[-7.15814590e+00 -1.73663855e-01]   [-5.33630848e+00  2.23019302e-01]   [-3.60880065e+00  1.16919529e+00]   [ 1.65422618e+00  3.21728516e+00]   [ 1.86843979e+00  1.13296022e+01]   [-6.71664524e+00  8.06290245e+00]   [-3.82262254e+00  4.57042742e+00]   [-7.61132431e+00  7.53255653e+00]   [ 1.63969231e+00 -1.19336343e+00]   [ 2.03410006e+00  5.48414516e+00]   [ 7.98875904e+00 -6.00354958e+00]   [ 5.37972260e+00 -3.13939238e+00]   [ 6.52196217e+00  5.99524212e+00]   [-3.65084100e+00  5.70605898e+00]   [ 5.66238022e+00 -4.25603628e-01]   [ 1.31335664e+00  3.34762931e-01]   [ 4.95460320e+00 -7.73174858e+00]   [-6.06322289e-02  7.14966822e+00]   [ 4.30868864e+00 -4.49330187e+00]   [ 3.00062609e+00 -3.45171928e+00]   [-8.88646841e-01  4.49364281e+00]   [-1.37166762e+00 -9.60632420e+00]   [ 2.72169065e+00 -2.02102685e+00]   [ 4.06615162e+00  2.21987987e+00]   [ 4.58932543e+00 -6.33985901e+00]   [-7.59764194e+00 -8.69492054e-01]   [ 6.72914386e-01  3.37907672e-02]   [-9.57373238e+00  4.29612064e+00]]  [[ 2.07057667e+00  2.49500203e+00]   [-2.39765930e+00  6.45140171e-01]   [ 9.70951462e+00  1.52998376e+00]   [ 9.77593803e+00  8.06670094e+00]   [ 8.35551929e+00  7.26291513e+00]   [-9.06231880e-01 -9.31769133e-01]   [-6.77584314e+00  3.27285552e+00]   [ 5.13162661e+00 -5.17782736e+00]   [-3.71608639e+00 -5.12819290e-01]   [ 1.48577709e+01 -2.64512122e-01]   [ 6.44747496e-01 -9.95941162e-02]   [ 1.04961805e+01 -3.98670554e+00]   [ 2.51394081e+00  1.80438447e+00]   [-5.59201813e+00  1.18733444e+01]   [-2.31048003e-01 -1.12039871e+01]   [-1.62683907e+01  2.02177715e+00]   [ 1.14540329e+01  2.30115056e-02]   [-1.10159683e+01 -3.24261713e+00]   [-1.33181334e+01 -8.00105953e+00]   [ 6.21838617e+00  8.89258957e+00]   [ 1.58339548e+00 -2.27107620e+00]   [-4.17989254e-01 -2.85755348e+00]   [-2.48508906e+00  9.64674568e+00]   [-1.08764257e+01  2.08483315e+00]   [ 9.77210236e+00  2.50418329e+00]   [-1.62253022e+00  1.67334347e+01]   [ 6.42501354e-01  2.53464675e+00]   [-1.12935200e+01  3.39891338e+00]]]], shape=(4, 3, 28, 2), dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">28</span>,<span class="number">32</span>])</span><br><span class="line">b = tf.random.normal([<span class="number">32</span>,<span class="number">16</span>])</span><br><span class="line"><span class="comment"># å…ˆè‡ªåŠ¨æ‰©å±•ï¼Œå†çŸ©é˜µç›¸ä¹˜</span></span><br><span class="line">tf.matmul(a,b)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=503, shape=(4, 28, 16), dtype=float32, numpy=array([[[ -2.7598646 ,   7.0569715 ,  -2.0019226 , ...,  -1.2552259 ,          -5.3215303 ,  -1.2467324 ],        [ -3.5755327 ,  -3.8002384 , -12.492091  , ...,   6.249779  ,          -3.7607257 ,  -2.4373896 ],        [  1.3191882 ,  -4.4746413 ,   2.4289536 , ...,  -1.8787553 ,          -0.10033526,  -1.4797553 ],        ...,        [ -2.0344322 ,   5.086643  ,  -7.6664243 , ...,  -3.0846074 ,          -8.448284  ,  -1.7322202 ],        [  0.57995903,  -3.7676647 ,  -3.6173913 , ...,   7.0568666 ,           2.3793366 ,   3.498049  ],        [  0.5311534 ,   3.0278618 ,   3.9090858 , ...,   4.8734083 ,          -6.3130484 ,  -3.7237642 ]],       [[  4.89592   ,  -2.8002422 ,  -0.7761507 , ...,   9.516954  ,          11.723758  ,  -2.5442433 ],        [ -0.47682646, -13.358232  , -11.200428  , ...,  -0.46236166,          -2.9554985 ,  -1.4849511 ],        [ 11.57021   ,  -8.973025  ,   2.9124722 , ...,  -5.2608457 ,           1.2784045 ,  -5.1128254 ],        ...,        [  2.318095  ,   2.843607  ,   4.602457  , ...,   5.6242056 ,           6.1018414 ,  -5.076501  ],        [ -4.3738413 ,  -5.2155914 ,   8.190216  , ...,  -3.7748199 ,          -4.86178   ,   2.7263112 ],        [ -1.4741284 ,   0.5153975 ,  -2.7228315 , ...,  -0.1337083 ,          -8.092061  ,  -3.1821835 ]],       [[  0.28089905,   9.784105  ,   2.9840403 , ...,   0.33226973,          -0.6826554 ,  -4.040504  ],        [ -5.8831253 ,  12.158736  ,  -7.0445533 , ...,   2.2380865 ,          -8.451615  ,   3.1144416 ],        [-12.613248  , -10.317265  ,  -5.9143896 , ...,  -2.8576682 ,         -10.0681925 ,   6.5913053 ],        ...,        [  5.002187  ,   0.69802207,   4.616313  , ...,   1.8524637 ,           1.6469531 ,   1.4813223 ],        [ -1.0592954 ,  -1.9839575 ,   6.1675334 , ...,  -3.4000485 ,           9.097794  ,   3.3264492 ],        [ -2.3593228 ,  -6.8569756 , -14.06582   , ...,  -9.968381  ,           9.856624  ,   5.7211127 ]],       [[  0.79352164, -12.076045  ,   4.5146046 , ...,  -0.5590708 ,          -0.44884235,   4.5407653 ],        [  3.3152225 ,  -1.2491262 ,   8.590666  , ...,   0.24038552,          12.144938  ,  11.659479  ],        [ -0.8445607 ,   6.594575  ,  -2.8742118 , ...,  -2.4811752 ,           3.3992496 ,   4.638756  ],        ...,        [ -8.9465065 ,  -6.0752807 ,  -4.039912  , ...,  -0.8335391 ,          -3.9777448 ,   3.659201  ],        [  4.1183553 ,   3.9281585 ,  -4.132287  , ...,  -7.197991  ,           5.790247  ,  -8.167656  ],        [ -4.423063  , -20.040358  ,  -9.854829  , ...,  -3.0150864 ,          -5.763957  ,   4.594075  ]]], dtype=float32)&gt;</code></pre><h2 id="å‰å‘ä¼ æ’­å®æˆ˜"><a href="#å‰å‘ä¼ æ’­å®æˆ˜" class="headerlink" title="å‰å‘ä¼ æ’­å®æˆ˜"></a>å‰å‘ä¼ æ’­å®æˆ˜</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras.datasets <span class="keyword">as</span> datasets</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.size&#x27;</span>] = <span class="number">16</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = [<span class="string">&#x27;STKaiti&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span>():</span></span><br><span class="line">    <span class="comment"># åŠ è½½ MNIST æ•°æ®é›†</span></span><br><span class="line">    (x, y), (x_val, y_val) = datasets.mnist.load_data()</span><br><span class="line">    <span class="comment"># è½¬æ¢ä¸ºæµ®ç‚¹å¼ é‡ï¼Œ å¹¶ç¼©æ”¾åˆ°-1~1</span></span><br><span class="line">    x = tf.convert_to_tensor(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    <span class="comment"># è½¬æ¢ä¸ºæ•´å½¢å¼ é‡</span></span><br><span class="line">    y = tf.convert_to_tensor(y, dtype=tf.int32)</span><br><span class="line">    <span class="comment"># one-hot ç¼–ç </span></span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ”¹å˜è§†å›¾ï¼Œ [b, 28, 28] =&gt; [b, 28*28]</span></span><br><span class="line">    x = tf.reshape(x, (-<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æ„å»ºæ•°æ®é›†å¯¹è±¡</span></span><br><span class="line">    train_dataset = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    <span class="comment"># æ‰¹é‡è®­ç»ƒ</span></span><br><span class="line">    train_dataset = train_dataset.batch(<span class="number">200</span>)</span><br><span class="line">    <span class="keyword">return</span> train_dataset</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_paramaters</span>():</span></span><br><span class="line">    <span class="comment"># æ¯å±‚çš„å¼ é‡éƒ½éœ€è¦è¢«ä¼˜åŒ–ï¼Œæ•…ä½¿ç”¨ Variable ç±»å‹ï¼Œå¹¶ä½¿ç”¨æˆªæ–­çš„æ­£å¤ªåˆ†å¸ƒåˆå§‹åŒ–æƒå€¼å¼ é‡</span></span><br><span class="line">    <span class="comment"># åç½®å‘é‡åˆå§‹åŒ–ä¸º 0 å³å¯</span></span><br><span class="line">    <span class="comment"># ç¬¬ä¸€å±‚çš„å‚æ•°</span></span><br><span class="line">    w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">    b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))</span><br><span class="line">    <span class="comment"># ç¬¬äºŒå±‚çš„å‚æ•°</span></span><br><span class="line">    w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">    b2 = tf.Variable(tf.zeros([<span class="number">128</span>]))</span><br><span class="line">    <span class="comment"># ç¬¬ä¸‰å±‚çš„å‚æ•°</span></span><br><span class="line">    w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">    b3 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line">    <span class="keyword">return</span> w1, b1, w2, b2, w3, b3</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch</span>(<span class="params">epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=<span class="number">0.001</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataset):</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            <span class="comment"># ç¬¬ä¸€å±‚è®¡ç®—ï¼Œ [b, 784]@[784, 256] + [256] =&gt; [b, 256] + [256] =&gt; [b,256] + [b, 256]</span></span><br><span class="line">            h1 = x @ w1 + tf.broadcast_to(b1, (x.shape[<span class="number">0</span>], <span class="number">256</span>))</span><br><span class="line">            h1 = tf.nn.relu(h1)  <span class="comment"># é€šè¿‡æ¿€æ´»å‡½æ•°</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># ç¬¬äºŒå±‚è®¡ç®—ï¼Œ [b, 256] =&gt; [b, 128]</span></span><br><span class="line">            h2 = h1 @ w2 + b2</span><br><span class="line">            h2 = tf.nn.relu(h2)</span><br><span class="line">            <span class="comment"># è¾“å‡ºå±‚è®¡ç®—ï¼Œ [b, 128] =&gt; [b, 10]</span></span><br><span class="line">            out = h2 @ w3 + b3</span><br><span class="line"></span><br><span class="line">            <span class="comment"># è®¡ç®—ç½‘ç»œè¾“å‡ºä¸æ ‡ç­¾ä¹‹é—´çš„å‡æ–¹å·®ï¼Œ mse = mean(sum(y-out)^2)</span></span><br><span class="line">            <span class="comment"># [b, 10]</span></span><br><span class="line">            loss = tf.square(y - out)</span><br><span class="line">            <span class="comment"># è¯¯å·®æ ‡é‡ï¼Œ mean: scalar</span></span><br><span class="line">            loss = tf.reduce_mean(loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># è‡ªåŠ¨æ¢¯åº¦ï¼Œéœ€è¦æ±‚æ¢¯åº¦çš„å¼ é‡æœ‰[w1, b1, w2, b2, w3, b3]</span></span><br><span class="line">            grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># æ¢¯åº¦æ›´æ–°ï¼Œ assign_sub å°†å½“å‰å€¼å‡å»å‚æ•°å€¼ï¼ŒåŸåœ°æ›´æ–°</span></span><br><span class="line">        w1.assign_sub(lr * grads[<span class="number">0</span>])</span><br><span class="line">        b1.assign_sub(lr * grads[<span class="number">1</span>])</span><br><span class="line">        w2.assign_sub(lr * grads[<span class="number">2</span>])</span><br><span class="line">        b2.assign_sub(lr * grads[<span class="number">3</span>])</span><br><span class="line">        w3.assign_sub(lr * grads[<span class="number">4</span>])</span><br><span class="line">        b3.assign_sub(lr * grads[<span class="number">5</span>])    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss.numpy()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epochs</span>):</span></span><br><span class="line">    losses = []</span><br><span class="line">    train_dataset = load_data()</span><br><span class="line">    w1, b1, w2, b2, w3, b3 = init_paramaters()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        loss = train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=<span class="number">0.001</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch:&#x27;</span>, epoch, <span class="string">&#x27;loss:&#x27;</span>, loss)</span><br><span class="line">        losses.append(loss)</span><br><span class="line"></span><br><span class="line">    x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, epochs)]</span><br><span class="line">    <span class="comment"># ç»˜åˆ¶æ›²çº¿</span></span><br><span class="line">    plt.plot(x, losses, color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, label=<span class="string">&#x27;è®­ç»ƒ&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;MSE&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train(epochs=<span class="number">20</span>)</span><br></pre></td></tr></table></figure><pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz11493376/11490434 [==============================] - 2s 0us/stepepoch: 0 loss: 0.16654462epoch: 1 loss: 0.14800379epoch: 2 loss: 0.13541555epoch: 3 loss: 0.12577298epoch: 4 loss: 0.11817748epoch: 5 loss: 0.11203371epoch: 6 loss: 0.1069127epoch: 7 loss: 0.10258315epoch: 8 loss: 0.09884895epoch: 9 loss: 0.095569395epoch: 10 loss: 0.092678epoch: 11 loss: 0.09010928epoch: 12 loss: 0.0878074epoch: 13 loss: 0.08572935epoch: 14 loss: 0.08384038epoch: 15 loss: 0.0821046epoch: 16 loss: 0.08050328epoch: 17 loss: 0.079019025epoch: 18 loss: 0.07763501findfont: Font family [&#39;STKaiti&#39;] not found. Falling back to DejaVu Sans.epoch: 19 loss: 0.07634819/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 35757 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 32451 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 35757 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 32451 missing from current font.  font.set_text(s, 0, flags=flags)</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210731145651.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> TensorFlow </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Low-Resource Knowledge-Grounded Dialogue Generatio</title>
      <link href="/2021/07/30/Low-Resource%20Knowledge-Grounded%20Dialogue%20Generatio/"/>
      <url>/2021/07/30/Low-Resource%20Knowledge-Grounded%20Dialogue%20Generatio/</url>
      
        <content type="html"><![CDATA[<h1 id="Low-Resource-Knowledge-Grounded-Dialogue-Generatio"><a href="#Low-Resource-Knowledge-Grounded-Dialogue-Generatio" class="headerlink" title="Low-Resource Knowledge-Grounded Dialogue Generatio"></a>Low-Resource Knowledge-Grounded Dialogue Generatio</h1><blockquote><p> <a href="https://arxiv.org/abs/2002.10348">è®ºæ–‡ï¼šhttps://arxiv.org/abs/2002.10348</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ï¼Œä½œä¸ºååº”ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒæ•°æ®ï¼Œå¾ˆéš¾è·å¾—ã€‚æœ¬æ–‡åœ¨æœ‰é™çš„è®­ç»ƒæ•°æ®ä¸‹ï¼Œè¿›è¡Œä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ç”Ÿæˆã€‚</p><p>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œä¸“æ³¨äºä»¥æ–‡æ¡£ä¸ºåŸºç¡€çš„å¯¹è¯ç”Ÿæˆï¼Œä½†æ‰€æå‡ºçš„æ–¹æ³•å®é™…ä¸Šä¸ºä½èµ„æºçŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ç”Ÿæˆæä¾›äº†ä¸€ä¸ªé€šç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œå…¶ä¸­çš„çŸ¥è¯†å¯ä»¥æ˜¯ç»“æ„åŒ–çš„çŸ¥è¯†åº“ã€å›¾åƒæˆ–è§†é¢‘ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œåªéœ€è¦ä¿®æ”¹çŸ¥è¯†ç¼–ç å™¨å’ŒçŸ¥è¯†å¤„ç†å™¨ï¼Œä½¿å…¶ä¸ç‰¹å®šç±»å‹çš„çŸ¥è¯†å…¼å®¹ï¼Œå¹¶é¢„å…ˆè®­ç»ƒçŸ¥è¯†ç¼–ç å™¨ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>åœ¨ä½èµ„æºç¯å¢ƒä¸‹ï¼Œè®¾è®¡äº†ä¸€ä¸ªåˆ†è§£ååº”è§£ç å™¨(disentangled response decoder)ï¼Œä»¥ä¾¿ä»æ•´ä¸ªç”Ÿæˆæ¨¡å‹ä¸­åˆ†ç¦»å‡ºä¾èµ–äºknowledge-groundedçš„å¯¹è¯çš„å‚æ•°ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹çš„ä¸»è¦éƒ¨åˆ†å¯ä»¥ä»å¤§é‡æ— åŸºç¡€çš„å¯¹è¯å’Œéç»“æ„åŒ–æ–‡æ¡£ä¸­å­¦ä¹ ï¼Œè€Œå‰©ä½™çš„å°å‚æ•°åˆ™å¯ä»¥ç”¨æœ‰é™çš„è®­ç»ƒå®ä¾‹å¾ˆå¥½åœ°æ‹Ÿåˆã€‚</p><p>è´¡çŒ®ï¼š</p><ul><li>åœ¨ä½èµ„æºç¯å¢ƒä¸‹æ¢ç´¢ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ç”Ÿæˆ</li><li>æå‡ºäº†ç”¨æ— åŸºç¡€çš„å¯¹è¯å’Œæ–‡æ¡£å¯¹ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ç”Ÿæˆæ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒçš„å»ºè®®</li><li>åœ¨ä¸¤ä¸ªåŸºå‡†ä¸Šå¯¹è¯¥æ¨¡å‹çš„æœ‰æ•ˆæ€§è¿›è¡Œäº†å®è¯éªŒè¯</li></ul><p>dataset $D_S$:</p><script type="math/tex; mode=display">D_S= {(U^S_i, D^S_i, r^S_i)}^n_{i=1}</script><p>$D^S_i$ï¼šæ–‡æ¡£</p><p>$U^S_i$ï¼šä¸Šä¸‹æ–‡</p><ul><li><script type="math/tex; mode=display">U^S_i=(u^S_{i,1},...u^S_{i,n_i})</script></li></ul><p>$r^S_i$ï¼šå…³äº$U^S_i ï¼Œ D^S_i$çš„response</p><p>å­¦ä¹ ç›®æ ‡ï¼šç”Ÿæˆå¼æ¨¡å‹$P(r|U, D; Î¸)$</p><p>ç»™å®šæ–‡æ¡£Då’Œä¸ä¹‹å…³è”çš„å¯¹è¯ä¸Šä¸‹æ–‡Uï¼Œé€šè¿‡$P(r|U, D; Î¸)$ç”Ÿæˆå“åº”rã€‚</p><p>ååº”çš„å½¢æˆå¯ä»¥åˆ†è§£ä¸ºä¸‰ä¸ªä¸ç›¸å…³çš„è¡Œä¸ºï¼š</p><ul><li>æ ¹æ®å·²ç»äº§ç”Ÿçš„å†…å®¹é€‰æ‹©ä¸€ä¸ªè¯ï¼Œä½¿å¥å­åœ¨è¯­è¨€ä¸Šæœ‰æ•ˆï¼ˆå¯¹åº”äºè¯­è¨€æ¨¡å‹ï¼‰</li><li>æ ¹æ®ä¸Šä¸‹æ–‡é€‰æ‹©ä¸€ä¸ªè¯ï¼Œä½¿å¯¹è¯è¿è´¯ï¼ˆå¯¹åº”äºä¸Šä¸‹æ–‡å¤„ç†å™¨ï¼‰</li><li>æ ¹æ®é¢å¤–çš„çŸ¥è¯†é€‰æ‹©ä¸€ä¸ªè¯ï¼Œä½¿å¯¹è¯æœ‰åŸºç¡€ï¼ˆå¯¹åº”äºçŸ¥è¯†å¤„ç†å™¨ï¼‰</li></ul><p><strong>æ¨¡å‹ç»“æ„ï¼š*</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210715213320.png" alt="image-20210715213320064"></p><p>ç»„æˆï¼šcontext encoder,  knowledge encoder, decoder,  decoding manager</p><p>è§£ç å™¨åˆ†è§£ä¸ºè¯­è¨€æ¨¡å‹ã€è¯­å¢ƒå¤„ç†å™¨å’ŒçŸ¥è¯†å¤„ç†å™¨ã€‚è¿™ä¸‰ä¸ªéƒ¨åˆ†çš„éšè—çŠ¶æ€æ˜¯ç‹¬ç«‹çš„ï¼Œç”±Manageråè°ƒã€‚</p><h3 id="ENCODERS"><a href="#ENCODERS" class="headerlink" title="ENCODERS"></a>ENCODERS</h3><p>dialogue contextä½¿ç”¨GRUç¼–ç ï¼Œå°†å•è¯åºåˆ—è½¬åŒ–ä¸ºéšè—å±‚å‘é‡åºåˆ—ï¼š</p><script type="math/tex; mode=display">h^u_ 1, . . . , h^u_ i, . . . , h^u _{lu}= GRU_{Î¸e}(e^u_ 1, . . . , e^u_ i, . . . , e^u_{lu}),</script><p>$e^u<em> 1$æ˜¯$w^u</em> 1$ä½¿ç”¨GloVeåˆå§‹åŒ–çš„embeddingã€‚</p><p>documentä½¿ç”¨BiGRUç¼–ç ï¼š</p><script type="math/tex; mode=display">h^d_ 1, . . . , h^d_ i, . . . , h^d _{ld}= BiGRU_{Î¸k}(e^d_ {i,1}, . . . , e^d_ {i,j}, . . . , e^d_{i,ld}),</script><p>$e^d_{i,j}$æ˜¯ç¬¬jä¸ªå•è¯ä½¿ç”¨GloVeåˆå§‹åŒ–çš„embeddingã€‚</p><p>ç¼–ç é˜¶æ®µæ²¡æœ‰è¿›è¡Œknowledge selectionï¼Œè¿™å¯ä»¥æ¶ˆé™¤ä¸Šä¸‹æ–‡ç¼–ç å’ŒçŸ¥è¯†ç¼–ç ä¹‹é—´çš„ä¾èµ–æ€§ã€‚</p><h3 id="DISENTANGLED-DECODER"><a href="#DISENTANGLED-DECODER" class="headerlink" title="DISENTANGLED DECODER"></a>DISENTANGLED DECODER</h3><p>è§£ç å™¨ç»´æŠ¤éšè—çš„åºåˆ—${s<em>t}^{l_r}</em>{t=1}$è¡¨ç¤ºt-1æ­¥çš„å•è¯é¢„æµ‹embeddingï¼Œ$s_t$å®šä¹‰ä¸ºï¼š</p><script type="math/tex; mode=display">s_t= GRU_{Î¸d}(e^r_{ tâˆ’1}, s_{tâˆ’1})</script><h3 id="DECODING-MANAGER"><a href="#DECODING-MANAGER" class="headerlink" title="DECODING MANAGER"></a>DECODING MANAGER</h3><p>ä¸‰ä¸ªdecoderç»„ä»¶ç”±è§£ç ç®¡ç†å™¨æ§åˆ¶ï¼Œåœ¨å“åº”é¢„æµ‹çš„æ¯ä¸€æ­¥éƒ½æœ‰ä¸€ä¸ªç»„ä»¶è¢«æ‹¾èµ·ã€‚</p><p>ä½¿ç”¨äº†ä¸€ä¸ªGumbel trick $Ï€_t$ï¼Œå®šä¹‰ä¸ºï¼š</p><script type="math/tex; mode=display">Ï€_t= gumbel\ softmax(f_Ï€(s_{tâˆ’1}), Ï„)</script><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>Wizard of Wikipedia (Wizard)</li><li>CMU Document Grounded Conversations(CMU DoG)</li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><ul><li>Wizard respectively</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210717113229.png" alt="image-20210717113229400"></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210717113305.png" alt="image-20210717113305198"></p><ul><li>CMU DoG</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210717113348.png" alt="image-20210717113348840"></p><p>å³ä½¿æ•°æ®é›†ç¼©å°ï¼ŒTest Unseenæ€§èƒ½ç›¸æ¯”äºTest seenä¾ç„¶ç¨³å®šï¼Œä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”Test Unseenæ€§èƒ½æå‡æ›´åŠ æ˜¾è‘—ã€‚</p><p>ITDDåœ¨Test Seenå’ŒCMU DoGä¸Šéƒ½å–å¾—äº†è¾ƒä½çš„PPLï¼Œè¿™å¯èƒ½æ˜¯ç”±äºtwo_passè§£ç å™¨çš„è¿‡åº¦æ‹Ÿåˆã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>æœ¬æ–‡ç ”ç©¶äº†åœ¨ä½èµ„æºç¯å¢ƒä¸‹ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ç”Ÿæˆã€‚ä¸ºäº†å…‹æœè®­ç»ƒæ•°æ®ä¸è¶³å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œå°†å“åº”è§£ç å™¨åˆ†è§£ä¸ºç‹¬ç«‹çš„ç»„ä»¶ï¼Œå…¶ä¸­å¤§éƒ¨åˆ†å‚æ•°ä¸å†ä¾èµ–è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥ä»å¤§è§„æ¨¡çš„æ— åŸºç¡€å¯¹è¯å’Œéç»“æ„åŒ–æ–‡æ¡£ä¸­ä¼°è®¡å‡ºæ¥ã€‚å¯¹ä¸¤ä¸ªåŸºå‡†çš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨åªæœ‰1/8çš„è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¯¹é¢†åŸŸå¤–çš„çŸ¥è¯†è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Low-Resource </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntuå¼€å¯sshæœåŠ¡è¿œç¨‹ç™»å½•</title>
      <link href="/2021/07/30/ubuntu%E5%BC%80%E5%90%AFssh%E6%9C%8D%E5%8A%A1%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95/"/>
      <url>/2021/07/30/ubuntu%E5%BC%80%E5%90%AFssh%E6%9C%8D%E5%8A%A1%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h1 id="ubuntuå¼€å¯sshæœåŠ¡è¿œç¨‹ç™»å½•"><a href="#ubuntuå¼€å¯sshæœåŠ¡è¿œç¨‹ç™»å½•" class="headerlink" title="ubuntuå¼€å¯sshæœåŠ¡è¿œç¨‹ç™»å½•"></a>ubuntuå¼€å¯sshæœåŠ¡è¿œç¨‹ç™»å½•</h1><p><strong>1. æŸ¥çœ‹å½“å‰çš„ubuntuæ˜¯å¦å®‰è£…äº†ssh-serveræœåŠ¡ã€‚é»˜è®¤åªå®‰è£…ssh-clientæœåŠ¡</strong><br><code>dpkg -l | grep ssh</code></p><p><strong>2. å®‰è£…ssh-serveræœåŠ¡</strong><br><code>sudo apt-get install openssh-server</code></p><p>ç„¶åç¡®è®¤ssh-serveræ˜¯å¦å¯åŠ¨äº†ï¼š</p><p><code>ps -e | grep ssh</code></p><p>å¦‚æœçœ‹åˆ°sshdé‚£è¯´æ˜ssh-serverå·²ç»å¯åŠ¨äº†ã€‚å¦‚æœæ²¡æœ‰åˆ™å¯ä»¥è¿™æ ·å¯åŠ¨ï¼š</p><p><code>sudo /etc/init.d/ssh start</code>æˆ–<code>sudo service ssh start</code></p><p><strong>3. ç™»é™†SSHï¼ˆLinuxï¼‰</strong><br><code>ssh username@192.168.1.103</code><br>å…¶ä¸­ï¼Œusernameä¸º192.168.1.103æœºå™¨ä¸Šçš„ç”¨æˆ·ï¼Œéœ€è¦è¾“å…¥å¯†ç ã€‚<br>æ–­å¼€è¿æ¥ï¼šexit</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210730183519.png" alt="image-20210730183519466" style="zoom:50%;" /></p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ssh </tag>
            
            <tag> ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æœåŠ¡å™¨ jupyter notebooké…ç½®</title>
      <link href="/2021/07/30/%E6%9C%8D%E5%8A%A1%E5%99%A8%20jupyter%20notebook%E9%85%8D%E7%BD%AE/"/>
      <url>/2021/07/30/%E6%9C%8D%E5%8A%A1%E5%99%A8%20jupyter%20notebook%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="æœåŠ¡å™¨-jupyter-notebooké…ç½®"><a href="#æœåŠ¡å™¨-jupyter-notebooké…ç½®" class="headerlink" title="æœåŠ¡å™¨ jupyter notebooké…ç½®"></a>æœåŠ¡å™¨ jupyter notebooké…ç½®</h1><p><strong>1. å»ºç«‹configæ–‡ä»¶</strong></p><p><code>jupyter notebook --generate-config</code></p><p><strong>2. è¿›å…¥.jupyteræ–‡ä»¶å¤¹</strong></p><p><code>cd ~/.jupyter</code></p><p><strong>3. æ‰“å¼€ jupyter_notebook_config.pyæ–‡ä»¶</strong></p><p><code>vim jupyter_notebook_config.py</code></p><p><strong>4. ä¿®æ”¹jupyter_notebook_config.pyæ–‡ä»¶ï¼Œæ·»åŠ å¦‚ä¸‹å‘½ä»¤</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#è·å–é…ç½®</span><br><span class="line">c = get_config()</span><br><span class="line">#è®¾ç½®ä¸º * è¡¨ç¤ºæ‰€æœ‰ IP éƒ½å¯ä»¥è®¿é—®</span><br><span class="line">c.NotebookApp.ip = &#x27;*&#x27;</span><br><span class="line">#ç¦æ­¢Notebook å¯åŠ¨æ—¶è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨</span><br><span class="line">c.NotebookApp.open_browser = False</span><br><span class="line">#æŒ‡å®šè®¿é—®çš„ç«¯å£ï¼Œé»˜è®¤æ˜¯8888,è‡ªå·±è®¾ç½®ä¸€ä¸ªå³å¯</span><br><span class="line">c.NotebookApp.port = 6006</span><br><span class="line">#å…¨0è¡¨ç¤ºæ¥å—ä»»ä½•IPåœ°å€çš„è®¿é—®</span><br><span class="line">c.ConnectionFileMixin.ip = &#x27;0.0.0.0&#x27;</span><br><span class="line">#å…è®¸è¿œç¨‹è®¿é—®</span><br><span class="line">c.NotebookApp.allow_remote_access = True</span><br></pre></td></tr></table></figure><p><strong>5. å°è¯•æ‰“å¼€jupyter notebook</strong></p><p><code>jupyter notebook --ip=æœåŠ¡å™¨ip</code></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210730182424.png" alt="image-20210730182424455"></p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ubuntu </tag>
            
            <tag> jupyter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cross-Lingual Machine Reading Comprehension</title>
      <link href="/2021/07/23/Cross-Lingual%20Machine%20Reading%20Comprehension/"/>
      <url>/2021/07/23/Cross-Lingual%20Machine%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="Cross-Lingual-Machine-Reading-Comprehension"><a href="#Cross-Lingual-Machine-Reading-Comprehension" class="headerlink" title="Cross-Lingual Machine Reading Comprehension"></a>Cross-Lingual Machine Reading Comprehension</h1><blockquote><p> <a href="https://arxiv.org/abs/1909.00361">è®ºæ–‡ï¼šhttps://arxiv.org/abs/1909.00361</a></p><p> <a href="https://github.com/ymcui/Cross-Lingual-MRC">ä»£ç ï¼šhttps://github.com/ymcui/Cross-Lingual-MRC</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><ul><li>è™½ç„¶æœºå™¨é˜…è¯»ç†è§£ç ”ç©¶å¾—åˆ°äº†é£é€Ÿå‘å±•ï¼Œå¤šæ•°å·¥ä½œé¢å‘çš„æ˜¯è‹±æ–‡æ•°æ®ï¼Œè€Œå¿½ç•¥äº†æœºå™¨é˜…è¯»ç†è§£åœ¨å…¶ä»–è¯­è¨€ä¸Šçš„è¡¨ç°ï¼Œå…¶æ ¹æœ¬åŸå› åœ¨äºå¤§è§„æ¨¡è®­ç»ƒæ•°æ®çš„ç¼ºå¤±ã€‚æœ¬æ–‡æå‡ºè·¨è¯­è¨€æœºå™¨é˜…è¯»ç†è§£ï¼ˆCross-Lingual MachineReading Comprehensionï¼ŒCLMRCï¼‰ä»»åŠ¡æ¥è§£å†³éè‹±æ–‡ä¸‹çš„æœºå™¨é˜…è¯»ç†è§£ã€‚</li><li>æœ¬æ–‡æ‰€æå‡ºçš„æ–¹æ³•å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ï¼Œå¯é€‚é…å¤šç§æœºå™¨é˜…è¯»ç†è§£ä»»åŠ¡ã€‚åœ¨æœ¬æ–‡ä¸­å°†ç€é‡è§£å†³åŸºäºç¯‡ç« ç‰‡æ®µæŠ½å–çš„æœºå™¨é˜…è¯»ç†è§£ï¼ˆSpan-Extraction MRCï¼‰ï¼Œè¿™ä¹Ÿæ˜¯ç›®å‰åœ¨è¯¥é¢†åŸŸä¸­ç ”ç©¶æœ€ä¸ºå¹¿æ³›çš„ä»»åŠ¡ä¹‹ä¸€ã€‚è¯¥ä»»åŠ¡éœ€è¦å¯¹&lt;ç¯‡ç« ï¼Œé—®é¢˜&gt;è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ä»ç¯‡ç« ä¸­æŠ½å–å‡ºä¸€ä¸ªè¿ç»­çš„ç‰‡æ®µä½œä¸ºç­”æ¡ˆã€‚æœ€å¹¿ä¸ºç†ŸçŸ¥çš„æ˜¯ç”±æ–¯å¦ç¦å¤§å­¦æå‡ºçš„SQuADï¼ˆStanford Question Answering Datasetï¼‰æ•°æ®é›†ã€‚</li><li>åˆ©ç”¨è‹±æ–‡ï¼ˆæºè¯­è¨€ï¼‰æ•°æ®æ¥æå‡ä¸­æ–‡ï¼ˆç›®æ ‡è¯­è¨€ï¼‰æœºå™¨é˜…è¯»ç†è§£ç³»ç»Ÿæ•ˆæœã€‚</li></ul><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><ul><li><p>é¦–å…ˆç»™å‡ºäº†åŸºäºå›è¯‘ï¼ˆBack-Translationï¼‰çš„è·¨è¯­è¨€é˜…è¯»ç†è§£æ–¹æ³•æ¥è§£å†³ç›®æ ‡è¯­è¨€æ²¡æœ‰è®­ç»ƒæ•°æ®çš„æƒ…å†µã€‚</p></li><li><p>å¯¹äºç›®æ ‡è¯­è¨€å­˜åœ¨ä¸€å®šçš„è®­ç»ƒæ•°æ®æ—¶ï¼Œåˆ›æ–°åœ°æå‡ºäº†Dual BERTæ¨¡å‹æ¥è¿›ä¸€æ­¥å€Ÿç”¨å¯Œèµ„æºè¯­è¨€ï¼ˆä¾‹å¦‚ï¼šè‹±æ–‡ï¼‰çš„è®­ç»ƒæ•°æ®æ¥å¸®åŠ©ä½èµ„æºè¯­è¨€ä¸‹çš„æœºå™¨é˜…è¯»ç†è§£æ•ˆæœã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿå¯¹&lt;ç¯‡ç« ï¼Œé—®é¢˜&gt;åœ¨åŒè¯­ç¯å¢ƒä¸­å»ºæ¨¡ï¼Œå¹¶ä¸”æœ€ç»ˆèåˆæˆä¸€ç§ç»Ÿä¸€çš„è¯­ä¹‰è¡¨ç¤ºï¼Œè¿›è€Œå¾—åˆ°æ›´åŠ ç²¾å‡†çš„ç­”æ¡ˆé¢„æµ‹ã€‚</p></li></ul><p>ä¸»è¦è´¡çŒ®ï¼š</p><ol><li>æå‡ºäº†è·¨è¯­è¨€æœºå™¨é˜…è¯»ç†è§£ä»»åŠ¡æ¥è¿›ä¸€æ­¥æå‡ä½èµ„æºè¯­è¨€ä¸‹çš„æœºå™¨é˜…è¯»ç†è§£ç³»ç»Ÿæ•ˆæœ</li><li>æå‡ºäº†Dual BERTæ¨¡å‹ï¼Œå¯¹è¾“å…¥æ–‡æœ¬å’Œé—®é¢˜åœ¨åŒè¯­ç¯å¢ƒä¸­å»ºæ¨¡ï¼Œè¿›ä¸€æ­¥ä¸°å¯Œäº†è¯­ä¹‰è¡¨ç¤º</li><li>æ‰€æå‡ºçš„Dual BERTæ¨¡å‹åœ¨ä¸¤ä¸ªä¸­æ–‡æœºå™¨é˜…è¯»ç†è§£æ•°æ®é›†ä¸Šè·å¾—state-of-the-artæ•ˆæœ</li></ol><h3 id="Back-Translation-Approaches"><a href="#Back-Translation-Approaches" class="headerlink" title="Back-Translation Approaches"></a>Back-Translation Approaches</h3><ul><li>æºè¯­è¨€ï¼šå…·æœ‰å¤§è§„æ¨¡çš„è¯­æ–™èµ„æºçš„è¯­ç§ã€‚æˆ‘ä»¬éœ€è¦ä»è¯¥è¯­ç§çš„èµ„æºä¸­æŠ½å–å‡ºä¸°å¯Œçš„çŸ¥è¯†ã€‚ä¸‹æ–‡ä¸­ä½¿ç”¨ä¸‹æ ‡Sæ¥ä»£è¡¨æºè¯­è¨€å˜é‡ã€‚</li><li>ç›®æ ‡è¯­è¨€ï¼šå¸Œæœ›ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½çš„è¯­ç§ï¼Œå³ç›®æ ‡ç³»ç»Ÿçš„è¯­ç§ã€‚è¯¥è¯­ç§æ²¡æœ‰å¯ç”¨æˆ–ä»…æœ‰å°‘é‡çš„è¯­æ–™èµ„æºã€‚ä¸‹æ–‡ä¸­ä½¿ç”¨ä¸‹æ ‡Tæ¥ä»£è¡¨ç›®æ ‡è¯­è¨€å˜é‡ã€‚</li></ul><p>æœ¬æ–‡åˆ©ç”¨è‹±æ–‡ï¼ˆæºè¯­è¨€ï¼‰æ•°æ®æ¥æå‡ä¸­æ–‡ï¼ˆç›®æ ‡è¯­è¨€ï¼‰æœºå™¨é˜…è¯»ç†è§£ç³»ç»Ÿæ•ˆæœã€‚</p><h3 id="several-back-translation-approaches"><a href="#several-back-translation-approaches" class="headerlink" title="several back-translation approaches"></a>several back-translation approaches</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210721102357.png" alt="image-20210721102357216"></p><h4 id="GNMT"><a href="#GNMT" class="headerlink" title="GNMT"></a>GNMT</h4><blockquote><p>(Google Neural MachineTranslation,GNMT)</p></blockquote><p>ä½¿ç”¨ç¿»è¯‘ç³»ç»Ÿæ¥å®ç°è·¨è¯­è¨€æœºå™¨é˜…è¯»ç†è§£æ˜¯å¾ˆç›´æ¥çš„æ–¹æ³•ï¼Œä¸»è¦æµç¨‹ï¼ˆFigure1 leftï¼‰ï¼š</p><ol><li>å°†ç›®æ ‡è¯­è¨€è¾“å…¥&lt;ç¯‡ç« ï¼Œé—®é¢˜&gt;ç¿»è¯‘æˆæºè¯­è¨€</li><li>é€šè¿‡æºè¯­è¨€çš„é˜…è¯»ç†è§£ç³»ç»Ÿå¾—åˆ°ä¸€ä¸ªæºè¯­è¨€çš„ç­”æ¡ˆ</li><li>å°†æºè¯­è¨€ç­”æ¡ˆå›è¯‘ä¸ºç›®æ ‡è¯­è¨€</li></ol><p><strong>å­˜åœ¨é—®é¢˜ï¼š</strong>ç»è¿‡å›è¯‘çš„ç­”æ¡ˆä¸ä¸€å®šæ˜¯åŸæ–‡ä¸­çš„æŸä¸ªç²¾å‡†ç‰‡æ®µã€‚</p><p><strong>è§£å†³æ–¹æ³•ï¼š</strong></p><h4 id="Simple-Match"><a href="#Simple-Match" class="headerlink" title="Simple Match"></a>Simple Match</h4><p>åˆ©ç”¨æ»‘åŠ¨çª—å£åœ¨ç›®æ ‡è¯­è¨€ç¯‡ç« ä¸­è¿›è¡Œæ»‘åŠ¨ï¼Œå‡è®¾ç¿»è¯‘å‡ºçš„ç­”æ¡ˆä¸çœŸå®ç­”æ¡ˆé•¿åº¦åŸºæœ¬ç›¸ä¼¼ï¼Œç”±æ­¤è®¡ç®—å‡ºå€™é€‰spanå’Œç¿»è¯‘ç­”æ¡ˆçš„F1-scoreï¼Œä»è¿™äº›çª—å£ä¸­é€‰å–ä¸€ä¸ªå­—çº§åˆ«F1-scoreæœ€é«˜çš„çª—å£ä½œä¸ºæœ€ç»ˆçš„é¢„æµ‹ç­”æ¡ˆCã€‚ä½¿ç”¨æ‰€æå‡ºçš„SimpleMatchå¯ä»¥ç¡®ä¿é¢„æµ‹çš„ç­”æ¡ˆæ˜¯ç›®æ ‡æ®µè½ä¸­çš„ç²¾ç¡®è·¨åº¦ã€‚</p><h4 id="Answer-Aligner"><a href="#Answer-Aligner" class="headerlink" title="Answer Aligner"></a>Answer Aligner</h4><blockquote><p>Figure 1 middle</p></blockquote><p>å¦‚æœç›®æ ‡è¯­è¨€æœ‰ä¸€å®šé‡çš„è®­ç»ƒæ•°æ®ï¼Œé‚£ä¹ˆå¯ä»¥è¿›ä¸€æ­¥æå‡ç­”æ¡ˆå¯¹é½çš„æ•ˆæœã€‚å°†å¯¹é½åçš„ç­”æ¡ˆCä¸ç›®æ ‡è¯­è¨€ç¯‡ç« Pè¾“å…¥åˆ°BERTä¸­ï¼Œå¹¶ä»¥ç›®æ ‡è¯­è¨€çœŸå®ç­”æ¡ˆä½œä¸ºç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œå°±å¯ä»¥å¾—åˆ°ç­”æ¡ˆå¯¹é½å™¨ï¼ˆAnswer Alignerï¼‰ã€‚</p><h4 id="Answer-Verifier"><a href="#Answer-Verifier" class="headerlink" title="Answer Verifier"></a>Answer Verifier</h4><blockquote><p>Figure 1 right</p></blockquote><p>åœ¨ç­”æ¡ˆå¯¹é½å™¨çš„åŸºç¡€ä¸Šè¿›ä¸€æ­¥åŠ å…¥ç›®æ ‡è¯­è¨€é—®é¢˜Qï¼Œå³å¯æˆä¸ºç­”æ¡ˆéªŒè¯å™¨ï¼ˆAnswer Verifierï¼‰ï¼Œä½¿ç”¨ç¿»è¯‘ç­”æ¡ˆéªŒè¯æ­£ç¡®æ€§ã€‚</p><h3 id="Dual-BERT"><a href="#Dual-BERT" class="headerlink" title="Dual BERT"></a>Dual BERT</h3><blockquote><p>é€‚ç”¨äºç›®æ ‡è¯­è¨€å­˜åœ¨ä¸€å®šçš„è®­ç»ƒæ•°æ®çš„æƒ…å†µã€‚</p></blockquote><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210722214244.png" alt="image-20210722214244596"></p><h4 id="Dual-Encoder"><a href="#Dual-Encoder" class="headerlink" title="Dual Encoder"></a>Dual Encoder</h4><p>æœ¬æ–‡ä½¿ç”¨BERTä½œä¸ºæ–‡æœ¬è¡¨ç¤ºæ¨¡å‹,å¯¹äºç»™å®šçš„ç›®æ ‡è¯­è¨€ç¯‡ç« $P_T$å’Œé—®é¢˜$Q_T$ï¼ŒBERTçš„è¾“å…¥$X_T$å¯ä»¥è¡¨ç¤ºä¸º:</p><script type="math/tex; mode=display">[CLS] \ Q_T \ [SEP]\ P_T\ [SEP]</script><p>åˆ©ç”¨GNMTç³»ç»Ÿï¼Œå¯ä»¥å°†ç›®æ ‡è¯­è¨€æ•°æ®ç¿»è¯‘æˆæºè¯­è¨€ï¼Œä»è€Œè·å¾—æºè¯­è¨€è¾“å…¥$X_S$ã€‚ç»è¿‡BERTç¼–ç åï¼Œåˆ†åˆ«è·å¾—ç›®æ ‡è¯­è¨€è¡¨ç¤º$B_T$å’Œæºè¯­è¨€è¡¨ç¤º$B_S$ã€‚</p><h4 id="Bilingual-Decoder"><a href="#Bilingual-Decoder" class="headerlink" title="Bilingual Decoder"></a>Bilingual Decoder</h4><blockquote><p>åŒè¯­è§£ç å™¨</p></blockquote><p>ä¸ºäº†å°†æºè¯­è¨€è¡¨ç¤ºèåˆåˆ°ç›®æ ‡è¯­è¨€è¡¨ç¤ºä¸­ï¼Œæå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Adaptive Attention, SAAï¼‰ã€‚</p><p>åœ¨åŸå§‹AttentionçŸ©é˜µè®¡ç®—ï¼š</p><script type="math/tex; mode=display">A_{T S}= B_TÂ· B_S^\mathsf{T}</script><p>ä¿®æ”¹åï¼š</p><script type="math/tex; mode=display">A_{T}= sotmax(B_TÂ· B_T^\mathsf{T})</script><script type="math/tex; mode=display">A_{S}= sotmax(B_SÂ· B_S^\mathsf{T})</script><script type="math/tex; mode=display">\hat{A}_{T S}= A_TÂ· A_{TS}Â·A_S^\mathsf{T}</script><p>è¯¥æ“ä½œçš„ç›®çš„æ˜¯ï¼Œåœ¨$B_T$å’Œ$B_S$è®¡ç®—æ³¨æ„åŠ›ä¹‹å‰ï¼Œé¦–å…ˆè®©$B_T$å’Œ$B_S$å…ˆå¯¹è‡ªèº«è¿›è¡ŒSelf-attentionè®¡ç®—ï¼Œè¿‡æ»¤æ‰ç›¸å¯¹æ— ç”¨çš„éƒ¨åˆ†ï¼Œç„¶åå†è®¡ç®—ä¸¤è€…ä¹‹é—´çš„æ³¨æ„åŠ›ï¼Œä»è€Œè¿›ä¸€æ­¥æå‡æ³¨æ„åŠ›è®¡ç®—çš„ç²¾å‡†åº¦ã€‚</p><p>å¾—åˆ°Attendedè¡¨ç¤º$Râ€™$åï¼Œå¹¶è¿›ä¸€æ­¥é€šè¿‡æ®‹å·®è¿æ¥ï¼ˆResidual Connectionï¼‰å’Œå±‚å½’ä¸€åŒ–ï¼ˆLayer Normalizationï¼‰è·å¾—æœ€ç»ˆçš„è¡¨ç¤º$H_T$ã€‚</p><script type="math/tex; mode=display">Râ€™=softmax(\hat{A}_{TS})Â·B_S</script><script type="math/tex; mode=display">R = W_rR'+ b_r</script><script type="math/tex; mode=display">H_T= concat[B_T, LayerNorm(B_T+ R)]</script><p>æœ€ç»ˆåˆ©ç”¨$H_T$è®¡ç®—ç›®æ ‡è¯­è¨€ä¸Šçš„å¼€å§‹å’Œç»“å°¾æŒ‡é’ˆå¹¶è®¡ç®—å¯¹åº”çš„äº¤å‰ç†µæŸå¤±ã€‚</p><h4 id="Auxiliary-Output"><a href="#Auxiliary-Output" class="headerlink" title="Auxiliary Output"></a>Auxiliary Output</h4><blockquote><p>è¾…åŠ©æŸå¤±</p></blockquote><p>åŒæ—¶å¯¹æºè¯­è¨€è¿›è¡Œé¢„æµ‹å¹¶è®¡ç®—å¯¹åº”çš„äº¤å‰ç†µ$L<em>{aux}$ä½œä¸ºè¾…åŠ©æŸå¤±ã€‚æœ€ç»ˆçš„æŸå¤±å‡½æ•°ä¸º$L=L_T+\lambda L</em>{aux}$ï¼Œå…¶ä¸­Î»âˆˆ[0,1]ä¸ºæ¯”ä¾‹ç³»æ•°ã€‚æºè¯­è¨€æ˜¯ç»è¿‡ç¿»è¯‘å¾—åˆ°çš„ï¼Œå­˜åœ¨ä¸€å®šçš„ä¿¡æ¯ç¼ºå¤±ï¼Œ$\lambda$ä¸ºåŠ¨æ€è®¡ç®—ï¼Œæ§åˆ¶è¾…åŠ©æŸå¤±å¯¹ä¸»æŸå¤±çš„å½±å“ã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><blockquote><p>ä¸¤ä¸ªç¯‡ç« ç‰‡æ®µæŠ½å–å‹ï¼ˆSpan-Extractionï¼‰ä¸­æ–‡æœºå™¨é˜…è¯»ç†è§£æ•°æ®é›†</p></blockquote><p>CMRC 2018ï¼ˆç®€ä½“ä¸­æ–‡ï¼‰</p><p>DRCDï¼ˆç¹ä½“ä¸­æ–‡ï¼‰</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p>å®éªŒç»“æœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210722221231.png" alt="image-20210722221231365"></p><ul><li>åŸºäºå›è¯‘çš„ç³»ç»Ÿä¸­ï¼Œç®€å•åŒ¹é…èƒ½å¤Ÿå¸¦æ¥æ˜¾è‘—æ€§èƒ½æå‡ï¼›åœ¨æœ‰ä¸€å®šè®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œç­”æ¡ˆéªŒè¯å™¨å’Œç­”æ¡ˆéªŒè¯å™¨èƒ½å¤Ÿè¿›ä¸€æ­¥å¸¦æ¥æ€§èƒ½æå‡</li><li>é‡‡ç”¨æºè¯­è¨€é¢„è®­ç»ƒçš„æ¨¡å‹å¯¹ç›®æ ‡è¯­è¨€çš„æœºå™¨é˜…è¯»ç†è§£ç³»ç»Ÿæœ‰æ˜¾è‘—æ€§èƒ½æå‡</li><li>Dual BERTçš„åŒè¯­å»ºæ¨¡èƒ½å¤Ÿåœ¨ä¸Šè¿°åŸºç¡€ä¸Šå¸¦æ¥è¿›ä¸€æ­¥çš„æ€§èƒ½æå‡</li></ul><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p><strong>é˜…è¯»ç†è§£ç³»ç»Ÿæ€§èƒ½æå‡ï¼š</strong></p><ul><li><p>åœ¨æ•°æ®é‡å·®å¼‚ä¸å¤§çš„æƒ…å†µä¸‹ï¼Œæ— éœ€æ ¹æ®è¯­ç§çš„è¿œè¿‘é€‰æ‹©æºè¯­è¨€æ•°æ®ï¼›</p></li><li><p>åœ¨æ•°æ®é‡å·®å¼‚è¾ƒå¤§çš„æƒ…å†µä¸‹ï¼Œåº”é¦–è¦è€ƒè™‘æºè¯­è¨€æ•°æ®çš„è§„æ¨¡è€Œéè¯­ç§çš„è¿œè¿‘ã€‚</p></li></ul><p>åœ¨ä¸¤ä¸ªä¸­æ–‡æœºå™¨é˜…è¯»ç†è§£æ•°æ®é›†ä¸ŠéªŒè¯å¾—çŸ¥è¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æå‡ä½èµ„æºä¸‹çš„æœºå™¨é˜…è¯»ç†è§£æ•ˆæœï¼Œä¸ºæœªæ¥ä½èµ„æºä¸‹çš„æœºå™¨é˜…è¯»ç†è§£æä¾›äº†ä¸€ç§è§£å†³æ–¹æ¡ˆã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Low-Resource </tag>
            
            <tag> CLMRC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨sklearnå¯¹æ–‡æ¡£è¿›è¡Œå‘é‡åŒ–çš„ç¨‹åº</title>
      <link href="/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E5%AF%B9%E6%96%87%E6%A1%A3%E8%BF%9B%E8%A1%8C%E5%90%91%E9%87%8F%E5%8C%96%E7%9A%84%E7%A8%8B%E5%BA%8F/"/>
      <url>/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E5%AF%B9%E6%96%87%E6%A1%A3%E8%BF%9B%E8%A1%8C%E5%90%91%E9%87%8F%E5%8C%96%E7%9A%84%E7%A8%8B%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨sklearnå¯¹æ–‡æ¡£è¿›è¡Œå‘é‡åŒ–çš„ç¨‹åº"><a href="#ä½¿ç”¨sklearnå¯¹æ–‡æ¡£è¿›è¡Œå‘é‡åŒ–çš„ç¨‹åº" class="headerlink" title="ä½¿ç”¨sklearnå¯¹æ–‡æ¡£è¿›è¡Œå‘é‡åŒ–çš„ç¨‹åº"></a>ä½¿ç”¨sklearnå¯¹æ–‡æ¡£è¿›è¡Œå‘é‡åŒ–çš„ç¨‹åº</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">æ¼”ç¤ºå†…å®¹ï¼šæ–‡æ¡£çš„å‘é‡åŒ–</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">corpus = [</span><br><span class="line"><span class="string">&#x27;Jobs was the chairman of Apple Inc., and he was very famous&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;I like to use apple computer&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;And I also like to eat apple&#x27;</span></span><br><span class="line">] </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æœªç»åœç”¨è¯è¿‡æ»¤çš„æ–‡æ¡£å‘é‡åŒ–</span></span><br><span class="line">vectorizer =CountVectorizer()</span><br><span class="line"><span class="built_in">print</span>(vectorizer.fit_transform(corpus).todense())  <span class="comment">#è½¬åŒ–ä¸ºå®Œæ•´ç‰¹å¾çŸ©é˜µ</span></span><br><span class="line"><span class="built_in">print</span>(vectorizer.vocabulary_)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>[[0 1 1 1 0 0 1 1 1 1 0 1 1 0 0 1 2] [0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0] [1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0]]&#123;&#39;jobs&#39;: 9, &#39;was&#39;: 16, &#39;the&#39;: 12, &#39;chairman&#39;: 3, &#39;of&#39;: 11, &#39;apple&#39;: 2, &#39;inc&#39;: 8, &#39;and&#39;: 1, &#39;he&#39;: 7, &#39;very&#39;: 15, &#39;famous&#39;: 6, &#39;like&#39;: 10, &#39;to&#39;: 13, &#39;use&#39;: 14, &#39;computer&#39;: 4, &#39;also&#39;: 0, &#39;eat&#39;: 5&#125;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ç»è¿‡åœç”¨è¯è¿‡æ»¤åçš„æ–‡æ¡£å‘é‡åŒ–</span></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download(<span class="string">&#x27;stopwords&#x27;</span>)</span><br><span class="line">stopwords = nltk.corpus.stopwords.words(<span class="string">&#x27;english&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> (stopwords)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line">vectorizer =CountVectorizer(stop_words=<span class="string">&#x27;english&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;after stopwords removal:  &quot;</span>, vectorizer.fit_transform(corpus).todense())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;after stopwords removal:  &quot;</span>, vectorizer.vocabulary_)</span><br></pre></td></tr></table></figure><pre><code>[nltk_data] Downloading package stopwords to /Users/maqi/nltk_data...[&#39;i&#39;, &#39;me&#39;, &#39;my&#39;, &#39;myself&#39;, &#39;we&#39;, &#39;our&#39;, &#39;ours&#39;, &#39;ourselves&#39;, &#39;you&#39;, &quot;you&#39;re&quot;, &quot;you&#39;ve&quot;, &quot;you&#39;ll&quot;, &quot;you&#39;d&quot;, &#39;your&#39;, &#39;yours&#39;, &#39;yourself&#39;, &#39;yourselves&#39;, &#39;he&#39;, &#39;him&#39;, &#39;his&#39;, &#39;himself&#39;, &#39;she&#39;, &quot;she&#39;s&quot;, &#39;her&#39;, &#39;hers&#39;, &#39;herself&#39;, &#39;it&#39;, &quot;it&#39;s&quot;, &#39;its&#39;, &#39;itself&#39;, &#39;they&#39;, &#39;them&#39;, &#39;their&#39;, &#39;theirs&#39;, &#39;themselves&#39;, &#39;what&#39;, &#39;which&#39;, &#39;who&#39;, &#39;whom&#39;, &#39;this&#39;, &#39;that&#39;, &quot;that&#39;ll&quot;, &#39;these&#39;, &#39;those&#39;, &#39;am&#39;, &#39;is&#39;, &#39;are&#39;, &#39;was&#39;, &#39;were&#39;, &#39;be&#39;, &#39;been&#39;, &#39;being&#39;, &#39;have&#39;, &#39;has&#39;, &#39;had&#39;, &#39;having&#39;, &#39;do&#39;, &#39;does&#39;, &#39;did&#39;, &#39;doing&#39;, &#39;a&#39;, &#39;an&#39;, &#39;the&#39;, &#39;and&#39;, &#39;but&#39;, &#39;if&#39;, &#39;or&#39;, &#39;because&#39;, &#39;as&#39;, &#39;until&#39;, &#39;while&#39;, &#39;of&#39;, &#39;at&#39;, &#39;by&#39;, &#39;for&#39;, &#39;with&#39;, &#39;about&#39;, &#39;against&#39;, &#39;between&#39;, &#39;into&#39;, &#39;through&#39;, &#39;during&#39;, &#39;before&#39;, &#39;after&#39;, &#39;above&#39;, &#39;below&#39;, &#39;to&#39;, &#39;from&#39;, &#39;up&#39;, &#39;down&#39;, &#39;in&#39;, &#39;out&#39;, &#39;on&#39;, &#39;off&#39;, &#39;over&#39;, &#39;under&#39;, &#39;again&#39;, &#39;further&#39;, &#39;then&#39;, &#39;once&#39;, &#39;here&#39;, &#39;there&#39;, &#39;when&#39;, &#39;where&#39;, &#39;why&#39;, &#39;how&#39;, &#39;all&#39;, &#39;any&#39;, &#39;both&#39;, &#39;each&#39;, &#39;few&#39;, &#39;more&#39;, &#39;most&#39;, &#39;other&#39;, &#39;some&#39;, &#39;such&#39;, &#39;no&#39;, &#39;nor&#39;, &#39;not&#39;, &#39;only&#39;, &#39;own&#39;, &#39;same&#39;, &#39;so&#39;, &#39;than&#39;, &#39;too&#39;, &#39;very&#39;, &#39;s&#39;, &#39;t&#39;, &#39;can&#39;, &#39;will&#39;, &#39;just&#39;, &#39;don&#39;, &quot;don&#39;t&quot;, &#39;should&#39;, &quot;should&#39;ve&quot;, &#39;now&#39;, &#39;d&#39;, &#39;ll&#39;, &#39;m&#39;, &#39;o&#39;, &#39;re&#39;, &#39;ve&#39;, &#39;y&#39;, &#39;ain&#39;, &#39;aren&#39;, &quot;aren&#39;t&quot;, &#39;couldn&#39;, &quot;couldn&#39;t&quot;, &#39;didn&#39;, &quot;didn&#39;t&quot;, &#39;doesn&#39;, &quot;doesn&#39;t&quot;, &#39;hadn&#39;, &quot;hadn&#39;t&quot;, &#39;hasn&#39;, &quot;hasn&#39;t&quot;, &#39;haven&#39;, &quot;haven&#39;t&quot;, &#39;isn&#39;, &quot;isn&#39;t&quot;, &#39;ma&#39;, &#39;mightn&#39;, &quot;mightn&#39;t&quot;, &#39;mustn&#39;, &quot;mustn&#39;t&quot;, &#39;needn&#39;, &quot;needn&#39;t&quot;, &#39;shan&#39;, &quot;shan&#39;t&quot;, &#39;shouldn&#39;, &quot;shouldn&#39;t&quot;, &#39;wasn&#39;, &quot;wasn&#39;t&quot;, &#39;weren&#39;, &quot;weren&#39;t&quot;, &#39;won&#39;, &quot;won&#39;t&quot;, &#39;wouldn&#39;, &quot;wouldn&#39;t&quot;]after stopwords removal:   [[1 1 0 0 1 1 0 0] [1 0 1 0 0 0 1 1] [1 0 0 1 0 0 1 0]]after stopwords removal:   &#123;&#39;jobs&#39;: 5, &#39;chairman&#39;: 1, &#39;apple&#39;: 0, &#39;famous&#39;: 4, &#39;like&#39;: 6, &#39;use&#39;: 7, &#39;computer&#39;: 2, &#39;eat&#39;: 3&#125;[nltk_data]   Unzipping corpora/stopwords.zip.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"><span class="comment">#é‡‡ç”¨ngramæ¨¡å¼è¿›è¡Œæ–‡æ¡£å‘é‡åŒ–</span></span><br><span class="line">vectorizer =CountVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">2</span>))<span class="comment">#è¡¨ç¤ºä»1-2ï¼Œæ—¢åŒ…æ‹¬unigramï¼Œä¹ŸåŒ…æ‹¬bigram</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;N-gram mode:     &quot;</span>,vectorizer.fit_transform(corpus).todense())  <span class="comment">#è½¬åŒ–ä¸ºå®Œæ•´ç‰¹å¾çŸ©é˜µ</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;N-gram mode:         &quot;</span>,vectorizer.vocabulary_)</span><br></pre></td></tr></table></figure><pre><code>N-gram mode:      [[0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 2 1 1] [0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0] [1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0]]N-gram mode:          &#123;&#39;jobs&#39;: 18, &#39;was&#39;: 33, &#39;the&#39;: 24, &#39;chairman&#39;: 8, &#39;of&#39;: 22, &#39;apple&#39;: 5, &#39;inc&#39;: 16, &#39;and&#39;: 2, &#39;he&#39;: 14, &#39;very&#39;: 31, &#39;famous&#39;: 13, &#39;jobs was&#39;: 19, &#39;was the&#39;: 34, &#39;the chairman&#39;: 25, &#39;chairman of&#39;: 9, &#39;of apple&#39;: 23, &#39;apple inc&#39;: 7, &#39;inc and&#39;: 17, &#39;and he&#39;: 4, &#39;he was&#39;: 15, &#39;was very&#39;: 35, &#39;very famous&#39;: 32, &#39;like&#39;: 20, &#39;to&#39;: 26, &#39;use&#39;: 29, &#39;computer&#39;: 10, &#39;like to&#39;: 21, &#39;to use&#39;: 28, &#39;use apple&#39;: 30, &#39;apple computer&#39;: 6, &#39;also&#39;: 0, &#39;eat&#39;: 11, &#39;and also&#39;: 3, &#39;also like&#39;: 1, &#39;to eat&#39;: 27, &#39;eat apple&#39;: 12&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> sklearn </tag>
            
            <tag> æ–‡æ¡£å‘é‡åŒ– </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨sklearnè¿›è¡Œçº¿æ€§å›å½’å’ŒäºŒæ¬¡å›å½’çš„æ¯”è¾ƒç¨‹åº</title>
      <link href="/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E8%BF%9B%E8%A1%8C%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%92%8C%E4%BA%8C%E6%AC%A1%E5%9B%9E%E5%BD%92%E7%9A%84%E6%AF%94%E8%BE%83%E7%A8%8B%E5%BA%8F/"/>
      <url>/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E8%BF%9B%E8%A1%8C%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%92%8C%E4%BA%8C%E6%AC%A1%E5%9B%9E%E5%BD%92%E7%9A%84%E6%AF%94%E8%BE%83%E7%A8%8B%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨sklearnè¿›è¡Œçº¿æ€§å›å½’å’ŒäºŒæ¬¡å›å½’çš„æ¯”è¾ƒç¨‹åº"><a href="#ä½¿ç”¨sklearnè¿›è¡Œçº¿æ€§å›å½’å’ŒäºŒæ¬¡å›å½’çš„æ¯”è¾ƒç¨‹åº" class="headerlink" title="ä½¿ç”¨sklearnè¿›è¡Œçº¿æ€§å›å½’å’ŒäºŒæ¬¡å›å½’çš„æ¯”è¾ƒç¨‹åº"></a>ä½¿ç”¨sklearnè¿›è¡Œçº¿æ€§å›å½’å’ŒäºŒæ¬¡å›å½’çš„æ¯”è¾ƒç¨‹åº</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">#æ¼”ç¤ºå†…å®¹ï¼šäºŒæ¬¡å›å½’å’Œçº¿æ€§å›å½’çš„æ‹Ÿåˆæ•ˆæœçš„å¯¹æ¯”</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(__doc__)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line">font_set = FontProperties(fname=<span class="string">r&quot;/System/Library/Fonts/STHeiti Medium.ttc&quot;</span>, size=<span class="number">20</span>) </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runplt</span>():</span></span><br><span class="line">    plt.figure()<span class="comment"># å®šä¹‰figure</span></span><br><span class="line">    plt.title(<span class="string">u&#x27;æŠ«è¨çš„ä»·æ ¼å’Œç›´å¾„&#x27;</span>,fontproperties=font_set)</span><br><span class="line">    plt.xlabel(<span class="string">u&#x27;ç›´å¾„ï¼ˆinchï¼‰&#x27;</span>,fontproperties=font_set)</span><br><span class="line">    plt.ylabel(<span class="string">u&#x27;ä»·æ ¼ï¼ˆç¾å…ƒï¼‰&#x27;</span>,fontproperties=font_set)</span><br><span class="line">    plt.axis([<span class="number">0</span>, <span class="number">25</span>, <span class="number">0</span>, <span class="number">25</span>])</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> plt</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>#æ¼”ç¤ºå†…å®¹ï¼šäºŒæ¬¡å›å½’å’Œçº¿æ€§å›å½’çš„æ‹Ÿåˆæ•ˆæœçš„å¯¹æ¯”</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ•°æ®</span></span><br><span class="line">X_train = [[<span class="number">6</span>], [<span class="number">8</span>], [<span class="number">10</span>], [<span class="number">14</span>], [<span class="number">18</span>]]</span><br><span class="line">y_train = [[<span class="number">7</span>], [<span class="number">9</span>], [<span class="number">13</span>], [<span class="number">17.5</span>], [<span class="number">18</span>]]</span><br><span class="line">X_test = [[<span class="number">7</span>], [<span class="number">9</span>], [<span class="number">11</span>], [<span class="number">15</span>]]</span><br><span class="line">y_test = [[<span class="number">8</span>], [<span class="number">12</span>], [<span class="number">15</span>], [<span class="number">18</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment">#ç”»å‡ºæ¨ªçºµåæ ‡ä»¥åŠè‹¥å¹²æ•£ç‚¹å›¾</span></span><br><span class="line">plt1 = runplt()</span><br><span class="line">plt1.scatter(X_train, y_train,s=<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#ç»™å‡ºä¸€äº›ç‚¹ï¼Œå¹¶ç”»å‡ºçº¿æ€§å›å½’çš„æ›²çº¿</span></span><br><span class="line">xx = np.linspace(<span class="number">0</span>, <span class="number">26</span>, <span class="number">5</span>)</span><br><span class="line">regressor = LinearRegression()</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line">yy = regressor.predict(xx.reshape(xx.shape[<span class="number">0</span>], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">plt.plot(xx, yy, label=<span class="string">&quot;linear equation&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#å¤šé¡¹å¼å›å½’ï¼ˆæœ¬ä¾‹ä¸­ä¸ºäºŒæ¬¡å›å½’ï¼‰</span></span><br><span class="line"><span class="comment">#é¦–å…ˆç”Ÿæˆå¤šé¡¹å¼ç‰¹å¾</span></span><br><span class="line">quadratic_featurizer = PolynomialFeatures(degree=<span class="number">2</span>)</span><br><span class="line">X_train_quadratic = quadratic_featurizer.fit_transform(X_train)</span><br><span class="line"></span><br><span class="line">regressor_quadratic = LinearRegression()</span><br><span class="line">regressor_quadratic.fit(X_train_quadratic, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#numpy.reshapeï¼ˆé‡å¡‘ï¼‰ç»™æ•°ç»„ä¸€ä¸ªæ–°çš„å½¢çŠ¶è€Œä¸æ”¹å˜å…¶æ•°æ®ã€‚åœ¨æŒ‡å®šçš„é—´éš”å†…è¿”å›å‡åŒ€é—´éš”çš„æ•°å­—</span></span><br><span class="line"><span class="comment">#ç»™å‡ºä¸€äº›ç‚¹ï¼Œå¹¶ç”»å‡ºçº¿æ€§å›å½’çš„æ›²çº¿</span></span><br><span class="line">xx = np.linspace(<span class="number">0</span>, <span class="number">26</span>, <span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span> (xx.shape)</span><br><span class="line"><span class="built_in">print</span> (xx.shape[<span class="number">0</span>])</span><br><span class="line">xx_quadratic = quadratic_featurizer.transform(xx.reshape(xx.shape[<span class="number">0</span>], <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span> (xx.reshape(xx.shape[<span class="number">0</span>], <span class="number">1</span>).shape)</span><br><span class="line"></span><br><span class="line">plt.plot(xx, regressor_quadratic.predict(xx_quadratic), <span class="string">&#x27;r-&#x27;</span>,label=<span class="string">&quot;quadratic equation&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">X_test_quadratic = quadratic_featurizer.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¡ç®—R^2å¾—åˆ† å¾—åˆ†è¶Šé«˜è¶Šå¥½</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;linear equation  r-squared&#x27;</span>, regressor.score(X_test, y_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;quadratic equation r-squared&#x27;</span>, regressor_quadratic.score(X_test_quadratic, y_test))</span><br></pre></td></tr></table></figure><pre><code>(5,)5(5, 1)</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210714231113.png" alt="output_2_1"></p><pre><code>linear equation  r-squared 0.8283656795834485quadratic equation r-squared 0.9785451046983036</code></pre>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> sklearn </tag>
            
            <tag> çº¿æ€§å›å½’ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨sklearnè¿›è¡Œé‡çº²ç¼©æ”¾çš„ç¨‹åº</title>
      <link href="/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E8%BF%9B%E8%A1%8C%E9%87%8F%E7%BA%B2%E7%BC%A9%E6%94%BE%E7%9A%84%E7%A8%8B%E5%BA%8F/"/>
      <url>/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E8%BF%9B%E8%A1%8C%E9%87%8F%E7%BA%B2%E7%BC%A9%E6%94%BE%E7%9A%84%E7%A8%8B%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨sklearnè¿›è¡Œé‡çº²ç¼©æ”¾çš„ç¨‹åº"><a href="#ä½¿ç”¨sklearnè¿›è¡Œé‡çº²ç¼©æ”¾çš„ç¨‹åº" class="headerlink" title="ä½¿ç”¨sklearnè¿›è¡Œé‡çº²ç¼©æ”¾çš„ç¨‹åº"></a>ä½¿ç”¨sklearnè¿›è¡Œé‡çº²ç¼©æ”¾çš„ç¨‹åº</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">æ¼”ç¤ºå†…å®¹ï¼šé‡çº²çš„ç‰¹å¾ç¼©æ”¾</span></span><br><span class="line"><span class="string">ï¼ˆä¸¤ç§æ–¹æ³•ï¼šæ ‡å‡†åŒ–ç¼©æ”¾æ³•å’ŒåŒºé—´ç¼©æ”¾æ³•ã€‚æ¯ç§æ–¹æ³•ä¸¾äº†ä¸¤ä¸ªä¾‹å­ï¼šç®€å•äºŒç»´çŸ©é˜µå’Œirisæ•°æ®é›†ï¼‰</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment">#æ–¹æ³•1ï¼šæ ‡å‡†åŒ–ç¼©æ”¾æ³• ä¾‹1ï¼šå¯¹ç®€å•ç¤ºä¾‹äºŒç»´çŸ©é˜µçš„åˆ—æ•°æ®è¿›è¡Œ</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing   </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="comment">#é‡‡ç”¨numpyçš„arrayè¡¨ç¤ºï¼Œå› ä¸ºè¦ç”¨åˆ°å…¶meanç­‰å‡½æ•°ï¼Œè€Œlistæ²¡æœ‰è¿™äº›å‡½æ•°</span></span><br><span class="line">X = np.array([[<span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">100</span>, <span class="number">1</span>], </span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>]])  </span><br><span class="line"><span class="comment"># calculate mean  </span></span><br><span class="line">X_mean = X.mean(axis=<span class="number">0</span>)  </span><br><span class="line"><span class="comment"># calculate variance   </span></span><br><span class="line">X_std = X.std(axis=<span class="number">0</span>)  </span><br><span class="line"><span class="comment">#print (X_std)</span></span><br><span class="line"><span class="comment"># standardize X  </span></span><br><span class="line">X1 = (X-X_mean)/X_std</span><br><span class="line"><span class="built_in">print</span> (X1)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># we can also use function preprocessing.scale to standardize X  </span></span><br><span class="line">X_scale = preprocessing.scale(X)  </span><br><span class="line"><span class="built_in">print</span> (X_scale)</span><br></pre></td></tr></table></figure><pre><code>[[-0.58504784 -1.        ] [-0.58504784 -1.        ] [ 1.73197332  1.        ] [-0.56187763  1.        ]][[-0.58504784 -1.        ] [-0.58504784 -1.        ] [ 1.73197332  1.        ] [-0.56187763  1.        ]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æ–¹æ³•1ï¼š æ ‡å‡†åŒ–ç¼©æ”¾æ³• ä¾‹2ï¼šå¯¹irisæ•°æ®äºŒç»´çŸ©é˜µçš„åˆ—æ•°æ®è¿›è¡Œã€‚è¿™æ¬¡é‡‡ç”¨ä¸€ä¸ªé›†æˆçš„æ–¹æ³•StandardScaler</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X_scale = preprocessing.scale(iris.data)  </span><br><span class="line"><span class="built_in">print</span> (X_scale)</span><br></pre></td></tr></table></figure><pre><code>[[-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.31544430e+00] [-1.14301691e+00 -1.31979479e-01 -1.34022653e+00 -1.31544430e+00] [-1.38535265e+00  3.28414053e-01 -1.39706395e+00 -1.31544430e+00] [-1.50652052e+00  9.82172869e-02 -1.28338910e+00 -1.31544430e+00] [-1.02184904e+00  1.24920112e+00 -1.34022653e+00 -1.31544430e+00] [-5.37177559e-01  1.93979142e+00 -1.16971425e+00 -1.05217993e+00] [-1.50652052e+00  7.88807586e-01 -1.34022653e+00 -1.18381211e+00] [-1.02184904e+00  7.88807586e-01 -1.28338910e+00 -1.31544430e+00] [-1.74885626e+00 -3.62176246e-01 -1.34022653e+00 -1.31544430e+00] [-1.14301691e+00  9.82172869e-02 -1.28338910e+00 -1.44707648e+00] [-5.37177559e-01  1.47939788e+00 -1.28338910e+00 -1.31544430e+00] [-1.26418478e+00  7.88807586e-01 -1.22655167e+00 -1.31544430e+00] [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.44707648e+00] [-1.87002413e+00 -1.31979479e-01 -1.51073881e+00 -1.44707648e+00] [-5.25060772e-02  2.16998818e+00 -1.45390138e+00 -1.31544430e+00] [-1.73673948e-01  3.09077525e+00 -1.28338910e+00 -1.05217993e+00] [-5.37177559e-01  1.93979142e+00 -1.39706395e+00 -1.05217993e+00] [-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.18381211e+00] [-1.73673948e-01  1.70959465e+00 -1.16971425e+00 -1.18381211e+00] [-9.00681170e-01  1.70959465e+00 -1.28338910e+00 -1.18381211e+00] [-5.37177559e-01  7.88807586e-01 -1.16971425e+00 -1.31544430e+00] [-9.00681170e-01  1.47939788e+00 -1.28338910e+00 -1.05217993e+00] [-1.50652052e+00  1.24920112e+00 -1.56757623e+00 -1.31544430e+00] [-9.00681170e-01  5.58610819e-01 -1.16971425e+00 -9.20547742e-01] [-1.26418478e+00  7.88807586e-01 -1.05603939e+00 -1.31544430e+00] [-1.02184904e+00 -1.31979479e-01 -1.22655167e+00 -1.31544430e+00] [-1.02184904e+00  7.88807586e-01 -1.22655167e+00 -1.05217993e+00] [-7.79513300e-01  1.01900435e+00 -1.28338910e+00 -1.31544430e+00] [-7.79513300e-01  7.88807586e-01 -1.34022653e+00 -1.31544430e+00] [-1.38535265e+00  3.28414053e-01 -1.22655167e+00 -1.31544430e+00] [-1.26418478e+00  9.82172869e-02 -1.22655167e+00 -1.31544430e+00] [-5.37177559e-01  7.88807586e-01 -1.28338910e+00 -1.05217993e+00] [-7.79513300e-01  2.40018495e+00 -1.28338910e+00 -1.44707648e+00] [-4.16009689e-01  2.63038172e+00 -1.34022653e+00 -1.31544430e+00] [-1.14301691e+00  9.82172869e-02 -1.28338910e+00 -1.31544430e+00] [-1.02184904e+00  3.28414053e-01 -1.45390138e+00 -1.31544430e+00] [-4.16009689e-01  1.01900435e+00 -1.39706395e+00 -1.31544430e+00] [-1.14301691e+00  1.24920112e+00 -1.34022653e+00 -1.44707648e+00] [-1.74885626e+00 -1.31979479e-01 -1.39706395e+00 -1.31544430e+00] [-9.00681170e-01  7.88807586e-01 -1.28338910e+00 -1.31544430e+00] [-1.02184904e+00  1.01900435e+00 -1.39706395e+00 -1.18381211e+00] [-1.62768839e+00 -1.74335684e+00 -1.39706395e+00 -1.18381211e+00] [-1.74885626e+00  3.28414053e-01 -1.39706395e+00 -1.31544430e+00] [-1.02184904e+00  1.01900435e+00 -1.22655167e+00 -7.88915558e-01] [-9.00681170e-01  1.70959465e+00 -1.05603939e+00 -1.05217993e+00] [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.18381211e+00] [-9.00681170e-01  1.70959465e+00 -1.22655167e+00 -1.31544430e+00] [-1.50652052e+00  3.28414053e-01 -1.34022653e+00 -1.31544430e+00] [-6.58345429e-01  1.47939788e+00 -1.28338910e+00 -1.31544430e+00] [-1.02184904e+00  5.58610819e-01 -1.34022653e+00 -1.31544430e+00] [ 1.40150837e+00  3.28414053e-01  5.35408562e-01  2.64141916e-01] [ 6.74501145e-01  3.28414053e-01  4.21733708e-01  3.95774101e-01] [ 1.28034050e+00  9.82172869e-02  6.49083415e-01  3.95774101e-01] [-4.16009689e-01 -1.74335684e+00  1.37546573e-01  1.32509732e-01] [ 7.95669016e-01 -5.92373012e-01  4.78571135e-01  3.95774101e-01] [-1.73673948e-01 -5.92373012e-01  4.21733708e-01  1.32509732e-01] [ 5.53333275e-01  5.58610819e-01  5.35408562e-01  5.27406285e-01] [-1.14301691e+00 -1.51316008e+00 -2.60315415e-01 -2.62386821e-01] [ 9.16836886e-01 -3.62176246e-01  4.78571135e-01  1.32509732e-01] [-7.79513300e-01 -8.22569778e-01  8.07091462e-02  2.64141916e-01] [-1.02184904e+00 -2.43394714e+00 -1.46640561e-01 -2.62386821e-01] [ 6.86617933e-02 -1.31979479e-01  2.51221427e-01  3.95774101e-01] [ 1.89829664e-01 -1.97355361e+00  1.37546573e-01 -2.62386821e-01] [ 3.10997534e-01 -3.62176246e-01  5.35408562e-01  2.64141916e-01] [-2.94841818e-01 -3.62176246e-01 -8.98031345e-02  1.32509732e-01] [ 1.03800476e+00  9.82172869e-02  3.64896281e-01  2.64141916e-01] [-2.94841818e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01] [-5.25060772e-02 -8.22569778e-01  1.94384000e-01 -2.62386821e-01] [ 4.32165405e-01 -1.97355361e+00  4.21733708e-01  3.95774101e-01] [-2.94841818e-01 -1.28296331e+00  8.07091462e-02 -1.30754636e-01] [ 6.86617933e-02  3.28414053e-01  5.92245988e-01  7.90670654e-01] [ 3.10997534e-01 -5.92373012e-01  1.37546573e-01  1.32509732e-01] [ 5.53333275e-01 -1.28296331e+00  6.49083415e-01  3.95774101e-01] [ 3.10997534e-01 -5.92373012e-01  5.35408562e-01  8.77547895e-04] [ 6.74501145e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01] [ 9.16836886e-01 -1.31979479e-01  3.64896281e-01  2.64141916e-01] [ 1.15917263e+00 -5.92373012e-01  5.92245988e-01  2.64141916e-01] [ 1.03800476e+00 -1.31979479e-01  7.05920842e-01  6.59038469e-01] [ 1.89829664e-01 -3.62176246e-01  4.21733708e-01  3.95774101e-01] [-1.73673948e-01 -1.05276654e+00 -1.46640561e-01 -2.62386821e-01] [-4.16009689e-01 -1.51316008e+00  2.38717193e-02 -1.30754636e-01] [-4.16009689e-01 -1.51316008e+00 -3.29657076e-02 -2.62386821e-01] [-5.25060772e-02 -8.22569778e-01  8.07091462e-02  8.77547895e-04] [ 1.89829664e-01 -8.22569778e-01  7.62758269e-01  5.27406285e-01] [-5.37177559e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01] [ 1.89829664e-01  7.88807586e-01  4.21733708e-01  5.27406285e-01] [ 1.03800476e+00  9.82172869e-02  5.35408562e-01  3.95774101e-01] [ 5.53333275e-01 -1.74335684e+00  3.64896281e-01  1.32509732e-01] [-2.94841818e-01 -1.31979479e-01  1.94384000e-01  1.32509732e-01] [-4.16009689e-01 -1.28296331e+00  1.37546573e-01  1.32509732e-01] [-4.16009689e-01 -1.05276654e+00  3.64896281e-01  8.77547895e-04] [ 3.10997534e-01 -1.31979479e-01  4.78571135e-01  2.64141916e-01] [-5.25060772e-02 -1.05276654e+00  1.37546573e-01  8.77547895e-04] [-1.02184904e+00 -1.74335684e+00 -2.60315415e-01 -2.62386821e-01] [-2.94841818e-01 -8.22569778e-01  2.51221427e-01  1.32509732e-01] [-1.73673948e-01 -1.31979479e-01  2.51221427e-01  8.77547895e-04] [-1.73673948e-01 -3.62176246e-01  2.51221427e-01  1.32509732e-01] [ 4.32165405e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01] [-9.00681170e-01 -1.28296331e+00 -4.30827696e-01 -1.30754636e-01] [-1.73673948e-01 -5.92373012e-01  1.94384000e-01  1.32509732e-01] [ 5.53333275e-01  5.58610819e-01  1.27429511e+00  1.71209594e+00] [-5.25060772e-02 -8.22569778e-01  7.62758269e-01  9.22302838e-01] [ 1.52267624e+00 -1.31979479e-01  1.21745768e+00  1.18556721e+00] [ 5.53333275e-01 -3.62176246e-01  1.04694540e+00  7.90670654e-01] [ 7.95669016e-01 -1.31979479e-01  1.16062026e+00  1.31719939e+00] [ 2.12851559e+00 -1.31979479e-01  1.61531967e+00  1.18556721e+00] [-1.14301691e+00 -1.28296331e+00  4.21733708e-01  6.59038469e-01] [ 1.76501198e+00 -3.62176246e-01  1.44480739e+00  7.90670654e-01] [ 1.03800476e+00 -1.28296331e+00  1.16062026e+00  7.90670654e-01] [ 1.64384411e+00  1.24920112e+00  1.33113254e+00  1.71209594e+00] [ 7.95669016e-01  3.28414053e-01  7.62758269e-01  1.05393502e+00] [ 6.74501145e-01 -8.22569778e-01  8.76433123e-01  9.22302838e-01] [ 1.15917263e+00 -1.31979479e-01  9.90107977e-01  1.18556721e+00] [-1.73673948e-01 -1.28296331e+00  7.05920842e-01  1.05393502e+00] [-5.25060772e-02 -5.92373012e-01  7.62758269e-01  1.58046376e+00] [ 6.74501145e-01  3.28414053e-01  8.76433123e-01  1.44883158e+00] [ 7.95669016e-01 -1.31979479e-01  9.90107977e-01  7.90670654e-01] [ 2.24968346e+00  1.70959465e+00  1.67215710e+00  1.31719939e+00] [ 2.24968346e+00 -1.05276654e+00  1.78583195e+00  1.44883158e+00] [ 1.89829664e-01 -1.97355361e+00  7.05920842e-01  3.95774101e-01] [ 1.28034050e+00  3.28414053e-01  1.10378283e+00  1.44883158e+00] [-2.94841818e-01 -5.92373012e-01  6.49083415e-01  1.05393502e+00] [ 2.24968346e+00 -5.92373012e-01  1.67215710e+00  1.05393502e+00] [ 5.53333275e-01 -8.22569778e-01  6.49083415e-01  7.90670654e-01] [ 1.03800476e+00  5.58610819e-01  1.10378283e+00  1.18556721e+00] [ 1.64384411e+00  3.28414053e-01  1.27429511e+00  7.90670654e-01] [ 4.32165405e-01 -5.92373012e-01  5.92245988e-01  7.90670654e-01] [ 3.10997534e-01 -1.31979479e-01  6.49083415e-01  7.90670654e-01] [ 6.74501145e-01 -5.92373012e-01  1.04694540e+00  1.18556721e+00] [ 1.64384411e+00 -1.31979479e-01  1.16062026e+00  5.27406285e-01] [ 1.88617985e+00 -5.92373012e-01  1.33113254e+00  9.22302838e-01] [ 2.49201920e+00  1.70959465e+00  1.50164482e+00  1.05393502e+00] [ 6.74501145e-01 -5.92373012e-01  1.04694540e+00  1.31719939e+00] [ 5.53333275e-01 -5.92373012e-01  7.62758269e-01  3.95774101e-01] [ 3.10997534e-01 -1.05276654e+00  1.04694540e+00  2.64141916e-01] [ 2.24968346e+00 -1.31979479e-01  1.33113254e+00  1.44883158e+00] [ 5.53333275e-01  7.88807586e-01  1.04694540e+00  1.58046376e+00] [ 6.74501145e-01  9.82172869e-02  9.90107977e-01  7.90670654e-01] [ 1.89829664e-01 -1.31979479e-01  5.92245988e-01  7.90670654e-01] [ 1.28034050e+00  9.82172869e-02  9.33270550e-01  1.18556721e+00] [ 1.03800476e+00  9.82172869e-02  1.04694540e+00  1.58046376e+00] [ 1.28034050e+00  9.82172869e-02  7.62758269e-01  1.44883158e+00] [-5.25060772e-02 -8.22569778e-01  7.62758269e-01  9.22302838e-01] [ 1.15917263e+00  3.28414053e-01  1.21745768e+00  1.44883158e+00] [ 1.03800476e+00  5.58610819e-01  1.10378283e+00  1.71209594e+00] [ 1.03800476e+00 -1.31979479e-01  8.19595696e-01  1.44883158e+00] [ 5.53333275e-01 -1.28296331e+00  7.05920842e-01  9.22302838e-01] [ 7.95669016e-01 -1.31979479e-01  8.19595696e-01  1.05393502e+00] [ 4.32165405e-01  7.88807586e-01  9.33270550e-01  1.44883158e+00] [ 6.86617933e-02 -1.31979479e-01  7.62758269e-01  7.90670654e-01]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æ–¹æ³•2ï¼š åŒºé—´ç¼©æ”¾æ³• ä¾‹3ï¼šå¯¹ç®€å•ç¤ºä¾‹äºŒç»´çŸ©é˜µçš„åˆ—æ•°æ®è¿›è¡Œ</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">data = [[<span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">100</span>, <span class="number">1</span>], </span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line"><span class="built_in">print</span>(scaler.fit(data))</span><br><span class="line"><span class="built_in">print</span>(scaler.transform(data))</span><br></pre></td></tr></table></figure><pre><code>MinMaxScaler(copy=True, feature_range=(0, 1))[[0.   0.  ] [0.   0.  ] [1.   1.  ] [0.01 1.  ]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æ–¹æ³•2ï¼š åŒºé—´ç¼©æ”¾æ³• ä¾‹4ï¼šå¯¹irisæ•°æ®äºŒç»´çŸ©é˜µçš„åˆ—æ•°æ®è¿›è¡Œ</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">data = iris.data</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line"><span class="built_in">print</span>(scaler.fit(data))</span><br><span class="line"><span class="built_in">print</span>(scaler.transform(data))</span><br></pre></td></tr></table></figure><pre><code>MinMaxScaler(copy=True, feature_range=(0, 1))[[0.22222222 0.625      0.06779661 0.04166667] [0.16666667 0.41666667 0.06779661 0.04166667] [0.11111111 0.5        0.05084746 0.04166667] [0.08333333 0.45833333 0.08474576 0.04166667] [0.19444444 0.66666667 0.06779661 0.04166667] [0.30555556 0.79166667 0.11864407 0.125     ] [0.08333333 0.58333333 0.06779661 0.08333333] [0.19444444 0.58333333 0.08474576 0.04166667] [0.02777778 0.375      0.06779661 0.04166667] [0.16666667 0.45833333 0.08474576 0.        ] [0.30555556 0.70833333 0.08474576 0.04166667] [0.13888889 0.58333333 0.10169492 0.04166667] [0.13888889 0.41666667 0.06779661 0.        ] [0.         0.41666667 0.01694915 0.        ] [0.41666667 0.83333333 0.03389831 0.04166667] [0.38888889 1.         0.08474576 0.125     ] [0.30555556 0.79166667 0.05084746 0.125     ] [0.22222222 0.625      0.06779661 0.08333333] [0.38888889 0.75       0.11864407 0.08333333] [0.22222222 0.75       0.08474576 0.08333333] [0.30555556 0.58333333 0.11864407 0.04166667] [0.22222222 0.70833333 0.08474576 0.125     ] [0.08333333 0.66666667 0.         0.04166667] [0.22222222 0.54166667 0.11864407 0.16666667] [0.13888889 0.58333333 0.15254237 0.04166667] [0.19444444 0.41666667 0.10169492 0.04166667] [0.19444444 0.58333333 0.10169492 0.125     ] [0.25       0.625      0.08474576 0.04166667] [0.25       0.58333333 0.06779661 0.04166667] [0.11111111 0.5        0.10169492 0.04166667] [0.13888889 0.45833333 0.10169492 0.04166667] [0.30555556 0.58333333 0.08474576 0.125     ] [0.25       0.875      0.08474576 0.        ] [0.33333333 0.91666667 0.06779661 0.04166667] [0.16666667 0.45833333 0.08474576 0.04166667] [0.19444444 0.5        0.03389831 0.04166667] [0.33333333 0.625      0.05084746 0.04166667] [0.16666667 0.66666667 0.06779661 0.        ] [0.02777778 0.41666667 0.05084746 0.04166667] [0.22222222 0.58333333 0.08474576 0.04166667] [0.19444444 0.625      0.05084746 0.08333333] [0.05555556 0.125      0.05084746 0.08333333] [0.02777778 0.5        0.05084746 0.04166667] [0.19444444 0.625      0.10169492 0.20833333] [0.22222222 0.75       0.15254237 0.125     ] [0.13888889 0.41666667 0.06779661 0.08333333] [0.22222222 0.75       0.10169492 0.04166667] [0.08333333 0.5        0.06779661 0.04166667] [0.27777778 0.70833333 0.08474576 0.04166667] [0.19444444 0.54166667 0.06779661 0.04166667] [0.75       0.5        0.62711864 0.54166667] [0.58333333 0.5        0.59322034 0.58333333] [0.72222222 0.45833333 0.66101695 0.58333333] [0.33333333 0.125      0.50847458 0.5       ] [0.61111111 0.33333333 0.61016949 0.58333333] [0.38888889 0.33333333 0.59322034 0.5       ] [0.55555556 0.54166667 0.62711864 0.625     ] [0.16666667 0.16666667 0.38983051 0.375     ] [0.63888889 0.375      0.61016949 0.5       ] [0.25       0.29166667 0.49152542 0.54166667] [0.19444444 0.         0.42372881 0.375     ] [0.44444444 0.41666667 0.54237288 0.58333333] [0.47222222 0.08333333 0.50847458 0.375     ] [0.5        0.375      0.62711864 0.54166667] [0.36111111 0.375      0.44067797 0.5       ] [0.66666667 0.45833333 0.57627119 0.54166667] [0.36111111 0.41666667 0.59322034 0.58333333] [0.41666667 0.29166667 0.52542373 0.375     ] [0.52777778 0.08333333 0.59322034 0.58333333] [0.36111111 0.20833333 0.49152542 0.41666667] [0.44444444 0.5        0.6440678  0.70833333] [0.5        0.33333333 0.50847458 0.5       ] [0.55555556 0.20833333 0.66101695 0.58333333] [0.5        0.33333333 0.62711864 0.45833333] [0.58333333 0.375      0.55932203 0.5       ] [0.63888889 0.41666667 0.57627119 0.54166667] [0.69444444 0.33333333 0.6440678  0.54166667] [0.66666667 0.41666667 0.6779661  0.66666667] [0.47222222 0.375      0.59322034 0.58333333] [0.38888889 0.25       0.42372881 0.375     ] [0.33333333 0.16666667 0.47457627 0.41666667] [0.33333333 0.16666667 0.45762712 0.375     ] [0.41666667 0.29166667 0.49152542 0.45833333] [0.47222222 0.29166667 0.69491525 0.625     ] [0.30555556 0.41666667 0.59322034 0.58333333] [0.47222222 0.58333333 0.59322034 0.625     ] [0.66666667 0.45833333 0.62711864 0.58333333] [0.55555556 0.125      0.57627119 0.5       ] [0.36111111 0.41666667 0.52542373 0.5       ] [0.33333333 0.20833333 0.50847458 0.5       ] [0.33333333 0.25       0.57627119 0.45833333] [0.5        0.41666667 0.61016949 0.54166667] [0.41666667 0.25       0.50847458 0.45833333] [0.19444444 0.125      0.38983051 0.375     ] [0.36111111 0.29166667 0.54237288 0.5       ] [0.38888889 0.41666667 0.54237288 0.45833333] [0.38888889 0.375      0.54237288 0.5       ] [0.52777778 0.375      0.55932203 0.5       ] [0.22222222 0.20833333 0.33898305 0.41666667] [0.38888889 0.33333333 0.52542373 0.5       ] [0.55555556 0.54166667 0.84745763 1.        ] [0.41666667 0.29166667 0.69491525 0.75      ] [0.77777778 0.41666667 0.83050847 0.83333333] [0.55555556 0.375      0.77966102 0.70833333] [0.61111111 0.41666667 0.81355932 0.875     ] [0.91666667 0.41666667 0.94915254 0.83333333] [0.16666667 0.20833333 0.59322034 0.66666667] [0.83333333 0.375      0.89830508 0.70833333] [0.66666667 0.20833333 0.81355932 0.70833333] [0.80555556 0.66666667 0.86440678 1.        ] [0.61111111 0.5        0.69491525 0.79166667] [0.58333333 0.29166667 0.72881356 0.75      ] [0.69444444 0.41666667 0.76271186 0.83333333] [0.38888889 0.20833333 0.6779661  0.79166667] [0.41666667 0.33333333 0.69491525 0.95833333] [0.58333333 0.5        0.72881356 0.91666667] [0.61111111 0.41666667 0.76271186 0.70833333] [0.94444444 0.75       0.96610169 0.875     ] [0.94444444 0.25       1.         0.91666667] [0.47222222 0.08333333 0.6779661  0.58333333] [0.72222222 0.5        0.79661017 0.91666667] [0.36111111 0.33333333 0.66101695 0.79166667] [0.94444444 0.33333333 0.96610169 0.79166667] [0.55555556 0.29166667 0.66101695 0.70833333] [0.66666667 0.54166667 0.79661017 0.83333333] [0.80555556 0.5        0.84745763 0.70833333] [0.52777778 0.33333333 0.6440678  0.70833333] [0.5        0.41666667 0.66101695 0.70833333] [0.58333333 0.33333333 0.77966102 0.83333333] [0.80555556 0.41666667 0.81355932 0.625     ] [0.86111111 0.33333333 0.86440678 0.75      ] [1.         0.75       0.91525424 0.79166667] [0.58333333 0.33333333 0.77966102 0.875     ] [0.55555556 0.33333333 0.69491525 0.58333333] [0.5        0.25       0.77966102 0.54166667] [0.94444444 0.41666667 0.86440678 0.91666667] [0.55555556 0.58333333 0.77966102 0.95833333] [0.58333333 0.45833333 0.76271186 0.70833333] [0.47222222 0.41666667 0.6440678  0.70833333] [0.72222222 0.45833333 0.74576271 0.83333333] [0.66666667 0.45833333 0.77966102 0.95833333] [0.72222222 0.45833333 0.69491525 0.91666667] [0.41666667 0.29166667 0.69491525 0.75      ] [0.69444444 0.5        0.83050847 0.91666667] [0.66666667 0.54166667 0.79661017 1.        ] [0.66666667 0.41666667 0.71186441 0.91666667] [0.55555556 0.20833333 0.6779661  0.75      ] [0.61111111 0.41666667 0.71186441 0.79166667] [0.52777778 0.58333333 0.74576271 0.91666667] [0.44444444 0.41666667 0.69491525 0.70833333]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> sklearn </tag>
            
            <tag> é‡çº²ç¼©æ”¾ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨Sklearnè¿›è¡Œç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿çš„ç»˜åˆ¶</title>
      <link href="/2021/07/13/%E4%BD%BF%E7%94%A8Sklearn%E8%BF%9B%E8%A1%8C%E7%B2%BE%E7%A1%AE%E7%8E%87-%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%9B%B2%E7%BA%BF%E7%9A%84%E7%BB%98%E5%88%B6/"/>
      <url>/2021/07/13/%E4%BD%BF%E7%94%A8Sklearn%E8%BF%9B%E8%A1%8C%E7%B2%BE%E7%A1%AE%E7%8E%87-%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%9B%B2%E7%BA%BF%E7%9A%84%E7%BB%98%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨Sklearnè¿›è¡Œç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿çš„ç»˜åˆ¶"><a href="#ä½¿ç”¨Sklearnè¿›è¡Œç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿çš„ç»˜åˆ¶" class="headerlink" title="ä½¿ç”¨Sklearnè¿›è¡Œç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿çš„ç»˜åˆ¶"></a>ä½¿ç”¨Sklearnè¿›è¡Œç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿çš„ç»˜åˆ¶</h1><ul><li>ç²¾ç¡®ç‡ï¼šæ¨¡å‹åˆ¤å®šçš„æ­£ä¾‹ä¸­çœŸæ­£æ­£ä¾‹æ‰€å çš„æ¯”é‡</li><li>å¬å›ç‡ï¼šæ€»æ­£ä¾‹ä¸­è¢«æ¨¡å‹åˆ¤å®šä¸ºæ­£ä¾‹çš„æ¯”é‡</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">#æ¼”ç¤ºç›®çš„ï¼šåˆ©ç”¨é¸¢å°¾èŠ±æ•°æ®é›†ç”»å‡ºP-Ræ›²çº¿</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(__doc__)</span><br></pre></td></tr></table></figure><pre><code>#æ¼”ç¤ºç›®çš„ï¼šåˆ©ç”¨é¸¢å°¾èŠ±æ•°æ®é›†ç”»å‡ºP-Ræ›²çº¿</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> average_precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> label_binarize</span><br><span class="line"><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsRestClassifier</span><br><span class="line"><span class="comment">#from sklearn.cross_validation import train_test_split  #é€‚ç”¨äºanaconda 3.6åŠä»¥å‰ç‰ˆæœ¬</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split<span class="comment">#é€‚ç”¨äºanaconda 3.7</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ä»¥irisæ•°æ®ä¸ºä¾‹ï¼Œç”»å‡ºP-Ræ›²çº¿</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="comment"># æ ‡ç­¾äºŒå€¼åŒ–,å°†ä¸‰ä¸ªç±»è½¬ä¸º001, 010, 100çš„æ ¼å¼.å› ä¸ºè¿™æ˜¯ä¸ªå¤šç±»åˆ†ç±»é—®é¢˜ï¼Œåé¢å°†è¦é‡‡ç”¨</span></span><br><span class="line"><span class="comment">#OneVsRestClassifierç­–ç•¥è½¬ä¸ºäºŒç±»åˆ†ç±»é—®é¢˜</span></span><br><span class="line">y = label_binarize(y, classes=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">n_classes = y.shape[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(y.shape)</span><br><span class="line"><span class="built_in">print</span> (y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¢åŠ äº†800ç»´çš„ å™ªå£°ç‰¹å¾</span></span><br><span class="line">random_state = np.random.RandomState(<span class="number">0</span>)</span><br><span class="line">n_samples, n_features = X.shape</span><br><span class="line"><span class="comment"># print(X.shape)  (150, 4)</span></span><br><span class="line">X = np.c_[X, random_state.randn(n_samples, <span class="number">200</span> * n_features)]</span><br><span class="line"><span class="comment"># print(X.shape)  (150, 804)</span></span><br><span class="line"><span class="comment"># Split into training and test</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">.5</span>, random_state=random_state) <span class="comment">#éšæœºæ•°ï¼Œå¡«0æˆ–ä¸å¡«ï¼Œæ¯æ¬¡éƒ½ä¼šä¸ä¸€æ ·</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run classifier probability : boolean, optional (default=False)Whether to enable probability estimates. This must be enabled prior to calling fit, and will slow down that method.</span></span><br><span class="line">classifier = OneVsRestClassifier(svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, probability=<span class="literal">True</span>, random_state=random_state))</span><br><span class="line">y_score = classifier.fit(X_train, y_train).decision_function(X_test)</span><br></pre></td></tr></table></figure><pre><code>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2](150, 3)[[1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Compute Precision-Recall and plot curve  </span></span><br><span class="line"><span class="comment">#ä¸‹é¢çš„ä¸‹åˆ’çº¿æ˜¯è¿”å›çš„é˜ˆå€¼ã€‚ä½œä¸ºä¸€ä¸ªåç§°ï¼šæ­¤æ—¶â€œ_â€ä½œä¸ºä¸´æ—¶æ€§çš„åç§°ä½¿ç”¨ã€‚</span></span><br><span class="line"><span class="comment">#è¡¨ç¤ºåˆ†é…äº†ä¸€ä¸ªç‰¹å®šçš„åç§°ï¼Œä½†æ˜¯å¹¶ä¸ä¼šåœ¨åé¢å†æ¬¡ç”¨åˆ°è¯¥åç§°ã€‚</span></span><br><span class="line">precision = <span class="built_in">dict</span>()</span><br><span class="line">recall = <span class="built_in">dict</span>()</span><br><span class="line">average_precision = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_classes):</span><br><span class="line">    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],  y_score[:, i]) <span class="comment">#The last precision and recall values are 1. and 0. respectively and do not have a corresponding threshold. This ensures that the graph starts on the x axis.</span></span><br><span class="line">    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])<span class="comment">#åˆ‡ç‰‡ï¼Œç¬¬iä¸ªç±»çš„åˆ†ç±»ç»“æœæ€§èƒ½</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute micro-average curve and area. ravel()å°†å¤šç»´æ•°ç»„é™ä¸ºä¸€ç»´</span></span><br><span class="line">precision[<span class="string">&quot;micro&quot;</span>], recall[<span class="string">&quot;micro&quot;</span>], _ = precision_recall_curve(y_test.ravel(),  y_score.ravel())</span><br><span class="line">average_precision[<span class="string">&quot;micro&quot;</span>] = average_precision_score(y_test, y_score, average=<span class="string">&quot;micro&quot;</span>) <span class="comment">#This score corresponds to the area under the precision-recall curve.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Precision-Recall curve for each class</span></span><br><span class="line">plt.clf()<span class="comment">#clf å‡½æ•°ç”¨äºæ¸…é™¤å½“å‰å›¾åƒçª—å£</span></span><br><span class="line">plt.plot(recall[<span class="string">&quot;micro&quot;</span>], precision[<span class="string">&quot;micro&quot;</span>],</span><br><span class="line">         label=<span class="string">&#x27;micro-average Precision-recall curve (area = &#123;0:0.2f&#125;)&#x27;</span>.<span class="built_in">format</span>(average_precision[<span class="string">&quot;micro&quot;</span>]))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_classes):</span><br><span class="line">    plt.plot(recall[i], precision[i],</span><br><span class="line">             label=<span class="string">&#x27;Precision-recall curve of class &#123;0&#125; (area = &#123;1:0.2f&#125;)&#x27;</span>.<span class="built_in">format</span>(i, average_precision[i]))</span><br><span class="line"></span><br><span class="line">plt.xlim([<span class="number">0.0</span>, <span class="number">1.0</span>])</span><br><span class="line">plt.ylim([<span class="number">0.0</span>, <span class="number">1.05</span>]) <span class="comment">#xlimã€ylimï¼šåˆ†åˆ«è®¾ç½®Xã€Yè½´çš„æ˜¾ç¤ºèŒƒå›´ã€‚</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Recall&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Precision&#x27;</span>,fontsize=<span class="number">16</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Extension of Precision-Recall curve to multi-class&#x27;</span>,fontsize=<span class="number">16</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;lower right&quot;</span>)<span class="comment">#legend æ˜¯ç”¨äºè®¾ç½®å›¾ä¾‹çš„å‡½æ•°</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210713112440.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sklearn </tag>
            
            <tag> P-Ræ›²çº¿ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zero-Resource Knowledge-Grounded Dialogue Generation</title>
      <link href="/2021/07/10/2020%20-%20Zero-Resource%20Knowledge-Grounded%20Dialogue%20Generati/"/>
      <url>/2021/07/10/2020%20-%20Zero-Resource%20Knowledge-Grounded%20Dialogue%20Generati/</url>
      
        <content type="html"><![CDATA[<h1 id="Zero-Resource-Knowledge-Grounded-Dialogue-Generation"><a href="#Zero-Resource-Knowledge-Grounded-Dialogue-Generation" class="headerlink" title="Zero-Resource Knowledge-Grounded Dialogue Generation"></a>Zero-Resource Knowledge-Grounded Dialogue Generation</h1><blockquote><p><a href="https://arxiv.org/abs/2008.12918">è®ºæ–‡ï¼šhttps://arxiv.org/abs/2008.12918</a></p><p><a href="https://github.com/nlpxucan/ZRKGC">ä»£ç ï¼šhttps://github.com/nlpxucan/ZRKGC</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>ç¥ç»ç½‘ç»œå¯¹è¯æ¨¡å‹éœ€è¦ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ï¼Œè€Œè¿™äº›å¯¹è¯å¾ˆéš¾è·å¾—ã€‚ä¸ºäº†å…‹æœæ•°æ®æ–¹é¢çš„æŒ‘æˆ˜å¹¶é™ä½æ„å»ºçŸ¥è¯†åŸºç¡€å¯¹è¯ç³»ç»Ÿçš„æˆæœ¬ï¼Œæœ¬æ–‡é€šè¿‡å‡è®¾è®­ç»ƒæ—¶ä¸éœ€è¦context-knowledge-responseä¸‰è¦ç´ ï¼Œåœ¨é›¶èµ„æºç¯å¢ƒä¸‹æ¢ç´¢è¿™ä¸ªé—®é¢˜ã€‚</p><p>è´¡çŒ®ï¼š</p><ul><li>åœ¨é›¶èµ„æºç¯å¢ƒä¸‹æ¢ç´¢ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ç”Ÿæˆï¼›</li><li>æå‡ºäº†ä¸€ä¸ªdouble latent variable modelï¼Œä¸ä»…æè¿°äº†è¿æ¥contextå’Œresponseçš„çŸ¥è¯†ï¼Œè¿˜æè¿°äº†çŸ¥è¯†çš„è¡¨è¾¾æ–¹å¼ï¼›</li><li>æå‡ºäº†ä¸€ä¸ªvariationalå­¦ä¹ æ–¹æ³•ï¼›</li><li>åœ¨çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ç”Ÿæˆçš„ä¸‰ä¸ªåŸºå‡†ä¸Šå¯¹æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§è¿›è¡Œäº†ç»éªŒéªŒè¯ã€‚</li></ul><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>æœ¬æ–‡æå‡ºå°†è¿æ¥context å’Œresponseçš„çŸ¥è¯†ä»¥åŠçŸ¥è¯†çš„è¡¨è¾¾æ–¹å¼è¡¨ç°ä¸ºæ½œåœ¨å˜é‡ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§variationalæ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ä»å¯¹è¯è¯­æ–™å’ŒçŸ¥è¯†è¯­æ–™ä¸­ä¼°è®¡å‡ºä¸€ä¸ªç›¸äº’ç‹¬ç«‹çš„ç”Ÿæˆæ¨¡å‹ã€‚</p><p>åœ¨é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹çš„åŸºç¡€ä¸Šå»ºç«‹æ¦‚ç‡æ¨¡å‹ã€‚ä¸ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ï¼Œè€Œæ˜¯å»ºè®®ç”¨ä¸€ä¸ªæ£€ç´¢æ¨¡å‹æ¥å®ä¾‹åŒ–åéªŒï¼Œåœ¨è¿™ä¸ªæ¨¡å‹ä¸­ï¼ŒçŸ¥è¯†çš„æœç´¢ç©ºé—´è¢«é™åˆ¶åœ¨å‡ ä¸ªç›¸å…³çš„å€™é€‰ä¹‹å†…ã€‚</p><p>dialogue corpusï¼š</p><script type="math/tex; mode=display">D_{cov}= \{(C_i, R_i)\}^n_{i=1}</script><blockquote><p>$C_i$æŒ‡çš„æ˜¯dialogue context</p><p>$R_i$æŒ‡çš„æ˜¯response</p></blockquote><p>knowledge baseï¼š</p><script type="math/tex; mode=display">K_{kg}= \{K_j\}^m _{j=1}</script><blockquote><p>$K_j$æŒ‡çš„æ˜¯ä¸€æ®µçŸ¥è¯†ï¼Œä¾‹å¦‚æ•°æ®é›†ä¸­çš„å¥å­ã€‚</p></blockquote><p>æ¨¡å‹ï¼š</p><script type="math/tex; mode=display">p(Râˆ£C, K)</script><p>ä¸å¤–éƒ¨çŸ¥è¯†å…³è”çš„Kå’Œæ–°çš„ä¸Šä¸‹æ–‡Cï¼Œæ ¹æ®$p(Râˆ£C, K)$ç”Ÿæˆå“åº”Rã€‚</p><h2 id="Zero-Resource-Learning-Framework"><a href="#Zero-Resource-Learning-Framework" class="headerlink" title="Zero-Resource Learning Framework"></a>Zero-Resource Learning Framework</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210709120019.png" alt="image-20210709120019816" style="zoom: 67%;" /></p><blockquote><p>dialogue context C</p><p>response R</p><p>latent knowledge $Z_k$</p><p>grounding rate $Z_Î±$ï¼Œè¡¨ç¤ºæ ¹æ®Cå…³äºRåœ¨$Z_k$ä¸­æºå¸¦äº†å¤šå°‘çŸ¥è¯†ã€‚</p></blockquote><h2 id="Neural-Parameterization"><a href="#Neural-Parameterization" class="headerlink" title="Neural Parameterization"></a>Neural Parameterization</h2><p>define $q(Z_k)$ with a retrieval modelï¼š</p><script type="math/tex; mode=display">q(Z_kâˆ£C, R) = \frac{exp^{F(C,R,Z_k)} }{âˆ‘_{Kâ€²âˆˆS(R)}exp^{F(C,R,K')}}</script><blockquote><p>S(R)è¡¨ç¤ºå¯¹æ½œåœ¨çŸ¥è¯†çš„æ¨æ–­ï¼Œè¯¥çŸ¥è¯†ç”±ç›¸å…³æ€§æ¨¡å‹rel(â‹…, â‹…)ä»$K_{kg}$ä¸­é€šè¿‡RæŸ¥è¯¢æ£€ç´¢åˆ°çš„å‰lä¸ªç»“æœç»„æˆã€‚</p><p>$Fï¼ˆâ‹…,â‹…,â‹…ï¼‰$æ˜¯ä¸€ä¸ªä¸‰å±‚transformerï¼Œå°†ï¼ˆc,r,$z_k$ï¼‰æ˜ å°„åˆ°åŒ¹é…åˆ†æ•°ã€‚</p></blockquote><p>ä¼˜åŒ–ç®—æ³•ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210709220311.png" alt="image-20210709220311538"></p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>Wizard</li><li>TC</li><li>CMU_DoG</li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p>æµ‹è¯•ç»“æœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210710000506.png" alt="image-20210710000506505"></p><p>F1:è™½ç„¶ZRKGCåœ¨åŸºå‡†ä¸­æ²¡æœ‰è·å–ä»»ä½•è®­ç»ƒå®ä¾‹ï¼Œä½†å®ƒä»ç„¶ä¼˜äºMTASK-RFã€TMNå’ŒITDDï¼Œå¹¶åœ¨æ‰€æœ‰æµ‹è¯•é›†ä¸Šå–å¾—äº†ä¸DRDç›¸å½“çš„æ€§èƒ½ï¼Œè¡¨æ˜è¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ å¦‚ä½•é€šè¿‡variationalæ–¹æ³•åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æ¥ç”Ÿæˆå“åº”ã€‚</p><p>ZRKGCåœ¨Test Seenå’ŒTest Unseenä¸Šå‡ ä¹æ²¡æœ‰å·®å¼‚ï¼Œè¯¥æ¨¡å‹ä¸å—ç‰¹å®šè®­ç»ƒæ•°æ®çš„å½±å“ï¼Œå› æ­¤åœ¨ä¸åŒä¸»é¢˜ä¸Šè¡¨ç°ç¨³å®šï¼Œè¿™æ­ç¤ºäº†è¯¥æ¨¡å‹è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›æ˜¯é›¶èµ„æºæ–¹æ³•çš„ä¼˜åŠ¿ã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>å¯¹ä¸‰ä¸ªä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯ç”ŸæˆåŸºå‡†çš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ¨¡å‹å¯ä»¥è¾¾åˆ°ä¸ä¾é ä»¥çŸ¥è¯†ä¸ºåŸºç¡€çš„å¯¹è¯è¿›è¡Œè®­ç»ƒçš„å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶åœ¨ä¸åŒçš„ä¸»é¢˜å’Œä¸åŒçš„æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ZRKGC </tag>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç”¨æ³¨æ„åŠ›æœºåˆ¶å®ç°ä¸­è‹±æ–‡äº’è¯‘</title>
      <link href="/2021/07/07/%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E4%B8%AD%E8%8B%B1%E6%96%87%E4%BA%92%E8%AF%91/"/>
      <url>/2021/07/07/%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E4%B8%AD%E8%8B%B1%E6%96%87%E4%BA%92%E8%AF%91/</url>
      
        <content type="html"><![CDATA[<h3>ç”¨æ³¨æ„åŠ›æœºåˆ¶å®ç°ä¸­è‹±æ–‡äº’è¯‘</h3><p>[KEY: &gt; input, = target, &lt; output]</p><blockquote><p>il est en train de peindre un tableau .<br>= he is painting a picture .<br>&lt; he is painting a picture .</p><p>pourquoi ne pas essayer ce vin delicieux ?<br>= why not try that delicious wine ?<br>&lt; why not try that delicious wine ?</p><p>elle n est pas poete mais romanciere .<br>= she is not a poet but a novelist .<br>&lt; she not not a poet but a novelist .</p><h3>å¯¼å…¥éœ€è¦çš„æ¨¡å—åŠæ•°æ®</h3></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">import</span> unicodedata</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.font_manager <span class="keyword">as</span> fm</span><br><span class="line">myfont = fm.FontProperties(fname=<span class="string">&#x27;/Users/maqi/opt/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf&#x27;</span>)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure><h3>é¢„å¤„ç†æ•°æ®</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">SOS_token = <span class="number">0</span></span><br><span class="line">EOS_token = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lang</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name</span>):</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.word2index = &#123;&#125;</span><br><span class="line">        self.word2count = &#123;&#125;</span><br><span class="line">        self.index2word = &#123;<span class="number">0</span>: <span class="string">&quot;SOS&quot;</span>, <span class="number">1</span>: <span class="string">&quot;EOS&quot;</span>&#125;</span><br><span class="line">        self.n_words = <span class="number">2</span>  <span class="comment"># Count SOS and EOS</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addSentence</span>(<span class="params">self, sentence</span>):</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> sentence.split(<span class="string">&#x27; &#x27;</span>):</span><br><span class="line">            self.addWord(word)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addSentence_cn</span>(<span class="params">self, sentence</span>):</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> <span class="built_in">list</span>(jieba.cut(sentence)):</span><br><span class="line">            self.addWord(word)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addWord</span>(<span class="params">self, word</span>):</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.word2index:</span><br><span class="line">            self.word2index[word] = self.n_words</span><br><span class="line">            self.word2count[word] = <span class="number">1</span></span><br><span class="line">            self.index2word[self.n_words] = word</span><br><span class="line">            self.n_words += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.word2count[word] += <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¸ºä¾¿äºæ•°æ®å¤„ç†ï¼ŒæŠŠUnicodeå­—ç¬¦ä¸²è½¬æ¢ä¸ºASCIIç¼–ç </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unicodeToAscii</span>(<span class="params">s</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(</span><br><span class="line">        c <span class="keyword">for</span> c <span class="keyword">in</span> unicodedata.normalize(<span class="string">&#x27;NFD&#x27;</span>, s)</span><br><span class="line">        <span class="keyword">if</span> unicodedata.category(c) != <span class="string">&#x27;Mn&#x27;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯¹è‹±æ–‡è½¬æ¢ä¸ºå°å†™ï¼Œå»ç©ºæ ¼åŠéå­—æ¯ç¬¦å·ç­‰å¤„ç†</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalizeString</span>(<span class="params">s</span>):</span></span><br><span class="line">    s = unicodeToAscii(s.lower().strip())</span><br><span class="line">    s = re.sub(<span class="string">r&quot;([.!?])&quot;</span>, <span class="string">r&quot; \1&quot;</span>, s)</span><br><span class="line">    <span class="comment">#s = re.sub(r&quot;[^a-zA-Z.!?]+&quot;, r&quot; &quot;, s)</span></span><br><span class="line">    <span class="keyword">return</span> s</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readLangs</span>(<span class="params">lang1, lang2, reverse=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Reading lines...&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è¯»æ–‡ä»¶ï¼Œç„¶ååˆ†æˆè¡Œ</span></span><br><span class="line">    lines = <span class="built_in">open</span>(<span class="string">&#x27;eng-cmn/%s-%s.txt&#x27;</span> % (lang1, lang2), encoding=<span class="string">&#x27;utf-8&#x27;</span>).\</span><br><span class="line">        read().strip().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># æŠŠè¡Œåˆ†æˆè¯­å¥å¯¹ï¼Œå¹¶è¿›è¡Œè§„èŒƒåŒ–</span></span><br><span class="line">    pairs = [[normalizeString(s) <span class="keyword">for</span> s <span class="keyword">in</span> l.split(<span class="string">&#x27;\t&#x27;</span>)] <span class="keyword">for</span> l <span class="keyword">in</span> lines]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># åˆ¤æ–­æ˜¯å¦éœ€è¦è½¬æ¢è¯­å¥å¯¹çš„æ¬¡åºï¼Œå¦‚[è‹±æ–‡ï¼Œä¸­æ–‡]è½¬æ¢ä¸º[ä¸­æ–‡ï¼Œè‹±æ–‡]æ¬¡åº</span></span><br><span class="line">    <span class="keyword">if</span> reverse:</span><br><span class="line">        pairs = [<span class="built_in">list</span>(<span class="built_in">reversed</span>(p)) <span class="keyword">for</span> p <span class="keyword">in</span> pairs]</span><br><span class="line">        input_lang = Lang(lang2)</span><br><span class="line">        output_lang = Lang(lang1)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        input_lang = Lang(lang1)</span><br><span class="line">        output_lang = Lang(lang2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> input_lang, output_lang, pairs</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ä¸ºä¾¿äºè®­ç»ƒï¼Œè¿™é‡Œé€‰æ‹©éƒ¨åˆ†æ•°æ®</span></span><br><span class="line">MAX_LENGTH = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">eng_prefixes = (</span><br><span class="line">    <span class="string">&quot;i am &quot;</span>, <span class="string">&quot;i m &quot;</span>,</span><br><span class="line">    <span class="string">&quot;he is&quot;</span>, <span class="string">&quot;he s &quot;</span>,</span><br><span class="line">    <span class="string">&quot;she is&quot;</span>, <span class="string">&quot;she s &quot;</span>,</span><br><span class="line">    <span class="string">&quot;you are&quot;</span>, <span class="string">&quot;you re &quot;</span>,</span><br><span class="line">    <span class="string">&quot;we are&quot;</span>, <span class="string">&quot;we re &quot;</span>,</span><br><span class="line">    <span class="string">&quot;they are&quot;</span>, <span class="string">&quot;they re &quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filterPair</span>(<span class="params">p</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(p[<span class="number">0</span>].split(<span class="string">&#x27; &#x27;</span>)) &lt; MAX_LENGTH <span class="keyword">and</span> \</span><br><span class="line">        <span class="built_in">len</span>(p[<span class="number">1</span>].split(<span class="string">&#x27; &#x27;</span>)) &lt; MAX_LENGTH <span class="keyword">and</span> \</span><br><span class="line">        p[<span class="number">1</span>].startswith(eng_prefixes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filterPairs</span>(<span class="params">pairs</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [pair <span class="keyword">for</span> pair <span class="keyword">in</span> pairs <span class="keyword">if</span> filterPair(pair)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepareData</span>(<span class="params">lang1, lang2, reverse=<span class="literal">False</span></span>):</span></span><br><span class="line">    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Read %s sentence pairs&quot;</span> % <span class="built_in">len</span>(pairs))</span><br><span class="line">    pairs = filterPairs(pairs)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Trimmed to %s sentence pairs&quot;</span> % <span class="built_in">len</span>(pairs))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Counting words...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> pair <span class="keyword">in</span> pairs:</span><br><span class="line">        input_lang.addSentence_cn(pair[<span class="number">0</span>])</span><br><span class="line">        output_lang.addSentence(pair[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Counted words:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(input_lang.name, input_lang.n_words)</span><br><span class="line">    <span class="built_in">print</span>(output_lang.name, output_lang.n_words)</span><br><span class="line">    <span class="keyword">return</span> input_lang, output_lang, pairs</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input_lang, output_lang, pairs = prepareData(<span class="string">&#x27;eng&#x27;</span>, <span class="string">&#x27;cmn&#x27;</span>,<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(random.choice(pairs))</span><br></pre></td></tr></table></figure><pre><code>Reading lines...Building prefix dict from the default dictionary ...Loading model from cache /var/folders/7t/wvjcfn5575g892qb2nqbd9kw0000gn/T/jieba.cacheRead 21007 sentence pairsTrimmed to 640 sentence pairsCounting words...Loading model cost 0.571 seconds.Prefix dict has been built succesfully.Counted words:cmn 1063eng 808[&#39;ä»–å¾ˆç©·ã€‚&#39;, &#39;he is poor .&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pairs[:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><pre><code>[[&#39;æˆ‘å†·ã€‚&#39;, &#39;i am cold .&#39;], [&#39;æˆ‘æ²’äº‹ã€‚&#39;, &#39;i am okay .&#39;], [&#39;æˆ‘ç”Ÿç—…äº†ã€‚&#39;, &#39;i am sick .&#39;]]</code></pre><h3>æ„å»ºæ¨¡å‹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderRNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, hidden_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(EncoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(input_size, hidden_size)</span><br><span class="line">        self.gru = nn.GRU(hidden_size, hidden_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden</span>):</span></span><br><span class="line">        embedded = self.embedding(<span class="built_in">input</span>).view(<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        output = embedded</span><br><span class="line">        output, hidden = self.gru(output, hidden)</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.hidden_size, device=device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderRNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, hidden_size, output_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DecoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(output_size, hidden_size)</span><br><span class="line">        self.gru = nn.GRU(hidden_size, hidden_size)</span><br><span class="line">        self.out = nn.Linear(hidden_size, output_size)</span><br><span class="line">        self.softmax = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden</span>):</span></span><br><span class="line">        output = self.embedding(<span class="built_in">input</span>).view(<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        output = F.relu(output)</span><br><span class="line">        output, hidden = self.gru(output, hidden)</span><br><span class="line">        output = self.softmax(self.out(output[<span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.hidden_size, device=device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AttnDecoderRNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, hidden_size, output_size, dropout_p=<span class="number">0.1</span>, max_length=MAX_LENGTH</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(AttnDecoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.output_size = output_size</span><br><span class="line">        self.dropout_p = dropout_p</span><br><span class="line">        self.max_length = max_length</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(self.output_size, self.hidden_size)</span><br><span class="line">        self.attn = nn.Linear(self.hidden_size * <span class="number">2</span>, self.max_length)</span><br><span class="line">        self.attn_combine = nn.Linear(self.hidden_size * <span class="number">2</span>, self.hidden_size)</span><br><span class="line">        self.dropout = nn.Dropout(self.dropout_p)</span><br><span class="line">        self.gru = nn.GRU(self.hidden_size, self.hidden_size)</span><br><span class="line">        self.out = nn.Linear(self.hidden_size, self.output_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden, encoder_outputs</span>):</span></span><br><span class="line">        embedded = self.embedding(<span class="built_in">input</span>).view(<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        embedded = self.dropout(embedded)</span><br><span class="line"></span><br><span class="line">        attn_weights = F.softmax(</span><br><span class="line">            self.attn(torch.cat((embedded[<span class="number">0</span>], hidden[<span class="number">0</span>]), <span class="number">1</span>)), dim=<span class="number">1</span>)</span><br><span class="line">        attn_applied = torch.bmm(attn_weights.unsqueeze(<span class="number">0</span>),</span><br><span class="line">                                 encoder_outputs.unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        output = torch.cat((embedded[<span class="number">0</span>], attn_applied[<span class="number">0</span>]), <span class="number">1</span>)</span><br><span class="line">        output = self.attn_combine(output).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        output = F.relu(output)</span><br><span class="line">        output, hidden = self.gru(output, hidden)</span><br><span class="line"></span><br><span class="line">        output = F.log_softmax(self.out(output[<span class="number">0</span>]), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output, hidden, attn_weights</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.hidden_size, device=device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">indexesFromSentence</span>(<span class="params">lang, sentence</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [lang.word2index[word] <span class="keyword">for</span> word <span class="keyword">in</span> sentence.split(<span class="string">&#x27; &#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">indexesFromSentence_cn</span>(<span class="params">lang, sentence</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [lang.word2index[word] <span class="keyword">for</span> word <span class="keyword">in</span> <span class="built_in">list</span>(jieba.cut(sentence))]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensorFromSentence</span>(<span class="params">lang, sentence</span>):</span></span><br><span class="line">    indexes = indexesFromSentence(lang, sentence)</span><br><span class="line">    indexes.append(EOS_token)</span><br><span class="line">    <span class="keyword">return</span> torch.tensor(indexes, dtype=torch.long, device=device).view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensorFromSentence_cn</span>(<span class="params">lang, sentence</span>):</span></span><br><span class="line">    indexes = indexesFromSentence_cn(lang, sentence)</span><br><span class="line">    indexes.append(EOS_token)</span><br><span class="line">    <span class="keyword">return</span> torch.tensor(indexes, dtype=torch.long, device=device).view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensorsFromPair</span>(<span class="params">pair</span>):</span></span><br><span class="line">    input_tensor = tensorFromSentence_cn(input_lang, pair[<span class="number">0</span>])</span><br><span class="line">    target_tensor = tensorFromSentence(output_lang, pair[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> (input_tensor, target_tensor)</span><br></pre></td></tr></table></figure><h3>è®­ç»ƒæ¨¡å‹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">teacher_forcing_ratio = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH</span>):</span></span><br><span class="line">    encoder_hidden = encoder.initHidden()</span><br><span class="line"></span><br><span class="line">    encoder_optimizer.zero_grad()</span><br><span class="line">    decoder_optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    input_length = input_tensor.size(<span class="number">0</span>)</span><br><span class="line">    target_length = target_tensor.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ei <span class="keyword">in</span> <span class="built_in">range</span>(input_length):</span><br><span class="line">        encoder_output, encoder_hidden = encoder(</span><br><span class="line">            input_tensor[ei], encoder_hidden)</span><br><span class="line">        encoder_outputs[ei] = encoder_output[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    decoder_input = torch.tensor([[SOS_token]], device=device)</span><br><span class="line"></span><br><span class="line">    decoder_hidden = encoder_hidden</span><br><span class="line"></span><br><span class="line">    use_teacher_forcing = <span class="literal">True</span> <span class="keyword">if</span> random.random() &lt; teacher_forcing_ratio <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> use_teacher_forcing:</span><br><span class="line">        <span class="comment"># Teacher forcing: Feed the target as the next input</span></span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> <span class="built_in">range</span>(target_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            loss += criterion(decoder_output, target_tensor[di])</span><br><span class="line">            decoder_input = target_tensor[di]  <span class="comment"># Teacher forcing</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Without teacher forcing: use its own predictions as the next input</span></span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> <span class="built_in">range</span>(target_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            topv, topi = decoder_output.topk(<span class="number">1</span>)</span><br><span class="line">            decoder_input = topi.squeeze().detach()  <span class="comment"># detach from history as input</span></span><br><span class="line"></span><br><span class="line">            loss += criterion(decoder_output, target_tensor[di])</span><br><span class="line">            <span class="keyword">if</span> decoder_input.item() == EOS_token:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    encoder_optimizer.step()</span><br><span class="line">    decoder_optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss.item() / target_length</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">asMinutes</span>(<span class="params">s</span>):</span></span><br><span class="line">    m = math.floor(s / <span class="number">60</span>)</span><br><span class="line">    s -= m * <span class="number">60</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;%dm %ds&#x27;</span> % (m, s)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timeSince</span>(<span class="params">since, percent</span>):</span></span><br><span class="line">    now = time.time()</span><br><span class="line">    s = now - since</span><br><span class="line">    es = s / (percent)</span><br><span class="line">    rs = es - s</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;%s (- %s)&#x27;</span> % (asMinutes(s), asMinutes(rs))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainIters</span>(<span class="params">encoder, decoder, n_iters, print_every=<span class="number">1000</span>, plot_every=<span class="number">100</span>, learning_rate=<span class="number">0.01</span></span>):</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    plot_losses = []</span><br><span class="line">    print_loss_total = <span class="number">0</span>  </span><br><span class="line">    plot_loss_total = <span class="number">0</span> </span><br><span class="line"></span><br><span class="line">    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)</span><br><span class="line">    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)</span><br><span class="line">    training_pairs = [tensorsFromPair(random.choice(pairs))</span><br><span class="line">                      <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_iters)]</span><br><span class="line">    criterion = nn.NLLLoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_iters + <span class="number">1</span>):</span><br><span class="line">        training_pair = training_pairs[<span class="built_in">iter</span> - <span class="number">1</span>]</span><br><span class="line">        input_tensor = training_pair[<span class="number">0</span>]</span><br><span class="line">        target_tensor = training_pair[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        loss = train(input_tensor, target_tensor, encoder,</span><br><span class="line">                     decoder, encoder_optimizer, decoder_optimizer, criterion)</span><br><span class="line">        print_loss_total += loss</span><br><span class="line">        plot_loss_total += loss</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">iter</span> % print_every == <span class="number">0</span>:</span><br><span class="line">            print_loss_avg = print_loss_total / print_every</span><br><span class="line">            print_loss_total = <span class="number">0</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;%s (%d %d%%) %.4f&#x27;</span> % (timeSince(start, <span class="built_in">iter</span> / n_iters),</span><br><span class="line">                                         <span class="built_in">iter</span>, <span class="built_in">iter</span> / n_iters * <span class="number">100</span>, print_loss_avg))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">iter</span> % plot_every == <span class="number">0</span>:</span><br><span class="line">            plot_loss_avg = plot_loss_total / plot_every</span><br><span class="line">            plot_losses.append(plot_loss_avg)</span><br><span class="line">            plot_loss_total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    showPlot(plot_losses)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#plt.switch_backend(&#x27;agg&#x27;)</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> ticker</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showPlot</span>(<span class="params">points</span>):</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    <span class="comment"># this locator puts ticks at regular intervals</span></span><br><span class="line">    loc = ticker.MultipleLocator(base=<span class="number">0.2</span>)</span><br><span class="line">    ax.yaxis.set_major_locator(loc)</span><br><span class="line">    plt.plot(points)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">encoder, decoder, sentence, max_length=MAX_LENGTH</span>):</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        input_tensor = tensorFromSentence_cn(input_lang, sentence)</span><br><span class="line">        input_length = input_tensor.size()[<span class="number">0</span>]</span><br><span class="line">        encoder_hidden = encoder.initHidden()</span><br><span class="line"></span><br><span class="line">        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> ei <span class="keyword">in</span> <span class="built_in">range</span>(input_length):</span><br><span class="line">            encoder_output, encoder_hidden = encoder(input_tensor[ei],</span><br><span class="line">                                                     encoder_hidden)</span><br><span class="line">            encoder_outputs[ei] += encoder_output[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        decoder_input = torch.tensor([[SOS_token]], device=device)  <span class="comment"># SOS</span></span><br><span class="line"></span><br><span class="line">        decoder_hidden = encoder_hidden</span><br><span class="line"></span><br><span class="line">        decoded_words = []</span><br><span class="line">        decoder_attentions = torch.zeros(max_length, max_length)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> <span class="built_in">range</span>(max_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            decoder_attentions[di] = decoder_attention.data</span><br><span class="line">            topv, topi = decoder_output.data.topk(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> topi.item() == EOS_token:</span><br><span class="line">                decoded_words.append(<span class="string">&#x27;&lt;EOS&gt;&#x27;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                decoded_words.append(output_lang.index2word[topi.item()])</span><br><span class="line"></span><br><span class="line">            decoder_input = topi.squeeze().detach()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> decoded_words, decoder_attentions[:di + <span class="number">1</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateRandomly</span>(<span class="params">encoder, decoder, n=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        pair = random.choice(pairs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&gt;&#x27;</span>, pair[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>, pair[<span class="number">1</span>])</span><br><span class="line">        output_words, attentions = evaluate(encoder, decoder, pair[<span class="number">0</span>])</span><br><span class="line">        output_sentence = <span class="string">&#x27; &#x27;</span>.join(output_words)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&lt;&#x27;</span>, output_sentence)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hidden_size = <span class="number">256</span></span><br><span class="line">encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)</span><br><span class="line">attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=<span class="number">0.1</span>).to(device)</span><br><span class="line"></span><br><span class="line">trainIters(encoder1, attn_decoder1, <span class="number">75000</span>, print_every=<span class="number">5000</span>)</span><br></pre></td></tr></table></figure><pre><code>1m 54s (- 26m 36s) (5000 6%) 2.63943m 43s (- 24m 10s) (10000 13%) 1.09165m 34s (- 22m 19s) (15000 20%) 0.20577m 29s (- 20m 36s) (20000 26%) 0.04459m 27s (- 18m 54s) (25000 33%) 0.025311m 25s (- 17m 7s) (30000 40%) 0.020213m 20s (- 15m 14s) (35000 46%) 0.017515m 17s (- 13m 23s) (40000 53%) 0.016717m 15s (- 11m 30s) (45000 60%) 0.014119m 13s (- 9m 36s) (50000 66%) 0.013721m 12s (- 7m 42s) (55000 73%) 0.011023m 12s (- 5m 48s) (60000 80%) 0.011625m 12s (- 3m 52s) (65000 86%) 0.012527m 11s (- 1m 56s) (70000 93%) 0.009129m 11s (- 0m 0s) (75000 100%) 0.0095&lt;Figure size 432x288 with 0 Axes&gt;</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210707193941.png" alt="png"></p><h3>éšæœºé‡‡æ ·ï¼Œå¯¹æ¨¡å‹è¿›è¡Œæµ‹è¯•</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">evaluateRandomly(encoder1, attn_decoder1)</span><br></pre></td></tr></table></figure><pre><code>&gt; ä»Šå¤©ä¸‹åˆæˆ‘æœƒå¤–å‡ºã€‚= i am going out this afternoon .&lt; i am going out this afternoon . &lt;EOS&gt;&gt; æˆ‘ç›¸ä¿¡ä»–æ˜¯ç„¡è¾œçš„ã€‚= i am convinced that he is innocent .&lt; i am convinced that he is innocent . &lt;EOS&gt;&gt; ä»–åœ¨è‡ªå·±æˆ¿é‡Œç©ã€‚= he is playing in his room .&lt; he is playing in his room . &lt;EOS&gt;&gt; æˆ‘ä¾†è‡ªå››åœ‹ã€‚= i am from shikoku .&lt; i am from shikoku . &lt;EOS&gt;&gt; å¥¹æˆ´è‘—ä¸€é ‚å¸½å­ã€‚= she is wearing a hat .&lt; she is wearing a hat . &lt;EOS&gt;&gt; æ‚¨éå¸¸å‹‡æ•¢ã€‚= you are very courageous .&lt; you are very brave . &lt;EOS&gt;&gt; ä»–æœ‰å‡ åˆ†åƒå­¦è€…ã€‚= he is something of a scholar .&lt; he is something of a scholar . &lt;EOS&gt;&gt; ä½ çœŸå‚»ã€‚= you are so stupid .&lt; you are so stupid . &lt;EOS&gt;&gt; ä»–å¹´ç´€å¤ å¤§å¯ä»¥ç­è§£å®ƒã€‚= he is old enough to understand it .&lt; he is old enough to understand it . &lt;EOS&gt;&gt; ä½ åˆ¥å°çœ‹äº†ä»–ã€‚= you are selling him short .&lt; you are selling him short . &lt;EOS&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_randomly</span>():</span></span><br><span class="line">    pair = random.choice(pairs)</span><br><span class="line">    </span><br><span class="line">    output_words, decoder_attn = evaluate(pair[<span class="number">0</span>])</span><br><span class="line">    output_sentence = <span class="string">&#x27; &#x27;</span>.join(output_words)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&gt;&#x27;</span>, pair[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>, pair[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&lt;&#x27;</span>, output_sentence)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateRandomly</span>(<span class="params">encoder, decoder, n=<span class="number">20</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        pair = random.choice(pairs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&gt;&#x27;</span>, pair[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>, pair[<span class="number">1</span>])</span><br><span class="line">        output_words, attentions = evaluate(encoder, decoder, pair[<span class="number">0</span>])</span><br><span class="line">        output_sentence = <span class="string">&#x27; &#x27;</span>.join(output_words)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&lt;&#x27;</span>, output_sentence)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><h3>å¯è§†åŒ–æ³¨æ„åŠ›</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showAttention</span>(<span class="params">input_sentence, output_words, attentions</span>):</span></span><br><span class="line">    <span class="comment"># Set up figure with colorbar</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    cax = ax.matshow(attentions.numpy(), cmap=<span class="string">&#x27;bone&#x27;</span>)</span><br><span class="line">    fig.colorbar(cax)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set up axes</span></span><br><span class="line">    ax.set_xticklabels([<span class="string">&#x27;&#x27;</span>] + <span class="built_in">list</span>(jieba.cut(input_sentence)) +</span><br><span class="line">                       [<span class="string">&#x27;&lt;EOS&gt;&#x27;</span>], rotation=<span class="number">90</span>,fontproperties=myfont)</span><br><span class="line">    ax.set_yticklabels([<span class="string">&#x27;&#x27;</span>] + output_words)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Show label at every tick</span></span><br><span class="line">    ax.xaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line">    ax.yaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateAndShowAttention</span>(<span class="params">input_sentence</span>):</span></span><br><span class="line">    output_words, attentions = evaluate(</span><br><span class="line">        encoder1, attn_decoder1, input_sentence)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;input =&#x27;</span>, input_sentence)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;output =&#x27;</span>, <span class="string">&#x27; &#x27;</span>.join(output_words))</span><br><span class="line">    showAttention(input_sentence, output_words, attentions)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">evaluateAndShowAttention(<span class="string">&quot;æˆ‘å¾ˆå¹¸ç¦ã€‚&quot;</span>)</span><br><span class="line"></span><br><span class="line">evaluateAndShowAttention(<span class="string">&quot;æˆ‘ä»¬åœ¨ä¸¥è‚ƒåœ°è°ˆè®ºä½ çš„æœªæ¥ã€‚&quot;</span>)</span><br><span class="line"></span><br><span class="line">evaluateAndShowAttention(<span class="string">&quot;æˆ‘åœ¨å®¶ã€‚&quot;</span>)</span><br><span class="line"></span><br><span class="line">evaluateAndShowAttention(<span class="string">&quot;æˆ‘ä»¬åœ¨ä¸¥è‚ƒåœ°è°ˆè®ºä½ çš„æœªæ¥ã€‚&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>input = æˆ‘å¾ˆå¹¸ç¦ã€‚output = i am very happy . &lt;EOS&gt;&lt;ipython-input-23-2d6791f485ef&gt;:9: UserWarning: FixedFormatter should only be used together with FixedLocator  ax.set_xticklabels([&#39;&#39;] + list(jieba.cut(input_sentence)) +&lt;ipython-input-23-2d6791f485ef&gt;:11: UserWarning: FixedFormatter should only be used together with FixedLocator  ax.set_yticklabels([&#39;&#39;] + output_words)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 25105 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24456 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24184 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 31119 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 12290 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 25105 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24456 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24184 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 31119 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 12290 missing from current font.  font.set_text(s, 0, flags=flags)</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210707193959.png" alt="png"></p><pre><code>input = æˆ‘ä»¬åœ¨ä¸¥è‚ƒåœ°è°ˆè®ºä½ çš„æœªæ¥ã€‚output = we are having a serious talk about your future . &lt;EOS&gt;/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20204 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 22312 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20005 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 32899 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 22320 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 35848 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 35770 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20320 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 30340 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 26410 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 26469 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20204 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 22312 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20005 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 32899 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 22320 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 35848 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 35770 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20320 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 30340 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 26410 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 26469 missing from current font.  font.set_text(s, 0, flags=flags)</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210707194006.png" alt="png"></p><pre><code>input = æˆ‘åœ¨å®¶ã€‚output = i am at home . &lt;EOS&gt;/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 23478 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 23478 missing from current font.  font.set_text(s, 0, flags=flags)</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210707194008.png" alt="png"></p><pre><code>input = æˆ‘ä»¬åœ¨ä¸¥è‚ƒåœ°è°ˆè®ºä½ çš„æœªæ¥ã€‚output = we are having a serious talk about your future . &lt;EOS&gt;</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210707194010.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-paragraph Reading Comprehension with Token-level Dynamic Reader and Hybrid Verifier</title>
      <link href="/2021/07/06/IJCNN2019-MRC-%E5%A4%9A%E6%8C%87%E9%92%88%E5%8F%82%E8%80%83/"/>
      <url>/2021/07/06/IJCNN2019-MRC-%E5%A4%9A%E6%8C%87%E9%92%88%E5%8F%82%E8%80%83/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-paragraph-Reading-Comprehension-with-Token-level-Dynamic-Reader-and-Hybrid-Verifier"><a href="#Multi-paragraph-Reading-Comprehension-with-Token-level-Dynamic-Reader-and-Hybrid-Verifier" class="headerlink" title="Multi-paragraph Reading Comprehension with Token-level Dynamic Reader and Hybrid Verifier"></a>Multi-paragraph Reading Comprehension with Token-level Dynamic Reader and Hybrid Verifier</h1><blockquote><p> è®ºæ–‡ï¼š<a href="http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/IEEE_WCCI_2020/IJCNN/Papers/N-20242.pdf">http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/IEEE_WCCI_2020/IJCNN/Papers/N-20242.pdf</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>å¤šæ®µå¼é˜…è¯»ç†è§£è¦æ±‚æ¨¡å‹é€šè¿‡æ¨ç†è·¨æ®µè½ä¿¡æ¯æ¥æ¨æ–­ä»»æ„ç”¨æˆ·ç”Ÿæˆçš„é—®é¢˜çš„ç­”æ¡ˆã€‚ä»¥å‰çš„å·¥ä½œé€šå¸¸é€šè¿‡ç›´æ¥é‡‡ç”¨æŒ‡é’ˆç½‘ç»œé¢„æµ‹ç­”æ¡ˆçš„å¼€å§‹å’Œç»“æŸä½ç½®æ¥ç”Ÿæˆç­”æ¡ˆã€‚ç„¶è€Œï¼Œå¯¹äºè·¨åº¦çº§åˆ«çš„é˜…è¯»ç†è§£æ˜¯ä¸å¤Ÿçš„ï¼Œå› ä¸ºä¸­é—´çš„è¯å¯èƒ½æ›´é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ç½‘ç»œï¼ŒåŒ…æ‹¬ä¸€ä¸ªé€‰æ‹©å™¨ï¼Œä¸€ä¸ªtokençº§åŠ¨æ€é˜…è¯»å™¨ï¼Œå’Œä¸€ä¸ªæ··åˆéªŒè¯å™¨ï¼ˆTH-Netï¼‰ã€‚æœ¬æ–‡ä¾§é‡äºè§£å†³æ–‡æ¡£çº§æ•°æ®è€Œä¸æ˜¯å•æ®µæ•°æ®çš„æŒ‘æˆ˜ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>æå‡ºäº†tokençº§åŠ¨æ€é˜…è¯»å™¨å’Œæ··åˆéªŒè¯å™¨ï¼Œä»¥é¿å…è¾¹ç•Œå’Œå†…å®¹çš„ç›¸ä¼¼æ€§ã€‚</p><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210704190423.png" alt="image-20210704190423456" style="zoom: 67%;" /></p><ul><li>é‡‡ç”¨ç»Ÿä¸€çš„æ–¹æ³•ï¼ˆUnified approachï¼‰ï¼Œé€šè¿‡å…±äº«ç›¸åŒçš„ä¸Šä¸‹æ–‡åµŒå…¥æ¥æé«˜ä¸‰ä¸ªç»„ä»¶çš„æ•´ä½“æ€§èƒ½ã€‚è¿™ä¸‰ä¸ªéƒ¨åˆ†ç”±é¢„è®­ç»ƒçš„LMåˆå§‹åŒ–ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒæ—¶è¿›è¡Œä¼˜åŒ–ã€‚</li><li>å¼•å…¥äº†tokençº§åŠ¨æ€é˜…è¯»å™¨ï¼Œé€šè¿‡è¾¹ç•Œå’Œä¸­é—´æ ‡è®°æ¥å†³å®šå€™é€‰ç­”æ¡ˆçš„åˆ†æ•°ã€‚è¿™ç§ç­–ç•¥åœ¨æ®µè½é˜…è¯»ä¸­è¢«è¯æ˜æ˜¯éå¸¸æœ‰æ•ˆçš„ï¼Œå› ä¸ºå®ƒå¯ä»¥æ›´å¥½åœ°è§£å†³è·¨åº¦çº§é˜…è¯»å™¨é€‰æ‹©çš„ç­”æ¡ˆä»£è¡¨æ€§ä¸è¶³çš„é—®é¢˜ã€‚</li><li>åœ¨ç­”æ¡ˆéªŒè¯ä¸­ï¼Œé‡‡ç”¨äº†ä¸€ä¸ªæ··åˆç½‘ç»œï¼Œå°†å€™é€‰ç­”æ¡ˆä¹‹é—´çš„ç›¸å…³è¯­ä¹‰å…³ç³»ä¸é—®é¢˜å’Œç­”æ¡ˆä¹‹é—´çš„å¿…ç„¶å…³ç³»ç»“åˆèµ·æ¥ã€‚è¿™ç§æœºåˆ¶ä¹Ÿæé«˜äº†éªŒè¯å™¨çš„æ€§èƒ½ã€‚</li></ul><h3 id="Segmentation-and-Encoding"><a href="#Segmentation-and-Encoding" class="headerlink" title="Segmentation and Encoding"></a>Segmentation and Encoding</h3><p>å°†æ‰€æœ‰ä½œä¸ºè¾“å…¥çš„æ®µè½ä¸²è”åä½¿ç”¨æ»‘çª—åˆ†æ®µï¼Œå†è¿›è¡Œç¼–ç ã€‚</p><p>è¾“å…¥åºåˆ—è¡¨ç¤ºï¼š</p><script type="math/tex; mode=display">S_i= [< CLS >, Q, < SEP >, P_i, < SEP >]</script><ul><li>&lt; SEP &gt;æ ‡è®°ç”¨æ¥åˆ†éš”é—®é¢˜å’Œæ®µè½ã€‚</li></ul><p>åºåˆ—$S_i$ä¸­ç¬¬$j^th$ä¸ªtokenè¡¨ç¤ºä¸ºï¼š</p><script type="math/tex; mode=display">h^0_{ij}= s^{tok}_{ij} + s^{pos}_{ij}+ s^{seg}_{ij}</script><ul><li>åˆ†åˆ«è¡¨ç¤ºtoken, position,å’Œsegmentçš„embeddingsã€‚</li><li>positionç›¸åŒçš„tokenå¯ä»¥å…±äº«ç›¸åŒçš„position embeddingã€‚</li><li>åŒä¸€é—®é¢˜æˆ–æ®µè½çš„tokenå¯ä»¥å…±äº«ç›¸åŒçš„segment embeddingã€‚</li></ul><h3 id="Paragraph-Selector"><a href="#Paragraph-Selector" class="headerlink" title="Paragraph Selector"></a>Paragraph Selector</h3><p>ç”±äºè¯»å–å¹¶ä¸ºæ¯ä¸ªæ®µè½ç”Ÿæˆå‡ ä¸ªå€™é€‰ç­”æ¡ˆå¯èƒ½å¯¼è‡´OOMé—®é¢˜ï¼Œå› æ­¤å°†ç¬¬ä¸€ä¸ª$L^{â€˜}$transformer blocksä½œä¸ºParagraph Selectorçš„è¾“å…¥ã€‚</p><h3 id="Token-level-Dynamic-Paragraph-Reader"><a href="#Token-level-Dynamic-Paragraph-Reader" class="headerlink" title="Token-level Dynamic Paragraph Reader"></a>Token-level Dynamic Paragraph Reader</h3><p>è¿™ä¸€å±‚æ—¨åœ¨ç†è§£é€‰æ‹©å™¨ä¸­çš„Sä¸ªæ®µè½ï¼Œå¹¶ä¸ºæ¯ä¸ªæ®µè½è¿”å›Mä¸ªå€™é€‰ç­”æ¡ˆï¼Œåˆ†æ•°æŒ‰tokençº§åˆ«è€Œä¸æ˜¯spançº§åˆ«è®¡ç®—ã€‚</p><p>token-level dynamic network ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210705092003.png" alt="image-20210705092003366" style="zoom: 67%;" /></p><p>token-level dynamic networkå¾—åˆ°ç­”æ¡ˆä¹‹é—´çš„åˆ†æ•°ï¼Œè¡¨æ˜æ¯ä¸ªè¯æ˜¯ç­”æ¡ˆå†…å®¹çš„æ¦‚ç‡ã€‚</p><p>åŠ¨æ€æ˜¯å› ä¸ºå®ƒå¯ä»¥æ ¹æ®è¾¹ç•Œtokenè‡ªåŠ¨é€‰æ‹©é‡è¦çš„tokenã€‚</p><p>é—¨æ§æœºåˆ¶ç”¨äºé€‰æ‹©æœ€é‡è¦çš„Kä¸ªå•è¯ ã€‚</p><h3 id="Hybrid-Answer-Verifier"><a href="#Hybrid-Answer-Verifier" class="headerlink" title="Hybrid Answer Verifier"></a>Hybrid Answer Verifier</h3><p>è¯¥æ¨¡å—é€šè¿‡æ„å»ºä¸¤ä¸ªæ¨¡å‹çš„æ··åˆç½‘ç»œï¼Œå¯ä»¥æœ‰æ•ˆåœ°åœ¨å€™é€‰ç­”æ¡ˆä¸­ä¿®å‰ªå™ªéŸ³ç­”æ¡ˆã€‚</p><p>ç½‘ç»œç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210705094738.png" alt="image-20210705094738594" style="zoom:67%;" /></p><ul><li>æ¨¡å‹Iæ—¨åœ¨æ•æ‰å€™é€‰ç­”æ¡ˆä¹‹é—´çš„è¯­ä¹‰å…³ç³»ã€‚</li><li>æ¨¡å‹IIåˆ™å¯»æ‰¾å€™é€‰ç­”æ¡ˆä¸è¾“å…¥åºåˆ—ä¹‹é—´çš„åŒ…å«å…³ç³»ã€‚</li></ul><h3 id="Joint-Training-and-Prediction"><a href="#Joint-Training-and-Prediction" class="headerlink" title="Joint Training and Prediction"></a>Joint Training and Prediction</h3><p>joint objective functionï¼š</p><script type="math/tex; mode=display">L = L_{PS}+ L_{PR}+ L_{AV}</script><p>åœ¨é¢„æµ‹æœ€ç»ˆç­”æ¡ˆæ—¶ï¼Œé¦–å…ˆè®¡ç®—æ¯ä¸ªè¾“å…¥åºåˆ—çš„selectorå¾—åˆ†ï¼Œå¹¶é€‰æ‹©å‰Sæ®µã€‚ç„¶åï¼Œå¯¹äºæ¯ä¸ªæ®µè½ï¼Œç”ŸæˆMä¸ªå…·æœ‰è¾¹ç•Œåˆ†æ•°å’Œå†…å®¹åˆ†æ•°çš„å€™é€‰ç­”æ¡ˆã€‚å†…å®¹å¾—åˆ†æ˜¯é€šè¿‡ä½¿ç”¨åŠ¨æ€é—¨æœºåˆ¶æ¥è®¡ç®—çš„ï¼Œè¯¥æœºåˆ¶ç‰¹åˆ«è€ƒè™‘äº†ç­”æ¡ˆè·¨åº¦ä¸­çš„é‡è¦è¯æ±‡ã€‚è¿˜é€šè¿‡ä¸€ä¸ªæ··åˆéªŒè¯å™¨å¯¹æœ‰å™ªå£°çš„å€™é€‰ç­”æ¡ˆè¿›è¡Œä¿®å‰ªã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>SQuAD-document</li><li>SQuAD-open</li><li>Trivia-wiki</li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210705103045.png" alt="image-20210705103045073"></p><p>æå‡ºçš„TH-Netæ¨¡å‹åœ¨SQuAD-document å’Œ SQuADopenä¸Šè¡¨ç°å‡ºäº†æœ€ä½³çš„æ€§èƒ½ã€‚</p><p>REQAé‡‡ç”¨äº†ä¸æœ¬æ–‡ç±»ä¼¼çš„ç»Ÿä¸€æ¶æ„ï¼Œä½†æ€§èƒ½ç•¥ä½ï¼Œè¯æ˜token-level dynamic readerå’Œhybrid verifierå¯¹æ€§èƒ½æå‡æœ‰å½±å“ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210705103110.png" alt="image-20210705103110529" style="zoom:67%;" /></p><p>åœ¨Trivia-wikiä¸Šæ¨¡å‹ä¾ç„¶å–å¾—äº†æœ€ä½³çš„æ€§èƒ½ã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>æœ¬æ–‡æå‡ºçš„TH-Netæ—¨åœ¨è§£å†³å¤šæ®µMRCä»»åŠ¡ã€‚æ‰€æå‡ºçš„æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯å¯ä»¥æœ‰æ•ˆåœ°ç†è§£tokençº§çš„æ®µè½ï¼Œå¹¶å°†ç­”æ¡ˆä¹‹é—´çš„è¯­ä¹‰ä¿¡æ¯ä¸ç­”æ¡ˆå’Œè¾“å…¥åºåˆ—ä¹‹é—´çš„å…³ç³»ä¿¡æ¯ç»“åˆèµ·æ¥ã€‚åœ¨ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šéƒ½è¡¨ç°å‡ºä¼˜ç§€çš„æ€§èƒ½ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> TH-Net </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç”¨LSTMé¢„æµ‹è‚¡ç¥¨è¡Œæƒ…</title>
      <link href="/2021/07/06/%E7%94%A8LSTM%E9%A2%84%E6%B5%8B%E8%82%A1%E7%A5%A8%E8%A1%8C%E6%83%85/"/>
      <url>/2021/07/06/%E7%94%A8LSTM%E9%A2%84%E6%B5%8B%E8%82%A1%E7%A5%A8%E8%A1%8C%E6%83%85/</url>
      
        <content type="html"><![CDATA[<p>è¿™é‡Œé‡‡ç”¨æ²ªæ·±300æŒ‡æ•°æ•°æ®ï¼Œæ—¶é—´è·¨åº¦ä¸º2010-10-10è‡³ä»Šï¼Œé€‰æ‹©æ¯å¤©æœ€é«˜ä»·æ ¼ã€‚å‡è®¾å½“å¤©æœ€é«˜ä»·ä¾èµ–å½“å¤©çš„å‰nï¼ˆå¦‚30ï¼‰å¤©çš„æ²ªæ·±300çš„æœ€é«˜ä»·ã€‚ç”¨LSTMæ¨¡å‹æ¥æ•æ‰æœ€é«˜ä»·çš„æ—¶åºä¿¡æ¯ï¼Œé€šè¿‡è®­ç»ƒæ¨¡å‹ï¼Œä½¿ä¹‹å­¦ä¼šç”¨å‰nå¤©çš„æœ€é«˜ä»·ï¼Œåˆ¤æ–­å½“å¤©çš„æœ€é«˜ä»·ï¼ˆä½œä¸ºè®­ç»ƒçš„æ ‡ç­¾å€¼ï¼‰ã€‚</p><h1 id="å¯¼å…¥æ•°æ®"><a href="#å¯¼å…¥æ•°æ®" class="headerlink" title="å¯¼å…¥æ•°æ®"></a>å¯¼å…¥æ•°æ®</h1><p>è¿™é‡Œä½¿ç”¨tushareæ¥ä¸‹è½½æ²ªæ·±300æŒ‡æ•°æ•°æ®ã€‚å¯ä»¥ç”¨pip å®‰è£…tushareã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tushare <span class="keyword">as</span> ts  <span class="comment">#å¯¼å…¥</span></span><br><span class="line">cons = ts.get_apis()   <span class="comment">#å»ºç«‹è¿æ¥</span></span><br><span class="line"><span class="comment">#è·å–æ²ªæ·±æŒ‡æ•°(000300)çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬äº¤æ˜“æ—¥æœŸï¼ˆdatetimeï¼‰ã€å¼€ç›˜ä»·(open)ã€æ”¶ç›˜ä»·(close)ï¼Œ</span></span><br><span class="line"><span class="comment">#æœ€é«˜ä»·(high)ã€æœ€ä½ä»·(low)ã€æˆäº¤é‡(vol)ã€æˆäº¤é‡‘é¢(amount)ã€æ¶¨è·Œå¹…(p_change)</span></span><br><span class="line">df = ts.bar(<span class="string">&#x27;000300&#x27;</span>, conn=cons, asset=<span class="string">&#x27;INDEX&#x27;</span>, start_date=<span class="string">&#x27;2010-01-01&#x27;</span>, end_date=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="comment">#åˆ é™¤æœ‰nullå€¼çš„è¡Œ</span></span><br><span class="line">df = df.dropna()</span><br><span class="line"><span class="comment">#æŠŠdfä¿å­˜åˆ°å½“å‰ç›®å½•ä¸‹çš„sh300.csvæ–‡ä»¶ä¸­ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨</span></span><br><span class="line">df.to_csv(<span class="string">&#x27;sh300.csv&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>æœ¬æ¥å£å³å°†åœæ­¢æ›´æ–°ï¼Œè¯·å°½å¿«ä½¿ç”¨Proç‰ˆæ¥å£ï¼šhttps://waditu.com/document/2</code></pre><h1 id="æ•°æ®æ¦‚è§ˆ"><a href="#æ•°æ®æ¦‚è§ˆ" class="headerlink" title="æ•°æ®æ¦‚è§ˆ"></a>æ•°æ®æ¦‚è§ˆ</h1><p>ï¼ˆ1ï¼‰æŸ¥çœ‹ä¸‹è½½æ•°æ®çš„å­—æ®µã€ç»Ÿè®¡ä¿¡æ¯ç­‰ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æŸ¥çœ‹dfæ¶‰åŠçš„åˆ—å</span></span><br><span class="line"><span class="built_in">print</span>(df.columns)</span><br><span class="line"><span class="comment"># Index([&#x27;code&#x27;, &#x27;open&#x27;, &#x27;close&#x27;, &#x27;high&#x27;, &#x27;low&#x27;, &#x27;vol&#x27;, &#x27;amount&#x27;, &#x27;p_change&#x27;], #dtype=&#x27;object&#x27;)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#æŸ¥çœ‹dfçš„ç»Ÿè®¡ä¿¡æ¯</span></span><br><span class="line">df.describe()</span><br></pre></td></tr></table></figure><pre><code>Index([&#39;code&#39;, &#39;open&#39;, &#39;close&#39;, &#39;high&#39;, &#39;low&#39;, &#39;vol&#39;, &#39;amount&#39;, &#39;p_change&#39;], dtype=&#39;object&#39;)</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>open</th>      <th>close</th>      <th>high</th>      <th>low</th>      <th>vol</th>      <th>amount</th>      <th>p_change</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>2795.000000</td>      <td>2795.000000</td>      <td>2795.000000</td>      <td>2795.000000</td>      <td>2.795000e+03</td>      <td>2.795000e+03</td>      <td>2795.000000</td>    </tr>    <tr>      <th>mean</th>      <td>3342.024819</td>      <td>3344.784845</td>      <td>3370.611827</td>      <td>3314.019947</td>      <td>1.146134e+06</td>      <td>1.499518e+11</td>      <td>0.023324</td>    </tr>    <tr>      <th>std</th>      <td>809.944990</td>      <td>810.070118</td>      <td>816.521375</td>      <td>800.923783</td>      <td>8.775841e+05</td>      <td>1.306605e+11</td>      <td>1.448982</td>    </tr>    <tr>      <th>min</th>      <td>2079.870000</td>      <td>2086.970000</td>      <td>2118.790000</td>      <td>2023.170000</td>      <td>2.190120e+05</td>      <td>2.120044e+10</td>      <td>-8.750000</td>    </tr>    <tr>      <th>25%</th>      <td>2618.540000</td>      <td>2620.265000</td>      <td>2645.770000</td>      <td>2598.400000</td>      <td>6.107925e+05</td>      <td>6.605147e+10</td>      <td>-0.640000</td>    </tr>    <tr>      <th>50%</th>      <td>3292.280000</td>      <td>3293.870000</td>      <td>3315.730000</td>      <td>3258.310000</td>      <td>8.908120e+05</td>      <td>1.074772e+11</td>      <td>0.040000</td>    </tr>    <tr>      <th>75%</th>      <td>3836.075000</td>      <td>3837.775000</td>      <td>3859.115000</td>      <td>3813.550000</td>      <td>1.344036e+06</td>      <td>1.847992e+11</td>      <td>0.720000</td>    </tr>    <tr>      <th>max</th>      <td>5922.070000</td>      <td>5807.720000</td>      <td>5930.910000</td>      <td>5747.660000</td>      <td>6.864391e+06</td>      <td>9.494980e+11</td>      <td>6.710000</td>    </tr>  </tbody></table></div><p>ï¼ˆ2ï¼‰å¯è§†åŒ–æœ€é«˜ä»·æ•°æ®</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df_index=df.code</span><br><span class="line">df_index = df_index.index.tolist()</span><br><span class="line"><span class="comment"># df_index=[str(year)[0:4] for year in df_index]</span></span><br><span class="line">df_all = np.array(df[<span class="string">&#x27;high&#x27;</span>].tolist())</span><br><span class="line">df=df[<span class="string">&#x27;high&#x27;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.plotting <span class="keyword">import</span> register_matplotlib_converters</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">register_matplotlib_converters()</span><br><span class="line"><span class="comment">#  è·å–è®­ç»ƒæ•°æ®ã€åŸå§‹æ•°æ®ã€ç´¢å¼•ç­‰ä¿¡æ¯</span></span><br><span class="line">df, df_all, df_index = readData(<span class="string">&#x27;high&#x27;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#å¯è§†åŒ–æœ€é«˜ä»·</span></span><br><span class="line">df_all = np.array(df_all.tolist())</span><br><span class="line">plt.plot(df_index, df_all, label=<span class="string">&#x27;real-data&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)  </span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.legend.Legend at 0x7fc8a932bfa0&gt;</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210706213411.png" alt="png"></p><h1 id="é¢„å¤„ç†æ•°æ®"><a href="#é¢„å¤„ç†æ•°æ®" class="headerlink" title="é¢„å¤„ç†æ•°æ®"></a>é¢„å¤„ç†æ•°æ®</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><p>ï¼ˆ1ï¼‰ç”Ÿæˆè®­ç»ƒæ•°æ®</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#é€šè¿‡ä¸€ä¸ªåºåˆ—æ¥ç”Ÿæˆä¸€ä¸ª31*(count(*)-train_end)çŸ©é˜µï¼ˆç”¨äºå¤„ç†æ—¶åºçš„æ•°æ®ï¼‰</span></span><br><span class="line"><span class="comment">#å…¶ä¸­æœ€åä¸€åˆ—ç»´æ ‡ç­¾æ•°æ®ã€‚å°±æ˜¯æŠŠå½“å¤©çš„å‰nå¤©ä½œä¸ºå‚æ•°ï¼Œå½“å¤©çš„æ•°æ®ä½œä¸ºlabel</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_data_by_n_days</span>(<span class="params">series, n, index=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(series) &lt;= n:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">&quot;The Length of series is %d, while affect by (n=%d).&quot;</span> % (<span class="built_in">len</span>(series), n))</span><br><span class="line">    df = pd.DataFrame()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        df[<span class="string">&#x27;c%d&#x27;</span> % i] = series.tolist()[i:-(n - i)]        </span><br><span class="line">    df[<span class="string">&#x27;y&#x27;</span>] = series.tolist()[n:]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> index:</span><br><span class="line">        df.index = series.index[n:]</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"> </span><br><span class="line"><span class="comment">#å‚æ•°nä¸ä¸Šç›¸åŒã€‚train_endè¡¨ç¤ºçš„æ˜¯åé¢å¤šå°‘ä¸ªæ•°æ®ä½œä¸ºæµ‹è¯•é›†ã€‚</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readData</span>(<span class="params">column=<span class="string">&#x27;high&#x27;</span>, n=<span class="number">30</span>, all_too=<span class="literal">True</span>, index=<span class="literal">False</span>, train_end=-<span class="number">500</span></span>):</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;sh300.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">    <span class="comment">#ä»¥æ—¥æœŸä¸ºç´¢å¼•</span></span><br><span class="line">    df.index = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: datetime.datetime.strptime(x, <span class="string">&quot;%Y-%m-%d&quot;</span>), df.index))</span><br><span class="line">    <span class="comment">#è·å–æ¯å¤©çš„æœ€é«˜ä»·</span></span><br><span class="line">    df_column = df[column].copy()</span><br><span class="line">    <span class="comment">#æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†</span></span><br><span class="line">    df_column_train, df_column_test = df_column[:train_end], df_column[train_end - n:]</span><br><span class="line">    <span class="comment">#ç”Ÿæˆè®­ç»ƒæ•°æ®</span></span><br><span class="line">    df_generate_train = generate_data_by_n_days(df_column_train, n, index=index)</span><br><span class="line">    <span class="keyword">if</span> all_too:</span><br><span class="line">        <span class="keyword">return</span> df_generate_train, df_column, df.index.tolist()</span><br><span class="line">    <span class="keyword">return</span> df_generate_train</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="æ¨¡å‹"><a href="#æ¨¡å‹" class="headerlink" title="æ¨¡å‹"></a>æ¨¡å‹</h1><p>ï¼ˆ1ï¼‰å®šä¹‰æ¨¡å‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RNN, self).__init__()</span><br><span class="line">        self.rnn = nn.LSTM(</span><br><span class="line">            input_size=input_size,</span><br><span class="line">            hidden_size=<span class="number">64</span>,</span><br><span class="line">            num_layers=<span class="number">1</span>,</span><br><span class="line">            batch_first=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        self.out = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        r_out, (h_n, h_c) = self.rnn(x, <span class="literal">None</span>)  <span class="comment">#Noneå³éšå±‚çŠ¶æ€ç”¨0åˆå§‹åŒ–</span></span><br><span class="line">        out = self.out(r_out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mytrainset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data</span>):</span>        </span><br><span class="line">        self.data, self.label = data[:, :-<span class="number">1</span>].<span class="built_in">float</span>(), data[:, -<span class="number">1</span>].<span class="built_in">float</span>()</span><br><span class="line">             </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.data[index], self.label[index]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ï¼ˆ<span class="number">2</span>ï¼‰è¶…å‚æ•°è®¾ç½®</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">30</span></span><br><span class="line">LR = <span class="number">0.001</span></span><br><span class="line">EPOCH = <span class="number">200</span></span><br><span class="line">batch_size=<span class="number">20</span></span><br><span class="line">train_end =-<span class="number">600</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure><p>ï¼ˆ3ï¼‰è®­ç»ƒæ¨¡å‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.plotting <span class="keyword">import</span> register_matplotlib_converters</span><br><span class="line">register_matplotlib_converters()</span><br><span class="line"><span class="comment"># è·å–è®­ç»ƒæ•°æ®ã€åŸå§‹æ•°æ®ã€ç´¢å¼•ç­‰ä¿¡æ¯</span></span><br><span class="line">df, df_all, df_index = readData(<span class="string">&#x27;high&#x27;</span>, n=n, train_end=train_end)</span><br><span class="line"></span><br><span class="line"><span class="comment">#å¯è§†åŒ–åŸé«˜ä»·æ•°æ®</span></span><br><span class="line">df_all = np.array(df_all.tolist())</span><br><span class="line">plt.plot(df_index, df_all, label=<span class="string">&#x27;real-data&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œè§„èŒƒåŒ–åŠè½¬æ¢ä¸ºTensor</span></span><br><span class="line">df_numpy = np.array(df)</span><br><span class="line"></span><br><span class="line">df_numpy_mean = np.mean(df_numpy)</span><br><span class="line">df_numpy_std = np.std(df_numpy)</span><br><span class="line"></span><br><span class="line">df_numpy = (df_numpy - df_numpy_mean) / df_numpy_std</span><br><span class="line">df_tensor = torch.Tensor(df_numpy)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">trainset = mytrainset(df_tensor)</span><br><span class="line">trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210706213425.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#è®°å½•æŸå¤±å€¼ï¼Œå¹¶ç”¨tensorboardxåœ¨webä¸Šå±•ç¤º</span></span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line">writer = SummaryWriter(log_dir=<span class="string">&#x27;logs&#x27;</span>)</span><br><span class="line"></span><br><span class="line">rnn = RNN(n).to(device)</span><br><span class="line">optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)  </span><br><span class="line">loss_func = nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH):</span><br><span class="line">    <span class="keyword">for</span> tx, ty <span class="keyword">in</span> trainloader:</span><br><span class="line">        tx=tx.to(device)</span><br><span class="line">        ty=ty.to(device)</span><br><span class="line">        <span class="comment">#åœ¨ç¬¬1ä¸ªç»´åº¦ä¸Šæ·»åŠ ä¸€ä¸ªç»´åº¦ä¸º1çš„ç»´åº¦ï¼Œå½¢çŠ¶å˜ä¸º[batch,seq_len,input_size]</span></span><br><span class="line">        output = rnn(torch.unsqueeze(tx, dim=<span class="number">1</span>)).to(device)</span><br><span class="line">        loss = loss_func(torch.squeeze(output), ty)</span><br><span class="line">        optimizer.zero_grad()  </span><br><span class="line">        loss.backward()  </span><br><span class="line">        optimizer.step()</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;sh300_loss&#x27;</span>, loss, step)</span><br></pre></td></tr></table></figure><p>ï¼ˆ4ï¼‰æµ‹è¯•æ¨¡å‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">generate_data_train = []</span><br><span class="line">generate_data_test = []</span><br><span class="line"></span><br><span class="line">test_index = <span class="built_in">len</span>(df_all) + train_end</span><br><span class="line"></span><br><span class="line">df_all_normal = (df_all - df_numpy_mean) / df_numpy_std</span><br><span class="line">df_all_normal_tensor = torch.Tensor(df_all_normal)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n, <span class="built_in">len</span>(df_all)):</span><br><span class="line">    x = df_all_normal_tensor[i - n:i].to(device)</span><br><span class="line">    <span class="comment">#rnnçš„è¾“å…¥å¿…é¡»æ˜¯3ç»´ï¼Œæ•…éœ€æ·»åŠ ä¸¤ä¸ª1ç»´çš„ç»´åº¦ï¼Œæœ€åæˆä¸º[1,1,input_size]</span></span><br><span class="line">    x = torch.unsqueeze(torch.unsqueeze(x, dim=<span class="number">0</span>), dim=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    y = rnn(x).to(device)</span><br><span class="line">    <span class="keyword">if</span> i &lt; test_index:</span><br><span class="line">        generate_data_train.append(torch.squeeze(y).detach().cpu().numpy() * df_numpy_std + df_numpy_mean)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        generate_data_test.append(torch.squeeze(y).detach().cpu().numpy() * df_numpy_std + df_numpy_mean)</span><br><span class="line">plt.plot(df_index[n:train_end], generate_data_train, label=<span class="string">&#x27;generate_train&#x27;</span>)</span><br><span class="line">plt.plot(df_index[train_end:], generate_data_test, label=<span class="string">&#x27;generate_test&#x27;</span>)</span><br><span class="line">plt.plot(df_index[train_end:], df_all[train_end:], label=<span class="string">&#x27;real-data&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210706213446.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.clf()</span><br><span class="line">plt.plot(df_index[train_end:-<span class="number">500</span>], df_all[train_end:-<span class="number">500</span>], label=<span class="string">&#x27;real-data&#x27;</span>)</span><br><span class="line">plt.plot(df_index[train_end:-<span class="number">500</span>], generate_data_test[-<span class="number">600</span>:-<span class="number">500</span>], label=<span class="string">&#x27;generate_test&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210706213449.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNNâ€”â€”ä½¿ç”¨å­—ç¬¦çº§RNNå¯¹åç§°è¿›è¡Œåˆ†ç±»</title>
      <link href="/2021/07/04/char_rnn_classification_tutorial/"/>
      <url>/2021/07/04/char_rnn_classification_tutorial/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨å­—ç¬¦çº§-RNN-å¯¹åç§°è¿›è¡Œåˆ†ç±»"><a href="#ä½¿ç”¨å­—ç¬¦çº§-RNN-å¯¹åç§°è¿›è¡Œåˆ†ç±»" class="headerlink" title="ä½¿ç”¨å­—ç¬¦çº§ RNN å¯¹åç§°è¿›è¡Œåˆ†ç±»"></a>ä½¿ç”¨å­—ç¬¦çº§ RNN å¯¹åç§°è¿›è¡Œåˆ†ç±»</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><p>å­—ç¬¦çº§ RNN å°†å•è¯è¯»å–ä¸ºä¸€ç³»åˆ—å­—ç¬¦ï¼Œåœ¨æ¯ä¸€æ­¥è¾“å‡ºé¢„æµ‹å’Œéšè—çŠ¶æ€ï¼Œå°†å…¶å…ˆå‰çš„éšè—çŠ¶æ€è¾“å…¥åˆ°ä¸‹ä¸€æ—¶é—´æ­¥ã€‚å°†æœ€ç»ˆé¢„æµ‹ä½œä¸ºè¾“å‡ºï¼Œå³å•è¯å±äºå“ªä¸ªç±»ã€‚</p><p>å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†è®­ç»ƒæ¥è‡ª 18 ç§èµ·æºè¯­è¨€çš„æ•°åƒä¸ªå§“æ°ï¼Œå¹¶æ ¹æ®æ‹¼å†™é¢„æµ‹åç§°æ¥è‡ªå“ªç§è¯­è¨€ï¼š<br>ç¤ºä¾‹ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ python predict.py Hinton</span><br><span class="line">(-0.47) Scottish</span><br><span class="line">(-1.52) English</span><br><span class="line">(-3.57) Irish</span><br><span class="line"></span><br><span class="line">$ python predict.py Schmidhuber</span><br><span class="line">(-0.19) German</span><br><span class="line">(-2.48) Czech</span><br><span class="line">(-2.68) Dutch</span><br></pre></td></tr></table></figure><p><strong>Note:</strong><br>   Download the data from<br>   <code>here &lt;https://download.pytorch.org/tutorial/data.zip&gt;</code>_<br>   and extract it to the current directory.</p><p>Included in the <code>data/names</code> directory are 18 text files named as<br>â€œ[Language].txtâ€. Each file contains a bunch of names, one name per<br>line, mostly romanized (but we still need to convert from Unicode to<br>ASCII).</p><p>Weâ€™ll end up with a dictionary of lists of names per language,<br><code>&#123;language: [names ...]&#125;</code>. The generic variables â€œcategoryâ€ and â€œlineâ€<br>(for language and name in our case) are used for later extensibility.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">findFiles</span>(<span class="params">path</span>):</span> <span class="keyword">return</span> glob.glob(path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(findFiles(<span class="string">&#x27;data/names/*.txt&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> unicodedata</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç”Ÿæˆå•è¯åˆ—è¡¨all_lettersï¼Œåç»­one-hotç¼–ç ä¸­ç”¨æ¥æŸ¥æ‰¾ç´¢å¼•</span></span><br><span class="line">all_letters = string.ascii_letters + <span class="string">&quot; .,;&#x27;&quot;</span></span><br><span class="line"><span class="comment"># n_letters å­—ç¬¦æ€»æ•°</span></span><br><span class="line">n_letters = <span class="built_in">len</span>(all_letters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unicodeToAscii</span>(<span class="params">s</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(</span><br><span class="line">        c <span class="keyword">for</span> c <span class="keyword">in</span> unicodedata.normalize(<span class="string">&#x27;NFD&#x27;</span>, s)</span><br><span class="line">        <span class="keyword">if</span> unicodedata.category(c) != <span class="string">&#x27;Mn&#x27;</span></span><br><span class="line">        <span class="keyword">and</span> c <span class="keyword">in</span> all_letters</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nunicodeToAscii:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(unicodeToAscii(<span class="string">&#x27;ÅšlusÃ rski&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build the category_lines dictionary, a list of names per language</span></span><br><span class="line">category_lines = &#123;&#125;</span><br><span class="line">all_categories = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read a file and split into lines</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readLines</span>(<span class="params">filename</span>):</span></span><br><span class="line">    lines = <span class="built_in">open</span>(filename, encoding=<span class="string">&#x27;utf-8&#x27;</span>).read().strip().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> [unicodeToAscii(line) <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> findFiles(<span class="string">&#x27;data/names/*.txt&#x27;</span>):</span><br><span class="line">    category = os.path.splitext(os.path.basename(filename))[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># os.path.splitext åˆ†å‰²æ–‡ä»¶åå’Œæ‰©å±•å</span></span><br><span class="line"><span class="comment"># os.path.basename è¿”å›æ–‡ä»¶å</span></span><br><span class="line">    all_categories.append(category)</span><br><span class="line">    lines = readLines(filename)</span><br><span class="line">    category_lines[category] = lines</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="comment"># print(category_lines)</span></span><br><span class="line">n_categories = <span class="built_in">len</span>(all_categories)</span><br><span class="line"><span class="built_in">print</span>(n_categories)</span><br></pre></td></tr></table></figure><pre><code>[&#39;data/names/Czech.txt&#39;, &#39;data/names/German.txt&#39;, &#39;data/names/Arabic.txt&#39;, &#39;data/names/Japanese.txt&#39;, &#39;data/names/Chinese.txt&#39;, &#39;data/names/Vietnamese.txt&#39;, &#39;data/names/Russian.txt&#39;, &#39;data/names/French.txt&#39;, &#39;data/names/Irish.txt&#39;, &#39;data/names/English.txt&#39;, &#39;data/names/Spanish.txt&#39;, &#39;data/names/Greek.txt&#39;, &#39;data/names/Italian.txt&#39;, &#39;data/names/Portuguese.txt&#39;, &#39;data/names/Scottish.txt&#39;, &#39;data/names/Dutch.txt&#39;, &#39;data/names/Korean.txt&#39;, &#39;data/names/Polish.txt&#39;]unicodeToAscii:Slusarski18</code></pre><p>å¾—åˆ°category_lineså­—å…¸åï¼ŒæŸ¥çœ‹æ ·ä¾‹æ•°æ®</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(category_lines[<span class="string">&#x27;Italian&#x27;</span>][:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>[&#39;Abandonato&#39;, &#39;Abatangelo&#39;, &#39;Abatantuono&#39;, &#39;Abate&#39;, &#39;Abategiovanni&#39;]</code></pre><h2 id="æŠŠåå­—è½¬æ¢æˆ-Tensors"><a href="#æŠŠåå­—è½¬æ¢æˆ-Tensors" class="headerlink" title="æŠŠåå­—è½¬æ¢æˆ Tensors"></a>æŠŠåå­—è½¬æ¢æˆ Tensors</h2><p>ä¸ºäº†è¡¨ç¤ºå•ä¸ªå­—æ¯ï¼Œä½¿ç”¨one-hotå‘é‡ã€‚é™¤äº†å½“å‰å­—æ¯çš„ç´¢å¼•å¤„ä¸º1å¤–ï¼Œå…¶ä½™ç”¨0å¡«å……ï¼Œä¾‹å¦‚<code>&quot;b&quot; = &lt;0 1 0 0 0 ...&gt;</code></p><p>ä¸ºäº†åˆ›å»ºä¸€ä¸ªå•è¯ï¼Œæˆ‘ä»¬å°†ä¸€å †å•è¯è¿æ¥åˆ°ä¸€ä¸ª 2D çŸ©é˜µä¸­ã€‚<code>&lt;line_length x 1 x n_letters&gt;</code></p><p>é¢å¤–çš„ 1 ç»´æ˜¯å› ä¸º PyTorch å‡è®¾ä¸€åˆ‡éƒ½æ˜¯æ‰¹é‡çš„ï¼Œåœ¨è¿™é‡Œä½¿æ‰¹é‡å¤§å°1ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(all_letters)</span><br><span class="line"><span class="comment"># Find letter index from all_letters, e.g. &quot;a&quot; = 0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">letterToIndex</span>(<span class="params">letter</span>):</span></span><br><span class="line">    <span class="keyword">return</span> all_letters.find(letter)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Just for demonstration, turn a letter into a &lt;1 x n_letters&gt; Tensor</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">letterToTensor</span>(<span class="params">letter</span>):</span></span><br><span class="line">    tensor = torch.zeros(<span class="number">1</span>, n_letters)</span><br><span class="line"><span class="comment">#     print(tensor)</span></span><br><span class="line">    tensor[<span class="number">0</span>][letterToIndex(letter)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> tensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn a line into a &lt;line_length x 1 x n_letters&gt;,</span></span><br><span class="line"><span class="comment"># or an array of one-hot letter vectors</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lineToTensor</span>(<span class="params">line</span>):</span></span><br><span class="line">    tensor = torch.zeros(<span class="built_in">len</span>(line), <span class="number">1</span>, n_letters)</span><br><span class="line">    <span class="keyword">for</span> li, letter <span class="keyword">in</span> <span class="built_in">enumerate</span>(line):</span><br><span class="line">        tensor[li][<span class="number">0</span>][letterToIndex(letter)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> tensor</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(letterToTensor(<span class="string">&#x27;a&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;lineToTensor\n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(lineToTensor(<span class="string">&#x27;Jones&#x27;</span>).size())</span><br><span class="line"><span class="built_in">print</span>(lineToTensor(<span class="string">&#x27;Jones&#x27;</span>))</span><br></pre></td></tr></table></figure><pre><code>abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;&#39;tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0.]])lineToTensortorch.Size([5, 1, 57])tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0.]],        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0.]],        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0.]],        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0.]],        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0.]]])</code></pre><h1 id="åˆ›å»ºç½‘ç»œ"><a href="#åˆ›å»ºç½‘ç»œ" class="headerlink" title="åˆ›å»ºç½‘ç»œ"></a>åˆ›å»ºç½‘ç»œ</h1><p>è¯¥RNNç½‘ç»œæœ‰2ä¸ªçº¿æ€§å±‚ï¼Œå¯¹è¾“å…¥å’Œéšè—çŠ¶æ€è¿›è¡Œæ“ä½œï¼Œè¾“å‡ºåæœ‰ä¸€ä¸ª LogSoftmaxå±‚ã€‚<br><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210704010147.png" alt="Unknown"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, hidden_size, output_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RNN, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.hidden_size = hidden_size <span class="comment">#éšè—å±‚å¤§å°</span></span><br><span class="line"></span><br><span class="line">        self.i2h = nn.Linear(input_size + hidden_size, hidden_size) <span class="comment">#è¾“å…¥åˆ°éšè—å±‚çš„çŸ©é˜µ</span></span><br><span class="line">        self.i2o = nn.Linear(input_size + hidden_size, output_size) <span class="comment">#è¾“å…¥åˆ°è¾“å‡ºçš„çŸ©é˜µ</span></span><br><span class="line">        self.softmax = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden</span>):</span></span><br><span class="line">        combined = torch.cat((<span class="built_in">input</span>, hidden), <span class="number">1</span>)</span><br><span class="line">        hidden = self.i2h(combined)</span><br><span class="line"><span class="comment">#         output = self.i2o(combined)</span></span><br><span class="line">        output = self.softmax(self.i2o(combined))</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, self.hidden_size)</span><br><span class="line"></span><br><span class="line">n_hidden = <span class="number">128</span></span><br><span class="line"><span class="built_in">print</span>(n_letters, n_hidden, n_categories)</span><br><span class="line">rnn = RNN(n_letters, n_hidden, n_categories)</span><br><span class="line"><span class="built_in">print</span>(rnn.i2h)</span><br></pre></td></tr></table></figure><pre><code>57 128 18Linear(in_features=185, out_features=128, bias=True)</code></pre><p>ä¸ºäº†è¿è¡Œè¿™ä¸ªç½‘ç»œçš„ä¸€ä¸ªæ—¶é—´æ­¥é•¿ï¼Œéœ€è¦ä¼ é€’ä¸€ä¸ªè¾“å…¥ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œä¸ºå½“å‰å­—æ¯çš„å¼ é‡ï¼‰å’Œä¸€ä¸ªå…ˆå‰çš„éšè—çŠ¶æ€ï¼ˆé¦–å…ˆå°†å…¶åˆå§‹åŒ–ä¸ºé›¶ã€‚å¾—åˆ°è¾“å‡ºï¼ˆæ¯ç§è¯­è¨€çš„æ¦‚ç‡ï¼‰å’Œä¸‹ä¸€ä¸ªéšè—çŠ¶æ€ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = letterToTensor(<span class="string">&#x27;A&#x27;</span>)</span><br><span class="line">hidden = torch.zeros(<span class="number">1</span>, n_hidden)</span><br><span class="line"></span><br><span class="line">output, next_hidden = rnn(<span class="built_in">input</span>, hidden)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure><pre><code>tensor([[-3.0130, -2.8982, -2.9242, -2.9052, -2.8677, -2.8176, -2.9350, -2.9060,         -2.8688, -2.9518, -2.9790, -2.9274, -2.8601, -2.8504, -2.8594, -2.8165,         -2.8698, -2.8037]], grad_fn=&lt;LogSoftmaxBackward&gt;)</code></pre><p>ä¸ºäº†æ•ˆç‡èµ·è§ï¼Œä¸æƒ³ä¸ºæ¯ä¸€æ­¥éƒ½åˆ›å»ºä¸€ä¸ªæ–°çš„å¼ é‡ï¼Œæ‰€ä»¥å°†ä½¿ç”¨lineToTensorä»£æ›¿letterToTensorå’Œä½¿ç”¨åˆ‡ç‰‡ã€‚è¿™å¯ä»¥é€šè¿‡é¢„å…ˆè®¡ç®—æ‰¹é‡å¼ é‡æ¥è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = lineToTensor(<span class="string">&#x27;Albert&#x27;</span>)</span><br><span class="line">hidden = torch.zeros(<span class="number">1</span>, n_hidden)</span><br><span class="line"></span><br><span class="line">output, next_hidden = rnn(<span class="built_in">input</span>[<span class="number">0</span>], hidden)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>tensor([[-3.0130, -2.8982, -2.9242, -2.9052, -2.8677, -2.8176, -2.9350, -2.9060,         -2.8688, -2.9518, -2.9790, -2.9274, -2.8601, -2.8504, -2.8594, -2.8165,         -2.8698, -2.8037]], grad_fn=&lt;LogSoftmaxBackward&gt;)</code></pre><p>è¾“å‡ºæ˜¯ä¸€ä¸ªå¼ é‡ï¼Œå…¶ä¸­æ¯ä¸ªé¡¹ç›®éƒ½æ˜¯è¯¥ç±»åˆ«çš„å¯èƒ½æ€§ï¼ˆè¶Šé«˜å¯èƒ½æ€§è¶Šå¤§ï¼‰ã€‚<code>&lt;1 x n_categories&gt;</code></p><h1 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h1><h2 id="Preparing-for-Training"><a href="#Preparing-for-Training" class="headerlink" title="Preparing for Training"></a>Preparing for Training</h2><p>è§£é‡Šç½‘ç»œçš„è¾“å‡ºï¼šè¾“å‡ºæ˜¯æ¯ä¸ªç±»åˆ«çš„å¯èƒ½æ€§ã€‚å¯ä»¥ä½¿ç”¨Tensor.topkè·å–æœ€å¤§å€¼çš„ç´¢å¼•ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">categoryFromOutput</span>(<span class="params">output</span>):</span></span><br><span class="line">    top_n, top_i = output.topk(<span class="number">1</span>)</span><br><span class="line"><span class="comment">#     print(top_n, top_i)</span></span><br><span class="line">    category_i = top_i[<span class="number">0</span>].item()</span><br><span class="line">    <span class="keyword">return</span> all_categories[category_i], category_i</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(categoryFromOutput(output))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>(&#39;Portuguese&#39;, 13)</code></pre><p>éœ€è¦ä¸€ç§å¿«é€Ÿè·å–è®­ç»ƒç¤ºä¾‹ï¼ˆåç§°åŠå…¶è¯­è¨€ï¼‰çš„æ–¹æ³•ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomChoice</span>(<span class="params">l</span>):</span></span><br><span class="line">    <span class="keyword">return</span> l[random.randint(<span class="number">0</span>, <span class="built_in">len</span>(l) - <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomTrainingExample</span>():</span></span><br><span class="line">    category = randomChoice(all_categories)</span><br><span class="line">    line = randomChoice(category_lines[category])</span><br><span class="line">    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)</span><br><span class="line">    line_tensor = lineToTensor(line)</span><br><span class="line">    <span class="keyword">return</span> category, line, category_tensor, line_tensor</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    category, line, category_tensor, line_tensor = randomTrainingExample()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;category =&#x27;</span>, category, <span class="string">&#x27;/ line =&#x27;</span>, line)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><pre><code>category = Vietnamese / line = Macategory = Japanese / line = Aidacategory = Portuguese / line = De santigocategory = Italian / line = Piovenecategory = Scottish / line = Taylorcategory = Spanish / line = Benitezcategory = Vietnamese / line = Quachcategory = Arabic / line = Sleimancategory = Russian / line = To The First Pagecategory = Korean / line = Kwang </code></pre><h2 id="æ¨¡å‹è®­ç»ƒ"><a href="#æ¨¡å‹è®­ç»ƒ" class="headerlink" title="æ¨¡å‹è®­ç»ƒ"></a>æ¨¡å‹è®­ç»ƒ</h2><p>RNN çš„æœ€åä¸€å±‚æ˜¯nn.LogSoftmaxï¼Œæ‰€ä»¥é€‰æ‹©æŸå¤±å‡½æ•°nn.NLLLossã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.NLLLoss()</span><br></pre></td></tr></table></figure><p>Each loop of training will:</p><ul><li>Create input and target tensors</li><li>Create a zeroed initial hidden state</li><li>Read each letter in and Keep hidden state for next letter</li><li>Compare final output to target</li><li>Back-propagate</li><li>Return the output and loss</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.005</span> <span class="comment"># If you set this too high, it might explode. If too low, it might not learn</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">category_tensor, line_tensor</span>):</span></span><br><span class="line">    hidden = rnn.initHidden()</span><br><span class="line"></span><br><span class="line">    rnn.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(line_tensor.size()[<span class="number">0</span>]):</span><br><span class="line"><span class="comment">#  line_tensoræ˜¯å¤šä¸ªå­—æ¯tensorçš„ç»„åˆåˆ—è¡¨</span></span><br><span class="line"><span class="comment">#  å¾ªç¯ä¸­æ›´æ–° hidden</span></span><br><span class="line">        output, hidden = rnn(line_tensor[i], hidden)</span><br><span class="line"></span><br><span class="line">    loss = criterion(output, category_tensor)</span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add parameters&#x27; gradients to their values, multiplied by learning rate</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> rnn.parameters():</span><br><span class="line">        p.data.add_(p.grad.data, alpha=-learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output, loss.item()</span><br></pre></td></tr></table></figure><p>ç°åœ¨åªéœ€è¦ç”¨ä¸€å †ä¾‹å­æ¥è¿è¡Œå®ƒã€‚ç”±äºè¯¥ trainå‡½æ•°è¿”å›è¾“å‡ºå’ŒæŸå¤±ï¼Œæˆ‘ä»¬å¯ä»¥æ‰“å°å®ƒçš„é¢„æµ‹å€¼å¹¶ç»˜åˆ¶æŸå¤±å˜åŒ–å›¾ã€‚ç”±äºæœ‰ 1000 ä¸ªç¤ºä¾‹ï¼Œæˆ‘ä»¬åªæ‰“å°æ¯ä¸ªprint_everyç¤ºä¾‹ï¼Œå¹¶å–æŸå¤±çš„å¹³å‡å€¼ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">n_iters = <span class="number">100000</span></span><br><span class="line">print_every = <span class="number">5000</span></span><br><span class="line">plot_every = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Keep track of losses for plotting</span></span><br><span class="line">current_loss = <span class="number">0</span></span><br><span class="line">all_losses = []</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timeSince</span>(<span class="params">since</span>):</span></span><br><span class="line">    now = time.time()</span><br><span class="line">    s = now - since</span><br><span class="line">    m = math.floor(s / <span class="number">60</span>)</span><br><span class="line">    s -= m * <span class="number">60</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;%dm %ds&#x27;</span> % (m, s)</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_iters + <span class="number">1</span>):</span><br><span class="line">    category, line, category_tensor, line_tensor = randomTrainingExample()</span><br><span class="line">    output, loss = train(category_tensor, line_tensor)</span><br><span class="line">    current_loss += loss</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print iter number, loss, name and guess</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">iter</span> % print_every == <span class="number">0</span>:</span><br><span class="line">        guess, guess_i = categoryFromOutput(output)</span><br><span class="line">        correct = <span class="string">&#x27;âœ“&#x27;</span> <span class="keyword">if</span> guess == category <span class="keyword">else</span> <span class="string">&#x27;âœ— (%s)&#x27;</span> % category</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%d %d%% (%s) %.4f %s / %s %s&#x27;</span> % (<span class="built_in">iter</span>, <span class="built_in">iter</span> / n_iters * <span class="number">100</span>, timeSince(start), loss, line, guess, correct))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add current loss avg to list of losses</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">iter</span> % plot_every == <span class="number">0</span>:</span><br><span class="line">        all_losses.append(current_loss / plot_every)</span><br><span class="line">        current_loss = <span class="number">0</span></span><br></pre></td></tr></table></figure><pre><code>tensor([[-2.4746]], grad_fn=&lt;TopkBackward&gt;) tensor([[3]])5000 5% (0m 6s) 2.6255 Ventura / Japanese âœ— (Portuguese)tensor([[-1.8169]], grad_fn=&lt;TopkBackward&gt;) tensor([[16]])10000 10% (0m 13s) 3.0541 Kron / Korean âœ— (German)tensor([[-1.0685]], grad_fn=&lt;TopkBackward&gt;) tensor([[4]])15000 15% (0m 20s) 1.0685 Ming / Chinese âœ“tensor([[-1.7141]], grad_fn=&lt;TopkBackward&gt;) tensor([[1]])20000 20% (0m 27s) 1.7141 Sommer / German âœ“tensor([[-1.7253]], grad_fn=&lt;TopkBackward&gt;) tensor([[7]])25000 25% (0m 34s) 1.8872 Maurice / French âœ— (Irish)tensor([[-0.1941]], grad_fn=&lt;TopkBackward&gt;) tensor([[3]])30000 30% (0m 41s) 0.1941 Jukodo / Japanese âœ“tensor([[-1.1135]], grad_fn=&lt;TopkBackward&gt;) tensor([[2]])35000 35% (0m 48s) 1.1135 Khouri / Arabic âœ“tensor([[-0.2534]], grad_fn=&lt;TopkBackward&gt;) tensor([[12]])40000 40% (0m 55s) 0.2534 Pietri / Italian âœ“tensor([[-0.3285]], grad_fn=&lt;TopkBackward&gt;) tensor([[11]])45000 45% (1m 3s) 0.3285 Panayiotopoulos / Greek âœ“tensor([[-0.7564]], grad_fn=&lt;TopkBackward&gt;) tensor([[4]])50000 50% (1m 11s) 0.7564 Song / Chinese âœ“tensor([[-0.6697]], grad_fn=&lt;TopkBackward&gt;) tensor([[12]])55000 55% (1m 18s) 2.2053 Castellano / Italian âœ— (Spanish)tensor([[-1.1335]], grad_fn=&lt;TopkBackward&gt;) tensor([[1]])60000 60% (1m 26s) 2.1380 Nunez / German âœ— (Spanish)tensor([[-1.0437]], grad_fn=&lt;TopkBackward&gt;) tensor([[3]])65000 65% (1m 33s) 1.0437 Ichiyusai / Japanese âœ“tensor([[-0.9454]], grad_fn=&lt;TopkBackward&gt;) tensor([[12]])70000 70% (1m 40s) 1.7417 Cardozo / Italian âœ— (Portuguese)tensor([[-1.5786]], grad_fn=&lt;TopkBackward&gt;) tensor([[1]])75000 75% (1m 47s) 2.0613 Macclelland / German âœ— (Irish)tensor([[-0.9435]], grad_fn=&lt;TopkBackward&gt;) tensor([[16]])80000 80% (1m 55s) 0.9435 Ri / Korean âœ“tensor([[-1.7442]], grad_fn=&lt;TopkBackward&gt;) tensor([[14]])85000 85% (2m 3s) 2.6989 Bran / Scottish âœ— (Irish)tensor([[-1.1392]], grad_fn=&lt;TopkBackward&gt;) tensor([[7]])90000 90% (2m 11s) 1.1392 Victor / French âœ“tensor([[-0.8626]], grad_fn=&lt;TopkBackward&gt;) tensor([[5]])95000 95% (2m 19s) 0.8626 Ton / Vietnamese âœ“tensor([[-0.7950]], grad_fn=&lt;TopkBackward&gt;) tensor([[14]])100000 100% (2m 28s) 4.5470 Budny / Scottish âœ— (Polish)</code></pre><h2 id="Plotting-the-Results"><a href="#Plotting-the-Results" class="headerlink" title="Plotting the Results"></a>Plotting the Results</h2><p>Plotting the historical loss from <code>all_losses</code> shows the network<br>learning:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> ticker</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(all_losses)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7fbbb7b60f10&gt;]</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210704005859.png" alt="png"></p><h1 id="Evaluating-the-Results"><a href="#Evaluating-the-Results" class="headerlink" title="Evaluating the Results"></a>Evaluating the Results</h1><p>To see how well the network performs on different categories, we will<br>create a confusion matrix, indicating for every actual language (rows)<br>which language the network guesses (columns). To calculate the confusion<br>matrix a bunch of samples are run through the network with<br><code>evaluate()</code>, which is the same as <code>train()</code> minus the backprop.</p><p>ä¸ºäº†æŸ¥çœ‹ç½‘ç»œåœ¨ä¸åŒç±»åˆ«ä¸Šçš„è¡¨ç°å¦‚ä½•ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªæ··æ·†çŸ©é˜µï¼Œactual language (rows)ï¼Œthe network guesses (columns)ã€‚è¿è¡Œ evaluate()è®¡ç®—æ··æ·†çŸ©é˜µï¼Œè¿™ä¸train()å‡å»åå‘ä¼ æ’­ç›¸åŒã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Keep track of correct guesses in a confusion matrix</span></span><br><span class="line">confusion = torch.zeros(n_categories, n_categories)</span><br><span class="line">n_confusion = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Just return an output given a line</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">line_tensor</span>):</span></span><br><span class="line">    hidden = rnn.initHidden()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(line_tensor.size()[<span class="number">0</span>]):</span><br><span class="line">        output, hidden = rnn(line_tensor[i], hidden)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># Go through a bunch of examples and record which are correctly guessed</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_confusion):</span><br><span class="line">    category, line, category_tensor, line_tensor = randomTrainingExample()</span><br><span class="line">    output = evaluate(line_tensor)</span><br><span class="line">    guess, guess_i = categoryFromOutput(output)</span><br><span class="line">    category_i = all_categories.index(category)</span><br><span class="line">    confusion[category_i][guess_i] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize by dividing every row by its sum</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_categories):</span><br><span class="line">    confusion[i] = confusion[i] / confusion[i].<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up plot</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">cax = ax.matshow(confusion.numpy())</span><br><span class="line">fig.colorbar(cax)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up axes</span></span><br><span class="line">ax.set_xticklabels([<span class="string">&#x27;&#x27;</span>] + all_categories, rotation=<span class="number">90</span>)</span><br><span class="line">ax.set_yticklabels([<span class="string">&#x27;&#x27;</span>] + all_categories)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Force label at every tick</span></span><br><span class="line">ax.xaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line">ax.yaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># sphinx_gallery_thumbnail_number = 2</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>&lt;ipython-input-61-a5b341ffc3a3&gt;:33: UserWarning: FixedFormatter should only be used together with FixedLocator  ax.set_xticklabels([&#39;&#39;] + all_categories, rotation=90)&lt;ipython-input-61-a5b341ffc3a3&gt;:34: UserWarning: FixedFormatter should only be used together with FixedLocator  ax.set_yticklabels([&#39;&#39;] + all_categories)</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210704005908.png" alt="png"></p><p>You can pick out bright spots off the main axis that show which<br>languages it guesses incorrectly, e.g. Chinese for Korean, and Spanish<br>for Italian. It seems to do very well with Greek, and very poorly with<br>English (perhaps because of overlap with other languages).</p><h2 id="Running-on-User-Input"><a href="#Running-on-User-Input" class="headerlink" title="Running on User Input"></a>Running on User Input</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">input_line, n_predictions=<span class="number">3</span></span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n&gt; %s&#x27;</span> % input_line)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        output = evaluate(lineToTensor(input_line))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Get top N categories</span></span><br><span class="line">        topv, topi = output.topk(n_predictions, <span class="number">1</span>, <span class="literal">True</span>)</span><br><span class="line">        predictions = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_predictions):</span><br><span class="line">            value = topv[<span class="number">0</span>][i].item()</span><br><span class="line">            category_index = topi[<span class="number">0</span>][i].item()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;(%.2f) %s&#x27;</span> % (value, all_categories[category_index]))</span><br><span class="line">            predictions.append([value, all_categories[category_index]])</span><br><span class="line"></span><br><span class="line">predict(<span class="string">&#x27;Dovesky&#x27;</span>)</span><br><span class="line">predict(<span class="string">&#x27;Jackson&#x27;</span>)</span><br><span class="line">predict(<span class="string">&#x27;Satoshi&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>&gt; Dovesky(-0.55) Russian(-1.52) Czech(-1.98) Polish&gt; Jackson(-1.27) Scottish(-1.61) French(-1.83) English&gt; Satoshi(-1.15) Italian(-1.88) Portuguese(-1.96) Polish</code></pre>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNNå¾ªç¯ç¥ç»ç½‘ç»œ</title>
      <link href="/2021/07/03/RNN%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2021/07/03/RNN%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="RNNå¾ªç¯ç¥ç»ç½‘ç»œ"><a href="#RNNå¾ªç¯ç¥ç»ç½‘ç»œ" class="headerlink" title="RNNå¾ªç¯ç¥ç»ç½‘ç»œ"></a>RNNå¾ªç¯ç¥ç»ç½‘ç»œ</h1><ul><li>åºåˆ—æ•°æ®ï¼šä¸å…ˆåé¡ºåºæœ‰å…³çš„æ•°æ®ã€‚</li><li>å¯¹äºåºåˆ—æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œã€‚</li></ul><script type="math/tex; mode=display">H_t=Ï•(X_tW_{xh}+H_{tâˆ’1}W_{hh}+b_h)</script><script type="math/tex; mode=display">O_t=H_tW_{hq}+b_q</script><blockquote><p>$X_tâˆˆR^{nÃ—d}$æ˜¯åºåˆ—ä¸­æ—¶é—´æ­¥$t$å°æ‰¹é‡è¾“å…¥ã€‚</p><p>$H_tâˆˆR^{nÃ—h}$æ˜¯è¯¥æ—¶é—´æ­¥çš„éšè—å˜é‡ã€‚</p><p>éšè—å±‚çš„æƒé‡$W<em>{xh}âˆˆR^{dÃ—h}$ã€$W</em>{hh}âˆˆR^{hÃ—h}$å’Œåå·® $b_hâˆˆR^{1Ã—h}$ </p><p>è¾“å‡ºå±‚çš„æƒé‡$W_{hq}âˆˆR^{hÃ—q}$å’Œåå·®$b_qâˆˆR^{1Ã—q}$</p><p>æ—¶é—´æ­¥$t$çš„éšè—å˜é‡çš„è®¡ç®—ç”±å½“å‰æ—¶é—´æ­¥çš„è¾“å…¥å’Œä¸Šä¸€æ—¶é—´æ­¥çš„éšè—å˜é‡å…±åŒå†³å®šã€‚</p></blockquote><p>å…¶ä¸­ï¼š$X<em>tW</em>{xh}+H<em>{tâˆ’1}W</em>{hh}$å¯ä»¥å†™æˆçŸ©é˜µ$[X<em>t,H</em>{tâˆ’1}]^T$ä¸$[W<em>{xh},W</em>{hh}]$è¿æ¥åçš„ä¹˜ç§¯ã€‚</p><p>å«éšè—çŠ¶æ€çš„å¾ªç¯ç¥ç»ç½‘ç»œ:</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201119164943.png" alt="image-20201119164943208" style="zoom:50%;" /></p><blockquote><p>åœ¨æ—¶é—´æ­¥$t$ï¼Œéšè—çŠ¶æ€çš„è®¡ç®—å¯ä»¥çœ‹æˆæ˜¯å°†è¾“å…¥$X<em>t$å’Œå‰ä¸€æ—¶é—´æ­¥éšè—çŠ¶æ€$H</em>{tâˆ’1}$è¿ç»“åè¾“å…¥ä¸€ä¸ªæ¿€æ´»å‡½æ•°ä¸º$Ï•$çš„å…¨è¿æ¥å±‚ã€‚</p><p>è¯¥å…¨è¿æ¥å±‚çš„è¾“å‡ºå°±æ˜¯å½“å‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€$Ht$ ï¼Œä¸”æ¨¡å‹å‚æ•°ä¸ºW<em>xhä¸$W</em>{hh}$ çš„è¿ç»“ï¼Œåå·®ä¸º$b_h$ã€‚</p><p>å½“å‰æ—¶é—´æ­¥$t$çš„éšè—çŠ¶æ€$H<em>t$å°†å‚ä¸ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥$t+1$çš„éšè—çŠ¶æ€$H</em>{t+1}$ çš„è®¡ç®—ï¼Œå¹¶è¾“å…¥åˆ°å½“å‰æ—¶é—´æ­¥çš„å…¨è¿æ¥è¾“å‡ºå±‚ã€‚</p></blockquote><p>å‰é¢è¯´åˆ°$X<em>tW</em>{xh}+H<em>{tâˆ’1}W</em>{hh}$ç­‰ä»·äºçŸ©é˜µ$[X<em>t,H</em>{tâˆ’1}]^T$ä¸$[W<em>{xh},W</em>{hh}]$è¿æ¥åçš„ä¹˜ç§¯ï¼Œæˆ‘ä»¬æ¥éªŒè¯ä¸€ä¸‹ï¼š</p><p>æ„é€ çŸ©é˜µï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">X, W_xh = torch.randn(3, 1), torch.randn(1, 4)</span><br><span class="line">H, W_hh = torch.randn(3, 4), torch.randn(4, 4)</span><br></pre></td></tr></table></figure><p>ä»£å…¥å…¬å¼ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.matmul(X, W_xh) + torch.matmul(H, W_hh)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.2453, -0.3466,  1.1116, -2.0741],</span><br><span class="line">        [ 7.5939,  0.3180,  0.7647,  2.4541],</span><br><span class="line">        [ 2.9573, -0.0598,  0.1762,  0.1142]])</span><br></pre></td></tr></table></figure><p>çŸ©é˜µè¿æ¥ä¹‹åï¼š</p><blockquote><p>dim=1ï¼šåˆ—æ‹¼æ¥</p><p>dim=0ï¼šè¡Œæ‹¼æ¥</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.matmul(torch.cat((X, H), dim=1), torch.cat((W_xh, W_hh), dim=0))</span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.2453, -0.3466,  1.1116, -2.0741],</span><br><span class="line">        [ 7.5939,  0.3180,  0.7647,  2.4541],</span><br><span class="line">        [ 2.9573, -0.0598,  0.1762,  0.1142]])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pythonâ€”â€”os.pathæ¨¡å—å¸¸ç”¨æ–¹æ³•æ±‡æ€»</title>
      <link href="/2021/07/03/python%E2%80%94%E2%80%94os.path%E6%A8%A1%E5%9D%97%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/"/>
      <url>/2021/07/03/python%E2%80%94%E2%80%94os.path%E6%A8%A1%E5%9D%97%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="os-pathæ¨¡å—å¸¸ç”¨æ–¹æ³•æ±‡æ€»"><a href="#os-pathæ¨¡å—å¸¸ç”¨æ–¹æ³•æ±‡æ€»" class="headerlink" title="os.pathæ¨¡å—å¸¸ç”¨æ–¹æ³•æ±‡æ€»"></a>os.pathæ¨¡å—å¸¸ç”¨æ–¹æ³•æ±‡æ€»</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">os.path.abspath(path) #è¿”å›ç»å¯¹è·¯å¾„</span><br><span class="line">os.path.basename(path) #è¿”å›æ–‡ä»¶å</span><br><span class="line">os.path.commonprefix(list) #è¿”å›list(å¤šä¸ªè·¯å¾„)ä¸­ï¼Œæ‰€æœ‰pathå…±æœ‰çš„æœ€é•¿çš„è·¯å¾„ã€‚</span><br><span class="line">os.path.dirname(path) #è¿”å›æ–‡ä»¶è·¯å¾„</span><br><span class="line">os.path.exists(path)  #è·¯å¾„å­˜åœ¨åˆ™è¿”å›True,è·¯å¾„æŸåè¿”å›False</span><br><span class="line">os.path.lexists  #è·¯å¾„å­˜åœ¨åˆ™è¿”å›True,è·¯å¾„æŸåä¹Ÿè¿”å›True</span><br><span class="line">os.path.expanduser(path)  #æŠŠpathä¸­åŒ…å«çš„&quot;~&quot;å’Œ&quot;~user&quot;è½¬æ¢æˆç”¨æˆ·ç›®å½•</span><br><span class="line">os.path.expandvars(path)  #æ ¹æ®ç¯å¢ƒå˜é‡çš„å€¼æ›¿æ¢pathä¸­åŒ…å«çš„â€$nameâ€å’Œâ€$&#123;name&#125;â€</span><br><span class="line">os.path.getatime(path)  #è¿”å›æœ€åä¸€æ¬¡è¿›å…¥æ­¤pathçš„æ—¶é—´ã€‚</span><br><span class="line">os.path.getmtime(path)  #è¿”å›åœ¨æ­¤pathä¸‹æœ€åä¸€æ¬¡ä¿®æ”¹çš„æ—¶é—´ã€‚</span><br><span class="line">os.path.getctime(path)  #è¿”å›pathçš„å¤§å°</span><br><span class="line">os.path.getsize(path)  #è¿”å›æ–‡ä»¶å¤§å°ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨å°±è¿”å›é”™è¯¯</span><br><span class="line">os.path.isabs(path)  #åˆ¤æ–­æ˜¯å¦ä¸ºç»å¯¹è·¯å¾„</span><br><span class="line">os.path.isfile(path)  #åˆ¤æ–­è·¯å¾„æ˜¯å¦ä¸ºæ–‡ä»¶</span><br><span class="line">os.path.isdir(path)  #åˆ¤æ–­è·¯å¾„æ˜¯å¦ä¸ºç›®å½•</span><br><span class="line">os.path.islink(path)  #åˆ¤æ–­è·¯å¾„æ˜¯å¦ä¸ºé“¾æ¥</span><br><span class="line">os.path.ismount(path)  #åˆ¤æ–­è·¯å¾„æ˜¯å¦ä¸ºæŒ‚è½½ç‚¹ï¼ˆï¼‰</span><br><span class="line">os.path.join(path1[, path2[, ...]])  #æŠŠç›®å½•å’Œæ–‡ä»¶ååˆæˆä¸€ä¸ªè·¯å¾„</span><br><span class="line">os.path.normcase(path)  #è½¬æ¢pathçš„å¤§å°å†™å’Œæ–œæ </span><br><span class="line">os.path.normpath(path)  #è§„èŒƒpathå­—ç¬¦ä¸²å½¢å¼</span><br><span class="line">os.path.realpath(path)  #è¿”å›pathçš„çœŸå®è·¯å¾„</span><br><span class="line">os.path.relpath(path[, start])  #ä»startå¼€å§‹è®¡ç®—ç›¸å¯¹è·¯å¾„</span><br><span class="line">os.path.samefile(path1, path2)  #åˆ¤æ–­ç›®å½•æˆ–æ–‡ä»¶æ˜¯å¦ç›¸åŒ</span><br><span class="line">os.path.sameopenfile(fp1, fp2)  #åˆ¤æ–­fp1å’Œfp2æ˜¯å¦æŒ‡å‘åŒä¸€æ–‡ä»¶</span><br><span class="line">os.path.samestat(stat1, stat2)  #åˆ¤æ–­stat tuple stat1å’Œstat2æ˜¯å¦æŒ‡å‘åŒä¸€ä¸ªæ–‡ä»¶</span><br><span class="line">os.path.split(path)  #æŠŠè·¯å¾„åˆ†å‰²æˆdirnameå’Œbasenameï¼Œè¿”å›ä¸€ä¸ªå…ƒç»„</span><br><span class="line">os.path.splitdrive(path)   #ä¸€èˆ¬ç”¨åœ¨windowsä¸‹ï¼Œè¿”å›é©±åŠ¨å™¨åå’Œè·¯å¾„ç»„æˆçš„å…ƒç»„</span><br><span class="line">os.path.splitext(path)  #åˆ†å‰²è·¯å¾„ï¼Œè¿”å›è·¯å¾„åå’Œæ–‡ä»¶æ‰©å±•åçš„å…ƒç»„</span><br><span class="line">os.path.splitunc(path)  #æŠŠè·¯å¾„åˆ†å‰²ä¸ºåŠ è½½ç‚¹ä¸æ–‡ä»¶</span><br><span class="line">os.path.walk(path, visit, arg)  #éå†pathï¼Œè¿›å…¥æ¯ä¸ªç›®å½•éƒ½è°ƒç”¨visitå‡½æ•°ï¼Œvisitå‡½æ•°å¿…é¡»æœ‰</span><br><span class="line">3ä¸ªå‚æ•°(arg, dirname, names)ï¼Œdirnameè¡¨ç¤ºå½“å‰ç›®å½•çš„ç›®å½•åï¼Œnamesä»£è¡¨å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰</span><br><span class="line">æ–‡ä»¶åï¼Œargsåˆ™ä¸ºwalkçš„ç¬¬ä¸‰ä¸ªå‚æ•°</span><br><span class="line">os.path.supports_unicode_filenames  #è®¾ç½®æ˜¯å¦æ”¯æŒunicodeè·¯å¾„å</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> os.path </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension</title>
      <link href="/2021/07/02/Recurrent%20Chunking%20Mechanisms%20for%20Long-Text%20Machine%20Reading%20Comprehension/"/>
      <url>/2021/07/02/Recurrent%20Chunking%20Mechanisms%20for%20Long-Text%20Machine%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="Recurrent-Chunking-Mechanisms-for-Long-Text-Machine-Reading-Comprehension"><a href="#Recurrent-Chunking-Mechanisms-for-Long-Text-Machine-Reading-Comprehension" class="headerlink" title="Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension"></a>Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension</h1><blockquote><p><a href="https://arxiv.org/abs/2005.08056">è®ºæ–‡ï¼šhttps://arxiv.org/abs/2005.08056</a></p><p>ä»£ç ï¼š<a href="https://github.com/HongyuGong/RCM-Question-Answering">https://github.com/HongyuGong/RCM-Question-Answering</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>ä¼ ç»Ÿçš„åŸºäºtransformerçš„æ¨¡å‹åªèƒ½æ¥å—å›ºå®šé•¿åº¦ï¼ˆå¦‚512ï¼‰çš„æ–‡æœ¬ä½œä¸ºå…¶è¾“å…¥ã€‚ä¸ºäº†å¤„ç†æ›´é•¿çš„æ–‡æœ¬è¾“å…¥ï¼Œä»¥å‰çš„æ–¹æ³•é€šå¸¸å°†å®ƒä»¬åˆ†å‰²æˆç­‰è·çš„ç‰‡æ®µï¼Œå¹¶æ ¹æ®æ¯ä¸ªç‰‡æ®µç‹¬ç«‹é¢„æµ‹ç­”æ¡ˆï¼Œè€Œä¸è€ƒè™‘å…¶ä»–ç‰‡æ®µçš„ä¿¡æ¯ã€‚å› æ­¤ï¼Œå¯èƒ½ä¼šå½¢æˆä¸èƒ½è¦†ç›–æ­£ç¡®ç­”æ¡ˆè·¨åº¦çš„ç‰‡æ®µï¼Œæˆ–åœ¨å…¶å‘¨å›´ä¿ç•™ä¸å……åˆ†çš„ä¸Šä¸‹æ–‡ï¼Œå¤§å¤§é™ä½æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå›ç­”éœ€è¦è·¨æ®µä¿¡æ¯çš„é—®é¢˜çš„èƒ½åŠ›è¾ƒå·®ã€‚æœ¬æ–‡æå‡ºrecurrent chunkingæœºåˆ¶(RCM)æå‡é•¿æ–‡æœ¬æœºå™¨é˜…è¯»ç†è§£çš„æ€§èƒ½ï¼Œä»¥é˜²æ­¢ç­”æ¡ˆè·¨åº¦è¿‡äºæ¥è¿‘æ®µçš„è¾¹ç•Œå’Œè¦†ç›–ä¸å®Œæ•´çš„ç­”æ¡ˆã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œè®©æ¨¡å‹ä»¥æ›´çµæ´»çš„æ–¹å¼å­¦ä¹ åˆ†å—ï¼šæ¨¡å‹å¯ä»¥å†³å®šå®ƒè¦å¤„ç†çš„ä¸‹ä¸€ä¸ªç‰‡æ®µçš„æ–¹å‘ã€‚è¿˜é‡‡ç”¨äº†é€’å½’æœºåˆ¶ï¼Œä½¿ä¿¡æ¯èƒ½å¤Ÿè·¨æ®µæµåŠ¨ã€‚</p><p><strong>ä¼ ç»Ÿæ–¹æ³•ï¼š</strong></p><p>é¦–å…ˆå°†è¾“å…¥çš„æ–‡æœ¬åˆ†æˆç­‰è·çš„ç‰‡æ®µï¼Œç„¶åé¢„æµ‹æ¯ä¸ªå•ç‹¬ç‰‡æ®µçš„ç­”æ¡ˆï¼Œæœ€åå°†å¤šä¸ªç‰‡æ®µçš„ç­”æ¡ˆé›†åˆåœ¨ä¸€èµ·ã€‚</p><ul><li>ä¼ ç»Ÿæ–¹æ³•ç¼ºé™·<ul><li>é¢„å…ˆç¡®å®šçš„å¤§è·¨åº¦çš„åˆ†å—å¯èƒ½ä¼šå¯¼è‡´ç­”æ¡ˆä¸å®Œæ•´ï¼Œå¹¶ä¸”å½“ç­”æ¡ˆåœ¨æ®µçš„è¾¹ç•Œé™„è¿‘æ—¶ï¼Œä¸ç­”æ¡ˆåœ¨æ®µçš„ä¸­å¿ƒï¼Œå‘¨å›´æœ‰æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡æ—¶ç›¸æ¯”ï¼Œæ¨¡å‹æ›´å®¹æ˜“å¤±è´¥ã€‚</li><li>æ ¹æ®ç»éªŒè§‚å¯Ÿåˆ°ï¼Œè¾ƒå°è·¨åº¦çš„åˆ†å—å¯¹æ¨¡å‹æ€§èƒ½çš„è´¡çŒ®å¾ˆå°ï¼ˆæœ‰æ—¶ç”šè‡³ä¼¤å®³äº†ï¼‰ã€‚</li></ul></li></ul><p>recurrent chunking mechanisms (RCM)</p><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210703105842.png" alt="image-20210703105842803"></p><ul><li>ç‰¹å¾<ul><li>å¯ä»¥è®©meachine readeré€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥å­¦ä¹ å¦‚ä½•åœ¨é˜…è¯»å†—é•¿çš„æ–‡ä»¶æ—¶æ™ºèƒ½åœ°é€‰æ‹©æ­¥å¹…å¤§å°ï¼Œæœ‰åŠ©äºé˜²æ­¢ä»ç‰‡æ®µä¸­æå–ä¸å®Œæ•´çš„ç­”æ¡ˆï¼Œå¹¶åœ¨ç­”æ¡ˆå‘¨å›´ä¿ç•™è¶³å¤Ÿçš„è¯­å¢ƒ</li><li>åº”ç”¨é€’å½’æœºåˆ¶ï¼Œè®©ä¿¡æ¯åœ¨å„æ®µä¹‹é—´æµåŠ¨ã€‚è¯¥æ¨¡å‹å¯ä»¥è®¿é—®å½“å‰ç‰‡æ®µä»¥å¤–çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</li></ul></li></ul><p>ä½¿ç”¨BERTç”Ÿæˆå‘é‡è¡¨ç¤ºï¼Œä½¿ç”¨max poolingå®ç°ç­”æ¡ˆèåˆã€‚</p><p>åŸºçº¿æ¨¡å‹å¯¹æ¯ä¸ªæ–‡æ¡£æ®µè¿›è¡Œç‹¬ç«‹çš„ç­”æ¡ˆé¢„æµ‹ï¼Œç”±äºç¼ºä¹æ–‡æ¡£çº§åˆ«çš„ä¿¡æ¯ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸åŒæ®µçš„ç­”æ¡ˆå¾—åˆ†æ— æ³•æ¯”è¾ƒã€‚æœ¬æ–‡ä½¿ç”¨ä¸€ä¸ªé€’å½’å±‚æ¥ä¼ æ’­ä¸åŒç‰‡æ®µçš„ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨åˆ†å—è¯„åˆ†å™¨æ¨¡å‹ï¼ˆchunking scorer modelï¼‰æ¥ä¼°è®¡ä¸€ä¸ªç‰‡æ®µåŒ…å«ç­”æ¡ˆçš„æ¦‚ç‡ã€‚</p><p>ä¸¤ä¸ªé€’å½’æœºåˆ¶ï¼š</p><ul><li>gated recurrence</li><li>Long Short Term Memory (LSTM)</li></ul><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li><p>CoQA</p></li><li><p>QuAC</p></li><li>TriviaQA</li></ul><h2 id="æ€§èƒ½æ°´å¹³-amp-ç»“è®º"><a href="#æ€§èƒ½æ°´å¹³-amp-ç»“è®º" class="headerlink" title="æ€§èƒ½æ°´å¹³&amp;ç»“è®º"></a>æ€§èƒ½æ°´å¹³&amp;ç»“è®º</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210703114724.png" alt="image-20210703114724411"></p><p>BERT-Largeæ¨¡å‹çš„æ€§èƒ½éšç€æœ€å¤§åºåˆ—é•¿åº¦çš„å‡å°ï¼Œæ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚å½“æœ€å¤§è¾“å…¥é•¿åº¦ä»512ä¸‹é™åˆ°192æ—¶ï¼ŒCoQAæ•°æ®é›†çš„F1åˆ†æ•°ä¸‹é™äº†8.6%ï¼ŒQuACæ•°æ®é›†çš„F1åˆ†æ•°ä¸‹é™äº†27.0%ã€‚</p><p>å…·æœ‰recurrentæœºåˆ¶çš„BERT-RCMæ€§èƒ½ä¼˜äºBERT-Largeå’ŒBERT-Sent-Selectorã€‚</p><p>RCMæ¨¡å‹å¯¹æœ€å¤§åºåˆ—é•¿åº¦ä¸å¤ªæ•æ„Ÿï¼Œè€ŒLSTMçš„æ€§èƒ½ä¸gated recurrenceæ€§èƒ½æ¥è¿‘ã€‚</p><p><strong>ä¸åŒstride sizeçš„æ€§èƒ½æ¯”è¾ƒï¼š</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210703122850.png" alt="image-20210703122850502"></p><p>è¿‡å°çš„stride sizeä¸ä¼šæå‡æ¨¡å‹å‡†ç¡®ç‡åè€Œä¼šé™ä½æ¨¡å‹æ€§èƒ½ã€‚</p><p><strong>æ•ˆæœå±•ç¤º</strong>ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210703123834.png" alt="image-20210703123834755"></p><p>åœ¨ä¸‰ä¸ªMRCæ•°æ®é›†CoQAã€QuACå’ŒTriviaQAä¸Šçš„å®éªŒè¯æ˜äº†æœ¬æ–‡æå‡ºçš„é€’å½’åˆ†å—æœºåˆ¶çš„æœ‰æ•ˆæ€§ï¼Œå¯ä»¥è·å¾—æ›´æœ‰å¯èƒ½åŒ…å«å®Œæ•´ç­”æ¡ˆçš„ç‰‡æ®µï¼ŒåŒæ—¶ä¸ºæ›´å¥½çš„é¢„æµ‹æä¾›å›´ç»•çœŸå®ç­”æ¡ˆçš„è¶³å¤Ÿä¸Šä¸‹æ–‡ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> RCM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Sampling Strategies for Multi-Task Reading Comprehension.md</title>
      <link href="/2021/06/04/Dynamic%20Sampling%20Strategies%20for%20Multi-Task%20Reading%20Comprehension/"/>
      <url>/2021/06/04/Dynamic%20Sampling%20Strategies%20for%20Multi-Task%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="Dynamic-Sampling-Strategies-for-Multi-Task-Reading-Comprehension"><a href="#Dynamic-Sampling-Strategies-for-Multi-Task-Reading-Comprehension" class="headerlink" title="Dynamic Sampling Strategies for Multi-Task Reading Comprehension"></a>Dynamic Sampling Strategies for Multi-Task Reading Comprehension</h1><blockquote><p> <a href="https://www.aclweb.org/anthology/2020.acl-main.86.pdf">è®ºæ–‡ï¼šhttps://www.aclweb.org/anthology/2020.acl-main.86.pdf</a></p><p> <a href="https://github.com/mrqa/MRQA-Shared-Task-2019">ä»£ç ï¼šhttps://github.com/mrqa/MRQA-Shared-Task-2019</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>æ ¹æ®å¤šä»»åŠ¡æ¨¡å‹åœ¨æ•°æ®é›†ä¸Šçš„å½“å‰è¡¨ç°ä¸å•ä»»åŠ¡è¡¨ç°çš„æ¯”ä¾‹æ¥é€‰æ‹©è®­ç»ƒå®ä¾‹ï¼Œæ¯”è¾ƒå“ªç§å®ä¾‹æŠ½æ ·æ–¹æ³•å’Œå†æ—¶è°ƒåº¦ç­–ç•¥èƒ½æä¾›æœ€ä½³æ€§èƒ½ã€‚</p><blockquote><p>catastrophic forgettingï¼šåœ¨ä¸€ä¸ªä¸å¹³è¡¡çš„è®­ç»ƒé›†ä¸­ï¼Œå½“è®­ç»ƒä»è¯¥æ•°æ®é›†å¼€å§‹æ—¶ï¼Œç‰¹å®šæ•°æ®é›†çš„æ€§èƒ½ä¼šæ€¥å‰§ä¸‹é™ã€‚</p><p>å¤šä»»åŠ¡è®­ç»ƒçš„ä¸¤ä¸ªåŸºæœ¬æ–¹é¢ï¼š</p><ul><li>how many instances are sampled from each task per epoch </li><li>how those instances are organized within the epoch</li></ul></blockquote><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>æœ¬æ–‡å¼•å…¥äº†ä¸€ç§åŠ¨æ€æŠ½æ ·ç­–ç•¥ï¼Œä»æ•°æ®é›†ä¸­é€‰æ‹©å®ä¾‹ï¼Œå…¶æ¦‚ç‡ä¸å½“å‰æŸäº›æŒ‡æ ‡ï¼ˆå¦‚EMæˆ–F1å¾—åˆ†ï¼‰çš„æ€§èƒ½å’ŒåŒä¸€æ¨¡å‹åœ¨è¯¥æ•°æ®é›†ä¸­çš„å•ä»»åŠ¡æ€§èƒ½ä¹‹é—´çš„å·®è·æˆæ­£æ¯”ã€‚</p><h3 id="Sampling-and-Scheduling-Strategies"><a href="#Sampling-and-Scheduling-Strategies" class="headerlink" title="Sampling and Scheduling Strategies"></a>Sampling and Scheduling Strategies</h3><p>æœ¬æ–‡æ¢è®¨äº†å¤šä»»åŠ¡å­¦ä¹ ä¸­å®ä¾‹æ’åºçš„ä¸¤ä¸ªä¸»è¦æ–¹é¢ï¼š</p><ul><li>ä»æ¯ä¸ªæ•°æ®é›†ä¸­è¿›è¡Œå®ä¾‹æŠ½æ ·ï¼Œä»¥è·å¾—ç”¨äºä¸€ä¸ªå‘¨æœŸçš„å®ä¾‹é›†åˆ</li><li>åœ¨å‘¨æœŸå†…å¯¹è¿™äº›å®ä¾‹è¿›è¡Œè°ƒåº¦ï¼Œç¡®å®šå®ƒä»¬åº”è¯¥å¦‚ä½•æ’åºå’Œåˆ†æ‰¹ã€‚</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210604155741.png" alt="image-20210604155741020"></p><p>å››ä¸ªæŠ½æ ·æ–¹æ³•ï¼š</p><blockquote><p>Uniformï¼ŒBy Sizeï¼ŒUniformâ†’Sizeï¼ŒDynamic</p></blockquote><p>Dynamicï¼šé¦–å…ˆè®¡ç®—æ­£åœ¨è®­ç»ƒçš„æ¨¡å‹çš„å•ä»»åŠ¡éªŒè¯æŒ‡æ ‡ã€‚å¯¹äºæ¯ä¸ªä»»åŠ¡ï¼Œè®¡ç®—å½“å‰çš„å¤šä»»åŠ¡æ€§èƒ½å’Œç›¸åº”çš„å•ä»»åŠ¡æ€§èƒ½ä¹‹é—´çš„å·®è·ï¼Œå¹¶å°†è¿™äº›æŒ‡æ ‡çš„å·®å¼‚å½’ä¸€åŒ–ï¼Œä»¥åˆ›å»ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚ç„¶åï¼Œå¯¹äºç¬¬ä¸€ä¸ªepochä¹‹åçš„æ¯ä¸€ä¸ªepochï¼Œä»è¿™ä¸ªåˆ†å¸ƒä¸­æŒ‰ä»»åŠ¡å–æ ·ã€‚å¦‚æœä¸€ä¸ªæ•°æ®é›†çš„æ€§èƒ½ä¸å•ä»»åŠ¡æ€§èƒ½ç›¸å·®ç”šè¿œï¼Œå®ƒå°†è¢«å¤§é‡æŠ½æ ·ï¼Œè€Œè¾¾åˆ°æˆ–è¶…è¿‡å•ä»»åŠ¡æ€§èƒ½çš„æ•°æ®é›†å°†è¢«å°‘é‡æŠ½æ ·ã€‚</p><p>ä¿®æ”¹ç”¨äºè®¡ç®—å·®å€¼çš„æŒ‡æ ‡çš„æ–¹æ³•ï¼Œæœ€ç»ˆå†³å®šä½¿ç”¨EM+F1å·®åˆ†ï¼Œæ€§èƒ½æ¯”EMæˆ–F1å·®åˆ†æ›´å¥½ï¼Œå¹¶ä¸”æ˜æ˜¾æ¯”æŸå¤±å·®åˆ†çš„æ€§èƒ½å¥½ã€‚</p><p>Epoch Schedulingï¼š</p><ul><li>Partitionedï¼šè¯¥è°ƒåº¦ç­–ç•¥æŒ‰ä»»åŠ¡åˆ’åˆ†epochä¸­çš„å®ä¾‹ã€‚</li><li>Homogeneous Batchesï¼šè¿™ç§è°ƒåº¦ç­–ç•¥å¹¶ä¸å¼ºè¿«å®ä¾‹åŸºäºæ•°æ®é›†çš„åˆ†åŒºã€‚ç›¸åï¼Œæ¯ä¸ªæ•°æ®é›†çš„å®ä¾‹éƒ½è¢«åˆ†åˆ°ä¸€èµ·ï¼Œç„¶åå¯¹åˆ†æ‰¹çš„å®ä¾‹è¿›è¡Œæ‰“ä¹±ã€‚</li><li>Heterogeneous Batchesï¼šè¿™ç§è°ƒåº¦ç­–ç•¥å¯¹æ‰€æœ‰é€‰å®šçš„å®ä¾‹æ‰“ä¹±ï¼Œç„¶åå°†å®ƒä»¬åˆ†æ‰¹è¿›è¡Œã€‚æ¯ä¸ªæ‰¹æ¬¡å¯èƒ½æœ‰æ¥è‡ªè®¸å¤šä¸åŒæ•°æ®é›†çš„å®ä¾‹ã€‚</li><li>Uniform Batchesï¼šè¿™ç§æ–¹æ³•åœ¨æ¯ä¸ªæ‰¹æ¬¡ä¸­ä¸ºæ¯ä¸ªæ•°æ®é›†æ”¾ç½®ä¸€ä¸ªå®ä¾‹ï¼Œç›´åˆ°æœ€å°çš„æ•°æ®é›†çš„å®ä¾‹ç”¨å®Œã€‚è¿™ç§ç­–ç•¥åœ¨å…¶ä½™çš„æ•°æ®é›†ä¸Šç»§ç»­è¿›è¡Œï¼Œç›´åˆ°æ‰€æœ‰æ•°æ®é›†éƒ½ç”¨å®Œã€‚</li></ul><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>å°å‹æ•°æ®é›†ï¼š</p><blockquote><p>Quoref,ROPES</p></blockquote><p>ä¸­å‹æ•°æ®é›†ï¼š</p><blockquote><p>DuoRC,NarrativeQA</p></blockquote><p>å¤§å‹æ•°æ®é›†ï¼š</p><blockquote><p>DROP,NewsQA,SQuAD1.1,SQuAD2.0</p></blockquote><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p>åŠ¨æ€æŠ½æ ·ï¼Œæ ¹æ®å„è‡ªçš„åº¦é‡å·®å¯¹æ¯ä¸ªä»»åŠ¡çš„å®ä¾‹è¿›è¡ŒæŠ½æ ·ï¼Œå¯ä»¥æé«˜æ€§èƒ½ã€‚åœ¨æ¯ä¸ªepochå†…å°†ä¸åŒä»»åŠ¡çš„å®ä¾‹äº¤é”™åœ¨ä¸€èµ·ï¼Œå½¢æˆå¼‚è´¨çš„æ‰¹æ¬¡ï¼Œå¯¹äºä¼˜åŒ–å¤šä»»åŠ¡æ€§èƒ½è‡³å…³é‡è¦ã€‚æœ€ç»ˆæ¨¡å‹ä¸å…¶ä»–çš„å¤šä»»åŠ¡é˜…è¯»ç†è§£åœ¨ORBåŸºå‡†ä¸Šçš„æ¨¡å‹æ€§èƒ½æœ‰å¾ˆå¤§çš„æé«˜ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> Dynamic Sampling Strategies </tag>
            
            <tag> ORB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Semantic Graphs for Generating Deep Questions</title>
      <link href="/2021/05/28/Semantic%20Graphs%20for%20Generating%20Deep%20Questions/"/>
      <url>/2021/05/28/Semantic%20Graphs%20for%20Generating%20Deep%20Questions/</url>
      
        <content type="html"><![CDATA[<h1 id="Semantic-Graphs-for-Generating-Deep-Questions"><a href="#Semantic-Graphs-for-Generating-Deep-Questions" class="headerlink" title="Semantic Graphs for Generating Deep Questions"></a>Semantic Graphs for Generating Deep Questions</h1><blockquote><p> <a href="https://arxiv.org/abs/2004.12704">è®ºæ–‡ï¼šhttps://arxiv.org/abs/2004.12704</a></p><p> <a href="https://github.com/WING-NUS/SG-Deep-Question-Generation">ä»£ç ï¼šhttps://github.com/WING-NUS/SG-Deep-Question-Generation</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>æœ¬æ–‡æå‡ºäº†æ·±åº¦é—®é¢˜ç”Ÿæˆï¼ˆDQGï¼‰çš„é—®é¢˜ï¼Œå…¶ç›®çš„æ˜¯ç”Ÿæˆéœ€è¦å¯¹è¾“å…¥æ®µè½çš„å¤šä¸ªä¿¡æ¯è¿›è¡Œæ¨ç†çš„å¤æ‚é—®é¢˜ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>ä¸ºäº†æ•æ‰æ–‡ä»¶çš„å…¨å±€ç»“æ„å¹¶ä¿ƒè¿›æ¨ç†ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œé¦–å…ˆä¸ºè¾“å…¥çš„æ–‡ä»¶æ„å»ºä¸€ä¸ªè¯­ä¹‰å±‚é¢çš„å›¾ï¼Œç„¶åé€šè¿‡å¼•å…¥ä¸€ä¸ªåŸºäºæ³¨æ„åŠ›çš„GGNNï¼ˆAtt-GGNNï¼‰å¯¹è¯­ä¹‰å›¾è¿›è¡Œç¼–ç ã€‚ä¹‹åï¼Œèåˆæ–‡æ¡£å±‚é¢å’Œå›¾å±‚é¢çš„è¡¨ç¤ºï¼Œå¯¹å†…å®¹é€‰æ‹©å’Œé—®é¢˜è§£ç è¿›è¡Œè”åˆè®­ç»ƒã€‚</p><p>é—®é¢˜å®šä¹‰ï¼š</p><script type="math/tex; mode=display">\overline{Q} = arg\ \underset{Q}max P(Q|D, A)</script><blockquote><p>$\overline{Q}$ï¼šç”Ÿæˆçš„é—®é¢˜</p><p>Dï¼šæ–‡æ¡£</p><p>Aï¼šç­”æ¡ˆ</p></blockquote><p><strong>æ¨¡å‹ç»“æ„ï¼š</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210525200100.png" alt="image-20210525200100849"></p><p>ä¸‰ä¸ªæ¨¡å—ï¼š</p><ul><li><p>semantic graph construction</p><blockquote><p>ä¸ºè¾“å…¥æ„å»ºDP(Dependency Parsing) or SRL-based semantic graphã€‚</p></blockquote></li><li><p>semantic-enriched document representation</p><blockquote><p>ä½¿ç”¨ Attention-enhanced Gated Graph Neural Network (Att-GGNN)å­¦ä¹ è¯­ä¹‰å›¾è¡¨ç¤ºã€‚</p></blockquote></li><li><p>joint-task question generation</p><blockquote><p>é€šè¿‡èŠ‚ç‚¹çº§å†…å®¹é€‰æ‹©å’Œå•è¯çº§é—®é¢˜è§£ç çš„è”åˆè®­ç»ƒæ¥ç”Ÿæˆæ·±åº¦é—®é¢˜ã€‚</p></blockquote></li></ul><h3 id="Semantic-Graph-Construction"><a href="#Semantic-Graph-Construction" class="headerlink" title="Semantic Graph Construction"></a>Semantic Graph Construction</h3><p>å®ä½“ä¹‹é—´çš„è¯­ä¹‰å…³ç³»æ˜¯å†³å®šè¯¢é—®ä»€ä¹ˆä»¥åŠå®ƒæ‰€åŒ…æ‹¬çš„æ¨ç†ç±»å‹çš„æœ‰åŠ›çº¿ç´¢ã€‚ä¸ºäº†æç‚¼å‡ºæ–‡æ¡£ä¸­çš„è¿™ç§è¯­ä¹‰ä¿¡æ¯ï¼Œæœ¬æ–‡ä½¿ç”¨åŸºäºSRLï¼ˆè¯­ä¹‰è§’è‰²æ ‡ç­¾ï¼‰å’ŒDP-ï¼ˆä¾èµ–åˆ†æï¼‰çš„æ–¹æ³•æ¥æ„å»ºè¯­ä¹‰å›¾ã€‚</p><h3 id="Semantic-Enriched-Document-Representations"><a href="#Semantic-Enriched-Document-Representations" class="headerlink" title="Semantic-Enriched Document Representations"></a>Semantic-Enriched Document Representations</h3><p>æœ¬æ–‡åˆ†åˆ«é€šè¿‡åŸºäºRNNçš„æ®µè½ç¼–ç å™¨å’Œæ–°é¢–çš„Att-GGNå›¾ç¼–ç å™¨å¯¹æ–‡æ¡£Då’Œè¯­ä¹‰å›¾Gè¿›è¡Œç¼–ç ï¼Œç„¶åå°†å…¶èåˆï¼Œå¾—åˆ°ç”¨äºé—®é¢˜ç”Ÿæˆçš„è¯­ä¹‰ä¸°å¯Œçš„æ–‡æ¡£è¡¨ç¤ºã€‚</p><p>ä½¿ç”¨ bi-directional Gated Recurrent Unit (GRU)ç¼–ç ä¸Šä¸‹æ–‡ã€‚</p><p>é‡‡ç”¨ä¸€ç§æ–°çš„AttGGNNï¼Œé€šè¿‡èšåˆæ¥è‡ªå…¶é‚»å±…çš„ä¿¡æ¯æ¥æ›´æ–°èŠ‚ç‚¹è¡¨å¾ã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>HotpotQA</p><h2 id="æ€§èƒ½æ°´å¹³-amp-ç»“è®º"><a href="#æ€§èƒ½æ°´å¹³-amp-ç»“è®º" class="headerlink" title="æ€§èƒ½æ°´å¹³&amp;ç»“è®º"></a>æ€§èƒ½æ°´å¹³&amp;ç»“è®º</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210529095840.png" alt="image-20210529095642633"></p><p>æœ¬æ–‡æå‡ºçš„æ¨¡å‹P1å’ŒP2åœ¨BLEUè¯„æµ‹ä¸Šéƒ½è¡¨ç°å‡ºäº†æœ€ä¼˜çš„æ•ˆæœã€‚</p><p>ä¸é‡‡ç”¨é—¨æ§è‡ªæ³¨æ„æœºåˆ¶å¹¶ä½¿ç”¨ä¸æœ¬æ–‡ç›¸åŒçš„è§£ç å™¨çš„B5æ¨¡å‹ç›¸æ¯”ï¼Œæœ¬æ–‡å¸¦æœ‰åŸºäºDPçš„è¯­ä¹‰å›¾çš„æ¨¡å‹ï¼ˆP2ï¼‰åœ¨BLEU-4ä¸­æ€§èƒ½æå‡æ˜¾è‘—ã€‚è¿™è¡¨æ˜äº†semantic-enrichedæ–‡æ¡£è¡¨ç¤ºçš„æ˜¾è‘—æ•ˆæœã€‚</p><p><strong>ç»“è®ºï¼š</strong></p><p>æœ¬æ–‡æå‡ºçš„æ¡†æ¶ç»“åˆäº†è¯­ä¹‰å›¾æ¥å¢å¼ºè¾“å…¥æ–‡ä»¶çš„è¡¨å¾ï¼Œå¹¶é€šè¿‡ä¸å†…å®¹é€‰æ‹©ä»»åŠ¡çš„è”åˆè®­ç»ƒæ¥ç”Ÿæˆé—®é¢˜ã€‚åœ¨HotpotQAæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå¼•å…¥è¯­ä¹‰å›¾å¤§å¤§å‡å°‘äº†è¯­ä¹‰é”™è¯¯ï¼Œè€Œå†…å®¹é€‰æ‹©æœ‰åˆ©äºå¯¹ä¸ç›¸å¹²çš„ç›¸å…³å†…å®¹è¿›è¡Œé€‰æ‹©å’Œæ¨ç†ï¼Œé—®é¢˜çš„è´¨é‡æé«˜æ˜¾è‘—æé«˜ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> DQG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hierarchical Graph Network for Multi-hop Question Answering</title>
      <link href="/2021/05/21/Hierarchical%20Graph%20Network%20for%20Multi-hop%20Question%20Answering/"/>
      <url>/2021/05/21/Hierarchical%20Graph%20Network%20for%20Multi-hop%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="Hierarchical-Graph-Network-for-Multi-hop-Question-Answering"><a href="#Hierarchical-Graph-Network-for-Multi-hop-Question-Answering" class="headerlink" title="Hierarchical Graph Network for Multi-hop Question Answering"></a>Hierarchical Graph Network for Multi-hop Question Answering</h1><blockquote><p> <a href="https://arxiv.org/abs/1911.03631">è®ºæ–‡ï¼šhttps://arxiv.org/abs/1911.03631</a></p><p> <a href="https://github.com/yuwfan/HGN">ä»£ç ï¼šhttps://github.com/yuwfan/HGN</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>â€‹        æå‡ºäº†ç”¨äºå¤šè·³é—®é¢˜å›ç­”çš„ Hierarchical Graph Networkï¼ˆHGNï¼‰ã€‚ä¸ºäº†å°†åˆ†æ•£åœ¨å¤šä¸ªæ®µè½çš„æ–‡æœ¬ä¸­çš„çº¿ç´¢æ±‡æ€»èµ·æ¥ï¼Œé€šè¿‡æ„å»ºä¸åŒç²’åº¦çº§åˆ«çš„èŠ‚ç‚¹ï¼ˆé—®é¢˜ã€æ®µè½ã€å¥å­å’Œå®ä½“ï¼‰æ¥åˆ›å»ºä¸€ä¸ªå±‚æ¬¡å›¾ã€‚å°†å¼‚è´¨èŠ‚ç‚¹è¢«ç¼–ç»‡æˆä¸€ä¸ªå®Œæ•´çš„å›¾ï¼Œä¸åŒé¢—ç²’åº¦çš„èŠ‚ç‚¹è¢«ç”¨äºä¸åŒçš„å­ä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼Œæ®µè½é€‰æ‹©ã€æ”¯æŒäº‹å®æå–å’Œç­”æ¡ˆé¢„æµ‹ï¼‰ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>â€‹        ä¸ºäº†å°†åˆ†æ•£åœ¨å¤šä¸ªæ®µè½çš„æ–‡æœ¬ä¸­çš„çº¿ç´¢æ±‡æ€»èµ·æ¥ï¼Œé€šè¿‡æ„å»ºä¸åŒç²’åº¦çº§åˆ«çš„èŠ‚ç‚¹ï¼ˆå³é—®é¢˜ã€æ®µè½ã€å¥å­å’Œå®ä½“ï¼‰æ¥åˆ›å»ºä¸€ä¸ªhierarchical graphï¼Œè¿™äº›èŠ‚ç‚¹çš„è¡¨ç¤ºæ˜¯ç”±åŸºäºBERTçš„ä¸Šä¸‹æ–‡ç¼–ç å™¨åˆå§‹åŒ–çš„ã€‚</p><h3 id="Hierarchical-Graph-Network"><a href="#Hierarchical-Graph-Network" class="headerlink" title="Hierarchical Graph Network"></a>Hierarchical Graph Network</h3><p>å››ä¸ªä¸»è¦çš„ç»„ä»¶ï¼š</p><ul><li><p>Graph Construction Module</p><blockquote><p>æ„å»ºå±‚æ¬¡å›¾ä»¥è¿æ¥ä¸åŒæ¥æºçš„çº¿ç´¢ã€‚</p></blockquote><p>æ„å»ºæ­¥éª¤</p><ul><li>è¯†åˆ«ç›¸å…³çš„å¤šè·³æ®µ</li><li>æ·»åŠ ä»£è¡¨æ‰€é€‰æ®µè½å†…å¥å­å’Œå®ä½“ä¹‹é—´è”ç³»çš„è¾¹</li></ul></li><li><p>Context Encoding Module</p><blockquote><p>é€šè¿‡åŸºäºBERTçš„ç¼–ç å™¨è·å¾—å›¾å½¢èŠ‚ç‚¹çš„åˆå§‹è¡¨ç¤ºã€‚</p></blockquote><p>å°†æ‰€é€‰æ®µè½å’Œé—®é¢˜ä¸²è”åè¾“å…¥åˆ°BERTé¢„è®­ç»ƒæ¨¡å‹ã€‚</p></li><li><p>Graph Reasoning Module</p><blockquote><p>åº”ç”¨åŸºäºå›¾å½¢æ³¨æ„åŠ›çš„æ¶ˆæ¯ä¼ é€’ç®—æ³•æ¥å…±åŒæ›´æ–°èŠ‚ç‚¹è¡¨ç¤ºã€‚</p></blockquote><p>GAT(Graph Attention Network)ï¼Œå°†èŠ‚ç‚¹ä½œä¸ºè¾“å…¥ï¼ŒGATé€šè¿‡é‚»å±…$N_i$æ›´æ–°èŠ‚ç‚¹çš„ç‰¹å¾è¡¨ç¤º$h_i^{â€˜}$ã€‚</p><script type="math/tex; mode=display">h_i^{'}= Ïƒ(\sum_{j \in N_i}a_{ij}Wh_j)</script><p>Ïƒ(Â·)è¡¨ç¤ºæ¿€æ´»å‡½æ•°ï¼Œ$Î±_{ij}$ä¸ºæ³¨æ„åŠ›ç³»æ•°ã€‚</p></li></ul><ul><li><p>Multi-task Prediction Module</p><blockquote><p>åŒæ—¶æ‰§è¡Œå¤šä¸ªå­ä»»åŠ¡ï¼ŒåŒ…æ‹¬æ®µè½é€‰æ‹©ã€æ”¯æŒäº‹å®é¢„æµ‹ã€å®ä½“é¢„æµ‹å’Œç­”æ¡ˆè·¨åº¦æå–ã€‚</p></blockquote><p>æ®µè½é€‰æ‹©åŸºäºæ®µè½èŠ‚ç‚¹ï¼Œæ”¯æŒäº‹å®é¢„æµ‹åŸºäºå¥å­èŠ‚ç‚¹ï¼Œç­”æ¡ˆé¢„æµ‹åŸºäºå®ä½“èŠ‚ç‚¹ã€‚</p></li></ul><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210521175510.png" alt="image-20210521175510269"></p><p>æ”¯æŒäº‹å®é¢„æµ‹è¿‡ç¨‹ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210521222206.png" alt="image-20210521222206209"></p><p>å·¦ä¾§é—®é¢˜ï¼šQ â†’ P1 â†’ S4 â†’ P2 â†’ S7</p><p>å³ä¾§é—®é¢˜ï¼šQ â†’ P1 â†’ S1 â†’ S2 â†’ P2 â†’ S3</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>HotpotQA Distractor and Fullwiki setting </p><h2 id="æ€§èƒ½æ°´å¹³-amp-ç»“è®º"><a href="#æ€§èƒ½æ°´å¹³-amp-ç»“è®º" class="headerlink" title="æ€§èƒ½æ°´å¹³ &amp; ç»“è®º"></a>æ€§èƒ½æ°´å¹³ &amp; ç»“è®º</h2><p>æ€§èƒ½æ°´å¹³ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210521192345.png" alt="image-20210521192345886"></p><p>HGNæ–¹æ³•åœ¨Distractorå’ŒFullwikiè®¾ç½®ä¸­éƒ½å–å¾—äº†é¢†å…ˆçš„æ€§èƒ½æ°´å¹³ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> HGN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Reinforced Multi-task Approach for Multi-hop Question Generation</title>
      <link href="/2021/05/14/COLING%202020-Reinforced%20Multi-task%20Approach%20for%20Multi-hop%20Question%20Generation/"/>
      <url>/2021/05/14/COLING%202020-Reinforced%20Multi-task%20Approach%20for%20Multi-hop%20Question%20Generation/</url>
      
        <content type="html"><![CDATA[<h1 id="Reinforced-Multi-task-Approach-for-Multi-hop-Question-Generation"><a href="#Reinforced-Multi-task-Approach-for-Multi-hop-Question-Generation" class="headerlink" title="Reinforced Multi-task Approach for Multi-hop Question Generation"></a>Reinforced Multi-task Approach for Multi-hop Question Generation</h1><blockquote><p> <a href="https://arxiv.org/abs/2004.02143">è®ºæ–‡ï¼šhttps://arxiv.org/abs/2004.02143</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>é—®é¢˜ç”Ÿæˆè¯•å›¾è§£å†³é—®é¢˜å›ç­”çš„é€†å‘é—®é¢˜ï¼Œé€šè¿‡ç»™å®šä¸€ä¸ªæ–‡ä»¶å’Œä¸€ä¸ªç­”æ¡ˆæ¥ç”Ÿæˆä¸€ä¸ªè‡ªç„¶è¯­è¨€é—®é¢˜ã€‚æœ¬æ–‡æ—¨åœ¨ä½¿ç”¨å¤šä¸ªæ”¯æŒæ€§äº‹å®æ¥ç”Ÿæˆé«˜è´¨é‡çš„é—®é¢˜ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>é‡‡ç”¨äº†å¤šè·³é—®é¢˜ç”Ÿæˆï¼Œæ ¹æ®ä¸Šä¸‹æ–‡ä¸­çš„æ”¯æŒäº‹å®ç”Ÿæˆç›¸å…³é—®é¢˜ã€‚é‡‡ç”¨äº†å¤šä»»åŠ¡å­¦ä¹ çš„æ–¹å¼ï¼Œå¹¶è¾…ä»¥answer-awareæ”¯æŒæ€§äº‹å®é¢„æµ‹çš„ä»»åŠ¡æ¥æŒ‡å¯¼é—®é¢˜ç”Ÿæˆå™¨ã€‚</p><p>é—®é¢˜ç”Ÿæˆç¤ºä¾‹ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210513095858.png" alt="image-20210513095855246"></p><p>å¤„ç†å¤šè·³é—®é¢˜ç”Ÿæˆçš„ä¸¤ä¸ªé˜¶æ®µï¼š</p><p>åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œå­¦ä¹ æ”¯æŒæ€§äº‹å®æ„awareçš„ç¼–ç å™¨è¡¨ç¤ºï¼Œé€šè¿‡ä¸é—®é¢˜ç”Ÿæˆçš„è”åˆè®­ç»ƒæ¥é¢„æµ‹æ–‡æ¡£ä¸­çš„æ”¯æŒæ€§äº‹å®ï¼Œéšåå¢å¼ºè¿™äº›æ”¯æŒæ€§äº‹å®çš„åˆ©ç”¨ã€‚</p><p>åè€…çš„ç›®æ ‡è¢«è¡¨è¿°ä¸ºä¸€ä¸ªé—®é¢˜æ„è¯†åˆ°çš„æ”¯æŒæ€§äº‹å®é¢„æµ‹å¥–åŠ±ï¼Œå®ƒä¸ç›‘ç£åºåˆ—æŸå¤±ä¸€èµ·è¢«ä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°å¤šä»»åŠ¡æ¡†æ¶ä¸ºé—®é¢˜ç”Ÿæˆçš„æ€§èƒ½æä¾›äº†å®è´¨æ€§çš„æ”¹è¿›ï¼Œä¹Ÿé¿å…äº†åœ¨ç”Ÿæˆçš„é—®é¢˜ä¸­åŒ…å«å™ªå£°å¥å­ä¿¡æ¯ï¼Œè€Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å°†å®Œæ•´å’Œå¤æ‚çš„é—®é¢˜å¸¦åˆ°å…¶ä»–æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰ä¼˜åŒ–çš„QGæ¨¡å‹ä¸­ã€‚</p><h3 id="Multi-Hop-Question-Generation-Model"><a href="#Multi-Hop-Question-Generation-Model" class="headerlink" title="Multi-Hop Question Generation Model"></a>Multi-Hop Question Generation Model</h3><p>ç»„ä»¶ï¼š</p><ul><li><p>Document and Answer Encoder</p><blockquote><p>ç¼–ç æ–‡æ¡£é›†å¹¶å›ç­”ä»¥è¿›ä¸€æ­¥ç”Ÿæˆé—®é¢˜ã€‚</p><p>ä½¿ç”¨Bi-LSTMç½‘ç»œã€‚</p></blockquote></li><li><p>Multi-task Learning</p><blockquote><p>æ–¹ä¾¿QGæ¨¡å‹è‡ªåŠ¨é€‰æ‹©æ”¯æŒäº‹å®ä»¥äº§ç”Ÿé—®é¢˜ã€‚</p></blockquote></li><li><p>Question Decoder</p><blockquote><p>ä½¿ç”¨pointer-generatoræœºåˆ¶ç”Ÿæˆé—®é¢˜ã€‚</p></blockquote></li><li><p>MultiHop-Enhanced QG</p><blockquote><p>æœ€å¤§é™åº¦åœ°æé«˜åŸºäºå¥–åŠ±çš„æ”¯æŒäº‹å®é¢„æµ‹ã€‚</p><p>Question-Aware Supporting Fact Prediction ç½‘ç»œç”¨æ¥é¢„æµ‹æ¯ä¸ªå€™é€‰å¥å­çš„æ”¯æŒäº‹å®æ¦‚ç‡ã€‚</p><p>ä½¿ç”¨binary cross-entropyæŸå¤±å‡½æ•°ã€‚</p></blockquote></li></ul><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210513104059.png" alt="image-20210513104057610"></p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>HotPotQA</li></ul><h2 id="æ€§èƒ½æ°´å¹³-amp-ç»“è®º"><a href="#æ€§èƒ½æ°´å¹³-amp-ç»“è®º" class="headerlink" title="æ€§èƒ½æ°´å¹³&amp;ç»“è®º"></a>æ€§èƒ½æ°´å¹³&amp;ç»“è®º</h2><ul><li>æ€§èƒ½æ¯”è¾ƒï¼š</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210514093029.png" alt="image-20210514093025859"></p><p>åœ¨HotpotQAæµ‹è¯•é›†ä¸Šï¼Œæœ¬æ–‡æå‡ºçš„æ¨¡å‹åœ¨BLEUè¯„æµ‹æŒ‡æ ‡ä¸Šéƒ½å–å¾—äº†æœ€ä¼˜çš„æ€§èƒ½ã€‚åœ¨æ”¯æŒäº‹å®è¦†ç›–ï¼ˆSF coverageï¼‰çš„å¤šè·³é—®é¢˜æ¨ç†ä¸­ä¹Ÿå–å¾—äº†æœ€ä¼˜çš„æ•ˆæœã€‚</p><ul><li>æ¶ˆèå®éªŒï¼š</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210514145811.png" alt="image-20210514145811434" style="zoom:50%;" /></p><p>ä½¿ç”¨å…±äº«ç¼–ç å™¨æä¾›å¤šä»»åŠ¡å­¦ä¹ æœ‰åŠ©äºæ¨¡å‹ åœ¨BLEU-4è¯„æµ‹ä¸‹æé«˜QGæ€§èƒ½ã€‚ </p><p>ä»ç­”æ¡ˆæ„ŸçŸ¥æ”¯æŒäº‹å®é¢„æµ‹ä»»åŠ¡ä¸­è·å¾—çš„æ”¯æŒäº‹å®ä¿¡æ¯è¿›ä¸€æ­¥æé«˜BLEU-4çš„QGæ€§èƒ½ã€‚</p><p>é€šè¿‡åœ¨ä¸¤ä¸ªä»»åŠ¡ä¹‹é—´å…±äº«æ–‡æ¡£ç¼–ç å™¨ï¼Œç½‘ç»œå¯¹è¾“å…¥æ–‡æ¡£å¯ä»¥æ›´å¥½çš„è¿›è¡Œç¼–ç ã€‚ èƒ½å¤Ÿåœ¨å¤„ç†å¤šä¸ªæ–‡æ¡£æ—¶æœ‰æ•ˆåœ°è¿‡æ»¤ä¸ç›¸å…³çš„ä¿¡æ¯å¹¶å¯¹é—®é¢˜ç”Ÿæˆè¿›è¡Œå¤šè·³æ¨ç†ã€‚</p><ul><li>ç»“è®º</li></ul><p>é€šè¿‡åœ¨å¤šè·³é—®é¢˜å›ç­”æ•°æ®é›†HotPotQAä¸Šçš„å®éªŒï¼Œè¯æ˜äº†æœ¬æ–‡æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ç»éªŒè¯„ä¼°è¡¨æ˜ï¼Œæœ¬æ–‡çš„æ¨¡å‹åœ¨è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚BLEUã€METEORå’ŒROUGEï¼‰å’Œäººå·¥è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚ç”Ÿæˆé—®é¢˜çš„è´¨é‡å’Œè¦†ç›–ç‡ï¼‰æ–¹é¢éƒ½ä¼˜äºå•è·³ç¥ç»é—®é¢˜ç”Ÿæˆæ¨¡å‹ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> QG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-Hop Paragraph Retrieval for Open-Domain Question Answering</title>
      <link href="/2021/05/07/Multi-Hop%20Paragraph%20Retrieval%20for%20Open-Domain%20Question%20Answering/"/>
      <url>/2021/05/07/Multi-Hop%20Paragraph%20Retrieval%20for%20Open-Domain%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-Hop-Paragraph-Retrieval-for-Open-Domain-Question-Answering"><a href="#Multi-Hop-Paragraph-Retrieval-for-Open-Domain-Question-Answering" class="headerlink" title="Multi-Hop Paragraph Retrieval for Open-Domain Question Answering"></a>Multi-Hop Paragraph Retrieval for Open-Domain Question Answering</h1><blockquote><p> <a href="https://arxiv.org/abs/1906.06606">è®ºæ–‡ï¼šhttps://arxiv.org/abs/1906.06606</a></p><p> <a href="https://github.com/yairf11/MUPPET">ä»£ç ï¼šhttps://github.com/yairf11/MUPPET</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>å¤šè·³å¼€æ”¾åŸŸé—®é¢˜å›ç­”(QA)ä»»åŠ¡ï¼Œéœ€è¦åŒæ—¶è¿›è¡Œæ–‡æœ¬æ¨ç†å’Œé«˜æ•ˆæœç´¢ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ£€ç´¢å¤šä¸ªæ”¯æŒæ®µè½çš„æ–¹æ³•ï¼Œè¿™äº›æ®µè½åµŒå¥—åœ¨ä¸€ä¸ªåºå¤§çš„ï¼ŒåŒ…å«å›ç­”ä¸€ä¸ªç»™å®šé—®é¢˜çš„å¿…è¦è¯æ®çš„çŸ¥è¯†åº“ä¸­ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>æœ¬æ–‡æå‡ºçš„æ–¹æ³•é€šè¿‡å½¢æˆä¸€ä¸ªé—®é¢˜å’Œæ®µè½çš„è”åˆå‘é‡è¡¨ç¤ºæ¥åå¤æ£€ç´¢æ”¯æŒæ€§æ®µè½ã€‚æ£€ç´¢æ˜¯é€šè¿‡è€ƒè™‘çŸ¥è¯†æºä¸­æ®µè½çš„ä¸Šä¸‹æ–‡å¥å­å±‚é¢çš„è¡¨ç¤ºæ¥è¿›è¡Œçš„ã€‚</p><ul><li><strong>ä»»åŠ¡å®šä¹‰ï¼š</strong></li></ul><p>$(KS, Q, A)$</p><p>Background knowledge sourceï¼š$KS = {P<em>1, P_2, . . . , P</em>{|KS|}}$</p><p>ç”±$l<em>i$ ä¸ªtokensç»„æˆçš„æ–‡æœ¬æ®µè½ï¼š$P_i = (p_1, p_2, . . . , p</em>{l_i})$</p><p>mä¸ªtokensç»„æˆçš„æ®µè½ï¼š$Q = (q_1, q_2, . . . , q_m)$</p><p>nä¸ªtokensç»„æˆçš„ç­”æ¡ˆï¼š$A = (a_1, a_2, . . . , a_n)$</p><ul><li><strong>ç›®æ ‡ï¼š</strong></li></ul><p>ä½¿ç”¨èƒŒæ™¯çŸ¥è¯†æºKSæ‰¾åˆ°å¯¹é—®é¢˜Qçš„ç­”æ¡ˆAã€‚</p><p>$A = Ï†(Q, KS)$</p><ul><li><strong>æ–¹æ³•ï¼š</strong></li></ul><p><strong>MUPPET (multi-hop paragraph retrieval)</strong></p><p>ä¸¤ä¸ªç»„ä»¶</p><blockquote><p>paragraph and question encoder</p><ul><li>æ®µè½ç¼–ç ä¸ä¾èµ–äºé—®é¢˜ã€‚</li></ul><p>paragraph reader</p></blockquote><p>ä½¿ç”¨MIPS(maximum inner product search)ç®—æ³•æ£€ç´¢æœ€æœ‰å¯èƒ½åŒ…å«ç­”æ¡ˆçš„æ®µè½ï¼Œç„¶åå°†çš„æ®µè½ä¼ é€’ç»™é˜…è¯»å™¨æ¨¡å—ï¼Œæå–é—®é¢˜æœ€æœ‰å¯èƒ½çš„ç­”æ¡ˆã€‚</p><p>æ”¯æŒå¤šè·³æ£€ç´¢ï¼š</p><p>å¯¹äºé—®é¢˜$Q$ï¼Œç¼–ç ä¸º$q$ï¼Œè½¬æ¢æˆæœç´¢ç©ºé—´å‘é‡$q^s$ï¼Œç”¨æ¥æ£€ç´¢ï¼ˆä½¿ç”¨MIPSç®—æ³•ï¼‰top-kç›¸å…³æ®µè½${P^Q<em> 1, P^Q _2, . . . , P^Q</em> k} âŠ‚ KS$ï¼Œä»æ£€ç´¢æ®µè½ä¸­é‡æ„æœç´¢å‘é‡ï¼Œ${\tilde q^s<em> 1, \tilde q^s</em> 2, . . . , \tilde q^s_ k}$ï¼Œå†æ‰§è¡Œä¸€éæ£€ç´¢è¿‡ç¨‹ï¼Œå¯æ£€ç´¢å‡ºä¸‹ä¸€ä¸ªtop-kç›¸å…³æ®µè½ã€‚</p><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210506144838.png" alt="image-20210506144811702"></p><h3 id="Paragraph-and-Question-Encoder"><a href="#Paragraph-and-Question-Encoder" class="headerlink" title="Paragraph and Question Encoder"></a>Paragraph and Question Encoder</h3><p>æ®µè½Pç”±kä¸ªæ®µè½ç»„æˆ</p><p>$P=(s_1, s_2, . . . , s_k)$</p><p>æ¯ä¸ªæ®µè½ç”±$l$ä¸ªtokensç»„æˆ</p><p>$s<em>i=(t</em>{i<em>1}, t</em>{i<em>2}, . . . , t</em>{i_l})$</p><blockquote><p>$l$ï¼šå¥å­é•¿åº¦</p></blockquote><p>ç¼–ç ï¼š</p><script type="math/tex; mode=display">(s_1, s_2, . . . , s_k)= f(P)</script><script type="math/tex; mode=display">q = f(Q)</script><h3 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h3><p>$t^w$ï¼šword-level embedding é€šè¿‡é¢„è®­ç»ƒçš„Word Embeddingè·å¾—ã€‚</p><p>$t^c$ï¼šcharacter-level embedding</p><p>token t æœ‰$l<em>t$ä¸ªå­—ç¬¦$(t</em>{1}^c, t<em>{2}^c, . . . , t</em>{l_t}^c)$</p><script type="math/tex; mode=display">t^c= max(CNN(t_{1}^c, t_{2}^c, . . . , t_{l_t}^c))</script><p>è¿æ¥ä¸¤ç§åµŒå…¥å½¢å¼ï¼š</p><script type="math/tex; mode=display">t = [t^w; t^c]</script><h3 id="Recurrent-Layer"><a href="#Recurrent-Layer" class="headerlink" title="Recurrent Layer"></a>Recurrent Layer</h3><p>è·å¾—word representationsä¹‹åï¼Œé€šè¿‡BiGRUè·å¾— contextualized word representationsã€‚</p><script type="math/tex; mode=display">(c_1, c_2, . . . , c_m) = BiGRU(t_1, t_2, . . . , t_m)</script><h3 id="Sentence-wise-max-pooling"><a href="#Sentence-wise-max-pooling" class="headerlink" title="Sentence-wise max-pooling"></a>Sentence-wise max-pooling</h3><p>ä½¿ç”¨max-poolingè·å¾—sentence representationsã€‚</p><script type="math/tex; mode=display">s_i=max(c_{i_1}, c_{i_2}, . . . , c_{i_l})</script><h3 id="Reformulation-Component"><a href="#Reformulation-Component" class="headerlink" title="Reformulation Component"></a>Reformulation Component</h3><p>ä½¿ç”¨recurrent layersåˆå§‹åŒ–é—®é¢˜Qå’Œæ®µè½Pçš„ç¼–ç ã€‚</p><p>$(c^q<em> 1, c^q</em> 2, . . . , c^q_{ n_q})$</p><p>$(c^p<em> 1, c^p</em> 2, . . . , c^p_{ n_p})$</p><p>ä¼ é€’ç»™bidirectional attention layerã€‚ä½¿ç”¨ReLUä½œä¸ºæ¿€æ´»å‡½æ•°ã€‚æœ€ç»ˆå¾—åˆ°reformulated question representation, $\tilde q$</p><p>Reformulation Componentå›¾ç¤ºï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210506145718.png" alt="image-20210506145716584" style="zoom:50%;" /></p><p>Sentence Encoder å›¾ç¤ºï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210506145108.png" alt="image-20210506145106251" style="zoom:50%;" /></p><h3 id="Paragraph-Reader"><a href="#Paragraph-Reader" class="headerlink" title="Paragraph Reader"></a>Paragraph Reader</h3><p>æ®µè½é˜…è¯»å™¨æ¥è¾“å…¥ä¸ºé—®é¢˜Qå’Œæ®µè½Pï¼Œå¹¶ä»Pä¸­æå–æœ€å¯èƒ½çš„ç­”æ¡ˆè·¨åº¦ã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>HotpotQA</li><li>SQuAD-Open</li></ul><h2 id="æ€§èƒ½æ°´å¹³å’Œç»“è®º"><a href="#æ€§èƒ½æ°´å¹³å’Œç»“è®º" class="headerlink" title="æ€§èƒ½æ°´å¹³å’Œç»“è®º"></a>æ€§èƒ½æ°´å¹³å’Œç»“è®º</h2><ul><li>HotpotQAæ•°æ®é›†ï¼š</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210507110944.png" alt="image-20210507110940732"></p><p>åœ¨HotpotQA distractor settingä¸‹ï¼ŒJoint EMå’ŒF1è¯„åˆ†æå‡æœ€ä¸ºæ˜¾è‘—ï¼Œåˆ†åˆ«æå‡äº†17.12å’Œ13.22ã€‚</p><p>åœ¨HotpotQA full wiki settingä¸‹ï¼ŒMUPPETåœ¨æ®µè½çº§åˆ«ç¼–ç æ—¶ï¼Œæ€§èƒ½è¦ä¼˜äºå¥å­çº§ç¼–ç ã€‚</p><ul><li>SQuAD-Openæ•°æ®é›†ï¼š</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210507111826.png" alt="image-20210507111825276" style="zoom:50%;" /></p><p>åœ¨SQuAD-Openæ•°æ®é›†ä¸Šï¼Œå¥å­çº§åˆ«ç¼–ç çš„MUPPETå–å¾—äº†æœ€ä¼˜çš„æ€§èƒ½ï¼Œè¡¨æ˜æœ¬æ–‡æå‡ºçš„ç¼–ç å™¨ä¸ä»…é€‚ç”¨äºå¤šè·³é—®é¢˜ï¼Œè¿˜å¯ä»¥ç”¨äºå•è·³é—®é¢˜ã€‚</p><p>ç»“è®ºï¼š</p><p>æœ¬æ–‡æå‡ºçš„MUPPETï¼Œç”¨äºå¤šè·³æ®µè½æ£€ç´¢åœ¨å•è·³å’Œå¤šè·³QAæ•°æ®é›†ä¸Šéƒ½å–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> MUPPET </tag>
            
            <tag> BiGRU </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning to Prune Dependency Trees with Rethinking for Neural Relation Extraction</title>
      <link href="/2021/05/01/Learning%20to%20Prune%20Dependency%20Trees%20with%20Rethinking%20for%20Neural%20Relation%20Extraction/"/>
      <url>/2021/05/01/Learning%20to%20Prune%20Dependency%20Trees%20with%20Rethinking%20for%20Neural%20Relation%20Extraction/</url>
      
        <content type="html"><![CDATA[<h1 id="Learning-to-Prune-Dependency-Trees-with-Rethinking-for-Neural-Relation-Extraction"><a href="#Learning-to-Prune-Dependency-Trees-with-Rethinking-for-Neural-Relation-Extraction" class="headerlink" title="Learning to Prune Dependency Trees with Rethinking for Neural Relation Extraction"></a>Learning to Prune Dependency Trees with Rethinking for Neural Relation Extraction</h1><blockquote><p> <a href="https://www.aclweb.org/anthology/2020.coling-main.341/">è®ºæ–‡ï¼šhttps://www.aclweb.org/anthology/2020.coling-main.341/</a></p><p> <a href="2https://github.com/Cartus/AGGCN">ä»£ç ï¼šhttps://github.com/Cartus/AGGCN</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>â€‹        é¢„æµ‹ç»™å®šå¥å­ä¸­çš„ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„å…³ç³»ã€‚</p><p>â€‹        åˆ©ç”¨è¾“å…¥å¥å­çš„ä¾èµ–æ ‘æ¨¡å‹åœ¨æ•è·ç›®æ ‡å®ä½“ä¹‹é—´çš„é•¿è·ç¦»å…³ç³»æ–¹é¢æ˜¯æœ‰æ•ˆçš„ã€‚ä½†å¹¶ä¸æ˜¯æ‰€æœ‰ä¾èµ–æ ‘ä¸­çš„æ ‡è®°éƒ½éœ€è¦è¡¨è¾¾ç›®æ ‡å®ä½“å¯¹çš„å…³ç³»ï¼Œä¸€äº›ä¸ç›®æ ‡ä¸ç›¸å…³çš„æ ‡è®°å¯èƒ½ä¼šå¼•å…¥å™ªéŸ³ã€‚å¦‚ä½•æœ‰é€‰æ‹©åœ°å¼ºè°ƒç›®æ ‡ç›¸å…³çš„ä¿¡æ¯ï¼Œå¹¶ä»ä¾èµ–æ ‘ä¸Šåˆ é™¤ä¸ç›¸å…³çš„å†…å®¹ï¼Œä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾çš„é—®é¢˜ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><blockquote><p>REï¼šRelation extraction  æ—¨åœ¨æ£€æµ‹å‡ºç°åœ¨å¥å­ä¸­å‡ºç°çš„ä¸¤ä¸ªç‰¹å®šå®ä½“ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼ˆé€šå¸¸åˆ†åˆ«è¢«ç§°ä¸ºä¸»é¢˜å’Œå¯¹è±¡ï¼‰ã€‚</p></blockquote><p>â€‹        ç”±äºè‡ªç„¶è¯­è¨€çš„å¯å˜æ€§å’Œæ¨¡ç³Šæ€§ï¼Œä¹‹å‰æ‰‹å·¥åˆ¶å®šçš„ä¿®å‰ªè§„åˆ™å¯èƒ½å¯¼è‡´æœ‰ç”¨çš„ä¿¡æ¯è¢«é—æ¼ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŠ¨æ€ä¿®å‰ªå›¾å·ç§¯ç½‘ç»œï¼ˆDP-GCNï¼‰çš„æ–°æ¶æ„ï¼Œå®ƒåœ¨ç«¯åˆ°ç«¯çš„æ–¹æ¡ˆä¸­å­¦ä¹ ä¿®å‰ªä¾èµ–æ ‘ï¼Œå¹¶è¿›è¡Œé‡æ–°æ€è€ƒã€‚åœ¨DP-GCNçš„æ¯ä¸€å±‚ï¼Œé‡‡ç”¨äº†ä¸€ä¸ªé€‰æ‹©æ¨¡å—ï¼ŒåŠ¨æ€åœ°è¯†åˆ«ä¾èµ–æ ‘ä¸­çš„å…³é”®èŠ‚ç‚¹å­é›†ï¼Œè¿™äº›èŠ‚ç‚¹æä¾›è¶³å¤Ÿçš„ä¿¡æ¯æ¥æå–ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„å…³ç³»ï¼Œè€ƒè™‘åˆ°æ¯ä¸ªèŠ‚ç‚¹å’Œç›®æ ‡å®ä½“çš„è¯­ä¹‰ï¼Œç”Ÿæˆä¸€ç»„ä¾èµ–è¾“å…¥çš„äºŒè¿›åˆ¶é—¨æ¥å†³å®šæ˜¯å¦åº”è¯¥ä¿ç•™è¯¥èŠ‚ç‚¹ã€‚ä¸ºäº†è§£å†³ä¾èµ–æ ‘çš„ç¨€ç–é˜»ç¢èŠ‚ç‚¹ä¹‹é—´çš„ä¿¡æ¯ä¼ æ’­ï¼Œä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶äº§ç”Ÿçš„ä¿®å‰ªè¿‡çš„è¯­ä¹‰å›¾æ¥åŠ å¼ºä¿®å‰ªè¿‡çš„æ ‘ï¼Œä»¥ç¡®ä¿è¿é€šæ€§ã€‚ä¹‹åï¼Œåˆ©ç”¨GCNæ¨¡å—æ¥æ›´æ–°å®ä½“ç‰¹å®šçš„ä¸Šä¸‹æ–‡è¡¨å¾ã€‚å¼•å…¥äº†ä¸€ä¸ªåæ€æœºåˆ¶ï¼Œé€šè¿‡åå¤åé¦ˆé«˜çº§åˆ«çš„å­¦ä¹ ç‰¹å¾æ¥æŒ‡å¯¼å’Œå®Œå–„å‰ªææ“ä½œã€‚</p><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210428111023.png" alt="image-20210428105439620"></p><h3 id="BiLSTM-encoderï¼šå°†è¾“å…¥å•è¯è½¬æ¢ä¸ºä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºã€‚"><a href="#BiLSTM-encoderï¼šå°†è¾“å…¥å•è¯è½¬æ¢ä¸ºä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºã€‚" class="headerlink" title="BiLSTM encoderï¼šå°†è¾“å…¥å•è¯è½¬æ¢ä¸ºä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºã€‚"></a>BiLSTM encoderï¼šå°†è¾“å…¥å•è¯è½¬æ¢ä¸ºä¸Šä¸‹æ–‡åŒ–è¡¨ç¤ºã€‚</h3><p>DP-GCNï¼šå°†å®ä½“ä¿¡æ¯ç»“åˆåˆ°å›¾å½¢å»ºæ¨¡è¿‡ç¨‹ä¸­ï¼Œå¹¶ä¸ºç»™å®šå®ä½“è¿‡æ»¤æ— ç”¨çš„ä¿¡æ¯ã€‚</p><p>pooling moduleï¼šèšåˆDP-GCNå±‚åŒ…å«çš„çš„èŠ‚ç‚¹è¡¨ç¤ºã€‚</p><p>Contextual Encoderï¼š</p><script type="math/tex; mode=display">hi= [\overrightarrow{LSTM}(x_i);\leftarrow{LSTM}(x_i)], i âˆˆ [1, n]</script><p>$X = [x_1, â€¦, x_n]$ï¼šè¡¨ç¤ºå¥å­ä¸­çš„nä¸ªå•è¯ã€‚</p><p>$H = [h_1, Â· Â· Â· , h_n]$ï¼šLSTMéšè—å±‚å‘é‡ã€‚</p><h3 id="Dynamically-Pruned-GCN"><a href="#Dynamically-Pruned-GCN" class="headerlink" title="Dynamically Pruned GCN"></a>Dynamically Pruned GCN</h3><p>ä¾èµ–æ ‘ä¸­çš„èŠ‚ç‚¹è¡¨ç¤ºå¥å­ä¸­çš„å•è¯ï¼Œè¾¹è¡¨ç¤ºå•è¯ä¹‹é—´è¯­æ³•ä¾èµ–è·¯å¾„ã€‚</p><p>é‡‡ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¿è¯å›¾çš„è¿é€šæ€§ã€‚</p><p>GCNï¼š</p><script type="math/tex; mode=display">h^l_i= g(\sum ^n _{j=1}A_{ij}W^lh^{l-1}_j+ b^l)</script><p>$A$ï¼šä¾èµ–æ ‘å›¾ä¸­nä¸ªèŠ‚ç‚¹çš„é‚»æ¥çŸ©é˜µã€‚</p><p>$W^l$ï¼šçº¿æ€§transformationã€‚</p><p>$g$ ï¼šéçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆRELUï¼‰ã€‚</p><p><strong>é€‰æ‹©æ¨¡å—ï¼š</strong></p><p>â€‹        çŸ©é˜µ<strong>A</strong>åŒ…å«äº†è®¸å¤šä¸ç›®æ ‡å®ä½“å¯¹æ— å…³çš„èŠ‚ç‚¹ã€‚å› æ­¤ï¼Œåœ¨æ¯ä¸€å±‚ï¼Œè®¾è®¡äº†ä¸€ä¸ªé€‰æ‹©æ¨¡å—æ¥ç†è§£å®ä½“çš„å…·ä½“ç¯å¢ƒï¼Œå¹¶ä»å›¾ä¸­åŠ¨æ€åœ°é€‰æ‹©å‡ºå…³é”®çš„ç›®æ ‡ç›¸å…³èŠ‚ç‚¹ã€‚</p><p>â€‹    å¼•å…¥ä¸€ç»„äºŒè¿›åˆ¶é—¨${z^l _1, Â· Â· Â· , z_l ^n}$ï¼Œå…³è”åˆ°æ¯ä¸ªèŠ‚ç‚¹ã€‚$z_l ^n$ï¼šå–å€¼ä¸º0/1ï¼Œè¡¨ç¤ºç¬¬$l$å±‚åº•$i$ä¸ªé—¨ã€‚</p><script type="math/tex; mode=display">\hat{A}^l_{ij}=\frac{z^l_j \cdot A_{ij}}{\epsilon +\sum^n_{m=1}z^l_m\cdot A_{im}}</script><p>$\hat{A}^l$ï¼šè¡¨ç¤ºç¬¬lå±‚ä¿®å‰ªä¹‹åçš„ä¾èµ–çŸ©é˜µã€‚</p><h3 id="Poolingï¼ˆmax-poolingï¼‰"><a href="#Poolingï¼ˆmax-poolingï¼‰" class="headerlink" title="Poolingï¼ˆmax-poolingï¼‰"></a>Poolingï¼ˆmax-poolingï¼‰</h3><p>ä½¿ç”¨äº†ä¸€ä¸ªçº¿æ€§ç»„åˆæ¥æ•´åˆæ¥è‡ªä¸åŒå±‚çš„è¡¨å¾ï¼Œå…è®¸æ•è·ä¸°å¯Œçš„æœ¬åœ°å’Œéæœ¬åœ°ä¿¡æ¯ã€‚</p><script type="math/tex; mode=display">h^{comb}_ i = W^{comb}[h^1_ i; Â· Â· Â· ; h^L_ i] + b^{comb}</script><script type="math/tex; mode=display">h_{sent}= F(h^{comb}_{1:n})</script><script type="math/tex; mode=display">r = [h_{sent}; h_{subj}; h_{obj}]</script><p>$h^{comb}_ i $ï¼štoken içš„ç»„åˆå‘é‡ã€‚</p><p>$W_{comb}$ï¼šæƒå€¼çŸ©é˜µã€‚</p><p>Fï¼šmax-pooling</p><h3 id="Rethinking-Mechanism"><a href="#Rethinking-Mechanism" class="headerlink" title="Rethinking Mechanism"></a>Rethinking Mechanism</h3><p>åœ¨æ± åŒ–è¿‡ç¨‹åå¼•å…¥Rethinking Mechanismæœºåˆ¶ï¼Œå°†æ± åŒ–æ¨¡å—çš„è¾“å‡ºä½œä¸ºé«˜çº§ç‰¹å¾ï¼Œå¹¶é€šè¿‡åœ¨æ¯ä¸ªDP-GCNå±‚å¼•å…¥åé¦ˆè¿æ¥ï¼Œåˆ©ç”¨è¿™äº›ç‰¹å¾æ¥è°ƒæ•´é€‰æ‹©æ¨¡å—çš„é—¨å€¼ã€‚ç½‘ç»œè¢«èµ‹äºˆäº†è‡ªé€‚åº”å®Œå–„ä¿®å‰ªæ“ä½œçš„èƒ½åŠ›ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£ç‰¹å®šç›®æ ‡çš„è¯­ä¹‰ã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>TACRED</li><li>SemEval</li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210501094735.png" alt="image-20210501094449787"></p><p>åœ¨TACREDæµ‹è¯•æ•°æ®é›†ä¸Šï¼Œæ€§èƒ½è¶…è¿‡äº†åŸºçº¿æ¨¡å‹ï¼Œç›¸æ¯”å¤§å¤šæ•°æ¨¡å‹æ€§èƒ½éƒ½æœ‰æ‰€æå‡ï¼Œå¹¶å–å¾—äº†æœ€é«˜çš„F1å¾—åˆ†ã€‚</p><p>å‡†ç¡®åº¦å’Œå¬å›ç‡çš„æé«˜ä¹Ÿè¡¨æ˜äº†åŠ¨æ€ä¿®å‰ªçš„æœ‰æ•ˆæ€§ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210501095848.png" alt="image-20210501095848865" style="zoom:50%;" /></p><p>åœ¨SemEvalæ•°æ®é›†ä¸Šï¼ŒDP-GCNåŒæ ·å–å¾—äº†æœ€ä¼˜çš„æ€§èƒ½ã€‚è¯æ˜äº†åˆ©ç”¨è¾“å…¥å¥å­çš„ä¾èµ–æ ‘æ¨¡å‹åœ¨æ•è·ç›®æ ‡å®ä½“ä¹‹é—´çš„é•¿è·ç¦»å…³ç³»æ–¹é¢æ˜¯æœ‰æ•ˆçš„ã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><h3 id="æ¶ˆèå®éªŒï¼š"><a href="#æ¶ˆèå®éªŒï¼š" class="headerlink" title="æ¶ˆèå®éªŒï¼š"></a>æ¶ˆèå®éªŒï¼š</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210501101611.png" alt="image-20210501101139982" style="zoom:50%;" /></p><p>å®éªŒè¡¨æ˜é€‰æ‹©æ¨¡å—ã€æ€è€ƒæœºåˆ¶ã€ä¾èµ–æ ‘ç»“æ„ã€äºŒè¿›åˆ¶é—¨æ§å‡½æ•°å¯¹æ¨¡å‹æ€§èƒ½éƒ½æœ‰å½±å“ã€‚</p><p>ç»“è®ºï¼š</p><p>â€‹        æœ¬æ–‡æå‡ºçš„DP-GCNæ¨¡å‹ï¼Œé€šè¿‡åœ¨æ¯ä¸ªGCNå±‚ä¸­åŠ å…¥é€‰æ‹©æ¨¡å‹ï¼Œè¿‡æ»¤æ‰ä¸ç›®æ ‡ä¸ç›¸å…³çš„ä¿¡æ¯ï¼Œä¸ä¾èµ–ä»»ä½•é¢„å…ˆå®šä¹‰çš„è§„åˆ™ã€‚å¹¶ä¸”åŠ å…¥ä¸€ä¸ªåæ€æœºåˆ¶ï¼ŒåŠ¨æ€å®ç°å‰ªææ“ä½œã€‚åœ¨ä¸¤ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæå‡ºçš„æ¨¡å‹è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> DP-GCN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-hop Reading Comprehension through Question Decomposition and Rescoring</title>
      <link href="/2021/04/24/ACL2019-Multi-hop%20Reading%20Comprehension%20through%20Question%20Decomposition%20and%20Rescoring.pdf/"/>
      <url>/2021/04/24/ACL2019-Multi-hop%20Reading%20Comprehension%20through%20Question%20Decomposition%20and%20Rescoring.pdf/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-hop-Reading-Comprehension-through-Question-Decomposition-and-Rescoring"><a href="#Multi-hop-Reading-Comprehension-through-Question-Decomposition-and-Rescoring" class="headerlink" title="Multi-hop Reading Comprehension through Question Decomposition and Rescoring"></a>Multi-hop Reading Comprehension through Question Decomposition and Rescoring</h1><blockquote><p> <a href="https://arxiv.org/abs/1906.02916">è®ºæ–‡ï¼šhttps://arxiv.org/abs/1906.02916</a></p><p> <a href="https://github.com/shmsw25/DecompRC">ä»£ç ï¼šhttps://github.com/shmsw25/DecompRC</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>å¤šè·³é˜…è¯»ç†è§£ï¼ˆRCï¼‰éœ€è¦åœ¨å‡ ä¸ªæ®µè½ä¸­è¿›è¡Œæ¨ç†å’Œæ±‡æ€»ã€‚æœ¬æ–‡æå‡ºäº†å°†ä¸€ä¸ªç»„åˆå¼é—®é¢˜åˆ†è§£ä¸ºæ›´ç®€å•çš„å­é—®é¢˜çš„å¤šè·³é˜…è¯»ç†è§£ç³»ç»Ÿï¼Œä¼¼çš„è¿™äº›åˆ†è§£çš„å­é—®é¢˜å¯ä»¥ç”±ç°æˆçš„å•è·³é˜…è¯»æ¨¡å‹æ¥å›ç­”ã€‚ç”±äºè¿™ç§åˆ†è§£çš„æ³¨é‡Šä»£ä»·å¾ˆé«˜ï¼Œæœ¬æ–‡å°†å­é—®é¢˜çš„ç”Ÿæˆé‡å¡‘ä¸ºä¸€ä¸ªè·¨åº¦é¢„æµ‹é—®é¢˜ï¼Œæ¥ç”Ÿæˆç±»ä¼¼äºäººç±»æå‡ºçš„é—®é¢˜ã€‚</p><p>å¤šè·³é—®é¢˜åˆ†è§£ä¸ºå•è·³å­é—®é¢˜ç¤ºä¾‹ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210423100215.png" alt="image-20210423100215572" style="zoom:50%;" /></p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é‡æ–°è¯„åˆ†çš„æ–¹æ³•ï¼Œä»ä¸åŒçš„å¯èƒ½çš„åˆ†è§£ä¸­è·å¾—ç­”æ¡ˆï¼Œå¹¶å¯¹æ¯ä¸ªåˆ†è§£çš„ç­”æ¡ˆé‡æ–°è¯„åˆ†ï¼Œä»¥å†³å®šæœ€ç»ˆçš„ç­”æ¡ˆï¼Œè€Œä¸æ˜¯ä¸€å¼€å§‹å°±å†³å®šåˆ†è§£çš„ç­”æ¡ˆã€‚</p><p><strong>DECOMPRCæ¨¡å‹å®ç°æ–¹æ³•ï¼š</strong></p><ol><li>é¦–å…ˆï¼ŒDECOMPRCæ ¹æ®è·¨åº¦é¢„æµ‹ï¼Œå°†åŸå§‹çš„å¤šè·³é—®é¢˜æŒ‰ç…§å‡ ä¸ªæ¨ç†ç±»å‹å¹³è¡Œåœ°åˆ†è§£æˆå‡ ä¸ªå•è·³çš„å­é—®é¢˜ã€‚</li><li>ç„¶åï¼Œå¯¹äºæ¯ä¸ªæ¨ç†ç±»å‹ï¼ŒDECOMPRCåˆ©ç”¨å•è·³é˜…è¯»ç†è§£æ¨¡å‹æ¥å›ç­”æ¯ä¸ªå­é—®é¢˜ï¼Œå¹¶æ ¹æ®æ¨ç†ç±»å‹æ¥ç»„åˆç­”æ¡ˆã€‚</li><li>æœ€åï¼ŒDECOMPRCåˆ©ç”¨äº†åˆ†è§£å¾—åˆ†æ•°æ¥åˆ¤æ–­å“ªä¸ªåˆ†è§£æ˜¯æœ€åˆé€‚çš„ï¼Œå¹¶å°†è¯¥åˆ†è§£çš„ç­”æ¡ˆè¾“å‡ºä¸ºæœ€ç»ˆç­”æ¡ˆã€‚</li></ol><p>ç¤ºä¾‹ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210423103807.png" alt="image-20210423103807723"></p><p><strong>æ¨ç†ç±»å‹</strong>ï¼šbridging, intersection and comparison</p><p>HotpotQAæ•°æ®é›†ä¸­æ¨ç†ç±»å‹åˆ†å¸ƒã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210423104159.png" alt="image-20210423104159546"></p><h3 id="Span-Prediction-for-Sub-question-Generation"><a href="#Span-Prediction-for-Sub-question-Generation" class="headerlink" title="Span Prediction for Sub-question Generation"></a>Span Prediction for Sub-question Generation</h3><p>è®­ç»ƒ$Pointer_c$æ¨¡å‹ï¼Œå°†ä¸€ä¸ªé—®é¢˜æ˜ å°„æˆ$c$ä¸ªç‚¹ï¼Œé€šè¿‡æ˜ å°„ç”Ÿæˆçš„ç‚¹æ¥æ”¶é›†æ³¨é‡Šï¼Œéšåå°†è¿™äº›ç‚¹ç”¨äºä¸ºæ¯ä¸ªæ¨ç†ç±»å‹ç»„æˆå­é—®é¢˜ã€‚</p><p>$S = [s_1, . . . , s_n]$ï¼šè¡¨ç¤ºå¥å­ä¸­çš„nä¸ªå•è¯ã€‚</p><p>ä½¿ç”¨BERTç¼–ç è¾“å…¥åºåˆ—S:</p><script type="math/tex; mode=display">U = BERT(S) âˆˆ R^{nÃ—h}</script><blockquote><p>næ˜¯è¾“å…¥å¥å­å•è¯ä¸ªæ•°</p><p>hæ˜¯ç¼–ç å™¨çš„è¾“å‡ºå°ºå¯¸</p></blockquote><p>è®¡ç®—æ¯ä¸ªæ˜ å°„ç‚¹çš„æ¦‚ç‡ï¼š</p><script type="math/tex; mode=display">ind_1, . . . , ind_c=   \underset{i_1<<...<<i_c} {argmax}\Pi^c_{j=1}P(i_j==ind_j)</script><p>ä½¿ç”¨single-hop RC modelå›ç­”åˆ’åˆ†çš„å­é—®é¢˜ï¼Œé¢„æµ‹4ç§ç±»å‹é—®é¢˜çš„æ¦‚ç‡ï¼Œè¿›è¡Œä¸‹ä¸€æ­¥é—®é¢˜å›ç­”ã€‚</p><script type="math/tex; mode=display">[y^{span}_ i ; y^{yes} _i ; y^{no} _i; y^{none} _i ] = max(U_i)W_1âˆˆ R_4</script><p>é€‰å®š4ç§ç±»å‹ä¸­æ¦‚ç‡è¾ƒå¤§çš„ä¸€ä¸ªä½œä¸ºé¢„æµ‹æ¦‚ç‡ï¼Œå¯¹ä¸åŒçš„é—®é¢˜ç±»å‹ï¼Œè¿›è¡Œä¸‹ä¸€æ­¥å¤„ç†ã€‚</p><p>å¦‚æœæ˜¯è·¨åº¦é—®é¢˜è¿˜éœ€è¦é¢„æµ‹è·¨åº¦çš„åŒºé—´ã€‚</p><script type="math/tex; mode=display">p^{start}_ i = softmax(U_iW_{start}) âˆˆ R_n</script><script type="math/tex; mode=display">p^{end}_ i = softmax(U_iW_{end}) âˆˆ R_n</script><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>HotpotQAæ•°æ®é›† </p><blockquote><p>Distractor settingå’ŒFull wiki setting</p></blockquote><h2 id="æ€§èƒ½æ°´å¹³-amp-ç»“è®º"><a href="#æ€§èƒ½æ°´å¹³-amp-ç»“è®º" class="headerlink" title="æ€§èƒ½æ°´å¹³&amp;ç»“è®º"></a>æ€§èƒ½æ°´å¹³&amp;ç»“è®º</h2><p>å®éªŒç»“æœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210423184100.png" alt="image-20210423184100910"></p><p>HOTPOTQA development setï¼š</p><ul><li>DECOMPRCåœ¨distractor and full wiki settings ä¸­éƒ½ä¼˜äºæ‰€æœ‰çš„åŸºçº¿ã€‚</li><li><p>æ²¡æœ‰ç»è¿‡å¤šè·³QAå¯¹è®­ç»ƒçš„DECOMPRCï¼ˆDECOMPRC-1hop trainï¼‰åœ¨æ‰€æœ‰æ•°æ®åˆ†å‰²ä¸­éƒ½è¡¨ç°å‡ºä¸é”™çš„æ€§èƒ½ã€‚</p></li><li><p>åœ¨å•è·³RCä¸Šè®­ç»ƒçš„BERTè·å¾—äº†å¾ˆé«˜çš„F1åˆ†æ•°ï¼ˆ87.21ï¼‰</p></li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210423184955.png" alt="image-20210423184955624" style="zoom:50%;" /></p><p>HOTPOTQA test set</p><blockquote><p> distractor setting and full wiki setting </p></blockquote><p>DECOMPRCåœ¨distractor setting å’Œ full wiki setting ç›¸å¯¹äºå…¶ä»–æ¨¡å‹å–å¾—äº†æœ€é«˜çš„F1åˆ†æ•°ã€‚</p><p>è¯¥æ–¹æ³•ä¹Ÿæœ‰ä¸€å®šçš„å±€é™æ€§</p><ul><li>æœ‰äº›é—®é¢˜ä¸æ˜¯ç»„åˆå¼çš„ï¼Œä½†æ˜¯éœ€è¦éšå«çš„å¤šè·³æ¨ç†ï¼Œå› æ­¤ä¸èƒ½è¢«åˆ†è§£ã€‚</li><li>æœ‰äº›é—®é¢˜å¯ä»¥è¢«åˆ†è§£ï¼Œä½†æ¯ä¸ªå­é—®é¢˜çš„ç­”æ¡ˆåœ¨æ–‡æœ¬ä¸­å¹¶ä¸æ˜ç¡®å­˜åœ¨ï¼Œè€Œæ˜¯å¿…é¡»é€šè¿‡å¸¸è¯†æ¨ç†æ¥æ¨æ–­ã€‚</li><li>æ‰€éœ€çš„æ¨ç†æœ‰æ—¶è¶…å‡ºäº†æ¨¡å‹è®¾å®šçš„å››ç§æ¨ç†ç±»å‹ï¼Œä¾‹å¦‚ç®—æ•°ç±»é—®é¢˜æ— æ³•æ¨ç†ã€‚</li></ul><p>æœ¬æ–‡å¼•å…¥ä¸€ç§æ–°çš„å…¨å±€é‡è¯„åˆ†æ–¹æ³•ï¼Œè€ƒè™‘æ¯ä¸ªåˆ†è§£ï¼ˆå³å­é—®é¢˜å’Œå®ƒä»¬çš„ç­”æ¡ˆï¼‰æ¥é€‰æ‹©æœ€ä½³çš„æœ€ç»ˆç­”æ¡ˆï¼Œæå¤§åœ°æé«˜äº†æ•´ä½“æ€§èƒ½ã€‚åœ¨HOTPOTQAä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼ŒåŒæ—¶ä»¥å­é—®é¢˜çš„å½¢å¼ä¸ºå…¶å†³ç­–æä¾›äº†å¯è§£é‡Šçš„è¯æ®ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> DECOMPRC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamically Fused Graph Network for Multi-hop Reasoning</title>
      <link href="/2021/04/16/Dynamically%20Fused%20Graph%20Network%20for%20Multi-hop%20Reasoning/"/>
      <url>/2021/04/16/Dynamically%20Fused%20Graph%20Network%20for%20Multi-hop%20Reasoning/</url>
      
        <content type="html"><![CDATA[<h1 id="Dynamically-Fused-Graph-Network-for-Multi-hop-Reasoning"><a href="#Dynamically-Fused-Graph-Network-for-Multi-hop-Reasoning" class="headerlink" title="Dynamically Fused Graph Network for Multi-hop Reasoning"></a>Dynamically Fused Graph Network for Multi-hop Reasoning</h1><blockquote><p> <a href="https://arxiv.org/abs/1905.06933">è®ºæ–‡ï¼šhttps://arxiv.org/abs/1905.06933</a></p><p> <a href="https://github.com/woshiyyya/DFGN-pytorch">ä»£ç ï¼šhttps://github.com/woshiyyya/DFGN-pytorch</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>å¤„ç†åŸºäºæ–‡æœ¬çš„é—®é¢˜å›ç­”ï¼ˆTBQAï¼‰,ç°æœ‰çš„å¤§å¤šæ•°æ–¹æ³•éƒ½ä¾§é‡äºåœ¨ä¸€ä¸ªæ®µè½ä¸­å¯»æ‰¾é—®é¢˜çš„ç­”æ¡ˆã€‚ä½†æ˜¯è®¸å¤šå¤æ‚çš„é—®é¢˜éœ€è¦ä»ä¸¤ä¸ªæˆ–æ›´å¤šçš„æ–‡æ¡£ä¸­åˆ†æ•£çš„æ–‡æœ¬ä¸­å¯»æ‰¾å¤šä¸ªæ”¯æŒè¯æ®ã€‚æœ¬æ–‡æå‡ºäº†åŠ¨æ€èåˆå›¾ç½‘ç»œï¼ˆ<strong>DFGN</strong>ï¼‰ï¼Œæ¥å›ç­”éœ€è¦ä»å¤šä¸ªåˆ†æ•£çš„è¯æ®æ¨ç†çš„é—®é¢˜ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>DFGNåŒ…å«ä¸€ä¸ªåŠ¨æ€èåˆå±‚ï¼Œå®ƒä»ç»™å®šæŸ¥è¯¢ä¸­æåˆ°çš„å®ä½“å¼€å§‹ï¼Œæ²¿ç€ä»æ–‡æœ¬ä¸­åŠ¨æ€æ„å»ºçš„å®ä½“å›¾è¿›è¡Œæ¢ç´¢ï¼Œå¹¶é€æ¸ä»ç»™å®šæ–‡æ¡£ä¸­æ‰¾åˆ°ç›¸å…³çš„æ”¯æŒå®ä½“ã€‚</p><p>å·¥ä½œæ–¹å¼ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210413205008.png" alt="image-20210413205001014" style="zoom:50%;" /></p><p>ä¸¤ä¸ªæŒ‘æˆ˜ï¼š</p><ul><li><p>å¹¶éæ¯ä¸ªæ–‡æ¡£éƒ½åŒ…å«ç›¸å…³ä¿¡æ¯ï¼Œå› æ­¤åŸºäºå¤šè·³æ–‡æœ¬çš„è´¨é‡æ£€æŸ¥è¦æ±‚ä»å¤šä¸ªæ®µè½ä¸­è¿‡æ»¤æ‰å™ªéŸ³å¹¶æå–æœ‰ç”¨çš„ä¿¡æ¯ã€‚</p></li><li><p>ä»¥å‰çš„å¤šè·³Qaå·¥ä½œé€šå¸¸ä¼šå°†æ–‡æ¡£ä¿¡æ¯æ±‡èšåˆ°å®ä½“å›¾å½¢ï¼Œç„¶ååœ¨å®ä½“å›¾çš„å®ä½“ä¸Šç›´æ¥é€‰æ‹©ç­”æ¡ˆã€‚ ä½†æ˜¯ï¼Œåœ¨æ›´çœŸå®çš„æƒ…å†µä¸‹ï¼Œç­”æ¡ˆç”šè‡³å¯èƒ½ä¸ä¼šé©»ç•™åœ¨æå–çš„å®ä½“å›¾çš„å®ä½“ä¸­ ã€‚</p></li></ul><p>è§£å†³ï¼š</p><ul><li>å¯¹äºç¬¬ä¸€ä¸ªæŒ‘æˆ˜ï¼ŒDFGNæ ¹æ®æŸ¥è¯¢å’Œæ–‡æ¡£ä¸­æåŠçš„å®ä½“ï¼Œæ„å»ºä¸€ä¸ªåŠ¨æ€å®ä½“å›¾ã€‚è¿™ä¸ªè¿‡ç¨‹ç»è¿‡å¤šè½®è¿­ä»£ï¼Œå®ç°å¤šè·³æ¨ç†ã€‚åœ¨æ¯ä¸€è½®ä¸­ï¼ŒDFGNéƒ½ä¼šåœ¨åŠ¨æ€å›¾ä¸Šç”Ÿæˆå’Œæ¨ç†ï¼Œé€šè¿‡æ©ç é¢„æµ‹æ¨¡å—(mask prediction module)ï¼Œå°†ä¸ç›¸å…³çš„å®ä½“å±è”½æ‰ï¼Œåªä¿ç•™æ¨ç†æºã€‚</li><li>æå‡ºfusion processï¼Œä¸ä»…å°†æ–‡æ¡£ä¸­çš„ä¿¡æ¯èšåˆåˆ°å®ä½“å›¾ï¼ˆdoc2graphï¼‰ï¼Œè¿˜å°†å®ä½“å›¾çš„ä¿¡æ¯ä¼ æ’­å›æ–‡æ¡£è¡¨ç¤ºï¼ˆgraph2docï¼‰ã€‚èåˆè¿‡ç¨‹åœ¨æ¯ä¸€è·³éƒ½ä¼šé€šè¿‡æ–‡æ¡£æ ‡è®°å’Œå®ä½“è¿›è¡Œè¿­ä»£ï¼Œç„¶åä»æ–‡æ¡£æ ‡è®°ä¸­å¾—åˆ°æœ€ç»ˆçš„ç»“æœç­”æ¡ˆã€‚doc2graphå’Œgraph2docçš„èåˆè¿‡ç¨‹ä¸åŠ¨æ€å®ä½“å›¾å…±åŒæé«˜äº†æ–‡æ¡£ä¿¡æ¯ä¸å®ä½“å›¾ä¹‹é—´çš„äº¤äº’æ€§ï¼Œä½¿å¾—å®ä½“å›¾çš„å™ªå£°æ›´å°ï¼Œä»è€Œä½¿ç­”æ¡ˆæ›´åŠ å‡†ç¡®ã€‚</li></ul><h3 id="Dynamically-Fused-Graph-Network-DFGN"><a href="#Dynamically-Fused-Graph-Network-DFGN" class="headerlink" title="Dynamically Fused Graph Network(DFGN)"></a>Dynamically Fused Graph Network(<strong>DFGN</strong>)</h3><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210414091728.png" alt="image-20210414091718194" style="zoom:50%;" /></p><p>5ä¸ªç»„ä»¶ï¼šparagraph selection sub-network, entity graph construction, encoding layer, a fusion block for multi-hop reasoning, final prediction layer</p><ul><li><p>paragraph selection sub-network</p><p>é€šè¿‡sub-networké€‰æ‹©ç›¸ä¼¼åº¦è¾ƒé«˜çš„æ®µè½ã€‚</p></li><li><p>Constructing Entity Graphï¼š</p><p>ä½¿ç”¨Stanford corenlp toolkitè¿›è¡Œå‘½åå®ä½“è¯†åˆ«ã€‚</p><p>è¾¹æ·»åŠ è§„åˆ™ï¼š</p><ol><li>å®ä½“åœ¨ä¸Šä¸‹æ–‡Cä¸­å‡ºç°åœ¨åŒä¸€å¥å­ä¸­ï¼ˆå¥å­çº§é“¾æ¥ï¼‰</li><li>æ¯å¯¹å®ä½“åœ¨Cä¸­å…·æœ‰ç›¸åŒæåŠæ–‡æœ¬çš„å®ä½“ï¼ˆä¸Šä¸‹æ–‡çº§åˆ«çš„é“¾æ¥ï¼‰</li><li>åœ¨ä¸­é—´å®ä½“èŠ‚ç‚¹å’ŒåŒä¸€æ®µè½å†…çš„å…¶ä»–å®ä½“ä¹‹é—´ï¼ˆæ®µè½çº§é“¾æ¥ï¼‰</li></ol><p>ä¸­é—´å®ä½“ä»æ ‡é¢˜ä¸­æå–ã€‚</p></li><li><p>Encoding Query and Context</p><p>å®éªŒBERTé¢„è®­ç»ƒæ¨¡å‹ç¼–ç ã€‚</p><script type="math/tex; mode=display">Q = [q_1, . . . , q_L] âˆˆ R^{LÃ—d_{1}}</script><script type="math/tex; mode=display">C= [c_1, . . . , c_M] âˆˆR^{MÃ—d_1}</script></li></ul><p>  Q,Cä»£è¡¨é—®é¢˜å’Œä¸Šä¸‹æ–‡ã€‚L,Måˆ†åˆ«è¡¨ç¤ºé—®é¢˜å’Œä¸Šä¸‹æ–‡çš„é•¿åº¦ï¼Œ$d_1$æ˜¯BERTéšè—å±‚çš„å°ºå¯¸ã€‚</p><ul><li><p>Reasoning with the Fusion Block</p><p>æ¨¡ä»¿äººç±»çš„one-stepæ¨ç†è¡Œä¸ºã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210414094506.png" alt="image-20210414094506444" style="zoom:50%;" /></p><ol><li>å°†æ–‡æ¡£ä¸­çš„ä¿¡æ¯èšåˆåˆ°å®ä½“å›¾ï¼ˆdoc2graph</li><li>å°†å®ä½“å›¾çš„ä¿¡æ¯ä¼ æ’­å›æ–‡æ¡£è¡¨ç¤ºï¼ˆgraph2docï¼‰</li><li>ç„¶åä»æ–‡æ¡£æ ‡è®°ä¸­å¾—åˆ°æœ€ç»ˆçš„ç»“æœç­”æ¡ˆ</li></ol></li></ul><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>HotpotQA ï¼šdistractor setting</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210414104935.png" alt="image-20210414104935396"></p><p>ç­”æ¡ˆæ€§èƒ½å’Œè”åˆè¡¨ç°è¾¾åˆ°äº†å½“å‰æœ€ä¼˜æ€§èƒ½ï¼ŒDFGNå¯ä»¥äº§ç”Ÿå¯è§£é‡Šçš„æ¨ç†é“¾ã€‚</p><p>æ¶ˆèç ”ç©¶ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210414105356.png" alt="image-20210414105356961" style="zoom:50%;" /></p><p>æ¯ä¸ªæ¨¡å‹ç»„ä»¶éƒ½å¯ä»¥æä¾›1ï¼…è‡³2ï¼…çš„æ€§èƒ½æå‡ã€‚</p><p>å¹¶ä¸”æ¨¡å‹å¯¹äºé»„é‡‘æ®µè½å’Œæ”¯æŒäº‹å®å¹¶ä¸æ•æ„Ÿã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>æå‡ºçš„åŠ¨æ€èåˆçš„å›¾å½¢ç½‘ç»œï¼ˆDFGNï¼‰ä»¥è§£å†³å¤šè·³æ¨ç†ã€‚åœ¨HotpotQAä¸Šå¯¹DFGNè¯„ä¼°å–å¾—äº†é¢†å…ˆçš„ç»“æœã€‚DFGNå¯ä»¥äº§ç”Ÿå¯é å’Œå¯è§£é‡Šçš„æ¨ç†é“¾ã€‚ä»æ–‡æœ¬ä¸­æ„å»ºå®ä½“å›¾ï¼Œå¯è§£å†³æ›´å¤šå›°éš¾çš„æ¨ç†é—®é¢˜ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> TBQA </tag>
            
            <tag> DFGN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Answering Complex Open-domain Questions Through Iterative Query Generation</title>
      <link href="/2021/04/10/Answering%20Complex%20Open-domain%20Questions%20Through%20Iterative%20Query%20Generation/"/>
      <url>/2021/04/10/Answering%20Complex%20Open-domain%20Questions%20Through%20Iterative%20Query%20Generation/</url>
      
        <content type="html"><![CDATA[<h1 id="Answering-Complex-Open-domain-Questions-Through-Iterative-Query-Generation"><a href="#Answering-Complex-Open-domain-Questions-Through-Iterative-Query-Generation" class="headerlink" title="Answering Complex Open-domain Questions Through Iterative Query Generation"></a>Answering Complex Open-domain Questions Through Iterative Query Generation</h1><blockquote><p> <a href="">è®ºæ–‡ï¼šAnswering Complex Open-domain Questions Through Iterative Query Generation</a></p><p> <a href="https://github.com/qipeng/golden-retriever">ä»£ç ï¼šhttps://github.com/qipeng/golden-retriever</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>å¯¹äºç›®å‰çš„å•è·³æ£€ç´¢å’Œé˜…è¯»é—®é¢˜å›ç­”ç³»ç»Ÿæ¥è¯´ï¼Œé—®é¢˜å¾ˆå°‘åŒ…å«å…³äºç¼ºå¤±å®ä½“çš„å¯æ£€ç´¢çº¿ç´¢ã€‚å›ç­”è¿™æ ·çš„é—®é¢˜éœ€è¦è¿›è¡Œå¤šè·³æ¨ç†ï¼Œå¿…é¡»æ”¶é›†å…³äºç¼ºå¤±å®ä½“ï¼ˆæˆ–äº‹å®ï¼‰çš„ä¿¡æ¯æ‰èƒ½è¿›è¡Œè¿›ä¸€æ­¥çš„æ¨ç†ã€‚æœ¬æ–‡æå‡ºäº†<strong>GOLDENï¼ˆGold Entityï¼‰Retriever</strong>ï¼Œå®ƒåœ¨é˜…è¯»ä¸Šä¸‹æ–‡å’Œæ£€ç´¢æ›´å¤šæ”¯æŒæ–‡æ¡£ä¹‹é—´è¿›è¡Œè¿­ä»£ï¼Œä»¥å›ç­”å¼€æ”¾é¢†åŸŸçš„å¤šè·³é—®é¢˜ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>GOLDEN Retrieverä¸ä½¿ç”¨ä¸é€æ˜å’Œè®¡ç®—ä»£ä»·è¾ƒé«˜çš„ç¥ç»æ£€ç´¢æ¨¡å‹ï¼Œè€Œæ˜¯æ ¹æ®é—®é¢˜å’Œå¯ç”¨çš„ä¸Šä¸‹æ–‡ç”Ÿæˆè‡ªç„¶è¯­è¨€æœç´¢æŸ¥è¯¢ï¼Œåœ¨æ¯ä¸€æ­¥ä¸­ï¼Œè¯¥æ¨¡å‹ä¹Ÿä¼šä½¿ç”¨å‰å‡ è·³æ¨ç†çš„IRç»“æœç”Ÿæˆæ–°çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œå¹¶åˆ©ç”¨ç°æˆçš„ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿæ¥æŸ¥è¯¢ç¼ºå¤±çš„å®ä½“æˆ–è¯æ®æ¥å›ç­”åŸé—®é¢˜ï¼Œè€Œä¸æ˜¯çº¯ç²¹ä¾é åŸé—®é¢˜æ¥æ£€ç´¢æ®µè½ã€‚è¿™ä½¿å¾—GOLDEN Retrieverèƒ½å¤Ÿåœ¨ä¿æŒå¯è§£é‡Šæ€§çš„åŒæ—¶ï¼Œæœ‰æ•ˆåœ°æ‰©å±•å¼€æ”¾é¢†åŸŸçš„å¤šè·³æ¨ç†ã€‚</p><ul><li>GOLDEN Retriever</li></ul><p>åœ¨æ¨ç†çš„ç¬¬ä¸€è·³ä¸­ï¼ŒGOLDEN RetrieveråŸºäºç»™å®šçš„åŸå§‹é—®é¢˜qï¼Œä»ä¸­ç”Ÿæˆä¸€ä¸ªæ£€ç´¢æ”¯æŒæ–‡æ¡£$d<em>1$ï¼Œç„¶åå¯¹åç»­çš„æ¯ä¸€ä¸ªæ¨ç†æ­¥éª¤$(\ k = 2ï¼Œâ€¦â€¦ï¼ŒS\ ï¼‰$ï¼ŒGOLDEN Retrieverä»é—®é¢˜å’Œå¯ç”¨ä¸Šä¸‹æ–‡$\ (qï¼Œd_1ï¼Œâ€¦â€¦ï¼Œd</em>{k-1}\ )$ä¸­ç”Ÿæˆä¸€ä¸ªæŸ¥è¯¢$q_k$ï¼Œä½¿å¾—æ¨¡å‹æ ¹æ®æ”¯æŒäº‹å®ä¸­æ­ç¤ºçš„ä¿¡æ¯ç”ŸæˆæŸ¥è¯¢ã€‚</p><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210406142938.png" alt="image-20210406142937978"></p><ul><li>Query Generation</li></ul><p>ä½¿ç”¨DrQAâ€™s Document Reader modelã€‚</p><p>ä»$C_k$ä¸­é€‰æ‹©ä¸€ä¸ªè·¨åº¦ä½œä¸ºæŸ¥è¯¢: $q_k= G_k(q, C_k)$</p><blockquote><p>$C_k$:retrieval context</p><p>gold supporting documents: $d<em>1,â€¦.,d</em>{k-1}$</p><p>generate a search query: $q_k$</p><p>$G_k$ : the query generator</p></blockquote><ul><li>Deriving Supervision Signal for Query Generation</li></ul><p>é‡‡ç”¨å‡ ç§å¯å‘å¼æ–¹æ³•æ¥ç”Ÿæˆå€™é€‰æŸ¥è¯¢ï¼šè®¡ç®—å½“å‰æ£€ç´¢ä¸Šä¸‹æ–‡ä¸ç›®çš„æ®µè½çš„æ ‡é¢˜/æ–‡æœ¬ä¹‹é—´æœ€é•¿çš„å…±åŒå­—ç¬¦ä¸²/åºåˆ—ï¼Œå¿½ç•¥åœé¡¿è¯ï¼Œç„¶åå–æ£€ç´¢ä¸Šä¸‹æ–‡ä¸­ä¸æ­¤é‡å å¯¹åº”çš„è¿ç»­æ–‡æœ¬è·¨åº¦ã€‚è¿™æ ·ä¸ä»…å¯ä»¥åˆ©ç”¨å®ä½“åç§°ï¼Œè¿˜å¯ä»¥åˆ©ç”¨æ–‡å­—æè¿°ï¼Œæ›´å¥½åœ°å¼•å‡ºé»„é‡‘å®ä½“ã€‚</p><ul><li>Question Answering Component</li></ul><p>ä¹‹å‰çš„æ¨¡å‹å°†æ‰€æœ‰ä¸Šä¸‹æ–‡æ®µè½è¿ç¼€æˆä¸€ä¸ªé•¿å­—ç¬¦ä¸²ï¼Œä»¥é¢„æµ‹ç­”æ¡ˆçš„è·¨åº¦å¼€å§‹å’Œç»“æŸåç§»ï¼Œè¿™å¯¹è¿™äº›æ®µè½å‘ˆç°ç»™æ¨¡å‹çš„é¡ºåºæœ‰æ½œåœ¨çš„æ•æ„Ÿæ€§ã€‚æœ¬æ–‡ç”¨å…±äº«ç¼–ç å™¨RNNå‚æ•°åˆ†åˆ«å¤„ç†ï¼Œä»¥è·å¾—æ¯ä¸ªæ®µè½çš„æ®µè½é¡ºåºä¸æ•æ„Ÿçš„è¡¨ç¤ºã€‚è·¨åº¦åç§»åˆ†æ•°ä»æ¯ä¸ªæ®µè½ä¸­ç‹¬ç«‹é¢„æµ‹ï¼Œæœ€åç”¨å…¨å±€ softmax æ“ä½œè¿›è¡Œèšåˆå’Œå½’ä¸€åŒ–ï¼Œä»¥äº§ç”Ÿè·¨åº¦çš„æ¦‚ç‡ã€‚</p><p>å°†åŸæ¨¡å‹ä¸­çš„æ‰€æœ‰æ³¨æ„åŠ›æœºåˆ¶éƒ½æ›¿æ¢æˆäº†å¹¶è”é—®é¢˜å’Œä¸Šä¸‹æ–‡çš„è‡ªæ³¨æ„åŠ›å±‚ã€‚ä¸ºäº†åŒºåˆ†ä¸Šä¸‹æ–‡æ®µè½è¡¨å¾å’Œé—®é¢˜è¡¨å¾åœ¨è¿™ä¸ªè‡ªæ³¨æ„æœºåˆ¶ä¸­çš„åŒºåˆ«ï¼Œåœ¨è¾“å…¥å±‚ç”¨ä¸€ä¸ª0/1çš„ç‰¹å¾æ¥è¡¨ç¤ºé—®é¢˜å’Œä¸Šä¸‹æ–‡æ ‡è®°ã€‚</p><p>QAæ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210409220949.png" alt="image-20210409220949967" style="zoom:50%;" /></p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>HOTPOTQA: fullwiki setting</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210410095902.png" alt="image-20210410095902227"></p><p>ä¸CogQAç›¸æ¯”ï¼ŒGOLDEN Retriever åœ¨ç»´åŸºç™¾ç§‘ä¸­æ‰¾åˆ°æ­£ç¡®æ”¯æŒäº‹å®çš„æ•ˆæœæ›´å¥½ï¼Œè¯æ˜å°½ç®¡æ²¡æœ‰ä½¿ç”¨BERTç­‰é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä½†å®ƒçš„è¡¨ç°ä¼˜äºä¹‹å‰å‘è¡¨çš„æœ€ä½³æ¨¡å‹ã€‚</p><p>GOLDEN Retrieverå‡ ä¹å°†å¬å›ç‡ç¿»å€ï¼Œé€šè¿‡å•è·³åŸºçº¿æ¨¡å‹ï¼Œä¸ºQAç»„ä»¶æä¾›äº†ä¸€ä¸ªæ›´å¥½çš„ä¸Šä¸‹æ–‡æ–‡æ¡£æ¥é¢„æµ‹ç­”æ¡ˆã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>æœ¬æ–‡æå‡ºäº†GOLDEN Retrieverï¼Œè¿™æ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„å¤šè·³æ¨ç†çš„å¼€æ”¾åŸŸå¤šè·³é—®é¢˜å›ç­”ç³»ç»Ÿã€‚é€šè¿‡è¿­ä»£æ¨ç†å’Œæ£€ç´¢ï¼ŒGOLDEN Retrieveræå¤§åœ°æé«˜äº†é»„é‡‘æ”¯æŒäº‹å®çš„å¬å›ç‡ï¼Œä»è€Œä¸ºé—®é¢˜å›ç­”æ¨¡å‹æä¾›äº†ä¸€ä¸ªæ›´å¥½çš„ä¸Šä¸‹æ–‡æ–‡æ¡£é›†æ¥äº§ç”Ÿç­”æ¡ˆï¼Œå¹¶å±•ç¤ºäº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ã€‚ä¸ºæ¯ä¸€æ­¥æ¨ç†ç”Ÿæˆè‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œä¸ä¹‹å‰çš„ç¥ç»æ£€ç´¢æ–¹æ³•ç›¸æ¯”ï¼ŒGOLDEN Retrieverå¯¹äººç±»çš„è§£é‡Šèƒ½åŠ›ä¹Ÿæ›´å¼ºï¼Œå¹¶èƒ½æ›´å¥½åœ°ç†è§£å’ŒéªŒè¯æ¨¡å‹è¡Œä¸ºã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> GOLDEN Retriever </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-hop Question Generation with Graph Convolutional Network</title>
      <link href="/2021/04/01/Multi-hop%20Question%20Generation%20with%20Graph%20Convolutional%20Network/"/>
      <url>/2021/04/01/Multi-hop%20Question%20Generation%20with%20Graph%20Convolutional%20Network/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-hop-Question-Generation-with-Graph-Convolutional-Network"><a href="#Multi-hop-Question-Generation-with-Graph-Convolutional-Network" class="headerlink" title="Multi-hop Question Generation with Graph Convolutional Network"></a>Multi-hop Question Generation with Graph Convolutional Network</h1><blockquote><p> <a href="https://arxiv.org/abs/2010.09240">è®ºæ–‡:https://arxiv.org/abs/2010.09240</a></p><p> <a href="https://github.com/HLTCHKUST/MulQG">ä»£ç :https://github.com/HLTCHKUST/MulQG</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>å¤šè·³é—®é¢˜ç”Ÿæˆ(Multi-hop Question Generation,<strong>QG</strong>)çš„ç›®çš„æ˜¯é€šè¿‡å¯¹ä¸åŒæ®µè½ä¸­å¤šä¸ªåˆ†æ•£çš„è¯æ®è¿›è¡Œæ±‡æ€»å’Œæ¨ç†ï¼Œç”Ÿæˆä¸ç­”æ¡ˆç›¸å…³çš„é—®é¢˜ã€‚è§£å†³ä¸¤ä¸ªé—®é¢˜ï¼š1.å¦‚ä½•æœ‰æ•ˆåœ°è¯†åˆ«åˆ†æ•£çš„è¯æ®ï¼Œå¯ä»¥è¿æ¥ç­”æ¡ˆå’Œé—®é¢˜çš„æ¨ç†è·¯å¾„ã€‚2.å¦‚ä½•æ¨ç†å¤šä¸ªåˆ†æ•£çš„è¯æ®æ¥äº§ç”Ÿäº‹å®è¿è´¯çš„é—®é¢˜ã€‚</p><p>è¯†åˆ«åˆ†æ•£çš„è¯æ®ï¼Œå¯ä»¥è¿æ¥ç­”æ¡ˆå’Œé—®é¢˜çš„æ¨ç†è·¯å¾„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210401093135.png" alt="image-20210401093128346" style="zoom:50%;" /></p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>ä¸ºäº†è§£å†³å¤šè·³QG<strong>(MulQG)</strong>ä¸­çš„é¢å¤–æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†é—®é¢˜ç”Ÿæˆçš„å¤šè·³ç¼–ç èåˆç½‘ç»œ(Multi-Hop Encoding Fusion Network)ï¼Œå®ƒé€šè¿‡Graph Convolutional Networkåœ¨å¤šè·³ä¸­è¿›è¡Œä¸Šä¸‹æ–‡ç¼–ç ï¼Œå¹¶é€šè¿‡ç¼–ç å™¨æ¨ç†é—¨(Encoder Reasoning Gate)è¿›è¡Œç¼–ç èåˆã€‚</p><p>MulQGå°†Seq2Seq QGæ¡†æ¶ä»å•è·³æ‰©å±•åˆ°å¤šè·³è¿›è¡Œä¸Šä¸‹æ–‡ç¼–ç ã€‚åˆ©ç”¨å›¾å·ç§¯ç½‘ç»œï¼ˆGCNï¼‰å¯¹ç­”æ¡ˆæ„ŸçŸ¥çš„åŠ¨æ€å®ä½“å›¾ï¼ˆç”±ç­”æ¡ˆå’Œè¾“å…¥æ®µè½ä¸­çš„å®ä½“æ„å»ºï¼‰ï¼Œä»¥èšåˆä¸é—®é¢˜ç›¸å…³çš„æ½œåœ¨è¯æ®ã€‚åœ¨å¤šè·³ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨ä¸åŒçš„æ³¨æ„åŠ›æœºåˆ¶æ¥æ¨¡ä»¿äººç±»çš„æ¨ç†è¿‡ç¨‹ã€‚</p><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210401101356.png" alt="image-20210401101356256"></p><h3 id="Multi-hop-Encoder"><a href="#Multi-hop-Encoder" class="headerlink" title="Multi-hop Encoder"></a>Multi-hop Encoder</h3><p>åŒ…å«3ä¸ªæ¨¡å—ï¼š</p><p>(1) Answer-aware context encoder</p><p>(2) GCN-based entity-aware answer encoder </p><p>(3) Gated encoder reasoning layer.</p><p>ä¸Šä¸‹æ–‡å’Œç­”æ¡ˆåˆ†å‰²ä¸ºword-level tokenï¼Œè¡¨ç¤ºä¸ºï¼š</p><p>$c ={c_1, c_2, â€¦, c_n}$ </p><p>$a = {a_1, a_2, â€¦, a_m}$</p><p>å•æ¬¡ä½¿ç”¨é¢„è®­ç»ƒçš„GloVe embeddingè¡¨ç¤ºï¼Œå¯¹äºä¸Šä¸‹æ–‡ä¸­çš„å•è¯ï¼ŒåŠ å…¥ç­”æ¡ˆæ ‡è®°åµŒå…¥ã€‚ä¸Šä¸‹æ–‡å’Œç­”æ¡ˆåµŒå…¥åˆ†åˆ«è¾“å…¥ä¸¤ä¸ªåŒå‘LSTM-RNNï¼Œè·å¾—å…¶åˆå§‹ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚</p><p>$C_0âˆˆ R^{dÃ—n}$ </p><p>$A_0 âˆˆ R^{dÃ—m}$</p><p>dæ˜¯LSTMéšè—å±‚ç»´åº¦ã€‚</p><ul><li>GCN-based Entity-aware Answer Encoder</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210401104651.png" alt="image-20210401104651769" style="zoom: 33%;" /></p><p>ä¸ºäº†è·å¾—å¤šè·³ç­”æ¡ˆè¡¨ç¤ºï¼Œé¦–å…ˆä»ç­”æ¡ˆæ„ŸçŸ¥ä¸Šä¸‹æ–‡ç¼–ç $C_1$è®¡ç®—å®ä½“ç¼–ç ï¼Œç„¶åæˆ‘ä»¬å°†GCNåº”ç”¨äºåœ¨ç­”æ¡ˆæ„ŸçŸ¥çš„å­å›¾ä¸Šä¼ æ’­å¤šè·³ä¿¡æ¯ã€‚ æœ€åï¼Œé€šè¿‡åŒå‘æ³¨æ„åŠ›æœºåˆ¶è·å¾—ç¼–ç $A_1$çš„æ›´æ–°ç­”æ¡ˆã€‚</p><p>Entity Graph Constructionï¼š</p><p>ä½¿ç”¨BERT-basedå‘½åå®ä½“è¯†åˆ«æ„å»ºèŠ‚ç‚¹ã€‚</p><p>å¤„äºåŒä¸€å¥å­æˆ–å‡ºç°åœ¨ç›¸åŒæ®µè½çš„èŠ‚ç‚¹æ·»åŠ è¾¹ã€‚</p><ul><li>Encoder Reasoning Gate</li></ul><p>åœ¨ä¹‹å‰ä¸Šä¸‹æ–‡context encoder hopsçš„ç­”æ¡ˆæ„ŸçŸ¥ä¸Šä¸‹æ–‡è¡¨ç¤º$C_1$å’Œ$C_2$ä¸Šåº”ç”¨é—¨æ§ç‰¹å¾èåˆæ¨¡å—ï¼Œä¿ç•™å’Œé—å¿˜ä¿¡æ¯ï¼Œå½¢æˆæœ€ç»ˆçš„ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚</p><ul><li>Maxout Pointer Decoder</li></ul><p>decoder:Uni-directional LSTM modelï¼ˆå•å‘ï¼‰</p><p>ä¸ºäº†å‡å°‘è¿­ä»£çš„é‡å¤ã€‚</p><ul><li>Breadth-First Search Loss</li></ul><p>cross-entropy loss:Breadth-First Search (BFS) Loss</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>HotpotQA</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210401131731.png" alt="image-20210401131731134"></p><p>æœ¬æ–‡æå‡ºçš„MulQGæ¨¡å‹æ•ˆæœè¿œå¥½äºåŸºçº¿æ¨¡å‹ï¼Œè¡¨æ˜å¤šè·³è¿‡ç¨‹å¯ä»¥æ˜¾ç€æé«˜ç¼–ç è¡¨ç¤ºçš„è´¨é‡ï¼Œä»è€Œæé«˜äº†å¤šè·³é—®é¢˜ç”Ÿæˆæ€§èƒ½ã€‚</p><p>BFS lossä¹Ÿå¯ä»¥é€šè¿‡é¼“åŠ±å­¦ä¹ ç­”æ¡ˆæ„ŸçŸ¥çš„åŠ¨æ€å®ä½“å›¾æ›´å¥½åœ°æé«˜ç³»ç»Ÿæ€§èƒ½ã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><h3 id="æ¶ˆèå®éªŒ"><a href="#æ¶ˆèå®éªŒ" class="headerlink" title="æ¶ˆèå®éªŒ"></a>æ¶ˆèå®éªŒ</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210401133530.png" alt="image-20210401133530810"></p><p>åŸºäºGCNçš„å®ä½“æ„ŸçŸ¥ç­”æ¡ˆç¼–ç å™¨æ¨¡å—å’Œé—¨æ§ä¸Šä¸‹æ–‡æ¨ç†æ¨¡å—éƒ½å¯¹æ¨¡å‹å¾ˆé‡è¦ï¼ˆGCN-based entity-aware answer encoder module and Gated Context Reasoning moduleï¼‰ã€‚</p><p> æ¨¡å‹æ•ˆæœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210401133518.png" alt="image-20210401133518720"></p><p>ä»è¯„ä¼°æ¥çœ‹ï¼Œæœ¬æ–‡æå‡ºçš„æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜å®Œæ•´æ€§çš„æµç•…é—®é¢˜ï¼Œå¹¶ä¸”åœ¨å¤šè·³è¯„ä¼°ä¸­æ¯”æœ€å¼ºçš„åŸºçº¿é«˜å‡º20.8%ï¼Œäººå·¥è¯„ä»·ç»“æœè¿›ä¸€æ­¥éªŒè¯äº†æˆ‘ä»¬æå‡ºçš„æ¨¡å‹æ›´å®¹æ˜“ç”Ÿæˆå¤šè·³é—®é¢˜ï¼Œå¹¶ä¸”åœ¨æµç•…æ€§ã€å¯å›ç­”æ€§å’Œå®Œæ•´æ€§å¾—åˆ†æ–¹é¢å…·æœ‰è¾ƒé«˜çš„è´¨é‡ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> QG </tag>
            
            <tag> GCN </tag>
            
            <tag> MulQG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Avoiding Reasoning Shortcuts Adversarial Evaluation, Training, and Model Development for Multi-HopQA</title>
      <link href="/2021/03/26/ACL2019-Avoiding%20Reasoning%20Shortcuts%20Adversarial%20Evaluation,%20Training,%20and%20Model%20Development%20for%20Multi-HopQA/"/>
      <url>/2021/03/26/ACL2019-Avoiding%20Reasoning%20Shortcuts%20Adversarial%20Evaluation,%20Training,%20and%20Model%20Development%20for%20Multi-HopQA/</url>
      
        <content type="html"><![CDATA[<h1 id="Avoiding-Reasoning-Shortcuts-Adversarial-Evaluation-Training-and-Model-Development-for-Multi-HopQA"><a href="#Avoiding-Reasoning-Shortcuts-Adversarial-Evaluation-Training-and-Model-Development-for-Multi-HopQA" class="headerlink" title="Avoiding Reasoning Shortcuts Adversarial Evaluation, Training, and Model Development for Multi-HopQA"></a>Avoiding Reasoning Shortcuts Adversarial Evaluation, Training, and Model Development for Multi-HopQA</h1><blockquote><p> <a href="https://arxiv.org/abs/1906.07132">è®ºæ–‡ï¼šhttps://arxiv.org/abs/1906.07132</a></p><p> <a href="https://github.com/jiangycTarheel/Adversarial-MultiHopQA">ä»£ç ï¼šhttps://github.com/jiangycTarheel/Adversarial-MultiHopQA</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>â€‹        å¤šè·³ç­”é¢˜éœ€è¦æ¨¡å‹å°†åˆ†æ•£åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­çš„å¤šä¸ªè¯æ®è¿æ¥èµ·æ¥æ¥å›ç­”é—®é¢˜ã€‚æœ¬æ–‡åœ¨HotpotQAæ•°æ®é›†ä¸Šï¼Œé€šè¿‡æ„å»ºå¯¹æŠ—æ€§æ–‡æ¡£ï¼ˆç”±äºåœ¨ç”Ÿæˆé—®é¢˜æ—¶ï¼Œäººå·¥å¹¶æ²¡æœ‰æä¾›å¹²æ‰°æ–‡æ¡£ï¼Œå› æ­¤æ— æ³•ä¿è¯æ”¯æŒæ–‡æ¡£å¿…é¡»åœ¨æ•´ä¸ªä¸Šä¸‹æ–‡æ¨æ–­ç­”æ¡ˆï¼‰æ¥è¯æ˜ï¼Œé€šè¿‡æ•°æ®é›†ä¸­éƒ¨åˆ†ä¾‹å­åŒ…å«çš„æ·å¾„ï¼Œæ¨¡å‹å¯ä»¥ç›´æ¥å°†é—®é¢˜ä¸ä¸Šä¸‹æ–‡ä¸­çš„å¥å­è¿›è¡Œè¯ä¹‰åŒ¹é…æ¥å®šä½ç­”æ¡ˆã€‚ç”Ÿæˆçš„è¿™äº›å¯¹æŠ—æ€§æ–‡æ¡£ä¼šå¯¹æ·å¾„äº§ç”ŸçŸ›ç›¾çš„ç­”æ¡ˆï¼Œä½†ä¸ä¼šå½±å“åŸå§‹ç­”æ¡ˆçš„æœ‰æ•ˆæ€§ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>ä¸ºæ¢ç©¶ç¥ç»ç½‘ç»œæ¨¡å‹æ˜¯å¦åˆ©ç”¨æ¨ç†å¿«æ·æ–¹å¼è€Œä¸æ˜¯æ¢ç´¢æ‰€éœ€çš„æ¨ç†è·¯å¾„ï¼Œä½¿ç”¨HotpotQAä¸­åŸå§‹æ•°æ®ä»¥æ¶ˆé™¤è¿™äº›å¿«æ·æ–¹å¼(shortcuts)ã€‚</p><p>context-question-answer tuple ï¼š(C, q, a)</p><p>å»é™¤å¿«æ·æ–¹å¼åï¼š(Câ€˜, q, a)</p><p>ç”±äºæ–°ç”Ÿæˆçš„æ–‡æ¡£å½¢æˆäº†å¦ä¸€ä¸ªå°†é—®é¢˜ä¸å‡ç­”æ¡ˆè”ç³»èµ·æ¥çš„æœ‰æ•ˆæ¨ç†é“¾ï¼Œå› æ­¤éœ€è¦æ›¿æ¢è¿æ¥ä¸¤æ¡è¯æ®çš„bridgeå®ä½“ä¸å¦ä¸€ä¸ªå®ä½“ï¼Œä»¥ä¾¿æ‰€ç”Ÿæˆçš„ç­”æ¡ˆä¸å†æ˜¯é—®é¢˜çš„æœ‰æ•ˆç­”æ¡ˆã€‚</p><p><strong>ADDDOC</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210325130113.png" alt="image-20210325130113477"></p><h3 id="Encoding"><a href="#Encoding" class="headerlink" title="Encoding"></a>Encoding</h3><p>embeddingï¼š<strong>x: context q: question</strong></p><p>contextualized word representations:<strong>h = BiLSTM(x); u = BiLSTM(q)</strong>ï¼ˆä½¿ç”¨bi-directional LSTM-RNNï¼‰</p><h3 id="Single-Hop-Baseline"><a href="#Single-Hop-Baseline" class="headerlink" title="Single-Hop Baseline"></a>Single-Hop Baseline</h3><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210325131930.png" alt="image-20210325131930096"></p><p>ä½¿ç”¨bi-attention + self-attention modelåšcontextualized encodingã€‚</p><script type="math/tex; mode=display">Ms,j= W_1u_s+ W_2h_j+ W_3(u_s\O h_j)</script><script type="math/tex; mode=display">p_{s,j}= \frac{exp(M_{s,j})} {\sum ^S_{s=1}exp(M_{s,j})}</script><script type="math/tex; mode=display">c_{q_j}=\sum^S_{s=1}p_{s,j}u_s</script><p>å¾—åˆ° question-aware contextä¸‹æ–‡è¡¨ç¤ºåä¼ é€’ç»™BiLSTMã€‚</p><script type="math/tex; mode=display">h^{'}_j= [h_j; c_{q_j}; h_j \O c_{q_j}; c_{q_j}\O qc]</script><script type="math/tex; mode=display">h^1= BiLSTM(h^{'})</script><h3 id="Compositional-Attention-over-Question"><a href="#Compositional-Attention-over-Question" class="headerlink" title="Compositional Attention over Question"></a>Compositional Attention over Question</h3><p>å°†æ§åˆ¶å•å…ƒä¸æœ€æ–°çš„å¤šè·³VQAæ¨¡å‹å’ŒåŸºäºæ–‡æœ¬çš„QAä¸Šé‡‡ç”¨çš„bi-attention mechanismç›¸ç»“åˆï¼Œä»¥å¯¹ä¸Šä¸‹æ–‡å’Œé—®é¢˜è¿›è¡Œç»¼åˆæ¨ç†ã€‚</p><p>ç”±äºä¸çŸ¥é“é—®é¢˜çš„å“ªä¸€éƒ¨åˆ†å¯¹å½“å‰çš„æ¨ç†æ­¥éª¤æ˜¯é‡è¦çš„ï¼Œä»è€Œä½¿æ§åˆ¶å•å…ƒæ— æ³•å­¦ä¹ å¤åˆæ¨ç†æŠ€èƒ½ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼ŒæŸ¥æ‰¾è¿æ¥ä¸¤ä¸ªæ”¯æŒæ–‡æ¡£çš„æ¡¥æ¥å®ä½“ã€‚ç›‘ç£ä¸»è¦æ¨¡å‹æ¥é¢„æµ‹æ¡¥å®ä½“è·¨åº¦ï¼Œåœ¨ç¬¬ä¸€ä¸ª biattention layerä¹‹åï¼Œé—´æ¥é¼“åŠ±æ§åˆ¶å•å…ƒåœ¨ç¬¬ä¸€è·³å¯»æ‰¾ä¸æ­¤å®ä½“ç›¸å…³çš„é—®é¢˜ä¿¡æ¯ã€‚å¯¹äºç­”æ¡ˆåŒæ—¶å‡ºç°åœ¨ä¸¤ä¸ªæ”¯æŒæ–‡æ¡£ä¸­çš„ä¾‹å­ï¼Œintermediate supervisionç»™å‡ºçš„æ˜¯ç¬¬ä¸€ä¸ªæ”¯æŒæ–‡æ¡£ä¸­å‡ºç°çš„ç­”æ¡ˆï¼Œè€Œç¬¬äºŒä¸ªæ”¯æŒæ–‡æ¡£ä¸­çš„ç­”æ¡ˆä½œä¸ºç­”æ¡ˆé¢„æµ‹ç›‘ç£ã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p><strong>HotpotQA  distractor setting</strong></p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210326113429.png" alt="image-20210326113429142" style="zoom:50%;" /></p><p>regular training setï¼šå‰ä¸¤åˆ—</p><p>åœ¨å¸¸è§„æ•°æ®ä¸Šè®­ç»ƒçš„å•è·³åŸºçº¿åœ¨å¯¹æŠ—æ€§è¯„ä»·ä¸Šè¡¨ç°ä¸ä½³ï¼Œè¿™è¯´æ˜å®ƒç¡®å®æ˜¯åœ¨åˆ©ç”¨æ¨ç†æ·å¾„ï¼Œè€Œä¸æ˜¯å®é™…æ‰§è¡Œå¤šè·³æ¨ç†æ¥å®šä½ç­”æ¡ˆã€‚æ·»åŠ äº†æ”¯æŒæ€§äº‹å®ç›‘ç£åï¼ˆç¬¬2è¡Œï¼‰ï¼Œåœ¨å¯¹æŠ—æ€§è¯„ä»·ä¸Šæœ‰æ˜¾è‘—çš„æ”¹å–„ã€‚</p><p>2-hopæ¨¡å‹è¢«é¢å¤–ç›‘ç£é¢„æµ‹å¥å­çº§æ”¯æŒäº‹å®åï¼Œåœ¨å¸¸è§„è¯„ä»·å’Œå¯¹æŠ—æ€§è¯„ä»·ä¸­çš„æ€§èƒ½éƒ½æœ‰æ‰€ä¸‹é™ã€‚</p><p>adversarial training setï¼šåä¸¤åˆ—</p><p>ç»è¿‡å¯¹æŠ—å¼è®­ç»ƒåï¼ŒåŸºçº¿å’Œå¸¦æœ‰æ§åˆ¶å•å…ƒçš„2-hopæ¨¡å‹åœ¨å¯¹æŠ—å¼è¯„ä»·ä¸Šæ€§èƒ½éƒ½æœ‰æ˜¾è‘—æå‡ã€‚</p><h3 id="æ¶ˆèå®éªŒ"><a href="#æ¶ˆèå®éªŒ" class="headerlink" title="æ¶ˆèå®éªŒ"></a>æ¶ˆèå®éªŒ</h3><h4 id="Adversary-Ablation"><a href="#Adversary-Ablation" class="headerlink" title="Adversary Ablation"></a>Adversary Ablation</h4><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210326115935.png" alt="image-20210326115935475" style="zoom:50%;" /></p><p>ä¸ºäº†æµ‹è¯•å¯¹æŠ—è®­ç»ƒçš„æ¨¡å‹çš„é²æ£’æ€§ï¼Œå…·æœ‰ä¸åŒæ•°é‡çš„å¯¹æŠ—æ–‡æ¡£å’Œä¸åŒå¯¹æŠ—ç­–ç•¥çš„devé›†ä¸Šå¯¹å®ƒä»¬è¿›è¡Œè¯„ä¼°ã€‚å½“å¯¹æŠ—æ–‡æ¡£è¢«é¢„ç½®åˆ°ä¸Šä¸‹æ–‡ä¸­æ—¶ï¼ŒåŸºçº¿å’Œ2-hopæ¨¡å‹éƒ½ä¸ä¼šå—åˆ°å½±å“ã€‚å½“æ¯ä¸ªæœ‰ç­”æ¡ˆçš„æ”¯æŒæ–‡æ¡£çš„å¯¹æŠ—æ€§æ–‡ä»¶æ•°é‡å¢åŠ åˆ°8ä¸ªæ—¶ï¼Œ4ä¸ªæ¨¡å‹çš„æ€§èƒ½éƒ½ä¸‹é™äº†ï¼Œä½†2-hopæ¨¡å‹çš„æ€§èƒ½ä¾ç„¶ä¼˜äºå•è·³æ¨¡å‹ã€‚</p><h4 id="Control-Unit-Ablation"><a href="#Control-Unit-Ablation" class="headerlink" title="Control Unit Ablation"></a>Control Unit Ablation</h4><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210326120528.png" alt="image-20210326120528188" style="zoom:50%;" /></p><p>å¯¹2-hopæ¨¡å‹è¿›è¡Œäº†å»æ‰æ§åˆ¶å•å…ƒçš„æ¶ˆèç ”ç©¶ã€‚å‰ä¸¤è¡Œåœ¨4ç§ä¸åŒè®­ç»ƒå’Œè¯„ä¼°æ•°æ®ç»„åˆçš„è®¾ç½®ä¸‹ï¼Œå¸¦æœ‰æ§åˆ¶å•å…ƒçš„æ¨¡å‹éƒ½ä¼˜äºæ›¿ä»£æ¨¡å‹ã€‚å³æ§åˆ¶å•å…ƒå¯ä»¥æé«˜æ¨¡å‹çš„å¤šè·³æ¨ç†èƒ½åŠ›å’Œå¯¹å¯¹æŠ—æ€§æ–‡æ¡£çš„é²æ£’æ€§ã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>â€‹        åœ¨æœ¬æ–‡çš„å¯¹æŠ—æ€§è¯„ä¼°ä¸­ï¼Œå¼ºåŸºçº¿æ¨¡å‹çš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¡¨æ˜å®ƒä»¬ç¡®å®åœ¨åˆ©ç”¨æ·å¾„è€Œä¸æ˜¯è¿›è¡Œå¤šè·³æ¨ç†ã€‚ç»è¿‡å¯¹æŠ—æ€§è®­ç»ƒåï¼ŒåŸºçº¿çš„æ€§èƒ½æœ‰æ‰€æé«˜ï¼Œä½†åœ¨å¯¹æŠ—æ€§è¯„ä»·ä¸Šä»ç„¶å—åˆ°é™åˆ¶ã€‚å› æ­¤ï¼Œä½¿ç”¨ä¸€ä¸ªåœ¨ä¸åŒæ¨ç†è·³æ•°ä¸ŠåŠ¨æ€å…³æ³¨é—®é¢˜çš„æ§åˆ¶å•å…ƒæ¥å¼•å¯¼æ¨¡å‹çš„å¤šè·³æ¨ç†ã€‚ç»“æœè¡¨æ˜ï¼Œè¿™ä¸ªåœ¨å¸¸è§„æ•°æ®ä¸Šè®­ç»ƒçš„2è·³æ¨¡å‹æ¯”åŸºçº¿æ¨¡å‹å¯¹å¯¹æŠ—è€…æ›´åŠ ç¨³å¥ã€‚ç»è¿‡å¯¹æŠ—è®­ç»ƒåï¼Œè¿™ä¸ª2è·³æ¨¡å‹ä¸ä»…æ¯”åœ¨å¸¸è§„æ•°æ®ä¸Šè®­ç»ƒçš„å¯¹åº”æ¨¡å‹å®ç°äº†æ”¹è¿›ï¼Œè€Œä¸”è¿˜ä¼˜äºå¯¹æŠ—è®­ç»ƒçš„1è·³åŸºçº¿æ¨¡å‹ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> HotpotQA </tag>
            
            <tag> ADDDOC </tag>
            
            <tag> KGE </tag>
            
            <tag> KG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Answering while Summarizing Multi-task Learning for Multi-hop QA with Evidence Extraction</title>
      <link href="/2021/03/18/ACL2019-Answering%20while%20Summarizing%20Multi-task%20Learning%20for%20Multi-hop%20QA%20with%20Evidence%20Extraction/"/>
      <url>/2021/03/18/ACL2019-Answering%20while%20Summarizing%20Multi-task%20Learning%20for%20Multi-hop%20QA%20with%20Evidence%20Extraction/</url>
      
        <content type="html"><![CDATA[<h1 id="Answering-while-Summarizing-Multi-task-Learning-for-Multi-hop-QA-with-Evidence-Extraction"><a href="#Answering-while-Summarizing-Multi-task-Learning-for-Multi-hop-QA-with-Evidence-Extraction" class="headerlink" title="Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction"></a>Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction</h1><blockquote><p><a href="https://arxiv.org/pdf/1905.08511.pdf">è®ºæ–‡ï¼šhttps://arxiv.org/pdf/1905.08511.pdf</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>æœ¬æ–‡èšç„¦äºå¯è§£é‡Šçš„å¤šè·³QAä»»åŠ¡ï¼Œè¦æ±‚ç³»ç»Ÿé€šè¿‡æ¨ç†å’Œæ”¶é›†å‚è€ƒæ–‡æœ¬çš„ä¸ç›¸äº¤ç‰‡æ®µæ¥è¿”å›å¸¦æœ‰è¯æ®å¥å­çš„ç­”æ¡ˆã€‚æå‡ºäº†<strong>Query Focused Extractor(QFE)</strong>æ¨¡å‹ç”¨äºè¯æ®æå–ï¼Œå¹¶ä½¿ç”¨å¤šä»»åŠ¡å­¦ä¹ ä¸QAæ¨¡å‹ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><h3 id="Query-Focused-Extractor-QFE"><a href="#Query-Focused-Extractor-QFE" class="headerlink" title="Query Focused Extractor (QFE)"></a>Query Focused Extractor (QFE)</h3><blockquote><p>æ•´ä½“æ¨¡å‹é‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ ï¼Œç­”æ¡ˆé€‰æ‹©é‡‡ç”¨QAæ¨¡å‹ï¼Œè¯æ®æå–é‡‡ç”¨QFEæ¨¡å‹ã€‚</p></blockquote><p>â€‹        QFEçš„çµæ„Ÿæ¥è‡ªäºæå–å¼æ‘˜è¦æ¨¡å‹<strong>(extractive summarization models)</strong>ï¼Œå°†å¯è§£é‡Šçš„å¤šè·³QAçš„è¯æ®æå–çœ‹ä½œæ˜¯ä¸€ä¸ªä»¥æŸ¥è¯¢ä¸ºä¸­å¿ƒçš„æ‘˜è¦ä»»åŠ¡ï¼Œä¸ç°æœ‰æ–¹æ³•ç‹¬ç«‹æå–æ¯ä¸ªè¯æ®å¥ç›¸æ¯”ï¼Œå®ƒé€šè¿‡ä½¿ç”¨RNNå¯¹é—®é¢˜å¥çš„å…³æ³¨æœºåˆ¶<strong>(attention mechanism)</strong>ï¼Œä¾æ¬¡æå–è¯æ®å¥ã€‚å®ƒä½¿QFEè€ƒè™‘åˆ°è¯æ®å¥ä¹‹é—´çš„ä¾èµ–æ€§ï¼Œè¦†ç›–äº†é—®é¢˜å¥ä¸­çš„é‡è¦ä¿¡æ¯ã€‚</p><h3 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h3><blockquote><p>é™¤äº†evidence layerå…¶ä»–éƒ¨åˆ†å’ŒHotpotQAçš„baselineæ¨¡å‹ä¸€æ ·ã€‚</p></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210316140120.png" alt="image-20210316140119983" style="zoom:50%;" /></p><p>Input: Context C (multiple texts), Query Q (text)</p><h4 id="The-Word-Embedding-Layer"><a href="#The-Word-Embedding-Layer" class="headerlink" title="The Word Embedding Layer"></a>The Word Embedding Layer</h4><p>å°†Cå’ŒQç¼–ç ä¸ºè¯å‘é‡(word vectors)åºåˆ—ã€‚</p><p>output: $C_1, Q_1$</p><h4 id="The-Context-Layer"><a href="#The-Context-Layer" class="headerlink" title="The Context Layer"></a>The Context Layer</h4><p>encodes $C_1, Q_1$as contextual vectors  $C_2, Q_2$ by using a bi-directional RNN<strong>(Bi-RNN)</strong>.</p><p>output:  $C_2, Q_2$</p><h4 id="The-Matching-Layer"><a href="#The-Matching-Layer" class="headerlink" title="The Matching Layer"></a>The Matching Layer</h4><p>encodes $C_2, Q_2$as matching vectors $C_3$ by using bi-directional attention,a Bi-RNN, and selfattention.</p><h4 id="The-Evidence-Layer"><a href="#The-Evidence-Layer" class="headerlink" title="The Evidence Layer"></a>The Evidence Layer</h4><p>first encodes $C_3$ as $[\overrightarrow{C4};\overleftarrow{C4}]$ by a Bi-RNN.</p><p>è®¾$j_1(i)$ä¸ºCä¸­ç¬¬iå¥çš„ç¬¬ä¸€ä¸ªè¯çš„ç´¢å¼•ï¼Œ$j_2(i)$ä¸ºæœ€åä¸€ä¸ªè¯çš„ç´¢å¼•ã€‚</p><script type="math/tex; mode=display">xi= [\overrightarrow{c4,j_2(i)};\overleftarrow{c4,j_1(i)}] \in R^{2d_c}</script><p>QFEè¾“å‡ºç¬¬iå¥ä¸ºè¯æ®çš„æ¦‚ç‡åˆ†å¸ƒ:</p><script type="math/tex; mode=display">Pr(i) = QFE(X, Y = Q_2)</script><blockquote><p>X:å¥å­çº§ä¸Šä¸‹æ–‡å‘é‡</p><p>Y:ä¸Šä¸‹æ–‡æŸ¥è¯¢å‘é‡Q2</p></blockquote><p>è¯æ®å±‚å°†å•è¯çº§å‘é‡å’Œå¥å­çº§å‘é‡è¿æ¥èµ·æ¥ã€‚</p><script type="math/tex; mode=display">c_5,j= [c_3,j; x_{i(j)}] \in R^{3d_c}</script><h4 id="The-Answer-Layer"><a href="#The-Answer-Layer" class="headerlink" title="The Answer Layer"></a>The Answer Layer</h4><p>predicts the answer type $A_T$ and the answer string $A_S$ from $C_5$.</p><p>Answer Layeræœ‰å¤šä¸ªå †å çš„Bi-RNNã€‚æ¯ä¸ªBi-RNNçš„è¾“å‡ºè¢«å…¨è¿æ¥å±‚å’Œsoftmaxå‡½æ•°æ˜ å°„åˆ°æ¦‚ç‡åˆ†å¸ƒä¸Šã€‚</p><h3 id="Query-Focused-Extractor"><a href="#Query-Focused-Extractor" class="headerlink" title="Query Focused Extractor"></a>Query Focused Extractor</h3><p>QFEç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210316152458.png" alt="image-20210316152458943" style="zoom:50%;" /></p><p>input:</p><blockquote><p>X:å¥å­çº§ä¸Šä¸‹æ–‡å‘é‡</p><p>Y:ä¸Šä¸‹æ–‡æŸ¥è¯¢å‘é‡</p></blockquote><p>å°†timestepå®šä¹‰ä¸ºæå–å¥å­çš„æ“ä½œã€‚</p><p>RNNçŠ¶æ€æ›´æ–°ï¼š</p><script type="math/tex; mode=display">z^t= RNN(z^{tâˆ’1}, x_{e^t}) \in R^{2d_c}</script><blockquote><p>$e^tâˆˆ {1, Â· Â· Â· , l_s}$ is the index of the sentence extracted at step t</p><p>$E^t= {e^1, Â· Â· Â· , e^t}$ to be the set of sentences extracted until step t</p></blockquote><p>QFEæ ¹æ®æ¦‚ç‡åˆ†å¸ƒæå–ç¬¬iä¸ªå¥å­ï¼š</p><script type="math/tex; mode=display">Pr(i; E^{tâˆ’1}) = softmax_i(u_i^t)</script><p>QFEé€‰æ‹©$e^t$:</p><script type="math/tex; mode=display">et= argmax Pr(i; E^{tâˆ’1})</script><p>RNNçš„åˆå§‹çŠ¶æ€æ˜¯é€šè¿‡å…¨è¿æ¥å±‚å’ŒXçš„æœ€å¤§æ± è·å¾—çš„å‘é‡ã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>HotpotQA</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210316130622.png" alt="image-20210316130615098" style="zoom: 50%;" /></p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210316193625.png" alt="image-20210316193625423" style="zoom:50%;" /></p><ul><li>åœ¨distractor settingä¸‹ï¼ŒQFEè¯æ®æå–å¾—åˆ†æ–¹é¢è¡¨ç°æœ€å¥½ã€‚åœ¨joint EM and F1 metricsä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚QFEåœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºåŸºçº¿æ¨¡å‹çš„è¡¨ç°ã€‚</li><li>QFEæ²¡æœ‰ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½†åœ¨Evidenceçš„è¯„æµ‹ä¸‹æ€§èƒ½è¦æ¯”æ¯”DFGN + BERT å’Œ BERT Pluså‡ºè‰²ã€‚</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210316194952.png" alt="image-20210316194952729" style="zoom:50%;" /></p><ul><li>åœ¨fullwiki settingä¸‹ï¼ŒQFEæ€§èƒ½ä¼˜äºbaselineæ¨¡å‹ã€‚</li><li>å› ä¸ºfullwikiçš„gold evidence sentenceså¯èƒ½ä¼šå°‘äºä¸¤ä¸ªç”šè‡³æ— æ³•å›ç­”ï¼Œå‡ºç°æ•°æ®é›†ç§»ä½çš„é—®é¢˜å¯¼è‡´æ€§èƒ½æœªè¶…è¶ŠCognitive Graphã€‚</li></ul><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><h3 id="æ¶ˆèå®éªŒ"><a href="#æ¶ˆèå®éªŒ" class="headerlink" title="æ¶ˆèå®éªŒ"></a>æ¶ˆèå®éªŒ</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210316195539.png" alt="image-20210316195539401" style="zoom:50%;" /></p><ul><li>evidence extraction modelå¯¹è¯æ®æå–å’Œç­”æ¡ˆæå–æœ‰æ•ˆã€‚</li><li>åˆ°è¾¾EOEå¥å­è‡ªé€‚åº”ç»ˆæ­¢æå–ï¼Œå¯¹æ¨¡å‹æ•ˆæœæœ‰æ‰€æå‡ã€‚</li></ul><p>â€‹        å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨ç®€å•RCåŸºçº¿æ¨¡å‹çš„QFEåœ¨HotpotQAä¸Šå®ç°äº†æœ€å…ˆè¿›çš„è¯æ®æå–å¾—åˆ†ã€‚è™½ç„¶æ˜¯ä¸ºRCè®¾è®¡çš„ï¼Œä½†åœ¨FEVERä¸Šä¹Ÿå–å¾—äº†æœ€å…ˆè¿›çš„è¯æ®æå–æˆç»©ã€‚ï¼ˆFEVERæ˜¯ä¸€ä¸ªåœ¨å¤§å‹æ–‡æœ¬æ•°æ®åº“ä¸Šè¯†åˆ«æ–‡æœ¬çš„ä»»åŠ¡ï¼‰ï¼ŒQFEæ›¿ä»£è¯æ®æå–æ¨¡å—å¯æé«˜æ€§èƒ½ï¼Œè‡ªé€‚åº”ç»ˆæ­¢æå–æœ‰åŠ©äºç¡®åˆ‡åŒ¹é…å’Œè¯æ®æå–çš„ç²¾ç¡®åº¦ï¼ŒQFEé—®é¢˜çš„éš¾åº¦å–å†³äºæ‰€éœ€è¯æ®å¥å­çš„æ•°é‡ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> HotpotQA </tag>
            
            <tag> QFE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨é€»è¾‘å›å½’å¯¹é¸¢å°¾èŠ±è¿›è¡Œåˆ†ç±»</title>
      <link href="/2021/03/18/%E4%BD%BF%E7%94%A8%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%AF%B9%E9%B8%A2%E5%B0%BE%E8%8A%B1%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/"/>
      <url>/2021/03/18/%E4%BD%BF%E7%94%A8%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%AF%B9%E9%B8%A2%E5%B0%BE%E8%8A%B1%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨é€»è¾‘å›å½’å¯¹é¸¢å°¾èŠ±è¿›è¡Œåˆ†ç±»"><a href="#ä½¿ç”¨é€»è¾‘å›å½’å¯¹é¸¢å°¾èŠ±è¿›è¡Œåˆ†ç±»" class="headerlink" title="ä½¿ç”¨é€»è¾‘å›å½’å¯¹é¸¢å°¾èŠ±è¿›è¡Œåˆ†ç±»"></a>ä½¿ç”¨é€»è¾‘å›å½’å¯¹é¸¢å°¾èŠ±è¿›è¡Œåˆ†ç±»</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åŠ è½½æ•°æ®é›†</span></span><br><span class="line">iris = load_iris()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ‰“å°æ•°æ®é›†æè¿°</span></span><br><span class="line"><span class="built_in">print</span>(iris.DESCR)</span><br></pre></td></tr></table></figure><pre><code>.. _iris_dataset:Iris plants dataset--------------------**Data Set Characteristics:**    :Number of Instances: 150 (50 in each of three classes)    :Number of Attributes: 4 numeric, predictive attributes and the class    :Attribute Information:        - sepal length in cm        - sepal width in cm        - petal length in cm        - petal width in cm        - class:                - Iris-Setosa                - Iris-Versicolour                - Iris-Virginica    :Summary Statistics:    ============== ==== ==== ======= ===== ====================                    Min  Max   Mean    SD   Class Correlation    ============== ==== ==== ======= ===== ====================    sepal length:   4.3  7.9   5.84   0.83    0.7826    sepal width:    2.0  4.4   3.05   0.43   -0.4194    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)    ============== ==== ==== ======= ===== ====================    :Missing Attribute Values: None    :Class Distribution: 33.3% for each of 3 classes.    :Creator: R.A. Fisher    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)    :Date: July, 1988The famous Iris database, first used by Sir R.A. Fisher. The dataset is takenfrom Fisher&#39;s paper. Note that it&#39;s the same as in R, but not as in the UCIMachine Learning Repository, which has two wrong data points.This is perhaps the best known database to be found in thepattern recognition literature.  Fisher&#39;s paper is a classic in the field andis referenced frequently to this day.  (See Duda &amp; Hart, for example.)  Thedata set contains 3 classes of 50 instances each, where each class refers to atype of iris plant.  One class is linearly separable from the other 2; thelatter are NOT linearly separable from each other... topic:: References   - Fisher, R.A. &quot;The use of multiple measurements in taxonomic problems&quot;     Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to     Mathematical Statistics&quot; (John Wiley, NY, 1950).   - Duda, R.O., &amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.     (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.   - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System     Structure and Classification Rule for Recognition in Partially Exposed     Environments&quot;.  IEEE Transactions on Pattern Analysis and Machine     Intelligence, Vol. PAMI-2, No. 1, 67-71.   - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;.  IEEE Transactions     on Information Theory, May 1972, 431-433.   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al&quot;s AUTOCLASS II     conceptual clustering system finds 3 classes in the data.   - Many, many more ...</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(iris)</span><br></pre></td></tr></table></figure><pre><code>&#123;&#39;data&#39;: array([[5.1, 3.5, 1.4, 0.2],       [4.9, 3. , 1.4, 0.2],       [4.7, 3.2, 1.3, 0.2],       [4.6, 3.1, 1.5, 0.2],       [5. , 3.6, 1.4, 0.2],       [5.4, 3.9, 1.7, 0.4],       [4.6, 3.4, 1.4, 0.3],       [5. , 3.4, 1.5, 0.2],       [4.4, 2.9, 1.4, 0.2],       [4.9, 3.1, 1.5, 0.1],       [5.4, 3.7, 1.5, 0.2],       [4.8, 3.4, 1.6, 0.2],       [4.8, 3. , 1.4, 0.1],       [4.3, 3. , 1.1, 0.1],       [5.8, 4. , 1.2, 0.2],       [5.7, 4.4, 1.5, 0.4],       [5.4, 3.9, 1.3, 0.4],       [5.1, 3.5, 1.4, 0.3],       [5.7, 3.8, 1.7, 0.3],       [5.1, 3.8, 1.5, 0.3],       [5.4, 3.4, 1.7, 0.2],       [5.1, 3.7, 1.5, 0.4],       [4.6, 3.6, 1. , 0.2],       [5.1, 3.3, 1.7, 0.5],       [4.8, 3.4, 1.9, 0.2],       [5. , 3. , 1.6, 0.2],       [5. , 3.4, 1.6, 0.4],       [5.2, 3.5, 1.5, 0.2],       [5.2, 3.4, 1.4, 0.2],       [4.7, 3.2, 1.6, 0.2],       [4.8, 3.1, 1.6, 0.2],       [5.4, 3.4, 1.5, 0.4],       [5.2, 4.1, 1.5, 0.1],       [5.5, 4.2, 1.4, 0.2],       [4.9, 3.1, 1.5, 0.2],       [5. , 3.2, 1.2, 0.2],       [5.5, 3.5, 1.3, 0.2],       [4.9, 3.6, 1.4, 0.1],       [4.4, 3. , 1.3, 0.2],       [5.1, 3.4, 1.5, 0.2],       [5. , 3.5, 1.3, 0.3],       [4.5, 2.3, 1.3, 0.3],       [4.4, 3.2, 1.3, 0.2],       [5. , 3.5, 1.6, 0.6],       [5.1, 3.8, 1.9, 0.4],       [4.8, 3. , 1.4, 0.3],       [5.1, 3.8, 1.6, 0.2],       [4.6, 3.2, 1.4, 0.2],       [5.3, 3.7, 1.5, 0.2],       [5. , 3.3, 1.4, 0.2],       [7. , 3.2, 4.7, 1.4],       [6.4, 3.2, 4.5, 1.5],       [6.9, 3.1, 4.9, 1.5],       [5.5, 2.3, 4. , 1.3],       [6.5, 2.8, 4.6, 1.5],       [5.7, 2.8, 4.5, 1.3],       [6.3, 3.3, 4.7, 1.6],       [4.9, 2.4, 3.3, 1. ],       [6.6, 2.9, 4.6, 1.3],       [5.2, 2.7, 3.9, 1.4],       [5. , 2. , 3.5, 1. ],       [5.9, 3. , 4.2, 1.5],       [6. , 2.2, 4. , 1. ],       [6.1, 2.9, 4.7, 1.4],       [5.6, 2.9, 3.6, 1.3],       [6.7, 3.1, 4.4, 1.4],       [5.6, 3. , 4.5, 1.5],       [5.8, 2.7, 4.1, 1. ],       [6.2, 2.2, 4.5, 1.5],       [5.6, 2.5, 3.9, 1.1],       [5.9, 3.2, 4.8, 1.8],       [6.1, 2.8, 4. , 1.3],       [6.3, 2.5, 4.9, 1.5],       [6.1, 2.8, 4.7, 1.2],       [6.4, 2.9, 4.3, 1.3],       [6.6, 3. , 4.4, 1.4],       [6.8, 2.8, 4.8, 1.4],       [6.7, 3. , 5. , 1.7],       [6. , 2.9, 4.5, 1.5],       [5.7, 2.6, 3.5, 1. ],       [5.5, 2.4, 3.8, 1.1],       [5.5, 2.4, 3.7, 1. ],       [5.8, 2.7, 3.9, 1.2],       [6. , 2.7, 5.1, 1.6],       [5.4, 3. , 4.5, 1.5],       [6. , 3.4, 4.5, 1.6],       [6.7, 3.1, 4.7, 1.5],       [6.3, 2.3, 4.4, 1.3],       [5.6, 3. , 4.1, 1.3],       [5.5, 2.5, 4. , 1.3],       [5.5, 2.6, 4.4, 1.2],       [6.1, 3. , 4.6, 1.4],       [5.8, 2.6, 4. , 1.2],       [5. , 2.3, 3.3, 1. ],       [5.6, 2.7, 4.2, 1.3],       [5.7, 3. , 4.2, 1.2],       [5.7, 2.9, 4.2, 1.3],       [6.2, 2.9, 4.3, 1.3],       [5.1, 2.5, 3. , 1.1],       [5.7, 2.8, 4.1, 1.3],       [6.3, 3.3, 6. , 2.5],       [5.8, 2.7, 5.1, 1.9],       [7.1, 3. , 5.9, 2.1],       [6.3, 2.9, 5.6, 1.8],       [6.5, 3. , 5.8, 2.2],       [7.6, 3. , 6.6, 2.1],       [4.9, 2.5, 4.5, 1.7],       [7.3, 2.9, 6.3, 1.8],       [6.7, 2.5, 5.8, 1.8],       [7.2, 3.6, 6.1, 2.5],       [6.5, 3.2, 5.1, 2. ],       [6.4, 2.7, 5.3, 1.9],       [6.8, 3. , 5.5, 2.1],       [5.7, 2.5, 5. , 2. ],       [5.8, 2.8, 5.1, 2.4],       [6.4, 3.2, 5.3, 2.3],       [6.5, 3. , 5.5, 1.8],       [7.7, 3.8, 6.7, 2.2],       [7.7, 2.6, 6.9, 2.3],       [6. , 2.2, 5. , 1.5],       [6.9, 3.2, 5.7, 2.3],       [5.6, 2.8, 4.9, 2. ],       [7.7, 2.8, 6.7, 2. ],       [6.3, 2.7, 4.9, 1.8],       [6.7, 3.3, 5.7, 2.1],       [7.2, 3.2, 6. , 1.8],       [6.2, 2.8, 4.8, 1.8],       [6.1, 3. , 4.9, 1.8],       [6.4, 2.8, 5.6, 2.1],       [7.2, 3. , 5.8, 1.6],       [7.4, 2.8, 6.1, 1.9],       [7.9, 3.8, 6.4, 2. ],       [6.4, 2.8, 5.6, 2.2],       [6.3, 2.8, 5.1, 1.5],       [6.1, 2.6, 5.6, 1.4],       [7.7, 3. , 6.1, 2.3],       [6.3, 3.4, 5.6, 2.4],       [6.4, 3.1, 5.5, 1.8],       [6. , 3. , 4.8, 1.8],       [6.9, 3.1, 5.4, 2.1],       [6.7, 3.1, 5.6, 2.4],       [6.9, 3.1, 5.1, 2.3],       [5.8, 2.7, 5.1, 1.9],       [6.8, 3.2, 5.9, 2.3],       [6.7, 3.3, 5.7, 2.5],       [6.7, 3. , 5.2, 2.3],       [6.3, 2.5, 5. , 1.9],       [6.5, 3. , 5.2, 2. ],       [6.2, 3.4, 5.4, 2.3],       [5.9, 3. , 5.1, 1.8]]), &#39;target&#39;: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), &#39;target_names&#39;: array([&#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39;], dtype=&#39;&lt;U10&#39;), &#39;DESCR&#39;: &#39;.. _iris_dataset:\n\nIris plants dataset\n--------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 150 (50 in each of three classes)\n    :Number of Attributes: 4 numeric, predictive attributes and the class\n    :Attribute Information:\n        - sepal length in cm\n        - sepal width in cm\n        - petal length in cm\n        - petal width in cm\n        - class:\n                - Iris-Setosa\n                - Iris-Versicolour\n                - Iris-Virginica\n                \n    :Summary Statistics:\n\n    ============== ==== ==== ======= ===== ====================\n                    Min  Max   Mean    SD   Class Correlation\n    ============== ==== ==== ======= ===== ====================\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n    ============== ==== ==== ======= ===== ====================\n\n    :Missing Attribute Values: None\n    :Class Distribution: 33.3% for each of 3 classes.\n    :Creator: R.A. Fisher\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n    :Date: July, 1988\n\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\nfrom Fisher\&#39;s paper. Note that it\&#39;s the same as in R, but not as in the UCI\nMachine Learning Repository, which has two wrong data points.\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher\&#39;s paper is a classic in the field and\nis referenced frequently to this day.  (See Duda &amp; Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\n.. topic:: References\n\n   - Fisher, R.A. &quot;The use of multiple measurements in taxonomic problems&quot;\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to\n     Mathematical Statistics&quot; (John Wiley, NY, 1950).\n   - Duda, R.O., &amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n     (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.\n   - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System\n     Structure and Classification Rule for Recognition in Partially Exposed\n     Environments&quot;.  IEEE Transactions on Pattern Analysis and Machine\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n   - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;.  IEEE Transactions\n     on Information Theory, May 1972, 431-433.\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al&quot;s AUTOCLASS II\n     conceptual clustering system finds 3 classes in the data.\n   - Many, many more ...&#39;, &#39;feature_names&#39;: [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;], &#39;filename&#39;: &#39;/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/sklearn/datasets/data/iris.csv&#39;&#125;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[<span class="number">0</span>:<span class="number">50</span>,<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. ])</code></pre><h3 id="ä»»å–ä¸¤ä¸ªç‰¹å¾ç”»å›¾"><a href="#ä»»å–ä¸¤ä¸ªç‰¹å¾ç”»å›¾" class="headerlink" title="ä»»å–ä¸¤ä¸ªç‰¹å¾ç”»å›¾"></a>ä»»å–ä¸¤ä¸ªç‰¹å¾ç”»å›¾</h3><blockquote><p>å…±æœ‰4ä¸ªç‰¹å¾ï¼Œæ— æ³•ç”»åœ¨åŒä¸€å¼ äºŒç»´å¹³é¢</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">feature = <span class="number">2</span></span><br><span class="line">feature_other = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">plt.scatter(X[<span class="number">0</span>:<span class="number">50</span>, feature], X[<span class="number">0</span>:<span class="number">50</span>, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;setosa&#x27;</span>)  <span class="comment"># å‰50ä¸ªæ ·æœ¬</span></span><br><span class="line">plt.scatter(X[<span class="number">50</span>:<span class="number">100</span>, feature], X[<span class="number">50</span>:<span class="number">100</span>, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, label=<span class="string">&#x27;versicolor&#x27;</span>)  <span class="comment"># ä¸­é—´50ä¸ª</span></span><br><span class="line">plt.scatter(X[<span class="number">100</span>:, feature], X[<span class="number">100</span>:, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, label=<span class="string">&#x27;Virginica&#x27;</span>)  <span class="comment"># å50ä¸ªæ ·æœ¬</span></span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x7ff42bef14f0&gt;</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210318193437.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ•°æ®ä»£å…¥æ¨¡å‹</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># é€»è¾‘å›å½’æ¨¡å‹</span></span><br><span class="line">model = linear_model.LogisticRegression(C=<span class="number">100.0</span>)</span><br><span class="line">model.fit(X, y)</span><br></pre></td></tr></table></figure><pre><code>/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.Increase the number of iterations (max_iter) or scale the data as shown in:    https://scikit-learn.org/stable/modules/preprocessing.htmlPlease also refer to the documentation for alternative solver options:    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression  n_iter_i = _check_optimize_result(LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,                   intercept_scaling=1, l1_ratio=None, max_iter=100,                   multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;,                   random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=0,                   warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(model.coef_) <span class="comment"># ç³»æ•° theta1,theta2...</span></span><br><span class="line"><span class="built_in">print</span>(model.intercept_) <span class="comment"># æˆªè· theta0</span></span><br><span class="line">y_hat = model.predict(X)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;å‡†ç¡®åº¦=&quot;</span>, accuracy_score(y, y_hat))</span><br></pre></td></tr></table></figure><pre><code>[[-0.27165929  3.28412217 -6.15316158 -4.05114224] [ 1.28462627  0.47872193 -0.5863018  -4.15124947] [-1.01296698 -3.7628441   6.73946338  8.20239171]][ 19.35565008   5.44146183 -24.79711191]å‡†ç¡®åº¦= 0.98</code></pre><h3 id="å¯è§†åŒ–åˆ†ç±»ç»“æœ"><a href="#å¯è§†åŒ–åˆ†ç±»ç»“æœ" class="headerlink" title="å¯è§†åŒ–åˆ†ç±»ç»“æœ"></a>å¯è§†åŒ–åˆ†ç±»ç»“æœ</h3><p>ä¸ºäº†å¯è§†åŒ–åˆ†ç±»ç»“æœï¼Œæˆ‘ä»¬å–2ä¸ªç‰¹å¾è¿›è¡Œè®­ç»ƒ</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">feature = <span class="number">2</span></span><br><span class="line">feature_other = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">X = iris.data</span><br><span class="line">X_2 = X[:, [feature, feature_other]] <span class="comment">#X_2ä¸ºä»…åŒ…å«ä¸¤ä¸ªç‰¹å¾çš„æ•°æ®é›†</span></span><br><span class="line">y = iris.target</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model_2 = linear_model.LogisticRegression(C=<span class="number">100.0</span>)</span><br><span class="line">model_2.fit(X_2, y)</span><br></pre></td></tr></table></figure><pre><code>LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,                   intercept_scaling=1, l1_ratio=None, max_iter=100,                   multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;,                   random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=0,                   warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># meshgridå‡½æ•°ç”Ÿæˆä¸¤ä¸ªç½‘æ ¼çŸ©é˜µ</span></span><br><span class="line">h = <span class="number">.02</span> <span class="comment">#æ­¥é•¿</span></span><br><span class="line">x_min, x_max = X[:, feature].<span class="built_in">min</span>() - <span class="number">.5</span>, X[:, feature].<span class="built_in">max</span>() + <span class="number">.5</span></span><br><span class="line">y_min, y_max = X[:, feature_other].<span class="built_in">min</span>() - <span class="number">.5</span>, X[:, feature_other].<span class="built_in">max</span>() + <span class="number">.5</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xx.shape</span><br></pre></td></tr></table></figure><pre><code>(170, 345)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yy</span><br></pre></td></tr></table></figure><pre><code>array([[-0.4 , -0.4 , -0.4 , ..., -0.4 , -0.4 , -0.4 ],       [-0.38, -0.38, -0.38, ..., -0.38, -0.38, -0.38],       [-0.36, -0.36, -0.36, ..., -0.36, -0.36, -0.36],       ...,       [ 2.94,  2.94,  2.94, ...,  2.94,  2.94,  2.94],       [ 2.96,  2.96,  2.96, ...,  2.96,  2.96,  2.96],       [ 2.98,  2.98,  2.98, ...,  2.98,  2.98,  2.98]])</code></pre><p>æ³¨æ„: [[1,2,3]]è¡¨ç¤ºä¸€è¡Œä¸‰åˆ—ï¼Œ[1,2,3]è¡¨ç¤º3è¡Œä¸€åˆ—ï¼Œæ‰€ä»¥ä¸‹é¢ä»£ç è¦æ‰§è¡Œxx.ravel()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç”Ÿæˆæ–°çš„æ•°æ®ç‚¹ ä¸ºäº†å¡«å……å¹³é¢</span></span><br><span class="line">np.c_[xx.ravel(), yy.ravel()]</span><br></pre></td></tr></table></figure><pre><code>array([[ 0.5 , -0.4 ],       [ 0.52, -0.4 ],       [ 0.54, -0.4 ],       ...,       [ 7.34,  2.98],       [ 7.36,  2.98],       [ 7.38,  2.98]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z = model_2.predict(np.c_[xx.ravel(), yy.ravel()])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z</span><br></pre></td></tr></table></figure><pre><code>array([0, 0, 0, ..., 2, 2, 2])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z.shape</span><br></pre></td></tr></table></figure><pre><code>(58650,)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xx.shape</span><br></pre></td></tr></table></figure><pre><code>(170, 345)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># è®¾ç½®æˆç›¸åŒçº¬åº¦</span></span><br><span class="line">z = z.reshape(xx.shape)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä½¿ç”¨æ–°ç”Ÿæˆçš„æ•°æ®ç‚¹ç»˜åˆ¶å¯†å¯†éº»éº»çš„ç½‘æ ¼å¹³é¢å›¾</span></span><br><span class="line">plt.pcolormesh(xx, yy, z, cmap=plt.cm.Paired)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç»˜åˆ¶åŸå§‹æ•°æ®ç‚¹</span></span><br><span class="line">plt.scatter(X[<span class="number">0</span>:<span class="number">50</span>, feature], X[<span class="number">0</span>:<span class="number">50</span>, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;setosa&#x27;</span>)  <span class="comment"># å‰50ä¸ªæ ·æœ¬</span></span><br><span class="line">plt.scatter(X[<span class="number">50</span>:<span class="number">100</span>, feature], X[<span class="number">50</span>:<span class="number">100</span>, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, label=<span class="string">&#x27;versicolor&#x27;</span>)  <span class="comment"># ä¸­é—´50ä¸ª</span></span><br><span class="line">plt.scatter(X[<span class="number">100</span>:, feature], X[<span class="number">100</span>:, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, label=<span class="string">&#x27;Virginica&#x27;</span>)  <span class="comment"># å50ä¸ªæ ·æœ¬</span></span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x7ff42c464d00&gt;</code></pre><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210318193446.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> sklearn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å¸¸ç”¨ä¸“ä¸šæœ¯è¯­</title>
      <link href="/2021/03/16/%E5%B8%B8%E7%94%A8%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/"/>
      <url>/2021/03/16/%E5%B8%B8%E7%94%A8%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/</url>
      
        <content type="html"><![CDATA[<h1 id="å¸¸ç”¨ä¸“ä¸šæœ¯è¯­"><a href="#å¸¸ç”¨ä¸“ä¸šæœ¯è¯­" class="headerlink" title="å¸¸ç”¨ä¸“ä¸šæœ¯è¯­"></a>å¸¸ç”¨ä¸“ä¸šæœ¯è¯­</h1><p>â€‹    â—¦    comes in handy æ´¾ä¸Šç”¨åœº<br>â€‹    â—¦    future-proofs é¢å‘æœªæ¥<br>â€‹    â—¦    deserialized ååºåˆ—åŒ–<br>â€‹    â—¦    Instantiate å®ä¾‹åŒ–<br>â€‹    â—¦    Simply put ç®€å•çš„è¯´<br>â€‹    â—¦    separate indices å•ç‹¬çš„ç´¢å¼•<br>â€‹    â—¦    diagram å›¾<br>â€‹    â—¦    customize å®šåˆ¶<br>â€‹    â—¦    explicitly æ˜ç¡®åœ°<br>â€‹    â—¦    prune ä¿®å‰ª<br>â€‹    â—¦    threshold é˜ˆ<br>â€‹    â—¦    deep dive æ·±å…¥æ¢è®¨<br>â€‹    â—¦    back-propagation åå‘ä¼ æ’­<br>â€‹    â—¦    accumulator ç´¯åŠ å™¨<br>â€‹    â—¦    cumbersome éº»çƒ¦çš„<br>â€‹    â—¦    analogous ç±»ä¼¼çš„<br>â€‹    â—¦    compatible å…¼å®¹<br>â€‹    â—¦    encapsulates å°è£…<br>â€‹    â—¦    arbitrary ä»»æ„çš„<br>â€‹    â—¦    explicit æ˜¾å¼çš„<br>â€‹    â—¦    heuristics å¯å‘å¼<br>â€‹    â—¦    discarding ä¸¢å¼ƒ<br>â€‹    â—¦    mechanism æœºåˆ¶<br>â€‹    â—¦    notion æ¦‚å¿µ<br>â€‹    â—¦    pseudo ä¼ª<br>â€‹    â—¦    arbitrary ä»»æ„çš„<br>â€‹    â—¦    nested åµŒå¥—çš„<br>â€‹    â—¦    quantifiable å¯é‡åŒ–çš„<br>â€‹    â—¦    spark å¼•å‘<br>â€‹    â—¦    inherently å›ºæœ‰çš„<br>â€‹    â—¦    distant supervision è¿œç¨‹ç›‘ç£<br>â€‹    â—¦    desiderata éœ€æ±‚<br>â€‹    â—¦    nontrivial éå¹³å‡¡çš„<br>â€‹    â—¦    overall setting è¯•ç‚¹ç ”ç©¶<br>â€‹    â—¦    counterproductive é€‚å¾—å…¶å<br>â€‹    â—¦    corpus è¯­æ–™åº“<br>â€‹    â—¦    alleviate å‡è½»<br>â€‹    â—¦    non-negligible ä¸å¯å¿½ç•¥çš„<br>â€‹    â—¦    subsumes åŒ…å«<br>â€‹    â—¦    Intuitively ç›´è§‚åœ°<br>â€‹    â—¦    marginally è¾¹é™…çš„èšåˆ<br>â€‹    â—¦    deterioration æ¶åŒ–<br>â€‹    â—¦    To the best of our knowledge æ®æˆ‘ä»¬æ‰€çŸ¥<br>â€‹    â—¦    in terms of åœ¨â€¦æ–¹é¢<br>â€‹    â—¦    aggregation èšåˆ<br>â€‹    â—¦    lexical è¯æ±‡çš„<br>â€‹    â—¦    iterative åå¤çš„<br>â€‹    â—¦    dampens æŠ‘åˆ¶<br>â€‹    â—¦    iteratively åå¤åœ°<br>â€‹    â—¦    facilitates ä¿ƒè¿›<br>â€‹    â—¦    adaptively é€‚åº”æ€§çš„<br>â€‹    â—¦    compression å‹ç¼©<br>â€‹    â—¦    arbitrary éšæ„çš„<br>â€‹    â—¦    propagate ä¼ æ’­<br>â€‹    â—¦    corpus è¯­æ–™åº“<br>â€‹    â—¦    capability èƒ½åŠ›<br>â€‹    â—¦    To address this challenge åº”å¯¹è¿™ä¸€æŒ‘æˆ˜<br>â€‹    â—¦    off-the-shelf ç°æˆçš„<br>â€‹    â—¦    In contrast ç›¸æ¯”ä¹‹ä¸‹<br>â€‹    â—¦    spread out æ‰©æ•£;ä¼ æ’­å¼€<br>â€‹    â—¦    complementary è¡¥å……<br>â€‹    â—¦    cast æŠ•å‘<br>â€‹    â—¦    jointly å…±åŒ<br>â€‹    â—¦    explicitly æ˜ç¡®<br>â€‹    â—¦    coreference å‚è€ƒèµ„æ–™<br>â€‹    â—¦    heterogeneous å¼‚è´¨<br>â€‹    â—¦    diagram å›¾è¡¨<br>â€‹    â—¦    formulate åˆ¶å®š<br>â€‹    â—¦    examine æ£€æŸ¥<br>â€‹    â—¦    threshold é˜ˆå€¼ ä¸´ç•Œç‚¹<br>â€‹    â—¦    relevance å…³è”<br>â€‹    â—¦    circumstances æƒ…å†µ<br>â€‹    â—¦    conjecture æ¨æµ‹<br>â€‹    â—¦    entailment å¾æœ<br>â€‹    â—¦    coverage èŒƒå›´</p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å•è¯ </tag>
            
            <tag> ä¸“ä¸šæœ¯è¯­ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹</title>
      <link href="/2021/03/15/%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/"/>
      <url>/2021/03/15/%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹"><a href="#æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹" class="headerlink" title="æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹"></a>æ³¢å£«é¡¿æˆ¿ä»·é¢„æµ‹</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span>  linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br></pre></td></tr></table></figure><h2 id="1-è·å–æ•°æ®"><a href="#1-è·å–æ•°æ®" class="headerlink" title="1.è·å–æ•°æ®"></a>1.è·å–æ•°æ®</h2><h3 id="1-1é€šè¿‡load-boston-è·å–æ•°æ®"><a href="#1-1é€šè¿‡load-boston-è·å–æ•°æ®" class="headerlink" title="1.1é€šè¿‡load_boston()è·å–æ•°æ®"></a>1.1é€šè¿‡load_boston()è·å–æ•°æ®</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boston = load_boston()</span><br></pre></td></tr></table></figure><h5 id="ç‰¹å¾å«ä¹‰"><a href="#ç‰¹å¾å«ä¹‰" class="headerlink" title="ç‰¹å¾å«ä¹‰"></a>ç‰¹å¾å«ä¹‰</h5><p>CRIMï¼šåŸé•‡äººå‡çŠ¯ç½ªç‡ã€‚<br/><br>ZNï¼šä½å®…ç”¨åœ°è¶…è¿‡ 25000 sq.ft. çš„æ¯”ä¾‹ã€‚<br/><br>INDUSï¼šåŸé•‡éé›¶å”®å•†ç”¨åœŸåœ°çš„æ¯”ä¾‹ã€‚<br/><br>CHASï¼šæŸ¥ç†æ–¯æ²³ç©ºå˜é‡ï¼ˆå¦‚æœè¾¹ç•Œæ˜¯æ²³æµï¼Œåˆ™ä¸º1ï¼›å¦åˆ™ä¸º0ï¼‰ã€‚<br/><br>NOXï¼šä¸€æ°§åŒ–æ°®æµ“åº¦ã€‚<br/><br>RMï¼šä½å®…å¹³å‡æˆ¿é—´æ•°ã€‚<br/><br>AGEï¼š1940 å¹´ä¹‹å‰å»ºæˆçš„è‡ªç”¨æˆ¿å±‹æ¯”ä¾‹ã€‚<br/><br>DISï¼šåˆ°æ³¢å£«é¡¿äº”ä¸ªä¸­å¿ƒåŒºåŸŸçš„åŠ æƒè·ç¦»ã€‚<br/><br>RADï¼šè¾å°„æ€§å…¬è·¯çš„æ¥è¿‘æŒ‡æ•°ã€‚<br/><br>TAXï¼šæ¯ 10000 ç¾å…ƒçš„å…¨å€¼è´¢äº§ç¨ç‡ã€‚<br/><br>PTRATIOï¼šåŸé•‡å¸ˆç”Ÿæ¯”ä¾‹ã€‚<br/><br>Bï¼š1000ï¼ˆBk-0.63ï¼‰^ 2ï¼Œå…¶ä¸­ Bk æŒ‡ä»£åŸé•‡ä¸­é»‘äººçš„æ¯”ä¾‹ã€‚<br/><br>LSTATï¼šäººå£ä¸­åœ°ä½ä½ä¸‹è€…çš„æ¯”ä¾‹ã€‚<br/><br>MEDVï¼šè‡ªä½æˆ¿çš„å¹³å‡æˆ¿ä»·ï¼Œä»¥åƒç¾å…ƒè®¡ã€‚<br/></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ•°æ®æè¿°</span></span><br><span class="line"><span class="built_in">print</span>(boston.DESCR)</span><br></pre></td></tr></table></figure><pre><code>.. _boston_dataset:Boston house prices dataset---------------------------**Data Set Characteristics:**      :Number of Instances: 506     :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.    :Attribute Information (in order):        - CRIM     per capita crime rate by town        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.        - INDUS    proportion of non-retail business acres per town        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)        - NOX      nitric oxides concentration (parts per 10 million)        - RM       average number of rooms per dwelling        - AGE      proportion of owner-occupied units built prior to 1940        - DIS      weighted distances to five Boston employment centres        - RAD      index of accessibility to radial highways        - TAX      full-value property-tax rate per $10,000        - PTRATIO  pupil-teacher ratio by town        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town        - LSTAT    % lower status of the population        - MEDV     Median value of owner-occupied homes in $1000&#39;s    :Missing Attribute Values: None    :Creator: Harrison, D. and Rubinfeld, D.L.This is a copy of UCI ML housing dataset.https://archive.ics.uci.edu/ml/machine-learning-databases/housing/</code></pre><p>â€‹<br>â€‹    This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.<br>â€‹<br>    The Boston house-price data of Harrison, D. and Rubinfeld, D.L. â€˜Hedonic<br>    prices and the demand for clean airâ€™, J. Environ. Economics &amp; Management,<br>    vol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, â€˜Regression diagnostics<br>    â€¦â€™, Wiley, 1980.   N.B. Various transformations are used in the table on<br>    pages 244-261 of the latter.</p><pre><code>The Boston house-price data has been used in many machine learning papers that address regressionproblems.   .. topic:: References   - Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics: Identifying Influential Data and Sources of Collinearity&#39;, Wiley, 1980. 244-261.   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æŸ¥çœ‹æ•°æ®</span></span><br><span class="line"><span class="built_in">print</span>(boston)</span><br></pre></td></tr></table></figure><pre><code>&#123;&#39;data&#39;: array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,        4.9800e+00],       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,        9.1400e+00],       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,        4.0300e+00],       ...,       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,        5.6400e+00],       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,        6.4800e+00],       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,        7.8800e+00]]), &#39;target&#39;: array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]), &#39;feature_names&#39;: array([&#39;CRIM&#39;, &#39;ZN&#39;, &#39;INDUS&#39;, &#39;CHAS&#39;, &#39;NOX&#39;, &#39;RM&#39;, &#39;AGE&#39;, &#39;DIS&#39;, &#39;RAD&#39;,       &#39;TAX&#39;, &#39;PTRATIO&#39;, &#39;B&#39;, &#39;LSTAT&#39;], dtype=&#39;&lt;U7&#39;), &#39;DESCR&#39;: &quot;.. _boston_dataset:\n\nBoston house prices dataset\n---------------------------\n\n**Data Set Characteristics:**  \n\n    :Number of Instances: 506 \n\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n    :Attribute Information (in order):\n        - CRIM     per capita crime rate by town\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS    proportion of non-retail business acres per town\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX      nitric oxides concentration (parts per 10 million)\n        - RM       average number of rooms per dwelling\n        - AGE      proportion of owner-occupied units built prior to 1940\n        - DIS      weighted distances to five Boston employment centres\n        - RAD      index of accessibility to radial highways\n        - TAX      full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n        - LSTAT    % lower status of the population\n        - MEDV     Median value of owner-occupied homes in $1000&#39;s\n\n    :Missing Attribute Values: None\n\n    :Creator: Harrison, D. and Rubinfeld, D.L.\n\nThis is a copy of UCI ML housing dataset.\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n\n\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. &#39;Hedonic\nprices and the demand for clean air&#39;, J. Environ. Economics &amp; Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics\n...&#39;, Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.\n\nThe Boston house-price data has been used in many machine learning papers that address regression\nproblems.   \n     \n.. topic:: References\n\n   - Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics: Identifying Influential Data and Sources of Collinearity&#39;, Wiley, 1980. 244-261.\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n&quot;, &#39;filename&#39;: &#39;/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/sklearn/datasets/data/boston_house_prices.csv&#39;&#125;</code></pre><h4 id="å–ç‰¹å¾Xå’Œæ ‡ç­¾y"><a href="#å–ç‰¹å¾Xå’Œæ ‡ç­¾y" class="headerlink" title="å–ç‰¹å¾Xå’Œæ ‡ç­¾y"></a>å–ç‰¹å¾Xå’Œæ ‡ç­¾y</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = boston.data</span><br><span class="line">y = boston.target</span><br></pre></td></tr></table></figure><h3 id="1-2-ä»æ–‡ä»¶è¯»å–"><a href="#1-2-ä»æ–‡ä»¶è¯»å–" class="headerlink" title="1.2 ä»æ–‡ä»¶è¯»å–"></a>1.2 ä»æ–‡ä»¶è¯»å–</h3><p>ä½¿ç”¨pandasè¯»å–ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_excel(<span class="string">&#x27;data/boston.xls&#x27;</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Unnamed: 0</th>      <th>CRIM</th>      <th>ZN</th>      <th>INDUS</th>      <th>CHAS</th>      <th>NOX</th>      <th>RM</th>      <th>AGE</th>      <th>DIS</th>      <th>RAD</th>      <th>TAX</th>      <th>PTRATIO</th>      <th>B</th>      <th>LSTAT</th>      <th>price</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>0.00632</td>      <td>18.0</td>      <td>2.31</td>      <td>0</td>      <td>0.538</td>      <td>6.575</td>      <td>65.2</td>      <td>4.0900</td>      <td>1</td>      <td>296</td>      <td>15.3</td>      <td>396.90</td>      <td>4.98</td>      <td>24.0</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>0.02731</td>      <td>0.0</td>      <td>7.07</td>      <td>0</td>      <td>0.469</td>      <td>6.421</td>      <td>78.9</td>      <td>4.9671</td>      <td>2</td>      <td>242</td>      <td>17.8</td>      <td>396.90</td>      <td>9.14</td>      <td>21.6</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>0.02729</td>      <td>0.0</td>      <td>7.07</td>      <td>0</td>      <td>0.469</td>      <td>7.185</td>      <td>61.1</td>      <td>4.9671</td>      <td>2</td>      <td>242</td>      <td>17.8</td>      <td>392.83</td>      <td>4.03</td>      <td>34.7</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>0.03237</td>      <td>0.0</td>      <td>2.18</td>      <td>0</td>      <td>0.458</td>      <td>6.998</td>      <td>45.8</td>      <td>6.0622</td>      <td>3</td>      <td>222</td>      <td>18.7</td>      <td>394.63</td>      <td>2.94</td>      <td>33.4</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>0.06905</td>      <td>0.0</td>      <td>2.18</td>      <td>0</td>      <td>0.458</td>      <td>7.147</td>      <td>54.2</td>      <td>6.0622</td>      <td>3</td>      <td>222</td>      <td>18.7</td>      <td>396.90</td>      <td>5.33</td>      <td>36.2</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>501</th>      <td>501</td>      <td>0.06263</td>      <td>0.0</td>      <td>11.93</td>      <td>0</td>      <td>0.573</td>      <td>6.593</td>      <td>69.1</td>      <td>2.4786</td>      <td>1</td>      <td>273</td>      <td>21.0</td>      <td>391.99</td>      <td>9.67</td>      <td>22.4</td>    </tr>    <tr>      <th>502</th>      <td>502</td>      <td>0.04527</td>      <td>0.0</td>      <td>11.93</td>      <td>0</td>      <td>0.573</td>      <td>6.120</td>      <td>76.7</td>      <td>2.2875</td>      <td>1</td>      <td>273</td>      <td>21.0</td>      <td>396.90</td>      <td>9.08</td>      <td>20.6</td>    </tr>    <tr>      <th>503</th>      <td>503</td>      <td>0.06076</td>      <td>0.0</td>      <td>11.93</td>      <td>0</td>      <td>0.573</td>      <td>6.976</td>      <td>91.0</td>      <td>2.1675</td>      <td>1</td>      <td>273</td>      <td>21.0</td>      <td>396.90</td>      <td>5.64</td>      <td>23.9</td>    </tr>    <tr>      <th>504</th>      <td>504</td>      <td>0.10959</td>      <td>0.0</td>      <td>11.93</td>      <td>0</td>      <td>0.573</td>      <td>6.794</td>      <td>89.3</td>      <td>2.3889</td>      <td>1</td>      <td>273</td>      <td>21.0</td>      <td>393.45</td>      <td>6.48</td>      <td>22.0</td>    </tr>    <tr>      <th>505</th>      <td>505</td>      <td>0.04741</td>      <td>0.0</td>      <td>11.93</td>      <td>0</td>      <td>0.573</td>      <td>6.030</td>      <td>80.8</td>      <td>2.5050</td>      <td>1</td>      <td>273</td>      <td>21.0</td>      <td>396.90</td>      <td>7.88</td>      <td>11.9</td>    </tr>  </tbody></table><p>506 rows Ã— 15 columns</p></div><h4 id="å–ç‰¹å¾Xå’Œæ ‡ç­¾y-1"><a href="#å–ç‰¹å¾Xå’Œæ ‡ç­¾y-1" class="headerlink" title="å–ç‰¹å¾Xå’Œæ ‡ç­¾y"></a>å–ç‰¹å¾Xå’Œæ ‡ç­¾y</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = df[df.columns[<span class="number">0</span>:-<span class="number">1</span>]]</span><br><span class="line">y = df[df.columns[-<span class="number">1</span>]]</span><br></pre></td></tr></table></figure><h2 id="2ã€é€‰æ‹©åˆé€‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹"><a href="#2ã€é€‰æ‹©åˆé€‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹" class="headerlink" title="2ã€é€‰æ‹©åˆé€‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹"></a>2ã€é€‰æ‹©åˆé€‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹</h2><p>è¯¥é—®é¢˜æ˜¯æˆ¿ä»·é¢„æµ‹é—®é¢˜ï¼Œçº¿æ€§å›å½’èƒ½å¾ˆå¥½çš„åº”ç”¨äºé¢„æµ‹é—®é¢˜ï¼Œå› æ­¤æˆ‘ä»¬é€‰æ‹©ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = linear_model.Ridge(alpha=<span class="number">0.1</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line">y_hat = model.predict(X)</span><br></pre></td></tr></table></figure><h2 id="3ã€è®­ç»ƒæ¨¡å‹-ä½¿ç”¨äº¤å‰éªŒè¯é€‰æ‹©åˆé€‚çš„å‚æ•°"><a href="#3ã€è®­ç»ƒæ¨¡å‹-ä½¿ç”¨äº¤å‰éªŒè¯é€‰æ‹©åˆé€‚çš„å‚æ•°" class="headerlink" title="3ã€è®­ç»ƒæ¨¡å‹(ä½¿ç”¨äº¤å‰éªŒè¯é€‰æ‹©åˆé€‚çš„å‚æ•°)"></a>3ã€è®­ç»ƒæ¨¡å‹(ä½¿ç”¨äº¤å‰éªŒè¯é€‰æ‹©åˆé€‚çš„å‚æ•°)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åˆ‡åˆ†æ•°æ®é›†</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ridge_model = linear_model.Ridge()</span><br><span class="line"><span class="comment"># å¯é€‰å‚æ•°èŒƒå›´</span></span><br><span class="line">param = &#123;<span class="string">&#x27;alpha&#x27;</span>:[<span class="number">0.01</span>,<span class="number">0.03</span>,<span class="number">0.05</span>,<span class="number">0.07</span>,<span class="number">0.1</span>,<span class="number">0.5</span>,<span class="number">0.8</span>,<span class="number">1</span>],<span class="string">&#x27;normalize&#x27;</span>:[<span class="literal">True</span>,<span class="literal">False</span>]&#125;</span><br><span class="line"><span class="comment"># cv=5 5æŠ˜äº¤å‰éªŒè¯</span></span><br><span class="line">gsearch = GridSearchCV(estimator=ridge_model,param_grid=param,cv=<span class="number">5</span>,scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>)</span><br><span class="line">gsearch.fit(X_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>GridSearchCV(cv=5, error_score=nan,             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,                             max_iter=None, normalize=False, random_state=None,                             solver=&#39;auto&#39;, tol=0.001),             iid=&#39;deprecated&#39;, n_jobs=None,             param_grid=&#123;&#39;alpha&#39;: [0.01, 0.03, 0.05, 0.07, 0.1, 0.5, 0.8, 1],                         &#39;normalize&#39;: [True, False]&#125;,             pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=False,             scoring=&#39;neg_mean_squared_error&#39;, verbose=0)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æœ€ä¼˜å‚æ•°</span></span><br><span class="line">gsearch.best_params_,gsearch.best_score_</span><br></pre></td></tr></table></figure><pre><code>(&#123;&#39;alpha&#39;: 0.03, &#39;normalize&#39;: True&#125;, -26.79889044849392)</code></pre><h2 id="4ã€æ¨¡å‹è¯„ä»·"><a href="#4ã€æ¨¡å‹è¯„ä»·" class="headerlink" title="4ã€æ¨¡å‹è¯„ä»·"></a>4ã€æ¨¡å‹è¯„ä»·</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">final_model = linear_model.Ridge(alpha=<span class="number">0.03</span>,normalize=<span class="literal">True</span>)</span><br><span class="line">final_model.fit(X_train,y_train)</span><br><span class="line">y_train_hat = final_model.predict(X_train)</span><br><span class="line">y_test_hat = final_model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train-MSE=&quot;</span>,mean_squared_error(y_train,y_train_hat))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test-MSE=&quot;</span>,mean_squared_error(y_test,y_test_hat))</span><br></pre></td></tr></table></figure><pre><code>train-MSE= 23.97025486039045test-MSE= 14.309867058504892</code></pre><h2 id="5ã€ä¸Šçº¿éƒ¨ç½²ä½¿ç”¨"><a href="#5ã€ä¸Šçº¿éƒ¨ç½²ä½¿ç”¨" class="headerlink" title="5ã€ä¸Šçº¿éƒ¨ç½²ä½¿ç”¨"></a>5ã€ä¸Šçº¿éƒ¨ç½²ä½¿ç”¨</h2><h3 id="5-1-ä¿å­˜æ¨¡å‹"><a href="#5-1-ä¿å­˜æ¨¡å‹" class="headerlink" title="5.1 ä¿å­˜æ¨¡å‹"></a>5.1 ä¿å­˜æ¨¡å‹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line">joblib.dump(final_model,<span class="string">&quot;house_train_model.m&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.  warnings.warn(msg, category=FutureWarning)[&#39;house_train_model.m&#39;]</code></pre><h3 id="5-2-æ¨¡å‹è¯»å–"><a href="#5-2-æ¨¡å‹è¯»å–" class="headerlink" title="5.2 æ¨¡å‹è¯»å–"></a>5.2 æ¨¡å‹è¯»å–</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load_model = joblib.load(<span class="string">&quot;house_train_model.m&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load_model.predict(X_test)</span><br></pre></td></tr></table></figure><pre><code>array([30.86303512, 32.79968797, 18.13455905, 20.40093887, 22.55648762,       18.52481884,  5.79687417, 21.9629842 ,  9.0068248 ,  9.96212273,       17.65398317, 30.25054533, 25.10003805, 17.40790836, 21.33936858,       33.59055899, 16.86450916, 19.61200224,  6.91328576, 25.14956329,       29.29708671, 15.44101851, 38.50687743, 15.56660779, 28.75792533,       14.87142875, 26.98223834, 15.26065778, 18.16696527, 28.15512538,       24.97284918, 21.69102163, 32.29555697, 20.20588182, 20.21130528,       19.51947782, 26.97609243, 17.12827828, 22.2803063 , 22.64121736,        8.72866157, 22.17943575, 28.66894552, 22.05452734, 18.08105446,       27.06372036, 29.40518658, 20.53498735, 34.30239592, 25.2630965 ,       17.91569653, 16.47077539, 24.93826934, 17.02902032, 28.46656821,       19.43795752, 31.32818684, 39.21693664, 10.21290457, 29.7576716 ,       18.44035523, 21.47856043, 15.61795029, 27.61939858, 32.41498347,       23.21414905, 13.9004624 , 21.08777079, 21.59304958, 19.0168253 ,       16.66463116, 34.61710439, 20.45793411, 23.45252405, 23.49866486,       25.68604367, 22.90430613, 18.7968677 , 21.45816043, 25.57413156,       27.04579564, 14.41884812, 14.45022443, 13.35822713, 13.6005322 ,       27.78762317, 23.48920868,  6.76428576, 22.03442767, 20.09361292,       21.33547403, 36.87517116, 37.20038258, 31.35625611, 25.66105111,       23.32712931, 35.89108294, 16.60310795, 19.15123475, 22.65298319,       24.98301704, 36.00402402])</code></pre>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> sklearn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Select, Answer and Explain Interpretable Multi-hop Reading Comprehension over Multiple Documents</title>
      <link href="/2021/03/12/Select%20Answer%20and%20Explain%20Interpretable%20Multi-hop%20Reading%20Comprehension%20over%20Multiple%20Documents/"/>
      <url>/2021/03/12/Select%20Answer%20and%20Explain%20Interpretable%20Multi-hop%20Reading%20Comprehension%20over%20Multiple%20Documents/</url>
      
        <content type="html"><![CDATA[<h1 id="Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents"><a href="#Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents" class="headerlink" title="Select Answer and Explain Interpretable Multi-hop Reading Comprehension over Multiple Documents"></a>Select Answer and Explain Interpretable Multi-hop Reading Comprehension over Multiple Documents</h1><blockquote><p>è®ºæ–‡ï¼š<a href="https://arxiv.org/abs/1911.00484">https://arxiv.org/abs/1911.00484</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>â€‹        åœ¨å¤šæ–‡æ¡£çš„å¤šè·³é˜…è¯»ç†è§£(RC)æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå› ä¸ºå®ƒéœ€è¦å¯¹å¤šä¸ªä¿¡æ¯æºè¿›è¡Œæ¨ç†ï¼Œå¹¶é€šè¿‡æä¾›æ”¯æŒè¯æ®æ¥è§£é‡Šç­”æ¡ˆé¢„æµ‹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆçš„ã€å¯è§£é‡Šæ€§çš„é€‰æ‹©ã€å›ç­”å’Œè§£é‡Š<strong>Select, Answer and Explain(SAE)</strong>ï¼Œç³»ç»Ÿæ¥è§£å†³å¤šæ–‡æ¡£çš„RCé—®é¢˜ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>â€‹        é¦–å…ˆè¿‡æ»¤æ‰ä¸ç­”æ¡ˆæ— å…³çš„æ–‡æ¡£ï¼Œä»è€Œå‡å°‘å¹²æ‰°ä¿¡æ¯é‡ã€‚ç”±ä¸€ä¸ªç”¨æ–°é¢–çš„pairwise learning-to-rank lossè®­ç»ƒçš„æ–‡æ¡£åˆ†ç±»å™¨(document classifier)å®ç°ã€‚ç„¶åå°†æ‰€é€‰çš„ç­”æ¡ˆç›¸å…³æ–‡æ¡£è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œå…±åŒé¢„æµ‹ç­”æ¡ˆå’Œæ”¯æŒå¥ã€‚è¯¥æ¨¡å‹é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ ç›®æ ‡è¿›è¡Œäº†ä¼˜åŒ–ï¼Œåœ¨tokenå±‚é¢ä¸Šè¿›è¡Œç­”æ¡ˆé¢„æµ‹ï¼Œåœ¨å¥å­å±‚é¢ä¸Šè¿›è¡Œè¾…åŠ©å¥å­é¢„æµ‹ï¼ŒåŒæ—¶åœ¨è¿™ä¸¤ä¸ªä»»åŠ¡ä¹‹é—´è¿›è¡Œäº†åŸºäºæ³¨æ„åŠ›çš„äº¤äº’ã€‚ç­”æ¡ˆé¢„æµ‹æ˜¯é€šè¿‡ä»¥å¼€å§‹å’Œç»“æŸæ ‡è®°ä¸ºç›®æ ‡çš„åºåˆ—æ ‡ç­¾æ¥å®Œæˆçš„ï¼Œå°†æ”¯æŒå¥é¢„æµ‹æŠ•å‘(cast)äº†èŠ‚ç‚¹åˆ†ç±»ä»»åŠ¡ã€‚å»ºç«‹äº†ä¸€ä¸ªGNNæ¨¡å‹ï¼Œåœ¨ä¸Šä¸‹æ–‡å¥å­åµŒå…¥ä¸Šåšæ¨ç†ï¼ŒåŸºäºä¸€ç§æ–°é¢–çš„æ··åˆæ³¨æ„åŠ›æ± åŒ–æœºåˆ¶(a novel mixed attentive pooling mechanism)ï¼Œåœ¨tokenè¡¨ç¤ºä¸Šè¿›è¡Œæ€»ç»“ï¼Œå¤šä»»åŠ¡å­¦ä¹ åŠ ä¸Šè¿™ä¸¤ä¸ªä»»åŠ¡ä¹‹é—´åŸºäºæ··åˆæ³¨æ„åŠ›çš„äº¤äº’ï¼Œä¿è¯äº†ä¸¤ä¸ªä»»åŠ¡ä¹‹é—´ä¿¡æ¯çš„äº’è¡¥æ€§å¾—åˆ°åˆ©ç”¨ã€‚</p><h3 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210309194459.png" alt="image-20210309194459126" style="zoom:50%;" /></p><p>è¾“å…¥åˆ°BERTçš„æ•°æ®æ ¼å¼ï¼š<strong>â€œ[CLS]â€ + question + â€œ[SEP]â€ + document + â€œ[SEP]â€</strong></p><p>binary cross entropy lossï¼š</p><script type="math/tex; mode=display">L = âˆ’\sum ^n _{i=0} t_ilogP(D_i) + (1 âˆ’ t_i)log(1 âˆ’ P (D_i))</script><blockquote><p>$t_i$æ˜¯$D_i$çš„æ ‡ç­¾</p><p>næ˜¯æ–‡æ¡£çš„æ•°é‡</p><p>$P(D_i)$æ˜¯æ–‡æ¡£iåœ¨æ ‡ç­¾$t_i$ä¸‹çš„æ¦‚ç‡</p></blockquote><h4 id="ä¸è¶³ï¼š"><a href="#ä¸è¶³ï¼š" class="headerlink" title="ä¸è¶³ï¼š"></a>ä¸è¶³ï¼š</h4><p>è¿™ç§ç®€å•çš„æ–¹æ³•å•ç‹¬å¤„ç†æ¯ä¸ªæ–‡æ¡£ï¼Œè€Œä¸è€ƒè™‘æ–‡æ¡£é—´çš„äº¤äº’å’Œå…³ç³»ï¼Œè€Œè¿™äº›å…³ç³»å¯¹äºä¸‹æ¸¸çš„å¤šè·³æ¨ç†ä»»åŠ¡è‡³å…³é‡è¦ã€‚</p><h4 id="æ”¹è¿›ï¼š"><a href="#æ”¹è¿›ï¼š" class="headerlink" title="æ”¹è¿›ï¼š"></a>æ”¹è¿›ï¼š</h4><p>åŠ å…¥multi-head self-attention (MHSA) å±‚ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210309200203.png" alt="image-20210309200203672" style="zoom:50%;" /></p><h4 id="MHSAå±‚å®šä¹‰ï¼š"><a href="#MHSAå±‚å®šä¹‰ï¼š" class="headerlink" title="MHSAå±‚å®šä¹‰ï¼š"></a>MHSAå±‚å®šä¹‰ï¼š</h4><script type="math/tex; mode=display">Attention = softmax( \frac{QK^T}{\sqrt{dk}}  )</script><script type="math/tex; mode=display">Multihead = Concat(head_i...head_n)W^o</script><script type="math/tex; mode=display">headi= Attention(QW^Q_i, KW^k_i, V W^v_i)</script><blockquote><p>Qã€Kã€Væ˜¯æ–‡æ¡£çš„ â€œCLS â€œåµŒå…¥çš„çº¿æ€§æŠ•å½±ï¼Œåˆ†åˆ«ä»£è¡¨æ³¨æ„åŠ›æŸ¥è¯¢ã€é”®å’Œå€¼ã€‚</p></blockquote><p>é€šè¿‡è®©æ–‡æ¡£/é—®é¢˜è¡¨ç¤ºç›¸äº’ä½œç”¨ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨æ›´å¥½çš„è¾“å…¥ä¿¡å·ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥é€‰æ‹©ä¸€ç»„éœ€è¦çš„é»„é‡‘æ–‡æ¡£è¿›è¡Œç­”æ¡ˆæå–å’Œæ”¯æŒå¥é¢„æµ‹ã€‚</p><p>binary cross entropy:</p><script type="math/tex; mode=display">L = âˆ’\sum^n  _{i=0}\sum ^i_{j=0}l_i,l_j logP (D_i, D_j)+(1âˆ’l_{i,j})log(1âˆ’P (D_i, D_j))</script><blockquote><p>$l_i,l_j$æ˜¯ä¸€å¯¹æ–‡æ¡£$(D_i, D_j)$çš„æ ‡ç­¾</p><p>$P(D_iï¼ŒD_j)$æ˜¯æ¨¡å‹é¢„æµ‹çš„$D_i$æ¯”$D_j$æ›´ç›¸å…³çš„æ¦‚ç‡</p></blockquote><p>æ”¯æŒå¥é¢„æµ‹ï¼š</p><p>â€‹        ç­”æ¡ˆé¢„æµ‹ä»»åŠ¡æ€»æ˜¯å¯ä»¥å¸®åŠ©æ”¯æŒå¥é¢„æµ‹ä»»åŠ¡ï¼Œå› ä¸ºæœ‰ç­”æ¡ˆçš„å¥å­æ€»æ˜¯ä¸€ä¸ªè¯æ®ï¼›ä½†åè¿‡æ¥å°±ä¸ä¸€æ ·äº†ï¼Œå› ä¸ºå¯èƒ½æœ‰å¤šä¸ªæ”¯æŒå¥ï¼Œè€Œæ¦‚ç‡æœ€é«˜çš„å¥å­å¯èƒ½ä¸åŒ…å«ç­”æ¡ˆã€‚å› æ­¤ï¼Œä¸ºäº†åˆ©ç”¨ä¸¤ä¸ªäº’è¡¥ä»»åŠ¡ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„æ€»ç»“å¥å­è¡¨ç¤ºæ³•(attention-based summarized sentence representation)ï¼Œä»ç­”æ¡ˆé¢„æµ‹ä¸­å¼•å…¥äº’è¡¥ä¿¡æ¯ã€‚</p><p>æ³¨æ„åŠ›æƒé‡çš„è®¡ç®—æ–¹æ³•ï¼šä¸€éƒ¨åˆ†æ³¨æ„åŠ›æ˜¯ç”¨$S_j$ä¸Šçš„è‡ªæ³¨æ„åŠ›è®¡ç®—çš„ï¼›å¦ä¸€éƒ¨åˆ†æ¥è‡ªç­”æ¡ˆé¢„æµ‹ä»»åŠ¡ä¸­çš„èµ·ç‚¹å’Œç»ˆç‚¹ä½ç½®logitsçš„ç›¸åŠ ã€‚</p><p>åœ¨å¥å­åµŒå…¥$s_j$ä¸Šå»ºç«‹ä¸€ä¸ªGNNæ¨¡å‹ï¼Œä¿ƒè¿›å¯¹é¢„æµ‹é»„é‡‘æ–‡æ¡£ä¸­æ‰€æœ‰å¥å­çš„å¤šè·³æ¨ç†ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨å¤æ‚çš„å…³ç³»ä¿¡æ¯ã€‚</p><h4 id="GNNæ¨¡å‹ç»“æ„ï¼š"><a href="#GNNæ¨¡å‹ç»“æ„ï¼š" class="headerlink" title="GNNæ¨¡å‹ç»“æ„ï¼š"></a>GNNæ¨¡å‹ç»“æ„ï¼š</h4><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210310093815.png" alt="image-20210310093815685" style="zoom:50%;" /></p><p>ä¸‰ç§ç±»å‹è¾¹ï¼š</p><ol><li>å¦‚æœå®ƒä»¬æœ€åˆæ¥è‡ªåŒä¸€æ–‡æ¡£ï¼Œåˆ™åœ¨ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´æ·»åŠ è¾¹ã€‚</li><li>å¦‚æœè¡¨ç¤ºä¸¤ä¸ªèŠ‚ç‚¹çš„å¥å­åœ¨é—®é¢˜ä¸­éƒ½åŒ…å«å‘½åå®ä½“æˆ–åè¯çŸ­è¯­ï¼ˆå¯èƒ½æ˜¯ä¸åŒçš„ï¼‰ï¼Œåˆ™åœ¨æ¥è‡ªä¸åŒæ–‡æ¡£çš„ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´å¢åŠ ä¸€æ¡è¾¹ã€‚</li><li>å¦‚æœè¡¨ç¤ºä¸¤ä¸ªèŠ‚ç‚¹çš„å¥å­å…·æœ‰ç›¸åŒçš„å‘½åå®ä½“æˆ–åè¯çŸ­è¯­ï¼Œåˆ™åœ¨æ¥è‡ªä¸åŒæ–‡æ¡£çš„ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´æ·»åŠ ä¸€æ¡è¾¹ã€‚</li></ol><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p><strong>HotpotQA</strong></p><p>ä¾‹å­ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210308200628.png" alt="image-20210308200628718" style="zoom: 33%;" /></p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210310195756.png" alt="image-20210310195756747"></p><ul><li>BERT base uncased model (â€œSAEâ€)</li><li>Roberta large model (â€œSAE-largeâ€)</li><li>ä½¿ç”¨wordpiece tokenizer</li><li>ä½¿ç”¨$spaCy^3$è¿›è¡Œå‘½åå®ä½“è¯†åˆ«</li></ul><p>æœ¬æ–‡æå‡ºçš„æ–¹æ³•æ¯”åŸºçº¿æ¨¡å‹åœ¨Jointä¸Šçš„EMå’ŒF1å¾—åˆ†åˆ†åˆ«æé«˜äº†28%å’Œ25%ä»¥ä¸Šï¼Œä¸ä¹‹å‰æå‡ºçš„æ¨¡å‹ç›¸æ¯”éƒ½æœ‰è¾ƒæ˜æ˜¾çš„æ”¹å–„ã€‚</p><p>æœ¬æ–‡ä½¿ç”¨çš„é¢„æµ‹é»„é‡‘æ–‡æ¡£çš„æ¨¡å‹ä¸oracleé»„é‡‘æ–‡æ¡£ä¹‹é—´çš„å·®è·çº¦ä¸º3-4%ï¼Œè¡¨æ˜æœ¬æ–‡æå‡ºçš„çš„æ–‡æ¡£é€‰æ‹©æ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚</p><p>ä½¿ç”¨large pre-trained language modelsä½œä¸ºencodersï¼Œæ€§èƒ½å¾—åˆ°äº†æå¤§çš„æ”¹å–„ã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><h3 id="æ¶ˆèå®éªŒ"><a href="#æ¶ˆèå®éªŒ" class="headerlink" title="æ¶ˆèå®éªŒ"></a>æ¶ˆèå®éªŒ</h3><ul><li>SAE</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210310202431.png" alt="image-20210310202416212" style="zoom:50%;" /></p><blockquote><p>â€œ$EM_S$ â€œå’Œ â€œ$Recalls_S$ â€œè¡¡é‡çš„æ˜¯ä¸¤ä¸ªé»„é‡‘æ–‡æ¡£è¢«é€‰ä¸­çš„å‡†ç¡®ç‡å’Œå¬å›ç‡</p><p>â€œ$Acc_{span}$ â€œè¡¡é‡çš„æ˜¯åŒ…å«ç­”æ¡ˆè·¨åº¦çš„é»„é‡‘æ–‡æ¡£çš„è¢«é€‰ä¸­çš„å‡†ç¡®ç‡ã€‚</p></blockquote><p>MHSAæœºåˆ¶å…è®¸æ¥è‡ªä¸åŒæ–‡ä»¶çš„ä¿¡æ¯ç›¸äº’ä½œç”¨ï¼Œä»æµ‹è¯•ç»“æœæ¥çœ‹ï¼Œå¯¹æ¨¡å‹çš„æ•ˆæœå¾ˆæœ‰å¿…è¦ã€‚</p><ul><li>æå‡ºçš„SAEç³»ç»Ÿåœ¨<strong>distractor setting</strong>ä¸‹å–å¾—äº†æ¯”å…¶ä»–ç°æœ‰ç³»ç»Ÿæ›´é«˜çš„ç«äº‰æ€§èƒ½ã€‚</li><li>æå‡ºçš„ç³»ç»Ÿåœ¨HotpotQAç›²æµ‹é›†ä¸Šè¾¾åˆ°äº†æ¯”ç°æœ‰ç³»ç»Ÿæ›´æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> HotpotQA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä¿®æ”¹é»˜è®¤çš„markdownæ¸²æŸ“å¼•æ“å®ç°Mathjaxæ•ˆæœ</title>
      <link href="/2021/03/12/%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E7%9A%84markdown%E6%B8%B2%E6%9F%93%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0Mathjax%E6%95%88%E6%9E%9C/"/>
      <url>/2021/03/12/%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E7%9A%84markdown%E6%B8%B2%E6%9F%93%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0Mathjax%E6%95%88%E6%9E%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="ä¿®æ”¹é»˜è®¤çš„markdownæ¸²æŸ“å¼•æ“å®ç°Mathjaxæ•ˆæœ"><a href="#ä¿®æ”¹é»˜è®¤çš„markdownæ¸²æŸ“å¼•æ“å®ç°Mathjaxæ•ˆæœ" class="headerlink" title="ä¿®æ”¹é»˜è®¤çš„markdownæ¸²æŸ“å¼•æ“å®ç°Mathjaxæ•ˆæœ"></a>ä¿®æ”¹é»˜è®¤çš„markdownæ¸²æŸ“å¼•æ“å®ç°Mathjaxæ•ˆæœ</h1><ul><li><p>æ”¯æŒæ›´å¤æ‚çš„å…¬å¼æ¸²æŸ“</p></li><li><p><a href="https://www.npmjs.com/package/hexo-renderer-kramed">hexo-renderer-kramed</a></p></li></ul><h2 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><p>å…ˆå¸è½½é»˜è®¤æ¸²æŸ“å¼•æ“</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><ul><li>è‹¥å®‰è£…cnpmä¹Ÿå¯ä»¥ä½¿ç”¨</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cnpm uninstall hexo-renderer-marked --save</span><br><span class="line">cnpm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><h2 id="é…ç½®"><a href="#é…ç½®" class="headerlink" title="é…ç½®"></a>é…ç½®</h2><ul><li>ä¿®æ”¹åšå®¢æ ¹ç›®å½•é…ç½®æ–‡ä»¶<code>_config.yml</code></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kramed:</span><br><span class="line">  gfm: true</span><br><span class="line">  pedantic: false</span><br><span class="line">  sanitize: false</span><br><span class="line">  tables: true</span><br><span class="line">  breaks: true</span><br><span class="line">  smartLists: true</span><br><span class="line">  smartypants: true</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> åšå®¢ </tag>
            
            <tag> mathjax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DDRQA:Dynamic Document Reranking for Open-domain Multi-hop Question Answering</title>
      <link href="/2021/03/05/DDRQA%20Dynamic%20Document%20Reranking%20for%20Open-domain%20Multi-hop%20Question%20Answering/"/>
      <url>/2021/03/05/DDRQA%20Dynamic%20Document%20Reranking%20for%20Open-domain%20Multi-hop%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="DDRQA-Dynamic-Document-Reranking-for-Open-domain-Multi-hop-Question-Answering"><a href="#DDRQA-Dynamic-Document-Reranking-for-Open-domain-Multi-hop-Question-Answering" class="headerlink" title="DDRQA: Dynamic Document Reranking for Open-domain Multi-hop Question Answering"></a>DDRQA: Dynamic Document Reranking for Open-domain Multi-hop Question Answering</h1><blockquote><p>è®ºæ–‡ï¼š<a href="https://arxiv.org/abs/2009.07465">https://arxiv.org/abs/2009.07465</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>â€‹        å¼€æ”¾é¢†åŸŸå¤šè·³ç­”é¢˜(QA)éœ€è¦æ£€ç´¢å¤šä¸ªæ”¯æŒæ€§æ–‡æ¡£ï¼Œå…¶ä¸­ä¸€äº›æ–‡æ¡£ä¸é—®é¢˜çš„è¯ä¹‰é‡åˆåº¦ä¸é«˜ï¼Œæ— æ³•ç›´æ¥æ£€ç´¢ï¼Œåªèƒ½é€šè¿‡è¿­ä»£æ–‡æ¡£æ£€ç´¢æ¥å®šä½ã€‚ç„¶è€Œï¼Œå¤šæ­¥éª¤çš„æ–‡æ¡£æ£€ç´¢å¾€å¾€ä¼šäº§ç”Ÿæ›´å¤šçš„ç›¸å…³ä½†éæ”¯æŒæ€§çš„æ–‡æ¡£ï¼Œè¿™å°±æŠ‘åˆ¶äº†ä¸‹æ¸¸å™ªå£°æ•æ„Ÿçš„readeræ¨¡å—çš„ç­”æ¡ˆæå–ã€‚ä¸ºäº†è§£å†³è¿™ä¸€éš¾é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†åŠ¨æ€æ–‡æ¡£é‡æ’åº(DDR)ï¼Œå¯¹æ–‡æ¡£è¿›è¡Œè¿­ä»£æ£€ç´¢ã€é‡æ’åºå’Œè¿‡æ»¤ï¼Œå¹¶è‡ªé€‚åº”åœ°å†³å®šä½•æ—¶åœæ­¢æ£€ç´¢è¿‡ç¨‹ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p><strong>Dynamic Document Reranking (DDR)</strong></p><blockquote><p>å­¦ä¹ è¿­ä»£æ£€ç´¢å¸¦æœ‰æ›´æ–°é—®é¢˜çš„æ–‡æ¡£ï¼Œé‡æ–°æ’åºå’Œè¿‡æ»¤æ–‡æ¡£ï¼Œå¹¶è‡ªé€‚åº”åœ°å†³å®šä½•æ—¶åœæ­¢æ£€ç´¢è¿‡ç¨‹ã€‚</p></blockquote><p>â€‹        é€šè¿‡åˆ©ç”¨å¤šæ–‡æ¡£ä¿¡æ¯ï¼Œæœ¬æ–‡çš„é‡æ–°æ’åºæ¨¡å‹æ‹¥æœ‰æ›´å¤šçš„çŸ¥è¯†æ¥åŒºåˆ†æ”¯æŒæ€§æ–‡æ¡£å’Œä¸ç›¸å…³æ–‡æ¡£ã€‚åœ¨åˆå§‹æ£€ç´¢åï¼Œè¯¥æ–¹æ³•åœ¨æ¯ä¸€ä¸ªæ£€ç´¢æ­¥éª¤ä¸­éƒ½ä¼šç”¨ä»æ£€ç´¢æ–‡æ¡£ä¸­æå–çš„æ–‡æœ¬è·¨åº¦æ¥æ›´æ–°é—®é¢˜ï¼Œç„¶åç”¨æ›´æ–°åçš„é—®é¢˜ä½œä¸ºæŸ¥è¯¢æ¥æ£€ç´¢è¡¥å……æ–‡æ¡£ï¼Œè¿™äº›æ–‡æ¡£è¢«æ·»åŠ åˆ°æ–‡æ¡£å›¾ä¸­ï¼Œè¿›è¡Œæ–°ä¸€è½®çš„äº¤äº’ã€‚å†åˆ©ç”¨é‡æ–°æ’åºæ¨¡å‹(reranking model)å¯¹æ–‡æ¡£å†æ¬¡è¿›è¡Œæ‰“åˆ†ï¼Œè¿‡æ»¤å‡ºæœ€ä¸ç›¸å…³çš„æ–‡æ¡£ã€‚å…¨å±€æ§åˆ¶å™¨(global controller)æ£€æŸ¥å‰©ä½™æ–‡æ¡£æ˜¯å¦è¶³ä»¥å›ç­”é—®é¢˜ï¼Œå¹¶æ®æ­¤å†³å®šæ˜¯å¦ç»§ç»­æ£€ç´¢å¾ªç¯ã€‚æ£€ç´¢å®Œæˆåï¼Œå°†ç»´æŠ¤å¥½çš„é«˜è´¨é‡çš„æ–‡æ¡£æ¸…å•é€å…¥é˜…è¯»å™¨æ¨¡å—ï¼Œè¿›è¡Œç­”æ¡ˆè·¨åº¦æŠ½å–ã€‚</p><p>æ£€ç´¢æ–¹å¼å’Œæ•ˆæœæ¯”è¾ƒï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210302200427.png" alt="image-20210302200420421" style="zoom:50%;" /></p><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210302200608.png" alt="image-20210302200608508"></p><p>â€‹        è¯¥ç³»ç»Ÿç”±åŠ¨æ€æ–‡ä»¶é‡æ–°æ’åº(DDR)é˜¶æ®µå’Œå›ç­”é—®é¢˜é˜¶æ®µç»„æˆã€‚ç»™å®šä¸€ä¸ªå¤šè·³é—®é¢˜ï¼ŒDDRè¿­ä»£æ£€ç´¢ã€é‡æ–°æ’åºå’Œè¿‡æ»¤æ–‡æ¡£ï¼Œå¹¶è‡ªé€‚åº”åœ°å†³å®šä½•æ—¶åœæ­¢æ£€ç´¢è¿‡ç¨‹ã€‚åœ¨åˆå§‹æ£€ç´¢åï¼ŒDDRä¼šå°†æå–çš„æ–‡æœ¬è·¨åº¦ä½œä¸ºæ–°çš„æŸ¥è¯¢æ›´æ–°é—®é¢˜ï¼Œä»¥åœ¨æ¯æ¬¡è¿­ä»£æ—¶æ£€ç´¢æ›´å¤šçš„æ–‡æ¡£ã€‚æ£€ç´¢å®Œæˆåï¼Œæœ€åå¾—åˆ†æœ€é«˜çš„æ–‡æ¡£ä¼šè¢«é€å…¥ä¸‹æ¸¸çš„é˜…è¯»å™¨æ¨¡å—è¿›è¡Œç­”æ¡ˆæå–ã€‚</p><h3 id="Graph-based-Reranking-Model"><a href="#Graph-based-Reranking-Model" class="headerlink" title="Graph-based Reranking Model"></a>Graph-based Reranking Model</h3><blockquote><p>ç”¨äºç²¾ç¡®è¯†åˆ«æ–‡æ¡£å›¾ä¸­çš„æ”¯æŒæ–‡æ¡£ã€‚</p></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210303192902.png" alt="image-20210303192902322"></p><h4 id="Contextual-Encoding"><a href="#Contextual-Encoding" class="headerlink" title="Contextual Encoding"></a>Contextual Encoding</h4><p>è¾“å…¥åˆ°pre-trained language modelçš„æ ¼å¼ï¼š</p><script type="math/tex; mode=display">I_{q,d_k}= {[CLS] }q_1. . . q_{|q|}{[SEP]} t^{(k)}_1{. . . }t^{(k)}_{|dk|}{[SEP]}</script><blockquote><p>$| q |$ å’Œ$| dk |$ è¡¨ç¤ºé—®é¢˜qå’Œæ–‡æ¡£$d_k$ä¸­çš„tokenæ•°é‡ã€‚</p></blockquote><h4 id="Graph-Attention"><a href="#Graph-Attention" class="headerlink" title="Graph Attention"></a>Graph Attention</h4><ul><li>Graph Attention Network (GAT)</li></ul><p>é‡‡ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œæ¥ä¼ æ’­æ–‡æ¡£å›¾è°±ä¸Šçš„ä¿¡æ¯ï¼Œå¦‚æœä¸¤ä¸ªæ–‡æ¡£æœ‰å…±äº«å®ä½“ï¼Œé‚£ä¹ˆå®ƒä»¬å°±ä¼šè¢«è¿æ¥èµ·æ¥ã€‚</p><h4 id="Multi-document-Fusion"><a href="#Multi-document-Fusion" class="headerlink" title="Multi-document Fusion"></a>Multi-document Fusion</h4><p>ä¸ºäº†è¿›ä¸€æ­¥å°†ä¿¡æ¯ä¼ æ’­åˆ°non-entity tokensï¼Œé¦–å…ˆå°†æ¯ä¸ªentity tokeçš„åµŒå…¥èåˆä¸º:</p><script type="math/tex; mode=display">\hat t^{(i)}_j= W_3[t^{(i)}_j; g_i^{(T)})]</script><p>$\hat v$è¢«è¾“å…¥åˆ°Transformerå±‚è¿›è¡Œå¤šæ–‡æ¡£èåˆï¼Œè¯¥å±‚æ›´æ–°æ‰€æœ‰tokençš„è¡¨ç¤ºå¹¶è¾“å‡ºèåˆçš„è¡¨ç¤ºå‘é‡$\tilde{v}$ã€‚</p><h4 id="Document-Filter-and-Global-Controller"><a href="#Document-Filter-and-Global-Controller" class="headerlink" title="Document Filter and Global Controller"></a>Document Filter and Global Controller</h4><p>â€‹        å¯¹äºæ¯ä¸ªæ–‡æ¡£ï¼Œä½¿ç”¨$\tilde{v}$ä¸­çš„[CLS] tokenåµŒå…¥ä½œä¸ºæ–‡æ¡£è¡¨ç¤ºï¼Œå°†å…¶é€å…¥äºŒè¿›åˆ¶åˆ†ç±»å™¨ä¸­ï¼Œå¯¹æ–‡æ¡£çš„æ”¯æŒçº§åˆ«è¿›è¡Œè¯„åˆ†ã€‚é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å‰Kä¸ªæ–‡æ¡£ï¼Œå…¶ä½™æ–‡æ¡£è¿›è¡Œç­›é€‰ã€‚å¦‚æœæ­£å‘æ®µæ•°å°äºè¶…å‚æ•°é˜ˆå€¼Sï¼Œå…¨å±€æ§åˆ¶å™¨å‘å‡ºä¿¡å·ï¼Œç»§ç»­æ£€ç´¢è¿‡ç¨‹ã€‚</p><h3 id="Reader-Module"><a href="#Reader-Module" class="headerlink" title="Reader Module"></a>Reader Module</h3><p>å°†é—®é¢˜qçš„tokenså’Œæœ€ç»ˆæ’åå‰Kçš„é‡æ–°æ’åºçš„æ–‡æ¡£è¿›è¡Œä¸²è”ï¼Œåé¦ˆåˆ°é˜…è¯»å™¨æ¨¡å—ã€‚</p><p>å¯»æ‰¾æ‰¾åˆ°æœ€ä½³å€™é€‰ç­”æ¡ˆè·¨åº¦ï¼š</p><script type="math/tex; mode=display">arg\ max \underset{i,j, iâ‰¤j}P^{start}_iP^{end}_j</script><p>$P^{start}_iP^{end}_j$è¡¨ç¤ºç¬¬iå’Œç¬¬jä¸ªtokenåœ¨ä¸²è”æ–‡æœ¬ä¸­çš„å¼€å§‹å’Œç»“æŸä½ç½®çš„æ¦‚ç‡ï¼Œå³ç­”æ¡ˆè·¨åº¦ã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p><strong>HotpotQA full wiki setting</strong></p><p>è¯¥æ•°æ®é›†ç”±113Kä¸ªä¼—åŒ…å¤šè·³é—®é¢˜ç»„æˆï¼Œè¿™äº›é—®é¢˜éœ€è¦ç»´åŸºç™¾ç§‘çš„ä»‹ç»æ®µè½æ¥å›ç­”ã€‚æ¯ä¸ªè®­ç»ƒç”¨çš„é—®é¢˜éƒ½å¸¦æœ‰ä¸¤ä¸ªç”±äººå·¥æ³¨é‡Šçš„é»„é‡‘æ”¯æŒæ®µè½ã€‚</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p>å®éªŒç»“æœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210304092847.png" alt="image-20210304092847547"></p><p>æå‡ºçš„reranking modelåœ¨Devå’ŒTestæ•°æ®é›†ä¸Šéƒ½è¡¨ç°å‡ºäº†æœ€ä½³çš„æ•ˆæœï¼ŒParagraphæ•ˆæœæå‡æœ€ä¸ºæ˜¾è‘—ã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><h3 id="æ¶ˆèå®éªŒ"><a href="#æ¶ˆèå®éªŒ" class="headerlink" title="æ¶ˆèå®éªŒ"></a>æ¶ˆèå®éªŒ</h3><ul><li><p>ç¦ç”¨Iterative Reranking, Graph-based Reranking and Question Updateræ¨¡å—ï¼Œæ®µè½é‡æ’åºå’ŒQAæ€§èƒ½ä¸‹é™è¾ƒä¸ºæ˜æ˜¾ã€‚</p></li><li><p>QAæ€§èƒ½åœ¨bridge questionsä¸‹é™æ¯”comparison questionsæ›´æ˜¾è‘—ã€‚</p></li></ul><p>æœ¬æ–‡æå‡ºçš„DDRQAï¼Œæ˜¯ä¸€ä¸ªå¼€æ”¾é¢†åŸŸçš„å¤šè·³QAç³»ç»Ÿï¼Œå®ƒå¯ä»¥ä»ä¸€ä¸ªå¤§å‹è¯­æ–™åº“ä¸­å‡†ç¡®å®šä½æ”¯æŒæ–‡æ¡£ã€‚DDRQAé€šè¿‡åŸºäºå›¾çš„é‡æ’åºæ¨¡å‹å¯¹æ–‡æ¡£è¿›è¡Œè¿­ä»£æ£€ç´¢ã€é‡æ’åºå’Œè¿‡æ»¤ï¼Œå¹¶åœ¨HotpotQA full wikiè®¾ç½®ä¸Šæ˜¾è‘—ä¼˜äºä¹‹å‰çš„æ–¹æ³•ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> hotpot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scpè‡ªåŠ¨å¡«å……å¯†ç shellè„šæœ¬</title>
      <link href="/2021/03/03/scp%E8%87%AA%E5%8A%A8%E5%A1%AB%E5%85%85%E5%AF%86%E7%A0%81shell%E8%84%9A%E6%9C%AC/"/>
      <url>/2021/03/03/scp%E8%87%AA%E5%8A%A8%E5%A1%AB%E5%85%85%E5%AF%86%E7%A0%81shell%E8%84%9A%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<h1 id="scpè‡ªåŠ¨å¡«å……å¯†ç shellè„šæœ¬"><a href="#scpè‡ªåŠ¨å¡«å……å¯†ç shellè„šæœ¬" class="headerlink" title="scpè‡ªåŠ¨å¡«å……å¯†ç shellè„šæœ¬"></a>scpè‡ªåŠ¨å¡«å……å¯†ç shellè„šæœ¬</h1><h2 id="å®‰è£…expect"><a href="#å®‰è£…expect" class="headerlink" title="å®‰è£…expect"></a>å®‰è£…expect</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install ecpect</span><br></pre></td></tr></table></figure><h2 id="ç¼–å†™è„šæœ¬mq-scp-sh"><a href="#ç¼–å†™è„šæœ¬mq-scp-sh" class="headerlink" title="ç¼–å†™è„šæœ¬mq_scp.sh"></a>ç¼–å†™è„šæœ¬mq_scp.sh</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/expect</span><br><span class="line">#*************************************************************************</span><br><span class="line">#        ./mq_scp.sh ç›®æ ‡ä¸Šä¼ æ–‡ä»¶</span><br><span class="line">#*************************************************************************</span><br><span class="line">set timeout 30</span><br><span class="line">set user root</span><br><span class="line">set pass 12398qq.</span><br><span class="line">set dir /root/mq_blog/source/_posts</span><br><span class="line">set ip 39.96.68.13</span><br><span class="line">set filen [lrange $argv 0 0] </span><br><span class="line"># [lrange $argv 0 0] 0 0è¡¨ç¤ºç¬¬ä¸€ä¸ªå‚æ•° </span><br><span class="line"></span><br><span class="line">spawn scp $&#123;filen&#125; $&#123;user&#125;@$&#123;ip&#125;:$&#123;dir&#125;</span><br><span class="line">expect &quot;$&#123;user&#125;@$&#123;ip&#125;&#x27;s password:&quot;</span><br><span class="line">send &quot;$&#123;pass&#125;\r&quot;</span><br><span class="line">interact</span><br></pre></td></tr></table></figure><h2 id="è½¯è¿æ¥åˆ°ç¯å¢ƒå˜é‡ç›®å½•"><a href="#è½¯è¿æ¥åˆ°ç¯å¢ƒå˜é‡ç›®å½•" class="headerlink" title="è½¯è¿æ¥åˆ°ç¯å¢ƒå˜é‡ç›®å½•"></a>è½¯è¿æ¥åˆ°ç¯å¢ƒå˜é‡ç›®å½•</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /home/maqi/blog/test/mq_scp.sh /usr/local/bin/mq_scp</span><br></pre></td></tr></table></figure><p>ä¹‹åä»»æ„ç»ˆç«¯è¾“å…¥<code>mq_scp ç›®æ ‡ä¸Šä¼ æ–‡ä»¶</code>å³å¯ã€‚</p><h2 id="exceptä»‹ç»"><a href="#exceptä»‹ç»" class="headerlink" title="exceptä»‹ç»"></a>exceptä»‹ç»</h2><ul><li><h1 id="usr-bin-expect"><a href="#usr-bin-expect" class="headerlink" title="!/usr/bin/expect"></a>!/usr/bin/expect</h1><p>å‘Šè¯‰æ“ä½œç³»ç»Ÿè„šæœ¬é‡Œçš„ä»£ç ä½¿ç”¨é‚£ä¸€ä¸ªshellæ¥æ‰§è¡Œã€‚è¿™é‡Œçš„expectå…¶å®å’Œlinuxä¸‹çš„bashã€windowsä¸‹çš„cmdæ˜¯ä¸€ç±»ä¸œè¥¿ã€‚</p></li><li><p>set timeout 30</p><p>è®¾ç½®è¶…æ—¶æ—¶é—´ã€‚</p></li><li><p>spawn</p><p>spawnæ˜¯è¿›å…¥expectç¯å¢ƒåæ‰å¯ä»¥æ‰§è¡Œçš„expectå†…éƒ¨å‘½ä»¤ï¼Œä¸»è¦çš„åŠŸèƒ½æ˜¯ç»™sshè¿è¡Œè¿›ç¨‹åŠ ä¸ªå£³ï¼Œç”¨æ¥ä¼ é€’äº¤äº’æŒ‡ä»¤ã€‚</p></li><li><p>expect â€œpassword:â€<br>è¿™é‡Œçš„expectä¹Ÿæ˜¯expectçš„ä¸€ä¸ªå†…éƒ¨å‘½ä»¤ã€‚è¿™ä¸ªå‘½ä»¤çš„æ„æ€æ˜¯åˆ¤æ–­ä¸Šæ¬¡è¾“å‡ºç»“æœé‡Œæ˜¯å¦åŒ…å«â€œpassword:â€çš„å­—ç¬¦ä¸²ï¼Œå¦‚æœæœ‰åˆ™ç«‹å³è¿”å›ï¼Œå¦åˆ™å°±ç­‰å¾…ä¸€æ®µæ—¶é—´åè¿”å›ï¼Œè¿™é‡Œç­‰å¾…æ—¶é•¿å°±æ˜¯å‰é¢è®¾ç½®çš„30ç§’ã€‚</p></li><li><p>send â€œ${pass}\râ€<br>æ‰§è¡Œäº¤äº’åŠ¨ä½œï¼Œä¸æ‰‹å·¥è¾“å…¥å¯†ç çš„åŠ¨ä½œç­‰æ•ˆã€‚</p><p><strong>å‘½ä»¤å­—ç¬¦ä¸²ç»“å°¾åˆ«å¿˜è®°åŠ ä¸Šâ€œ\râ€ã€‚</strong></p></li><li><p>interact</p><p>æ‰§è¡Œå®Œæˆåä¿æŒäº¤äº’çŠ¶æ€ï¼ŒæŠŠæ§åˆ¶æƒäº¤ç»™æ§åˆ¶å°ï¼Œè¿™ä¸ªæ—¶å€™å°±å¯ä»¥æ‰‹å·¥æ“ä½œäº†ï¼Œå¦‚æœæ²¡æœ‰è¿™ä¸€å¥ç™»å½•å®Œæˆåä¼šé€€å‡ºã€‚</p></li></ul><h2 id="ç¼–å†™è„šæœ¬åŒæ­¥åšå®¢"><a href="#ç¼–å†™è„šæœ¬åŒæ­¥åšå®¢" class="headerlink" title="ç¼–å†™è„šæœ¬åŒæ­¥åšå®¢"></a>ç¼–å†™è„šæœ¬åŒæ­¥åšå®¢</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/expect</span><br><span class="line">#*************************************************************************</span><br><span class="line">#        ./mq_sync_blog.sh ç›®æ ‡ä¸Šä¼ æ–‡ä»¶</span><br><span class="line">#*************************************************************************</span><br><span class="line">set timeout 30</span><br><span class="line">set user root</span><br><span class="line">set pass 12398qq.</span><br><span class="line">set ip 39.96.68.13</span><br><span class="line"></span><br><span class="line">spawn ssh $&#123;user&#125;@$&#123;ip&#125;</span><br><span class="line">expect &quot;$&#123;user&#125;@$&#123;ip&#125;&#x27;s password:&quot;</span><br><span class="line">send &quot;$&#123;pass&#125;\r&quot;</span><br><span class="line">expect &quot;#&quot;</span><br><span class="line">send &quot;cd /root/mq_blog\r&quot;</span><br><span class="line">expect &quot;#&quot;</span><br><span class="line">send &quot;./quick_push\r&quot;</span><br><span class="line"></span><br><span class="line">expect &quot;#&quot;</span><br><span class="line">send &quot;cd /root/fluid_blog\r&quot;</span><br><span class="line">expect &quot;#&quot;</span><br><span class="line">send &quot;./quick_push\r&quot;</span><br><span class="line">interact</span><br><span class="line">#expect eof</span><br></pre></td></tr></table></figure><h2 id="è½¯è¿æ¥åˆ°ç¯å¢ƒå˜é‡ç›®å½•-1"><a href="#è½¯è¿æ¥åˆ°ç¯å¢ƒå˜é‡ç›®å½•-1" class="headerlink" title="è½¯è¿æ¥åˆ°ç¯å¢ƒå˜é‡ç›®å½•"></a>è½¯è¿æ¥åˆ°ç¯å¢ƒå˜é‡ç›®å½•</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /home/maqi/blog/test/mq_sync_blog.sh /usr/local/bin/mq_sync_blog</span><br></pre></td></tr></table></figure><p>ä¹‹åä»»æ„ç»ˆç«¯è¾“å…¥<code>mq_sync_blog</code>å³å¯ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> shell </tag>
            
            <tag> except </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PIDå‚æ•°è°ƒèŠ‚</title>
      <link href="/2021/03/01/PID%E5%8F%82%E6%95%B0%E8%B0%83%E8%8A%82/"/>
      <url>/2021/03/01/PID%E5%8F%82%E6%95%B0%E8%B0%83%E8%8A%82/</url>
      
        <content type="html"><![CDATA[<h1 id="PIDå‚æ•°è°ƒèŠ‚"><a href="#PIDå‚æ•°è°ƒèŠ‚" class="headerlink" title="PIDå‚æ•°è°ƒèŠ‚"></a>PIDå‚æ•°è°ƒèŠ‚</h1><p>æœ€ä¼˜å‚æ•°ï¼š</p><ul><li>x100ï¼š34 15 18</li><li>x80ï¼š26 17 2</li></ul><h2 id="å·¥å…·"><a href="#å·¥å…·" class="headerlink" title="å·¥å…·"></a>å·¥å…·</h2><p>control_keyboard.cpp</p><p>KP KI KP é€šè¿‡é”®ç›˜æŒ‰é”®åŠ¨æ€è°ƒèŠ‚</p><p>åŠ 1ï¼šI O P</p><p>å‡1ï¼šJ K L</p><h2 id="è°ƒèŠ‚æ–¹æ³•"><a href="#è°ƒèŠ‚æ–¹æ³•" class="headerlink" title="è°ƒèŠ‚æ–¹æ³•"></a>è°ƒèŠ‚æ–¹æ³•</h2><h3 id="æ€è·¯"><a href="#æ€è·¯" class="headerlink" title="æ€è·¯"></a>æ€è·¯</h3><ul><li>å…ˆè°ƒPï¼Œä»å°åˆ°å¤§è°ƒèŠ‚Pä½¿æ›²çº¿éœ‡è¡ç¨³å®šã€‚</li><li>è°ƒèŠ‚Iä½¿å¾—æ›²çº¿åç¦»ç›®æ ‡å€¼æœ€å°</li><li>è°ƒèŠ‚ï¼¤ä½¿éœ‡è¡ç¨³å®šï¼Œéœ‡è¡é¢‘ç‡é™ä½ã€‚</li></ul><p>æ³¨æ„ï¼š</p><blockquote><p>ç©ºè½½æ—¶è¡¨ç°è¾ƒå¥½çš„å‚æ•°åœ¨è´Ÿè½½æˆ–é€Ÿåº¦è¾ƒå¤§æ—¶å¯èƒ½ä¼šå‡ºç°è¿è¡Œæ—¶å™ªéŸ³è¾ƒå¤§çš„é—®é¢˜ï¼Œéœ€è¦ç»¼åˆè€ƒè™‘ã€‚</p></blockquote><ol><li>å…ˆè°ƒPï¼Œä»å°åˆ°å¤§è°ƒèŠ‚Pä½¿æ›²çº¿éœ‡è¡ç¨³å®šã€‚</li></ol><p>P=15</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226102521631.png" alt="image-20210226102521631"></p><p>p=34</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226170551440.png" alt="image-20210226170551440"></p><p>P=42</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226102401389.png" alt=""></p><p>kp=34å’Œkp=42æ•ˆæœæ¥è¿‘ï¼Œä½†kp=42å™ªéŸ³è¾ƒå¤§ã€‚</p><ol><li>è°ƒèŠ‚Iä½¿å¾—æ›²çº¿åç¦»ç›®æ ‡å€¼æœ€å°</li></ol><p>p=34 i=5</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226170959661.png" alt="image-20210226170959661"></p><p>P=34 I=15</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226171135272.png" alt="image-20210226171135272"></p><p>P=34 I=20</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226171548299.png" alt="image-20210226171548299"></p><ol><li>è°ƒèŠ‚dä½¿éœ‡è¡ç¨³å®šï¼Œéœ‡è¡é¢‘ç‡é™ä½ã€‚</li></ol><p><strong>ç©ºè½½ï¼š</strong></p><p>34 12 13</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226172623763.png" alt="image-20210226172623763"></p><p>34 12 0</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226172858816.png" alt="image-20210226172858816"></p><p>34 15 16</p><p><img src="../.config/Typora/typora-user-images/image-20210226165509225.png" alt="image-20210226165509225"></p><p>34 15 18 </p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226165933457.png" alt="image-20210226165933457"></p><p>æ ¹æ®éœ‡è¡é¢‘ç‡å’Œå¹…åº¦é€‰æ‹©å‚æ•°kp=34,ki=15,kd=18</p><p><strong>è´Ÿè½½ï¼š</strong></p><p>34 12 13</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226174907240.png" alt="image-20210226174907240"></p><p>34 12 0</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226174729477.png" alt="image-20210226174729477"></p><p>34 15 18</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226173434718.png" alt="image-20210226173434718"></p><ul><li>34 15 18 *</li><li>35 14 15</li><li>34 15 17</li><li>34 15 16</li></ul><h2 id="è·Ÿè¸ªæ›²çº¿"><a href="#è·Ÿè¸ªæ›²çº¿" class="headerlink" title="è·Ÿè¸ªæ›²çº¿"></a>è·Ÿè¸ªæ›²çº¿</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export LCM_DEFAULT_URL=udpm://239.255.76.67:7666</span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/app/lib</span><br></pre></td></tr></table></figure><p>34 14 0</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302104113288.png" alt="image-20210302104113288"></p><p>34 15 18</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302101225620.png" alt="image-20210302101225620"></p><p>35 14 15</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302104322620.png" alt="image-20210302104322620"></p><p>34 15 17</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302103526539.png" alt="image-20210302103526539"></p><p>34 15 16</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302103845153.png" alt="image-20210302103845153"></p><p>34 16 2</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302110527330.png" alt="image-20210302110527330"></p><p>34 16 12</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302110851191.png" alt="image-20210302110851191"></p><p>34 16 18</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302111233819.png" alt="image-20210302111233819"></p><p>34 16 15</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302111638689.png" alt="image-20210302111638689"></p>]]></content>
      
      
      <categories>
          
          <category> ç¡¬ä»¶å¼€å‘ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchå¸¸ç”¨æ“ä½œ</title>
      <link href="/2021/03/01/PyTorch%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
      <url>/2021/03/01/PyTorch%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchå¸¸ç”¨æ“ä½œ"><a href="#PyTorchå¸¸ç”¨æ“ä½œ" class="headerlink" title="PyTorchå¸¸ç”¨æ“ä½œ"></a>PyTorchå¸¸ç”¨æ“ä½œ</h1><h2 id="æŒ‡å®šGPU"><a href="#æŒ‡å®šGPU" class="headerlink" title="æŒ‡å®šGPU"></a>æŒ‡å®šGPU</h2><ul><li>ç»ˆç«¯æŒ‡å®š</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 nohup python demo.py &gt;&gt; base_log.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><ul><li>ç¨‹åºæŒ‡å®š</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">int id = &#123;0-max_gpu_num&#125;</span><br><span class="line">torch.cuda.set_device(id)</span><br></pre></td></tr></table></figure><h2 id="æ£€æµ‹GPUæ˜¯å¦å¯ç”¨"><a href="#æ£€æµ‹GPUæ˜¯å¦å¯ç”¨" class="headerlink" title="æ£€æµ‹GPUæ˜¯å¦å¯ç”¨"></a>æ£€æµ‹GPUæ˜¯å¦å¯ç”¨</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> æ•™ç¨‹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Typora+PicGo-core å®ç°å›¾ç‰‡è‡ªåŠ¨ä¸Šä¼ </title>
      <link href="/2021/03/01/Typora+PicGo-core%20%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%89%87%E8%87%AA%E5%8A%A8%E4%B8%8A%E4%BC%A0/"/>
      <url>/2021/03/01/Typora+PicGo-core%20%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%89%87%E8%87%AA%E5%8A%A8%E4%B8%8A%E4%BC%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="Typora-PicGo-core-å®ç°å›¾ç‰‡è‡ªåŠ¨ä¸Šä¼ "><a href="#Typora-PicGo-core-å®ç°å›¾ç‰‡è‡ªåŠ¨ä¸Šä¼ " class="headerlink" title="Typora+PicGo-core å®ç°å›¾ç‰‡è‡ªåŠ¨ä¸Šä¼ "></a>Typora+PicGo-core å®ç°å›¾ç‰‡è‡ªåŠ¨ä¸Šä¼ </h1><h2 id="åœ¨Typoraä¸­å®‰è£…PicGo-core"><a href="#åœ¨Typoraä¸­å®‰è£…PicGo-core" class="headerlink" title="åœ¨Typoraä¸­å®‰è£…PicGo-core"></a>åœ¨Typoraä¸­å®‰è£…PicGo-core</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210301151027421.png" alt="image-20210301151027421"></p><h2 id="å®‰è£…æ’ä»¶"><a href="#å®‰è£…æ’ä»¶" class="headerlink" title="å®‰è£…æ’ä»¶"></a>å®‰è£…æ’ä»¶</h2><ol><li><p>æ‰¾åˆ°PicGoå®‰è£…è·¯å¾„</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/maqi/.config/Typora/picgo/linux/picgo</span><br></pre></td></tr></table></figure></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210301151218251.png" alt="image-20210301151218251"></p></li><li><p>å®‰è£…æ’ä»¶</p><blockquote><p>gitee-uploaderå³å¯</p></blockquote></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.\picgo install smms-user</span><br><span class="line">.\picgo install gitee-uploader</span><br><span class="line">.\picgo install github-plus</span><br></pre></td></tr></table></figure><ol><li>ä¿®æ”¹é…ç½®æ–‡ä»¶</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;picBed&quot;: &#123;</span><br><span class="line">    &quot;current&quot;: &quot;gitee&quot;,</span><br><span class="line">    &quot;uploader&quot;: &quot;gitee&quot;,</span><br><span class="line">    &quot;githubPlus&quot;: &#123;</span><br><span class="line">      &quot;branch&quot;: &quot;master&quot;,</span><br><span class="line">      &quot;customUrl&quot;: &quot;https://cdn.jsdelivr.net/gh/ç”¨æˆ·å/é¡¹ç›®å&quot;,</span><br><span class="line">      &quot;path&quot;: &quot;img/&quot;,</span><br><span class="line">      &quot;repo&quot;: &quot;githubç”¨æˆ·å/githubä»“åº“å&quot;,</span><br><span class="line">      &quot;token&quot;: &quot;è‡ªå·±çš„token&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;gitee&quot;: &#123;</span><br><span class="line">      &quot;customUrl&quot;: &quot;&quot;,</span><br><span class="line">      &quot;repo&quot;: &quot;Asimok/picgo&quot;,</span><br><span class="line">      &quot;branch&quot;: &quot;master&quot;,</span><br><span class="line">      &quot;token&quot;: &quot;ae27b6635e613294f7131c20669d940d&quot;,</span><br><span class="line">      &quot;path&quot;: &quot;img/linux&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;smms-user&quot;: &#123;</span><br><span class="line">      &quot;Authorization&quot;: &quot;æ›¿æ¢æˆä½ è‡ªå·±çš„token&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;transformer&quot;: &quot;path&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;picgoPlugins&quot;: &#123;</span><br><span class="line">    &quot;picgo-plugin-gitee-uploader&quot;: true,</span><br><span class="line">    &quot;picgo-plugin-smms-user&quot;: true,</span><br><span class="line">    &quot;picgo-plugin-github-plus&quot;: true</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;picgo-plugin-gitee-uploader&quot;: &#123;</span><br><span class="line">    &quot;lastSync&quot;: &quot;2021-03-01 03:12:33&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;picgo-plugin-github-plus&quot;: &#123;</span><br><span class="line">    &quot;lastSync&quot;: &quot;2020-04-07 11:09:08&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>éªŒè¯å³å¯</li></ol>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gitee </tag>
            
            <tag> PicGo </tag>
            
            <tag> Typora </tag>
            
            <tag> å›¾åºŠ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gitå¸¸ç”¨æ“ä½œ</title>
      <link href="/2021/03/01/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
      <url>/2021/03/01/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="gitå¸¸ç”¨æ“ä½œ"><a href="#gitå¸¸ç”¨æ“ä½œ" class="headerlink" title="gitå¸¸ç”¨æ“ä½œ"></a>gitå¸¸ç”¨æ“ä½œ</h1><h2 id="å…‹éš†æŒ‡å®šåˆ†æ”¯"><a href="#å…‹éš†æŒ‡å®šåˆ†æ”¯" class="headerlink" title="å…‹éš†æŒ‡å®šåˆ†æ”¯"></a>å…‹éš†æŒ‡å®šåˆ†æ”¯</h2><ul><li>-b</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone -b åˆ†æ”¯å git åœ°å€</span><br></pre></td></tr></table></figure><h2 id="æŸ¥çœ‹è¿œç¨‹åˆ†æ”¯"><a href="#æŸ¥çœ‹è¿œç¨‹åˆ†æ”¯" class="headerlink" title="æŸ¥çœ‹è¿œç¨‹åˆ†æ”¯"></a>æŸ¥çœ‹è¿œç¨‹åˆ†æ”¯</h2><p><strong>æŸ¥çœ‹è¿œç¨‹åˆ†æ”¯</strong></p><ul><li>-r</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -r</span><br></pre></td></tr></table></figure><p><strong>æŸ¥çœ‹è¿œç¨‹å’Œæœ¬åœ°æ‰€æœ‰åˆ†æ”¯</strong></p><ul><li>-a</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -a</span><br></pre></td></tr></table></figure><p><strong>æŸ¥çœ‹æœ¬åœ°åˆ†æ”¯</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure><h2 id="æ‹‰å–è¿œç¨‹åˆ†æ”¯å¹¶åˆ›å»ºæœ¬åœ°åˆ†æ”¯"><a href="#æ‹‰å–è¿œç¨‹åˆ†æ”¯å¹¶åˆ›å»ºæœ¬åœ°åˆ†æ”¯" class="headerlink" title="æ‹‰å–è¿œç¨‹åˆ†æ”¯å¹¶åˆ›å»ºæœ¬åœ°åˆ†æ”¯"></a>æ‹‰å–è¿œç¨‹åˆ†æ”¯å¹¶åˆ›å»ºæœ¬åœ°åˆ†æ”¯</h2><ul><li>-b</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b æœ¬åœ°åˆ†æ”¯å orign/è¿œç¨‹åˆ†æ”¯å</span><br></pre></td></tr></table></figure><ul><li>fetch</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git fetch orign è¿œç¨‹åˆ†æ”¯å:æœ¬åœ°åˆ†æ”¯å</span><br></pre></td></tr></table></figure><blockquote><p>checkoutä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°æ–°åˆ›å»ºçš„åˆ†æ”¯ï¼Œfetchä¸ä¼šã€‚</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux top å‘½ä»¤è¯¦è§£</title>
      <link href="/2021/03/01/linux%20top%20%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
      <url>/2021/03/01/linux%20top%20%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="linux-top-å‘½ä»¤è¯¦è§£"><a href="#linux-top-å‘½ä»¤è¯¦è§£" class="headerlink" title="linux top å‘½ä»¤è¯¦è§£"></a>linux top å‘½ä»¤è¯¦è§£</h1><blockquote><p>topå‘½ä»¤æ˜¯Linuxä¸‹å¸¸ç”¨çš„æ€§èƒ½åˆ†æå·¥å…·ï¼Œèƒ½å¤Ÿå®æ—¶æ˜¾ç¤ºç³»ç»Ÿä¸­å„ä¸ªè¿›ç¨‹çš„èµ„æºå ç”¨çŠ¶å†µã€‚</p></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210127170328319.png" alt="image-20210127170328319"></p><h2 id="å‚æ•°"><a href="#å‚æ•°" class="headerlink" title="ã€€å‚æ•°"></a>ã€€å‚æ•°</h2><ul><li>cpu<ul><li>usrï¼šç”¨æˆ·ç©ºé—´cpuå ç”¨ç‡</li><li>sysï¼šç³»ç»Ÿå†…æ ¸cpuå ç”¨ç‡</li><li>nicï¼šæ”¹å˜è¿‡ä¼˜å…ˆçº§çš„è¿›ç¨‹å ç”¨CPUçš„ç™¾åˆ†æ¯”</li><li>idleï¼šç©ºé—²CPUç™¾åˆ†æ¯”</li><li>ioï¼šIOç­‰å¾…å ç”¨CPUçš„ç™¾åˆ†æ¯”</li><li>irqï¼š ç¡¬ä¸­æ–­å ç”¨CPUçš„ç™¾åˆ†æ¯”</li><li>sirqï¼š è½¯ä¸­æ–­å ç”¨CPUçš„ç™¾åˆ†æ¯”</li><li>Load averageï¼šè´Ÿè½½å‡è¡¡ï¼Œ1åˆ†é’Ÿã€5åˆ†é’Ÿã€15åˆ†é’Ÿçš„è´Ÿè½½æƒ…å†µã€‚</li></ul></li></ul><h2 id="htop"><a href="#htop" class="headerlink" title="htop"></a>htop</h2>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> top </tag>
            
            <tag> htop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Asking Complex Questions with Multi-hop Answer-focused Reasoning</title>
      <link href="/2021/02/27/Asking%20Complex%20Questions%20with%20Multi-hop%20Answer-focused%20Reasoning/"/>
      <url>/2021/02/27/Asking%20Complex%20Questions%20with%20Multi-hop%20Answer-focused%20Reasoning/</url>
      
        <content type="html"><![CDATA[<h1 id="Asking-Complex-Questions-with-Multi-hop-Answer-focused-Reasoning"><a href="#Asking-Complex-Questions-with-Multi-hop-Answer-focused-Reasoning" class="headerlink" title="Asking Complex Questions with Multi-hop Answer-focused Reasoning"></a>Asking Complex Questions with Multi-hop Answer-focused Reasoning</h1><blockquote><p>è®ºæ–‡ï¼š<a href="https://arxiv.org/abs/2009.07402">Asking Complex Questions with Multi-hop Answer-focused Reasoning</a></p><p>ä»£ç ï¼š<a href="https://github.com/Shawn617/Multi-hop-NQG">https://github.com/Shawn617/Multi-hop-NQG</a></p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p><strong>multihop question generation</strong></p><p>å¤§å¤šæ•°å…ˆè¿›çš„æ–¹æ³•éƒ½é›†ä¸­åœ¨æ¶‰åŠå•è·³å…³ç³»çš„ç®€å•é—®é¢˜çš„æé—®ä¸Šï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºå¤šè·³é—®é¢˜ç”Ÿæˆçš„æ–°ä»»åŠ¡ï¼Œé€šè¿‡é¢å¤–å‘ç°å’Œå»ºæ¨¡ç»™å®šæ–‡æ¡£é›†åˆå’Œç›¸åº”ç­”æ¡ˆçš„å¤šä¸ªå®ä½“åŠå…¶è¯­ä¹‰å…³ç³»æ¥æå‡ºå¤æ‚çš„å’Œè¯­ä¹‰ç›¸å…³çš„é—®é¢˜ã€‚</p><p>ç¤ºä¾‹ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210225085024.png" alt="image-20210225085017189" style="zoom:50%;" /></p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p><strong>multi-hop answer-focused reasoning model</strong></p><p>æœ¬æ–‡æå‡ºäº†åœ¨ä»¥ç­”æ¡ˆä¸ºä¸­å¿ƒçš„å®ä½“å›¾ä¸Šè¿›è¡Œä»¥ç­”æ¡ˆä¸ºä¸­å¿ƒçš„å¤šè·³æ¨ç†ï¼Œä»¥åŒ…æ‹¬ä¸åŒç²’åº¦çº§åˆ«çš„è¯­ä¹‰ä¿¡æ¯ï¼ŒåŒ…æ‹¬å®ä½“çš„è¯çº§å’Œæ–‡æ¡£çº§è¯­ä¹‰åŠå…¶è¯­ä¹‰å…³ç³»ã€‚</p><p>é€šè¿‡æå–æ–‡æ¡£ä¸­å„ä¸ªå®ä½“ä¹‹é—´ä¸åŒç±»å‹çš„è¯­ä¹‰å…³ç³»æ¥æ„å»ºä»¥ç­”æ¡ˆä¸ºä¸­å¿ƒ(<strong>answer-centric entity graph</strong>)çš„å®ä½“å›¾ï¼Œä»è€Œå®ç°å¤šè·³æ¨ç†ã€‚</p><h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><p>(i) answer-focused document encoding.</p><p>(ii) multi-hop answer-centric reasoning.</p><p>(iii) aggregation layer, finally providing an answer-focused and enriched contextual representation.</p><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210225192912.png" alt="image-20210225192912200"></p><h3 id="Answer-focused-Document-Encoding"><a href="#Answer-focused-Document-Encoding" class="headerlink" title="Answer-focused Document Encoding"></a>Answer-focused Document Encoding</h3><blockquote><p>ä»¥ç­”æ¡ˆä¸ºä¸­å¿ƒçš„æ–‡æ¡£ç¼–ç </p></blockquote><h4 id="Document-Encoding"><a href="#Document-Encoding" class="headerlink" title="Document Encoding"></a>Document Encoding</h4><p>çº§è”æ–‡æœ¬å’Œæ ‡é¢˜</p><script type="math/tex; mode=display">X =\{X_0^{text}, X_0^{title}, ..., X_I^{text}, X_I^{title}\}</script><p>one-layer bi-directional LSTMä½œä¸ºencoderè·å¾—æ–‡æ¡£è¡¨ç¤ºã€‚</p><script type="math/tex; mode=display">H = [h_1, h_2, ..., h_m]\in R^{Mâˆ—D}</script><script type="math/tex; mode=display">h_i= LSTM_{enc}(x_i, h_{iâˆ’1})</script><h4 id="Gated-Self-attention-Layer"><a href="#Gated-Self-attention-Layer" class="headerlink" title="Gated Self-attention Layer"></a>Gated Self-attention Layer</h4><p>æ–‡æ¡£è¡¨ç¤ºå¯¹ä¸Šä¸‹æ–‡è¡¨ç¤ºæœ‰å±€é™ï¼Œåˆ©ç”¨gated selfattention layerå’ŒBi-GRUå­¦ä¹ ä¸Šä¸‹æ–‡è¡¨ç¤º$h_i$ã€‚</p><script type="math/tex; mode=display">\hat h_i= Bi-GRU(\hat h^D_{i-1}, [h_i, o_i])</script><p>$v_i$æ˜¯é€šè¿‡ä¸Šä¸‹æ–‡è·å¾—çš„å‘é‡ï¼š</p><script type="math/tex; mode=display">d^i_j= W_d^Ttanh(W^{'}_vh_j+ W_vh_i)</script><script type="math/tex; mode=display">a^i_k= exp(d^i_k)/\sum^n_{j=1}exp(d^i_j)</script><script type="math/tex; mode=display">o_i= \sum ^n _{k=1}a^i_kh_k</script><blockquote><p>$W_d, W_v,W^{â€˜}_v$æ˜¯å¯è®­ç»ƒçš„æƒé‡ã€‚</p></blockquote><h4 id="Answer-Gating-Mechanism"><a href="#Answer-Gating-Mechanism" class="headerlink" title="Answer Gating Mechanism"></a>Answer Gating Mechanism</h4><p>æˆæƒæ¨¡å‹å­¦ä¹ ä»¥ç­”æ¡ˆä¸ºä¸­å¿ƒçš„æ–‡æ¡£è¡¨ç¤ºå½¢å¼ã€‚</p><script type="math/tex; mode=display">H^a= \{\hat h^a_i\}^M_{i=1}</script><p>å°†ä¸Šå±‚gateçš„è®¡ç®—ç»“æœé€šè¿‡sigmoidå‡½æ•°è¿‡æ»¤ï¼Œä»…å°†æ–‡æ¡£çš„ä¸ç­”æ¡ˆç›¸å…³çš„è¯­ä¹‰ä¿¡æ¯è½¬å‘ç»™ä¸‹æ¸¸å¤šè·³æ¨ç† ã€‚</p><script type="math/tex; mode=display">h^a_i= Ïƒ(aW_a\hat h_i) âˆ— \hat h_i</script><blockquote><p>$a$ï¼šç¬¬ä¸€ä¸ªç­”æ¡ˆè¯çš„éšè—çŠ¶æ€ã€‚</p><p>$W_a$ï¼šæ˜¯å¯è®­ç»ƒæƒé‡ã€‚</p></blockquote><h3 id="Multi-hop-Answer-focused-Reasoning-Answer-centric-Entity-Graph-Grounding"><a href="#Multi-hop-Answer-focused-Reasoning-Answer-centric-Entity-Graph-Grounding" class="headerlink" title="Multi-hop Answer-focused Reasoning Answer-centric Entity Graph Grounding"></a>Multi-hop Answer-focused Reasoning Answer-centric Entity Graph Grounding</h3><p>ä»¥ç­”æ¡ˆä¸ºä¸­å¿ƒçš„å®ä½“å›¾è¡¨ç¤ºä¸ºï¼š$G = {V, E}$</p><blockquote><p>$V$ï¼šè¡¨ç¤ºä¸åŒçº§åˆ«çš„å®ä½“èŠ‚ç‚¹ã€‚</p><p>Eï¼šè¡¨ç¤ºå¸¦æœ‰ä¸åŒè¯­ä¹‰å…³ç³»çš„èŠ‚ç‚¹ä¹‹é—´çš„è¾¹ã€‚</p></blockquote><p>å°†å®Œå…¨åŒ¹é…çš„ä¸åœè¯ï¼Œå‘½åå®ä½“ï¼Œç­”æ¡ˆå’Œæ ‡é¢˜è§†ä¸ºèŠ‚ç‚¹ã€‚</p><p>ä¸Šä¸‹æ–‡è¡¨ç¤ºçš„ä¸åŒç²’åº¦çº§åˆ«ï¼š</p><ul><li>å®Œå…¨åŒ¹é…çš„ä¸åœè¯å’Œå®ä½“èŠ‚ç‚¹å¯¹ç‰¹å®šæ–‡æ¡£ä¸Šä¸‹æ–‡ä¸­çš„å•è¯çº§åˆ«å’Œæœ¬åœ°è¡¨ç¤ºè¿›è¡Œç¼–ç ã€‚</li><li>æ ‡é¢˜èŠ‚ç‚¹ä»£è¡¨æ–‡æ¡£çº§è¯­ä¹‰ã€‚</li><li>ç­”æ¡ˆèŠ‚ç‚¹æä¾›å›¾æ¨ç†çš„ç­”æ¡ˆæ„ŸçŸ¥è¡¨ç¤ºï¼Œå¹¶è·¨æ–‡æ¡£å»ºæ¨¡å…¨å±€è¡¨ç¤ºã€‚</li></ul><p>èŠ‚ç‚¹ä¹‹é—´è¾¹çš„å®šä¹‰ï¼š</p><ul><li>å°†æ‰€æœ‰å®Œå…¨åŒ¹é…çš„å‘½åå®ä½“è¿æ¥åœ¨ä¸€èµ·ï¼Œæ— è®ºå®ƒä»¬åœ¨åŒä¸€æ–‡æ¡£ä¸­è¿˜æ˜¯åœ¨ä¸åŒæ–‡æ¡£ä¸­ã€‚</li><li>å°†æ‰€æœ‰æ–‡æ¡£é—´å’Œæ–‡æ¡£å†…å®Œå…¨åŒ¹é…çš„ä¸åœè¯ï¼ˆä¾‹å¦‚â€œæ­Œæ‰‹ï¼Œè¯æ›²ä½œè€…â€ï¼‰è¿æ¥èµ·æ¥ã€‚</li><li>å°†æ‰€æœ‰å…±æŒ‡è¯ç›¸äº’é“¾æ¥ã€‚</li><li>å°†æ ‡é¢˜èŠ‚ç‚¹ä¸åŒä¸€æ–‡æ¡£ä¸­çš„æ‰€æœ‰å®ä½“èŠ‚ç‚¹è¿æ¥èµ·æ¥ã€‚</li><li>åœ¨æ‰€æœ‰æ ‡é¢˜èŠ‚ç‚¹ä¹‹é—´æ·»åŠ å¯†é›†è¿æ¥ã€‚</li><li>ç­”æ¡ˆèŠ‚ç‚¹è¿æ¥åˆ°å›¾ä¸­çš„æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹ï¼Œä»è€Œå½¢æˆä¸€ä¸ªä»¥ç­”æ¡ˆä¸ºä¸­å¿ƒçš„å®ä½“å›¾ã€‚</li></ul><p>ç¤ºä¾‹ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210225201957.png" alt="image-20210225201957327" style="zoom:50%;" /></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210225201936.png" alt="image-20210225201936243" style="zoom:50%;" /></p><h3 id="Multi-hop-Reasoning-with-RGCN"><a href="#Multi-hop-Reasoning-with-RGCN" class="headerlink" title="Multi-hop Reasoning with RGCN"></a>Multi-hop Reasoning with RGCN</h3><p>ä½¿ç”¨GNN-based modelè¿›è¡Œå¤šè·³æ¨ç†ã€‚â€”â€”<strong>RGCN</strong></p><p>ç»è¿‡Lå±‚æ¨ç†åï¼Œæœ€å¤šå¯ä»¥æ•è·åˆ°Lè·³å…³ç³»ã€‚</p><h2 id="Aggregation-Layer"><a href="#Aggregation-Layer" class="headerlink" title="Aggregation Layer"></a>Aggregation Layer</h2><p>é€šè¿‡ä½¿ç”¨å¯è®­ç»ƒçš„layer-wiseæƒé‡é€‰æ‹©æ€§åœ°æ±‡æ€»æ¯ä¸ªRGCNå±‚çš„è¾“å‡ºå’Œç­”æ¡ˆæ„ŸçŸ¥æ–‡æ¡£è¡¨ç¤ºç”Ÿæˆæ¥è®¡ç®—æœ€ç»ˆçš„ç­”æ¡ˆæ„ŸçŸ¥ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚</p><p>æ¯å±‚çš„ç­”æ¡ˆèŠ‚ç‚¹è¡¨ç¤ºå½¢å¼å’ŒLSTMçš„æœ€åä¸€ä¸ªéšè—çŠ¶æ€å †å åœ¨ä¸€èµ·ï¼Œä»¥äº§ç”Ÿæ›´å‡†ç¡®çš„æ–‡æ¡£çº§å’Œå…¨å±€è¡¨ç¤ºå½¢å¼ã€‚</p><h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p>å°†éšè—çŠ¶æ€åˆå§‹åŒ–ä¸º$s_0 = z$æ—¶ï¼Œå°†å•å‘LSTMç”¨ä½œè§£ç å™¨ä»¥ç”Ÿæˆé—®é¢˜ï¼Œåœ¨ç»™å®šå…ˆå‰ç”Ÿæˆçš„å•è¯å’Œå…ˆå‰éšè—çŠ¶æ€çš„æƒ…å†µä¸‹ï¼Œæ›´æ–°å½“å‰éšè—çŠ¶æ€ã€‚</p><script type="math/tex; mode=display">s_t= LSTM_{Dec}([w_t; c_{tâˆ’1}], s_{tâˆ’1})</script><p>è§£å†³è¯æ±‡é‡ä¸è¶³çš„é—®é¢˜ï¼š</p><p>åœ¨encoderçš„æ¯ä¸ªæ­¥éª¤ä¸­ï¼Œè®¡ç®—æ¦‚ç‡ï¼Œä»è€Œå†³å®šåŸºäºæ³¨æ„åŠ›çŸ©é˜µä»è¾“å…¥æ–‡æ¡£ä¸­å¤åˆ¶å•è¯ï¼Œæˆ–é€šè¿‡å…·æœ‰softmaxåŠŸèƒ½çš„è¾“å‡ºå±‚ä»è¯æ±‡è¡¨ç”Ÿæˆå•è¯ã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>HOTPOTQA</p><p>ä¸¢å¼ƒâ€œcomparisonâ€ç±»å‹çš„é—®é¢˜ï¼Œå¹¶ä¸”ä»…æ”¶é›†æ–‡æ¡£é›†ä¸­æ ‡æœ‰â€œsupporting factsâ€çš„æ–‡æœ¬ã€‚ ç”±äºç¼ºä¹å¯¹åŸå§‹testing datasetçš„è®¿é—®æƒé™ï¼Œå°†training setå’Œdevelopment setç»“åˆåœ¨ä¸€èµ·ï¼Œå¹¶å°†å®ƒä»¬éšæœºåˆ†ä¸ºtraining set,development set,testing datasetã€‚</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p>å®éªŒç»“æœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210226193222.png" alt="image-20210226193222793"></p><p>æœ¬æ–‡æå‡ºçš„ä»¥å¤šè·³å›ç­”ä¸ºé‡ç‚¹çš„æ¨ç†æ¨¡å‹æ¯”åŸºçº¿è·å¾—æ›´é«˜çš„åˆ†æ•°ï¼Œå› ä¸ºå®ƒåœ¨åˆ©ç”¨ä»¥å›ç­”ä¸ºä¸­å¿ƒçš„å®ä½“å›¾ä¸Šçš„åŸºç¡€ä¸Šä½¿ç”¨ä¸åŒçš„å›ç­”æ„ŸçŸ¥ä¸Šä¸‹æ–‡å®ä½“è¡¨ç¤ºå½¢å¼å’Œå®ä½“ä¹‹é—´çš„è¯­ä¹‰å…³ç³»çš„ç²’åº¦çº§åˆ«ï¼Œä»è€Œå¯¹è§£ç å™¨äº§ç”Ÿäº†ç²¾ç¡®è€Œä¸°å¯Œçš„è¯­ä¹‰ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210226194739.png" alt="image-20210226194739677" style="zoom:50%;" /></p><p>DecompRCæ¨¡å‹ä½¿ç”¨æœ¬æ–‡æ¨¡å‹ç”Ÿæˆçš„é—®é¢˜ï¼Œå–å¾—äº†é™¤äººå·¥æå‡ºçš„é—®é¢˜å¤–æœ€ä½³æ•ˆæœã€‚</p><blockquote><p>DecompRCåœ¨ä¸åŒç”Ÿæˆé—®é¢˜ä¸Šçš„æ€§èƒ½ç›´è§‚åœ°åæ˜ äº†ç”Ÿæˆé—®é¢˜çš„è´¨é‡å’Œæ¨¡å‹çš„å¤šè·³æ¨ç†èƒ½åŠ›ã€‚</p></blockquote><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>ä»¥ç­”æ¡ˆä¸ºä¸­å¿ƒçš„å¤šè·³æ¨ç†æ¨¡å‹çš„è®¾è®¡æ˜¯åˆ©ç”¨å®ƒä»¬ä¹‹é—´çš„å„ç§è¯­ä¹‰å…³ç³»æ¥å‘ç°å’Œæ•è·ä¸ç­”æ¡ˆæœ‰å…³çš„å®ä½“ã€‚</p><p>æœ¬æ–‡é€šè¿‡å‘ç°å’Œå»ºæ¨¡æ–‡æ¡£ä¸­çš„å¤šä¸ªå®ä½“åŠå…¶è¯­ä¹‰å…³ç³»ï¼Œå¯¹ç»™å®šæ–‡æ¡£é›†åˆå’Œç›¸åº”ç­”æ¡ˆçš„å¤æ‚é—®é¢˜è¿›è¡Œè¯¢é—®ã€‚ ä¸ºäº†è§£å†³è¯¥é—®é¢˜ï¼Œæœ¬æ–‡é€šè¿‡åˆ©ç”¨ä»¥è‡ªç„¶è¯­è¨€æ–‡æœ¬æ„å»ºçš„ä»¥ç­”æ¡ˆä¸ºä¸­å¿ƒçš„å®ä½“å›¾ä¸­çš„è¯­ä¹‰ä¿¡æ¯çš„ä¸åŒç²’åº¦çº§åˆ«ï¼Œæå‡ºäº†é’ˆå¯¹ç­”æ¡ˆçš„å¤šè·³æ¨ç†ã€‚ å®éªŒç»“æœè¯æ˜åœ¨æœºå™¨è¯„ä¼°å’Œäººå·¥è¯„ä¼°æ–¹é¢éƒ½å–å¾—ä¼˜ç§€çš„ç»“æœã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> hotpot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tag-based-multi-span-extraction</title>
      <link href="/2021/02/19/tag-based-multi-span-extraction/"/>
      <url>/2021/02/19/tag-based-multi-span-extraction/</url>
      
        <content type="html"><![CDATA[<h1 id="tag-based-multi-span-extraction"><a href="#tag-based-multi-span-extraction" class="headerlink" title="tag-based-multi-span-extraction"></a>tag-based-multi-span-extraction</h1><blockquote><p><a href="https://github.com/eladsegal/tag-based-multi-span-extraction">ä»£ç ï¼šhttps://github.com/eladsegal/tag-based-multi-span-extraction</a></p><p><a href="https://arxiv.org/abs/1909.13375">è®ºæ–‡ï¼šA Simple and Effective Model for Answering Multi-span Questions</a></p></blockquote><ul><li>é…ç½®ç¯å¢ƒå˜é‡æ·»åŠ ä»£ç†</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r zhaoxiaofeng@219.216.64.175:~/.proxychains ./</span><br></pre></td></tr></table></figure><p>ä¿®æ”¹~/.bashrcï¼Œåœ¨æœ«å°¾æ·»åŠ æŒ‡ä»¤åˆ«å</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alias proxy=/data0/zhaoxiaofeng/usr/bin/proxychains4 # 77, 175, 206åªæ·»åŠ è¿™æ¡ </span><br><span class="line">alias aliasproxy=/home/zhaoxiaofeng/usr/bin/proxychains4 # 154åªæ·»åŠ è¿™æ¡</span><br></pre></td></tr></table></figure><ul><li>ä¸‹è½½ä»£ç ï¼š</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/eladsegal/tag-based-multi-span-extraction</span><br></pre></td></tr></table></figure><ul><li>é…ç½®ç¯å¢ƒ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">proxy conda create -n allennlp python=3.6.9</span><br><span class="line">proxy pip install -r requirements.txt</span><br><span class="line">proxy conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch</span><br><span class="line">pip install en_core_web_sm-2.1.0.tar.gz</span><br><span class="line">åŠ è½½æœ¬åœ°é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå‚è€ƒ é¢„è®­ç»ƒæ¨¡å‹â€”â€”æ›¿æ¢ä¸ºæœ¬åœ°æ–‡ä»¶ï¼‰</span><br></pre></td></tr></table></figure><ul><li><p>è®­ç»ƒæ¨¡å‹</p><blockquote><p>å¯ä»¥ä½¿ç”¨nohup + &amp;åœ¨åå°è®­ç»ƒ</p><p>tail -f nohup.txt å¯ä»¥å®æ—¶æŸ¥çœ‹æ—¥å¿—</p><p>nohup command &gt;&gt; nohup.out 2&gt;&amp;1 &amp;</p><ul><li>2&gt;&amp;1çš„æ„æ€æ˜¯å°†æ ‡å‡†é”™è¯¯(2)ä¹Ÿå®šå‘åˆ°æ ‡å‡†è¾“å‡º(1)çš„è¾“å‡ºæ–‡ä»¶ä¸­ã€‚</li></ul></blockquote></li></ul><p><strong>RoBERTa TASE_IO + SSE</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp train configs/drop/roberta/drop_roberta_large_TASE_IO_SSE.jsonnet -s training_directory -f --include-package src</span><br></pre></td></tr></table></figure><p>æœåŠ¡å™¨è¿è¡Œï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup allennlp train configs/drop/roberta/drop_roberta_large_TASE_IO_SSE.jsonnet -s training_directory_base -f --include-package src &gt;&gt; base_log.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>æˆ–ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp train download_data/config.json -s training_directory --include-package src</span><br></pre></td></tr></table></figure><p><strong>Bert_large TASE_BIO + SSE</strong></p><blockquote><p>-f ï¼šå¯ä»¥æ¸…ç©ºè®­ç»ƒæ•°æ®æ–‡ä»¶å¤¹ï¼Œé‡æ–°è®­ç»ƒ</p><p>-rï¼šå¯ä»¥ä»ä¹‹å‰çš„è®­ç»ƒçŠ¶æ€æ¢å¤</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp train configs/drop/bert/drop_bert_large_TASE_BIO_SSE.jsonnet -s training_directory_bert -f --include-package src</span><br></pre></td></tr></table></figure><p>æœåŠ¡å™¨è¿è¡Œï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup allennlp train configs/drop/bert/drop_bert_large_TASE_BIO_SSE.jsonnet -s training_directory_bert -f --include-package src &gt;&gt; bertlog.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><ul><li><p>é¢„æµ‹æ¨¡å‹</p><blockquote><p>cuda-device åªèƒ½ä½¿ç”¨ä¸€ä¸ªGPU</p><p>åæ–‡è¯¦ç»†ä»‹ç»</p></blockquote></li><li><p>è¯„ä¼°æ¨¡å‹</p><blockquote><p>åæ–‡è¯¦ç»†ä»‹ç»</p></blockquote></li></ul><h2 id="é¢„è®­ç»ƒæ¨¡å‹â€”â€”æ›¿æ¢ä¸ºæœ¬åœ°æ–‡ä»¶"><a href="#é¢„è®­ç»ƒæ¨¡å‹â€”â€”æ›¿æ¢ä¸ºæœ¬åœ°æ–‡ä»¶" class="headerlink" title="é¢„è®­ç»ƒæ¨¡å‹â€”â€”æ›¿æ¢ä¸ºæœ¬åœ°æ–‡ä»¶"></a>é¢„è®­ç»ƒæ¨¡å‹â€”â€”æ›¿æ¢ä¸ºæœ¬åœ°æ–‡ä»¶</h2><p><strong>å®šä½æŠ€å·§ï¼š</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find è·¯å¾„ | grep -ri  â€œå­—ç¬¦ä¸²â€ -l</span><br></pre></td></tr></table></figure><p>ä¸‹è½½æ–‡ä»¶ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt</span><br></pre></td></tr></table></figure><p><strong>å¿«é€Ÿä¸‹è½½æ–‡ä»¶æŠ€å·§ï¼š</strong></p><blockquote><p>ç”±äºpythonä¸­æ— æ³•æ‰§è¡Œproxyï¼ŒæŠ¥é”™<code>sh: 1: proxy: not found</code>åªèƒ½é€šè¿‡æ‰‹åŠ¨æ–¹å¼è¿›è¡Œï¼Œæ•…ç¼–å†™å¦‚ä¸‹è„šæœ¬ï¼Œå®ç°å‘½ä»¤ç”Ÿæˆï¼Œæ‰“å°ï¼Œå¤åˆ¶æ‰“å°çš„å†…å®¹å¹¶æ‰§è¡Œå¯å®ç°æ‰¹é‡ä¸‹è½½ã€‚</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">BERT_PRETRAINED_MODEL_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;bert-base-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-cased-pytorch_model.bin&quot;</span><br><span class="line">&#125;</span><br><span class="line">for url in BERT_PRETRAINED_MODEL_ARCHIVE_MAP.values():</span><br><span class="line">    urls= &#x27;proxy wget &#x27;+url</span><br><span class="line">    print(urls)</span><br></pre></td></tr></table></figure><p>æ‰§è¡Œç»“æœï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json</span><br><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json</span><br><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json</span><br><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json</span><br><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json</span><br></pre></td></tr></table></figure><p>æ¶‰åŠæ–‡ä»¶ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_roberta.py</span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_roberta.py</span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_roberta.py</span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_utils.py </span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_bert.py</span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_bert.py</span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_bert.py</span><br></pre></td></tr></table></figure><ul><li>å„æœåŠ¡å™¨è·¯å¾„</li></ul><div class="table-container"><table><thead><tr><th>æœåŠ¡å™¨</th><th>è·¯å¾„</th></tr></thead><tbody><tr><td>202.199.6.77</td><td>/data0/maqi</td></tr><tr><td>219.216.64.206</td><td>/data0/maqi</td></tr><tr><td>219.216.64.175</td><td></td></tr><tr><td>219.216.64.154</td></tr></tbody></table></div><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_roberta.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_roberta.py</span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_roberta.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_roberta.py </span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_roberta.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_roberta.py </span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_utils.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_utils.py</span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_bert.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_bert.py</span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_bert.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_bert.py</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_bert.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_bert.py</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>tokenization_roberta.py</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_roberta.py</span><br></pre></td></tr></table></figure><p>åŸå§‹ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_VOCAB_FILES_MAP = &#123;</span><br><span class="line">    &#x27;vocab_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;roberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large-mnli&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-vocab.json&quot;,</span><br><span class="line">        &#x27;distilroberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-base-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#x27;merges_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;roberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large-mnli&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-merges.txt&quot;,</span><br><span class="line">        &#x27;distilroberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-base-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>æ›¿æ¢ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_VOCAB_FILES_MAP = &#123;</span><br><span class="line">    &#x27;vocab_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;roberta-base&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large-mnli&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-mnli-vocab.json&quot;,</span><br><span class="line">        &#x27;distilroberta-base&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/distilroberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-base-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-vocab.json&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#x27;merges_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;roberta-base&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large-mnli&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-mnli-merges.txt&quot;,</span><br><span class="line">        &#x27;distilroberta-base&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/distilroberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-base-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-merges.txt&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>modeling_roberta.py</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_roberta.py</span><br></pre></td></tr></table></figure><p>åŸå§‹ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;roberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large-mnli&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;distilroberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-base-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-openai-detector-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-openai-detector-pytorch_model.bin&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ›¿æ¢ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;roberta-base&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/roberta-base-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/roberta-large-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large-mnli&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/roberta-large-mnli-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;distilroberta-base&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/distilroberta-base-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-base-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/roberta-base-openai-detector-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/roberta-large-openai-detector-pytorch_model.bin&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>configuration_roberta.py</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_roberta.py</span><br></pre></td></tr></table></figure><p>åŸå§‹ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;roberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large-mnli&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-config.json&quot;,</span><br><span class="line">    &#x27;distilroberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-config.json&quot;,</span><br><span class="line">    &#x27;roberta-base-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-openai-detector-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-openai-detector-config.json&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ›¿æ¢ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;roberta-base&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/roberta-base-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/roberta-large-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large-mnli&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/roberta-large-mnli-config.json&quot;,</span><br><span class="line">    &#x27;distilroberta-base&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/distilroberta-base-config.json&quot;,</span><br><span class="line">    &#x27;roberta-base-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/roberta-base-openai-detector-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/roberta-large-openai-detector-config.json&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>tokenization_bert.py</li></ul><p>åŸå§‹ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_VOCAB_FILES_MAP = &#123;</span><br><span class="line">    &#x27;vocab_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;bert-base-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-multilingual-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-multilingual-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-chinese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-cased&#x27;: &quot;https://int-deepset-models-bert.s3.eu-central-1.amazonaws.com/pytorch/bert-base-german-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-finnish-cased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-uncased-v1/vocab.txt&quot;,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ›¿æ¢ï¼š</p><blockquote><p>æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼š/data0/maqi/pretrained_model/tokenization_bert</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_VOCAB_FILES_MAP = &#123;</span><br><span class="line">    &#x27;vocab_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;bert-base-uncased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-large-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-cased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-multilingual-uncased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-multilingual-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-multilingual-cased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-multilingual-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-chinese&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-chinese-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-cased&#x27;: &quot;https://int-deepset-models-bert.s3.eu-central-1.amazonaws.com/pytorch/bert-base-german-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-large-uncased-whole-word-masking-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-large-cased-whole-word-masking-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-large-uncased-whole-word-masking-finetuned-squad-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-large-cased-whole-word-masking-finetuned-squad-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-cased-finetuned-mrpc-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-german-dbmdz-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-german-dbmdz-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-finnish-cased-v1&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/TurkuNLP/bert-base-finnish-cased-v1/vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/TurkuNLP/bert-base-finnish-uncased-v1/vocab.txt&quot;,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>configuration_bert.py</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_bert.py</span><br></pre></td></tr></table></figure><p>åŸå§‹ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">BERT_PRETRAINED_CONFIG_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;bert-base-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-chinese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-cased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/config.json&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-uncased-v1/config.json&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ›¿æ¢ï¼š</p><blockquote><p>æœ¬åœ°æ–‡ä»¶ï¼š/data0/maqi/pretrained_model/configuration_bert</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">BERT_PRETRAINED_CONFIG_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;bert-base-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-chinese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-cased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/config.json&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-uncased-v1/config.json&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>modeling_bert.py</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_bert.py</span><br></pre></td></tr></table></figure><p>åŸå§‹ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">BERT_PRETRAINED_MODEL_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;bert-base-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-chinese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-cased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-uncased-v1/pytorch_model.bin&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ›¿æ¢ï¼š</p><blockquote><p>æœ¬åœ°è·¯å¾„ï¼š/data0/maqi/pretrained_model/modeling_bert</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">BERT_PRETRAINED_MODEL_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;bert-base-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-multilingual-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-multilingual-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-chinese&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-chinese-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-german-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-uncased-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-cased-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-uncased-whole-word-masking-finetuned-squad-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-cased-finetuned-mrpc-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-german-dbmdz-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-german-dbmdz-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/cl-tohoku/bert-base-japanese-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/cl-tohoku/bert-base-japanese-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/cl-tohoku/bert-base-japanese-char-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-cased-v1&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/TurkuNLP/bert-base-finnish-cased-v1/pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/TurkuNLP/bert-base-finnish-uncased-v1/pytorch_model.bin&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="æ‰§è¡Œæµç¨‹"><a href="#æ‰§è¡Œæµç¨‹" class="headerlink" title="æ‰§è¡Œæµç¨‹"></a>æ‰§è¡Œæµç¨‹</h2><blockquote><p>é’ˆå¯¹tag-based-multi-span-extraction/configs/drop/roberta/drop_roberta_large_TASE_IO_SSE.jsonnetâ€‹åˆ†æ</p></blockquote><ul><li><p>dataset_reader</p><blockquote><p>â€œis_trainingâ€: true,è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">&quot;dataset_reader&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;tbmse_drop&quot;,//é€‰æ‹©src/data/dataset_readers/drop/drop_reader.py</span><br><span class="line">    &quot;answer_field_generators&quot;: &#123;</span><br><span class="line">        &quot;arithmetic_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;arithmetic_answer_generator&quot;,//é€‰æ‹©src/data/dataset_readers/answer_field_generators/arithmetic_answer_generator.py</span><br><span class="line">            &quot;special_numbers&quot;: [</span><br><span class="line">                100,</span><br><span class="line">                1</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;count_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;count_answer_generator&quot;//é€‰æ‹©src/data/dataset_readers/answer_field_generators/count_answer_generator.py</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;passage_span_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;span_answer_generator&quot;,//é€‰æ‹©src/data/dataset_readers/answer_field_generators/span_answer_generator.py</span><br><span class="line">            &quot;text_type&quot;: &quot;passage&quot;//å‚æ•°</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;question_span_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;span_answer_generator&quot;,//é€‰æ‹©src/data/dataset_readers/answer_field_generators/span_answer_generator.py</span><br><span class="line">            &quot;text_type&quot;: &quot;question&quot;//å‚æ•°</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;tagged_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;tagged_answer_generator&quot;,//é€‰æ‹©src/data/dataset_readers/answer_field_generators/tagged_answer_generator.py</span><br><span class="line">            &quot;ignore_question&quot;: false,</span><br><span class="line">            &quot;labels&quot;: &#123;</span><br><span class="line">                &quot;I&quot;: 1,</span><br><span class="line">                &quot;O&quot;: 0</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;answer_generator_names_per_type&quot;: &#123;//drop_reader.pyçš„å‚æ•°</span><br><span class="line">        &quot;date&quot;: [</span><br><span class="line">            &quot;arithmetic_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;,</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;multiple_span&quot;: [</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;number&quot;: [</span><br><span class="line">            &quot;arithmetic_answer&quot;,</span><br><span class="line">            &quot;count_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;,</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;single_span&quot;: [</span><br><span class="line">            &quot;tagged_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;is_training&quot;: true,</span><br><span class="line">    &quot;lazy&quot;: true,</span><br><span class="line">    &quot;old_reader_behavior&quot;: true,</span><br><span class="line">    &quot;pickle&quot;: &#123;</span><br><span class="line">        &quot;action&quot;: &quot;load&quot;,</span><br><span class="line">        &quot;file_name&quot;: &quot;all_heads_IO_roberta-large&quot;,</span><br><span class="line">        &quot;path&quot;: &quot;../pickle/drop&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;huggingface_transformers&quot;,//é€‰æ‹©src/data/tokenizers/huggingface_transformers_tokenizer.py</span><br><span class="line">        &quot;pretrained_model&quot;: &quot;roberta-large&quot;//å‚æ•°</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ul><li>model</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line">&quot;model&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;multi_head&quot;,//é€‰æ‹©src/models/multi_head_model.py</span><br><span class="line">    &quot;dataset_name&quot;: &quot;drop&quot;,</span><br><span class="line">    &quot;head_predictor&quot;: &#123;</span><br><span class="line">        &quot;activations&quot;: [</span><br><span class="line">            &quot;relu&quot;,</span><br><span class="line">            &quot;linear&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;dropout&quot;: [</span><br><span class="line">            0.1,</span><br><span class="line">            0</span><br><span class="line">        ],</span><br><span class="line">        &quot;hidden_dims&quot;: [</span><br><span class="line">            1024,</span><br><span class="line">            5</span><br><span class="line">        ],</span><br><span class="line">        &quot;input_dim&quot;: 2048,</span><br><span class="line">        &quot;num_layers&quot;: 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;heads&quot;: &#123;</span><br><span class="line">        &quot;arithmetic&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;arithmetic_head&quot;,//é€‰æ‹©src/modules/heads/arithmetic_head.py</span><br><span class="line">            &quot;output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: [</span><br><span class="line">                    &quot;relu&quot;,</span><br><span class="line">                    &quot;linear&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;dropout&quot;: [</span><br><span class="line">                    0.1,</span><br><span class="line">                    0</span><br><span class="line">                ],</span><br><span class="line">                &quot;hidden_dims&quot;: [</span><br><span class="line">                    1024,</span><br><span class="line">                    3</span><br><span class="line">                ],</span><br><span class="line">                &quot;input_dim&quot;: 2048,</span><br><span class="line">                &quot;num_layers&quot;: 2</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;special_embedding_dim&quot;: 1024,</span><br><span class="line">            &quot;special_numbers&quot;: [</span><br><span class="line">                100,</span><br><span class="line">                1</span><br><span class="line">            ],</span><br><span class="line">            &quot;training_style&quot;: &quot;soft_em&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;count&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;count_head&quot;,//é€‰æ‹©src/modules/heads/count_head.py</span><br><span class="line">            &quot;max_count&quot;: 10,</span><br><span class="line">            &quot;output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: [</span><br><span class="line">                    &quot;relu&quot;,</span><br><span class="line">                    &quot;linear&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;dropout&quot;: [</span><br><span class="line">                    0.1,</span><br><span class="line">                    0</span><br><span class="line">                ],</span><br><span class="line">                &quot;hidden_dims&quot;: [</span><br><span class="line">                    1024,</span><br><span class="line">                    11</span><br><span class="line">                ],</span><br><span class="line">                &quot;input_dim&quot;: 1024,</span><br><span class="line">                &quot;num_layers&quot;: 2</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;multi_span&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;multi_span_head&quot;,//é€‰æ‹©src/modules/heads/multi_span_head.py</span><br><span class="line">            &quot;decoding_style&quot;: &quot;at_least_one&quot;,</span><br><span class="line">            &quot;ignore_question&quot;: false,</span><br><span class="line">            &quot;labels&quot;: &#123;</span><br><span class="line">                &quot;I&quot;: 1,</span><br><span class="line">                &quot;O&quot;: 0</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: [</span><br><span class="line">                    &quot;relu&quot;,</span><br><span class="line">                    &quot;linear&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;dropout&quot;: [</span><br><span class="line">                    0.1,</span><br><span class="line">                    0</span><br><span class="line">                ],</span><br><span class="line">                &quot;hidden_dims&quot;: [</span><br><span class="line">                    1024,</span><br><span class="line">                    2</span><br><span class="line">                ],</span><br><span class="line">                &quot;input_dim&quot;: 1024,</span><br><span class="line">                &quot;num_layers&quot;: 2</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;prediction_method&quot;: &quot;viterbi&quot;,</span><br><span class="line">            &quot;training_style&quot;: &quot;soft_em&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;passage_span&quot;: &#123;//ç»§æ‰¿äº†src/modules/heads/single_span_head.py </span><br><span class="line">            &quot;type&quot;: &quot;passage_span_head&quot;,//é€‰æ‹©src/modules/heads/passage_span_head.py</span><br><span class="line">            &quot;end_output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: &quot;linear&quot;,</span><br><span class="line">                &quot;hidden_dims&quot;: 1,</span><br><span class="line">                &quot;input_dim&quot;: 1024,</span><br><span class="line">                &quot;num_layers&quot;: 1</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;start_output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: &quot;linear&quot;,</span><br><span class="line">                &quot;hidden_dims&quot;: 1,</span><br><span class="line">                &quot;input_dim&quot;: 1024,</span><br><span class="line">                &quot;num_layers&quot;: 1</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;training_style&quot;: &quot;soft_em&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;question_span&quot;: &#123;//ç»§æ‰¿äº†src/modules/heads/single_span_head.py </span><br><span class="line">            &quot;type&quot;: &quot;question_span_head&quot;,//é€‰æ‹©src/modules/heads/question_span_head.py  </span><br><span class="line">            &quot;end_output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: [</span><br><span class="line">                    &quot;relu&quot;,</span><br><span class="line">                    &quot;linear&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;dropout&quot;: [</span><br><span class="line">                    0.1,</span><br><span class="line">                    0</span><br><span class="line">                ],</span><br><span class="line">                &quot;hidden_dims&quot;: [</span><br><span class="line">                    1024,</span><br><span class="line">                    1</span><br><span class="line">                ],</span><br><span class="line">                &quot;input_dim&quot;: 2048,</span><br><span class="line">                &quot;num_layers&quot;: 2</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;start_output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: [</span><br><span class="line">                    &quot;relu&quot;,</span><br><span class="line">                    &quot;linear&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;dropout&quot;: [</span><br><span class="line">                    0.1,</span><br><span class="line">                    0</span><br><span class="line">                ],</span><br><span class="line">                &quot;hidden_dims&quot;: [</span><br><span class="line">                    1024,</span><br><span class="line">                    1</span><br><span class="line">                ],</span><br><span class="line">                &quot;input_dim&quot;: 2048,</span><br><span class="line">                &quot;num_layers&quot;: 2</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;training_style&quot;: &quot;soft_em&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;passage_summary_vector_module&quot;: &#123;</span><br><span class="line">        &quot;activations&quot;: &quot;linear&quot;,</span><br><span class="line">        &quot;hidden_dims&quot;: 1,</span><br><span class="line">        &quot;input_dim&quot;: 1024,</span><br><span class="line">        &quot;num_layers&quot;: 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;pretrained_model&quot;: &quot;roberta-large&quot;,</span><br><span class="line">    &quot;question_summary_vector_module&quot;: &#123;</span><br><span class="line">        &quot;activations&quot;: &quot;linear&quot;,</span><br><span class="line">        &quot;hidden_dims&quot;: 1,</span><br><span class="line">        &quot;input_dim&quot;: 1024,</span><br><span class="line">        &quot;num_layers&quot;: 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ul><li>æ•°æ®é›†</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;train_data_path&quot;: &quot;drop_data/drop_dataset_train.json&quot;,</span><br><span class="line">&quot;validation_data_path&quot;: &quot;drop_data/drop_dataset_dev.json&quot;,</span><br></pre></td></tr></table></figure><ul><li><p>trainer</p><blockquote><p>â€œcuda_deviceâ€: -1,è¡¨ç¤ºä½¿ç”¨cpu</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&quot;trainer&quot;: &#123;</span><br><span class="line">    &quot;cuda_device&quot;: 0,</span><br><span class="line">    &quot;keep_serialized_model_every_num_seconds&quot;: 3600,</span><br><span class="line">    &quot;num_epochs&quot;: 35,</span><br><span class="line">    &quot;num_steps_to_accumulate&quot;: 6,</span><br><span class="line">    &quot;optimizer&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;adamw&quot;,</span><br><span class="line">        &quot;lr&quot;: 5e-06</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;patience&quot;: 10,</span><br><span class="line">    &quot;summary_interval&quot;: 100,</span><br><span class="line">    &quot;validation_metric&quot;: &quot;+f1&quot;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ul><li><p>validation_dataset_reader</p><blockquote><p>â€œis_trainingâ€: false,è®¾ç½®ä¸ºè¯„ä¼°</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">&quot;validation_dataset_reader&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;tbmse_drop&quot;,//é€‰æ‹©src/data/dataset_readers/drop/drop_reader.py</span><br><span class="line">    &quot;answer_field_generators&quot;: &#123;</span><br><span class="line">        &quot;arithmetic_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;arithmetic_answer_generator&quot;,</span><br><span class="line">            &quot;special_numbers&quot;: [</span><br><span class="line">                100,</span><br><span class="line">                1</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;count_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;count_answer_generator&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;passage_span_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;span_answer_generator&quot;,</span><br><span class="line">            &quot;text_type&quot;: &quot;passage&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;question_span_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;span_answer_generator&quot;,</span><br><span class="line">            &quot;text_type&quot;: &quot;question&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;tagged_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;tagged_answer_generator&quot;,</span><br><span class="line">            &quot;ignore_question&quot;: false,</span><br><span class="line">            &quot;labels&quot;: &#123;</span><br><span class="line">                &quot;I&quot;: 1,</span><br><span class="line">                &quot;O&quot;: 0</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;answer_generator_names_per_type&quot;: &#123;</span><br><span class="line">        &quot;date&quot;: [</span><br><span class="line">            &quot;arithmetic_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;,</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;multiple_span&quot;: [</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;number&quot;: [</span><br><span class="line">            &quot;arithmetic_answer&quot;,</span><br><span class="line">            &quot;count_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;,</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;single_span&quot;: [</span><br><span class="line">            &quot;tagged_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;is_training&quot;: false,//è®¾ç½®ä¸ºè¯„ä¼°</span><br><span class="line">    &quot;lazy&quot;: true,</span><br><span class="line">    &quot;old_reader_behavior&quot;: true,</span><br><span class="line">    &quot;pickle&quot;: &#123;</span><br><span class="line">        &quot;action&quot;: &quot;load&quot;,</span><br><span class="line">        &quot;file_name&quot;: &quot;all_heads_IO_roberta-large&quot;,</span><br><span class="line">        &quot;path&quot;: &quot;../pickle/drop&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;huggingface_transformers&quot;,</span><br><span class="line">        &quot;pretrained_model&quot;: &quot;roberta-large&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="é¢„æµ‹"><a href="#é¢„æµ‹" class="headerlink" title="é¢„æµ‹"></a>é¢„æµ‹</h2><p>è®­ç»ƒæ¨¡å‹æ‰“åŒ…ä¸º<strong>model.tar.gz</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp predict training_directory/model.tar.gz drop_data/drop_dataset_dev.json --predictor machine-comprehension --cuda-device 0 --output-file predictions.jsonl --use-dataset-reader --include-package src</span><br></pre></td></tr></table></figure><p>é¢„æµ‹ç»“æœä¿å­˜åœ¨æ ¹ç›®å½•çš„predictions.jsonl</p><h2 id="è¯„ä¼°"><a href="#è¯„ä¼°" class="headerlink" title="è¯„ä¼°"></a>è¯„ä¼°</h2><p><strong>DROP</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp evaluate training_directory/model.tar.gz drop_data/drop_dataset_dev.json --cuda-device 3 --output-file eval.json --include-package src</span><br></pre></td></tr></table></figure><p><strong>BERT</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp evaluate training_directory_bert/model.tar.gz drop_data/drop_dataset_dev.json --cuda-device 1 --output-file eval_bert.json --include-package src</span><br></pre></td></tr></table></figure><p>é¢„æµ‹ç»“æœä¿å­˜åœ¨æ ¹ç›®å½•çš„eval.json</p><h3 id="è¯„ä¼°ç»“æœâ€”â€”DROP"><a href="#è¯„ä¼°ç»“æœâ€”â€”DROP" class="headerlink" title="è¯„ä¼°ç»“æœâ€”â€”DROP"></a>è¯„ä¼°ç»“æœâ€”â€”<strong>DROP</strong></h3><p><strong>TASE_IO+SSE</strong></p><div class="table-container"><table><thead><tr><th>em_all_spans</th><th>f1_all_spans</th><th>em_multi_span</th><th>f1_multi_span</th><th>em_span</th><th>f1_span</th></tr></thead><tbody><tr><td>80.6</td><td>87.8</td><td>60.8</td><td>82.6</td><td>84.2</td><td>89.0</td></tr></tbody></table></div><p><strong>TASE_IO+SSE(BLOCK)</strong></p><div class="table-container"><table><thead><tr><th>em_all_spans</th><th>f1_all_spans</th><th>em_multi_span</th><th>f1_multi_span</th><th>em_span</th><th>f1_span</th></tr></thead><tbody><tr><td>55.3</td><td>62.8</td><td>0</td><td>0</td><td>56.5</td><td>64.2</td></tr></tbody></table></div><p><strong>TASE_IO+SSE(BERT_large)</strong></p><div class="table-container"><table><thead><tr><th>em_all_spans</th><th>f1_all_spans</th><th>em_multi_span</th><th>f1_multi_span</th><th>em_span</th><th>f1_span</th></tr></thead><tbody><tr><td>76.4</td><td>83.9</td><td>54.5</td><td>80.1</td><td>80.7</td><td>85.2</td></tr></tbody></table></div><p><strong>TASE_IO+SSE(åªå¯¹åŒ…å«ç­”æ¡ˆçš„å¥å­åšIOæ ‡è®°)</strong></p><div class="table-container"><table><thead><tr><th>em_all_spans</th><th>f1_all_spans</th><th>em_multi_span</th><th>f1_multi_span</th><th>em_span</th><th>f1_span</th></tr></thead><tbody><tr><td>57.8</td><td>64.5</td><td>16.7</td><td>23.3</td><td>58.1</td><td>64.2</td></tr></tbody></table></div><p>è®ºæ–‡ç»“æœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210212155322.png" alt="image-20210212155315238"></p>]]></content>
      
      
      <categories>
          
          <category> è½¯ä»¶å¼€å‘&amp;æ¨¡å‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> DROP </tag>
            
            <tag> QUOREF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HOTPOTQA A Dataset for Diverse, Explainable Multi-hop Question Answering</title>
      <link href="/2021/02/05/HOTPOTQA%20A%20Dataset%20for%20Diverse,%20Explainable%20Multi-hop%20Question%20Answering/"/>
      <url>/2021/02/05/HOTPOTQA%20A%20Dataset%20for%20Diverse,%20Explainable%20Multi-hop%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="HOTPOTQA-A-Dataset-for-Diverse-Explainable-Multi-hop-Question-Answering"><a href="#HOTPOTQA-A-Dataset-for-Diverse-Explainable-Multi-hop-Question-Answering" class="headerlink" title="HOTPOTQA A Dataset for Diverse, Explainable Multi-hop Question Answering"></a>HOTPOTQA A Dataset for Diverse, Explainable Multi-hop Question Answering</h1><blockquote><p><a href="https://arxiv.org/pdf/1809.09600.pdf">è®ºæ–‡ï¼šhttps://arxiv.org/pdf/1809.09600.pdf</a></p><p>ä¸€ä¸ªå¤šæ ·çš„ï¼Œå¯è§£é‡Šçš„å¤šè·³é—®ç­”æ•°æ®é›†ã€‚</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>ç°æœ‰çš„é—®ç­”æ•°æ®é›†ä¸èƒ½è®­ç»ƒQAç³»ç»Ÿè¿›è¡Œå¤æ‚çš„æ¨ç†å¹¶æä¾›ç­”æ¡ˆçš„è§£é‡Šã€‚æå‡ºhotpotæ•°æ®é›†ï¼Œæä¾›æ”¯æŒäº‹å®ä½¿æ¨¡å‹èƒ½å¤Ÿæ”¹è¿›æ€§èƒ½å¹¶åšå‡ºå¯è§£é‡Šçš„é¢„æµ‹ã€‚</p><h2 id="HOTPOTQAä»‹ç»"><a href="#HOTPOTQAä»‹ç»" class="headerlink" title="HOTPOTQAä»‹ç»"></a>HOTPOTQAä»‹ç»</h2><p>HOTPOTQAæ˜¯ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œæ‹¥æœ‰113kä¸ªåŸºäºWikipediaçš„é—®ç­”å¯¹ï¼Œå…·æœ‰ä»¥ä¸‹å››ä¸ªå…³é”®ç‰¹æ€§ï¼š</p><ul><li>è¿™äº›é—®é¢˜éœ€è¦åœ¨å¤šä¸ªæ”¯æŒæ–‡æ¡£ä¸Šæ‰¾åˆ°ç­”æ¡ˆå¹¶è¿›è¡Œæ¨ç†ã€‚</li><li>é—®é¢˜æ˜¯å¤šæ ·çš„ï¼Œä¸å±€é™äºä»»ä½•é¢„å…ˆå­˜åœ¨çš„çŸ¥è¯†åº“æˆ–çŸ¥è¯†æ¨¡å¼ã€‚</li><li>æä¾›æ¨ç†æ‰€éœ€çš„å¥å­çº§æ”¯æŒäº‹å®ï¼Œå…è®¸QAç³»ç»Ÿåœ¨å¼ºç›‘ç£ä¸‹æ¨ç†å¹¶è§£é‡Šé¢„æµ‹ã€‚</li><li>æå‡ºäº†ä¸€ç§æ–°çš„factoid comparison questionsæ¥æµ‹è¯•QAç³»ç»Ÿæå–ç›¸å…³äº‹å®å’Œè¿›è¡Œå¿…è¦æ¯”è¾ƒçš„èƒ½åŠ›ã€‚</li></ul><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><h3 id="æ•°æ®é›†åˆ’åˆ†"><a href="#æ•°æ®é›†åˆ’åˆ†" class="headerlink" title="æ•°æ®é›†åˆ’åˆ†"></a>æ•°æ®é›†åˆ’åˆ†</h3><p>single-hopæ•°æ®é›†ï¼šThe train-easy set contains 18,089 mostly single-hop examples.</p><p>å°†hard exampleséšæœºåˆ’åˆ†ä¸º4ä¸ªå­é›†ï¼š</p><ul><li>train-hard, dev, test-distractor, test-fullwiki</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210131161128.png" alt="image-20210131161127920" style="zoom: 67%;" /></p><h3 id="two-benchmark-settings"><a href="#two-benchmark-settings" class="headerlink" title="two benchmark settings"></a>two benchmark settings</h3><ul><li><p>distractor</p><blockquote><p>8 paragraphs from Wikipedia + 2 gold paragraphs</p></blockquote></li><li><p>full wiki</p><blockquote><p>è¦æ±‚æ¨¡å‹å›ç­”æ‰€æœ‰Wikipediaæ–‡ç« çš„ç¬¬ä¸€æ®µç»™å‡ºçš„é—®é¢˜ã€‚</p></blockquote></li></ul><p>ä¸¤ç§è®¾ç½®ä½¿ç”¨ä¸åŒæ•°æ®é›†çš„åŸå› ï¼šdistractorè®¾ç½®ä¸­çš„æ¨¡å‹å¯ä»¥ä½¿ç”¨gold paragraphsï¼Œä½†full wikiè®¾ç½®ä¸­ä¸å¯ä»¥ä½¿ç”¨gold paragraphsã€‚</p><h3 id="Question-Types"><a href="#Question-Types" class="headerlink" title="Question Types"></a>Question Types</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210131164223.png" alt="image-20210131164223663"></p><h3 id="Answer-Types"><a href="#Answer-Types" class="headerlink" title="Answer Types"></a>Answer Types</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210131164623.png" alt="image-20210131164623642"></p><ul><li>68%çš„å›ç­”å®ä½“ç›¸å…³ã€‚</li></ul><h2 id="æ¨¡å‹ç»“æ„"><a href="#æ¨¡å‹ç»“æ„" class="headerlink" title="æ¨¡å‹ç»“æ„"></a>æ¨¡å‹ç»“æ„</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210131171031.png" alt="image-20210131171031628"></p><ul><li>å¯¹äºæ¯ä¸ªå¥å­ï¼Œåœ¨ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªä½ç½®è¿æ¥selfattention layerçš„è¾“å‡ºï¼Œå¹¶ä½¿ç”¨binary linear classifieræ¥é¢„æµ‹å½“å‰å¥å­æˆä¸ºæ”¯æŒäº‹å®çš„æ¦‚ç‡ã€‚ </li><li>å°†æ­¤åˆ†ç±»å™¨çš„äºŒè¿›åˆ¶äº¤å‰ç†µæŸå¤±æœ€å°åŒ–ã€‚ åœ¨å¤šä»»åŠ¡å­¦ä¹ ç¯å¢ƒä¸­ï¼Œè¯¥ç›®æ ‡ä¸æ­£å¸¸é—®ç­”ç›®æ ‡å…±åŒå¾—åˆ°ä¼˜åŒ–ï¼Œå¹¶ä¸”å®ƒä»¬å…±äº«ç›¸åŒçš„low-level representationsã€‚ </li><li>ä½¿ç”¨è¯¥åˆ†ç±»å™¨ï¼Œè¿˜å¯ä»¥åœ¨æ”¯æŒäº‹å®é¢„æµ‹çš„ä»»åŠ¡ä¸Šè¯„ä¼°æ¨¡å‹ä»¥è¯„ä¼°å…¶å¯è§£é‡Šæ€§ ã€‚</li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><h3 id="è¯„ä¼°æŒ‡æ ‡"><a href="#è¯„ä¼°æŒ‡æ ‡" class="headerlink" title="è¯„ä¼°æŒ‡æ ‡"></a>è¯„ä¼°æŒ‡æ ‡</h3><ul><li><p>exact match (EM) and F1</p></li><li><p>è®¡ç®—F1</p></li></ul><script type="math/tex; mode=display">P^{(joint)}= P^{(ans)}P^{(sup)}</script><script type="math/tex; mode=display">R^{(joint)}= R^{(ans)}R^{(sup)}</script><script type="math/tex; mode=display">Joint \ F1= \frac{2P^{(joint)}R^{(joint)}}{P^{(joint)}+ R^{(joint)}}</script><ul><li>è®¡ç®—EM<ul><li>ä»…å½“ä¸¤ä¸ªä»»åŠ¡éƒ½å®Œå…¨åŒ¹é…æ—¶ï¼ŒJoint EMæ‰ä¸º1ï¼Œå¦åˆ™ä¸º0ã€‚</li><li>é€ä¸ªç¤ºä¾‹è¯„ä¼°æ‰€æœ‰æŒ‡æ ‡ï¼Œç„¶åå¯¹è¯„ä¼°é›†ä¸­çš„ç¤ºä¾‹è¿›è¡Œå¹³å‡ã€‚</li></ul></li></ul><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210131172445.png" alt="image-20210131172445507"></p><p>åœ¨ä¸¤ç§è®¾ç½®ä¸‹ï¼Œæ‰©å¤§ä¸Šä¸‹æ–‡èŒƒå›´ä¼šå¢åŠ é—®é¢˜å›ç­”çš„éš¾åº¦ï¼Œæ‰€æœ‰è®¾ç½®ä¸‹çš„æ¨¡å‹æ€§èƒ½å‡æ˜æ˜¾ä½äºäººå·¥æ€§èƒ½ã€‚ ä¸distractorç›¸æ¯”full wikiè®¾ç½®ä¸­çš„æ€§èƒ½è¦ä½å¾—å¤šã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210131174126.png" alt="image-20210131174126572"></p><p>æŒ‰ä¸åŒé—®é¢˜ç±»å‹æµ‹è¯•ï¼š</p><ul><li>distractor settingä¸‹comparison questionsçš„F1å¾—åˆ†æ¯”bridge entities questionsä½ï¼Œè¡¨æ˜å¯¹è¿™ç§æ–°é¢–çš„é—®é¢˜ç±»å‹è¿›è¡Œæ›´å¥½çš„å»ºæ¨¡å¯èƒ½éœ€è¦æ›´å¥½çš„ç¥ç»ç½‘ç»œç»“æ„ã€‚</li><li>full wiki settingä¸‹bridge entities questionsçš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè€Œcomparison questionsçš„æ€§èƒ½ä»…ç•¥æœ‰ä¸‹é™ï¼Œæ˜¯å› ä¸ºä¸¤ä¸ªå®ä½“é€šå¸¸éƒ½å‡ºç°åœ¨æ¯”è¾ƒé—®é¢˜ä¸­ï¼Œä»è€Œé™ä½äº†æ£€ç´¢éš¾åº¦ ã€‚</li></ul><h2 id="å•ä¸ªæ ·æœ¬ç»“æ„"><a href="#å•ä¸ªæ ·æœ¬ç»“æ„" class="headerlink" title="å•ä¸ªæ ·æœ¬ç»“æ„"></a>å•ä¸ªæ ·æœ¬ç»“æ„</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210205091447.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> HOTPOTQA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchå­¦ä¹ ç¬”è®°(ä¸€)</title>
      <link href="/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/"/>
      <url>/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchå­¦ä¹ ç¬”è®°-ä¸€"><a href="#PyTorchå­¦ä¹ ç¬”è®°-ä¸€" class="headerlink" title="PyTorchå­¦ä¹ ç¬”è®°(ä¸€)"></a>PyTorchå­¦ä¹ ç¬”è®°(ä¸€)</h1><h2 id="åˆ›å»ºå¼ é‡-Tensors"><a href="#åˆ›å»ºå¼ é‡-Tensors" class="headerlink" title="åˆ›å»ºå¼ é‡ Tensors"></a>åˆ›å»ºå¼ é‡ Tensors</h2><h3 id="torch-rand"><a href="#torch-rand" class="headerlink" title="torch.rand"></a>torch.rand</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.rand(*sizes, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«äº†ä»åŒºé—´<strong>[0,1)</strong>çš„å‡åŒ€åˆ†å¸ƒä¸­æŠ½å–çš„ä¸€ç»„éšæœºæ•°ï¼Œå½¢çŠ¶ç”±å¯å˜å‚æ•°sizes å®šä¹‰ã€‚</p><p>å‚æ•°:</p><ul><li>sizes (intâ€¦) â€“ æ•´æ•°åºåˆ—ï¼Œå®šä¹‰äº†è¾“å‡ºå½¢çŠ¶</li><li>out (Tensor, optinal) - ç»“æœå¼ é‡ </li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.rand(4)</span><br><span class="line"></span><br><span class="line"> 0.9193</span><br><span class="line"> 0.3347</span><br><span class="line"> 0.3232</span><br><span class="line"> 0.7715</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.rand(2, 3)</span><br><span class="line"></span><br><span class="line"> 0.5010  0.5140  0.0719</span><br><span class="line"> 0.1435  0.5636  0.0538</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br></pre></td></tr></table></figure><h3 id="torch-randn"><a href="#torch-randn" class="headerlink" title="torch.randn"></a>torch.randn</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randn(*sizes, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«äº†ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒ(<strong>å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º 1ï¼Œå³é«˜æ–¯ç™½å™ªå£°</strong>)ä¸­æŠ½å–ä¸€ç»„éšæœºæ•°ï¼Œå½¢çŠ¶ç”±å¯å˜å‚æ•°sizeså®šä¹‰ã€‚ </p><p>å‚æ•°:</p><ul><li>sizes (intâ€¦) â€“ æ•´æ•°åºåˆ—ï¼Œå®šä¹‰äº†è¾“å‡ºå½¢çŠ¶</li><li>out (Tensor, optinal) - ç»“æœå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.randn(4)</span><br><span class="line"></span><br><span class="line">-0.1145</span><br><span class="line"> 0.0094</span><br><span class="line">-1.1717</span><br><span class="line"> 0.9846</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.randn(2, 3)</span><br><span class="line"></span><br><span class="line"> 1.4339  0.3351 -1.0999</span><br><span class="line"> 1.5458 -0.9643 -0.3558</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br></pre></td></tr></table></figure><h3 id="torch-randperm"><a href="#torch-randperm" class="headerlink" title="torch.randperm"></a>torch.randperm</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randperm(n, out=None) â†’ LongTensor</span><br></pre></td></tr></table></figure><p>ç»™å®šå‚æ•°nï¼Œè¿”å›ä¸€ä¸ªä»0 åˆ°n -1 (<strong>[0,n-1)</strong>)çš„éšæœºæ•´æ•°æ’åˆ—ã€‚</p><p>å‚æ•°:</p><ul><li>n (int) â€“ ä¸Šè¾¹ç•Œ(ä¸åŒ…å«)</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.randperm(4)</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line"> 1</span><br><span class="line"> 3</span><br><span class="line"> 0</span><br><span class="line">[torch.LongTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-arange"><a href="#torch-arange" class="headerlink" title="torch.arange"></a>torch.arange</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.arange(start, end, step=1, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ª1ç»´å¼ é‡ï¼Œé•¿åº¦ä¸º <strong>floor((endâˆ’start)/step) ï¼ˆå‘ä¸‹å–æ•´ï¼‰</strong>ã€‚<strong>åŒ…å«</strong>(é—­åŒºé—´)ä»startåˆ°endï¼Œä»¥stepä¸ºæ­¥é•¿çš„ä¸€ç»„åºåˆ—å€¼(é»˜è®¤æ­¥é•¿ä¸º1)ã€‚</p><p>å‚æ•°:</p><ul><li>start (float) â€“ åºåˆ—çš„èµ·å§‹ç‚¹</li><li>end (float) â€“ åºåˆ—çš„ç»ˆæ­¢ç‚¹</li><li>step (float) â€“ ç›¸é‚»ç‚¹çš„é—´éš”å¤§å°</li><li>out (Tensor, optional) â€“ ç»“æœå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.arange(1, 4)</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line">[torch.FloatTensor of size 3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.arange(1, 2.5, 0.5)</span><br><span class="line"></span><br><span class="line"> 1.0000</span><br><span class="line"> 1.5000</span><br><span class="line"> 2.0000</span><br><span class="line">[torch.FloatTensor of size 3]</span><br></pre></td></tr></table></figure><h3 id="torch-range-å»ºè®®ä½¿ç”¨-torch-arange"><a href="#torch-range-å»ºè®®ä½¿ç”¨-torch-arange" class="headerlink" title="torch.range() å»ºè®®ä½¿ç”¨  torch.arange()"></a>torch.range() å»ºè®®ä½¿ç”¨  torch.arange()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.range(start, end, step=1, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ª1ç»´å¼ é‡ï¼Œæœ‰ <strong>floor((endâˆ’start)/step)+1</strong> ä¸ªå…ƒç´ ã€‚åŒ…å«åœ¨<strong>åŠå¼€åŒºé—´[start, end</strong>ï¼‰ä»startå¼€å§‹ï¼Œä»¥stepä¸ºæ­¥é•¿çš„ä¸€ç»„å€¼ã€‚ step æ˜¯ä¸¤ä¸ªå€¼ä¹‹é—´çš„é—´éš”ï¼Œå³ $x_{i+1}=x_i+step$</p><p><strong>è­¦å‘Šï¼šå»ºè®®ä½¿ç”¨å‡½æ•° torch.arange()</strong></p><p>å‚æ•°:</p><ul><li>start (float) â€“ åºåˆ—çš„èµ·å§‹ç‚¹</li><li>end (float) â€“ åºåˆ—çš„æœ€ç»ˆå€¼</li><li>step (int) â€“ ç›¸é‚»ç‚¹çš„é—´éš”å¤§å°</li><li>out (Tensor, optional) â€“ ç»“æœå¼ é‡</li></ul><p>ç‰¹ä¾‹ï¼š</p><ul><li>mean=0.0ï¼Œæ‰€æœ‰æŠ½å–çš„æ ·æœ¬å…±äº«å‡å€¼</li><li>std=1.0ï¼Œæ‰€æœ‰æŠ½å–çš„æ ·æœ¬å…±äº«æ ‡å‡†å·®</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.range(1, 4)</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.range(1, 4, 0.5)</span><br><span class="line"></span><br><span class="line"> 1.0000</span><br><span class="line"> 1.5000</span><br><span class="line"> 2.0000</span><br><span class="line"> 2.5000</span><br><span class="line"> 3.0000</span><br><span class="line"> 3.5000</span><br><span class="line"> 4.0000</span><br><span class="line">[torch.FloatTensor of size 7]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchå­¦ä¹ ç¬”è®°(ä¸‰)</title>
      <link href="/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%89)/"/>
      <url>/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%89)/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchå­¦ä¹ ç¬”è®°-ä¸‰"><a href="#PyTorchå­¦ä¹ ç¬”è®°-ä¸‰" class="headerlink" title="PyTorchå­¦ä¹ ç¬”è®°(ä¸‰)"></a>PyTorchå­¦ä¹ ç¬”è®°(ä¸‰)</h1><h2 id="éšæœºæŠ½æ ·-Random-sampling"><a href="#éšæœºæŠ½æ ·-Random-sampling" class="headerlink" title="éšæœºæŠ½æ · Random sampling"></a>éšæœºæŠ½æ · Random sampling</h2><h3 id="torch-manual-seed"><a href="#torch-manual-seed" class="headerlink" title="torch.manual_seed"></a>torch.manual_seed</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(seed)</span><br></pre></td></tr></table></figure><p>è®¾å®šç”Ÿæˆéšæœºæ•°çš„ç§å­ï¼Œå¹¶è¿”å›ä¸€ä¸ª torch._C.Generator å¯¹è±¡</p><p>å‚æ•°: </p><ul><li>seed (int or long) â€“ ç§å­</li></ul><h3 id="torch-initial-seed"><a href="#torch-initial-seed" class="headerlink" title="torch.initial_seed"></a>torch.initial_seed</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.initial_seed()</span><br></pre></td></tr></table></figure><p>è¿”å›ç”Ÿæˆéšæœºæ•°çš„åŸå§‹ç§å­å€¼ï¼ˆpython longï¼‰</p><h3 id="torch-get-rng-state"><a href="#torch-get-rng-state" class="headerlink" title="torch.get_rng_state"></a>torch.get_rng_state</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.get_rng_state</span><br></pre></td></tr></table></figure><p>è¿”å›éšæœºç”Ÿæˆå™¨çŠ¶æ€(ByteTensor)</p><h3 id="torch-set-rng-state"><a href="#torch-set-rng-state" class="headerlink" title="torch.set_rng_state"></a>torch.set_rng_state</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.set_rng_state(new_state)</span><br></pre></td></tr></table></figure><p>è®¾å®šéšæœºç”Ÿæˆå™¨çŠ¶æ€ </p><p>å‚æ•°: </p><ul><li>new_state (torch.ByteTensor) â€“ æœŸæœ›çš„çŠ¶æ€</li></ul><h3 id="torch-torch-bernoulli"><a href="#torch-torch-bernoulli" class="headerlink" title="torch.torch.bernoulli"></a>torch.torch.bernoulli</h3><p>ä»<strong>ä¼¯åŠªåˆ©åˆ†å¸ƒ</strong>ä¸­æŠ½å–äºŒå…ƒéšæœºæ•°(0 æˆ–è€… 1)ã€‚</p><p>è¾“å…¥å¼ é‡é¡»åŒ…å«ç”¨äºæŠ½å–ä¸Šè¿°äºŒå…ƒéšæœºå€¼çš„æ¦‚ç‡ã€‚ å› æ­¤ï¼Œè¾“å…¥ä¸­çš„æ‰€æœ‰å€¼éƒ½å¿…é¡»åœ¨<strong>ï¼»0,1ï¼½</strong>åŒºé—´ï¼Œå³ $0&lt;=input_i&lt;=1$</p><p>è¾“å‡ºå¼ é‡çš„ç¬¬iä¸ªå…ƒç´ å€¼ï¼Œ å°†ä¼šä»¥è¾“å…¥å¼ é‡çš„ç¬¬iä¸ªæ¦‚ç‡å€¼ç­‰äº1ã€‚</p><p>è¿”å›å€¼å°†ä¼šæ˜¯ä¸è¾“å…¥ç›¸åŒå¤§å°çš„å¼ é‡ï¼Œæ¯ä¸ªå€¼ä¸º0æˆ–è€…1ã€‚</p><p>å‚æ•°:</p><ul><li>input (Tensor) â€“ è¾“å…¥ä¸ºä¼¯åŠªåˆ©åˆ†å¸ƒçš„æ¦‚ç‡å€¼</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡(å¯é€‰)</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.Tensor(3, 3).uniform_(0, 1) # generate a uniform random matrix with range [0, 1]</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 0.7544  0.8140  0.9842</span><br><span class="line"> 0.5282  0.0595  0.6445</span><br><span class="line"> 0.1925  0.9553  0.9732</span><br><span class="line">[torch.FloatTensor of size 3x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.bernoulli(a)</span><br><span class="line"></span><br><span class="line"> 1  1  1</span><br><span class="line"> 0  0  1</span><br><span class="line"> 0  1  1</span><br><span class="line">[torch.FloatTensor of size 3x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; a = torch.ones(3, 3) # probability of drawing &quot;1&quot; is 1</span><br><span class="line">&gt;&gt;&gt; torch.bernoulli(a)</span><br><span class="line"></span><br><span class="line"> 1  1  1</span><br><span class="line"> 1  1  1</span><br><span class="line"> 1  1  1</span><br><span class="line">[torch.FloatTensor of size 3x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; a = torch.zeros(3, 3) # probability of drawing &quot;1&quot; is 0</span><br><span class="line">&gt;&gt;&gt; torch.bernoulli(a)</span><br><span class="line"></span><br><span class="line"> 0  0  0</span><br><span class="line"> 0  0  0</span><br><span class="line"> 0  0  0</span><br><span class="line">[torch.FloatTensor of size 3x3]</span><br></pre></td></tr></table></figure><h3 id="torch-multinomial"><a href="#torch-multinomial" class="headerlink" title="torch.multinomial"></a>torch.multinomial</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.multinomial(input, num_samples,replacement=False, out=None) â†’ LongTensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªå¼ é‡ï¼Œæ¯è¡ŒåŒ…å«ä»<code>input</code>ç›¸åº”<code>è¡Œ</code>ä¸­å®šä¹‰çš„å¤šé¡¹åˆ†å¸ƒä¸­æŠ½å–çš„<code>num_samples</code>ä¸ªæ ·æœ¬ã€‚</p><blockquote><p>ä½œç”¨æ˜¯å¯¹inputçš„æ¯ä¸€è¡Œåšn_samplesæ¬¡å–å€¼ï¼Œè¾“å‡ºçš„å¼ é‡æ˜¯æ¯ä¸€æ¬¡å–å€¼æ—¶inputå¼ é‡å¯¹åº”è¡Œçš„ä¸‹æ ‡ã€‚</p></blockquote><p>æ³¨æ„ï¼šè¾“å…¥<code>input</code>æ¯è¡Œçš„å€¼<strong>ä¸éœ€è¦æ€»å’Œä¸º1</strong> (è¿™é‡Œæˆ‘ä»¬ç”¨æ¥åšæƒé‡)ï¼Œä½†æ˜¯<strong>å¿…é¡»éè´Ÿä¸”æ€»å’Œä¸èƒ½ä¸º0</strong>ã€‚</p><p>å½“æŠ½å–æ ·æœ¬æ—¶ï¼Œä¾æ¬¡ä»å·¦åˆ°å³æ’åˆ—(ç¬¬ä¸€ä¸ªæ ·æœ¬å¯¹åº”ç¬¬ä¸€åˆ—)ã€‚</p><p>å¦‚æœè¾“å…¥<code>input</code>æ˜¯ä¸€ä¸ªå‘é‡ï¼Œè¾“å‡ºoutä¹Ÿæ˜¯ä¸€ä¸ªç›¸åŒé•¿åº¦<code>num_samples</code>çš„å‘é‡ã€‚å¦‚æœè¾“å…¥<code>input</code>æ˜¯æœ‰<code>m</code>è¡Œçš„çŸ©é˜µï¼Œè¾“å‡ºoutæ˜¯å½¢å¦‚<code>mÃ—num_samples</code>çš„çŸ©é˜µã€‚</p><p>å¦‚æœå‚æ•°<code>replacement</code> ä¸º<code>True</code>, åˆ™æ ·æœ¬æŠ½å–å¯ä»¥é‡å¤ã€‚å¦åˆ™ï¼Œä¸€ä¸ªæ ·æœ¬åœ¨æ¯è¡Œä¸èƒ½è¢«é‡å¤æŠ½å–ã€‚</p><p>å‚æ•°<code>num_samples</code>å¿…é¡»å°äº<code>input</code>é•¿åº¦(å³ï¼Œ<code>input</code>çš„åˆ—æ•°ï¼Œå¦‚æœæ˜¯inputæ˜¯ä¸€ä¸ªçŸ©é˜µ)ã€‚</p><p>å‚æ•°:</p><ul><li>input (Tensor) â€“ åŒ…å«æ¦‚ç‡å€¼çš„å¼ é‡</li><li>num_samples (int) â€“ æŠ½å–çš„æ ·æœ¬æ•°</li><li>replacement (bool, optional) â€“ å¸ƒå°”å€¼ï¼Œå†³å®šæ˜¯å¦èƒ½é‡å¤æŠ½å–</li><li>out (Tensor, optional) â€“ ç»“æœå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; weights = torch.Tensor([0, 10, 3, 0]) # create a Tensor of weights</span><br><span class="line">&gt;&gt;&gt; torch.multinomial(weights, 4, replacement=True)</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line">[torch.LongTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; weights = torch.rand(3, 4)</span><br><span class="line">tensor([[0.9005, 0.8463, 0.6070, 0.4762],</span><br><span class="line">        [0.6458, 0.0261, 0.7618, 0.7244],</span><br><span class="line">        [0.5225, 0.9317, 0.8163, 0.2554]])</span><br><span class="line">&gt;&gt;&gt; torch.multinomial(weights, 2)</span><br><span class="line">tensor([[0, 1],</span><br><span class="line">        [2, 3],</span><br><span class="line">        [3, 0]])</span><br></pre></td></tr></table></figure><blockquote><p>è¾“å…¥æ˜¯[0,10,3,0]ï¼Œä¹Ÿå°±æ˜¯è¯´ç¬¬0ä¸ªå…ƒç´ å’Œç¬¬3ä¸ªå…ƒç´ æƒé‡éƒ½æ˜¯0ï¼Œåœ¨å…¶ä»–å…ƒç´ è¢«å–å®Œä¹‹å‰æ˜¯ä¸ä¼šè¢«å–åˆ°çš„ã€‚</p></blockquote><h3 id="torch-normal"><a href="#torch-normal" class="headerlink" title="torch.normal()"></a>torch.normal()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.normal(means, std, out=None)</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«ä»ç»™å®šå‚æ•°<code>means</code>,stdçš„<strong>ç¦»æ•£æ­£æ€åˆ†å¸ƒ</strong>ä¸­æŠ½å–éšæœºæ•°ã€‚ <code>å‡å€¼means</code>æ˜¯ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«æ¯ä¸ªè¾“å‡ºå…ƒç´ ç›¸å…³çš„æ­£æ€åˆ†å¸ƒçš„å‡å€¼ã€‚ <code>std</code>æ˜¯ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«æ¯ä¸ªè¾“å‡ºå…ƒç´ ç›¸å…³çš„æ­£æ€åˆ†å¸ƒçš„<strong>æ ‡å‡†å·®</strong>ã€‚ å‡å€¼å’Œæ ‡å‡†å·®çš„å½¢çŠ¶ä¸é¡»åŒ¹é…ï¼Œä½†æ¯ä¸ªå¼ é‡çš„<strong>å…ƒç´ ä¸ªæ•°é¡»ç›¸åŒ</strong>ã€‚</p><p>å‚æ•°:</p><ul><li>means (Tensor) â€“ å‡å€¼</li><li>std (Tensor) â€“ æ ‡å‡†å·®</li><li>out (Tensor) â€“ å¯é€‰çš„è¾“å‡ºå¼ é‡</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">torch.normal(means=torch.arange(1, 11), std=torch.arange(1, 0, -0.1))</span><br><span class="line"></span><br><span class="line"> 1.5104</span><br><span class="line"> 1.6955</span><br><span class="line"> 2.4895</span><br><span class="line"> 4.9185</span><br><span class="line"> 4.9895</span><br><span class="line"> 6.9155</span><br><span class="line"> 7.3683</span><br><span class="line"> 8.1836</span><br><span class="line"> 8.7164</span><br><span class="line"> 9.8916</span><br><span class="line">[torch.FloatTensor of size 10]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchå­¦ä¹ ç¬”è®°(äºŒ)</title>
      <link href="/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%BA%8C)/"/>
      <url>/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%BA%8C)/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchå­¦ä¹ ç¬”è®°-äºŒ"><a href="#PyTorchå­¦ä¹ ç¬”è®°-äºŒ" class="headerlink" title="PyTorchå­¦ä¹ ç¬”è®°(äºŒ)"></a>PyTorchå­¦ä¹ ç¬”è®°(äºŒ)</h1><blockquote><p>dimensionï¼š0è¡Œ 1åˆ—</p></blockquote><h2 id="å¼ é‡æ“ä½œ"><a href="#å¼ é‡æ“ä½œ" class="headerlink" title="å¼ é‡æ“ä½œ"></a>å¼ é‡æ“ä½œ</h2><h3 id="torch-cat"><a href="#torch-cat" class="headerlink" title="torch.cat"></a>torch.cat</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(inputs, dimension=0) â†’ Tensor</span><br></pre></td></tr></table></figure><p>åœ¨ç»™å®šç»´åº¦ä¸Šå¯¹è¾“å…¥çš„å¼ é‡åºåˆ—<code>seq</code>è¿›è¡Œè¿æ¥æ“ä½œã€‚</p><p>torch.cat()å¯ä»¥çœ‹åš <code>torch.split()</code> å’Œ <code>torch.chunk()</code>çš„åæ“ä½œã€‚ <code>cat()</code> å‡½æ•°å¯ä»¥é€šè¿‡ä¸‹é¢ä¾‹å­æ›´å¥½çš„ç†è§£ã€‚</p><p>å‚æ•°:</p><ul><li>inputs (sequence of Tensors) â€“ å¯ä»¥æ˜¯ä»»æ„<strong>ç›¸åŒ</strong>Tensor ç±»å‹çš„python åºåˆ—ã€‚</li><li>dimension (int, optional) â€“ æ²¿ç€æ­¤ç»´è¿æ¥å¼ é‡åºåˆ—ã€‚</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.randn(2, 3)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line"></span><br><span class="line"> 0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.cat((x, x, x), 0)</span><br><span class="line"></span><br><span class="line"> 0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735</span><br><span class="line"> 0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735</span><br><span class="line"> 0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735</span><br><span class="line">[torch.FloatTensor of size 6x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.cat((x, x, x), 1)</span><br><span class="line"></span><br><span class="line"> 0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735</span><br><span class="line">[torch.FloatTensor of size 2x9]</span><br></pre></td></tr></table></figure><h3 id="torch-chunk"><a href="#torch-chunk" class="headerlink" title="torch.chunk"></a>torch.chunk</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.chunk(tensor, chunks, dim=0)</span><br></pre></td></tr></table></figure><p>åœ¨ç»™å®šç»´åº¦(è½´)ä¸Šå°†è¾“å…¥å¼ é‡è¿›è¡Œåˆ†å—å„¿ã€‚</p><p>å‚æ•°:</p><ul><li>tensor (Tensor) â€“ å¾…åˆ†å—çš„è¾“å…¥å¼ é‡</li><li>chunks (int) â€“ åˆ†å—çš„ä¸ªæ•°</li><li>dim (int) â€“ æ²¿ç€æ­¤ç»´åº¦è¿›è¡Œåˆ†å—</li></ul><h3 id="torch-gather"><a href="#torch-gather" class="headerlink" title="torch.gather"></a>torch.gather</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.gather(input, dim, index, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>æ²¿ç»™å®šè½´<code>dim</code>ï¼Œå°†è¾“å…¥ç´¢å¼•å¼ é‡<code>index</code>æŒ‡å®šä½ç½®çš„å€¼è¿›è¡Œèšåˆã€‚</p><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ æºå¼ é‡</li><li>dim (int) â€“ ç´¢å¼•çš„è½´</li><li>index (LongTensor) â€“ èšåˆå…ƒç´ çš„ä¸‹æ ‡</li><li>out (Tensor, optional) â€“ ç›®æ ‡å¼ é‡</li></ul><p>å¯¹ä¸€ä¸ª3ç»´å¼ é‡ï¼Œè¾“å‡ºå¯ä»¥å®šä¹‰ä¸ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">out[i][j][k] = tensor[index[i][j][k]][j][k]  # dim=0</span><br><span class="line">out[i][j][k] = tensor[i][index[i][j][k]][k]  # dim=1</span><br><span class="line">out[i][j][k] = tensor[i][j][index[i][j][k]]  # dim=3</span><br></pre></td></tr></table></figure><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t = torch.Tensor([[1,2],[3,4]])</span><br><span class="line"> 1  2</span><br><span class="line"> 3  4</span><br><span class="line">&gt;&gt;&gt; torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]]))</span><br><span class="line"> 1  1</span><br><span class="line"> 4  3</span><br><span class="line">[torch.FloatTensor of size 2x2]</span><br></pre></td></tr></table></figure><blockquote><p>dim=1</p><p>i=0,j=0</p><p>out[0][0]=input[0,index[0][0]]=input[0,0]=1</p><p>i=0,j=1</p><p>out[0][1]=input[0,index[0][1]]=input[0,0]]=1</p><p>i=1,j=0</p><p>out[1][0]=input[1,index[1][0]]=input[1,1]]=4</p><p>i=1,j=1</p><p>out[1][1]=input[1,index[1][1]]=input[1,0]]=3</p></blockquote><h3 id="torch-index-select"><a href="#torch-index-select" class="headerlink" title="torch.index_select"></a>torch.index_select</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.index_select(input, dim, index, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>æ²¿ç€æŒ‡å®šç»´åº¦å¯¹è¾“å…¥è¿›è¡Œåˆ‡ç‰‡ï¼Œå–<code>index</code>ä¸­æŒ‡å®šçš„ç›¸åº”é¡¹(indexä¸ºä¸€ä¸ªLongTensor)ï¼Œç„¶åè¿”å›åˆ°ä¸€ä¸ªæ–°çš„å¼ é‡ï¼Œ è¿”å›çš„å¼ é‡ä¸åŸå§‹å¼ é‡<em>Tensor</em>æœ‰ç›¸åŒçš„ç»´åº¦(åœ¨æŒ‡å®šè½´ä¸Š)ã€‚</p><p>æ³¨æ„ï¼š è¿”å›çš„å¼ é‡<strong>ä¸ä¸åŸå§‹å¼ é‡å…±äº«å†…å­˜ç©ºé—´</strong>ã€‚</p><p>å‚æ•°:</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>dim (int) â€“ ç´¢å¼•çš„è½´</li><li>index (LongTensor) â€“ åŒ…å«ç´¢å¼•ä¸‹æ ‡çš„ä¸€ç»´å¼ é‡</li><li>out (Tensor, optional) â€“ ç›®æ ‡å¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><figcaption><span>x </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x</span><br><span class="line"></span><br><span class="line"> 1.2045  2.4084  0.4001  1.1372</span><br><span class="line"> 0.5596  1.5677  0.6219 -0.7954</span><br><span class="line"> 1.3635 -1.2313 -0.5414 -1.8478</span><br><span class="line">[torch.FloatTensor of size 3x4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; indices = torch.LongTensor([0, 2])</span><br><span class="line">&gt;&gt;&gt; torch.index_select(x, 0, indices)</span><br><span class="line"></span><br><span class="line"> 1.2045  2.4084  0.4001  1.1372</span><br><span class="line"> 1.3635 -1.2313 -0.5414 -1.8478</span><br><span class="line">[torch.FloatTensor of size 2x4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.index_select(x, 1, indices)</span><br><span class="line"></span><br><span class="line"> 1.2045  0.4001</span><br><span class="line"> 0.5596  0.6219</span><br><span class="line"> 1.3635 -0.5414</span><br><span class="line">[torch.FloatTensor of size 3x2]</span><br></pre></td></tr></table></figure><blockquote><p>dim=0,[0,2]ï¼šå–ç¬¬0å’Œç¬¬1è¡Œã€‚</p><p>dim=1,[0,2]ï¼šå–ç¬¬0å’Œç¬¬1åˆ—ã€‚</p></blockquote><h3 id="torch-masked-select"><a href="#torch-masked-select" class="headerlink" title="torch.masked_select"></a>torch.masked_select</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.masked_select(input, mask, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>æ ¹æ®æ©ç å¼ é‡maskä¸­çš„äºŒå…ƒå€¼ï¼Œå–è¾“å…¥å¼ é‡ä¸­çš„æŒ‡å®šé¡¹(maskä¸ºä¸€ä¸ª ByteTensor)ï¼Œå°†å–å€¼è¿”å›åˆ°ä¸€ä¸ªæ–°çš„1Då¼ é‡ï¼Œå¼ é‡maské¡»è·Ÿinputå¼ é‡æœ‰<strong>ç›¸åŒæ•°é‡çš„å…ƒç´ æ•°ç›®</strong>ï¼Œä½†å½¢çŠ¶æˆ–ç»´åº¦ä¸éœ€è¦ç›¸åŒã€‚ </p><p>æ³¨æ„ï¼š è¿”å›çš„å¼ é‡<strong>ä¸ä¸åŸå§‹å¼ é‡å…±äº«å†…å­˜ç©ºé—´</strong>ã€‚</p><p>å‚æ•°:</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>mask (ByteTensor) â€“ æ©ç å¼ é‡ï¼ŒåŒ…å«äº†äºŒå…ƒç´¢å¼•å€¼</li><li>out (Tensor, optional) â€“ ç›®æ ‡å¼ é‡</li></ul><h3 id="torch-nonzero"><a href="#torch-nonzero" class="headerlink" title="torch.nonzero"></a>torch.nonzero</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nonzero(input, out=None) â†’ LongTensor</span><br></pre></td></tr></table></figure><p>è¿”å›è¾“å…¥å¼ é‡ä¸­çš„éé›¶å…ƒç´ çš„ç´¢å¼•ã€‚</p><p>å¦‚æœè¾“å…¥<code>input</code>æœ‰<code>n</code>ç»´ï¼Œåˆ™è¾“å‡ºçš„ç´¢å¼•å¼ é‡outputçš„å½¢çŠ¶ä¸º <code>z x n</code>, è¿™é‡Œ <code>z</code> æ˜¯è¾“å…¥å¼ é‡inputä¸­æ‰€æœ‰éé›¶å…ƒç´ çš„ä¸ªæ•°ã€‚</p><p>å‚æ•°:</p><ul><li>input (Tensor) â€“ æºå¼ é‡</li><li>out (LongTensor, optional) â€“ åŒ…å«ç´¢å¼•å€¼çš„ç»“æœå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.nonzero(torch.Tensor([1, 1, 1, 0, 1]))</span><br><span class="line"></span><br><span class="line"> 0</span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 4</span><br><span class="line">[torch.LongTensor of size 4x1]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.nonzero(torch.Tensor([[0.6, 0.0, 0.0, 0.0],</span><br><span class="line">...                             [0.0, 0.4, 0.0, 0.0],</span><br><span class="line">...                             [0.0, 0.0, 1.2, 0.0],</span><br><span class="line">...                             [0.0, 0.0, 0.0,-0.4]]))</span><br><span class="line"></span><br><span class="line"> 0  0</span><br><span class="line"> 1  1</span><br><span class="line"> 2  2</span><br><span class="line"> 3  3</span><br><span class="line">[torch.LongTensor of size 4x2]</span><br></pre></td></tr></table></figure><h3 id="torch-split"><a href="#torch-split" class="headerlink" title="torch.split"></a>torch.split</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.split(tensor, split_size, dim=0)</span><br></pre></td></tr></table></figure><p>å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆç›¸ç­‰å½¢çŠ¶çš„chunksï¼ˆå¦‚æœå¯åˆ†ï¼‰ã€‚ å¦‚æœæ²¿æŒ‡å®šç»´çš„å¼ é‡å½¢çŠ¶å¤§å°ä¸èƒ½è¢«<code>split_size</code> æ•´åˆ†ï¼Œ åˆ™æœ€åä¸€ä¸ªåˆ†å—ä¼šå°äºå…¶å®ƒåˆ†å—ã€‚</p><p>å‚æ•°:</p><ul><li>tensor (Tensor) â€“ å¾…åˆ†å‰²å¼ é‡</li><li>split_size (int) â€“ å•ä¸ªåˆ†å—çš„å½¢çŠ¶å¤§å°</li><li>dim (int) â€“ æ²¿ç€æ­¤ç»´è¿›è¡Œåˆ†å‰²</li></ul><h3 id="torch-squeeze"><a href="#torch-squeeze" class="headerlink" title="torch.squeeze"></a>torch.squeeze</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.squeeze(input, dim=None, out=None)</span><br></pre></td></tr></table></figure><p>è¾“å…¥å¼ é‡å½¢çŠ¶ä¸­çš„<code>1</code>å»é™¤å¹¶è¿”å›ã€‚ å¦‚æœè¾“å…¥æ˜¯å½¢å¦‚<code>(AÃ—1Ã—BÃ—1Ã—CÃ—1Ã—D)</code>ï¼Œé‚£ä¹ˆè¾“å‡ºå½¢çŠ¶å°±ä¸º:<code>(AÃ—BÃ—CÃ—D)</code><br>å½“ç»™å®š<code>dim</code>æ—¶ï¼Œé‚£ä¹ˆæŒ¤å‹æ“ä½œåªåœ¨ç»™å®šç»´åº¦ä¸Šã€‚ä¾‹å¦‚ï¼Œè¾“å…¥å½¢çŠ¶ä¸º: <code>(AÃ—1Ã—B), squeeze(input, 0)</code> å°†ä¼šä¿æŒå¼ é‡ä¸å˜ï¼Œåªæœ‰ç”¨ <code>squeeze(input, 1)</code>ï¼Œå½¢çŠ¶ä¼šå˜æˆ <code>(AÃ—B)</code>ã€‚</p><p>æ³¨æ„ï¼š è¿”å›å¼ é‡ä¸è¾“å…¥å¼ é‡<strong>å…±äº«å†…å­˜</strong>ï¼Œæ‰€ä»¥æ”¹å˜å…¶ä¸­ä¸€ä¸ªçš„å†…å®¹ä¼šæ”¹å˜å¦ä¸€ä¸ªã€‚</p><p>å‚æ•°:</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>dim (int, optional) â€“ å¦‚æœç»™å®šï¼Œåˆ™inputåªä¼šåœ¨ç»™å®šç»´åº¦æŒ¤å‹ï¼Œè‹¥ä¸ç»™å®šï¼Œåœ¨æ‰€æœ‰ç»´åº¦æŒ¤å‹ã€‚</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.zeros(2,1,2,1,2)</span><br><span class="line">&gt;&gt;&gt; x.size()</span><br><span class="line">(2L, 1L, 2L, 1L, 2L)</span><br><span class="line">&gt;&gt;&gt; y = torch.squeeze(x)</span><br><span class="line">&gt;&gt;&gt; y.size()</span><br><span class="line">(2L, 2L, 2L)</span><br><span class="line">&gt;&gt;&gt; y = torch.squeeze(x, 0)</span><br><span class="line">&gt;&gt;&gt; y.size()</span><br><span class="line">(2L, 1L, 2L, 1L, 2L)</span><br><span class="line">&gt;&gt;&gt; y = torch.squeeze(x, 1)</span><br><span class="line">&gt;&gt;&gt; y.size()</span><br><span class="line">(2L, 2L, 1L, 2L)</span><br></pre></td></tr></table></figure><h3 id="torch-stack"><a href="#torch-stack" class="headerlink" title="torch.stack"></a>torch.stack</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.stack(sequence, dim=0)</span><br></pre></td></tr></table></figure><p>æ²¿ç€ä¸€ä¸ªæ–°ç»´åº¦å¯¹è¾“å…¥å¼ é‡åºåˆ—è¿›è¡Œè¿æ¥ã€‚ åºåˆ—ä¸­æ‰€æœ‰çš„å¼ é‡éƒ½åº”è¯¥ä¸ºç›¸åŒå½¢çŠ¶ã€‚</p><p>å‚æ•°:</p><ul><li>sqequence (Sequence) â€“ å¾…è¿æ¥çš„å¼ é‡åºåˆ—</li><li>dim (int) â€“ æ’å…¥çš„ç»´åº¦ã€‚å¿…é¡»ä»‹äº0ä¸å¾…è¿æ¥çš„å¼ é‡åºåˆ—æ•°ä¹‹é—´ã€‚</li></ul><h3 id="torch-t"><a href="#torch-t" class="headerlink" title="torch.t"></a>torch.t</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.t(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¾“å…¥ä¸€ä¸ªçŸ©é˜µï¼ˆ<strong>2ç»´å¼ é‡</strong>ï¼‰ï¼Œå¹¶è½¬ç½®0, 1ç»´ã€‚ å¯ä»¥è¢«è§†ä¸ºå‡½æ•°<code>transpose(input, 0, 1)</code>çš„ç®€å†™å‡½æ•°ã€‚</p><p>å‚æ•°:</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>out (Tensor, optional) â€“ ç»“æœå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.randn(2, 3)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line"></span><br><span class="line"> 0.4834  0.6907  1.3417</span><br><span class="line">-0.1300  0.5295  0.2321</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.t(x)</span><br><span class="line"></span><br><span class="line"> 0.4834 -0.1300</span><br><span class="line"> 0.6907  0.5295</span><br><span class="line"> 1.3417  0.2321</span><br><span class="line">[torch.FloatTensor of size 3x2]</span><br></pre></td></tr></table></figure><h3 id="torch-transpose"><a href="#torch-transpose" class="headerlink" title="torch.transpose"></a>torch.transpose</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.transpose(input, dim0, dim1, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›è¾“å…¥çŸ©é˜µ<code>input</code>çš„è½¬ç½®ã€‚äº¤æ¢ç»´åº¦<code>dim0</code>å’Œdim1ã€‚ è¾“å‡ºå¼ é‡ä¸è¾“å…¥å¼ é‡<strong>å…±äº«å†…å­˜</strong>ï¼Œæ‰€ä»¥æ”¹å˜å…¶ä¸­ä¸€ä¸ªä¼šå¯¼è‡´å¦å¤–ä¸€ä¸ªä¹Ÿè¢«ä¿®æ”¹ã€‚</p><p>å‚æ•°:</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>dim0 (int) â€“ è½¬ç½®çš„ç¬¬ä¸€ç»´</li><li>dim1 (int) â€“ è½¬ç½®çš„ç¬¬äºŒç»´</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.randn(2, 3)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line"></span><br><span class="line"> 0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.transpose(x, 0, 1)</span><br><span class="line"></span><br><span class="line"> 0.5983  1.5981</span><br><span class="line">-0.0341 -0.5265</span><br><span class="line"> 2.4918 -0.8735</span><br><span class="line">[torch.FloatTensor of size 3x2]</span><br></pre></td></tr></table></figure><h3 id="torch-unbind"><a href="#torch-unbind" class="headerlink" title="torch.unbind"></a>torch.unbind</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unbind(tensor, dim=0)</span><br></pre></td></tr></table></figure><p>ç§»é™¤æŒ‡å®šç»´åï¼Œè¿”å›ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«äº†æ²¿ç€æŒ‡å®šç»´åˆ‡ç‰‡åçš„å„ä¸ªåˆ‡ç‰‡ã€‚</p><p>å‚æ•°:</p><ul><li>tensor (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>dim (int) â€“ åˆ é™¤çš„ç»´åº¦</li></ul><h3 id="torch-unsqueeze"><a href="#torch-unsqueeze" class="headerlink" title="torch.unsqueeze"></a>torch.unsqueeze</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unsqueeze(input, dim, out=None)</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°çš„å¼ é‡ï¼Œå¯¹è¾“å…¥çš„åˆ¶å®šä½ç½®<strong>æ’å…¥ç»´åº¦ 1</strong>ã€‚</p><p>æ³¨æ„ï¼š è¿”å›å¼ é‡ä¸è¾“å…¥å¼ é‡<strong>å…±äº«å†…å­˜</strong>ï¼Œæ‰€ä»¥æ”¹å˜å…¶ä¸­ä¸€ä¸ªçš„å†…å®¹ä¼šæ”¹å˜å¦ä¸€ä¸ªã€‚</p><p>å¦‚æœ<strong>dimä¸ºè´Ÿ</strong>ï¼Œåˆ™å°†ä¼šè¢«è½¬åŒ–<strong>dim+input.dim()+1</strong><br>å‚æ•°:</p><ul><li>tensor (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>dim (int) â€“ æ’å…¥ç»´åº¦çš„ç´¢å¼•</li><li>out (Tensor, optional) â€“ ç»“æœå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.Tensor([1, 2, 3, 4])</span><br><span class="line">&gt;&gt;&gt; torch.unsqueeze(x, 0)</span><br><span class="line"> 1  2  3  4</span><br><span class="line">[torch.FloatTensor of size 1x4]</span><br><span class="line">&gt;&gt;&gt; torch.unsqueeze(x, 1)</span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[torch.FloatTensor of size 4x1]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchå­¦ä¹ ç¬”è®°(å››)</title>
      <link href="/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E5%9B%9B)/"/>
      <url>/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E5%9B%9B)/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorchå­¦ä¹ ç¬”è®°-å››"><a href="#PyTorchå­¦ä¹ ç¬”è®°-å››" class="headerlink" title="PyTorchå­¦ä¹ ç¬”è®°(å››)"></a>PyTorchå­¦ä¹ ç¬”è®°(å››)</h1><h2 id="æ•°å­¦æ“ä½œMath-operations"><a href="#æ•°å­¦æ“ä½œMath-operations" class="headerlink" title="æ•°å­¦æ“ä½œMath operations"></a>æ•°å­¦æ“ä½œMath operations</h2><h3 id="torch-abs"><a href="#torch-abs" class="headerlink" title="torch.abs"></a>torch.abs</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.abs(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è®¡ç®—è¾“å…¥å¼ é‡çš„æ¯ä¸ªå…ƒç´ ç»å¯¹å€¼ã€‚</p><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.abs(torch.FloatTensor([-1, -2, 3]))</span><br><span class="line">FloatTensor([1, 2, 3])</span><br></pre></td></tr></table></figure><h3 id="torch-add"><a href="#torch-add" class="headerlink" title="torch.add()"></a>torch.add()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.add(input, value, out=None)</span><br></pre></td></tr></table></figure><p>å¯¹è¾“å…¥å¼ é‡<code>input</code>é€å…ƒç´ åŠ ä¸Šæ ‡é‡å€¼valueï¼Œå¹¶è¿”å›ç»“æœåˆ°ä¸€ä¸ªæ–°çš„å¼ é‡outï¼Œå³ $out=tensor+value$ã€‚</p><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>value (Number) â€“ æ·»åŠ åˆ°è¾“å…¥æ¯ä¸ªå…ƒç´ çš„æ•°</li><li>out (Tensor, optional) â€“ ç»“æœå¼ é‡</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.add(input, value=1, other, out=None)</span><br></pre></td></tr></table></figure><p><code>other</code>å¼ é‡çš„æ¯ä¸ªå…ƒç´ ä¹˜ä»¥ä¸€ä¸ªæ ‡é‡å€¼<code>value</code>ï¼Œå¹¶åŠ åˆ°<code>input</code> å¼ é‡ä¸Šã€‚è¿”å›ç»“æœåˆ°è¾“å‡ºå¼ é‡<code>out</code>ã€‚å³ï¼Œ$out=input+(otherâˆ—value)$</p><p>ä¸¤ä¸ªå¼ é‡ <code>input and other</code>çš„å°ºå¯¸<strong>ä¸éœ€è¦åŒ¹é…</strong>ï¼Œä½†å…ƒç´ æ€»æ•°å¿…é¡»ä¸€æ ·ã€‚</p><p>æ³¨æ„ :å½“ä¸¤ä¸ªå¼ é‡å½¢çŠ¶ä¸åŒ¹é…æ—¶ï¼Œè¾“å…¥å¼ é‡çš„å½¢çŠ¶ä¼šä½œä¸ºè¾“å‡ºå¼ é‡çš„å°ºå¯¸ã€‚</p><p>å‚æ•°:</p><ul><li>input (Tensor) â€“ ç¬¬ä¸€ä¸ªè¾“å…¥å¼ é‡</li><li>value (Number) â€“ ç”¨äºç¬¬äºŒä¸ªå¼ é‡çš„å°ºå¯¸å› å­</li><li>other (Tensor) â€“ ç¬¬äºŒä¸ªè¾“å…¥å¼ é‡</li><li>out (Tensor, optional) â€“ ç»“æœå¼ é‡</li></ul><h3 id="torch-addcdiv"><a href="#torch-addcdiv" class="headerlink" title="torch.addcdiv"></a>torch.addcdiv</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>ç”¨<code>tensor2</code>å¯¹<code>tensor1</code>é€å…ƒç´ ç›¸é™¤ï¼Œç„¶åä¹˜ä»¥æ ‡é‡å€¼<code>value</code> å¹¶åŠ åˆ°tensorã€‚å³ï¼Œ$out=t1/t2*value+t$</p><p>å¼ é‡çš„<strong>å½¢çŠ¶ä¸éœ€è¦åŒ¹é…</strong>ï¼Œä½†å…ƒç´ æ•°é‡å¿…é¡»ä¸€è‡´ã€‚</p><p>å¦‚æœè¾“å…¥æ˜¯FloatTensor or DoubleTensorç±»å‹ï¼Œåˆ™<code>value</code>å¿…é¡»ä¸ºå®æ•°ï¼Œå¦åˆ™é¡»ä¸ºæ•´æ•°ã€‚</p><p>å‚æ•°ï¼š</p><ul><li>tensor (Tensor) â€“ å¼ é‡ï¼Œè¾“å‡º</li><li>value (Number, optional) â€“ æ ‡é‡ï¼Œå¯¹ tensor1 ./ tensor2 è¿›è¡Œç›¸ä¹˜</li><li>tensor1 (Tensor) â€“ å¼ é‡ï¼Œä½œä¸ºè¢«é™¤æ•°(åˆ†å­)</li><li>tensor2 (Tensor) â€“å¼ é‡ï¼Œä½œä¸ºé™¤æ•°(åˆ†æ¯)</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t = torch.randn(1, 6)</span><br><span class="line">&gt;&gt;&gt; t1 = torch.randn(1, 6)</span><br><span class="line">&gt;&gt;&gt; t2 = torch.randn(6, 1)</span><br><span class="line">&gt;&gt;&gt; torch.addcdiv(t, 0.1, t1, t2)</span><br><span class="line"></span><br><span class="line"> 0.0122 -0.0188 -0.2354</span><br><span class="line"> 0.7396 -1.5721  1.2878</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br></pre></td></tr></table></figure><h3 id="torch-addcmul"><a href="#torch-addcmul" class="headerlink" title="torch.addcmul"></a>torch.addcmul</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.addcmul(tensor, value=1, tensor1, tensor2, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>ç”¨<code>tensor2</code>å¯¹<code>tensor1</code>é€å…ƒç´ ç›¸ä¹˜ï¼Œå¹¶å¯¹ç»“æœä¹˜ä»¥æ ‡é‡å€¼<code>value</code>ç„¶ååŠ åˆ°tensorã€‚ å¼ é‡çš„å½¢çŠ¶ä¸éœ€è¦åŒ¹é…ï¼Œä½†å…ƒç´ æ•°é‡å¿…é¡»ä¸€è‡´ã€‚ </p><p>å¦‚æœè¾“å…¥æ˜¯FloatTensor or DoubleTensorç±»å‹ï¼Œåˆ™<code>value</code>å¿…é¡»ä¸ºå®æ•°ï¼Œå¦åˆ™é¡»ä¸ºæ•´æ•°ã€‚</p><p>å‚æ•°ï¼š</p><ul><li>tensor (Tensor) â€“ å¼ é‡ï¼Œè¾“å‡º</li><li>value (Number, optional) â€“ æ ‡é‡ï¼Œå¯¹ tensor1 . tensor2 è¿›è¡Œç›¸ä¹˜</li><li>tensor1 (Tensor) â€“ å¼ é‡ï¼Œä½œä¸ºä¹˜å­1</li><li>tensor2 (Tensor) â€“å¼ é‡ï¼Œä½œä¸ºä¹˜å­2</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><h3 id="torch-mul"><a href="#torch-mul" class="headerlink" title="torch.mul"></a>torch.mul</h3><ol><li>æ ‡é‡</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.mul(input, value, out=None)</span><br></pre></td></tr></table></figure><p>ç”¨<strong>æ ‡é‡å€¼value</strong>ä¹˜ä»¥è¾“å…¥<code>input</code>çš„æ¯ä¸ªå…ƒç´ ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ–°çš„ç»“æœå¼ é‡ã€‚ $out=tensorâˆ—value$</p><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>value (Number) â€“ ä¹˜åˆ°æ¯ä¸ªå…ƒç´ çš„æ•°</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.9374</span><br><span class="line">-0.5254</span><br><span class="line">-0.6069</span><br><span class="line">[torch.FloatTensor of size 3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.mul(a, 100)</span><br><span class="line"></span><br><span class="line">-93.7411</span><br><span class="line">-52.5374</span><br><span class="line">-60.6908</span><br><span class="line">[torch.FloatTensor of size 3]</span><br></pre></td></tr></table></figure><ol><li>å¼ é‡</li></ol><ul><li>å¯¹åº”å…ƒç´ ç›¸ä¹˜</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.mul(input, other, out=None)</span><br></pre></td></tr></table></figure><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4,4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.7280  0.0598 -1.4327 -0.5825</span><br><span class="line">-0.1427 -0.0690  0.0821 -0.3270</span><br><span class="line">-0.9241  0.5110  0.4070 -1.1188</span><br><span class="line">-0.8308  0.7426 -0.6240 -1.1582</span><br><span class="line">[torch.FloatTensor of size 4x4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; b = torch.randn(2, 8)</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line"></span><br><span class="line"> 0.0430 -1.0775  0.6015  1.1647 -0.6549  0.0308 -0.1670  1.0742</span><br><span class="line">-1.2593  0.0292 -0.0849  0.4530  1.2404 -0.4659 -0.1840  0.5974</span><br><span class="line">[torch.FloatTensor of size 2x8]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.mul(a, b)</span><br><span class="line"></span><br><span class="line">-0.0313 -0.0645 -0.8618 -0.6784</span><br><span class="line"> 0.0934 -0.0021 -0.0137 -0.3513</span><br><span class="line"> 1.1638  0.0149 -0.0346 -0.5068</span><br><span class="line">-1.0304 -0.3460  0.1148 -0.6919</span><br><span class="line">[torch.FloatTensor of size 4x4]</span><br></pre></td></tr></table></figure><h3 id="torch-div"><a href="#torch-div" class="headerlink" title="torch.div()"></a>torch.div()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.div(input, value, out=None)</span><br></pre></td></tr></table></figure><p>å°†<code>input</code>é€å…ƒç´ é™¤ä»¥æ ‡é‡å€¼valueï¼Œå¹¶è¿”å›ç»“æœåˆ°è¾“å‡ºå¼ é‡<code>out</code>ã€‚ å³ $out=tensor/value$</p><h3 id="torch-sqrt"><a href="#torch-sqrt" class="headerlink" title="torch.sqrt"></a>torch.sqrt</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sqrt(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„å¹³æ–¹æ ¹ã€‚</p><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 1.2290</span><br><span class="line"> 1.3409</span><br><span class="line">-0.5662</span><br><span class="line">-0.0899</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.sqrt(a)</span><br><span class="line"></span><br><span class="line"> 1.1086</span><br><span class="line"> 1.1580</span><br><span class="line">    nan</span><br><span class="line">    nan</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-neg"><a href="#torch-neg" class="headerlink" title="torch.neg"></a>torch.neg</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.neg(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥input å¼ é‡æŒ‰å…ƒç´ å–è´Ÿã€‚ å³ï¼Œ $out=âˆ’1âˆ—input$<br>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(5)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.4430</span><br><span class="line"> 1.1690</span><br><span class="line">-0.8836</span><br><span class="line">-0.4565</span><br><span class="line"> 0.2968</span><br><span class="line">[torch.FloatTensor of size 5]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.neg(a)</span><br><span class="line"></span><br><span class="line"> 0.4430</span><br><span class="line">-1.1690</span><br><span class="line"> 0.8836</span><br><span class="line"> 0.4565</span><br><span class="line">-0.2968</span><br><span class="line">[torch.FloatTensor of size 5]</span><br></pre></td></tr></table></figure><h3 id="torch-pow"><a href="#torch-pow" class="headerlink" title="torch.pow"></a>torch.pow</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.pow(input, exponent, out=None)</span><br></pre></td></tr></table></figure><p>å¯¹è¾“å…¥<code>input</code>çš„æŒ‰å…ƒç´ æ±‚<code>exponent</code>æ¬¡å¹‚å€¼ï¼Œå¹¶è¿”å›ç»“æœå¼ é‡ã€‚ å¹‚å€¼<code>exponent</code> å¯ä»¥ä¸ºå•ä¸€ <code>float</code> æ•°æˆ–è€…ä¸<code>input</code><strong>ç›¸åŒå…ƒç´ æ•°</strong>çš„å¼ é‡ã€‚</p><ul><li>å½“å¹‚å€¼ä¸ºæ ‡é‡æ—¶ï¼Œæ‰§è¡Œæ“ä½œï¼š<br>$out_i=x^{exponent}$</li><li>å½“å¹‚å€¼ä¸ºå¼ é‡æ—¶ï¼Œæ‰§è¡Œæ“ä½œï¼š<br>$out_i=x^{exponent_i}$</li></ul><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>exponent (float or Tensor) â€“ å¹‚å€¼</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.5274</span><br><span class="line">-0.8232</span><br><span class="line">-2.1128</span><br><span class="line"> 1.7558</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.pow(a, 2)</span><br><span class="line"></span><br><span class="line"> 0.2781</span><br><span class="line"> 0.6776</span><br><span class="line"> 4.4640</span><br><span class="line"> 3.0829</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; exp = torch.arange(1, 5)</span><br><span class="line">&gt;&gt;&gt; a = torch.arange(1, 5)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; exp</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.pow(a, exp)</span><br><span class="line"></span><br><span class="line">   1</span><br><span class="line">   4</span><br><span class="line">  27</span><br><span class="line"> 256</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><p>åŒæ ·åº•æ•°å¯ä»¥ä¸ºå¼ é‡ï¼ŒæŒ‡æ•°ä¸ºå¼ é‡ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.pow(base, input, out=None)</span><br></pre></td></tr></table></figure><p><code>base</code> ä¸ºæ ‡é‡æµ®ç‚¹å€¼,<code>input</code>ä¸ºå¼ é‡ï¼Œ è¿”å›çš„è¾“å‡ºå¼ é‡ out ä¸è¾“å…¥å¼ é‡ç›¸åŒå½¢çŠ¶ã€‚</p><p>æ‰§è¡Œæ“ä½œä¸º:<br>$out_i=base^{input_i}$</p><h3 id="torch-exp"><a href="#torch-exp" class="headerlink" title="torch.exp"></a>torch.exp</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.exp(tensor, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„æŒ‡æ•°ã€‚</p><h3 id="torch-log"><a href="#torch-log" class="headerlink" title="torch.log"></a>torch.log</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.log(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è®¡ç®—<code>input</code> çš„è‡ªç„¶å¯¹æ•°ã€‚</p><h3 id="torch-acos-input-out-None-â†’-Tensor"><a href="#torch-acos-input-out-None-â†’-Tensor" class="headerlink" title="torch.acos(input, out=None) â†’ Tensor"></a>torch.acos(input, out=None) â†’ Tensor</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.acos(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥å¼ é‡æ¯ä¸ªå…ƒç´ çš„åä½™å¼¦ã€‚ </p><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>out (Tensor, optional) â€“ ç»“æœå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.6366</span><br><span class="line"> 0.2718</span><br><span class="line"> 0.4469</span><br><span class="line"> 1.3122</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.acos(a)</span><br><span class="line"> 2.2608</span><br><span class="line"> 1.2956</span><br><span class="line"> 1.1075</span><br><span class="line">    nan</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-asin"><a href="#torch-asin" class="headerlink" title="torch.asin"></a>torch.asin</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.asin(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„åæ­£å¼¦å‡½æ•°ã€‚</p><h3 id="torch-atan"><a href="#torch-atan" class="headerlink" title="torch.atan"></a>torch.atan</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.atan(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„åæ­£åˆ‡å‡½æ•°ã€‚</p><h3 id="torch-sin"><a href="#torch-sin" class="headerlink" title="torch.sin"></a>torch.sin</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sin(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„æ­£å¼¦ã€‚</p><h3 id="torch-cos"><a href="#torch-cos" class="headerlink" title="torch.cos"></a>torch.cos</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cos(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„ä½™å¼¦ã€‚</p><h3 id="torch-tan"><a href="#torch-tan" class="headerlink" title="torch.tan"></a>torch.tan</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.tan(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„æ­£åˆ‡ã€‚</p><h3 id="torch-sinh"><a href="#torch-sinh" class="headerlink" title="torch.sinh"></a>torch.sinh</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sinh(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„åŒæ›²æ­£å¼¦ã€‚</p><h3 id="torch-cosh"><a href="#torch-cosh" class="headerlink" title="torch.cosh"></a>torch.cosh</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cosh(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„åŒæ›²ä½™å¼¦ã€‚</p><h3 id="torch-tanh"><a href="#torch-tanh" class="headerlink" title="torch.tanh"></a>torch.tanh</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.tanh(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„åŒæ›²æ­£åˆ‡ã€‚</p><h3 id="torch-ceil"><a href="#torch-ceil" class="headerlink" title="torch.ceil"></a>torch.ceil</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.ceil(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>å¤©äº•å‡½æ•°ï¼Œå¯¹è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ å‘ä¸Šå–<strong>æ•´</strong>, å³å–ä¸å°äºæ¯ä¸ªå…ƒç´ çš„æœ€å°æ•´æ•°ï¼Œå¹¶è¿”å›ç»“æœåˆ°è¾“å‡ºã€‚</p><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 1.3869</span><br><span class="line"> 0.3912</span><br><span class="line">-0.8634</span><br><span class="line">-0.5468</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.ceil(a)</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line"> 1</span><br><span class="line">-0</span><br><span class="line">-0</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-floor"><a href="#torch-floor" class="headerlink" title="torch.floor"></a>torch.floor</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.floor(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>åºŠå‡½æ•°: è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„<code>floor</code>ï¼Œå³ä¸å°äºå…ƒç´ çš„æœ€å¤§æ•´æ•°ã€‚å‘ä¸‹å–æ•´ã€‚</p><h3 id="torch-round"><a href="#torch-round" class="headerlink" title="torch.round"></a>torch.round</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.round(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼Œå°†è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ <strong>èˆå…¥åˆ°æœ€è¿‘çš„æ•´æ•°(å››èˆäº”å…¥)</strong>ã€‚</p><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 1.2290</span><br><span class="line"> 1.3409</span><br><span class="line">-0.5662</span><br><span class="line">-0.0899</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.round(a)</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 1</span><br><span class="line">-1</span><br><span class="line">-0</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-trunc"><a href="#torch-trunc" class="headerlink" title="torch.trunc"></a>torch.trunc</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.trunc(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„æˆªæ–­å€¼(æ ‡é‡<code>x</code>çš„æˆªæ–­å€¼æ˜¯æœ€æ¥è¿‘å…¶çš„æ•´æ•°ï¼Œå…¶æ¯”xæ›´æ¥è¿‘é›¶ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæœ‰ç¬¦å·æ•°çš„å°æ•°éƒ¨åˆ†è¢«èˆå¼ƒ)ã€‚</p><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.4972</span><br><span class="line"> 1.3512</span><br><span class="line"> 0.1056</span><br><span class="line">-0.2650</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.trunc(a)</span><br><span class="line"></span><br><span class="line">-0</span><br><span class="line"> 1</span><br><span class="line"> 0</span><br><span class="line">-0</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-clamp"><a href="#torch-clamp" class="headerlink" title="torch.clamp"></a>torch.clamp</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.clamp(input, min, max, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>å°†è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„å¤¹ç´§åˆ°åŒºé—´ $[min,max]$ï¼Œå¹¶è¿”å›ç»“æœåˆ°ä¸€ä¸ªæ–°å¼ é‡ã€‚</p><p>å…¬å¼ï¼š</p><script type="math/tex; mode=display">y_i = \begin{cases}min, if\ x_i < min\\ x_i, if \ min <= x_i <= max    \\max, if \ x_i > max\end{cases}</script><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>min (Number) â€“ é™åˆ¶èŒƒå›´ä¸‹é™</li><li>max (Number) â€“ é™åˆ¶èŒƒå›´ä¸Šé™</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p>å°†è¾“å‡ºé™åˆ¶åˆ°ä¸å°äº0.5</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.clamp(a, min=0.5)</span><br></pre></td></tr></table></figure><p>å°†è¾“å‡ºé™åˆ¶åˆ°ä¸å¤§äº0.5</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.clamp(a, max=0.5)</span><br></pre></td></tr></table></figure><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 1.3869</span><br><span class="line"> 0.3912</span><br><span class="line">-0.8634</span><br><span class="line">-0.5468</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.clamp(a, min=-0.5, max=0.5)</span><br><span class="line"></span><br><span class="line"> 0.5000</span><br><span class="line"> 0.3912</span><br><span class="line">-0.5000</span><br><span class="line">-0.5000</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-fmod"><a href="#torch-fmod" class="headerlink" title="torch.fmod"></a>torch.fmod</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.fmod(input, divisor, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è®¡ç®—é™¤æ³•ä½™æ•°ã€‚ </p><p>é™¤æ•°ä¸è¢«é™¤æ•°å¯èƒ½åŒæ—¶å«æœ‰æ•´æ•°å’Œæµ®ç‚¹æ•°ã€‚æ­¤æ—¶ï¼Œä½™æ•°çš„æ­£è´Ÿä¸è¢«é™¤æ•°ç›¸åŒã€‚</p><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¢«é™¤æ•° </li><li>divisor (Tensor or float) â€“ é™¤æ•°ï¼Œä¸€ä¸ªæ•°æˆ–ä¸è¢«é™¤æ•°ç›¸åŒç±»å‹çš„å¼ é‡ </li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p><strong>torch.remainde</strong>rç”¨æ³•ç›¸åŒã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.remainder(input, divisor, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.fmod(torch.Tensor([-3, -2, -1, 1, 2, 3]), 2)</span><br><span class="line">torch.FloatTensor([-1, -0, -1, 1, 0, 1])</span><br><span class="line">&gt;&gt;&gt; torch.fmod(torch.Tensor([1, 2, 3, 4, 5]), 1.5)</span><br><span class="line">torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5])</span><br></pre></td></tr></table></figure><h3 id="torch-frac"><a href="#torch-frac" class="headerlink" title="torch.frac"></a>torch.frac</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.frac(tensor, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>è¿”å›æ¯ä¸ªå…ƒç´ çš„åˆ†æ•°éƒ¨åˆ†ã€‚</p><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.frac(torch.Tensor([1, 2.5, -3.2])</span><br><span class="line">torch.FloatTensor([0, 0.5, -0.2])</span><br></pre></td></tr></table></figure><h3 id="torch-lerp"><a href="#torch-lerp" class="headerlink" title="torch.lerp"></a>torch.lerp</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.lerp(start, end, weight, out=None)</span><br></pre></td></tr></table></figure><p>å¯¹ä¸¤ä¸ªå¼ é‡ä»¥<code>start</code>ï¼Œendåš<strong>çº¿æ€§æ’å€¼</strong>ï¼Œ å°†ç»“æœè¿”å›åˆ°è¾“å‡ºå¼ é‡ã€‚</p><p>å³ï¼Œ$out_i=start_i+weightâˆ—(end_iâˆ’start_i)$<br>å‚æ•°ï¼š</p><ul><li>start (Tensor) â€“ èµ·å§‹ç‚¹å¼ é‡</li><li>end (Tensor) â€“ ç»ˆæ­¢ç‚¹å¼ é‡</li><li>weight (float) â€“ æ’å€¼å…¬å¼çš„weight</li><li>out (Tensor, optional) â€“ ç»“æœå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; start = torch.arange(1, 5)</span><br><span class="line">&gt;&gt;&gt; end = torch.Tensor(4).fill_(10)</span><br><span class="line">&gt;&gt;&gt; start</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; end</span><br><span class="line"></span><br><span class="line"> 10</span><br><span class="line"> 10</span><br><span class="line"> 10</span><br><span class="line"> 10</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.lerp(start, end, 0.5)</span><br><span class="line"></span><br><span class="line"> 5.5000</span><br><span class="line"> 6.0000</span><br><span class="line"> 6.5000</span><br><span class="line"> 7.0000</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-sign"><a href="#torch-sign" class="headerlink" title="torch.sign"></a>torch.sign</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sign(input, out=None) â†’ Tensor</span><br></pre></td></tr></table></figure><p>ç¬¦å·å‡½æ•°ï¼šè¿”å›ä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥<code>input</code>å¼ é‡æ¯ä¸ªå…ƒç´ çš„æ­£è´Ÿã€‚</p><p>å‚æ•°ï¼š</p><ul><li>input (Tensor) â€“ è¾“å…¥å¼ é‡</li><li>out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡</li></ul><p>ä¾‹å­ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">-0.6366</span><br><span class="line"> 0.2718</span><br><span class="line"> 0.4469</span><br><span class="line"> 1.3122</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.sign(a)</span><br><span class="line"></span><br><span class="line">-1</span><br><span class="line"> 1</span><br><span class="line"> 1</span><br><span class="line"> 1</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨Nginxé…ç½®åŒä¸€ç«¯å£è®¿é—®ä¸åŒè·¯å¾„ä¸‹çš„æ–‡ä»¶</title>
      <link href="/2021/02/01/%E4%BD%BF%E7%94%A8Nginx%E9%85%8D%E7%BD%AE%E5%90%8C%E4%B8%80%E7%AB%AF%E5%8F%A3%E8%AE%BF%E9%97%AE%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6/"/>
      <url>/2021/02/01/%E4%BD%BF%E7%94%A8Nginx%E9%85%8D%E7%BD%AE%E5%90%8C%E4%B8%80%E7%AB%AF%E5%8F%A3%E8%AE%BF%E9%97%AE%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨Nginxé…ç½®åŒä¸€ç«¯å£è®¿é—®ä¸åŒè·¯å¾„ä¸‹çš„æ–‡ä»¶"><a href="#ä½¿ç”¨Nginxé…ç½®åŒä¸€ç«¯å£è®¿é—®ä¸åŒè·¯å¾„ä¸‹çš„æ–‡ä»¶" class="headerlink" title="ä½¿ç”¨Nginxé…ç½®åŒä¸€ç«¯å£è®¿é—®ä¸åŒè·¯å¾„ä¸‹çš„æ–‡ä»¶"></a>ä½¿ç”¨Nginxé…ç½®åŒä¸€ç«¯å£è®¿é—®ä¸åŒè·¯å¾„ä¸‹çš„æ–‡ä»¶</h1><ol><li>ç¼–è¾‘é…ç½®æ–‡ä»¶</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"># http  </span><br><span class="line">  server &#123;</span><br><span class="line">        listen       80 default_server;</span><br><span class="line">        listen       [::]:80 default_server;</span><br><span class="line">        server_name www.asimok.com;</span><br><span class="line">        # Load configuration files for the default server block.</span><br><span class="line">        include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">        root /root/mq_blog/public;</span><br><span class="line">        index index.html;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 404 /404.html;</span><br><span class="line">        location = /404.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 500 502 503 504 /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        return 301 https://$host$request_uri;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">#https</span><br><span class="line">   server&#123;</span><br><span class="line">        #ç›‘å¬443ç«¯å£</span><br><span class="line">        listen 443 ssl;</span><br><span class="line">        #å¯¹åº”çš„åŸŸåï¼ŒæŠŠbaofeidyz.comæ”¹æˆä½ ä»¬è‡ªå·±çš„åŸŸåå°±å¯ä»¥äº†</span><br><span class="line">        server_name www.asimok.com;</span><br><span class="line">        #ä»è…¾è®¯äº‘è·å–åˆ°çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„å…¨è·¯å¾„</span><br><span class="line">        ssl_certificate /etc/ssl/1_www.asimok.site_bundle.crt;</span><br><span class="line">        #ä»è…¾è®¯äº‘è·å–åˆ°çš„ç¬¬äºŒä¸ªæ–‡ä»¶çš„å…¨è·¯å¾„</span><br><span class="line">        ssl_certificate_key /etc/ssl/2_www.asimok.site.key;</span><br><span class="line">        ssl_session_timeout 5m;</span><br><span class="line">        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;</span><br><span class="line">        ssl_prefer_server_ciphers on;</span><br><span class="line">        #è¿™æ˜¯æˆ‘çš„ä¸»é¡µè®¿é—®åœ°å€ï¼Œå› ä¸ºä½¿ç”¨çš„æ˜¯é™æ€çš„htmlç½‘é¡µï¼Œæ‰€ä»¥ç›´æ¥ä½¿ç”¨locationå°±å¯ä»¥å®Œæˆäº†ã€‚</span><br><span class="line">        location / &#123;</span><br><span class="line">               #æ–‡ä»¶å¤¹</span><br><span class="line">               root /root/mq_blog/public;</span><br><span class="line">               #ä¸»é¡µæ–‡ä»¶</span><br><span class="line">               index index.html;</span><br><span class="line">        &#125;</span><br><span class="line"># å¤§è¥¿ç“œ</span><br><span class="line">        location /daxigua &#123;</span><br><span class="line">               alias /root/daxigua;</span><br><span class="line">               index index.html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ol><li>ä¿å­˜é€€å‡º </li><li>å¯¹é…ç½®æ–‡ä»¶è¿›è¡Œæ ¡éªŒ</li></ol><p>ä¿å­˜é…ç½®æ–‡ä»¶ä¹‹åæ‰§è¡Œï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -t</span><br></pre></td></tr></table></figure><p>susccessfulå³å¯</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/night1/image-20201209112907309.png" alt="image-20201209112907309"></p><ol><li>é‡å¯nginxæœåŠ¡</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><ol><li>é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><h2 id="å¤šä¸ªè·¯å¾„é…ç½®"><a href="#å¤šä¸ªè·¯å¾„é…ç½®" class="headerlink" title="å¤šä¸ªè·¯å¾„é…ç½®"></a>å¤šä¸ªè·¯å¾„é…ç½®</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location /daxigua &#123;</span><br><span class="line">           alias /root/daxigua;</span><br><span class="line">           index index.html;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨rootä¼šå°†locationåçš„daxiguaè¿½åŠ åœ¨è·¯å¾„çš„å°¾éƒ¨ï¼Œåœ¨è®¿é—®æ—¶å°±ä¼šè®¿é—®åˆ°/root/daxigua/daxiguaè·¯å¾„ä¸‹å»ã€‚<br>å°†rootæ”¹æˆaliasåˆ™ä¸ä¼šå°†daxiguaè¿½åŠ åœ¨è·¯å¾„å°¾éƒ¨ï¼Œè®¿é—®æ—¶å°±ä¸ºæ­£ç¡®è·¯å¾„/root/daxiguaã€‚</p><h2 id="æµ‹è¯•"><a href="#æµ‹è¯•" class="headerlink" title="æµ‹è¯•"></a>æµ‹è¯•</h2><p><a href="https://www.asimok.site/daxigua">https://www.asimok.site/daxigua</a></p><p><a href="https://www.asimok.site">https://www.asimok.site</a></p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-hop Question Answering via Reasoning Chains</title>
      <link href="/2021/01/29/Multi-hop%20Question%20Answering%20via%20Reasoning%20Chains%20/"/>
      <url>/2021/01/29/Multi-hop%20Question%20Answering%20via%20Reasoning%20Chains%20/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-hop-Question-Answering-via-Reasoning-Chains"><a href="#Multi-hop-Question-Answering-via-Reasoning-Chains" class="headerlink" title="Multi-hop Question Answering via Reasoning Chains"></a>Multi-hop Question Answering via Reasoning Chains</h1><blockquote><p><a href="https://arxiv.org/abs/1910.02610">è®ºæ–‡ï¼š2019-Multi-hop Question Answering via Reasoning Chains</a></p><p>åŸºäºæ¨ç†é“¾çš„å¤šè·³é—®é¢˜å›ç­”</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>â€‹        æœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨æ–‡æœ¬ä¸­æå–ç¦»æ•£æ¨ç†é“¾çš„æ–¹æ³•ï¼Œæ¨¡å‹ä¸ä¾èµ–äºgold annotated chains or â€œsupporting factsï¼Œä½¿ç”¨åŸºäºå‘½åå®ä½“è¯†åˆ«å’Œå…±æŒ‡æ¶ˆè§£çš„å¯å‘å¼ç®—æ³•å¾—åˆ°çš„pseudogold reasoning chainsã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210124163210.png" alt="image-20210124163210620"></p><blockquote><p>æ¨ç†é“¾æ˜¯ä¸€ç³»åˆ—çš„å¥å­ï¼Œé€»è¾‘ä¸ŠæŠŠé—®é¢˜ä¸ä¸€ä¸ªäº‹å®è”ç³»èµ·æ¥ï¼Œè¿™ä¸ªäº‹å®ä¸ç»™å‡ºä¸€ä¸ªåˆç†çš„ç­”æ¡ˆç›¸å…³ï¼ˆæˆ–éƒ¨åˆ†ç›¸å…³ï¼‰ã€‚</p></blockquote><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>æå‡ºä¸€ä¸ªtwo-stage model</p><blockquote><p>extractor modelï¼šæå–æ¨ç†è·¯å¾„ã€‚extractoræ¨¡å‹å¯¹å¥å­åºåˆ—è¿›è¡Œè¯„åˆ†ï¼Œå¹¶é€šè¿‡<strong>beam search</strong>ç”Ÿæˆ<strong>n-best</strong>é“¾åˆ—è¡¨ã€‚</p><p>answer moduleï¼šå°†æå–çš„æ¨ç†é“¾è¾“å…¥åˆ°BERTä¸­æå–æœ€ç»ˆçš„ç­”æ¡ˆã€‚</p></blockquote><h3 id="Learning-to-Extract-Chains"><a href="#Learning-to-Extract-Chains" class="headerlink" title="Learning to Extract Chains"></a>Learning to Extract Chains</h3><h4 id="Heuristic-oracle-chain-construction"><a href="#Heuristic-oracle-chain-construction" class="headerlink" title="Heuristic oracle chain construction"></a>Heuristic oracle chain construction</h4><ul><li><p>ä½¿ç”¨å‘½åå®ä½“è¯†åˆ«æå–å¥å­ä¸­çš„å®ä½“ï¼Œå¦‚æœä¸¤ä¸ªå¥å­ä¸­æœ‰åŒ¹é…çš„å®ä½“ï¼Œåˆ™åœ¨è¿™ä¸¤ä¸ªèŠ‚ç‚¹ä¸Šæ·»åŠ ä¸€æ¡è¾¹ã€‚å¯¹æ®µè½ä¸­çš„æ‰€æœ‰å¥å­è¿›è¡Œè¿™ä¸€æ“ä½œã€‚</p></li><li><p>ä»é—®é¢˜çš„èŠ‚ç‚¹å¼€å§‹ï¼Œæœç´¢æ‰€æœ‰å¯èƒ½çš„æ¨ç†é“¾ã€‚</p></li></ul><p>ä½¿ç”¨ä¸¤ç§æ–¹å¼é€‰æ‹©heuristic oraclesï¼š</p><blockquote><p>Shortest Pathï¼šé€‰æ‹©æœ€çŸ­çš„æ¨ç†é“¾ã€‚</p><p>Question Overlapï¼šè®¡ç®—æ¯æ¡é“¾çš„Rouge-F1ï¼Œé€‰æ‹©å¾—åˆ†æœ€é«˜çš„æ¨ç†é“¾ï¼Œè¿™æ ·å¯ä»¥æ‰¾åˆ°æ›´å®Œæ•´çš„ç­”æ¡ˆé“¾ã€‚</p></blockquote><h4 id="Chain-extraction-model"><a href="#Chain-extraction-model" class="headerlink" title="Chain extraction model"></a>Chain extraction model</h4><blockquote><p>è¾“å…¥ï¼šæ–‡æ¡£+é—®é¢˜</p><p>å¤„ç†æµç¨‹ï¼šsentence encoding and chain prediction</p></blockquote><h5 id="Sentence-Encoding"><a href="#Sentence-Encoding" class="headerlink" title="Sentence Encoding"></a>Sentence Encoding</h5><ul><li>å°†è¾“å…¥é—®é¢˜å’Œæ®µè½ä½¿ç”¨BERTç¼–ç ã€‚å¥å­å¯ä»¥ä»æ®µè½ä¸­æå–å‡ºæ¥ã€‚</li></ul><script type="math/tex; mode=display">s_j = Span Extractor(p_i, s^{START}_j , s^{END}_j )</script><blockquote><p>$s_j$è¡¨ç¤ºæ®µè½$p_i$ä¸­ç¬¬iå¥è¯</p></blockquote><ul><li><p>BERT-para</p><blockquote><p>æœ¬æ–‡è®¾è®¡çš„paragraph-factored modelï¼Œæ¯”åœ¨æ•´ä¸ªä¸Šä¸‹æ–‡è¿è¡ŒBERTæ›´é«˜çš„æ•ˆç‡å’Œå¯æ‹“å±•æ€§ã€‚</p><p>ä½¿ç”¨bert-base-uncasedé¢„è®­ç»ƒæ¨¡å‹ã€‚</p></blockquote></li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210124182342.png" alt="image-20210124182342557"></p><h5 id="Chain-Prediction"><a href="#Chain-Prediction" class="headerlink" title="Chain Prediction"></a>Chain Prediction</h5><p>â€‹        å°†æ‰€æœ‰ç¼–ç çš„å¥å­è¡¨ç¤ºä½œä¸ºä¸€ä¸ªå¥å­åŒ…ï¼Œå¹¶é‡‡ç”¨åŸºäºLSTMçš„pointer networkæ¥æå–æ¨ç†é“¾ã€‚</p><blockquote><p>åœ¨ç¬¬ä¸€æ­¥ä¸­ï¼Œä½¿ç”¨é—®é¢˜qçš„max-pooledè¡¨ç¤ºåˆå§‹åŒ–pointer networkä¸­çš„éšè—çŠ¶æ€$h_0$ï¼Œå¹¶æä¾›ä¸€ä¸ªç‰¹æ®Šçš„ä»¤ç‰ŒSOSä½œä¸ºç¬¬ä¸€ä¸ªè¾“å…¥ã€‚</p></blockquote><script type="math/tex; mode=display">P(c_t= i|c_1, . . . , c_{tâˆ’1}, s) = softmax(Î±)[i]</script><script type="math/tex; mode=display">Î±_i= W[h_{tâˆ’1}; s_{c_{tâˆ’1}};h_{tâˆ’1} \odot s_{c_{tâˆ’1}}]</script><blockquote><p>$c<em>1, . . . , c</em>{tâˆ’1}$ï¼šæ¨ç†é“¾ä¸­å¥å­ç´¢å¼•ã€‚</p><p>Wï¼šè¦å­¦ä¹ çš„æƒé‡ã€‚</p></blockquote><h5 id="Training-the-Chain-Extractor"><a href="#Training-the-Chain-Extractor" class="headerlink" title="Training the Chain Extractor"></a>Training the Chain Extractor</h5><p>step tçš„æŸå¤±ï¼š</p><script type="math/tex; mode=display">loss_t=-log(P(câˆ—t)|c^âˆ—_1,...,c^âˆ—_{tâˆ’1}s)</script><blockquote><p>$c^âˆ—_1$ï¼šç›®æ ‡å¥å­</p></blockquote><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>WikiHop</li><li>HotpotQA</li></ul><h2 id="æ€§èƒ½æ°´å¹³-amp-ç»“è®º"><a href="#æ€§èƒ½æ°´å¹³-amp-ç»“è®º" class="headerlink" title="æ€§èƒ½æ°´å¹³&amp;ç»“è®º"></a>æ€§èƒ½æ°´å¹³&amp;ç»“è®º</h2><h3 id="Comparison-of-Chain-Extraction-Methods"><a href="#Comparison-of-Chain-Extraction-Methods" class="headerlink" title="Comparison of Chain Extraction Methods"></a>Comparison of Chain Extraction Methods</h3><ul><li>ä½¿ç”¨æ›´å¤šçš„ä¸Šä¸‹æ–‡æœ‰åŠ©äºé“¾æå–å™¨æ‰¾åˆ°ç›¸å…³çš„å¥å­ã€‚</li><li>one-bestæ¨ç†è¿é€šå¸¸åŒ…å«ç­”æ¡ˆã€‚</li><li>Q-Overlapæœ‰åŠ©äºæ‰¾åˆ°æ›´å¤šçš„æ”¯æŒäº‹å®ã€‚</li><li>å¯ä»¥é€šè¿‡è·¨å¤šä¸ªé“¾ä½¿ç”¨å¹¶é›†æ¥æé«˜æ€§èƒ½ã€‚ï¼ˆBRRT-Para(top5)ï¼‰</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210124194515.png" alt="image-20210124194515730"></p><h3 id="Results-compared-to-other-systems"><a href="#Results-compared-to-other-systems" class="headerlink" title="Results compared to other systems"></a>Results compared to other systems</h3><blockquote><p>HotpotQAï¼šä½¿ç”¨RoBERTa é¢„æ¨¡å‹ä½œä¸ºæƒé‡ã€‚</p></blockquote><ul><li>æ€§èƒ½è¶…è¿‡äº†ä½¿ç”¨æ ‡è®°æ”¯æŒäº‹å®çš„æ¨¡å‹ï¼Œè¯´æ˜æœ¬æ–‡æå‡ºçš„heuristicallyextracted chainså¯ä»¥æœ‰æ•ˆçš„æ›¿ä»£æ ‡è®°æ”¯æŒäº‹å®è¿›è¡Œç›‘ç£ã€‚</li></ul><p><img src="/Users/maqi/Library/Application Support/typora-user-images/image-20210129092022793.png" alt="image-20210129092022793" style="zoom:50%;" /></p><h3 id="Evaluation-of-chains"><a href="#Evaluation-of-chains" class="headerlink" title="Evaluation of chains"></a>Evaluation of chains</h3><ul><li><p>æœ‰åºæŠ½å–ä¼˜äºæ— åºæŠ½å–ã€‚</p><blockquote><p>åœ¨HotpotQA-Hardä¸Šï¼Œæ›´éœ€è¦å¤šè·³æ¨ç†ã€‚</p></blockquote></li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210129092925.png" alt="image-20210129092925076"></p><ul><li>é“¾æ¥æå–çš„æ€§èƒ½å·²æ¥è¿‘HotpotQAä¸Šçš„æ€§èƒ½æé™ã€‚</li><li>Table4ä¸­äººç±»è¯„ä¼°çš„å¾—åˆ†ä¸æ¨¡å‹åœ¨oracleä¸Šçš„F1çš„åˆ†ç›¸è¿‘ï¼Œè¡¨æ˜æœ¬æ–‡æå‡ºçš„æ¨¡å‹ä¸å†éœ€è¦äººå·¥æ³¨é‡Šçš„æ”¯æŒäº‹å®ã€‚</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210129093850.png" alt="image-20210129093850960"></p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> HotpotQA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pythonâ€”â€”pickleæ¨¡å—çš„è¯¦è§£</title>
      <link href="/2021/01/29/python%E2%80%94%E2%80%94pickle%E6%A8%A1%E5%9D%97%E7%9A%84%E8%AF%A6%E8%A7%A3/"/>
      <url>/2021/01/29/python%E2%80%94%E2%80%94pickle%E6%A8%A1%E5%9D%97%E7%9A%84%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="pythonâ€”â€”pickleæ¨¡å—çš„è¯¦è§£"><a href="#pythonâ€”â€”pickleæ¨¡å—çš„è¯¦è§£" class="headerlink" title="pythonâ€”â€”pickleæ¨¡å—çš„è¯¦è§£"></a>pythonâ€”â€”pickleæ¨¡å—çš„è¯¦è§£</h1><h2 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h2><ul><li><p>pickleæ¨¡å—å®ç°äº†ç”¨äºåºåˆ—åŒ–å’Œååºåˆ—åŒ–Pythonå¯¹è±¡ç»“æ„çš„äºŒè¿›åˆ¶åè®®</p></li><li><p>â€œPicklingâ€æ˜¯å°†Pythonå¯¹è±¡å±‚æ¬¡ç»“æ„è½¬æ¢ä¸ºå­—èŠ‚æµçš„è¿‡ç¨‹ï¼Œ â€œunpicklingâ€æ˜¯åå‘æ“ä½œï¼Œä»è€Œå°†å­—èŠ‚æµï¼ˆæ¥è‡ªäºŒè¿›åˆ¶æ–‡ä»¶æˆ–ç±»ä¼¼å­—èŠ‚çš„å¯¹è±¡ï¼‰è½¬æ¢å›å¯¹è±¡å±‚æ¬¡ç»“æ„ã€‚</p></li><li><p>pickleåè®®å’ŒJSONï¼ˆJavaScript Object Notationï¼‰çš„åŒºåˆ« ï¼š</p><ol><li>JSONæ˜¯ä¸€ç§æ–‡æœ¬åºåˆ—åŒ–æ ¼å¼ï¼ˆå®ƒè¾“å‡ºunicodeæ–‡æœ¬ï¼Œè™½ç„¶å¤§éƒ¨åˆ†æ—¶é—´å®ƒè¢«ç¼–ç utf-8ï¼‰ï¼Œè€Œpickleæ˜¯äºŒè¿›åˆ¶åºåˆ—åŒ–æ ¼å¼;</li><li>JSONæ˜¯äººç±»å¯è¯»çš„ï¼Œè€Œpickleåˆ™ä¸æ˜¯;</li><li>JSONæ˜¯å¯äº’æ“ä½œçš„ï¼Œå¹¶ä¸”åœ¨Pythonç”Ÿæ€ç³»ç»Ÿä¹‹å¤–å¹¿æ³›ä½¿ç”¨ï¼Œè€Œpickleæ˜¯ç‰¹å®šäºPythonçš„;</li></ol></li><li>pickleå¯ä»¥è¡¨ç¤ºæå…¶åºå¤§çš„Pythonç±»å‹ï¼ˆå…¶ä¸­è®¸å¤šæ˜¯è‡ªåŠ¨çš„ï¼Œé€šè¿‡å·§å¦™åœ°ä½¿ç”¨Pythonçš„å†…çœå·¥å…·;å¤æ‚çš„æ¡ˆä¾‹å¯ä»¥é€šè¿‡å®ç°ç‰¹å®šçš„å¯¹è±¡APIæ¥è§£å†³ï¼‰ã€‚</li><li>pickle æ•°æ®æ ¼å¼æ˜¯ç‰¹å®šäºPythonçš„ã€‚å®ƒçš„ä¼˜ç‚¹æ˜¯æ²¡æœ‰å¤–éƒ¨æ ‡å‡†å¼ºåŠ çš„é™åˆ¶ï¼Œ ä½†æ˜¯è¿™æ„å‘³ç€éPythonç¨‹åºå¯èƒ½æ— æ³•é‡å»ºpickled Pythonå¯¹è±¡ã€‚</li></ul><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><h3 id="dumps"><a href="#dumps" class="headerlink" title="dumps()"></a>dumps()</h3><ul><li>åºåˆ—åŒ–å¯¹è±¡å±‚æ¬¡ç»“æ„ã€‚</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.dumpï¼ˆobjï¼Œfileï¼Œprotocol = Noneï¼Œ*ï¼Œfix_imports = True ï¼‰</span><br></pre></td></tr></table></figure><p>å°†objå¯¹è±¡çš„ç¼–ç pickleç¼–ç è¡¨ç¤ºå†™å…¥åˆ°æ–‡ä»¶å¯¹è±¡ä¸­ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.loadï¼ˆfileï¼Œ*ï¼Œfix_imports = Trueï¼Œencoding =â€œASCIIâ€ï¼Œerrors =â€œstrictâ€ ï¼‰</span><br></pre></td></tr></table></figure><p>ä»æ‰“å¼€çš„æ–‡ä»¶å¯¹è±¡ æ–‡ä»¶ä¸­è¯»å–pickleå¯¹è±¡è¡¨ç¤ºï¼Œå¹¶è¿”å›å…¶ä¸­æŒ‡å®šçš„é‡æ„å¯¹è±¡å±‚æ¬¡ç»“æ„ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.dumpsï¼ˆobjï¼Œprotocol = Noneï¼Œ*ï¼Œfix_imports = True ï¼‰</span><br></pre></td></tr></table></figure><p>å°†å¯¹è±¡çš„pickledè¡¨ç¤ºä½œä¸ºbyteså¯¹è±¡è¿”å›ï¼Œè€Œä¸æ˜¯å°†å…¶å†™å…¥æ–‡ä»¶ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.loadsï¼ˆbytes_objectï¼Œ*ï¼Œfix_imports = Trueï¼Œencoding =â€œASCIIâ€ï¼Œerrors =â€œstrictâ€ ï¼‰</span><br></pre></td></tr></table></figure><p>ä»byteså¯¹è±¡è¯»å–pickleå¯¹è±¡å±‚æ¬¡ç»“æ„å¹¶è¿”å›å…¶ä¸­æŒ‡å®šçš„é‡æ„å¯¹è±¡å±‚æ¬¡ç»“æ„ã€‚</p><h3 id="loads"><a href="#loads" class="headerlink" title="loads()"></a>loads()</h3><ul><li>å¯¹æ•°æ®æµè¿›è¡Œååºåˆ—åŒ–ã€‚</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pickle</span><br><span class="line">import io</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    path = &#x27;test&#x27;</span><br><span class="line">    f = open(path, &#x27;wb&#x27;)</span><br><span class="line">    data = &#123;&#x27;a&#x27;:123, &#x27;b&#x27;:&#x27;ads&#x27;, &#x27;c&#x27;:[[1,2],[3,4]]&#125;</span><br><span class="line">    pickle.dump(data, f)</span><br><span class="line">    f.close()</span><br><span class="line"></span><br><span class="line">    f1 = open(path, &#x27;rb&#x27;)</span><br><span class="line">    data1 = pickle.load(f1)</span><br><span class="line">    print(data1)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> pickle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pythonâ€”â€”type hints</title>
      <link href="/2021/01/29/python%E2%80%94%E2%80%94type%20hints/"/>
      <url>/2021/01/29/python%E2%80%94%E2%80%94type%20hints/</url>
      
        <content type="html"><![CDATA[<h1 id="pythonâ€”â€”type-hints"><a href="#pythonâ€”â€”type-hints" class="headerlink" title="pythonâ€”â€”type hints"></a>pythonâ€”â€”type hints</h1><h2 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h2><ul><li>type hints ä¸»è¦æ˜¯è¦æŒ‡ç¤ºå‡½æ•°çš„è¾“å…¥å’Œè¾“å‡ºçš„æ•°æ®ç±»å‹ï¼Œæ•°æ®ç±»å‹åœ¨typing åŒ…ä¸­ï¼ŒåŸºæœ¬ç±»å‹æœ‰str,list,dictç­‰ç­‰ã€‚</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def hello(name: str) -&gt; None:</span><br><span class="line"> </span><br><span class="line">Â  Â  print(&#x27;hello &#123;&#125;&#x27;.format(name))</span><br></pre></td></tr></table></figure><h2 id="å¸¸ç”¨ç±»å‹"><a href="#å¸¸ç”¨ç±»å‹" class="headerlink" title="å¸¸ç”¨ç±»å‹"></a>å¸¸ç”¨ç±»å‹</h2><h3 id="Union"><a href="#Union" class="headerlink" title="Union"></a>Union</h3><ul><li>Union æ˜¯å½“æœ‰å¤šç§å¯èƒ½çš„æ•°æ®ç±»å‹æ—¶ä½¿ç”¨ï¼Œæ¯”å¦‚å‡½æ•°æœ‰å¯èƒ½æ ¹æ®ä¸åŒæƒ…å†µæœ‰æ—¶è¿”å›stræˆ–è¿”å›listï¼Œé‚£ä¹ˆå°±å¯ä»¥å†™æˆ<code>Union[list, str]</code></li></ul><h3 id="Optional"><a href="#Optional" class="headerlink" title="Optional"></a>Optional</h3><ul><li>Optionalæ˜¯Unionçš„ä¸€ä¸ªç®€åŒ–ï¼Œ å½“æ•°æ®ç±»å‹ä¸­æœ‰å¯èƒ½æ˜¯Noneæ—¶ï¼Œæ¯”å¦‚æœ‰å¯èƒ½æ˜¯strä¹Ÿæœ‰å¯èƒ½æ˜¯Noneï¼Œåˆ™Optional[str], ç›¸å½“äºUnion[str, None]. <strong>æ³¨æ„</strong>å’Œå‡½æ•°æœ‰é»˜è®¤å‚æ•°Noneæœ‰åŒºåˆ«ï¼Œä¸å¯çœç•¥é»˜è®¤å‚æ•°ï¼Œå¦‚ä¸‹ç¤ºä¾‹ï¼š</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">åŸå§‹ï¼šdef func(args = None):</span><br><span class="line">é”™ï¼šdef func(args:Optional[str]) -&gt; None:</span><br><span class="line">å¯¹ï¼šdef func(args:Optional[str] = None) -&gt; None: #ä¾ç„¶è¦ä¿ç•™é»˜è®¤èµ‹å€¼</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> type hints </tag>
            
            <tag> Optional </tag>
            
            <tag> Union </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç¯å¢ƒé…ç½®</title>
      <link href="/2021/01/29/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2021/01/29/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="ç¯å¢ƒé…ç½®"><a href="#ç¯å¢ƒé…ç½®" class="headerlink" title="ç¯å¢ƒé…ç½®"></a>ç¯å¢ƒé…ç½®</h1><h2 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h2><p>é…ç½®æ–‡ä»¶ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/.pip/pip.conf</span><br></pre></td></tr></table></figure><p>æ›´æ¢å›½å†…é•œåƒæºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">[install]</span><br><span class="line">trusted-host = mirrors.aliyun.com</span><br></pre></td></tr></table></figure><h2 id="TensorFlow-gpu"><a href="#TensorFlow-gpu" class="headerlink" title="TensorFlow-gpu"></a>TensorFlow-gpu</h2><blockquote><p>ä¸ºé¿å…å‡ºé”™ pytorchå’Œtensorflowéƒ½ä½¿ç”¨conda installå®‰è£…</p></blockquote><ol><li><p><strong>anconda</strong><br> <code>conda create -n tf python=3.6</code></p></li><li><p><strong>cuda deb</strong></p></li><li><p><strong>pytorch å®˜ç½‘ è‡ªåŠ¨å®‰è£…cudnn</strong></p><blockquote><p><a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p></blockquote><p> <code>conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch</code><br> æµ‹è¯•ï¼š</p><pre><code>     `import torch`     `torch.cuda.is_available()`</code></pre></li><li><p><strong>TensorFlow gpu</strong><br> <code>conda install tensorflow-gpu</code><br> æµ‹è¯•:</p><p> â€‹        <code>import tensorflow as tf</code></p><p> â€‹        <code>tf.test.is_gpu_available()</code></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ç¯å¢ƒå˜é‡ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AllenNLPå®è·µ</title>
      <link href="/2021/01/26/allennlp/"/>
      <url>/2021/01/26/allennlp/</url>
      
        <content type="html"><![CDATA[<h1 id="AllenNLP"><a href="#AllenNLP" class="headerlink" title="AllenNLP"></a>AllenNLP</h1><ul><li><a href="https://allennlp.org/">https://allennlp.org/</a></li></ul><h2 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conda create -n allennlp python=3.7</span><br><span class="line">pip install allennlp</span><br><span class="line">pip install allennlp-models</span><br><span class="line">pip install allennlp_optuna</span><br><span class="line">git clone https://github.com/allenai/allennlp-server</span><br><span class="line">cd allennlp-server</span><br><span class="line">pip install --editable .</span><br></pre></td></tr></table></figure><h2 id="å®‰è£…è€ç‰ˆæœ¬"><a href="#å®‰è£…è€ç‰ˆæœ¬" class="headerlink" title="å®‰è£…è€ç‰ˆæœ¬"></a>å®‰è£…è€ç‰ˆæœ¬</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n allennlp python=3.6.9</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AllenNLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Simple and Effective Model for Answering Multi-span Questions</title>
      <link href="/2021/01/20/A%20Simple%20and%20Effective%20Model%20for%20Answering%20Multi-span%20Questions/"/>
      <url>/2021/01/20/A%20Simple%20and%20Effective%20Model%20for%20Answering%20Multi-span%20Questions/</url>
      
        <content type="html"><![CDATA[<h1 id="A-Simple-and-Effective-Model-for-Answering-Multi-span-Questions"><a href="#A-Simple-and-Effective-Model-for-Answering-Multi-span-Questions" class="headerlink" title="A Simple and Effective Model for Answering Multi-span Questions"></a>A Simple and Effective Model for Answering Multi-span Questions</h1><blockquote><p>è®ºæ–‡ï¼šEMNLP20-A Simple and Effective Model for Answering Multi-span Questions</p><p>ä»£ç ï¼š<a href="https://github.com/eladsegal/tag-based-multi-span-extraction">https://github.com/eladsegal/tag-based-multi-span-extraction</a></p><p>multi-span architecture (TASE: TAg-based Span Extraction)</p><p>traditional single-span extraction (SSE)</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>â€‹        ä¼ ç»Ÿçš„é˜…è¯»ç†è§£æ¨¡å‹å°†é—®é¢˜çš„ç­”æ¡ˆé™åˆ¶åœ¨å•ä¸ªè·¨åº¦ï¼Œå¯¹äºç­”æ¡ˆå¤„äºå¤šè·¨åº¦çš„é—®é¢˜ä¼šæœ‰é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç®€å•çš„ä½“ç³»ç»“æ„ï¼Œé€šè¿‡å°†ä»»åŠ¡è½¬æ¢ä¸ºåºåˆ—æ ‡è®°é—®é¢˜æ¥å›ç­”å¤šè·¨åº¦é—®é¢˜ï¼Œä¸ºæ¯ä¸ªè¾“å…¥tokené¢„æµ‹æ˜¯å¦åº”è¯¥å°†å…¶ä½œä¸ºè¾“å‡ºçš„ä¸€éƒ¨åˆ†ã€‚</p><p>é˜…è¯»ç†è§£(RC)ä»»åŠ¡ï¼š</p><ul><li>åœ¨ç»™å®šä¸€ä¸ªé—®é¢˜å’Œä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹æä¾›ç­”æ¡ˆã€‚</li></ul><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><h3 id="Single-span-Model"><a href="#Single-span-Model" class="headerlink" title="Single-span Model"></a>Single-span Model</h3><p>question-context-answer triplets $(q<em>i, c_i, a_i)^N</em>{i=1}$</p><p>ç›®æ ‡ï¼šå­¦ä¹ ä¸€ä¸ªå‡½æ•°å°†ä¸€ä¸ªquestion-contextå¯¹æ˜ å°„åˆ°answerã€‚</p><p>å°†question and contextç¼–ç ï¼š</p><script type="math/tex; mode=display">h = Encoder([q, c])</script><p>$h$æ˜¯æ‰€æœ‰è¾“å…¥tokençš„ä¸Šä¸‹æ–‡è¡¨ç¤ºåºåˆ—:</p><script type="math/tex; mode=display">h = (h_1, . . . , h_m)</script><p>å‰é¦ˆç½‘ç»œ:</p><script type="math/tex; mode=display">p_{start}^ i = softmax (f_{start}(h_1), . . . , f_{start}(h_m))_i</script><script type="math/tex; mode=display">p_{end}^ i = softmax (f_{end}(h_1), . . . , f_{end}(h_m))_i</script><blockquote><p>é€šè¿‡$f<em>{start}(hi) and f</em>{end}(hi)$è®¡ç®—æ¯ä¸ªtokençš„å¾—åˆ†ï¼Œå†é€šè¿‡softmaxå¾—åˆ°æ¦‚ç‡åˆ†å¸ƒã€‚</p></blockquote><p>æå–ç­”æ¡ˆèŒƒå›´ï¼š</p><script type="math/tex; mode=display">(s, e) = \underset {s \le e} {arg max}  \ p_s^{start}  p_e^{end}</script><h3 id="Multi-span-Model"><a href="#Multi-span-Model" class="headerlink" title="Multi-span Model"></a>Multi-span Model</h3><h4 id="Span-Extraction-as-Sequence-Tagging"><a href="#Span-Extraction-as-Sequence-Tagging" class="headerlink" title="Span Extraction as Sequence Tagging"></a>Span Extraction as Sequence Tagging</h4><p>ä¸Single-span Modelç›¸åŒçš„æ˜¯ï¼šä½¿ç”¨ç›¸åŒçš„ä¸Šä¸‹æ–‡è¡¨ç¤º$h$</p><p>ä¸åŒçš„æ˜¯ï¼šä¸æ˜¯é¢„æµ‹å¼€å§‹å’Œç»“æŸæ¦‚ç‡ï¼Œè€Œæ˜¯ä¸ºæ¯ä¸ªæ ‡è®°åœ¨ä¸€ç»„æ ‡ç­¾ä¸Šè¾“å‡ºæ¦‚ç‡åˆ†å¸ƒã€‚</p><p>two tagging schemesï¼š</p><ul><li><p>BIO</p><blockquote><p>Bï¼šè¡¨ç¤ºè¾“å‡ºèŒƒå›´çš„ç¬¬ä¸€ä¸ªæ ‡è®°</p><p>Iï¼šè¡¨ç¤ºèŒƒå›´ä¸­çš„åç»­æ ‡è®°</p><p>Oï¼šè¡¨ç¤ºä¸å±äºè¾“å‡ºèŒƒå›´çš„æ ‡è®°</p></blockquote></li><li><p>IO</p><blockquote><p>Iï¼šå•è¯è¢«æ ‡è®°ä¸ºç­”æ¡ˆçš„ä¸€éƒ¨åˆ†</p><p>Oï¼šå•è¯æœªè¢«æ ‡è®°ä¸ºç­”æ¡ˆçš„ä¸€éƒ¨åˆ†</p></blockquote></li></ul><blockquote><p>æœ¬æ–‡é€‰æ‹©è¾ƒä¸ºç®€å•çš„<strong>IO</strong></p></blockquote><p><em>è¿™é‡Œç»™ä¸€ä¸ªä¾‹å­ï¼š</em></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210118200430.png" alt="image-20210118200430617" style="zoom:50%;" /></p><p>ç¬¬iä¸ªtokençš„æ ‡ç­¾çš„æ¦‚ç‡ï¼š</p><script type="math/tex; mode=display">p_i= softmax(f(h_i))</script><h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><p>ç»™å®šçš„ç­”æ¡ˆè·¨åº¦åœ¨è¾“å…¥ä¸­å¤šæ¬¡å‡ºç°çš„æƒ…å†µï¼š</p><blockquote><p>inputï¼šâ€œX Y Z Y Zâ€</p><p>answer spanï¼š{â€œXâ€, â€œZâ€},</p><p>taggingsï¼šB O B O B, B O B O O, and B O O O B.</p><ul><li>Xå¿…ç„¶ä¼šå‡ºç°</li><li>Yå¿…ç„¶ä¸ä¼šå‡ºç°</li><li>Zè‡³å°‘å‡ºç°1æ¬¡</li></ul></blockquote><p><strong>åœ¨è¿™ç§æƒ…å†µä¸‹ä¸èƒ½æ˜ç¡®ç¡®å®šåŸºæœ¬äº‹å®BIOã€‚</strong></p><p>ä¸ºäº†å¤„ç†è¿™ç§æƒ…å†µï¼Œåˆ—ä¸¾äº†æ‰€æœ‰å¯èƒ½å‡ºç°çš„æ ‡ç­¾ç»„åˆï¼š</p><script type="math/tex; mode=display">possibly-correct taggings, \tau</script><p>é€šè¿‡æœ€å¤§åŒ–æ‰€æœ‰å¯èƒ½çš„æ­£ç¡®æ ‡è®°çš„è¾¹ç•Œæ¦‚ç‡æ¥è®­ç»ƒæ¨¡å‹</p><script type="math/tex; mode=display">\log\ p(\tau | h) = log \sum_{T âˆˆ \tau}(\Pi^m_{i=1}(p_i[T_i]))</script><blockquote><p>$p_i[T_i]$æ˜¯token iæ‹¥æœ‰æ ‡ç­¾$T_i$çš„æ¦‚ç‡ã€‚</p><p>å½“pä¸º1æ˜¯æŸå¤±æœ€å°ã€‚</p></blockquote><h4 id="Decoding-Spans-from-a-Tagging"><a href="#Decoding-Spans-from-a-Tagging" class="headerlink" title="Decoding Spans from a Tagging"></a>Decoding Spans from a Tagging</h4><script type="math/tex; mode=display">\hat{T} = \underset{Tâˆˆ\nu}{arg\max} (\Pi^m_{i=1}(p_i[T_i]))</script><blockquote><p>$\hat{T}$ï¼šæœ€æœ‰å¯èƒ½çš„æ ‡è®°</p><p>$\nu$ï¼šæ‰€æœ‰æœ‰æ•ˆæ ‡è®°çš„é›†åˆ </p></blockquote><p>å¯¹äº<strong>IO</strong>æ ‡ç­¾ï¼Œæ‰€æœ‰æ ‡ç­¾å‡æœ‰æ•ˆï¼Œå¹¶ä¸”é€šè¿‡ç‹¬ç«‹é¢„æµ‹æ¯ä¸ªtokenä¸­æ¦‚ç‡æœ€é«˜çš„æ ‡ç­¾æ¥å®ç°æœ€å¤§åŒ–ã€‚</p><blockquote><p>ç”±äºç­”æ¡ˆè·¨åº¦åœ¨RCä»»åŠ¡ä¸­ä»ä¸ç›¸é‚»ï¼Œå› æ­¤<strong>IO</strong>æ ‡è®°é€šè¿‡é€‰æ‹©æ‰€æœ‰ä»¥<strong>I</strong>è¿ç»­æ ‡è®°çš„æœ€å¤§è·¨åº¦æ¥ç”Ÿæˆä¸€ç»„è·¨åº¦ã€‚</p></blockquote><h3 id="â€œMulti-Headâ€-Models"><a href="#â€œMulti-Headâ€-Models" class="headerlink" title="â€œMulti-Headâ€ Models"></a>â€œMulti-Headâ€ Models</h3><p>ä¸€äº›RCæ•°æ®é›†åŒ…å«çš„ä¸€äº›é—®é¢˜ï¼Œå…¶è¾“å‡ºä¸ä¸€å®šæ˜¯è·¨åº¦çš„ï¼Œä¾‹å¦‚ï¼šé€šè¿‡ç®—æœ¯è¿ç®—è·å–ç­”æ¡ˆã€‚</p><p>å¯¹æ­¤ä¸€äº›æ¨¡å‹ä½¿ç”¨äº†<strong><em>multi-head architecture</em></strong></p><script type="math/tex; mode=display">p_z(a | q, c) = p_z(a | h)</script><blockquote><p>æ¯ä¸ªhead zæ˜¯ä¸€ä¸ªå°æ¨¡å—ï¼Œå°†ä¸Šä¸‹æ–‡è¡¨ç¤ºhä½œä¸ºè¾“å…¥å¹¶è®¡ç®—ç­”æ¡ˆçš„æ¦‚ç‡åˆ†å¸ƒã€‚</p></blockquote><p>ä¸ºäº†ç¡®å®šå“ªä¸ªé—®é¢˜éœ€è¦ä½¿ç”¨å“ªä¸ªå¤´ï¼Œéœ€è¦è®­ç»ƒä¸€ä¸ªé™„åŠ æ¨¡å‹ï¼š</p><script type="math/tex; mode=display">p_{head}(z | q, c) = p_{head}(z | h)</script><p>ç­”æ¡ˆçš„æ¦‚ç‡åˆ†å¸ƒï¼š</p><script type="math/tex; mode=display">p(a | q, c) = \sum_z p_{head}(z | q, c) Â· p_z(a | q, c)</script><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li><p>DROP</p><blockquote><p>DROPâ€™s leaderboardï¼š<a href="https://leaderboard.allenai.org/drop/submissions/public">https://leaderboard.allenai.org/drop/submissions/public</a></p></blockquote></li><li><p>QUOREF</p></li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210119092212.png" alt="image-20210119092212691"></p><ul><li><p>æ¨¡å‹æ¯”è¾ƒï¼š</p><p>åœ¨DROPä¸Š:</p><p>â€‹        ä½¿ç”¨$BERT<em>{LARGE}$ä½œä¸ºencoderçš„$TASE</em>{BIO}+SSE (BERT<em>{LARGE})$è¶…è¶Šæ‰€æœ‰å¤„ç†multi-span questionsçš„æ¨¡å‹ã€‚ç›¸æ¯”$BERT-C</em>{ALC}$å’Œ$MTMSN$æ•ˆæœè¾ƒä¸ºæ˜¾è‘—ã€‚</p><p>åœ¨QUOREFä¸Š:</p><p>â€‹        å¤„ç†multi-span questionsæ˜¯æ€§èƒ½è¿œè¶…$CorefRoBERTa_{LARGE}$ 20ä¸ªç™¾åˆ†ç‚¹ã€‚</p></li><li><p>è·¨åº¦æå–æ¶æ„æ¯”è¾ƒ</p><p>â€‹        åœ¨DROPå’ŒQUOREFä¸­ï¼Œç”¨å¤šè·¨åº¦æå–æ›¿æ¢å•è·¨åº¦æå–å¯ä»¥æ˜¾è‘—æ”¹å–„å¤šè·¨åº¦é—®é¢˜çš„æ€§èƒ½ï¼Œè€Œå•è·¨åº¦é—®é¢˜çš„æ€§èƒ½è¾ƒä¹‹å‰å˜åŒ–ä¸å¤§ã€‚è¿™è¡¨æ˜å¤šè·¨åº¦æ¶æ„æœ¬èº«å¯ä»¥ç”¨ä½œé€šç”¨è·¨åº¦æå–æ–¹æ³•ã€‚</p></li><li><p>taggingæ–¹æ¡ˆçš„æ•ˆæœæ¯”è¾ƒ</p><p>â€‹        <strong>BIO</strong>å’Œ<strong>IO</strong>æ–¹æ¡ˆï¼Œç»“æœéå¸¸ç›¸ä¼¼ã€‚<strong>IO</strong>ç•¥å ä¼˜åŠ¿ã€‚</p></li></ul><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>â€‹        æœ¬æ–‡æå‡ºçš„çš„$TASE_{IO} + SSE$æ¨¡å‹åœ¨æ•´ä¸ªæµ‹è¯•é›†ä¸Šéƒ½å–å¾—äº†è¾ƒé«˜çš„å¾—åˆ†ã€‚</p><p>â€‹        æœ¬æ–‡å°†å›ç­”å¤šè·¨åº¦é—®é¢˜çš„ä»»åŠ¡ä½œä¸ºåºåˆ—æ ‡è®°é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç®€å•çš„å¯¹åº”å¤šè·¨åº¦ä½“ç³»ç»“æ„ã€‚ ä½¿ç”¨å¤šè·¨åº¦ä½“ç³»ç»“æ„æ›¿æ¢æ ‡å‡†çš„å•è·¨</p><p>åº¦ä½“ç³»ç»“æ„å¯ä»¥æ˜¾è‘—æ”¹å–„å¤šè·¨åº¦é—®é¢˜çš„ç»“æœï¼Œè€Œä¸ä¼šæŸå®³å•è·¨åº¦é—®é¢˜çš„æ€§èƒ½ï¼Œä»è€Œè·å¾—è¾ƒå¥½çš„QUOREFç»“æœã€‚ å°†å¤šè·¨åº¦æ¶æ„é›†æˆåˆ°ç°æœ‰æ¨¡</p><p>å‹ä¸­å¯ä»¥è¿›ä¸€æ­¥æé«˜DROPçš„æ€§èƒ½ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> RC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> DROP </tag>
            
            <tag> QUOREF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>condaåˆ›å»ºæ–°ç¯å¢ƒ</title>
      <link href="/2021/01/19/conda%E5%88%9B%E5%BB%BA%E6%96%B0%E7%8E%AF%E5%A2%83/"/>
      <url>/2021/01/19/conda%E5%88%9B%E5%BB%BA%E6%96%B0%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h1 id="condaåˆ›å»ºæ–°ç¯å¢ƒ"><a href="#condaåˆ›å»ºæ–°ç¯å¢ƒ" class="headerlink" title="condaåˆ›å»ºæ–°ç¯å¢ƒ"></a>condaåˆ›å»ºæ–°ç¯å¢ƒ</h1><h2 id="åˆ›å»ºæ–°ç¯å¢ƒ"><a href="#åˆ›å»ºæ–°ç¯å¢ƒ" class="headerlink" title="åˆ›å»ºæ–°ç¯å¢ƒ"></a>åˆ›å»ºæ–°ç¯å¢ƒ</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n &#x27;ç¯å¢ƒå&#x27; python=3.6</span><br></pre></td></tr></table></figure><h2 id="åˆ é™¤ç¯å¢ƒ"><a href="#åˆ é™¤ç¯å¢ƒ" class="headerlink" title="åˆ é™¤ç¯å¢ƒ"></a>åˆ é™¤ç¯å¢ƒ</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda remove -n &#x27;ç¯å¢ƒå&#x27; --all</span><br></pre></td></tr></table></figure><h2 id="é‡å‘½åç¯å¢ƒ"><a href="#é‡å‘½åç¯å¢ƒ" class="headerlink" title="é‡å‘½åç¯å¢ƒ"></a>é‡å‘½åç¯å¢ƒ</h2><p>conda å…¶å®æ²¡æœ‰é‡å‘½åæŒ‡ä»¤ï¼Œå®ç°é‡å‘½åæ˜¯é€šè¿‡ clone å®Œæˆçš„ï¼Œåˆ†ä¸¤æ­¥ï¼š</p><ol><li>å…ˆ clone ä¸€ä»½ new name çš„ç¯å¢ƒ</li><li>åˆ é™¤ old name çš„ç¯å¢ƒ</li></ol><p>ä¾‹ï¼šæ¯”å¦‚ï¼Œæƒ³æŠŠç¯å¢ƒenv1 é‡å‘½åæˆenv2</p><ul><li>ç¬¬1æ­¥</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n env2 --clone env1</span><br></pre></td></tr></table></figure><ul><li>ç¬¬2æ­¥</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda remove -n env1 --all</span><br></pre></td></tr></table></figure><ul><li>ç»“æœ</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda info -e</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>READING AND ANSWERING GIVEN REASONING PATHS</title>
      <link href="/2021/01/15/READING%20AND%20ANSWERING%20GIVEN%20REASONING%20PATHS/"/>
      <url>/2021/01/15/READING%20AND%20ANSWERING%20GIVEN%20REASONING%20PATHS/</url>
      
        <content type="html"><![CDATA[<h1 id="READING-AND-ANSWERING-GIVEN-REASONING-PATHS"><a href="#READING-AND-ANSWERING-GIVEN-REASONING-PATHS" class="headerlink" title="READING AND ANSWERING GIVEN REASONING PATHS"></a>READING AND ANSWERING GIVEN REASONING PATHS</h1><blockquote><p>reader model</p><p>å¤šä»»åŠ¡é˜…è¯»å™¨æ¨¡å‹</p></blockquote><h2 id="å¤šä»»åŠ¡é˜…è¯»å™¨æ¨¡å‹"><a href="#å¤šä»»åŠ¡é˜…è¯»å™¨æ¨¡å‹" class="headerlink" title="å¤šä»»åŠ¡é˜…è¯»å™¨æ¨¡å‹"></a>å¤šä»»åŠ¡é˜…è¯»å™¨æ¨¡å‹</h2><ul><li><p>é˜…è¯»ç†è§£ä»»åŠ¡</p><blockquote><p>ä½¿ç”¨BERTä»æ¨ç†è·¯å¾„ä¸­æå–ç­”æ¡ˆèŒƒå›´ã€‚</p></blockquote></li><li><p>å¯¹æ¨ç†è·¯å¾„é‡æ’åº</p><blockquote><p> ä½¿ç”¨Bertæ¨¡å‹å¯¹åº”äºCLSæ ‡è¯†ç¬¦ä½çš„è¾“å‡ºåˆ¤æ–­æ¨ç†è·¯å¾„åŒ…æ‹¬ç­”æ¡ˆçš„æ¦‚ç‡ã€‚æ ¹æ®æ¦‚ç‡å¯¹æ¨ç†è·¯å¾„é‡æ–°æ’åºã€‚</p></blockquote></li></ul><script type="math/tex; mode=display">P(E|q) = Ïƒ(w_nÂ· u_E) \ \ s.t. \ \ u_E= BERT_{[CLS]}(q, E) âˆˆ \R^D</script><blockquote><p>$w_nâˆˆ R^D$ï¼šæƒé‡å‘é‡</p><p>$P(E|q)$ï¼šæ¨ç†è·¯å¾„Eçš„æ¦‚ç‡</p></blockquote><script type="math/tex; mode=display">E_{best}=\underset{EâˆˆE} {arg\ max } \ P(E|q)</script><blockquote><p>$E_{best}$ï¼šæœ€ä½³è·¯å¾„</p></blockquote><script type="math/tex; mode=display">S_{read}= \underset{i,j, iâ‰¤j}{arg \ max}\   P^{start}_i P^{end}_j</script><blockquote><p>$S_{read}$ï¼šæ­£ç¡®ç­”æ¡ˆçš„èŒƒå›´</p><p>$P^{start}<em>iï¼ŒP^{end}_j$è¡¨ç¤º$E</em>{best}$ä¸­ç¬¬iä¸ªtokenå’Œç¬¬jä¸ªtokenåˆ†åˆ«ä¸ºå¼€å§‹ä½ç½®å’Œç»“æŸä½ç½®çš„æ¦‚ç‡</p></blockquote><ul><li>å¢åŠ è´Ÿä¾‹æ•°æ®ï¼š</li></ul><p>â€‹    ä¸ºäº†è®­ç»ƒæˆ‘ä»¬çš„è¯»è€…æ¨¡å‹æ¥åŒºåˆ†ç›¸å…³å’Œä¸ç›¸å…³çš„æ¨ç†è·¯å¾„ï¼Œæˆ‘ä»¬å¯¹åŸå§‹è®­ç»ƒæ•°æ®è¿›è¡Œäº†è¡¥å……ï¼Œå¹¶é™„åŠ äº†å…¶ä»–è´Ÿé¢ç¤ºä¾‹æ¥æ¨¡æ‹Ÿä¸å®Œå…¨çš„è¯æ®ã€‚</p><ul><li>æŸå¤±å‡½æ•°</li></ul><p>ç›®æ ‡æ˜¯è·¨åº¦é¢„æµ‹å’Œé‡æ–°æ’åºä»»åŠ¡çš„äº¤å‰ç†µæŸå¤±ä¹‹å’Œã€‚ é—®é¢˜qåŠå…¶å€™é€‰è¯æ®Eçš„æŸå¤±:</p><script type="math/tex; mode=display">L_{read}= L_{span}+ L_{no\_answer}= (âˆ’ log P^{start}_{y^{start}} âˆ’ log P^{end}_{y^{end}}) âˆ’ log P^r</script><blockquote><p>$y^{start}, y^{end}$æ˜¯ ground-truthçš„å¼€å§‹å’Œç»“æŸã€‚</p><p>$L_{no_answer}$ï¼šé‡æ–°re-ranking modelçš„æŸå¤±ï¼Œè¾¨åˆ«æ²¡æœ‰ç­”æ¡ˆçš„å¤±çœŸæ¨ç†è·¯å¾„ã€‚</p><p>$P^r$ï¼š if E is the ground-truth evidence;   $P^r= P(E|q)$,otherwise $P^r= 1 âˆ’ P(E|q)$.</p></blockquote><p>å±è”½äº†è´Ÿæ ·æœ¬è·¨åº¦æŸå¤±ï¼Œä»¥é¿å…å¯¹è·¨åº¦é¢„æµ‹äº§ç”Ÿæ„å¤–å½±å“ã€‚</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p>ä¼˜åŒ–å™¨ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">optimizer = BertAdam(optimizer_grouped_parameters,</span><br><span class="line">                                 lr=args.learning_rate,</span><br><span class="line">                                 warmup=args.warmup_proportion,</span><br><span class="line">                                 t_total=num_train_optimization_steps)</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨dataloaderåŠ è½½è®­ç»ƒæ•°æ®</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_sampler = DistributedSampler(train_data)</span><br><span class="line">        train_dataloader = DataLoader(</span><br><span class="line">            train_data, sampler=train_sampler, batch_size=args.train_batch_size)</span><br></pre></td></tr></table></figure><p>æ˜¾ç¤ºè¿›åº¦</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for _ in trange(int(args.num_train_epochs), desc=&quot;Epoch&quot;):</span><br></pre></td></tr></table></figure><blockquote><p> Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03&lt;00:00,  1.00s/it]</p></blockquote><p>åˆ›å»ºæ¨¡å‹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = BertForQuestionAnsweringConfidence.from_pretrained(args.bert_model,</span><br><span class="line">                                                                   cache_dir=os.path.join(</span><br><span class="line">                                                                       str(PYTORCH_PRETRAINED_BERT_CACHE), &#x27;distributed_&#123;&#125;&#x27;.format(args.local_rank)),</span><br><span class="line">                                                                   num_labels=4,</span><br><span class="line">                                                                   no_masking=args.no_masking,</span><br><span class="line">                                                                   lambda_scale=args.lambda_scale)</span><br></pre></td></tr></table></figure><p>æŸå¤±å‡½æ•°</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask,</span><br><span class="line">                             start_positions=start_positions, end_positions=end_positions, switch_list=switches)</span><br></pre></td></tr></table></figure><p>$L<em>{span}+L</em>{no_answer}$</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">span_mask = (switch_list == 0).type(torch.FloatTensor).cuda()</span><br><span class="line">start_losses = loss_fct(</span><br><span class="line">                    start_logits, start_positions) * span_mask</span><br><span class="line">end_losses = loss_fct(end_logits, end_positions) * span_mask</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">collections.OrderedDict()#å®ç°å¯¹å­—å…¸å…ƒç´ æ’åº</span><br><span class="line">collections.namedtuple()#ç±»ä¼¼äºç»“æ„ä½“çš„ç”¨æ³•</span><br><span class="line">json.dumps()#å°†pythonå¯¹è±¡ç¼–ç æˆJsonå­—ç¬¦ä¸²</span><br></pre></td></tr></table></figure><p>ä»…ä½¿ç”¨å¯ä»¥æ‰¾å¤§ç­”æ¡ˆçš„é—®é¢˜</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">actual_text = &quot; &quot;.join(</span><br><span class="line">    doc_tokens[start_position:(end_position + 1)])</span><br><span class="line">cleaned_answer_text = &quot; &quot;.join(</span><br><span class="line">    whitespace_tokenize(orig_answer_text))</span><br><span class="line">if actual_text.find(cleaned_answer_text) == -1:</span><br><span class="line">    logger.warning(&quot;Could not find answer: &#x27;%s&#x27; vs. &#x27;%s&#x27;&quot;,</span><br><span class="line">                   actual_text, cleaned_answer_text)</span><br><span class="line">    continue</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>è¿‡æ»¤æ‰è¿‡é•¿çš„é—®é¢˜</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if len(orig_answer_text.split()) &gt; max_answer_len:</span><br><span class="line">    logger.info(</span><br><span class="line">        &quot;Omitting a long answer: &#x27;%s&#x27;&quot;, orig_answer_text)</span><br><span class="line">    continue</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_train_optimization_steps // int(save_chunk) #ç»“æœå–æ•´æ•°</span><br></pre></td></tr></table></figure><p>å°†ç­”æ¡ˆèŒƒå›´è®¾ç½®ä¸ºä¸aåŒ¹é…å¹¶é¦–å…ˆå‡ºç°çš„å­—ç¬¦ä¸²ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for i in range(len(index_and_score)):</span><br><span class="line">    if i &gt;= n_best_size:</span><br><span class="line">        break</span><br><span class="line">    best_indexes.append(index_and_score[i][0])</span><br></pre></td></tr></table></figure><p>BRETè¾“å…¥ç¤ºä¾‹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokens: [CLS] this singer of a rather blu ##ster ##y day also voiced what hedge ##hog ? [SEP] &quot; a rather blu ##ster ##y day &quot; is a w ##him ##sic ##al song from the walt disney musical film feature ##tte , &quot; winnie the po ##oh and the blu ##ster ##y day &quot; . it was written by robert &amp; richard sherman and sung by jim cummings as &quot; po ##oh &quot; . james jonah cummings ( born november 3 , 1952 ) is an american voice actor and singer , who has appeared in almost 400 roles . he is known for vo ##icing the title character from &quot; dark ##wing duck &quot; , dr . robot ##nik from &quot; sonic the hedge ##hog &quot; , and pete . his other characters include winnie the po ##oh , ti ##gger , and the tasmanian devil . he has performed in numerous disney and dream ##works animation ##s including &quot; ala ##ddin &quot; , &quot; the lion king &quot; , &quot; bal ##to &quot; , &quot; ant ##z &quot; , &quot; the road to el dora ##do &quot; , &quot; sh ##rek &quot; , and &quot; the princess and the frog &quot; . he has also provided voice - over work for video games , such as &quot; ice ##wind dale &quot; , &quot; fallout &quot; , &quot; &quot; , &quot; bald ##ur &#x27; s gate &quot; , &quot; mass effect 2 &quot; , &quot; &quot; , &quot; &quot; , &quot; &quot; , and &quot; sp ##lat ##ter ##house &quot; . [SEP]</span><br></pre></td></tr></table></figure><p>è¾“å…¥é•¿åº¦ä¸è¶³è¡¥0</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">while len(input_ids) &lt; max_seq_length:</span><br><span class="line">    input_ids.append(pad_token)</span><br><span class="line">    input_mask.append(0 if mask_padding_with_zero else 1)</span><br><span class="line">    segment_ids.append(pad_token_segment_id)</span><br><span class="line">    p_mask.append(1)</span><br></pre></td></tr></table></figure><p>ç¤ºä¾‹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br></pre></td></tr></table></figure><h2 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h2><p>ä¸‹è½½ç¨‹åº</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!git clone https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths.git</span><br><span class="line">%cd /content/learning_to_retrieve_reasoning_paths</span><br><span class="line">!pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>ä¸‹è½½è®­ç»ƒæ•°æ®</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths</span><br><span class="line">!mkdir data</span><br><span class="line">%cd data</span><br><span class="line">!mkdir hotpot</span><br><span class="line">%cd hotpot</span><br><span class="line">!gdown https://drive.google.com/uc?id=1_a8KliAHKIwrYRrHgHOlzM0Jon3AqZLs</span><br><span class="line">!mv hotpot_reader_train_data.json.json____ hotpot_reader_train_data.json</span><br><span class="line">!gdown https://drive.google.com/uc?id=1R4exuPDaV2yD18xUBsnNyQpXwn0ty5pc</span><br><span class="line">!mv nq_reader_train_data_public.json.json____ nq_reader_train_data_public.json</span><br><span class="line">!gdown https://drive.google.com/uc?id=1FB5gB9aM8rmbpIwYf-1o6lmxMYQsg_rP</span><br><span class="line">!mv squad_reader_train_data.json.json____ squad_reader_train_data.json</span><br><span class="line">!gdown https://drive.google.com/uc?id=1MysthH2TRYoJcK_eLOueoLeYR42T-JhB</span><br><span class="line">!ls</span><br></pre></td></tr></table></figure><p><strong>è®­ç»ƒæ¨¡å‹</strong></p><blockquote><p>æ•°æ®é›†å‡é‡‡ç”¨SQuAD v.2 format</p><p>ä½¿ç”¨hotpot_dev_squad_v2.0_format.jsonè®­ç»ƒ</p><p>hotpot_reader_train_data.jsonå¤ªå¤§è®­ç»ƒä¸å‡ºæ¥ï¼Œè¿™é‡Œç”¨hotpot_dev_squad_v2.0_format.jsonåªæ˜¯ä¸ºäº†ä½“éªŒä¸‹è®­ç»ƒçš„è¿‡ç¨‹ï¼</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths/reader/</span><br><span class="line">!python run_reader_confidence.py \</span><br><span class="line">--bert_model bert-base-uncased \</span><br><span class="line">--output_dir output_hotpot_bert_base \</span><br><span class="line">--train_file /content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json \</span><br><span class="line">--predict_file /content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json \</span><br><span class="line">--max_seq_length 384 \</span><br><span class="line">--do_train \</span><br><span class="line">--do_predict \</span><br><span class="line">--do_lower_case \</span><br><span class="line">--version_2_with_negative \</span><br><span class="line">--train_batch_size 16</span><br></pre></td></tr></table></figure><blockquote><p>â€”train_batch_size æ ¹æ®æ˜¾å¡å†…å­˜è°ƒæ•´</p><p>â€”version_2_with_negative ä½¿ç”¨è´Ÿä¾‹æ•°æ®è®­ç»ƒ</p></blockquote><p>ä»…è®­ç»ƒ</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths/reader/</span><br><span class="line">!python run_reader_confidence.py \</span><br><span class="line">--bert_model bert-base-uncased \</span><br><span class="line">--output_dir output_hotpot_bert_base \</span><br><span class="line">--train_file /content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json \</span><br><span class="line">--max_seq_length 384 \</span><br><span class="line">--do_train \</span><br><span class="line">--do_lower_case \</span><br><span class="line">--version_2_with_negative \</span><br><span class="line">--train_batch_size 16</span><br></pre></td></tr></table></figure><p>ä»…é¢„æµ‹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths/reader/</span><br><span class="line">!python run_reader_confidence.py \</span><br><span class="line">--bert_model bert-base-uncased \</span><br><span class="line">--output_dir output_hotpot_bert_base \</span><br><span class="line">--predict_file /content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json \</span><br><span class="line">--max_seq_length 384 \</span><br><span class="line">--do_predict \</span><br><span class="line">--do_lower_case \</span><br><span class="line">--version_2_with_negative \</span><br><span class="line">--train_batch_size 16</span><br></pre></td></tr></table></figure><p><strong>è¯„ä¼°</strong></p><p>ä¸‹è½½è¯„ä¼°æ•°æ®é›†</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths</span><br><span class="line">!mkdir data</span><br><span class="line">%cd data</span><br><span class="line">!mkdir hotpot</span><br><span class="line">%cd hotpot</span><br><span class="line">!gdown https://drive.google.com/uc?id=1MysthH2TRYoJcK_eLOueoLeYR42T-JhB</span><br><span class="line">!ls</span><br></pre></td></tr></table></figure><p>è¯„ä¼°æ¨¡å‹</p><blockquote><p>predictions.json ä¸ºæ¨¡å‹é¢„æµ‹åè‡ªåŠ¨ç”Ÿæˆ</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths/reader/</span><br><span class="line">!wget https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/</span><br><span class="line">!mv index.html evaluate-v2.0.py</span><br><span class="line">!python evaluate-v2.0.py \</span><br><span class="line">/content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json \</span><br><span class="line">/content/learning_to_retrieve_reasoning_paths/reader/output_hotpot_bert_base/predictions.json</span><br></pre></td></tr></table></figure><blockquote><p>è¯„ä¼°æ•°æ®ï¼š/content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> è½¯ä»¶å¼€å‘&amp;æ¨¡å‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> BERT </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GRAPH-BASED RECURRENT RETRIEVER</title>
      <link href="/2021/01/09/GRAPH-BASED%20RECURRENT%20RETRIEVER/"/>
      <url>/2021/01/09/GRAPH-BASED%20RECURRENT%20RETRIEVER/</url>
      
        <content type="html"><![CDATA[<h2 id="GRAPH-BASED-RECURRENT-RETRIEVER"><a href="#GRAPH-BASED-RECURRENT-RETRIEVER" class="headerlink" title="GRAPH-BASED RECURRENT RETRIEVER"></a>GRAPH-BASED RECURRENT RETRIEVER</h2><blockquote><p>a new graph-based recurrent retrieval method</p><p>æŸ¥æ‰¾è¯æ®æ–‡æ¡£ä½œä¸ºå›ç­”å¤æ‚é—®é¢˜çš„æ¨ç†è·¯å¾„ã€‚</p></blockquote><script type="math/tex; mode=display">w_i=BERT_{CLS}(q,p_i) \in \R^d</script><script type="math/tex; mode=display">P(p_i|h_t)=\sigma(w_iÂ·h_t+b)</script><script type="math/tex; mode=display">h_{t=1}=RNN(h_t,w_i) \in \R^d</script><blockquote><p>bï¼šåç½®é¡¹</p></blockquote><ul><li>ä½¿ç”¨RNNå»ºæ¨¡é—®é¢˜$Q$çš„æ¨ç†è·¯å¾„ã€‚</li><li>ç»™å®šé—®é¢˜$q$ï¼Œåœ¨æ—¶é—´æ­¥$t$æ—¶ï¼Œæ¨¡å‹ä»å€™é€‰æ®µè½é›†$C_t$ä¸­æ‰¾å‡º$p_i$ ï¼Œä¸$q$æ‹¼æ¥è®¡ç®—$p_i$çš„æ¦‚ç‡ã€‚</li><li>é‡åˆ°$[EOE]$æ—¶ç»“æŸæ¨ç†ï¼Œå…è®¸å®ƒåœ¨ç»™å®šæ¯ä¸ªé—®é¢˜çš„æƒ…å†µä¸‹æ•è·å…·æœ‰ä»»æ„é•¿åº¦çš„æ¨ç†è·¯å¾„ã€‚</li></ul><h3 id="æœ¬æ–‡BERTç»“æ„ï¼š"><a href="#æœ¬æ–‡BERTç»“æ„ï¼š" class="headerlink" title="æœ¬æ–‡BERTç»“æ„ï¼š"></a>æœ¬æ–‡BERTç»“æ„ï¼š</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210108150704.png" alt="image-20210108150704041" style="zoom:50%;" /></p><h3 id="RNNç»“æ„ï¼š"><a href="#RNNç»“æ„ï¼š" class="headerlink" title="RNNç»“æ„ï¼š"></a>RNNç»“æ„ï¼š</h3><p>$P(p_i|h_t)$ï¼šè¡¨ç¤ºåœ¨æ—¶é—´æ­¥$t$é€‰æ‹©æ®µè½$p_i$çš„æ¦‚ç‡ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210108151355.png" alt="image-20210108151355616" style="zoom:50%;" /></p><p>æœ€ç»ˆå¾—åˆ°æ¨ç†è·¯å¾„ã€$p_1,p_2$ã€‘</p><p>beam search </p><ul><li>é€šè¿‡æŸæœç´¢å¾—åˆ°ç»™å®šæ—¶é—´æ­¥é•¿çš„æœ‰é™æ•°é‡çš„æœ€å¯èƒ½æ¨ç†è·¯å¾„ï¼Œå‡å°è¾“å…¥BERTçš„æ•°æ®é‡ï¼Œå‡å°è®¡ç®—é‡ã€‚</li><li>$C_1$æ˜¯ç”¨åœ¨è¾“å…¥é—®é¢˜ä¸Š TF-IDF å¾—åˆ†æœ€é«˜çš„æ®µè½ã€‚</li><li>$C_t$æ˜¯åœ¨C_1åŸºç¡€ä¸Šï¼Œæ‹“å±•çš„è¿æ¥æ®µè½ï¼Œç”¨è¾“å…¥åˆ°BERTã€‚</li><li>æ¨ç†è·¯å¾„$E = [p<em>i, . . . , p_k]$ä¹˜æ®µè½æ¦‚ç‡$P(p_i|h_1) . . . P(p_k|h</em>{|E|})$å¾—åˆ°beam search çš„è¾“å‡ºï¼Œå³å¾—åˆ°top B æ¨ç†è·¯å¾„ $E = {E_1, . . . , E_B}$ä½œä¸ºBERTè¾“å…¥ï¼Œå†å°†BERTè¾“å‡ºä½œä¸ºRNNè¾“å…¥ã€‚</li></ul><h2 id="BERTç›¸å…³"><a href="#BERTç›¸å…³" class="headerlink" title="BERTç›¸å…³"></a>BERTç›¸å…³</h2><blockquote><p>Bidirectional Encoder Representations from Transformers</p><p>æ˜¯Googleä»¥æ— ç›‘ç£çš„æ–¹å¼åˆ©ç”¨å¤§é‡æ— æ ‡æ³¨æ–‡æœ¬è®­ç»ƒçš„çš„è¯­è¨€ä»£è¡¨æ¨¡å‹ï¼Œå…¶æ¶æ„ä¸ºTransformerä¸­çš„Encoderã€‚</p></blockquote><ul><li><a href="https://youtu.be/UYPa347-DdE">è®²è§£è§†é¢‘</a>ï¼š<a href="https://youtu.be/UYPa347-DdE">https://youtu.be/UYPa347-DdE</a></li></ul><iframe         width="900"         height="675"         src="https://www.youtube.com/embed/UYPa347-DdE"         frameborder="0"         allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"         allowfullscreen></iframe><ul><li>ä½¿ç”¨BERTé¢„è®­ç»ƒæ¨¡å‹<code>bert-base-uncased</code>ä¸åŒºåˆ†å¤§å°å†™ã€‚</li></ul><p>BERT é‡Œ5ä¸ªç‰¹æ®Štokensï¼š</p><ol><li>[CLS]ï¼šåœ¨åšåˆ†ç±»ä»»åŠ¡æ—¶å…¶æœ€åä¸€å±‚çš„repr. ä¼šè¢«è§†ä¸ºæ•´ä¸ªè¾“å…¥åºåˆ—çš„reprã€‚</li></ol><blockquote><p>repræŒ‡çš„éƒ½æ˜¯ä¸€ä¸ªå¯ä»¥ç”¨æ¥ä»£è¡¨æŸè¯æ±‡ï¼ˆåœ¨æŸä¸ªè¯­å¢ƒä¸‹ï¼‰çš„å¤šç»´è¿ç»­å‘é‡ï¼ˆcontinuous vectorï¼‰ã€‚</p></blockquote><ol><li>[SEP]ï¼šæœ‰ä¸¤ä¸ªå¥å­çš„æ–‡æœ¬ä¼šè¢«ä¸²æ¥æˆä¸€ä¸ªè¾“å…¥åºåˆ—ï¼Œå¹¶åœ¨ä¸¤å¥ä¹‹é—´æ’å…¥è¿™ä¸ªtoken ä»¥åšåŒºéš”ã€‚</li><li>[UNK]ï¼šæ²¡å‡ºç°åœ¨BERT å­—å…¸é‡Œå¤´çš„å­—ä¼šè¢«è¿™ä¸ªtoken å–ä»£ã€‚</li><li>[PAD]ï¼šzero padding é®ç½©ï¼Œå°†é•¿åº¦ä¸ä¸€çš„è¾“å…¥åºåˆ—è¡¥é½æ–¹ä¾¿åšbatch è¿ç®—ã€‚</li><li>[MASK]ï¼šæœªçŸ¥é®ç½©ï¼Œä»…åœ¨é¢„è®­ç»ƒé˜¶æ®µä¼šç”¨åˆ°ã€‚</li></ol><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p>åŠ è½½BERTé¢„è®­ç»ƒæ¨¡å‹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = BertForGraphRetriever.from_pretrained(args.bert_model,cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / &#x27;distributed_&#123;&#125;&#x27;.format(-1),graph_retriever_config=graph_retriever_config)</span><br></pre></td></tr></table></figure><blockquote><p>é»˜è®¤ä»ç¼“å­˜ä¸­åŠ è½½ï¼Œä¸‹è½½ä¹‹åæºç ä¸­æ›¿æ¢è‡ªå·±æœ¬åœ°è·¯å¾„å³å¯ã€‚</p></blockquote><ul><li>any() å‡½æ•°ç”¨äºåˆ¤æ–­ç»™å®šçš„å¯è¿­ä»£å‚æ•° iterable æ˜¯å¦å…¨éƒ¨ä¸º Falseï¼Œåˆ™è¿”å› Falseï¼Œå¦‚æœæœ‰ä¸€ä¸ªä¸º Trueï¼Œåˆ™è¿”å› Trueã€‚</li></ul><p>ä½¿ç”¨BertAdamè‡ªå®šä¹‰Adamä¼˜åŒ–å™¨</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">optimizer = BertAdam(optimizer_grouped_parameters,</span><br><span class="line">                             lr=args.learning_rate,</span><br><span class="line">                             warmup=args.warmup_proportion,</span><br><span class="line">                             t_total=t_total,</span><br><span class="line">                             max_grad_norm=1.0)</span><br></pre></td></tr></table></figure><blockquote><p>åœ¨å‰10%çš„stepsä¸­ï¼Œlrä»0çº¿æ€§å¢åŠ åˆ° init_learning_rateï¼Œè¿™ä¸ªé˜¶æ®µåˆå« warmupï¼Œç„¶åï¼Œlråˆä» init_learning_rate çº¿æ€§è¡°å‡åˆ°0ï¼ˆå®Œæˆæ‰€æœ‰stepsï¼‰ã€‚</p></blockquote><p>å¯¹é—®é¢˜å’Œæ®µè½åŠ ä¸Š[CLS],[SEP]</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">def tokenize_question(question, tokenizer):</span><br><span class="line">    tokens_q = tokenizer.tokenize(question)</span><br><span class="line">    tokens_q = [&#x27;[CLS]&#x27;] + tokens_q + [&#x27;[SEP]&#x27;]</span><br><span class="line"></span><br><span class="line">    return tokens_q</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def tokenize_paragraph(p, tokens_q, max_seq_length, tokenizer):</span><br><span class="line">    tokens_p = tokenizer.tokenize(p)[:max_seq_length - len(tokens_q) - 1]</span><br><span class="line">    tokens_p = tokens_p + [&#x27;[SEP]&#x27;]</span><br><span class="line"></span><br><span class="line">    padding = [0] * (max_seq_length - len(tokens_p) - len(tokens_q))</span><br><span class="line"></span><br><span class="line">    input_ids_ = tokenizer.convert_tokens_to_ids(tokens_q + tokens_p)</span><br><span class="line">    input_masks_ = [1] * len(input_ids_)</span><br><span class="line">    segment_ids_ = [0] * len(tokens_q) + [1] * len(tokens_p)</span><br><span class="line"></span><br><span class="line">    input_ids_ += padding</span><br><span class="line">    input_masks_ += padding</span><br><span class="line">    segment_ids_ += padding</span><br><span class="line"></span><br><span class="line">    assert len(input_ids_) == max_seq_length</span><br><span class="line">    assert len(input_masks_) == max_seq_length</span><br><span class="line">    assert len(segment_ids_) == max_seq_length</span><br><span class="line"></span><br><span class="line">    return input_ids_, input_masks_, segment_ids_</span><br></pre></td></tr></table></figure><p>RNNåˆå§‹åŒ–</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.rw = nn.Linear(2 * config.hidden_size, config.hidden_size)</span><br></pre></td></tr></table></figure><p>é€šè¿‡beam search æ‰¾å‡ºtop B æ¨ç†è·¯å¾„</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">b = 0</span><br><span class="line">while b &lt; beam:</span><br><span class="line">    s, p = torch.max(score.view(score.size(0) * score.size(1)), dim=0)</span><br><span class="line">    s = s.item()</span><br><span class="line">    p = p.item()</span><br><span class="line">    row = p // score.size(1)</span><br><span class="line">    col = p % score.size(1)</span><br><span class="line"></span><br><span class="line">    if j == 0:</span><br><span class="line">        score[:, col] = 0.0</span><br><span class="line">    else:</span><br><span class="line">        score[row, col] = 0.0</span><br><span class="line"></span><br><span class="line">    p = [[index for index in pred_[row][0]] + [col],</span><br><span class="line">         output[row].topk(k=2, dim=0)[1].tolist(),</span><br><span class="line">         s]</span><br><span class="line">    new_pred_.append(p)</span><br><span class="line"></span><br><span class="line">    p = [[p_ for p_ in prb] for prb in prob_[row]] + [output[row].tolist()]</span><br><span class="line">    new_prob_.append(p)</span><br><span class="line"></span><br><span class="line">    state_tmp[b].copy_(state_[row])</span><br><span class="line">    b += 1</span><br></pre></td></tr></table></figure><h2 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h2><p>ä¸‹è½½ç¨‹åºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!git clone https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths.git</span><br><span class="line">%cd /content/learning_to_retrieve_reasoning_paths</span><br><span class="line">!pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>ä¸‹è½½æ•°æ®é›†</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths</span><br><span class="line">!mkdir data</span><br><span class="line">%cd data</span><br><span class="line">!mkdir hotpot</span><br><span class="line">%cd hotpot</span><br><span class="line">!gdown https://drive.google.com/uc?id=1AIRo66I2Izs80nNLt4MaLu7kqhTuIQ0u</span><br><span class="line">!unzip hotpotqa_new_selector_train_data_db_2017_10_12_fix.zip.zip____</span><br><span class="line">!rm hotpotqa_new_selector_train_data_db_2017_10_12_fix.zip.zip____</span><br></pre></td></tr></table></figure><p>è®­ç»ƒæ¨¡å‹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths/graph_retriever</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">!python3 run_graph_retriever.py \</span><br><span class="line">--task hotpot_distractor \</span><br><span class="line">--bert_model bert-base-uncased --do_lower_case \</span><br><span class="line">--train_file_path /content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpotqa_new_selector_train_data_db_2017_10_12_fix/db=wiki_hotpotqa.db_hotpotqa_new_test_tfidf_k=50.pruning_l=100_tag_me=True.prune_after_agg=False.prune_in_article=False_use_link=True_start=0_end=5000.json \</span><br><span class="line">--output_dir graph_retriever/ \</span><br><span class="line">--max_para_num 10 \</span><br><span class="line">--neg_chunk 8 --train_batch_size 4 --gradient_accumulation_steps 4 \</span><br><span class="line">--learning_rate 3e-5 --num_train_epochs 3 \</span><br><span class="line">--max_select_num 3</span><br></pre></td></tr></table></figure><blockquote><ul><li><p>â€”max_para_numï¼šä¸é—®é¢˜ç›¸å…³çš„æ®µè½æ•°é‡ã€‚å¦‚æœâ€”max_para_numæ˜¯nï¼Œé—®é¢˜çš„åŸºç¡€çœŸå®æ®µè½æ•°é‡æ˜¯k(2)ï¼Œé‚£ä¹ˆæœ‰n-2ä¸ªæ®µè½ä½œä¸ºè®­ç»ƒçš„åä¾‹ã€‚æ­¤æ—¶åä¾‹æ•°é‡ä¸º8ã€‚</p></li><li><p>â€”neg_chunkï¼šä¸ºäº†æ§åˆ¶GPUå†…å­˜æ¶ˆè€—ï¼Œå°†è´Ÿä¾‹æ‹†åˆ†ä¸ºå°å—ã€‚</p></li><li>â€”max_select_numï¼šæŒ‡å®šæ¨¡å‹æ¨ç†æ­¥éª¤çš„æœ€å¤§æ•°é‡ï¼Œå¦‚æœé—®é¢˜çš„åŸºç¡€çœŸå®æ®µè½æ•°é‡æ˜¯kï¼Œè¿™ä¸ªå€¼åº”è¯¥ä¸ºk+1ï¼Œ1è¡¨ç¤ºç»“æŸç¬¦å·EOEï¼Œæ­¤æ—¶k+1=3ã€‚</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> è½¯ä»¶å¼€å‘&amp;æ¨¡å‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> BERT </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è°·æ­Œç¿»è¯‘æ¥å£</title>
      <link href="/2021/01/08/%E8%B0%B7%E6%AD%8C%E7%BF%BB%E8%AF%91%E6%8E%A5%E5%8F%A3/"/>
      <url>/2021/01/08/%E8%B0%B7%E6%AD%8C%E7%BF%BB%E8%AF%91%E6%8E%A5%E5%8F%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="è°·æ­Œç¿»è¯‘æ¥å£"><a href="#è°·æ­Œç¿»è¯‘æ¥å£" class="headerlink" title="è°·æ­Œç¿»è¯‘æ¥å£"></a>è°·æ­Œç¿»è¯‘æ¥å£</h1><h2 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install google_trans_new</span><br></pre></td></tr></table></figure><h2 id="æµ‹è¯•"><a href="#æµ‹è¯•" class="headerlink" title="æµ‹è¯•"></a>æµ‹è¯•</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from google_trans_new import  google_translator  </span><br><span class="line"></span><br><span class="line">translator = google_translator()  </span><br><span class="line">translate_text = translator.translate(&#x27;ç¾å›½ä¸‹ä¸€å±Šæ€»ç»Ÿå°†ä¼šæ˜¯è°ï¼Ÿ&#x27;,lang_src=&#x27;zh-cn&#x27;,lang_tgt=&#x27;en&#x27;)  </span><br><span class="line">print(translate_text)</span><br></pre></td></tr></table></figure><blockquote><p>é»˜è®¤è‡ªåŠ¨æ£€æµ‹è¯­ç§</p></blockquote><h2 id="æ•ˆæœ"><a href="#æ•ˆæœ" class="headerlink" title="æ•ˆæœ"></a>æ•ˆæœ</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Who will be the next president of the United States? </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ•™ç¨‹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SRLGRN</title>
      <link href="/2020/12/31/SRLGRN/"/>
      <url>/2020/12/31/SRLGRN/</url>
      
        <content type="html"><![CDATA[<h1 id="SRLGRN"><a href="#SRLGRN" class="headerlink" title="SRLGRN"></a>SRLGRN</h1><blockquote><p>è®ºæ–‡ï¼šEMNLP2020-Semantic Role Labeling Graph Reasoning Network</p><p>è¯­ä¹‰è§’è‰²æ ‡æ³¨å›¾æ¨ç†ç½‘ç»œ</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>â€‹        æå‡ºäº†ä¸€ä¸ªåŸºäºå¥å­è¯­ä¹‰ç»“æ„çš„å›¾æ¨ç†ç½‘ç»œæ¥å­¦ä¹ è·¨æ®µè½æ¨ç†è·¯å¾„ï¼Œå¹¶è”åˆå¯»æ‰¾æ”¯æŒäº‹å®å’Œç­”æ¡ˆã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><h3 id="SRLGRN-1"><a href="#SRLGRN-1" class="headerlink" title="SRLGRN"></a>SRLGRN</h3><blockquote><p>è¯¥æ¡†æ¶åœ¨æ„å»ºæ¨ç†å›¾ç½‘ç»œæ—¶ä¼šè€ƒè™‘å¥å­çš„è¯­ä¹‰ç»“æ„ã€‚ ä¸ä»…åˆ©ç”¨èŠ‚ç‚¹çš„è¯­ä¹‰è§’è‰²ï¼Œè€Œä¸”ä¼šåˆ©ç”¨è¾¹ç¼˜çš„è¯­ä¹‰ã€‚</p></blockquote><ul><li><p>è®­ç»ƒä¸€ä¸ªæ®µè½é€‰æ‹©æ¨¡å—æ¥æ£€ç´¢gold documentså¹¶æœ€å°åŒ–å¹²æ‰°å› ç´ ã€‚</p></li><li><p>æ„å»ºäº†ä¸€ä¸ªå¼‚ç±»æ–‡æ¡£çº§å›¾ï¼Œå…¶ä¸­åŒ…å«ä»¥å¥å­ä¸ºèŠ‚ç‚¹ä»¥åŠSRLå­å›¾ï¼Œå…¶ä¸­SRLå­å›¾åŒ…æ‹¬è¯­ä¹‰è§’è‰²æ ‡ç­¾å‚æ•°ä½œä¸ºèŠ‚ç‚¹ï¼Œè°“è¯ä½œä¸ºè¾¹ã€‚</p></li><li><p>è®­ç»ƒå›¾ç¼–ç å™¨æ¥è·å¾—å›¾èŠ‚ç‚¹è¡¨ç¤ºï¼Œè¯¥å›¾èŠ‚ç‚¹è¡¨ç¤ºåœ¨å­¦ä¹ çš„è¡¨ç¤ºä¸­ç»“åˆäº†å‚æ•°ç±»å‹å’Œè°“è¯è¾¹çš„è¯­ä¹‰ã€‚</p></li><li><p>æœ€åï¼Œå…±åŒè®­ç»ƒä¸€ä¸ªmulti-hop supporting fact prediction moduleå’Œanswer prediction moduleã€‚</p><blockquote><p>multi-hop supporting fact prediction moduleå¯ä»¥æ‰¾åˆ°è·¨æ®µè½æ¨ç†è·¯å¾„ï¼Œanswer prediction moduleå¯ä»¥å¾—åˆ°æœ€ç»ˆç­”æ¡ˆã€‚</p><p>based on contextual semantics graph representations as well as token-level BERT pre-trained representations.</p></blockquote></li></ul><p>æ¨¡å‹ç»“æ„ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201230205729.png" alt="image-20201230205718629"></p><blockquote><p>SRLGRNç”±æ®µè½é€‰æ‹©ï¼Œå›¾å½¢æ„é€ ï¼Œå›¾å½¢ç¼–ç å™¨ï¼Œæ”¯æŒäº‹å®é¢„æµ‹å’Œç­”æ¡ˆè·¨åº¦é¢„æµ‹æ¨¡å—ç»„æˆã€‚</p></blockquote><h3 id="Paragraph-Selection"><a href="#Paragraph-Selection" class="headerlink" title="Paragraph Selection"></a>Paragraph Selection</h3><ul><li>based on the pre-trained BERT model</li></ul><p>ä¸¤è½®è§£é‡Šï¼š</p><h4 id="First-Round-Paragraph-Selection"><a href="#First-Round-Paragraph-Selection" class="headerlink" title="First Round Paragraph Selection"></a>First Round Paragraph Selection</h4><p>input:$Q_1$</p><script type="math/tex; mode=display">Q_1= [[CLS]; q; [SEP]; C]</script><blockquote><p>q: question</p><p>C: paragraph content</p></blockquote><script type="math/tex; mode=display">C = \{t, s_1, . . . , s_n\}</script><blockquote><p>t: title</p><p>$s_n$: sentences</p></blockquote><ul><li>å°†$Q_1$è¾“å…¥åˆ°é¢„è®­ç»ƒçš„BERTç¼–ç å™¨ä»¥è·å¾—tokenè¡¨ç¤ºã€‚</li><li>ä½¿ç”¨$BERT_{[CLS]}$ä½œä¸ºè¯¥æ®µçš„æ‘˜è¦è¡¨ç¤ºã€‚</li><li>åˆ©ç”¨ä¸¤å±‚MLPè¾“å‡ºç›¸å…³æ€§å¾—åˆ†ã€‚</li><li>é€‰æ‹©è·å¾—æœ€é«˜ç›¸å…³æ€§å¾—åˆ†çš„æ®µè½ä½œä¸ºç¬¬ä¸€ç›¸å…³ä¸Šä¸‹æ–‡ã€‚</li><li>å°†$q$è¿æ¥åˆ°æ‰€é€‰æ®µè½ä½œä¸º$q_{new}$ï¼Œä»¥è¿›è¡Œä¸‹ä¸€è½®æ®µè½é€‰æ‹©ã€‚</li></ul><h4 id="Second-Round-Paragraph-Selection"><a href="#Second-Round-Paragraph-Selection" class="headerlink" title="Second Round Paragraph Selection"></a>Second Round Paragraph Selection</h4><ul><li>å¯¹äºå‰©ä½™çš„N-1ä¸ªå€™é€‰æ®µè½ï¼Œä½¿ç”¨ä¸ç¬¬ä¸€è½®æ®µè½é€‰æ‹©ç›¸åŒçš„æ¨¡å‹æ¥ç”Ÿæˆç›¸å…³æ€§å¾—åˆ†ï¼Œè¯¥ç›¸å…³æ€§å¾—åˆ†ä»¥$q_{new}$å’Œæ®µè½å†…å®¹ä¸ºè¾“å…¥ã€‚</li><li>å°†é—®é¢˜å’Œä¸¤ä¸ªé€‰å®šçš„æ®µè½è¿æ¥èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªæ–°çš„ä¸Šä¸‹æ–‡ï¼Œç”¨ä½œå›¾å½¢æ„é€ çš„è¾“å…¥æ–‡æœ¬ã€‚</li></ul><h3 id="Heterogeneous-SRL-Graph-Construction"><a href="#Heterogeneous-SRL-Graph-Construction" class="headerlink" title="Heterogeneous SRL Graph Construction"></a>Heterogeneous SRL Graph Construction</h3><p>æ¯ä¸ªæ•°æ®å®ä¾‹æ„å»ºä¸€ä¸ªåŒ…å«document-levelå­å›¾$S$å’Œargument- predicate SRL å­å›¾$Arg$çš„å¼‚æ„å›¾ã€‚</p><ul><li>$S$ </li></ul><blockquote><p>includes question q, title $t_1$and sentences $s_1^{1,â€¦,n}$  from first round se- lected paragraph.and title $t_2$and sentences $s_2^{1,â€¦,n}$ from the second round selected paragraph.</p></blockquote><ul><li>$Arg$</li></ul><blockquote><p>åŒ…å«ä½¿ç”¨AllenNLP-SRLæ¨¡å‹ç”Ÿæˆçš„å‚æ•°ä½œä¸ºèŠ‚ç‚¹ï¼Œè°“è¯ä½œä¸ºè¾¹ã€‚</p></blockquote><script type="math/tex; mode=display">{q, t_1, s_1 1, . . . , s_n 1, t_2, s_1 2, . . . , sn_ 2} âˆˆ S.</script><p><img src="/Users/maqi/Library/Application Support/typora-user-images/image-20201230214154969.png" alt="image-20201230214154969"></p><p>å¼‚æ„å›¾çš„è¾¹æ·»åŠ è§„åˆ™ï¼š</p><ol><li>å¦‚æœåœ¨è¯¥å¥å­ä¸­æœ‰ä¸€ä¸ªargumentï¼Œåˆ™è¯¥å¥å­å’Œargumentä¹‹é—´å°†å­˜åœ¨ä¸€æ¡è¾¹ï¼ˆå›¾3ä¸­çš„é»‘è‰²è™šçº¿ï¼‰</li><li>$s_i$å’Œ$s$ä¸¤ä¸ªå¥å­ï¼Œå¦‚æœä»–ä»¬é€šè¿‡ç²¾ç¡®åŒ¹é…å…±äº«ä¸€ä¸ªå‚æ•°ï¼Œåˆ™å­˜åœ¨ä¸€æ¡è¾¹ï¼ˆçº¢è‰²è™šçº¿ï¼‰</li><li>ä¸¤ä¸ªargumentèŠ‚ç‚¹$Arg_i$ å’Œ$Arg_j$ä¹‹é—´å­˜åœ¨è°“è¯ï¼Œåˆ™å­˜åœ¨ä¸€æ¡è¾¹ï¼ˆé»‘è‰²å®çº¿ï¼‰</li><li>å¦‚æœå®ƒä»¬å…±äº«ä¸€ä¸ªargumentï¼Œåˆ™é—®é¢˜å’Œå¥å­ä¹‹é—´ä¼šæœ‰ä¸€æ¡è¾¹ï¼ˆçº¢è‰²è™šçº¿ï¼‰</li></ol><p>å»ºç«‹äº†ä¸€ä¸ªåŸºäºè°“è¯çš„è¯­ä¹‰è¾¹ç¼˜çŸ©é˜µ$K$å’Œä¸€ä¸ªå¼‚æ„è¾¹ç¼˜æƒé‡çŸ©é˜µ$A$ã€‚</p><blockquote><p>è¯­ä¹‰è¾¹ç¼˜çŸ©é˜µ$K$æ˜¯ä¸€ä¸ªå­˜å‚¨è°“è¯å•è¯ç´¢å¼•çš„çŸ©é˜µã€‚ </p><p>å¼‚æ„è¾¹ç¼˜æƒé‡çŸ©é˜µ$A$æ˜¯å­˜å‚¨ä¸åŒç±»å‹è¾¹æƒé‡çš„çŸ©é˜µã€‚</p></blockquote><h3 id="Supporting-Fact-Prediction"><a href="#Supporting-Fact-Prediction" class="headerlink" title="Supporting Fact Prediction"></a>Supporting Fact Prediction</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201231111925.png" alt="image-20201231111925399" style="zoom: 67%;" /></p><ol><li>$G_S$: graph sentence embedding(è“è‰²åœ†åœˆ)ã€‚</li><li>BERTâ€™s [CLS] token representationï¼š æ©™è‰²åœ†åœˆã€‚</li><li>$X_S^{cand}$: å€™é€‰å¥å­ã€‚</li><li>$S_{cand}$:å€™é€‰å¥å­çš„ç›¸é‚»å¥å­ã€‚</li></ol><script type="math/tex; mode=display">X_S^{cand}  = [G_S^{cand} ; BERT[CLS](q, S_{cand})]</script><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>HotpotQA</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201231113847.png" alt="image-20201231113847927"></p><blockquote><p>EMï¼šå®Œå…¨åŒ¹é…</p><p>F1ï¼šéƒ¨åˆ†åŒ¹é…</p></blockquote><p>åœ¨Distractor settingä¸‹çš„æµ‹è¯•ç»“æœï¼š</p><p>â€‹        è¯¥æ¨¡å‹åœ¨Jointä¸Šè·å¾—äº†39.41ï¼…çš„å®Œå…¨ç²¾ç¡®åŒ¹é…åˆ†æ•°å’Œ66.37ï¼…çš„éƒ¨åˆ†åŒ¹é…åˆ†æ•°,è¿œè¶…åŸºçº¿æ¨¡å‹ï¼Œç›¸æ¯”å…¶ä»–æ¨¡å‹ä¹Ÿæœ‰æ˜æ˜¾çš„æå‡ã€‚è¿™å¾—ç›Šäºtoken-level BERTå’Œgraph-level SRL nodeçš„ç»“åˆã€‚</p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><h3 id="Ablation-study"><a href="#Ablation-study" class="headerlink" title="Ablation study"></a>Ablation study</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201231115716.png" alt="image-20201231115716017" style="zoom:50%;" /></p><p>Graph:</p><ul><li><p>åˆ é™¤æ•´ä¸ªSRLå›¾ã€‚ </p><p>ä¸å®Œæ•´çš„SRLGRNæ¨¡å‹ç›¸æ¯”ï¼Œåœ¨F1è¯„åˆ†ä¸Šä¸‹é™äº†8.46ï¼…ã€‚ å¦‚æœåˆ é™¤SRLå›¾ï¼Œè€Œä»…ä½¿ç”¨BERTè¿›è¡Œç­”æ¡ˆé¢„æµ‹ï¼Œåˆ™è¯¥æ¨¡å‹å°†å¤±å»ç”¨äºå¤šè·³æ¨ç†çš„è¿æ¥ã€‚</p></li><li><p>ä»SRLå›¾ä¸­åˆ é™¤äº†åŸºäºè°“è¯çš„è¾¹ç¼˜ä¿¡æ¯ã€‚</p><p>å¦‚æœä¸åˆå¹¶è¯­ä¹‰è¾¹ç¼˜ä¿¡æ¯å’Œå‚æ•°ç±»å‹ï¼Œåˆ™ç­”æ¡ˆè·¨åº¦é¢„æµ‹çš„F1åˆ†æ•°é™ä½2.9ï¼…ã€‚åˆ é™¤è°“è¯è¾¹å’Œå‚æ•°ç±»å‹å°†ç ´åSRLå›¾ä¸­çš„å‚æ•°-è°“è¯å…³ç³»ï¼Œå¹¶æ‰“ç ´æ¨ç†é“¾ã€‚</p></li></ul><p>Joint:</p><p>â€‹    å¦‚æœä¸å…±åŒè®­ç»ƒæ¨¡å‹ï¼Œæ€§èƒ½å°†ä¸‹é™4.56ï¼…ã€‚</p><p>Language Modelsï¼š</p><p>â€‹    å°½ç®¡BERTè·å¾—äº†ç›¸å¯¹æ›´å¥½çš„æ€§èƒ½ï¼Œä½†ALBERTæ¶æ„çš„å‚æ•°å°‘18Xï¼Œå¹¶ä¸”æ¯”BERTæ›´å¿«ã€‚</p><h2 id="æ‹“å±•"><a href="#æ‹“å±•" class="headerlink" title="æ‹“å±•"></a>æ‹“å±•</h2><p>â€‹        è¯­ä¹‰è§’è‰²æ ‡æ³¨ (Semantic Role Labeling, SRL) æ˜¯ä¸€ç§æµ…å±‚çš„è¯­ä¹‰åˆ†ææŠ€æœ¯ï¼Œæ ‡æ³¨å¥å­ä¸­æŸäº›çŸ­è¯­ä¸ºç»™å®šè°“è¯çš„è®ºå…ƒ (è¯­ä¹‰è§’è‰²) ï¼Œå¦‚æ–½äº‹ã€å—äº‹ã€æ—¶é—´å’Œåœ°ç‚¹ç­‰ã€‚å…¶èƒ½å¤Ÿå¯¹é—®ç­”ç³»ç»Ÿã€ä¿¡æ¯æŠ½å–å’Œæœºå™¨ç¿»è¯‘ç­‰åº”ç”¨äº§ç”Ÿæ¨åŠ¨ä½œç”¨ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pythonâ€”â€”Argparse æ•™ç¨‹</title>
      <link href="/2020/12/20/python%E2%80%94%E2%80%94Argparse%20%E6%95%99%E7%A8%8B/"/>
      <url>/2020/12/20/python%E2%80%94%E2%80%94Argparse%20%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="pythonâ€”â€”Argparse-æ•™ç¨‹"><a href="#pythonâ€”â€”Argparse-æ•™ç¨‹" class="headerlink" title="pythonâ€”â€”Argparse æ•™ç¨‹"></a>pythonâ€”â€”Argparse æ•™ç¨‹</h1><blockquote><p>æ­¤æ¨¡å—æ˜¯ Python æ ‡å‡†åº“ä¸­æ¨èçš„å‘½ä»¤è¡Œè§£ææ¨¡å—ã€‚</p></blockquote><h2 id="ä½ç½®å‚æ•°"><a href="#ä½ç½®å‚æ•°" class="headerlink" title="ä½ç½®å‚æ•°"></a>ä½ç½®å‚æ•°</h2><ol><li><strong>add_argument()</strong> æ–¹æ³•<ul><li>è¯¥æ–¹æ³•ç”¨äºæŒ‡å®šç¨‹åºèƒ½å¤Ÿæ¥å—å“ªäº›å‘½ä»¤è¡Œé€‰é¡¹ã€‚</li></ul></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;echo&quot;, help=&quot;echo the string you use here&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">print(args.echo)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py -h</span><br><span class="line">usage: test.py [-h] echo</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  echo        echo the string you use here</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help  show this help message and exit</span><br></pre></td></tr></table></figure><ul><li>æŒ‡å®šä¼ é€’å‚æ•°ç±»å‹ï¼ˆé»˜è®¤ä¸ºå­—ç¬¦ä¸²ï¼‰</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;square&quot;, help=&quot;display a square of a given number&quot;,</span><br><span class="line">                    type=int)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">print(args.square ** 2)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 </span><br><span class="line">16</span><br></pre></td></tr></table></figure><h2 id="å¯é€‰å‚æ•°"><a href="#å¯é€‰å‚æ•°" class="headerlink" title="å¯é€‰å‚æ•°"></a>å¯é€‰å‚æ•°</h2><blockquote><p>å‚æ•°åŠ â€â€”â€œç¬¦å·ã€‚</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;--verbosity&quot;, help=&quot;increase output verbosity&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">if args.verbosity:</span><br><span class="line">    print(&quot;verbosity turned on&quot;)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py --verbosity 1</span><br><span class="line">verbosity turned on</span><br></pre></td></tr></table></figure><ul><li>å½“æŒ‡å®š â€”verbosity å‚æ•°æ—¶æ˜¾ç¤ºæŸäº›ä¸œè¥¿ï¼Œå¦åˆ™ä¸æ˜¾ç¤ºã€‚</li><li>å¦‚æœä¸€ä¸ªå¯é€‰å‚æ•°æ²¡æœ‰è¢«ä½¿ç”¨æ—¶ï¼Œç›¸å…³å˜é‡è¢«èµ‹å€¼ä¸º Noneï¼Œåœ¨æ­¤ä¾‹ä¸­æ˜¯ args.verbosityï¼Œè¿™ä¹Ÿå°±æ˜¯ä¸ºä»€ä¹ˆå®ƒåœ¨ if è¯­å¥ä¸­è¢«å½“ä½œé€»è¾‘å‡ã€‚</li><li>ä½¿ç”¨ â€”verbosity é€‰é¡¹æ—¶ï¼Œå¿…é¡»æŒ‡å®šä¸€äº›å€¼ï¼ˆä»»ä½•å€¼ï¼‰,ä¾‹å¦‚æœ¬ä¾‹ä¸­æŒ‡å®šå€¼ä¸ºâ€œ1â€ã€‚</li></ul><ol><li><strong>action</strong>å…³é”®è¯</li></ol><blockquote><p>å‚æ•°åªæœ‰ä¸¤ä¸ªå€¼æœ‰å®é™…æ„ä¹‰ï¼šTrue æˆ–è€… Falseæ—¶ä½¿ç”¨ã€‚</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;--verbose&quot;, help=&quot;increase output verbosity&quot;,</span><br><span class="line">                    action=&quot;store_true&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">if args.verbose:</span><br><span class="line">    print(&quot;verbosity turned on&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py --verbose  </span><br><span class="line">verbosity turned on</span><br></pre></td></tr></table></figure><ul><li>æŒ‡å®šäº†ä¸€ä¸ªæ–°çš„å…³é”®è¯ actionï¼Œå¹¶èµ‹å€¼ä¸º â€œstore_trueâ€ã€‚è¿™æ„å‘³ç€ï¼Œå½“è¿™ä¸€é€‰é¡¹å­˜åœ¨æ—¶ï¼Œä¸º args.verbose èµ‹å€¼ä¸º Trueã€‚æ²¡æœ‰æŒ‡å®šæ—¶åˆ™éšå«åœ°èµ‹å€¼ä¸º Falseã€‚</li><li>å½“ä½ ä¸ºå…¶æŒ‡å®šä¸€ä¸ªå€¼æ—¶ï¼Œå®ƒä¼šæŠ¥é”™ï¼Œä¾‹å¦‚ï¼šåªå†™â€”verboseå³å¯ï¼Œä¼ é€’ä»»ä½•å€¼ä¼šæŠ¥é”™ã€‚</li></ul><h2 id="çŸ­é€‰é¡¹"><a href="#çŸ­é€‰é¡¹" class="headerlink" title="çŸ­é€‰é¡¹"></a>çŸ­é€‰é¡¹</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbose&quot;, help=&quot;increase output verbosity&quot;,</span><br><span class="line">                    action=&quot;store_true&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">if args.verbose:</span><br><span class="line">    print(&quot;verbosity turned on&quot;)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py -v </span><br><span class="line">verbosity turned on</span><br></pre></td></tr></table></figure><h2 id="ç»“åˆä½ç½®å‚æ•°å’Œå¯é€‰å‚æ•°"><a href="#ç»“åˆä½ç½®å‚æ•°å’Œå¯é€‰å‚æ•°" class="headerlink" title="ç»“åˆä½ç½®å‚æ•°å’Œå¯é€‰å‚æ•°"></a>ç»“åˆä½ç½®å‚æ•°å’Œå¯é€‰å‚æ•°</h2><blockquote><p>ä½ç½®å‚æ•°è¦æ³¨æ„é¡ºåºã€‚</p><p>ä½ç½®å‚æ•°å’Œå¯é€‰å‚æ•°é¡ºåºå¯ä»¥é¢ å€’ã€‚</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;square&quot;, type=int,</span><br><span class="line">                    help=&quot;display a square of a given number&quot;)</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbose&quot;, action=&quot;store_true&quot;,</span><br><span class="line">                    help=&quot;increase output verbosity&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square ** 2</span><br><span class="line">if args.verbose:</span><br><span class="line">    print(&quot;the square of &#123;&#125; equals &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">else:</span><br><span class="line">    print(answer)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 </span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 --verbose</span><br><span class="line">the square of 4 equals 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -v       </span><br><span class="line">the square of 4 equals 16</span><br></pre></td></tr></table></figure><ul><li>å‚æ•°é¡ºåºæ— å…³ç´§è¦ã€‚</li><li>ä½ç½®å‚æ•°å¿…é¡»ä¼ å€¼ã€‚</li></ul><ol><li><p><strong>count</strong>åŠ¨ä½œ</p><p>æ¥æ•°æŸä¸€ä¸ªå¯é€‰å‚æ•°å‡ºç°äº†å‡ æ¬¡ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;square&quot;, type=int,</span><br><span class="line">                    help=&quot;display the square of a given number&quot;)</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbosity&quot;, action=&quot;count&quot;,</span><br><span class="line">                    help=&quot;increase output verbosity&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square ** 2</span><br><span class="line">if args.verbosity == 2:</span><br><span class="line">    print(&quot;the square of &#123;&#125; equals &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">elif args.verbosity == 1:</span><br><span class="line">    print(&quot;&#123;&#125;^2 == &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">else:</span><br><span class="line">    print(answer)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 </span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -v</span><br><span class="line">4^2 == 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -vv</span><br><span class="line">the square of 4 equals 16</span><br></pre></td></tr></table></figure></li><li><p><strong>choices</strong>å…³é”®å­—</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;square&quot;, type=int,</span><br><span class="line">                    help=&quot;display a square of a given number&quot;)</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbosity&quot;, type=int, choices=[0, 1, 2],</span><br><span class="line">                    help=&quot;increase output verbosity&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square ** 2</span><br><span class="line">if args.verbosity == 2:</span><br><span class="line">    print(&quot;the square of &#123;&#125; equals &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">elif args.verbosity == 1:</span><br><span class="line">    print(&quot;&#123;&#125;^2 == &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">else:</span><br><span class="line">    print(answer)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 -v 1</span><br><span class="line">4^2 == 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -v 3</span><br><span class="line">usage: test.py [-h] [-v &#123;0,1,2&#125;] square</span><br><span class="line">test.py: error: argument -v/--verbosity: invalid choice: 3 (choose from 0, 1, 2)</span><br></pre></td></tr></table></figure><ol><li><strong>default</strong>å…³é”®å­—</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;square&quot;, type=int,</span><br><span class="line">                    help=&quot;display a square of a given number&quot;)</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbosity&quot;, action=&quot;count&quot;, default=0,</span><br><span class="line">                    help=&quot;increase output verbosity&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square ** 2</span><br><span class="line">if args.verbosity &gt;= 2:</span><br><span class="line">    print(&quot;the square of &#123;&#125; equals &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">elif args.verbosity &gt;= 1:</span><br><span class="line">    print(&quot;&#123;&#125;^2 == &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">else:</span><br><span class="line">    print(answer)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 </span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -v</span><br><span class="line">4^2 == 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -vv</span><br><span class="line">the square of 4 equals 16</span><br></pre></td></tr></table></figure><ul><li><p>ç»“åˆä½¿ç”¨</p><blockquote><p>ä½ç½®å‚æ•°è¦æ³¨æ„é¡ºåºã€‚</p><p>ä½ç½®å‚æ•°å’Œå¯é€‰å‚æ•°é¡ºåºå¯ä»¥é¢ å€’ã€‚</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;x&quot;, type=int, help=&quot;the base&quot;)</span><br><span class="line">parser.add_argument(&quot;y&quot;, type=int, help=&quot;the exponent&quot;)</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbosity&quot;, action=&quot;count&quot;, default=0)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.x ** args.y</span><br><span class="line">if args.verbosity &gt;= 2:</span><br><span class="line">    print(&quot;Running &#x27;&#123;&#125;&#x27;&quot;.format(__file__))</span><br><span class="line">if args.verbosity &gt;= 1:</span><br><span class="line">    print(&quot;&#123;&#125;^&#123;&#125; == &quot;.format(args.x, args.y), end=&quot;&quot;)</span><br><span class="line">print(answer)</span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 2   </span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -v</span><br><span class="line">4^2 == 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -vv</span><br><span class="line">Running &#x27;test.py&#x27;</span><br><span class="line">4^2 == 16</span><br></pre></td></tr></table></figure><h2 id="çŸ›ç›¾çš„é€‰é¡¹-add-mutually-exclusive-group"><a href="#çŸ›ç›¾çš„é€‰é¡¹-add-mutually-exclusive-group" class="headerlink" title="çŸ›ç›¾çš„é€‰é¡¹ add_mutually_exclusive_group()"></a>çŸ›ç›¾çš„é€‰é¡¹ add_mutually_exclusive_group()</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">group = parser.add_mutually_exclusive_group()</span><br><span class="line">group.add_argument(&quot;-v&quot;, &quot;--verbose&quot;, action=&quot;store_true&quot;)</span><br><span class="line">group.add_argument(&quot;-q&quot;, &quot;--quiet&quot;, action=&quot;store_true&quot;)</span><br><span class="line">parser.add_argument(&quot;x&quot;, type=int, help=&quot;the base&quot;)</span><br><span class="line">parser.add_argument(&quot;y&quot;, type=int, help=&quot;the exponent&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.x**args.y</span><br><span class="line"></span><br><span class="line">if args.quiet:</span><br><span class="line">    print(answer)</span><br><span class="line">elif args.verbose:</span><br><span class="line">    print(&quot;&#123;&#125; to the power &#123;&#125; equals &#123;&#125;&quot;.format(args.x, args.y, answer))</span><br><span class="line">else:</span><br><span class="line">    print(&quot;&#123;&#125;^&#123;&#125; == &#123;&#125;&quot;.format(args.x, args.y, answer))</span><br></pre></td></tr></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 2 </span><br><span class="line">4^2 == 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -q</span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -v</span><br><span class="line">4 to the power 2 equals 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -vq</span><br><span class="line">usage: test.py [-h] [-v | -q] x y</span><br><span class="line">test.py: error: argument -q/--quiet: not allowed with argument -v/--verbose</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -v -q</span><br><span class="line">usage: test.py [-h] [-v | -q] x y</span><br><span class="line">test.py: error: argument -q/--quiet: not allowed with argument -v/--verbose</span><br></pre></td></tr></table></figure><ul><li>add_mutually_exclusive_group()å®ƒå…è®¸æˆ‘ä»¬æŒ‡å®šå½¼æ­¤ç›¸äº’å†²çªçš„é€‰é¡¹ã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> Argparse </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pythonçŸ¥è¯†ç‚¹</title>
      <link href="/2020/12/20/python%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
      <url>/2020/12/20/python%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<h1 id="pythonçŸ¥è¯†ç‚¹"><a href="#pythonçŸ¥è¯†ç‚¹" class="headerlink" title="pythonçŸ¥è¯†ç‚¹"></a>pythonçŸ¥è¯†ç‚¹</h1><ol><li><strong>tqdm</strong>ï¼šè¿›åº¦æ¡</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from tqdm import tqdm</span><br><span class="line"></span><br><span class="line">pbar = tqdm([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;])</span><br><span class="line">for char in pbar:</span><br><span class="line">    pbar.set_description(&quot;Processing %s&quot; % char)</span><br></pre></td></tr></table></figure><p>æ•ˆæœï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201220184527.png" alt="image-20201220184518149"></p><ol><li><p><strong>@staticmethod</strong></p><blockquote><p>é™æ€æ–¹æ³•æ— éœ€å®ä¾‹åŒ–<br>ä¹Ÿå¯ä»¥å®ä¾‹åŒ–åè°ƒç”¨</p></blockquote></li><li><p><strong>list</strong></p><p>append()ï¼šå°†å…ƒç´ ç›´æ¥å†…åµŒåˆ°åˆ—è¡¨</p><p>+=ï¼šæ‹¼æ¥åŒçº§åˆ—è¡¨</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = []</span><br><span class="line">a.append([&#x27;s&#x27;])</span><br><span class="line">a += [&#x27;d&#x27;]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[&#x27;s&#x27;], &#x27;d&#x27;]</span><br></pre></td></tr></table></figure></li><li><p><strong>if any pythonæ¡ä»¶åˆ¤æ–­ all(),any()</strong></p><p>any() ç†è§£æˆany Trueçš„æ„æ€ï¼Œæ˜¯å¦å­˜åœ¨Trueï¼Œåªè¦æœ‰ä¸€ä¸ªæ˜¯Trueï¼Œç»“æœå°±æ˜¯Trueã€‚</p><p>not any() å…¨ä¸ºFalseåˆ™ä¸ºTrueã€‚</p></li><li><p><strong>assert</strong></p><p>assert expression</p><p>assert çš„ä½œç”¨æ˜¯ç°è®¡ç®—è¡¨è¾¾å¼ expression ï¼Œå¦‚æœå…¶å€¼ä¸ºå‡ï¼ˆå³ä¸º0ï¼‰ï¼Œé‚£ä¹ˆå®ƒå…ˆå‘ stderr æ‰“å°ä¸€æ¡å‡ºé”™ä¿¡æ¯,ç„¶åé€šè¿‡è°ƒç”¨ abort æ¥ç»ˆæ­¢ç¨‹åºè¿è¡Œã€‚</p></li><li><p><strong>action=â€store_trueâ€</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(&quot;--verbose&quot;, help=&quot;increase output verbosity&quot;,action=&quot;store_true&quot;)</span><br></pre></td></tr></table></figure><p>é»˜è®¤ä¸ºFalse</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ™ºèƒ½é—¨é”</title>
      <link href="/2020/12/13/%E6%99%BA%E8%83%BD%E9%97%A8%E9%94%81/"/>
      <url>/2020/12/13/%E6%99%BA%E8%83%BD%E9%97%A8%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h1 id="æ™ºèƒ½é—¨é”"><a href="#æ™ºèƒ½é—¨é”" class="headerlink" title="æ™ºèƒ½é—¨é”"></a>æ™ºèƒ½é—¨é”</h1><p>æ¼”ç¤ºè§†é¢‘ï¼š<a href="https://www.bilibili.com/video/BV1Z5411V7Gh/">https://www.bilibili.com/video/BV1Z5411V7Gh/</a></p><p>æ•™å­¦è§†é¢‘ï¼š<a href="https://www.bilibili.com/video/BV1g54y1t7C9/">https://www.bilibili.com/video/BV1g54y1t7C9/</a></p><p>å®‰è£…æ•ˆæœå›¾</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201213161946.JPG" alt="IMG_0115"></p><h2 id="æ¸…å•"><a href="#æ¸…å•" class="headerlink" title="æ¸…å•"></a>æ¸…å•</h2><p><strong>NodeMCU</strong>ï¼šESP8266ä¸²å£wifiæ¨¡å— NodeMCU Lua V3ç‰©è”ç½‘å¼€å‘æ¿ CH340 CP2102(æ·˜å®æœç´¢)</p><p><strong>Arduino uno r3</strong>(å¯é€‰)</p><p><strong>RFID-RC522</strong></p><p><strong>èˆµæœº</strong>ï¼šMG996R</p><p><strong>èœ‚é¸£å™¨ï¼ˆæœ‰æºï¼‰</strong></p><p><strong>è§¦æ‘¸æŒ‰é”®æ¨¡å—</strong>ï¼ˆTTP223/224/226/229çš†å¯ï¼‰</p><p><strong>ç”µæºæ¨¡å—</strong>ï¼šæä¾›5v,3.3vè¾“å‡º</p><p><strong>æœé‚¦çº¿</strong> ï¼šå…¬å¯¹å…¬  å…¬å¯¹æ¯  æ¯å¯¹æ¯</p><blockquote><p>esp8266åº“ï¼š<code>https://arduino.esp8266.com/stable/package_esp8266com_index.json</code></p></blockquote><h2 id="æ¥çº¿"><a href="#æ¥çº¿" class="headerlink" title="æ¥çº¿"></a>æ¥çº¿</h2><h3 id="ESP8266-â€”â€”-MFRC522"><a href="#ESP8266-â€”â€”-MFRC522" class="headerlink" title="ESP8266 â€”â€” MFRC522"></a>ESP8266 â€”â€” MFRC522</h3><ul><li>D1 â€”â€” RST</li><li>D2 â€”â€” NSS(SDA) </li><li>3V3 â€”â€”3V3</li><li>GND â€”â€” GND</li><li>D5 â€”â€” SCK</li><li>D6 â€”â€” MIS0</li><li>D7 â€”â€” MIS1</li></ul><h3 id="ESP8266-â€”â€”-èˆµæœº"><a href="#ESP8266-â€”â€”-èˆµæœº" class="headerlink" title="ESP8266 â€”â€” èˆµæœº"></a>ESP8266 â€”â€” èˆµæœº</h3><ul><li>D4</li></ul><h3 id="ESP8266-â€”â€”-uno-r3"><a href="#ESP8266-â€”â€”-uno-r3" class="headerlink" title="ESP8266 â€”â€” uno r3"></a>ESP8266 â€”â€” uno r3</h3><ul><li>D0 â€”â€” 3</li><li>D3 â€”â€” 2</li></ul><h3 id="uno-r3-â€”â€”-èœ‚é¸£å™¨"><a href="#uno-r3-â€”â€”-èœ‚é¸£å™¨" class="headerlink" title="uno r3 â€”â€” èœ‚é¸£å™¨"></a>uno r3 â€”â€” èœ‚é¸£å™¨</h3><ul><li>4</li></ul><h2 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h2><p>esp8266ä»£ç ï¼š<a href="https://github.com/Asimok/unoproject_backup/blob/master/smartlock208/smartlock208/smartlock208.ino">https://github.com/Asimok/unoproject_backup/blob/master/smartlock208/smartlock208/smartlock208.ino</a></p><p>uno r3ä»£ç ï¼š<a href="https://github.com/Asimok/unoproject_backup/blob/master/smartlock208/smartlock_unor3/smartlock_unor3.ino">https://github.com/Asimok/unoproject_backup/blob/master/smartlock208/smartlock_unor3/smartlock_unor3.ino</a></p>]]></content>
      
      
      <categories>
          
          <category> ç¡¬ä»¶å¼€å‘ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Arduino </tag>
            
            <tag> C </tag>
            
            <tag> ESP8266 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering</title>
      <link href="/2020/12/12/Learning%20to%20Retrieve%20Reasoning%20Paths%20over%20Wikipedia%20Graph%20for%20Question%20Answering/"/>
      <url>/2020/12/12/Learning%20to%20Retrieve%20Reasoning%20Paths%20over%20Wikipedia%20Graph%20for%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="Learning-to-Retrieve-Reasoning-Paths-over-Wikipedia-Graph-for-Question-Answering"><a href="#Learning-to-Retrieve-Reasoning-Paths-over-Wikipedia-Graph-for-Question-Answering" class="headerlink" title="Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering"></a>Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering</h1><blockquote><p><a href="https://arxiv.org/abs/1911.10470">è®ºæ–‡ï¼šhttps://arxiv.org/abs/1911.10470</a></p><p><a href="https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths">ä»£ç ï¼šhttps://github.com/AkariAsai/learning_to_retrieve_reasoning_paths</a></p><p>å­¦ä¹ åœ¨ç»´åŸºç™¾ç§‘ä¸­æ£€ç´¢é—®é¢˜çš„æ¨ç†è·¯å¾„</p><ul><li>åŸºäºæ¨ç†è·¯å¾„</li></ul></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>ä»ç»´åŸºç™¾ç§‘ä¸­æå–æ¨ç†è·¯å¾„å®ç°å¤šè½®é—®ç­”ã€‚</p><ul><li><p>å¤šè½®é—®ç­”ï¼š</p><p>éœ€è¦ç»“åˆå¤šç¯‡æ–‡æ¡£çš„â€œçŸ¥è¯†æ¨ç†â€èƒ½å¾—åˆ°æœ€ç»ˆç­”æ¡ˆã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201208143543.png" alt="image-20201208143543082"></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201208143557.png" alt="image-20201208143556977"></p></li></ul><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><ol><li>é€šè¿‡ç»´åŸºç™¾ç§‘çš„è¶…é“¾æ¥æ„å»ºä¸€ä¸ªç»´åŸºç™¾ç§‘å›¾ç½‘ç»œï¼Œåœ¨ä¸åŒçš„æ–‡æ¡£ä¹‹é—´å»ºæ¨¡ã€‚</li><li>ä½¿ç”¨ä¸€ä¸ªRNNç»™æ¨ç†è·¯å¾„å»ºæ¨¡ï¼Œä»è€Œæ‰¾åˆ°æœ€ä½³æ¨ç†è·¯å¾„ã€‚</li></ol><h3 id="æ¨¡å‹ç»“æ„ï¼š"><a href="#æ¨¡å‹ç»“æ„ï¼š" class="headerlink" title="æ¨¡å‹ç»“æ„ï¼š"></a>æ¨¡å‹ç»“æ„ï¼š</h3><blockquote><p>ç”±ä¸€ä¸ªæå–å™¨å’Œé˜…è¯»å™¨ç»„æˆ</p></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201208143829.png" alt="image-20201208143829008"></p><p>æ¨ç†è·¯å¾„æå–å™¨ï¼ˆReasoning Path Retrievalï¼‰ï¼šæ ¹æ®ç»´åŸºç™¾ç§‘ä¹‹é—´çš„è¶…é“¾æ¥å…³ç³»å¾—åˆ°è‹¥å¹²æ¨ç†è·¯å¾„ã€‚</p><p>é˜…è¯»ç†è§£ç­”æ¡ˆæŠ½å–å™¨ï¼ˆReading and Answering Reasoning Pathï¼‰ï¼šåŸºäºè¿™äº›è·¯å¾„æ‰¾åˆ°æœ€å¯èƒ½çš„ä¸€æ¡è·¯å¾„ä½œä¸ºæœ€ç»ˆçš„ç­”æ¡ˆã€‚</p><blockquote><p>å°†ç»´åŸºç™¾ç§‘æ–‡ç« é‡Œçš„æ¯ä¸ªæ®µè½$p$ä½œä¸ºåŸºæœ¬å•å…ƒã€‚ç»™å®šé—®é¢˜$q$ï¼Œæ¨¡å‹é¦–å…ˆæ‰¾åˆ°ä¸€æ¡æ¨ç†è·¯å¾„$E = [p<em>i, . . . , p_k]$ï¼Œç”¨$S</em>{retr}(q, E)$è¡¨ç¤ºï¼›ç„¶ååœ¨$E$ä¸­æ‰¾åˆ°ç­”æ¡ˆ$a$ï¼Œç”¨$S_{read}(q, E, a)$è¡¨ç¤ºã€‚</p></blockquote><script type="math/tex; mode=display">\underset{E,a}{arg \ max} \ S(q, E, a) \ \ \ \  s.t. \ \ S(q, E, a) = S_{retr}(q, E) + S_{read}(q, E, a)</script><h3 id="æ¨ç†è·¯å¾„æå–"><a href="#æ¨ç†è·¯å¾„æå–" class="headerlink" title="æ¨ç†è·¯å¾„æå–"></a>æ¨ç†è·¯å¾„æå–</h3><h4 id="Constructing-the-Wikipedia-graph"><a href="#Constructing-the-Wikipedia-graph" class="headerlink" title="Constructing the Wikipedia graph"></a>Constructing the Wikipedia graph</h4><p>ç›´æ¥ä½¿ç”¨ç»´åŸºç™¾ç§‘ä¸­çš„è¶…é“¾æ¥æ„å»ºæœ‰å‘å›¾$G$ã€‚</p><h4 id="General-formulation-with-a-recurrent-retriever"><a href="#General-formulation-with-a-recurrent-retriever" class="headerlink" title="General formulation with a recurrent retriever"></a>General formulation with a recurrent retriever</h4><p>ä½¿ç”¨RNNå»ºæ¨¡é—®é¢˜$Q$çš„æ¨ç†è·¯å¾„ã€‚</p><p>ç»™å®šé—®é¢˜$q$ï¼Œåœ¨æ—¶é—´æ­¥$t$æ—¶ï¼Œæ¨¡å‹ä»å€™é€‰æ®µè½é›†$C_t$ä¸­æ‰¾å‡º$p_i$ ï¼Œä¸$q$æ‹¼æ¥è®¡ç®—$p_i$çš„æ¦‚ç‡ã€‚</p><p>é‡åˆ°$[EOE]$æ—¶ç»“æŸæ¨ç†ï¼Œå…è®¸å®ƒåœ¨ç»™å®šæ¯ä¸ªé—®é¢˜çš„æƒ…å†µä¸‹æ•è·å…·æœ‰ä»»æ„é•¿åº¦çš„æ¨ç†è·¯å¾„ã€‚</p><script type="math/tex; mode=display">w_i=BERT_{CLS}(q,p_i) \in \R^d</script><script type="math/tex; mode=display">P(p_i|h_t)=\sigma(w_iÂ·h_t+b)</script><script type="math/tex; mode=display">h_{t=1}=RNN(h_t,w_i) \in \R^d</script><h4 id="Beam-search-for-candidate-paragraphs"><a href="#Beam-search-for-candidate-paragraphs" class="headerlink" title="Beam search for candidate paragraphs"></a>Beam search for candidate paragraphs</h4><p>ä¸ºé˜²æ­¢è®¡ç®—é‡è¿‡å¤§ï¼Œä½¿ç”¨Beam Searchæ¥æ„å»ºå¤šä¸ªæ£€ç´¢è·¯å¾„ã€‚</p><h4 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h4><p>å¯¹çœŸå®çš„æ¨ç†è·¯å¾„$g = [p<em>1, . . . , p</em>{|g|}]$å¢åŠ ä¸€æ¡æ–°çš„æ¨ç†è·¯å¾„$g = [p<em>r,p_1, . . . , p</em>{|g|}]$ï¼Œ$p_r$æ˜¯ä¸$p_1$æœ‰è”ç³»çš„TF-IDFåˆ†æœ€é«˜çš„ä¸€ä¸ªæ®µè½ã€‚</p><h4 id="Negative-examples-for-robustness"><a href="#Negative-examples-for-robustness" class="headerlink" title="Negative examples for robustness"></a>Negative examples for robustness</h4><p>ä½¿ç”¨ä¸¤ç§è´Ÿé‡‡æ ·ç­–ç•¥ï¼š</p><p>â€‹    (1)åŸºäºTF-IDF</p><p>â€‹    (2)åŸºäºè¶…é“¾æ¥</p><p>å•è½®QAåªç”¨(1)ï¼Œå¤šè½®QAä¸¤è€…éƒ½ç”¨ï¼Œè´Ÿé‡‡æ ·æ•°ä¸º50ã€‚</p><h4 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h4><p>åœ¨ $C_t$ä¸Šä½¿ç”¨å¹¿æ³›ä½¿ç”¨çš„äº¤å‰ç†µæŸå¤±å’Œsoftmaxå½’ä¸€åŒ–æ˜¯ä¸ç†æƒ³çš„ï¼Œå› ä¸ºåŒæ—¶æœ€å¤§åŒ–$g$å’Œå¢å¹¿çš„$g_r$æ˜¯çŸ›ç›¾çš„ã€‚å› æ­¤æœ¬æ–‡ç‹¬ç«‹è¯„ä¼°$P(p_i|h_t)$å¹¶ä½¿ç”¨ binary cross-entropy lossæ¥æœ€å¤§åŒ–æ‰€æœ‰å¯èƒ½è·¯å¾„çš„æ¦‚ç‡å€¼ã€‚</p><script type="math/tex; mode=display">L_{retr}(p_t, h_t) = âˆ’ log P(p_t|h_t) âˆ’ \ \underset{\tilde{p}âˆˆ\tilde C_t} \sum log (1 âˆ’ P(\tilde{p}|h_t))</script><ul><li>$\tilde{p}âˆˆ\tilde C_t$æ˜¯è´Ÿæ ·æœ¬é›†åˆã€‚</li></ul><h3 id="READING-AND-ANSWERING-GIVEN-REASONING-PATHS"><a href="#READING-AND-ANSWERING-GIVEN-REASONING-PATHS" class="headerlink" title="READING AND ANSWERING GIVEN REASONING PATHS"></a>READING AND ANSWERING GIVEN REASONING PATHS</h3><p>ä½¿ç”¨Bertæ¨¡å‹è®¡ç®—æ¨ç†è·¯å¾„å’Œç­”æ¡ˆæ¦‚ç‡ã€‚</p><blockquote><p>ä½¿ç”¨Bertæ¨¡å‹å¯¹åº”äºCLSæ ‡è¯†ç¬¦ä½çš„è¾“å‡ºåˆ¤æ–­æ¨ç†è·¯å¾„åŒ…æ‹¬ç­”æ¡ˆçš„æ¦‚ç‡ã€‚</p></blockquote><script type="math/tex; mode=display">P(E|q) = Ïƒ(w_nÂ· u_E) \ \ s.t. \ \ u_E= BERT_{[CLS]}(q, E) âˆˆ \R^D</script><script type="math/tex; mode=display">E_{best}=\underset{EâˆˆE} {arg\ max } \ P(E|q)</script><script type="math/tex; mode=display">S_{read}= \underset{i,j, iâ‰¤j}{arg \ max}\   P^{start}_i P^{end}_j</script><h3 id="Multi-task-loss-function"><a href="#Multi-task-loss-function" class="headerlink" title="Multi-task loss function"></a>Multi-task loss function</h3><script type="math/tex; mode=display">L_{read}= L_{span}+ L_{no\_answer}= (âˆ’ log P^{start}_{y^{start}} âˆ’ log P^{end}_{y^{end}}) âˆ’ log P^r</script><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li><strong>HotpotQA</strong></li><li>SQuAD Open</li><li>Natural Question Open</li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p>HotpotQAéªŒè¯é›†æµ‹è¯•ç»“æœ:</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201210141209.png" alt="image-20201210141209866"></p><p>HotpotQAæµ‹è¯•é›†æµ‹è¯•ç»“æœ:</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201210141630.png" alt="image-20201210141630169" style="zoom:50%;" /></p><blockquote><p>æœ¬æ–‡æå‡ºçš„æ¨¡å‹åœ¨hotpotæ•°æ®é›†ä¸Šå–å¾—äº†éå¸¸ä¼˜ç§€çš„æµ‹è¯•ç»“æœã€‚</p></blockquote><p>SQuAD Openæµ‹è¯•ç»“æœ:</p><p><img src="/Users/maqi/Library/Application Support/typora-user-images/image-20201210141756755.png" alt="image-20201210141756755" style="zoom:50%;" /></p><p>Natural Question Openæµ‹è¯•ç»“æœ:</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201210141817.png" alt="image-20201210141817154" style="zoom:50%;" /></p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>ä¸åŒçš„è·¯å¾„æŠ½å–æ–¹æ³•æ¯”è¾ƒï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201210142007.png" alt="image-20201210142007831" style="zoom:50%;" /></p><p><strong>æ¶ˆèå®éªŒï¼š</strong></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201210142257.png" alt="image-20201210142257828" style="zoom:50%;" /></p><blockquote><p>å¯ä»¥çœ‹åˆ°ï¼Œç§»é™¤ä»»ä½•ä¸€éƒ¨åˆ†å¯¹æ¨¡å‹çš„ç»“æœå½±å“éƒ½æ¯”è¾ƒå¤§ã€‚</p></blockquote><p>å®ä½“é“¾æ¥ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201210142511.png" alt="image-20201210142511733" style="zoom:50%;" /></p><blockquote><p>ä½¿ç”¨è¶…é“¾æ¥å’Œå®ä½“é“¾æ¥ç³»ç»Ÿå¯¹å®éªŒç»“æœå½±å“ä¸å¤§ï¼Œè¯´æ˜è¶…é“¾æ¥å¹¶ä¸æ˜¯å¿…è¦å› ç´ ã€‚</p></blockquote><p>æ¨ç†è·¯å¾„é•¿åº¦ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201210142637.png" alt="image-20201210142637317" style="zoom:50%;" /></p><blockquote><p>æ¨ç†è·¯å¾„çš„é•¿åº¦å¯¹å®éªŒç»“æœæœ‰æ˜¾è‘—çš„å½±å“ï¼Œæ¨ç†è·¯å¾„è¾ƒçŸ­æ—¶å‡†ç¡®ç‡è¾ƒä½ã€‚</p></blockquote><p>â€‹        æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„åŸºäºå›¾çš„é€’å½’æ£€ç´¢æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨ç»´åŸºç™¾ç§‘å›¾ä¸Šæ£€ç´¢æ¨ç†è·¯å¾„ï¼Œä»¥å›ç­”å¼€æ”¾é¢†åŸŸå¤šè½®é—®ç­”ã€‚ä½¿ç”¨æ¨ç†è·¯å¾„æå–å™¨æ„å»ºæ¨ç†è·¯å¾„ï¼Œä½¿ç”¨é˜…è¯»ç†è§£ç­”æ¡ˆæŠ½å–å™¨å¯¹æ¨ç†è·¯å¾„è¿›è¡Œé‡æ–°æ’åºï¼Œå¹¶å°†æœ€ç»ˆç­”æ¡ˆç¡®å®šä¸ºä»æœ€ä½³æ¨ç†è·¯å¾„ä¸­æå–çš„ç­”æ¡ˆã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šéƒ½è¡¨ç°å‡ºäº†ä¼˜ç§€çš„æ€§èƒ½ã€‚</p><h2 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h2><h3 id="æœç´¢ç®—æ³•beam-searchï¼ˆæŸæœç´¢ï¼‰"><a href="#æœç´¢ç®—æ³•beam-searchï¼ˆæŸæœç´¢ï¼‰" class="headerlink" title="æœç´¢ç®—æ³•beam searchï¼ˆæŸæœç´¢ï¼‰"></a>æœç´¢ç®—æ³•beam searchï¼ˆæŸæœç´¢ï¼‰</h3><blockquote><p>æ˜¯exhaustive searchå’Œgreedy searchçš„æŠ˜ä¸­æ–¹æ¡ˆã€‚</p></blockquote><p>â€‹        beam searchæœ‰ä¸€ä¸ªè¶…å‚æ•°<strong>beam size</strong>ï¼ˆæŸå®½ï¼‰ï¼Œè®¾ä¸º$k$ ã€‚ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥é•¿ï¼Œé€‰å–å½“å‰æ¡ä»¶æ¦‚ç‡æœ€å¤§çš„ $k$ä¸ªè¯ï¼Œå½“åšå€™é€‰è¾“å‡ºåºåˆ—çš„ç¬¬ä¸€ä¸ªè¯ã€‚ä¹‹åçš„æ¯ä¸ªæ—¶é—´æ­¥é•¿ï¼ŒåŸºäºä¸Šä¸ªæ­¥é•¿çš„è¾“å‡ºåºåˆ—ï¼ŒæŒ‘é€‰å‡º<strong>æ‰€æœ‰ç»„åˆä¸­</strong>æ¡ä»¶æ¦‚ç‡æœ€å¤§çš„$k$ ä¸ªï¼Œä½œä¸ºè¯¥æ—¶é—´æ­¥é•¿ä¸‹çš„å€™é€‰è¾“å‡ºåºåˆ—ã€‚å§‹ç»ˆä¿æŒ$k$ä¸ªå€™é€‰ã€‚æœ€åä»$k$ä¸ªå€™é€‰ä¸­æŒ‘å‡ºæœ€ä¼˜çš„ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MRC </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ™ºèƒ½å¼€å…³(Android)</title>
      <link href="/2020/12/10/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3(Android)/"/>
      <url>/2020/12/10/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3(Android)/</url>
      
        <content type="html"><![CDATA[<h1 id="æ™ºèƒ½å¼€å…³ï¼ˆAndroidï¼‰"><a href="#æ™ºèƒ½å¼€å…³ï¼ˆAndroidï¼‰" class="headerlink" title="æ™ºèƒ½å¼€å…³ï¼ˆAndroidï¼‰"></a>æ™ºèƒ½å¼€å…³ï¼ˆAndroidï¼‰</h1><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201206135913.jpg" alt="Screenshot_2020-12-02-12-39-30-190_com.example.do"></p><h2 id="å¼€å‘å·¥å…·"><a href="#å¼€å‘å·¥å…·" class="headerlink" title="å¼€å‘å·¥å…·"></a>å¼€å‘å·¥å…·</h2><ul><li>AndroidStudio</li></ul><h2 id="Android-APPä»£ç "><a href="#Android-APPä»£ç " class="headerlink" title="Android APPä»£ç "></a>Android APPä»£ç </h2><blockquote><p>GitHub:<a href="https://github.com/Asimok/dorm_light">https://github.com/Asimok/dorm_light</a></p></blockquote><h2 id="æ•™å­¦è§†é¢‘"><a href="#æ•™å­¦è§†é¢‘" class="headerlink" title="æ•™å­¦è§†é¢‘"></a>æ•™å­¦è§†é¢‘</h2><blockquote><p>å“”å“©å“”å“©ï¼š<a href="https://www.bilibili.com/video/BV18Z4y1g7VS/">https://www.bilibili.com/video/BV18Z4y1g7VS/</a></p></blockquote><h2 id="å®Œæ•´æ•™ç¨‹"><a href="#å®Œæ•´æ•™ç¨‹" class="headerlink" title="å®Œæ•´æ•™ç¨‹"></a>å®Œæ•´æ•™ç¨‹</h2><p>åšå®¢ï¼š<a href="https://www.asimok.site/2020/12/06/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3/">https://www.asimok.site/2020/12/06/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3/</a></p>]]></content>
      
      
      <categories>
          
          <category> è½¯ä»¶å¼€å‘&amp;æ¨¡å‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQTT </tag>
            
            <tag> Android </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx æœåŠ¡å™¨è¯ä¹¦å®‰è£…ï¼ˆé…ç½®httpsï¼‰</title>
      <link href="/2020/12/09/Nginx%20%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AF%81%E4%B9%A6%E5%AE%89%E8%A3%85%EF%BC%88%E9%85%8D%E7%BD%AEhttps%EF%BC%89/"/>
      <url>/2020/12/09/Nginx%20%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AF%81%E4%B9%A6%E5%AE%89%E8%A3%85%EF%BC%88%E9%85%8D%E7%BD%AEhttps%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="Nginx-æœåŠ¡å™¨è¯ä¹¦å®‰è£…ï¼ˆé…ç½®httpsï¼‰"><a href="#Nginx-æœåŠ¡å™¨è¯ä¹¦å®‰è£…ï¼ˆé…ç½®httpsï¼‰" class="headerlink" title="Nginx æœåŠ¡å™¨è¯ä¹¦å®‰è£…ï¼ˆé…ç½®httpsï¼‰"></a>Nginx æœåŠ¡å™¨è¯ä¹¦å®‰è£…ï¼ˆé…ç½®httpsï¼‰</h1><h2 id="ä¸‹è½½è¯ä¹¦"><a href="#ä¸‹è½½è¯ä¹¦" class="headerlink" title="ä¸‹è½½è¯ä¹¦"></a>ä¸‹è½½è¯ä¹¦</h2><ol><li>ä»è¯ä¹¦é¢å‘å¹³å°ä¸‹è½½è¯ä¹¦</li></ol><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/night1/image-20201209111622263.png" alt="image-20201209111622263"></p><ol><li>é€‰æ‹©Nginxä¸‹çš„è¯ä¹¦æ–‡ä»¶</li></ol><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/night1/image-20201209111746085.png" alt="image-20201209111746085"></p><ol><li>ä¸Šä¼ åˆ°æœåŠ¡å™¨</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/ssl</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/night1/image-20201209111909373.png" alt="image-20201209111909373"></p><h2 id="é…ç½®Nginx"><a href="#é…ç½®Nginx" class="headerlink" title="é…ç½®Nginx"></a>é…ç½®Nginx</h2><ol><li>å¯åŠ¨nginx</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><ol><li>æŸ¥æ‰¾æ­£åœ¨è¿è¡Œä¸­çš„nginxæœåŠ¡</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep nginx</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/night1/image-20201209112109135.png" alt="image-20201209112109135"></p><ol><li>ä¿®æ”¹é…ç½®æ–‡ä»¶</li></ol><ul><li>ä»æ­£åœ¨è¿è¡Œä¸­çš„nginxæœåŠ¡å¯ä»¥çŸ¥é“å½“å‰ç”Ÿæ•ˆçš„é…ç½®æ–‡ä»¶ã€‚</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><ol><li>åœ¨httpèŠ‚ç‚¹ä¸‹æ·»åŠ serverèŠ‚ç‚¹ï¼Œå¹¶å®Œæˆé‡å®šå‘</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">http&#123;</span><br><span class="line">server&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å…·ä½“é…ç½®å¦‚ä¸‹ï¼š</p><ul><li>httpèŠ‚ç‚¹ä¸­å¯ä»¥æ·»åŠ å¤šä¸ªserverèŠ‚ç‚¹ã€‚</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">    server&#123;</span><br><span class="line">        #ç›‘å¬443ç«¯å£</span><br><span class="line">        listen 443 ssl;</span><br><span class="line">        #å¯¹åº”çš„åŸŸåï¼ŒæŠŠwww.asimok.comæ”¹æˆä½ ä»¬è‡ªå·±çš„åŸŸåå°±å¯ä»¥äº†</span><br><span class="line">        server_name www.asimok.com;</span><br><span class="line">        #ä»è…¾è®¯äº‘è·å–åˆ°çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„å…¨è·¯å¾„</span><br><span class="line">        ssl_certificate /etc/ssl/1_www.asimok.site_bundle.crt;</span><br><span class="line">        #ä»è…¾è®¯äº‘è·å–åˆ°çš„ç¬¬äºŒä¸ªæ–‡ä»¶çš„å…¨è·¯å¾„</span><br><span class="line">        ssl_certificate_key /etc/ssl/2_www.asimok.site.key;</span><br><span class="line">        ssl_session_timeout 5m;</span><br><span class="line">        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;</span><br><span class="line">        ssl_prefer_server_ciphers on;</span><br><span class="line">        #è¿™æ˜¯æˆ‘çš„ä¸»é¡µè®¿é—®åœ°å€ï¼Œå› ä¸ºä½¿ç”¨çš„æ˜¯é™æ€çš„htmlç½‘é¡µï¼Œæ‰€ä»¥ç›´æ¥ä½¿ç”¨locationå°±å¯ä»¥å®Œæˆäº†ã€‚</span><br><span class="line">        location / &#123;</span><br><span class="line">                #æ–‡ä»¶å¤¹</span><br><span class="line">                root /root/mq_blog/public;</span><br><span class="line">                #ä¸»é¡µæ–‡ä»¶</span><br><span class="line">                index index.html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"># å¦‚æœç”¨æˆ·ä½¿ç”¨çš„æ˜¯httpåè®®è¿›è¡Œè®¿é—®ï¼Œé‚£ä¹ˆé»˜è®¤æ‰“å¼€çš„ç«¯å£æ˜¯80ç«¯å£ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦åšä¸€ä¸ªé‡å®šå‘ï¼Œæˆ‘ä»¬åœ¨ä¸Šä¸€ä¸ªä»£ç å—çš„åŸºç¡€ä¸Šå¢åŠ ä¸€ä¸ªserverèŠ‚ç‚¹æä¾›é‡å®šå‘æœåŠ¡ã€‚</span><br><span class="line"># å°† HTTP è¯·æ±‚è‡ªåŠ¨é‡å®šå‘åˆ° HTTPS</span><br><span class="line">    server&#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        server_name www.asimok.com;</span><br><span class="line">        rewrite ^/(.*)$ https://www.asimok.com:443/$1 permanent;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ol><li>å¯¹é…ç½®æ–‡ä»¶è¿›è¡Œæ ¡éªŒ</li></ol><p>ä¿å­˜é…ç½®æ–‡ä»¶ä¹‹åæ‰§è¡Œï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -t</span><br></pre></td></tr></table></figure><p>susccessfulå³å¯</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/night1/image-20201209112907309.png" alt="image-20201209112907309"></p><ol><li>é‡å¯nginxæœåŠ¡</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><ol><li>é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><h2 id="æµ‹è¯•"><a href="#æµ‹è¯•" class="headerlink" title="æµ‹è¯•"></a>æµ‹è¯•</h2><p>ä½¿ç”¨httpsè®¿é—®ï¼š<a href="https://asimok.site">https://asimok.site</a></p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> https </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>anacondaæ›´æ¢æ¸…åæºåŠ å¿«ä¸‹è½½é€Ÿåº¦</title>
      <link href="/2020/12/08/anaconda%E6%9B%B4%E6%8D%A2%E6%B8%85%E5%8D%8E%E6%BA%90%E5%8A%A0%E5%BF%AB%E4%B8%8B%E8%BD%BD%E9%80%9F%E5%BA%A6/"/>
      <url>/2020/12/08/anaconda%E6%9B%B4%E6%8D%A2%E6%B8%85%E5%8D%8E%E6%BA%90%E5%8A%A0%E5%BF%AB%E4%B8%8B%E8%BD%BD%E9%80%9F%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<h1 id="anacondaæ›´æ¢æ¸…åæºåŠ å¿«ä¸‹è½½é€Ÿåº¦"><a href="#anacondaæ›´æ¢æ¸…åæºåŠ å¿«ä¸‹è½½é€Ÿåº¦" class="headerlink" title="anacondaæ›´æ¢æ¸…åæºåŠ å¿«ä¸‹è½½é€Ÿåº¦"></a>anacondaæ›´æ¢æ¸…åæºåŠ å¿«ä¸‹è½½é€Ÿåº¦</h1><p>ç»ˆç«¯æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼š<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --append channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/fastai/</span><br><span class="line">conda config --append channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">conda config --append channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ </span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure><br>å¯ä»¥çœ‹åˆ° ~/.condarcæ–‡ä»¶å¦‚ä¸‹ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">  - defaults</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/fastai/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/</span><br><span class="line">show_channel_urls: true</span><br></pre></td></tr></table></figure><p>é…ç½®å®Œæˆåï¼Œä¸‹è½½é€Ÿåº¦ä¼šæå‡å¾ˆå¤šã€‚</p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LinuxæŒ‚è½½ç§»åŠ¨ç¡¬ç›˜å‡ºç°é”™è¯¯ï¼šmount:unknown filesystem type &#39;exfat&#39;</title>
      <link href="/2020/12/07/Linux%E6%8C%82%E8%BD%BD%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AF/"/>
      <url>/2020/12/07/Linux%E6%8C%82%E8%BD%BD%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="LinuxæŒ‚è½½ç§»åŠ¨ç¡¬ç›˜å‡ºç°é”™è¯¯ï¼šmount-unknown-filesystem-type-â€˜exfatâ€™"><a href="#LinuxæŒ‚è½½ç§»åŠ¨ç¡¬ç›˜å‡ºç°é”™è¯¯ï¼šmount-unknown-filesystem-type-â€˜exfatâ€™" class="headerlink" title="LinuxæŒ‚è½½ç§»åŠ¨ç¡¬ç›˜å‡ºç°é”™è¯¯ï¼šmount:unknown filesystem type â€˜exfatâ€™"></a>LinuxæŒ‚è½½ç§»åŠ¨ç¡¬ç›˜å‡ºç°é”™è¯¯ï¼šmount:unknown filesystem type â€˜exfatâ€™</h1><p>exfatæ˜¯å¯ä»¥åœ¨windows,mac,Linuxå…±äº«çš„æ–‡ä»¶ç³»ç»Ÿ</p><p><strong>è§£å†³åŠæ³•ï¼š</strong></p><ul><li><p>å®‰è£…exfat-fuse:</p><p><code>sudo apt-get install exfat-fuse</code></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch_pretrained_bertçš„é…ç½®ä½¿ç”¨</title>
      <link href="/2020/12/07/Bert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2020/12/07/Bert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="pytorch-pretrained-bertçš„é…ç½®ä½¿ç”¨"><a href="#pytorch-pretrained-bertçš„é…ç½®ä½¿ç”¨" class="headerlink" title="pytorch_pretrained_bertçš„é…ç½®ä½¿ç”¨"></a>pytorch_pretrained_bertçš„é…ç½®ä½¿ç”¨</h1><h2 id="pytorch-pretrained-bert"><a href="#pytorch-pretrained-bert" class="headerlink" title="pytorch_pretrained_bert"></a>pytorch_pretrained_bert</h2><blockquote><p><a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p></blockquote><ul><li><p>å®‰è£…åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œæƒé‡çš„åŒ…ï¼špip install pytorch-pretrained-bert</p></li><li><p>ä¿®æ”¹æºç </p><blockquote><p>ä»äºšé©¬é€Šç«™ç‚¹ä¸‹è½½éå¸¸æ…¢ï¼Œå¯ä»¥å°†æºç ä¸­çš„åœ°å€æ›´æ¢ä¸ºæœ¬åœ°æ–‡ä»¶ã€‚</p></blockquote><ol><li>pytorch_pretrained_bert/modeling.pyçš„ 40-51è¡Œ</li></ol><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201207210830.png" alt="image-20201207210830430"></p><ol><li>pytorch_pretrained_bert/tokenization.pyçš„30-41è¡Œ</li></ol></li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201207210928.png" alt="image-20201207210928928"></p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> bert </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux(Ubuntu)å®‰è£…é…ç½®</title>
      <link href="/2020/12/07/Linux(Ubuntu)%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/12/07/Linux(Ubuntu)%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux-Ubuntu-å®‰è£…é…ç½®"><a href="#Linux-Ubuntu-å®‰è£…é…ç½®" class="headerlink" title="Linux(Ubuntu)å®‰è£…é…ç½®"></a>Linux(Ubuntu)å®‰è£…é…ç½®</h1><h2 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><h3 id="åˆ†åŒº"><a href="#åˆ†åŒº" class="headerlink" title="åˆ†åŒº"></a>åˆ†åŒº</h3><div class="table-container"><table><thead><tr><th>æŒ‚è½½ç‚¹</th><th>è¯´æ˜</th><th>å¤§å°</th></tr></thead><tbody><tr><td>/</td><td>ä¸»åˆ†åŒº</td><td>100G</td></tr><tr><td>/home</td><td></td><td>100G</td></tr><tr><td>/efi</td><td>ä¸å…¶ä»–ç³»ç»Ÿå…±ç”¨å³å¯</td><td>200M</td></tr></tbody></table></div><h3 id="æŒ‚è½½åˆ†åŒºåˆ°-home"><a href="#æŒ‚è½½åˆ†åŒºåˆ°-home" class="headerlink" title="æŒ‚è½½åˆ†åŒºåˆ°/home"></a>æŒ‚è½½åˆ†åŒºåˆ°/home</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo fdisk /dev/vdb</span><br><span class="line">mount /dev/sda4 /home</span><br></pre></td></tr></table></figure><p>å¼€æœºè‡ªåŠ¨æŒ‚è½½ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/fstab</span><br><span class="line">/dev/sda4        /home        ext4        defaults        0  0</span><br></pre></td></tr></table></figure><p>éªŒè¯ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df -h</span><br></pre></td></tr></table></figure><h2 id="é…ç½®"><a href="#é…ç½®" class="headerlink" title="é…ç½®"></a>é…ç½®</h2><ul><li>å®‰è£…win10åŒç³»ç»Ÿä¼šå¯¼è‡´æ—¶é—´å·®é—®é¢˜</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timedatectl set-local-rtc true</span><br></pre></td></tr></table></figure><ul><li>æ›´æ¢é•œåƒæº</li></ul><blockquote><p>æŸ¥çœ‹ç³»ç»Ÿä»£å·(Ubuntu19.10)<br><code>lsb_release -c</code></p></blockquote><p>1.é•œåƒæºæ–‡ä»¶å­˜æ”¾åœ¨/etc/apt/sources.listä¸‹ï¼Œæ‹·è´ä¸€ä»½sources.listæ–‡ä»¶ï¼Œä»¥é˜²ä¸‡ä¸€ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp -v /etc/apt/sources.list /etc/apt/sources.list.backup</span><br></pre></td></tr></table></figure><p>2.ä½¿ç”¨geditç¼–è¾‘é•œåƒæºæ–‡ä»¶</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo  gedit /etc/apt/sources.list</span><br></pre></td></tr></table></figure><p>3.æ›¿æ¢æ–‡ä»¶ï¼Œå°†ä»¥ä¸‹å†…å®¹æ‹·è´åˆ°sources.list,å°†ä¸‹é¢ä»£ç ä¸­çš„ã€€ eoanã€€æ”¹ä¸ºè‡ªå·±ç‰ˆæœ¬çš„ç³»ç»Ÿä»£å·å³å¯ã€‚</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>ï¼”.æ”¹å¥½ä¹‹åæ›´æ–°ä¸€ä¸‹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br></pre></td></tr></table></figure><ul><li>ä»£ç†</li></ul><div class="table-container"><table><thead><tr><th>åè®®</th><th>ip</th><th>ç«¯å£</th></tr></thead><tbody><tr><td>http</td><td>127.0.0.1</td><td>ç«¯å£ä¸€èˆ¬12333</td></tr><tr><td>socks v5</td><td>127.0.0.1</td><td>1080</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Liunx </tag>
            
            <tag> Ubuntu </tag>
            
            <tag> é…ç½® </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æ™ºèƒ½å¼€å…³</title>
      <link href="/2020/12/06/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3/"/>
      <url>/2020/12/06/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3/</url>
      
        <content type="html"><![CDATA[<h1 id="æ™ºèƒ½å¼€å…³"><a href="#æ™ºèƒ½å¼€å…³" class="headerlink" title="æ™ºèƒ½å¼€å…³"></a>æ™ºèƒ½å¼€å…³</h1><p>æ¼”ç¤ºè§†é¢‘ï¼š<a href="https://www.bilibili.com/video/BV1qz4y1k7xS/">https://www.bilibili.com/video/BV1qz4y1k7xS/</a></p><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201202174343.jpeg" alt="å›¾åƒ"></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201206135913.jpg" alt="Screenshot_2020-12-02-12-39-30-190_com.example.do"></p><h2 id="èµ„æ–™"><a href="#èµ„æ–™" class="headerlink" title="èµ„æ–™"></a>èµ„æ–™</h2><p>å®Œæ•´æ•™å­¦è§†é¢‘ï¼š</p><ul><li>ç¬¬ä¸€æœŸï¼š<a href="https://www.bilibili.com/video/BV1Ma4y1W7jh/">https://www.bilibili.com/video/BV1Ma4y1W7jh/</a></li><li>ç¬¬äºŒæœŸï¼š<a href="https://www.bilibili.com/video/BV1ZK41137YH/">https://www.bilibili.com/video/BV1ZK41137YH/</a></li><li>ç¬¬ä¸‰æœŸï¼š<a href="https://www.bilibili.com/video/BV18Z4y1g7VS/">https://www.bilibili.com/video/BV18Z4y1g7VS/</a></li></ul><h2 id="ç»“æ„"><a href="#ç»“æ„" class="headerlink" title="ç»“æ„"></a>ç»“æ„</h2><p><strong>ç¡¬ä»¶éƒ¨åˆ†      æœåŠ¡å™¨       å®‰å“APP</strong></p><blockquote><p>é€šä¿¡åè®®ï¼šMQTT</p></blockquote><h2 id="æ¸…å•"><a href="#æ¸…å•" class="headerlink" title="æ¸…å•"></a>æ¸…å•</h2><p><strong>NodeMCU</strong>ï¼šESP8266ä¸²å£wifiæ¨¡å— NodeMCU Lua V3ç‰©è”ç½‘å¼€å‘æ¿ CH340 CP2102(æ·˜å®æœç´¢)<br><strong>èˆµæœº</strong>ï¼š180åº¦<br><strong>ç”µæºæ¨¡å—</strong>ï¼šæä¾›5v,3.3vè¾“å‡º<br><strong>dht11</strong>æ¸©æ¹¿åº¦ä¼ æ„Ÿå™¨<br><strong>æœé‚¦çº¿</strong> ï¼šå…¬å¯¹å…¬  å…¬å¯¹æ¯  æ¯å¯¹æ¯</p><blockquote><p>esp8266åº“ï¼š<code>https://arduino.esp8266.com/stable/package_esp8266com_index.json</code></p></blockquote><h2 id="å¼€å‘å·¥å…·"><a href="#å¼€å‘å·¥å…·" class="headerlink" title="å¼€å‘å·¥å…·"></a>å¼€å‘å·¥å…·</h2><ul><li>Arduino IDE</li><li>EMQ X</li><li>AndroidStudio</li></ul><h2 id="Android-APPä»£ç "><a href="#Android-APPä»£ç " class="headerlink" title="Android APPä»£ç "></a>Android APPä»£ç </h2><blockquote><p>GitHub:<a href="https://github.com/Asimok/dorm_light">https://github.com/Asimok/dorm_light</a></p></blockquote><h2 id="nodeMCUä»£ç "><a href="#nodeMCUä»£ç " class="headerlink" title="nodeMCUä»£ç "></a>nodeMCUä»£ç </h2><blockquote><p>GitHub:<a href="https://github.com/Asimok/unoproject_backup/tree/master/dorm_light/dorm_light_temp_8266">https://github.com/Asimok/unoproject_backup/tree/master/dorm_light/dorm_light_temp_8266</a></p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">  æ™ºèƒ½å¼€å…³nodemcuä»£ç </span></span><br><span class="line"><span class="comment">  D0 èˆµæœºå·¦</span></span><br><span class="line"><span class="comment">  D1 èˆµæœºå³</span></span><br><span class="line"><span class="comment">  D2 dht11</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">/*arduinoå®‰è£…è‡ªå¸¦*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;Servo.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;SoftwareSerial.h&gt;</span></span></span><br><span class="line"><span class="comment">/*è‡ªè¡Œå®‰è£…*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ESP8266WiFi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;PubSubClient.h&gt;</span></span></span><br><span class="line"><span class="comment">/*å¼•å…¥æœ¬åœ°å¤´æ–‡ä»¶*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;dht11.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;ArduinoJson-v6.15.2.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> dht11Pin D2   <span class="comment">//å®šä¹‰æ¸©æ¹¿åº¦é’ˆè„šå·ä¸ºD2å·å¼•è„š</span></span></span><br><span class="line"><span class="comment">/*å®ä¾‹åŒ–å¯¹è±¡*/</span></span><br><span class="line">dht11 dht;</span><br><span class="line">Servo left_servo, right_servo;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**MQTTæœåŠ¡å™¨å‚æ•°é…ç½®*/</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* wifiSSID = <span class="string">&quot;wifiåç§°&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* password = <span class="string">&quot;å¯†ç &quot;</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* mqttServer = <span class="string">&quot;IP&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> mqttPort = <span class="number">1883</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* clientId = <span class="string">&quot;è®¾å¤‡id&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* topic = <span class="string">&quot;è®¢é˜…ä¸»é¢˜&quot;</span>;</span><br><span class="line"></span><br><span class="line">WiFiClient espClient;</span><br><span class="line"><span class="function">PubSubClient <span class="title">client</span><span class="params">(espClient)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*å¼€å…³çŠ¶æ€*/</span></span><br><span class="line"><span class="keyword">bool</span> leftStatue = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">bool</span> rightStatue = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">setup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  delay(<span class="number">1000</span>);</span><br><span class="line">  switchlight(<span class="string">&quot;closeLeft&quot;</span>);</span><br><span class="line">  delay(<span class="number">500</span>);</span><br><span class="line">  switchlight(<span class="string">&quot;closeRight&quot;</span>);</span><br><span class="line">  delay(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  <span class="comment">/*è¿æ¥wifi*/</span></span><br><span class="line">  WiFi.begin(wifiSSID, password);</span><br><span class="line">  <span class="keyword">while</span> (WiFi.status() != WL_CONNECTED) &#123;</span><br><span class="line">    delay(<span class="number">500</span>);</span><br><span class="line">    <span class="comment">// Serial.println(&quot;Connecting to WiFi..&quot;);</span></span><br><span class="line">  &#125;</span><br><span class="line">  Serial.println(<span class="string">&quot;Connected to the WiFi network&quot;</span>);</span><br><span class="line">  <span class="comment">/*è¿æ¥MQTTæœåŠ¡å™¨*/</span></span><br><span class="line">  client.setServer(mqttServer, mqttPort);</span><br><span class="line">  client.setCallback(callback);</span><br><span class="line">  <span class="keyword">while</span> (!client.connected()) &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;Connecting to MQTT...&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (client.connect(clientId)) &#123;</span><br><span class="line">      Serial.println(<span class="string">&quot;MQTT connected&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      Serial.print(<span class="string">&quot;failed with state &quot;</span>);</span><br><span class="line">      Serial.print(client.state());</span><br><span class="line">      delay(<span class="number">2000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  pinMode(dht11Pin, OUTPUT);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">char</span> buff[<span class="number">50</span>];</span><br><span class="line">  <span class="built_in">memset</span>(buff, <span class="number">0</span>, <span class="keyword">sizeof</span>(buff));</span><br><span class="line">  <span class="built_in">strcpy</span>(buff, clientId);</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span> *buff2 = <span class="string">&quot; ä¸Šçº¿&quot;</span>;</span><br><span class="line">  <span class="built_in">strcat</span>(buff, buff2);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯</span></span><br><span class="line">  client.publish(topic, buff );</span><br><span class="line">  <span class="comment">//è®¢é˜…ä¸»é¢˜</span></span><br><span class="line">  client.subscribe(topic);</span><br><span class="line">  delay(<span class="number">100</span>);</span><br><span class="line">  <span class="comment">//  åˆå§‹åŒ–å¼€å…³çŠ¶æ€</span></span><br><span class="line">  switchlight(<span class="string">&quot;closeLeft&quot;</span>);</span><br><span class="line">  delay(<span class="number">1000</span>);</span><br><span class="line">  switchlight(<span class="string">&quot;closeRight&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">get_dht11</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">char</span> msg[<span class="number">500</span>];</span><br><span class="line">  <span class="keyword">int</span> tol = dht.read(dht11Pin);    <span class="comment">//å°†è¯»å–åˆ°çš„å€¼èµ‹ç»™tol</span></span><br><span class="line">  <span class="keyword">int</span> temp = (<span class="keyword">float</span>)dht.temperature; <span class="comment">//å°†æ¸©åº¦å€¼èµ‹å€¼ç»™temp</span></span><br><span class="line">  <span class="keyword">int</span> humi = (<span class="keyword">float</span>)dht.humidity; <span class="comment">//å°†æ¹¿åº¦å€¼èµ‹ç»™humi</span></span><br><span class="line">  </span><br><span class="line">  delay(<span class="number">10</span>);      <span class="comment">//å»¶æ—¶1ç§’</span></span><br><span class="line">  StaticJsonDocument&lt;<span class="number">200</span>&gt; temperature_data;</span><br><span class="line">  temperature_data[<span class="string">&quot;sensor&quot;</span>] = <span class="string">&quot;DHT11&quot;</span>;</span><br><span class="line">  temperature_data[<span class="string">&quot;temp&quot;</span>] = temp;</span><br><span class="line">  temperature_data[<span class="string">&quot;humi&quot;</span>] = humi;</span><br><span class="line">  serializeJson(temperature_data, msg);</span><br><span class="line">  <span class="comment">//Serial.println(msg);</span></span><br><span class="line">  client.publish(topic, msg);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   æ–­å¼€é‡è¿</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reconnect_mqtt</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (!client.connected()) &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;reConnecting to MQTT...&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (client.connect(clientId)) &#123;</span><br><span class="line">      Serial.println(<span class="string">&quot;connected&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      Serial.print(<span class="string">&quot;failed with state &quot;</span>);</span><br><span class="line">      Serial.print(client.state());</span><br><span class="line">      delay(<span class="number">2000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reconnect_wifi</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (WiFi.status() != WL_CONNECTED) &#123;</span><br><span class="line">    delay(<span class="number">500</span>);</span><br><span class="line">    Serial.println(<span class="string">&quot;Connecting to WiFi..&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  Serial.println(<span class="string">&quot;reConnected to the WiFi network&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">callback</span><span class="params">(<span class="keyword">char</span>* topic, byte* payload, <span class="keyword">unsigned</span> <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//æ”¶åˆ°æ¶ˆæ¯</span></span><br><span class="line">  Serial.print(<span class="string">&quot;Message:&quot;</span>);</span><br><span class="line">  <span class="keyword">char</span> a[<span class="number">2000</span>] = <span class="string">&quot;&quot;</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">    Serial.print((<span class="keyword">char</span>)payload[i]);</span><br><span class="line">    a[i] = (<span class="keyword">char</span>)payload[i];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  docode(a);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">docode</span><span class="params">(<span class="keyword">char</span> json[<span class="number">2000</span>])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="comment">//  è§£ææŒ‡ä»¤</span></span><br><span class="line">  <span class="comment">//  &#123;&quot;code&quot;:&quot;openLeft&quot;&#125;</span></span><br><span class="line">  StaticJsonDocument&lt;<span class="number">200</span>&gt; doc;</span><br><span class="line">  deserializeJson(doc, json);</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span>* code = doc[<span class="string">&quot;code&quot;</span>];</span><br><span class="line">  Serial.println();</span><br><span class="line">  Serial.println(code);</span><br><span class="line">  String tempcode;</span><br><span class="line">  tempcode = String(code);</span><br><span class="line">  <span class="keyword">if</span> (tempcode == <span class="string">&quot;get_dht11&quot;</span>)</span><br><span class="line">    get_dht11();</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (tempcode == <span class="string">&quot;get_light_status&quot;</span>)</span><br><span class="line">    send_light_data();</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    switchlight(tempcode);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">switchlight</span><span class="params">(String tempcode)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  delay(<span class="number">50</span>);</span><br><span class="line">  <span class="keyword">if</span> (tempcode == <span class="string">&quot;openLeft&quot;</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    left_servo.attach(D0);</span><br><span class="line">    left_servo.write(<span class="number">82</span>);</span><br><span class="line">    delay(<span class="number">300</span>);</span><br><span class="line">    left_servo.write(<span class="number">45</span>);</span><br><span class="line">    delay(<span class="number">100</span>);</span><br><span class="line">    left_servo.detach();</span><br><span class="line">    leftStatue = <span class="literal">true</span>;</span><br><span class="line">    send_light_data();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (tempcode == <span class="string">&quot;openRight&quot;</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    right_servo.attach(D1);</span><br><span class="line">    right_servo.write(<span class="number">8</span>);</span><br><span class="line">    delay(<span class="number">300</span>);</span><br><span class="line">    right_servo.write(<span class="number">65</span>);</span><br><span class="line">    delay(<span class="number">100</span>);</span><br><span class="line">    right_servo.detach();</span><br><span class="line">    rightStatue = <span class="literal">true</span>;</span><br><span class="line">    send_light_data();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (tempcode == <span class="string">&quot;closeLeft&quot;</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    left_servo.attach(D0);</span><br><span class="line">    left_servo.write(<span class="number">2</span>);</span><br><span class="line">    delay(<span class="number">300</span>);</span><br><span class="line">    left_servo.write(<span class="number">45</span>);</span><br><span class="line">    delay(<span class="number">100</span>);</span><br><span class="line">    left_servo.detach();</span><br><span class="line">    leftStatue = <span class="literal">false</span>;</span><br><span class="line">    send_light_data();</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (tempcode == <span class="string">&quot;closeRight&quot;</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    right_servo.attach(D1);</span><br><span class="line">    right_servo.write(<span class="number">130</span>);</span><br><span class="line">    delay(<span class="number">300</span>);</span><br><span class="line">    right_servo.write(<span class="number">65</span>);</span><br><span class="line">    delay(<span class="number">100</span>);</span><br><span class="line">    right_servo.detach();</span><br><span class="line">    rightStatue = <span class="literal">false</span>;</span><br><span class="line">    send_light_data();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">send_light_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  delay(<span class="number">10</span>);</span><br><span class="line">  <span class="keyword">char</span> msg[<span class="number">500</span>];</span><br><span class="line">  StaticJsonDocument&lt;<span class="number">200</span>&gt; light_data;</span><br><span class="line">  light_data[<span class="string">&quot;sensor&quot;</span>] = <span class="string">&quot;servo&quot;</span>;</span><br><span class="line">  light_data[<span class="string">&quot;left&quot;</span>] = leftStatue;</span><br><span class="line">  light_data[<span class="string">&quot;right&quot;</span>] = rightStatue;</span><br><span class="line">  serializeJson(light_data, msg);</span><br><span class="line">  <span class="comment">// Serial.println(msg);</span></span><br><span class="line">  </span><br><span class="line">  client.publish(topic, msg );</span><br><span class="line">  delay(<span class="number">100</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">loop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">//é‡è¿æœºåˆ¶</span></span><br><span class="line">  <span class="keyword">if</span> (!client.connected()) &#123;</span><br><span class="line">    reconnect_mqtt();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (WiFi.status() != WL_CONNECTED)</span><br><span class="line">  &#123;</span><br><span class="line">    reconnect_wifi();</span><br><span class="line">  &#125;</span><br><span class="line">  client.loop();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> ç¡¬ä»¶å¼€å‘ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQTT </tag>
            
            <tag> Arduino </tag>
            
            <tag> Android </tag>
            
            <tag> C </tag>
            
            <tag> ESP8266 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Is Graph Structure Necessary for Multi-hop Question Answering?</title>
      <link href="/2020/12/03/Is%20Graph%20Structure%20Necessary%20for%20Multi-hop%20Question%20Answering/"/>
      <url>/2020/12/03/Is%20Graph%20Structure%20Necessary%20for%20Multi-hop%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="Is-Graph-Structure-Necessary-for-Multi-hop-Question-Answering"><a href="#Is-Graph-Structure-Necessary-for-Multi-hop-Question-Answering" class="headerlink" title="Is Graph Structure Necessary for Multi-hop Question Answering?"></a>Is Graph Structure Necessary for Multi-hop Question Answering?</h1><blockquote><p>è®ºæ–‡ï¼šEMNLP 2020-Is Graph Structure Necessary for Multi-hop Question Answering</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>æ¢è®¨å¤šæ­¥æ¨ç†é—®ç­”ä»»åŠ¡ä¸­æ˜¯å¦éœ€è¦å›¾ç»“æ„çš„é—®é¢˜ã€‚</p><p>éªŒè¯è‡ªæ³¨æ„åŠ›æˆ–è€…Transformerå¯èƒ½æ›´åŠ æ“…é•¿å¤„ç†å¤šæ­¥æ¨ç†é—®ç­”ä»»åŠ¡ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><ul><li>æœ¬æ–‡çš„å®éªŒä½¿ç”¨Distractorè®¾å®šã€‚</li></ul><h3 id="åŸºçº¿æ¨¡å‹"><a href="#åŸºçº¿æ¨¡å‹" class="headerlink" title="åŸºçº¿æ¨¡å‹"></a>åŸºçº¿æ¨¡å‹</h3><ul><li><p>ä½¿ç”¨ä¸€ä¸ªæ£€ç´¢æ¨¡å‹æ£€å‡ºå€™é€‰æ®µè½ä¸­çš„ç›¸å…³æ®µè½å¹¶è¾“å…¥ä¸€ä¸ªåŸºäºå›¾çš„é—®ç­”æ¨¡å‹ï¼Œå…¶ä¸­å›¾ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯ç”±ä¸€ä¸ªé¢å¤–çš„NERæ¨¡å‹æ‰€è¯†åˆ«å¾—åˆ°çš„å®ä½“æ„æˆã€‚</p></li><li><p>ä½¿ç”¨ä¸€ä¸ª<strong>RoBERTa large</strong>æ¨¡å‹æ¥è®¡ç®—æ¯ä¸ªé—®é¢˜ä¸å€™é€‰æ®µè½ä¹‹é—´çš„ç›¸å…³æ€§ã€‚</p></li><li>åœ¨ç¼–ç å±‚ï¼Œå°†é—®é¢˜å’Œä¸Šä¸‹æ–‡æ‹¼æ¥å¹¶è¾“å…¥å¦ä¸€ä¸ª<strong>RoBERTa large</strong>æ¨¡å‹ï¼Œæ‰€å¾—åˆ°çš„è¾“å‡ºè¢«è¾“å…¥åˆ°ä¸€ä¸ªåŒå‘æ³¨æ„åŠ›å±‚æ¥å¾—åˆ°ç¼–ç å±‚çš„è¾“å‡ºã€‚</li><li>åœ¨å›¾èåˆå±‚(Graph Fusion Block)ï¼Œç»™å®šç¬¬$t-1$æ­¥çš„ä¸Šä¸‹æ–‡è¡¨ç¤º$C<em>{t-1}$ï¼Œå…¶ä¸­æ‰€æœ‰<strong>token</strong>çš„å‘é‡è¡¨ç¤ºéƒ½ä¼šé€šè¿‡<strong>mean-max</strong>æ± åŒ–å±‚æ¥å¾—åˆ°å®ä½“å›¾ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹çš„è¡¨ç¤º$H</em>{t-1}\in â„^{2d\times N}$ï¼Œå…¶ä¸­Nä¸ºå®ä½“çš„æ•°é‡ã€‚</li><li>åœ¨é¢„æµ‹å±‚ï¼Œè¿™é‡Œä½¿ç”¨äº†ä¸€ç§â€œç€‘å¸ƒå¼â€çš„ç»“æ„æ¥é¢„æµ‹<strong>HotpotQA</strong>ä»»åŠ¡æ‰€è¦æ±‚çš„ç­”æ¡ˆæ–‡æœ¬å’Œçº¿ç´¢å¥å­ã€‚</li><li>ä¸ºäº†å¯»æ‰¾æ–‡æœ¬ä¸­çš„å®ä½“å¹¶æ„å»ºå®ä½“å›¾ï¼Œä½¿ç”¨ä¸€ä¸ªåŸºäºBERTçš„NERæ¨¡å‹å¹¶åœ¨<strong>CoNLLâ€™03</strong>æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒã€‚</li></ul><h3 id="ç†è§£å›¾ç½‘ç»œ"><a href="#ç†è§£å›¾ç½‘ç»œ" class="headerlink" title="ç†è§£å›¾ç½‘ç»œ"></a>ç†è§£å›¾ç½‘ç»œ</h3><p>åŸå§‹æ–‡æœ¬ä¸­çš„å®ä½“è¢«å»ºæ¨¡ä¸ºå®ä½“å›¾å¹¶ä½¿ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œè¿›è¡Œå¤„ç†ï¼Œå½“å®ä½“å›¾ä¸ºå…¨è¿æ¥æ—¶ï¼Œå›¾æ³¨æ„åŠ›å±‚å°†é€€åŒ–ä¸ºä¼ ç»Ÿçš„è‡ªæ³¨æ„åŠ›å±‚ã€‚</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201202220312.png" alt="image-20201202220312314"></p><p>â€‹        ä¸ºäº†å›ç­”ä¸€ä¸ªéœ€è¦å¤šæ­¥æ¨ç†çš„é—®é¢˜ï¼Œé¦–å…ˆéœ€è¦ä»åŸå§‹æ–‡æœ¬ä¸­æ‰¾åˆ°ä¸é—®é¢˜ä¸­å‡ºç°çš„ç›¸åŒå®ä½“ï¼Œç„¶åä»¥è¯¥å®ä½“ä½œä¸ºèµ·ç‚¹æ„å»ºä»è¯¥å®ä½“åˆ°å…¶ä»–å…±ç°æˆ–ç›¸åŒå®ä½“çš„æ¨ç†é“¾ã€‚</p><h4 id="å®éªŒ"><a href="#å®éªŒ" class="headerlink" title="å®éªŒ"></a>å®éªŒ</h4><p>é¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨Feature-basedçš„æ–¹æ³•ã€‚</p><h5 id="åŒ…å«å›¾ç»“æ„çš„æ¨¡å‹"><a href="#åŒ…å«å›¾ç»“æ„çš„æ¨¡å‹" class="headerlink" title="åŒ…å«å›¾ç»“æ„çš„æ¨¡å‹"></a>åŒ…å«å›¾ç»“æ„çš„æ¨¡å‹</h5><blockquote><p>éªŒè¯ä½œä¸ºå…ˆéªŒçŸ¥è¯†çš„é‚»æ¥çŸ©é˜µæ˜¯å¦å¿…è¦ã€‚</p></blockquote><ul><li><p>éªŒè¯ä½œä¸ºå…ˆéªŒçŸ¥è¯†çš„é‚»æ¥çŸ©é˜µæ˜¯å¦å¿…è¦ã€‚</p></li><li><p>è¯„ä¼°äº†ä¸åŒé‚»æ¥çŸ©é˜µå¯†åº¦å¯¹äºç»“æœçš„å½±å“ã€‚</p><blockquote><p>å°†ä¸€ä¸ª0-1çŸ©é˜µçš„å¯†åº¦å®šä¹‰ä¸ºå…¶ä¸­1çš„æ¯”ä¾‹ã€‚</p></blockquote></li></ul><h5 id="ä¸åŒ…å«å›¾çš„æ¨¡å‹"><a href="#ä¸åŒ…å«å›¾çš„æ¨¡å‹" class="headerlink" title="ä¸åŒ…å«å›¾çš„æ¨¡å‹"></a>ä¸åŒ…å«å›¾çš„æ¨¡å‹</h5><p>â€‹        ä¸ºäº†éªŒè¯å›¾ç»“æ„æœ¬èº«æ˜¯å¦æœ‰å¿…è¦ï¼Œè¿™é‡Œç›´æ¥å°†ä¸¤å±‚çš„å›¾ç»“æ„æ›¿æ¢ä¸ºä¼ ç»Ÿçš„Transformerå±‚ã€‚å…¶ä¸­ç¼–ç å±‚å¾—åˆ°çš„ä¸Šä¸‹æ–‡tokenè¡¨ç¤ºç›´æ¥è¾“å…¥Transformerã€‚</p><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p><strong>HotpotQAæ•°æ®é›†</strong></p><ul><li>ä¸€ä¸ªå¹¿æ³›ä½¿ç”¨çš„å¤šæ­¥æ¨ç†é—®ç­”æ•°æ®ã€‚</li><li>è¯¥æ•°æ®åŒ…å«ä¸¤ç§è®¾å®šï¼š<strong>Distractor</strong>,<strong>Fullwiki</strong>ã€‚<ul><li>Distractorè®¾å®šä¸­æ¯ä¸ªé—®é¢˜å¯¹åº”2ä¸ªæ­£ç¡®æ®µè½å’Œ8ä¸ªå¹²æ‰°æ®µè½ã€‚</li><li>Fullwikiè®¾å®šåˆ™è¦æ±‚æ¨¡å‹ä»æ•´ä¸ªç»´åŸºç™¾ç§‘ä¸­æ£€å‡ºæ­£ç¡®çš„æ®µè½ã€‚</li></ul></li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><h3 id="åŸºçº¿æ¨¡å‹-1"><a href="#åŸºçº¿æ¨¡å‹-1" class="headerlink" title="åŸºçº¿æ¨¡å‹"></a>åŸºçº¿æ¨¡å‹</h3><ul><li>åŸºçº¿æ¨¡å‹åœ¨HotpotQAæµ‹è¯•é›†çš„ç»“æœ</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201202214006.png" alt="image-20201202214006013"></p><p>æœ¬æ–‡æå‡ºçš„æ¨¡å‹ï¼Œåœ¨HotpotQAéšè—çš„æµ‹è¯•é›†ä¸Šä¸å…¶ä»–æ¨¡å‹ç›¸æ¯”æ•ˆæœæœ€ä¼˜åŒ–ã€‚</p><ul><li>ä¸åŒè®¾å®šä¸‹å›¾ç»“æ„çš„æ¶ˆèå®éªŒ</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201202214543.png" alt="image-20201202214543544"></p><blockquote><p>ä¸ºäº†åˆ†æå›¾ç»“æ„å¯¹äºæ•´ä¸ªæ¨¡å‹èµ·äº†å¤šå¤§çš„è´¡çŒ®ï¼Œæœ¬æ–‡çš„æ¨¡å‹ç§»é™¤äº†æ•´ä¸ªå›¾èåˆæ¨¡å—ï¼Œä½¿é¢„è®­ç»ƒçš„è¾“å‡ºç›´æ¥è¾“å…¥ç»™é¢„æµ‹å±‚ã€‚</p></blockquote><p>åœ¨é¢„è®­ç»ƒæ¨¡å‹ä»¥fine-tuningçš„æ–¹å¼ä½¿ç”¨æ—¶:</p><ul><li>åŒ…å«å’Œä¸åŒ…å«å›¾ç»“æ„çš„æ¨¡å‹éƒ½å–å¾—äº†ç›¸ä¼¼çš„ç»“æœã€‚</li></ul><p>å½“å›ºå®šé¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°æ—¶ï¼š</p><ul><li>åŒ…å«å›¾ç»“æ„æ—¶ï¼šEMå’ŒF1æ˜¾è‘—ä¸‹é™ã€‚</li><li>ç§»é™¤å›¾ç»“æ„æ—¶ï¼šEMå’ŒF1ç•¥æœ‰ä¸‹é™ã€‚</li></ul><h3 id="ç†è§£å›¾ç½‘ç»œ-1"><a href="#ç†è§£å›¾ç½‘ç»œ-1" class="headerlink" title="ç†è§£å›¾ç½‘ç»œ"></a>ç†è§£å›¾ç½‘ç»œ</h3><p>è®¾ç½®ä¸åŒæ¨¡å—æ¡ä»¶ä¸‹EMå’ŒF1æ€§èƒ½çš„æ¯”è¾ƒï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201202222312.png" alt="image-20201202222312328"></p><ul><li>ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œå¸¦æœ‰å›¾èåˆå±‚çš„æ¨¡å‹æœ‰éå¸¸æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚</li><li>ç»™åŸºçº¿æ¨¡å‹æ·»åŠ äº†å›¾æ³¨æ„åŠ›å±‚åï¼ŒåŸºçº¿æ¨¡å‹è·å¾—äº†è¾ƒä¸ºæ˜æ˜¾çš„æå‡ï¼Œä½†ä¸æ·»åŠ è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„æ•ˆæœæ¥è¿‘ã€‚</li><li>Transformerä¹Ÿè¡¨ç°å‡ºäº†è¾ƒå¥½çš„æ¨ç†èƒ½åŠ›ã€‚</li></ul><p>ä½äºä¸åŒåˆ†ä½ç‚¹æ ·æœ¬çš„é‚»æ¥çŸ©é˜µå¯†åº¦ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201203123235.png" alt="image-20201203123235725"></p><p>ä¸åŒé‚»æ¥çŸ©é˜µå¯†åº¦ä¸‹å›¾æ³¨æ„åŠ›å’Œè‡ªæ³¨æ„åŠ›çš„æ•ˆæœå¯¹æ¯”ï¼š</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201203123554.png" alt="image-20201203123554888"></p><ul><li>å›¾æ³¨æ„åŠ›ç½‘ç»œä¸è‡ªæ³¨æ„åŠ›åœ¨ä¸åŒé‚»æ¥çŸ©é˜µå¯†åº¦çš„æ ·æœ¬ä¸Šç»“æœç›¸è¿‘ï¼Œè¯æ˜è‡ªæ³¨æ„åŠ›ç¡®å®èƒ½å¤Ÿè‡ªè¡Œå­¦ä¼šå¿½ç•¥ä¸ç›¸å¹²å®ä½“ã€‚</li><li>å¯†åº¦è¶Šå¤§çš„æ ·æœ¬EM/F1å¾—åˆ†è¶Šé«˜ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºè¿™äº›æ ·æœ¬é•¿åº¦æ™®éæ›´çŸ­ï¼Œå› æ­¤ä¹Ÿæ›´åŠ å®¹æ˜“å®šä½ç­”æ¡ˆçš„ä½ç½®ã€‚</li></ul><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><ul><li>åªæœ‰å½“é¢„è®­ç»ƒæ¨¡å‹ä»¥Feature-basedçš„æ–¹å¼ä½¿ç”¨æ—¶ï¼Œå›¾ç»“æ„æ‰ä¼šèµ·åˆ°æ¯”è¾ƒæ˜æ˜¾çš„ä½œç”¨ã€‚è€Œå½“é¢„è®­ç»ƒæ¨¡å‹ä»¥Fine-tuningçš„æ–¹å¼ä½¿ç”¨æ—¶ï¼Œå›¾ç»“æ„å¹¶æ²¡æœ‰å¯¹ç»“æœèµ·åˆ°è´¡çŒ®ï¼Œå› æ­¤ï¼Œå›¾ç»“æ„å¯èƒ½ä¸æ˜¯è§£å†³å¤šæ­¥æ¨ç†é—®é¢˜æ‰€å¿…è¦çš„ç»“æ„ã€‚</li><li>å›¾æ³¨æ„åŠ›æœºåˆ¶å’Œå›¾ç»“æ„å¯ä»¥è¢«è‡ªæ³¨æ„åŠ›æœºåˆ¶æˆ–Transformerä»£æ›¿ã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> æœºå™¨é˜…è¯»ç†è§£ </tag>
            
            <tag> MC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MemNN</title>
      <link href="/2020/11/26/MemNN/"/>
      <url>/2020/11/26/MemNN/</url>
      
        <content type="html"><![CDATA[<h1 id="MemNN"><a href="#MemNN" class="headerlink" title="MemNN"></a>MemNN</h1><blockquote><p>Memory Networksï¼šè®°å¿†ç½‘ç»œ</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><p>ä¼ ç»Ÿçš„RNNå’Œå…¶æ”¹è¿›æ¨¡å‹è™½ç„¶å…·æœ‰è®°å¿†åŠŸèƒ½ï¼Œä½†æ˜¯åœ¨é•¿æœŸè®°å¿†ä¸­è¡¨ç°å¹¶ä¸å¥½ï¼ŒMemory Networksçš„ç›®çš„æ˜¯å®ç°é•¿æœŸè®°å¿†ã€‚</p><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><h3 id="MEMORY-NETWORKS"><a href="#MEMORY-NETWORKS" class="headerlink" title="MEMORY NETWORKS"></a>MEMORY NETWORKS</h3><p>ç»„æˆï¼š1ä¸ªå†…å­˜æ¨¡å—(mâ€”ç”¨ç´¢å¼•çš„æ•°ç»„)ï¼Œ4ä¸ªç»„ä»¶(I,G,O,Râ€”é€šè¿‡å­¦ä¹ å¾—åˆ°)</p><h4 id="ç»„ä»¶"><a href="#ç»„ä»¶" class="headerlink" title="ç»„ä»¶"></a>ç»„ä»¶</h4><ul><li>$I$:ï¼ˆè¾“å…¥ç‰¹å¾æ˜ å°„ï¼‰â€”â€” å°†è¾“å…¥è½¬æ¢ä¸ºå†…éƒ¨ç‰¹å¾è¡¨ç¤ºã€‚</li><li><p>$G$:ï¼ˆæ³›åŒ–ï¼‰â€”â€” å¯¹äºç»™å®šæ–°çš„è¾“å…¥æ›´æ–°æ—§çš„å†…å­˜ã€‚ç§°ä¹‹ä¸ºæ³›åŒ–æ˜¯å› ä¸ºåœ¨è¿™ä¸ªé˜¶æ®µç½‘ç»œæœ‰æœºä¼šå‹ç¼©å¹¶æ³›åŒ–å…¶å†…å­˜ä»¥ä¾›æœªæ¥æŸäº›éœ€è¦ã€‚</p></li><li><p>$O$:ï¼ˆè¾“å‡ºç‰¹å¾æ˜ å°„ï¼‰â€”â€” ç»™å®šæ–°çš„è¾“å…¥ä¸å½“å‰çš„å†…å­˜çŠ¶æ€ï¼Œäº§ç”Ÿæ–°çš„è¾“å‡ºï¼ˆåœ¨ç‰¹å¾ç©ºé—´ä¸­ï¼‰ã€‚</p></li><li>$R$:ï¼ˆå›å¤ï¼‰â€”â€” å°†è¾“å‡ºè½¬æ¢ä¸ºç‰¹å®šæ ¼å¼çš„å›å¤ã€‚æ¯”å¦‚ï¼Œæ–‡æœ¬å›å¤æˆ–è€…ä¸€ä¸ªåŠ¨ä½œã€‚</li></ul><h4 id="æµç¨‹"><a href="#æµç¨‹" class="headerlink" title="æµç¨‹"></a>æµç¨‹</h4><ul><li>è¾“å…¥$x$ï¼ˆå¯ä»¥æ˜¯å•è¯ï¼Œå¥å­ï¼Œå›¾ç‰‡ï¼ŒéŸ³é¢‘ï¼‰</li><li>å°†$x$è½¬ä¸ºå†…éƒ¨ç‰¹å¾è¡¨ç¤ºï¼š$I(x)$</li><li>æ›´æ–°å†…å­˜$m_i$ï¼š$m_i= G(m_i, I(x), m), âˆ€i$</li><li>è®¡ç®—è¾“å‡ºç‰¹å¾ï¼š$o = O(I(x), m)$</li><li>å°†è¾“å‡ºç‰¹å¾è§£ç ï¼Œå¾—åˆ°æœ€ç»ˆå›å¤ï¼š$r = R(o)$</li></ul><h4 id="å®ç°"><a href="#å®ç°" class="headerlink" title="å®ç°"></a>å®ç°</h4><ul><li>$G$ï¼šæœ€ç®€å•çš„å®ç°æ˜¯åˆ©ç”¨ä¸‹è¿°$H(x$)å°†è¾“å…¥$I(x)$å­˜å‚¨åˆ°æ§½ä¸­ã€‚</li></ul><script type="math/tex; mode=display">m_{H(x)}=I(x)</script><blockquote><p> H(x) æ˜¯ä¸€ä¸ªå¯»å€å‡½æ•°ï¼ˆslot choosing functionï¼‰ã€‚</p><p>G æ›´æ–°çš„æ˜¯$m$çš„$index$ï¼Œå¯ä»¥ç›´æ¥æŠŠæ–°çš„è¾“å…¥ $I(x)$ ä¿å­˜åˆ°ä¸‹ä¸€ä¸ªç©ºé—²çš„åœ°å€$m_n$ï¼Œå¹¶ä¸æ›´æ–°åŸæœ‰çš„memoryã€‚</p></blockquote><p>æ›´å¤æ‚çš„ G å‡½æ•°å¯ä»¥å»æ›´æ–°æ›´æ—©çš„memoryç”šè‡³æ˜¯æ‰€æœ‰çš„memoryã€‚</p><h4 id="A-MEMNN-IMPLEMENTATION-FOR-TEXT"><a href="#A-MEMNN-IMPLEMENTATION-FOR-TEXT" class="headerlink" title="A MEMNN IMPLEMENTATION FOR TEXT"></a>A MEMNN IMPLEMENTATION FOR TEXT</h4><ul><li>$I$ï¼šsentence</li><li>$G$ï¼šå°†è¾“å…¥ä¿å­˜åˆ°ä¸‹ä¸€ä¸ªå¯ç”¨çš„åœ°å€ï¼Œä»…ç”¨äºå­˜å‚¨æ–°çš„memoryï¼Œå¹¶ä¸æ›´æ–°åŸæœ‰çš„memoryã€‚</li><li>$O$ï¼šè¾“å…¥ä¸€ä¸ªé—®é¢˜$x$ï¼Œå°†æœ€åˆé€‚çš„$k$ä¸ªæ”¯æ’‘è®°å¿†ï¼ˆthe supporting memoriesï¼‰è¿”å›ã€‚</li></ul><p>k=1æ—¶ï¼š</p><script type="math/tex; mode=display">o1= O1(x, m) =  \underset{i=1,...,N}{arg\max}\ s_O(x, m_i)</script><p>k=2æ—¶ï¼š</p><script type="math/tex; mode=display">o2= O2(x, m) = \underset{i=1,...,N} {arg\ max} \  s_O([x, m_{o1}], mi)</script><p>è¾“å‡ºï¼š$o$ï¼š$[x, m<em>{o1}, m</em>{o2}]$</p><blockquote><p>$s_O$ï¼šå¯¹åŒ¹é…é¡¹çš„è¯„åˆ†å‡½æ•°ã€‚</p></blockquote><ul><li>$R$ï¼šæ ¹æ®$O$çš„è¾“å‡ºï¼Œè¿”å›ä¸€ç»„è¯æ±‡ã€‚</li></ul><script type="math/tex; mode=display">r = argmax_{wâˆˆW}s_R([x, m_{o1}, m_{o2}], w)</script><blockquote><p>$W$ï¼šå­—å…¸ä¸­å·¦å³å•è¯çš„è¯æ±‡åˆ—è¡¨ã€‚</p><p>$s_R$ï¼šå¯¹åŒ¹é…é¡¹çš„è¯„åˆ†å‡½æ•°ã€‚</p><p>æ¨ç†çš„æ ¸å¿ƒï¼š$O,R$ç»„ä»¶ã€‚</p></blockquote><h5 id="è¯„åˆ†å‡½æ•°"><a href="#è¯„åˆ†å‡½æ•°" class="headerlink" title="è¯„åˆ†å‡½æ•°"></a>è¯„åˆ†å‡½æ•°</h5><p>è¯„åˆ†å‡½æ•°$s_O,s_R$å…·æœ‰ä¸åµŒå…¥æ¨¡å‹ç›¸åŒçš„å½¢å¼ã€‚</p><script type="math/tex; mode=display">s(x, y) = Î¦_x(x)^âŠ¤U^âŠ¤UÎ¦_y(y)</script><ul><li>ä½¿ç”¨æŸå¤±å‡½æ•°<strong>MarginRankingLoss</strong>å’Œ<strong>SGD</strong>ä¼˜åŒ–å™¨è®­ç»ƒã€‚</li></ul><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>$QA$</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201124162815.png" alt="image-20201124162815142" style="zoom:50%;" /></p><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>å•ä¸ªå•è¯å›ç­”ä»»åŠ¡ï¼š</p><ul><li>åœ¨Difficulty 1ä»»åŠ¡ä¸Šï¼ŒRNNå’ŒLSTMåœ¨æé—®ä¹‹å‰è¡¨ç°è¾ƒå¥½ï¼Œä½†æ˜¯æé—®åæ•ˆæœå˜å·®ï¼Œæ˜¯ç”±äºRNNå’ŒLSTMé•¿æœŸè®°å¿†è¾ƒå·®å¯¼è‡´çš„ã€‚</li><li>åœ¨Difficulty 5ä»»åŠ¡ä¸Šï¼Œç”±äºæ¨¡å‹é™åˆ¶RNNå’ŒLSTMè¡¨ç°è¾ƒå·®ï¼Œéšç€éš¾åº¦å¢åŠ ï¼Œæ•ˆæœè¿˜ä¼šæ›´å·®ã€‚</li><li>åœ¨actorå’Œactor+objectä»»åŠ¡ä¸ŠåŠ å…¥æ—¶é—´ç‰¹å¾ï¼Œæ•ˆæœæå‡å¾ˆæ˜æ˜¾ã€‚</li><li>ä½¿ç”¨äº†ä¸¤æ®µæ¨ç†çš„MemNNè¡¨ç°æœ€å¥½ã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MemNN </tag>
            
            <tag> é˜…è¯»ç†è§£ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>emqxé…ç½®httpså¹¶ä½¿ç”¨nginxåå‘ä»£ç†</title>
      <link href="/2020/11/20/emqx%E9%85%8D%E7%BD%AEhttps%E5%B9%B6%E4%BD%BF%E7%94%A8nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"/>
      <url>/2020/11/20/emqx%E9%85%8D%E7%BD%AEhttps%E5%B9%B6%E4%BD%BF%E7%94%A8nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="emqxé…ç½®httpså¹¶ä½¿ç”¨nginxåå‘ä»£ç†"><a href="#emqxé…ç½®httpså¹¶ä½¿ç”¨nginxåå‘ä»£ç†" class="headerlink" title="emqxé…ç½®httpså¹¶ä½¿ç”¨nginxåå‘ä»£ç†"></a>emqxé…ç½®httpså¹¶ä½¿ç”¨nginxåå‘ä»£ç†</h1><ol><li><p>ä¸‹è½½åŸŸåè¯ä¹¦ï¼Œæ‰¾åˆ°.crtæˆ–.keyï¼Œç¼–è¾‘å™¨æ‰“å¼€ï¼Œå¤åˆ¶ç§˜é’¥æ–‡æœ¬ï¼Œæ‰¾åœ¨çº¿è½¬pemå·¥å…·ï¼Œç”Ÿæˆ.pemæ–‡ä»¶ã€‚</p><blockquote><p><a href="https://www.myssl.cn/tools/merge-pem-cert.html">https://www.myssl.cn/tools/merge-pem-cert.html</a></p><p>é€‰æ‹©PEMæ–‡ä»¶åŒ…æ‹¬è¯ä¹¦(CRT/CER)</p></blockquote></li></ol><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201121105009.jpg" alt="621605869569_.pic_hd"></p><ol><li><p>åœ¨emqä¸­å¯åŠ¨ssl</p><blockquote><p>whereis emqx å¯æŸ¥çœ‹å®‰è£…è·¯å¾„</p></blockquote></li></ol><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201121105109.jpg" alt="641605869642_.pic_hd"></p><p>é‡å¯emqx</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">emqx stop</span><br><span class="line">emqx start</span><br></pre></td></tr></table></figure><ol><li><p>é…ç½®nginxçš„åå‘ä»£ç†</p><blockquote><p>é…ç½®æ–‡æ¡£ï¼š<a href="https://docs.emqx.net">https://docs.emqx.net</a> SDK &amp; Tools -&gt; MQTTå¾®ä¿¡å°ç¨‹åºæ¥å…¥</p></blockquote></li></ol><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201121105124.jpg" alt="661605869702_.pic_hd"></p><p>ç¼–è¾‘/etc/nginx/nginx.conf</p><p>å¯¹é…ç½®æ–‡ä»¶è¿›è¡Œæ ¡éªŒ</p><p>ä¿å­˜é…ç½®æ–‡ä»¶ä¹‹åæ‰§è¡Œï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -t</span><br></pre></td></tr></table></figure><p>susccessfulå³å¯</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/night1/image-20201209112907309.png" alt="image-20201209112907309"></p><p>é‡å¯nginxæœåŠ¡</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><p>é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><ul><li>ç”¨ngixåå‘ä»£ç†åï¼Œwssè¿æ¥ç«¯å£å°±æˆäº†443ï¼Œä¸æ˜¯8084ã€‚</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201121105147.jpg" alt="681605869823_.pic_hd"></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201121105159.jpg" alt="691605869841_.pic_hd"></p><ol><li>é…ç½®æ–‡ä»¶</li></ol><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201121105227.jpg" alt="711605869889_.pic_hd"></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201121105245.jpg" alt="721605869914_.pic_hd"></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201121105709.jpg" alt="751605870352_.pic_hd"></p><ul><li>æŸ¥çœ‹å®‰è£…è·¯å¾„</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201121105423.jpg" alt="761605870415_.pic_hd"></p><blockquote><p>ä½†ä¸çŸ¥é“ä»€ä¹ˆåŸå› ï¼Œä¸ä½¿ç”¨nginxåšåå‘ä»£ç†çš„è¯ï¼Œç”¨wss 8084 æ˜¯æ— æ³•è¿æ¥çš„ã€‚</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> https </tag>
            
            <tag> nginx </tag>
            
            <tag> emqx </tag>
            
            <tag> MQTT </tag>
            
            <tag> ssl </tag>
            
            <tag> wss </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention Is All You Need</title>
      <link href="/2020/11/19/Attention%20Is%20All%20You%20Need/"/>
      <url>/2020/11/19/Attention%20Is%20All%20You%20Need/</url>
      
        <content type="html"><![CDATA[<h1 id="Attention-Is-All-You-Need"><a href="#Attention-Is-All-You-Need" class="headerlink" title="Attention Is All You Need"></a>Attention Is All You Need</h1><blockquote><p>åº”ç”¨äºNLPçš„æœºå™¨ç¿»è¯‘é—®é¢˜ã€‚</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><ul><li>ç”±äºRNNçš„é€’å½’ç»“æ„ï¼Œå¯¼è‡´å®ƒæ— æ³•å¹¶è¡Œè®¡ç®—ï¼ŒRNNä»¥åŠä»–çš„è¡ç”Ÿæ¨¡å‹æœ€å¤§çš„ç¼ºç‚¹å°±æ˜¯è®¡ç®—ç¼“æ…¢ã€‚å¹¶ä¸”ç¼ºä¹å¯¹å…¨å±€ä¿¡æ¯çš„ç†è§£ã€‚å› æ­¤æå‡ºäº†å®Œå…¨åŸºäºattentionçš„Transformeræ¨¡å‹ã€‚</li></ul><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p>Transformeræ¨¡å‹æ˜¯çº¯attentionæ¨¡å‹ï¼Œå®Œå…¨ä¾èµ–attentionæœºåˆ¶æ¥æè¿°è¾“å…¥ä¸è¾“å‡ºçš„å…¨å±€ä¾èµ–ã€‚</p><h3 id="æ¨¡å‹ï¼š"><a href="#æ¨¡å‹ï¼š" class="headerlink" title="æ¨¡å‹ï¼š"></a>æ¨¡å‹ï¼š</h3><ul><li>è¾“å…¥ï¼š$x=(x1,x2,â‹¯,xn)$ï¼ˆæ˜¯ä¸€ä¸ªç¦»æ•£çš„ç¬¦å·åºåˆ—ï¼‰</li><li>encoderï¼šå°†å®ƒæ˜ å°„æˆè¿ç»­å€¼åºï¼Œ$z=(z1,z2,â‹¯,zn)$</li><li>decoderï¼šå¯¹äºç»™å®šçš„$z$ï¼Œç”Ÿæˆä¸€ä¸ªè¾“å‡ºç¬¦å·åºåˆ—ï¼Œ$y=(y1,y2,â‹¯,ym)$</li><li>ä¼˜åŒ–å™¨ï¼šAdam</li><li>ä½¿ç”¨dropoutå’ŒLabel Smoothingé˜²æ­¢è¿‡æ‹Ÿåˆ</li></ul><h3 id="Encoder-and-Decoder-Stacks"><a href="#Encoder-and-Decoder-Stacks" class="headerlink" title="Encoder and Decoder Stacks"></a>Encoder and Decoder Stacks</h3><blockquote><p>Encoderä¸Decoderå †å </p></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201117204449.png" alt="image-20201117204444453" style="zoom:50%;" /></p><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><ul><li>Transformeræ¨¡å‹çš„Encoderç”±6ä¸ªåŸºæœ¬å±‚å †å èµ·æ¥ï¼Œæ¯ä¸ªåŸºæœ¬å±‚åŒ…å«ä¸¤ä¸ªå­å±‚ã€‚</li><li>ç¬¬ä¸€ä¸ªå­å±‚ï¼šæ³¨æ„åŠ›æœºåˆ¶</li><li>ç¬¬äºŒä¸ªå­å±‚ï¼šå…¨è¿æ¥å‰å‘ç¥ç»ç½‘ç»œã€‚</li><li>å¯¹ä¸¤ä¸ªå­å±‚éƒ½é‡‡ç”¨äº†residual connectionï¼Œå¹¶è¿›è¡Œäº†layer normalizationã€‚</li></ul><h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><ul><li>Decoderç”±6ä¸ªåŸºæœ¬å±‚å †å èµ·æ¥ï¼Œæ¯ä¸ªåŸºæœ¬å±‚åŒ…å«ä¸‰ä¸ªå­å±‚ã€‚</li><li>ç¬¬ä¸€ä¸ªå­å±‚ï¼šæ³¨æ„åŠ›æœºåˆ¶</li><li>ç¬¬äºŒä¸ªå­å±‚ï¼šå…¨è¿æ¥å‰å‘ç¥ç»ç½‘ç»œã€‚</li><li>ç¬¬ä¸‰ä¸ªå­å±‚ï¼šæ³¨æ„åŠ›æœºåˆ¶</li><li>å¯¹ä¸¤ä¸ªå­å±‚éƒ½é‡‡ç”¨äº†residual connectionï¼Œå¹¶è¿›è¡Œäº†layer normalizationã€‚</li></ul><h4 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h4><p>æ³¨æ„åŠ›æœºåˆ¶ï¼šå°†ä¸€ä¸ª<strong>query</strong>å’Œä¸€ä¸ª<strong>key-value pairs</strong>ï¼Œæ˜ å°„åˆ°æ­£ç¡®çš„è¾“å…¥ã€‚</p><ul><li><strong>queryã€keyã€valueã€output</strong>éƒ½æ˜¯å‘é‡ã€‚</li><li>è¾“å‡ºä½œä¸ºä¸€ä¸ªå€¼çš„åŠ æƒå’Œè®¡ç®—å¾—åˆ°ï¼Œå…¶ä¸­åˆ†é…åˆ°æ¯ä¸ªå€¼çš„æƒé‡ç”±è¯·æ±‚çš„å…¼å®¹å‡½æ•°å…³äºå¯¹åº”é”®è®¡ç®—å¾—åˆ°ã€‚</li></ul><h4 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h4><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201117205900.png" alt="image-20201117205900924" style="zoom:50%;" /></p><script type="math/tex; mode=display">Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt {d_k}})V</script><blockquote><p>è¾“å…¥ï¼š$d_k$ç»´çš„<strong>query</strong>ã€<strong>key</strong>ã€$d_v$ç»´çš„<strong>value</strong></p><p>MatMulï¼šè®¡ç®—<strong>query</strong>å’Œå„ä¸ªkeyçš„ç‚¹ç§¯</p><p>Scaleï¼šé™¤ä»¥$\sqrt {d_k}$ å½’ä¸€åŒ–</p><p>softmaxï¼šè·å¾—æƒé‡</p><p>MatMulï¼šå’Œ<strong>value</strong>ç›¸ä¹˜å¾—åˆ°è¾“å‡º</p></blockquote><h4 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h4><blockquote><p>å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶</p><p>å‚æ•°ä¸å…±äº«</p></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201117211209.png" alt="image-20201117211209369" style="zoom:50%;" /></p><script type="math/tex; mode=display">head_i=Attention(QW^Q_i,KW^K_i,VW^V_i)</script><script type="math/tex; mode=display">MultiHead(Q,K,V)=Concat(head1,â‹¯,headh)W^O</script><blockquote><p>ç”¨hä¸ªä¸åŒçš„çº¿æ€§å˜æ¢åˆ†åˆ«å°†$d_{model}$ç»´çš„<strong>key</strong>ã€<strong>value</strong>ã€<strong>query</strong>æ˜ å°„æˆ$d_k$ç»´ã€$d_k$ç»´å’Œ$d_v$ç»´</p><p>ä»£å…¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œäº§ç”Ÿ$hÃ—d_v$ç»´è¾“å‡ºï¼Œç„¶åæ‹¼èµ·æ¥</p><p>å†ç”¨ä¸€ä¸ªçº¿æ€§å˜æ¢å¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºã€‚</p></blockquote><h4 id="Position-wise-Feed-Forward-Networks"><a href="#Position-wise-Feed-Forward-Networks" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h4><blockquote><p>Position-wise å‰å‘ç¥ç»ç½‘ç»œ</p></blockquote><ul><li>encoderå’Œdecoderçš„æ¯ä¸€å±‚éƒ½åŒ…å«ä¸€ä¸ªå‰å‘ç¥ç»ç½‘ç»œã€‚</li></ul><script type="math/tex; mode=display">FFN(x)=max(0,xW_1+b_1)W_2+b_2</script><blockquote><p>ç”±ä¸¤ä¸ªçº¿æ€§å˜æ¢å’ŒReLUæ¿€æ´»å‡½æ•°ç»„æˆã€‚</p></blockquote><h4 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h4><blockquote><p>ä½ç½®ç¼–ç </p><p>è®ºæ–‡ä¸­çš„ä½ç½®ç¼–ç æ˜¯æ ¹æ®ä¸‹è¿°å…¬å¼è®¡ç®—å¾—åˆ°çš„ã€‚</p></blockquote><script type="math/tex; mode=display">PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})</script><script type="math/tex; mode=display">PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})</script><ul><li><p>æœ¬æ–‡çš„æ¨¡å‹ç»“æ„æ²¡æœ‰ä½¿ç”¨ä»»ä½•é€’å½’ç»“æ„æˆ–å·ç§¯ç»“æ„ï¼Œä¸ºäº†è®©æ¨¡å‹èƒ½ä½¿ç”¨åºåˆ—çš„é¡ºåºï¼Œå¿…é¡»å¼•å…¥æŸç§èƒ½è¡¨è¾¾è¾“å…¥åºåˆ—æ¯ä¸ªéƒ¨åˆ†çš„ç»å¯¹æˆ–ç›¸å¯¹ä½ç½®çš„ä¿¡æ¯ã€‚</p></li><li><p>ä½ç½®ç¼–ç ï¼šåœ¨é€å…¥encoderå’Œdecoderä¹‹å‰ï¼Œå…ˆå¯¹è¾“å…¥è¿›è¡Œç¼–ç ï¼Œç¼–ç åçš„å‘é‡ç»´åº¦æ˜¯$d_{model}$ï¼Œå’Œembedingså…·æœ‰ç›¸åŒçš„ç»´åº¦ï¼Œå› æ­¤å¯ä»¥ç›¸åŠ ã€‚ </p></li><li>é€šè¿‡ç»“åˆä½ç½®å‘é‡å’Œè¯å‘é‡ï¼Œå°±ç»™æ¯ä¸ªè¯éƒ½å¼•å…¥äº†ä¸€å®šçš„ä½ç½®ä¿¡æ¯ï¼Œè¿™æ · Attention å°±å¯ä»¥åˆ†è¾¨å‡ºä¸åŒä½ç½®çš„è¯äº†ã€‚</li><li>é€‰æ‹©æ­£å¼¦æ›²çº¿ç‰ˆæœ¬æ˜¯å› ä¸ºå®ƒå¯ä»¥ä½¿æ¨¡å‹æ¨æ–­å‡ºæ¯”è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°çš„åºåˆ—é•¿åº¦æ›´é•¿çš„åºåˆ—é•¿åº¦ã€‚</li></ul><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>WMT 2014 English-German</p><p>WMT 2014 English-French</p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201118110252.png" alt="image-20201118110252849" style="zoom:50%;" /></p><ul><li>Transformeråœ¨è‹±è¯­-å¾·è¯­ï¼Œè‹±è¯­-æ³•è¯­çš„ç¿»è¯‘ä»»åŠ¡ä¸Šéƒ½è¡¨ç°å‡ºæ¯”è¾ƒå¥½çš„ç¿»è¯‘æ•ˆæœã€‚</li><li>å¹¶ä¸”Transformerçš„è®­ç»ƒå¼€é”€ä¹Ÿæ˜¯æœ€å°çš„ã€‚</li></ul><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><ul><li>æå‡ºçš„Transformerï¼Œæ˜¯ç¬¬ä¸€ä¸ªå®Œå…¨åŸºäºattentionçš„åºåˆ—è½¬å¯¼æ¨¡å‹ï¼Œç”¨multi-headed self-attentionå–ä»£äº†encoder-decoderç»“æ„ä¸­æœ€å¸¸ç”¨çš„å¾ªç¯å±‚ã€‚</li><li>å¯¹äºç¿»è¯‘ä»»åŠ¡ï¼ŒTransformerå¯ä»¥æ¯”åŸºäºå¾ªç¯æˆ–å·ç§¯å±‚çš„ä½“ç³»ç»“æ„è®­ç»ƒæ›´å¿«ã€‚</li></ul><h2 id="æ‰©å±•äº†è§£"><a href="#æ‰©å±•äº†è§£" class="headerlink" title="æ‰©å±•äº†è§£"></a>æ‰©å±•äº†è§£</h2><p>æœºå™¨ç¿»è¯‘è¯„ä»·æŒ‡æ ‡ï¼š<strong>BLEU</strong>ï¼ˆBilingual Evaluation Understudyï¼‰</p><blockquote><p>åŒè¯­è¯„ä¼°æ›¿è¡¥</p></blockquote><script type="math/tex; mode=display">BLEU=BPâ‹…exp(\sum _{n=1}^Nw_nlogP_n)</script><script type="math/tex; mode=display">BP=\begin{cases}1 & c\gt r \\ 0 & e^{1-r/c} \leq r \end{cases}</script><ul><li>ç”¨äºè¯„ä¼°æ¨¡å‹ç”Ÿæˆçš„å¥å­(candidate)å’Œå®é™…å¥å­(reference)çš„å·®å¼‚çš„æŒ‡æ ‡ã€‚</li><li>å–å€¼èŒƒå›´åœ¨0åˆ°1ä¹‹é—´,ï¼Œå¦‚æœä¸¤ä¸ªå¥å­å®Œç¾åŒ¹é…(perfect match)ï¼Œé‚£ä¹ˆBLEUæ˜¯1ï¼Œåä¹‹ï¼Œå¦‚æœä¸¤ä¸ªå¥å­å®Œç¾ä¸åŒ¹é…(perfect mismatch)ï¼Œé‚£ä¹ˆBLEUä¸º0ã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Transformer </tag>
            
            <tag> æœºå™¨ç¿»è¯‘ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å¸¸è§æŠ¥é”™æ±‡æ€»</title>
      <link href="/2020/11/18/%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99%E6%B1%87%E6%80%BB/"/>
      <url>/2020/11/18/%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="å¸¸è§æŠ¥é”™æ±‡æ€»"><a href="#å¸¸è§æŠ¥é”™æ±‡æ€»" class="headerlink" title="å¸¸è§æŠ¥é”™æ±‡æ€»"></a>å¸¸è§æŠ¥é”™æ±‡æ€»</h1><h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><p>æŠ¥é”™ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device(&#x27;cpu&#x27;) to map your storages to the CPU.</span><br></pre></td></tr></table></figure><p>è§£å†³ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.load(xxx)æ”¹æˆ torch.load(xxx,map_location=&#x27;cpu&#x27;)</span><br></pre></td></tr></table></figure><h2 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h2><p>æŠ¥é”™ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorflow2.0åŠ è½½modelå‡ºç°AttributeError: â€˜strâ€˜ object has no attribute â€˜decodeâ€˜</span><br></pre></td></tr></table></figure><p>è§£å†³ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">æŠŠh5pyé™åˆ°2.10.0ç‰ˆæœ¬å°±è¡Œäº†ï¼ï¼ï¼ï¼</span><br><span class="line">å®‰è£…kerasè‡ªåŠ¨ç»™ä¸‹è½½é«˜ç‰ˆæœ¬h5pyå¯¼è‡´æŠ¥é”™ï¼ï¼</span><br><span class="line"></span><br><span class="line">pip install h5py==2.10.0</span><br><span class="line">å®‰è£…åé‡å¯æœåŠ¡</span><br></pre></td></tr></table></figure><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><p>æŠ¥é”™ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx: [emerg] bind() to 0.0.0.0:443 failed (98: Address already in use)</span><br></pre></td></tr></table></figure><p>è§£å†³ï¼š</p><ol><li>æŸ¥çœ‹443ç«¯å£æ˜¯å¦è¢«å ç”¨ï¼Ÿæ˜¯å“ªä¸ªå ç”¨çš„ï¼Ÿ</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -anon | grep 443</span><br></pre></td></tr></table></figure><ol><li>æ€æ‰å ç”¨çš„443ç«¯å£çš„è¿›ç¨‹</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fuser -k 443/tcp</span><br></pre></td></tr></table></figure><ol><li>é‡å¯nginx</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><ol><li>é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æŠ¥é”™ </tag>
            
            <tag> ç»éªŒ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>æœºå™¨å­¦ä¹ åŸºç¡€</title>
      <link href="/2020/11/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
      <url>/2020/11/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="æœºå™¨å­¦ä¹ åŸºç¡€"><a href="#æœºå™¨å­¦ä¹ åŸºç¡€" class="headerlink" title="æœºå™¨å­¦ä¹ åŸºç¡€"></a>æœºå™¨å­¦ä¹ åŸºç¡€</h1><h2 id="1-æœºå™¨å­¦ä¹ çš„åŸºæœ¬å†…å®¹"><a href="#1-æœºå™¨å­¦ä¹ çš„åŸºæœ¬å†…å®¹" class="headerlink" title="1. æœºå™¨å­¦ä¹ çš„åŸºæœ¬å†…å®¹"></a>1. æœºå™¨å­¦ä¹ çš„åŸºæœ¬å†…å®¹</h2><ul><li>ç›‘ç£å­¦ä¹ </li><li>æ— ç›‘ç£å­¦ä¹ </li><li>åŠç›‘ç£å­¦ä¹ </li><li>å¼ºåŒ–å­¦ä¹ </li></ul><h2 id="2-å¸¸ç”¨çš„æ­£åˆ™åŒ–æ–¹æ³•"><a href="#2-å¸¸ç”¨çš„æ­£åˆ™åŒ–æ–¹æ³•" class="headerlink" title="2. å¸¸ç”¨çš„æ­£åˆ™åŒ–æ–¹æ³•"></a>2. å¸¸ç”¨çš„æ­£åˆ™åŒ–æ–¹æ³•</h2><blockquote><ul><li><p>æ­£åˆ™åŒ–æ˜¯è§£å†³è¿‡æ‹Ÿåˆçš„å¸¸ç”¨æ–¹æ³•ã€‚</p></li><li><p>æ­£åˆ™åŒ–æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ</p><ul><li>åœ¨æœºå™¨å­¦ä¹ ä¸­å¾ˆå¤šæ˜¾å¼çš„ç”¨æ¥å‡å°‘æµ‹è¯•è¯¯å·®çš„ç­–ç•¥ï¼Œç»Ÿç§°ä¸ºæ­£åˆ™åŒ–ã€‚</li></ul></li><li>æ­£åˆ™åŒ–çš„ç›®çš„æ˜¯å‡å°‘æ³›åŒ–è¯¯å·®è€Œä¸æ˜¯è®­ç»ƒè¯¯å·®ã€‚</li></ul></blockquote><h3 id="2-1æƒé‡æ­£åˆ™åŒ–"><a href="#2-1æƒé‡æ­£åˆ™åŒ–" class="headerlink" title="2.1æƒé‡æ­£åˆ™åŒ–"></a>2.1æƒé‡æ­£åˆ™åŒ–</h3><ul><li>L2æ­£åˆ™åŒ–ç§°ä¸ºï¼šæƒé‡è¡°å‡(Weight Deacy)</li></ul><script type="math/tex; mode=display">min_\theta\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+\lambda||W||^2</script><blockquote><p>$\lambda$ï¼šæƒå€¼è¡°å‡ç‡</p></blockquote><h3 id="2-2-Dropout-æ­£åˆ™åŒ–"><a href="#2-2-Dropout-æ­£åˆ™åŒ–" class="headerlink" title="2.2 Dropout æ­£åˆ™åŒ–"></a>2.2 Dropout æ­£åˆ™åŒ–</h3><blockquote><ul><li>è®­ç»ƒè¿‡ç¨‹ä¸­æŒ‰ä¸€å®šçš„æ¯”ä¾‹ï¼Œéšæœºå¿½ç•¥æˆ–å±è”½ä¸€äº›ç¥ç»å…ƒã€‚</li><li>è¢«éšæœºå¿½ç•¥æˆ–å±è”½çš„ç¥ç»å…ƒåœ¨åå‘ä¼ æ’­ä¸­ä¹Ÿä¸ä¼šæœ‰ä»»ä½•çš„æƒå€¼æ›´æ–°ï¼Œåœ¨ä¼ æ’­è¿‡ç¨‹ä¸­äº§ç”ŸäºL2èŒƒæ•°ç›¸åŒçš„æ”¶ç¼©æƒé‡æ•ˆæœã€‚</li><li>åŠ å…¥Dropoutä¹‹åï¼Œè¾“å…¥ç‰¹å¾ä¹Ÿä¼šéšæœºæ¸…é™¤ï¼Œæ‰€ä»¥ä¸ä¼šç»™ä»»ä½•ä¸€ä¸ªè¾“å…¥è®¾ç½®å¤ªå¤§çš„æƒé‡ã€‚</li><li>ç”±äºç½‘ç»œæ¨¡å‹å¯¹ç¥ç»å…ƒç‰¹å®šçš„æƒé‡ä¸é‚£ä¹ˆæ•æ„Ÿï¼Œåè€Œä¼šå¢åŠ æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li></ul></blockquote><ul><li><p>é€šå¸¸Dropoutçš„ä¸¢å¼ƒç‡æ§åˆ¶åœ¨20%-50%ã€‚</p><blockquote><p>å¤ªä½èµ·ä¸åˆ°æ•ˆæœï¼Œå¤ªé«˜ä¼šå¯¼è‡´æ¬ æ‹Ÿåˆã€‚</p></blockquote></li><li><p>åœ¨è¾ƒå¤§å‹çš„ç½‘ç»œæ•ˆæœæ›´å¥½ï¼Œä¼šå­¦åˆ°å¤šç§ç‹¬ç«‹è¡¨å¾ã€‚</p></li><li><p>è¾“å…¥å±‚å’Œéšè—å±‚éƒ½ä½¿ç”¨Dropoutã€‚</p><blockquote><p>ç¥ç»å…ƒè¾ƒå°‘çš„å±‚ï¼Œè®¾ç½®keep_probä¸º1æˆ–æ¥è¿‘1ã€‚</p><p>ç¥ç»å…ƒè¾ƒå¤šçš„å±‚ï¼Œè®¾ç½®keep_probä¸º0.5æˆ–æ›´å°ã€‚</p></blockquote></li><li><p>å¢åŠ å­¦ä¹ ç‡å’Œå†²é‡</p><blockquote><p>å­¦ä¹ ç‡ï¼šæ‰©å¤§10-100å€</p><p>å†²é‡ï¼šæé«˜åˆ°0.9-0.99</p></blockquote></li></ul><p><strong>å¯¹ç½‘ç»œçš„æƒé‡å€¼åšæœ€å¤§èŒƒæ•°æ­£åˆ™ï¼Œå¯ä»¥æå‡æ¨¡å‹æ€§èƒ½ã€‚</strong></p><h3 id="2-3-æ‰¹é‡æ­£åˆ™åŒ–-Batch-Normalization"><a href="#2-3-æ‰¹é‡æ­£åˆ™åŒ–-Batch-Normalization" class="headerlink" title="2.3 æ‰¹é‡æ­£åˆ™åŒ–(Batch Normalization)"></a>2.3 æ‰¹é‡æ­£åˆ™åŒ–(Batch Normalization)</h3><blockquote><p>ç”¨äºéšè—å±‚æ•°æ®åˆ†å¸ƒä¸å‡ï¼Œå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±æˆ–ä¸èµ·ä½œç”¨çš„æƒ…å†µã€‚</p></blockquote><ul><li>BNä½œç”¨åœ¨å“ªé‡Œï¼Ÿ<ul><li>BNåº”è¯¥ä½œç”¨åœ¨éçº¿æ€§æ˜ å°„ä¹‹å‰ã€‚</li></ul></li><li>BNå¦‚ä½•ä½¿ç”¨ï¼Ÿ<ul><li>åœ¨ç¥ç»ç½‘ç»œè®­ç»ƒæ”¶æ•›é€Ÿåº¦å¾ˆæ…¢ï¼Œæˆ–è€…æ¢¯åº¦çˆ†ç‚¸æ— æ³•è®­ç»ƒçš„æƒ…å†µä¸‹ä½¿ç”¨ã€‚</li><li>BNå¯ä»¥é€‰æ‹©æ¯”è¾ƒå¤§çš„å­¦ä¹ ç‡ï¼Œå®ƒå…·æœ‰å¿«é€Ÿæ”¶æ•›çš„ç‰¹æ€§ã€‚</li><li>BNå…·æœ‰æé«˜ç½‘ç»œæ³›åŒ–èƒ½åŠ›çš„ç‰¹æ€§ï¼Œå› æ­¤ä¸å¿…ä½¿ç”¨è¿‡æ‹Ÿåˆä¸­Dropoutå’ŒL2æ­£åˆ™åŒ–ã€‚</li></ul></li></ul><h3 id="2-4-æƒé‡åˆå§‹åŒ–"><a href="#2-4-æƒé‡åˆå§‹åŒ–" class="headerlink" title="2.4 æƒé‡åˆå§‹åŒ–"></a>2.4 æƒé‡åˆå§‹åŒ–</h3><ul><li>ä¸€èˆ¬ä½¿ç”¨æ­£æ€åˆ†å¸ƒæˆ–å‡åŒ€åˆ†å¸ƒçš„åˆå§‹å€¼ã€‚</li><li>nn.initæ¨¡å—ä¸­æä¾›äº†xavierã€kaimingç­‰ç»å…¸çš„åˆå§‹åŒ–ç­–ç•¥ã€‚<ul><li>xavierä¸€èˆ¬ç”¨äºæ¿€æ´»å‡½æ•°æ˜¯Så‹ï¼Œä¾‹å¦‚sigmodã€tanh</li><li>kaimingé€‚åˆäºReLUç±»çš„æƒé‡åˆå§‹åŒ–ã€‚</li></ul></li></ul><h2 id="3-é€‰æ‹©åˆé€‚çš„æ¿€æ´»å‡½æ•°"><a href="#3-é€‰æ‹©åˆé€‚çš„æ¿€æ´»å‡½æ•°" class="headerlink" title="3. é€‰æ‹©åˆé€‚çš„æ¿€æ´»å‡½æ•°"></a>3. é€‰æ‹©åˆé€‚çš„æ¿€æ´»å‡½æ•°</h2><blockquote><ul><li><p>æ¿€æ´»å‡½æ•°ä¸»è¦ä½œç”¨æ˜¯ï¼Œç»™ç¥ç»ç½‘ç»œæä¾›éçº¿æ€§å»ºæ¨¡èƒ½åŠ›ã€‚</p></li><li><p>å¦‚æœæ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼Œç¥ç»ç½‘ç»œæ™ºåªèƒ½å¤„ç†çº¿æ€§å¯åˆ†çš„é—®é¢˜ã€‚</p></li></ul></blockquote><h3 id="3-1-å¸¸ç”¨æ¿€æ´»å‡½æ•°"><a href="#3-1-å¸¸ç”¨æ¿€æ´»å‡½æ•°" class="headerlink" title="3.1 å¸¸ç”¨æ¿€æ´»å‡½æ•°"></a>3.1 å¸¸ç”¨æ¿€æ´»å‡½æ•°</h3><div class="table-container"><table><thead><tr><th>åç§°</th><th>è¡¨è¾¾å¼</th><th>å¯¼æ•°</th><th>å›¾å½¢</th></tr></thead><tbody><tr><td>sigmoid</td><td>$f(x)=\frac{1}{1+e^{-x}}$</td><td>$fâ€™=f(x)(1-f(x))$</td><td><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115202913.png" alt=""></td></tr><tr><td>tanh</td><td>$f(x=\frac{1-e^{-2x}}{1+e^{2x}})$</td><td>$fâ€™e(x)=1-(f(x))^2$</td><td><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115202919.png" alt="png"></td></tr><tr><td>ReLU</td><td>$f(x)=\max(0,x)$</td><td>$ fâ€™(x)=\begin{cases}1 &amp; x\geq 0 \0 &amp; x\lt0\end{cases}$</td><td><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115202934.png" alt="png"></td></tr><tr><td>LeakyReLU</td><td>$f(x)=\max(ax,0)$</td><td>$ fâ€™(x)=\begin{cases}1 &amp; x\geq 0 \ax &amp; x\lt0\end{cases}$</td><td><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115202927.png" alt="png"></td></tr><tr><td>softmax</td><td>$\sigma<em>i(z)=\frac{e^{z_i}}{\sum</em>{j=1}^me^{z_j}}$</td><td></td></tr></tbody></table></div><ul><li>å¦‚ä½•é€‰æ‹©æ¿€æ´»å‡½æ•°<ul><li>å¦‚æœç½‘ç»œå±‚æ•°ä¸å¤šï¼Œè¿™å‡ ç§éƒ½å¯ä»¥ä½¿ç”¨ã€‚</li><li>ç½‘ç»œå±‚æ•°è¾ƒå¤šæ—¶ï¼Œæ¿€æ´»å‡½æ•°çš„å¯¼æ•°å¤§äº1å°†å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸ï¼Œå°äº1æ—¶ï¼Œç»è¿‡å¤šå±‚å åŠ ï¼Œæ ¹æ®å¾®ç§¯åˆ†æ±‚å¯¼é“¾å¼æ³•åˆ¶ï¼Œå¯¼æ•°æˆ–è€…åå¯¼å°†æŒ‡æ•°çº§å˜å°ã€‚æ‰€ä»¥å¯¼æ•°ä¸º1æ—¶æœ€å¥½ï¼Œ<strong>ReLU</strong>æ­£å¥½æ»¡è¶³ã€‚</li></ul></li><li>softmaxæ¿€æ´»å‡½æ•°ï¼š<ul><li>$\sum_i\sigma_i(z)=1$ï¼Œå¸¸ç”¨äºå¤šåˆ†ç±»ç¥ç»ç½‘ç»œè¾“å‡ºå±‚ã€‚</li><li>softmaxæ¿€æ´»å‡½æ•°å°†ä¸€ä¸ªå‘é‡è¿›è¡Œâ€å½’ä¸€åŒ–â€æˆæ¦‚ç‡åˆ†å¸ƒçš„å½¢å¼ã€‚</li></ul></li></ul><h2 id="4-é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°"><a href="#4-é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°" class="headerlink" title="4. é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°"></a>4. é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°</h2><blockquote><p>äº¤å‰ç†µï¼š(Cross Entropy)    <strong>åˆ†ç±»é—®é¢˜</strong></p><ul><li>äº¤å‰ç†µæŸå¤±(Cross-Entropy Loss)ï¼Œåˆç§°å¯¹æ•°ä¼¼ç„¶æŸå¤±(Log-likelihood Loss)ï¼Œå¯¹æ•°æŸå¤±ã€‚äºŒåˆ†ç±»æ—¶è¿˜å¯ç§°ä¸ºé€»è¾‘å›å½’æŸå¤±(Logistic Loss)ã€‚</li></ul><p>å‡æ–¹å·®ï¼š(Mean squared errorï¼ŒMSE)    <strong>å›å½’é—®é¢˜</strong></p></blockquote><ul><li>æ­£åˆ™åŒ–é¡¹è¦åŠ åœ¨æŸå¤±å‡½æ•°åé¢ã€‚</li><li>æŸå¤±å‡½æ•°è¶Šå°è¯´æ˜æ¨¡å‹å’Œå‚æ•°è¶Šç¬¦åˆè®­ç»ƒæ ·æœ¬ã€‚</li></ul><h3 id="4-1-åˆ†ç±»é—®é¢˜"><a href="#4-1-åˆ†ç±»é—®é¢˜" class="headerlink" title="4.1 åˆ†ç±»é—®é¢˜"></a>4.1 åˆ†ç±»é—®é¢˜</h3><ul><li><p>æŸå¤±å‡½æ•°ä¸€èˆ¬ä½¿ç”¨<strong>äº¤å‰ç†µ</strong>ã€‚</p><blockquote><p>äº¤å‰ç†µååº”ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„è·ç¦»ã€‚</p></blockquote></li></ul><h3 id="4-2-å›å½’é—®é¢˜"><a href="#4-2-å›å½’é—®é¢˜" class="headerlink" title="4.2 å›å½’é—®é¢˜"></a>4.2 å›å½’é—®é¢˜</h3><ul><li>å›å½’é—®é¢˜é¢„æµ‹çš„ä¸æ˜¯ä¸€ä¸ªç±»åˆ«ï¼Œè€Œæ˜¯ä¸€ä¸ª<strong>ä»»æ„å®æ•°</strong>ã€‚ç¥ç»ç½‘ç»œä¸€èˆ¬åªæœ‰ä¸€ä¸ªè¾“å‡ºèŠ‚ç‚¹ï¼Œå³é¢„æµ‹å€¼ã€‚</li><li>åæ˜ çœŸå®å€¼ä¸é¢„æµ‹å€¼ä¹‹é—´çš„è·ç¦»å¯ä»¥ç”¨æ¬§å¼è·ç¦»è¡¨ç¤ºã€‚æ‰€ä»¥å¯¹å›å½’é—®é¢˜ä¸€èˆ¬ä½¿ç”¨<strong>å‡æ–¹å·®</strong>ä½œä¸ºæŸå¤±å‡½æ•°ã€‚</li></ul><p>å‡æ–¹å·®å®šä¹‰ï¼š</p><script type="math/tex; mode=display">MES=\frac{\sum_{i=1}^n(y_i-y_i')^2}{n}</script><h2 id="5-é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–å™¨"><a href="#5-é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–å™¨" class="headerlink" title="5.é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–å™¨"></a>5.é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–å™¨</h2><ul><li>å½±å“ä¼˜åŒ–çš„ä¸¤ä¸ªå› ç´ ï¼š<strong>å­¦ä¹ ç‡</strong>ï¼Œ<strong>æ¢¯åº¦</strong>ã€‚</li></ul><h3 id="5-1-åŠ¨é‡ç®—æ³•"><a href="#5-1-åŠ¨é‡ç®—æ³•" class="headerlink" title="5.1 åŠ¨é‡ç®—æ³•"></a>5.1 åŠ¨é‡ç®—æ³•</h3><ul><li><p>æ¢¯åº¦ä¸‹é™æ³•åœ¨é‡åˆ°å¹³å¦æˆ–é«˜æ›²ç‡åŒºåŸŸæ—¶ï¼Œå­¦ä¹ è¿‡ç¨‹æœ‰æ—¶å¾ˆæ…¢ã€‚åˆ©ç”¨åŠ¨é‡ç®—æ³•èƒ½æ¯”è¾ƒå¥½è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</p></li><li><p>åŠ¨é‡ç®—æ³•ç¤ºæ„å›¾ï¼š</p></li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115215631.png" alt="image-20201115215631480" style="zoom:50%;" /></p><ul><li>åŠ¨é‡ç®—æ³•æ¯ä¸‹é™ä¸€æ­¥éƒ½æ˜¯ç”±å‰é¢ä¸‹é™æ–¹å‘çš„ä¸€ä¸ªç´¯ç§¯å’Œå½“å‰ç‚¹çš„æ¢¯åº¦æ–¹å‘ç»„åˆè€Œæˆã€‚</li></ul><ul><li><p>æ”¹è¿›çš„NGAç®—æ³•ï¼š</p><blockquote><ul><li><p>åŠ¨é‡ç®—æ³•æ¯ä¸€æ­¥éƒ½è¦å°†ä¸¤ä¸ªæ¢¯åº¦æ–¹å‘ï¼ˆå†å²æ¢¯åº¦ã€å½“å‰æ¢¯åº¦ï¼‰åšä¸€ä¸ªåˆå¹¶å†ä¸‹é™ã€‚</p></li><li><p>å…ˆæŒ‰ç…§å†å²æ¢¯åº¦å¾€å‰èµ°ä¸€å°æ­¥ï¼ŒæŒ‰ç…§å‰é¢ä¸€å°æ­¥ä½ç½®çš„â€œè¶…å‰æ¢¯åº¦â€æ¥åšæ¢¯åº¦åˆå¹¶ï¼Œå¾—åˆ°äº†åŠ¨é‡ç®—æ³•çš„ä¸€ç§æ”¹è¿›ç®—æ³•ï¼Œç§°ä¸ºNesterov accelerated gradient ç®€ç§° NAG ç®—æ³•ã€‚</p></li><li>è¿™ç§é¢„æ›´æ–°æ–¹æ³•èƒ½é˜²æ­¢å¤§å¹…æŒ¯è¡ï¼Œä¸ä¼šé”™è¿‡æœ€å°å€¼ï¼Œå¹¶å¯¹å‚æ•°æ›´æ–°æ›´åŠ æ•æ„Ÿã€‚</li></ul></blockquote></li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115220311.png" alt="image-20201115220311795" style="zoom:50%;" /></p><ul><li>NAGåŠ¨é‡æ³•å’Œç»å…¸åŠ¨é‡æ³•çš„å·®åˆ«å°±åœ¨Bç‚¹å’ŒCç‚¹æ¢¯åº¦çš„ä¸åŒã€‚åŠ¨é‡æ³•ï¼Œæ›´å¤šå…³æ³¨æ¢¯åº¦ä¸‹é™æ–¹æ³•çš„ä¼˜åŒ–ã€‚</li></ul><h3 id="5-2-AdaGradç®—æ³•"><a href="#5-2-AdaGradç®—æ³•" class="headerlink" title="5.2 AdaGradç®—æ³•"></a>5.2 AdaGradç®—æ³•</h3><ul><li><p>AdaGradç®—æ³•æ˜¯é€šè¿‡å‚æ•°æ¥è°ƒæ•´åˆé€‚çš„å­¦ä¹ ç‡Î»ï¼Œèƒ½ç‹¬ç«‹åœ°è‡ªåŠ¨è°ƒæ•´æ¨¡å‹å‚æ•°çš„å­¦ä¹ ç‡ï¼Œå¯¹ç¨€ç–å‚æ•°è¿›è¡Œå¤§å¹…æ›´æ–°å’Œå¯¹é¢‘ç¹å‚æ•°è¿›è¡Œå°å¹…æ›´æ–°ã€‚</p><blockquote><p>Adagradæ–¹æ³•éå¸¸é€‚åˆå¤„ç†ç¨€ç–æ•°æ®ã€‚</p></blockquote></li></ul><p>ç‰¹ç‚¹ï¼š</p><ul><li><p>éšç€è¿­ä»£æ—¶é—´è¶Šé•¿ï¼Œç´¯ç§¯æ¢¯åº¦rè¶Šå¤§ï¼Œä»è€Œå­¦ä¹ é€Ÿç‡$\fracÎ»{(Î´+\sqrt r)}$éšç€æ—¶é—´å°±å‡å°ï¼Œåœ¨æ¥è¿‘ ç›®æ ‡å€¼æ—¶ï¼Œä¸ä¼šå› ä¸ºå­¦ä¹ é€Ÿç‡è¿‡å¤§è€Œè¶Šè¿‡æå€¼ç‚¹ã€‚</p><blockquote><p>å°å‚æ•°Î´ï¼šä¸€èˆ¬å–ä¸€ä¸ªè¾ƒå°å€¼(å¦‚$10^{-7}$)ï¼Œè¯¥å‚æ•°é¿å…åˆ†æ¯ä¸º0ã€‚</p></blockquote></li><li><p>ä¸åŒå‚æ•°ä¹‹é—´å­¦ä¹ é€Ÿç‡ä¸åŒï¼Œå› æ­¤ï¼Œä¸å‰é¢å›ºå®šå­¦ä¹ é€Ÿç‡ç›¸æ¯”ï¼Œä¸å®¹æ˜“åœ¨éç‚¹å¡ä½ã€‚</p></li><li><p>å¦‚æœæ¢¯åº¦ç´¯ç§¯å‚æ•°r$æ¯”è¾ƒå°$ï¼Œåˆ™å­¦ä¹ é€Ÿç‡ä¼šæ¯”è¾ƒå¤§ï¼Œæ‰€ä»¥å‚æ•°è¿­ä»£çš„æ­¥é•¿å°±ä¼šæ¯”è¾ƒå¤§ã€‚ ç›¸åï¼Œå¦‚æœæ¢¯åº¦ç´¯ç§¯å‚æ•°æ¯”è¾ƒå¤§ï¼Œåˆ™å­¦ä¹ é€Ÿç‡ä¼šæ¯”è¾ƒå°ï¼Œæ‰€ä»¥è¿­ä»£çš„æ­¥é•¿ä¼šæ¯”è¾ƒå°ã€‚</p></li></ul><h3 id="5-3-RMSPropç®—æ³•"><a href="#5-3-RMSPropç®—æ³•" class="headerlink" title="5.3 RMSPropç®—æ³•"></a>5.3 RMSPropç®—æ³•</h3><ul><li>RMSPropç®—æ³•ä¿®æ”¹AdaGradï¼Œä¸ºçš„æ˜¯åœ¨éå‡¸èƒŒæ™¯ä¸‹æ•ˆæœæ›´å¥½ã€‚</li><li>é’ˆå¯¹æ¢¯åº¦å¹³æ–¹å’Œç´¯è®¡è¶Šæ¥è¶Šå¤§çš„é—®é¢˜ï¼ŒRMSPropæŒ‡æ•°åŠ æƒçš„ç§»åŠ¨å¹³å‡ä»£æ›¿æ¢¯åº¦å¹³æ–¹å’Œã€‚</li></ul><h3 id="5-4-Admaç®—æ³•"><a href="#5-4-Admaç®—æ³•" class="headerlink" title="5.4 Admaç®—æ³•"></a>5.4 Admaç®—æ³•</h3><ul><li>Adam(Adaptive Moment Estimation)æœ¬è´¨ä¸Šæ˜¯å¸¦æœ‰åŠ¨é‡é¡¹çš„RMSpropï¼Œå®ƒåˆ©ç”¨æ¢¯åº¦çš„ä¸€é˜¶çŸ©ä¼°è®¡å’ŒäºŒé˜¶çŸ©ä¼°è®¡åŠ¨æ€è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡ã€‚</li><li>Adamçš„ä¼˜ç‚¹ä¸»è¦åœ¨äºç»è¿‡åç½®æ ¡æ­£åï¼Œæ¯ä¸€æ¬¡è¿­ä»£å­¦ä¹ ç‡éƒ½æœ‰ä¸ªç¡®å®šèŒƒå›´ï¼Œä½¿å¾—å‚æ•°æ¯”è¾ƒå¹³ç¨³ã€‚</li></ul><h3 id="5-5æ€»ç»“"><a href="#5-5æ€»ç»“" class="headerlink" title="5.5æ€»ç»“"></a>5.5æ€»ç»“</h3><ul><li>RMSpropï¼ŒAdadeltaå’ŒAdamè¢«è®¤ä¸ºæ˜¯è‡ªé€‚åº”ä¼˜åŒ–ç®—æ³•ï¼Œå› ä¸ºå®ƒä»¬ä¼šè‡ªåŠ¨æ›´æ–°å­¦ä¹ ç‡ã€‚è€Œä½¿ç”¨SGDæ—¶ï¼Œå¿…é¡»æ‰‹åŠ¨é€‰æ‹©å­¦ä¹ ç‡å’ŒåŠ¨é‡å‚æ•°ï¼Œé€šå¸¸ä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œé™ä½å­¦ä¹ ç‡ã€‚</li><li>å¯ä»¥é€šè¿‡å…ˆä½¿ç”¨Adamä¼˜åŒ–ç®—æ³•è¿›è¡Œè®­ç»ƒï¼Œè¿™å°†å¤§å¤§èŠ‚çœè®­ç»ƒæ—¶é—´ï¼Œä¸”ä¸å¿…æ‹…å¿ƒåˆå§‹åŒ–å’Œå‚æ•°è°ƒæ•´ï¼Œä¸€æ—¦ç”¨Adamè®­ç»ƒè·å¾—è¾ƒå¥½çš„å‚æ•°åï¼Œæˆ‘ä»¬å¯ä»¥åˆ‡æ¢åˆ°SGD +åŠ¨é‡ä¼˜åŒ–ï¼Œä»¥è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> æ­£åˆ™åŒ– </tag>
            
            <tag> æ¿€æ´»å‡½æ•° </tag>
            
            <tag> æŸå¤±å‡½æ•° </tag>
            
            <tag> ä¼˜åŒ–å™¨ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>å¸¸ç”¨æ¿€æ´»å‡½æ•°</title>
      <link href="/2020/11/16/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
      <url>/2020/11/16/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="å¸¸ç”¨æ¿€æ´»å‡½æ•°"><a href="#å¸¸ç”¨æ¿€æ´»å‡½æ•°" class="headerlink" title="å¸¸ç”¨æ¿€æ´»å‡½æ•°"></a>å¸¸ç”¨æ¿€æ´»å‡½æ•°</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">fig = plt.figure()</span><br></pre></td></tr></table></figure><h2 id="1-sigmoid"><a href="#1-sigmoid" class="headerlink" title="1. sigmoid"></a>1. sigmoid</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">y_sigmoid = <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">221</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">11</span>, <span class="number">11</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.gca()  <span class="comment"># è·å¾—å½“å‰axisåæ ‡è½´å¯¹è±¡</span></span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># å»é™¤å³è¾¹ç•Œçº¿</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># å»é™¤ä¸Šè¾¹ç•Œçº¿</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æŒ‡å®šdata è®¾ç½®çš„bottomï¼ˆä¹Ÿå°±æ˜¯æŒ‡å®šçš„xè½´ï¼‰ç»‘å®šåˆ°yè½´çš„0è¿™ä¸ªç‚¹ä¸Š</span></span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))  <span class="comment"># æŒ‡å®šyè½´ç»‘å®šåˆ°xè½´çš„0è¿™ä¸ªç‚¹ä¸Š</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;Sigmoid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y_sigmoid, label=<span class="string">&#x27;sigmoid&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, color=<span class="string">&#x27;darkviolet&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;sigmoid&#x27;</span>])</span><br><span class="line">plt.savefig(<span class="string">&#x27;figs/sigmoid.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115202913.png" alt="png"></p><h2 id="2-tanh"><a href="#2-tanh" class="headerlink" title="2.tanh"></a>2.tanh</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">y_tanh = (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))</span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">222</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">11</span>, <span class="number">11</span>)</span><br><span class="line">plt.ylim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.gca()  <span class="comment"># è·å¾—å½“å‰axisåæ ‡è½´å¯¹è±¡</span></span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># å»é™¤å³è¾¹ç•Œçº¿</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># å»é™¤ä¸Šè¾¹ç•Œçº¿</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æŒ‡å®šdata è®¾ç½®çš„bottomï¼ˆä¹Ÿå°±æ˜¯æŒ‡å®šçš„xè½´ï¼‰ç»‘å®šåˆ°yè½´çš„0è¿™ä¸ªç‚¹ä¸Š</span></span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))  <span class="comment"># æŒ‡å®šyè½´ç»‘å®šåˆ°xè½´çš„0è¿™ä¸ªç‚¹ä¸Š</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y_tanh, label=<span class="string">&#x27;tanh&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, color=<span class="string">&#x27;darkviolet&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;tanh&#x27;</span>])</span><br><span class="line">plt.savefig(<span class="string">&#x27;figs/tanh.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115202919.png" alt="png"></p><h2 id="3-ReLU"><a href="#3-ReLU" class="headerlink" title="3.ReLU"></a>3.ReLU</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">y_relu = np.array([<span class="number">0</span>*item <span class="keyword">if</span> item &lt; <span class="number">0</span> <span class="keyword">else</span> item <span class="keyword">for</span> item <span class="keyword">in</span> x])</span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">223</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">11</span>, <span class="number">11</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.gca()  <span class="comment"># è·å¾—å½“å‰axisåæ ‡è½´å¯¹è±¡</span></span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># å»é™¤å³è¾¹ç•Œçº¿</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># å»é™¤ä¸Šè¾¹ç•Œçº¿</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æŒ‡å®šdata è®¾ç½®çš„bottomï¼ˆä¹Ÿå°±æ˜¯æŒ‡å®šçš„xè½´ï¼‰ç»‘å®šåˆ°yè½´çš„0è¿™ä¸ªç‚¹ä¸Š</span></span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))  <span class="comment"># æŒ‡å®šyè½´ç»‘å®šåˆ°xè½´çš„0è¿™ä¸ªç‚¹ä¸Š</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;ReLU&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y_relu, label=<span class="string">&#x27;ReLU&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, color=<span class="string">&#x27;darkviolet&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;ReLU&#x27;</span>])</span><br><span class="line">plt.savefig(<span class="string">&#x27;figs/ReLU.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115202934.png" alt="png"></p><h2 id="4-LeakyReLU"><a href="#4-LeakyReLU" class="headerlink" title="4. LeakyReLU"></a>4. LeakyReLU</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">y_leakyrelu = np.array([<span class="number">0.2</span>*item <span class="keyword">if</span> item &lt; <span class="number">0</span> <span class="keyword">else</span> item <span class="keyword">for</span> item <span class="keyword">in</span> x])</span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">224</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">11</span>,<span class="number">11</span>)</span><br><span class="line">plt.ylim(-<span class="number">2</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.gca() <span class="comment"># è·å¾—å½“å‰axisåæ ‡è½´å¯¹è±¡</span></span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>) <span class="comment"># å»é™¤å³è¾¹ç•Œçº¿</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>) <span class="comment"># å»é™¤ä¸Šè¾¹ç•Œçº¿</span></span><br><span class="line"></span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>)) <span class="comment"># æŒ‡å®šdata è®¾ç½®çš„bottomï¼ˆä¹Ÿå°±æ˜¯æŒ‡å®šçš„xè½´ï¼‰ç»‘å®šåˆ°yè½´çš„0è¿™ä¸ªç‚¹ä¸Š</span></span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>))  <span class="comment"># æŒ‡å®šyè½´ç»‘å®šåˆ°xè½´çš„0è¿™ä¸ªç‚¹ä¸Š</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;LeakyReLU&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x,y_leakyrelu,label = <span class="string">&#x27;LeakyReLU&#x27;</span>,linestyle=<span class="string">&#x27;-&#x27;</span>,color=<span class="string">&#x27;darkviolet&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;LeakyReLU&#x27;</span>])</span><br><span class="line">plt.savefig(<span class="string">&#x27;figs/LeakyReLU.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115202927.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>åˆ©ç”¨ç¥ç»ç½‘ç»œå®Œæˆå¯¹æ‰‹å†™æ•°å­—è¿›è¡Œè¯†åˆ«</title>
      <link href="/2020/11/15/%E5%88%A9%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%8C%E6%88%90%E5%AF%B9%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%BF%9B%E8%A1%8C%E8%AF%86%E5%88%AB/"/>
      <url>/2020/11/15/%E5%88%A9%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%8C%E6%88%90%E5%AF%B9%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%BF%9B%E8%A1%8C%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="åˆ©ç”¨ç¥ç»ç½‘ç»œå®Œæˆå¯¹æ‰‹å†™æ•°å­—è¿›è¡Œè¯†åˆ«"><a href="#åˆ©ç”¨ç¥ç»ç½‘ç»œå®Œæˆå¯¹æ‰‹å†™æ•°å­—è¿›è¡Œè¯†åˆ«" class="headerlink" title="åˆ©ç”¨ç¥ç»ç½‘ç»œå®Œæˆå¯¹æ‰‹å†™æ•°å­—è¿›è¡Œè¯†åˆ«"></a>åˆ©ç”¨ç¥ç»ç½‘ç»œå®Œæˆå¯¹æ‰‹å†™æ•°å­—è¿›è¡Œè¯†åˆ«</h1><ul><li>ç½‘ç»œç»“æ„</li></ul><p>  <img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201114171840.png" alt=""></p><blockquote><p>ä¸¤ä¸ªéšè—å±‚<br>æ¯å±‚æ¿€æ´»å‡½æ•°ä¸ºRelu<br>æ•°æ®é›†ï¼šmnist</p></blockquote><h2 id="1-å‡†å¤‡æ•°æ®"><a href="#1-å‡†å¤‡æ•°æ®" class="headerlink" title="1. å‡†å¤‡æ•°æ®"></a>1. å‡†å¤‡æ•°æ®</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># å¯¼å…¥ pytorch å†…ç½®çš„ mnist æ•°æ®</span></span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="comment"># å¯¼å…¥é¢„å¤„ç†æ¨¡å—</span></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="comment"># å¯¼å…¥nnåŠä¼˜åŒ–å™¨</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br></pre></td></tr></table></figure><h2 id="2-å®šä¹‰ä¸€äº›è¶…å‚æ•°"><a href="#2-å®šä¹‰ä¸€äº›è¶…å‚æ•°" class="headerlink" title="2. å®šä¹‰ä¸€äº›è¶…å‚æ•°"></a>2. å®šä¹‰ä¸€äº›è¶…å‚æ•°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰ä¸€äº›è¶…å‚æ•°</span></span><br><span class="line">train_batch_size = <span class="number">64</span></span><br><span class="line">test_batch_size = <span class="number">128</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">num_epoches = <span class="number">20</span></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">momentum = <span class="number">0.5</span></span><br></pre></td></tr></table></figure><h2 id="3-ä¸‹è½½æ•°æ®å¹¶å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†"><a href="#3-ä¸‹è½½æ•°æ®å¹¶å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†" class="headerlink" title="3. ä¸‹è½½æ•°æ®å¹¶å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†"></a>3. ä¸‹è½½æ•°æ®å¹¶å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰é¢„å¤„ç†å‡½æ•°ï¼Œè¿™äº›é¢„å¤„ç†ä¾æ¬¡æ”¾åœ¨Composeå‡½æ•°ä¸­ã€‚</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(), transforms.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>])])</span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ¤æ–­æ˜¯å¦éœ€è¦ä»ç½‘ç»œä¸‹è½½æ•°æ®é›†</span></span><br><span class="line">is_downloda = <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(<span class="string">&#x27;./data/MNIST&#x27;</span>):</span><br><span class="line">    is_downloda = <span class="literal">False</span></span><br><span class="line"><span class="comment"># ä¸‹è½½æ•°æ®ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†</span></span><br><span class="line">train_dataset = mnist.MNIST(</span><br><span class="line">    <span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, transform=transform, download=is_downloda)</span><br><span class="line">test_dataset = mnist.MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, transform=transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataloaderæ˜¯ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼Œå¯ä»¥ä½¿ç”¨è¿­ä»£å™¨ä¸€æ ·ä½¿ç”¨ã€‚</span></span><br><span class="line">train_loader = DataLoader(</span><br><span class="line">    train_dataset, batch_size=train_batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">    test_dataset, batch_size=test_batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li>Normalize([0.5], [0.5])å¯¹å¼ é‡è¿›è¡Œå½’ä¸€åŒ–ï¼Œè¿™é‡Œä¸¤ä¸ª0.5åˆ†åˆ«è¡¨ç¤ºå¯¹å¼ é‡è¿›è¡Œå½’ä¸€åŒ–çš„å…¨å±€å¹³å‡å€¼å’Œæ–¹å·®ã€‚å› å›¾åƒæ˜¯ç°è‰²çš„åªæœ‰ä¸€ä¸ªé€šé“ï¼Œå¦‚æœæœ‰å¤šä¸ªé€šé“ï¼Œéœ€è¦æœ‰å¤šä¸ªæ•°å­—ï¼Œå¦‚ä¸‰ä¸ªé€šé“ï¼Œåº”è¯¥æ˜¯Normalize([m1,m2,m3], [n1,n2,n3])</li><li>ç”¨DataLoaderå¾—åˆ°ç”Ÿæˆå™¨ï¼Œå¯èŠ‚çœå†…å­˜ã€‚</li></ul><h2 id="4-å¯è§†åŒ–æºæ•°æ®"><a href="#4-å¯è§†åŒ–æºæ•°æ®" class="headerlink" title="4. å¯è§†åŒ–æºæ•°æ®"></a>4. å¯è§†åŒ–æºæ•°æ®</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">examples = <span class="built_in">enumerate</span>(test_loader)</span><br><span class="line"><span class="comment"># enumerate() å‡½æ•°ç”¨äºå°†ä¸€ä¸ªå¯éå†çš„æ•°æ®å¯¹è±¡(å¦‚åˆ—è¡¨ã€å…ƒç»„æˆ–å­—ç¬¦ä¸²)ç»„åˆä¸ºä¸€ä¸ªç´¢å¼•åºåˆ—ï¼ŒåŒæ—¶åˆ—å‡ºæ•°æ®å’Œæ•°æ®ä¸‹æ ‡ã€‚</span></span><br><span class="line">batch_idx, (example_data, example_targets) = <span class="built_in">next</span>(examples)</span><br><span class="line"><span class="comment"># next() è¿”å›è¿­ä»£å™¨çš„ä¸‹ä¸€ä¸ªé¡¹ç›®ã€‚</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">3</span>, i+<span class="number">1</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.imshow(example_data[i][<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;Ground Truth: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(example_targets[i]))</span><br><span class="line">    <span class="comment"># å…³é—­x,yè½´æ˜¾ç¤º</span></span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201114172136.png" alt="png"></p><h2 id="5-æ„å»ºæ¨¡å‹"><a href="#5-æ„å»ºæ¨¡å‹" class="headerlink" title="5. æ„å»ºæ¨¡å‹"></a>5. æ„å»ºæ¨¡å‹</h2><h3 id="5-1-æ„å»ºç½‘ç»œ"><a href="#5-1-æ„å»ºç½‘ç»œ" class="headerlink" title="5.1 æ„å»ºç½‘ç»œ"></a>5.1 æ„å»ºç½‘ç»œ</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ä½¿ç”¨sequentialæ„å»ºç½‘ç»œï¼ŒSequential()å‡½æ•°çš„åŠŸèƒ½æ˜¯å°†ç½‘ç»œçš„å±‚ç»„åˆåˆ°ä¸€èµ·</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, n_hidden_1, n_hidden_2, out_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.layer1 = nn.Sequential(</span><br><span class="line">            nn.Linear(in_dim, n_hidden_1), nn.BatchNorm1d(n_hidden_1))</span><br><span class="line">        self.layer2 = nn.Sequential(</span><br><span class="line">            nn.Linear(n_hidden_1, n_hidden_2), nn.BatchNorm1d(n_hidden_2))</span><br><span class="line">        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.relu(self.layer1(x))</span><br><span class="line">        x = F.relu(self.layer2(x))</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="5-2-å®ä¾‹åŒ–ç½‘ç»œ"><a href="#5-2-å®ä¾‹åŒ–ç½‘ç»œ" class="headerlink" title="5.2 å®ä¾‹åŒ–ç½‘ç»œ"></a>5.2 å®ä¾‹åŒ–ç½‘ç»œ</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ£€æµ‹æ˜¯å¦æœ‰å¯ç”¨çš„GPUï¼Œæœ‰åˆ™ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨CPU</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;GPUæ˜¯å¦å¯ç”¨&quot;</span>, torch.cuda.is_available())</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># å®ä¾‹åŒ–ç½‘ç»œ</span></span><br><span class="line">model = Net(<span class="number">28</span> * <span class="number">28</span>, <span class="number">300</span>, <span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># è¾“å‡º10ç»´ï¼ˆ10ä¸ªæ•°å­—ï¼‰</span></span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)</span><br></pre></td></tr></table></figure><pre><code>GPUæ˜¯å¦å¯ç”¨ False</code></pre><h2 id="6-è®­ç»ƒæ¨¡å‹"><a href="#6-è®­ç»ƒæ¨¡å‹" class="headerlink" title="6. è®­ç»ƒæ¨¡å‹"></a>6. è®­ç»ƒæ¨¡å‹</h2><h3 id="6-1-è®­ç»ƒæ¨¡å‹"><a href="#6-1-è®­ç»ƒæ¨¡å‹" class="headerlink" title="6.1 è®­ç»ƒæ¨¡å‹"></a>6.1 è®­ç»ƒæ¨¡å‹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¼€å§‹è®­ç»ƒ</span></span><br><span class="line">losses = []</span><br><span class="line">acces = []</span><br><span class="line">eval_losses = []</span><br><span class="line">eval_acces = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoches):</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    train_acc = <span class="number">0</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment"># åŠ¨æ€ä¿®æ”¹å‚æ•°å­¦ä¹ ç‡</span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">        optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>] *= <span class="number">0.1</span></span><br><span class="line">    <span class="keyword">for</span> img, label <span class="keyword">in</span> train_loader:</span><br><span class="line">        img = img.to(device)</span><br><span class="line">        label = label.to(device)</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), -<span class="number">1</span>)  <span class="comment"># å±•æˆ1ç»´</span></span><br><span class="line">        <span class="comment"># å‰å‘ä¼ æ’­</span></span><br><span class="line">        out = model(img)  <span class="comment"># ä¼ å…¥å‚æ•°ï¼Œè‡ªåŠ¨æ‰§è¡Œforwardå‡½æ•°</span></span><br><span class="line">        loss = criterion(out, label)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># æ¢¯åº¦æ¸…é›¶</span></span><br><span class="line">        <span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line">        <span class="comment"># ç¼ºçœæƒ…å†µä¸‹ï¼Œæ¢¯åº¦æ˜¯ç´¯åŠ çš„ï¼Œåœ¨æ¢¯åº¦åå‘ä¼ æ’­ä¹‹å‰ï¼Œéœ€è¦æ¢¯åº¦æ¸…é›¶</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()  <span class="comment"># åŸºäºå½“å‰æ¢¯åº¦ï¼Œæ›´æ–°å‚æ•°</span></span><br><span class="line">        <span class="comment"># è®°å½•è¯¯å·®</span></span><br><span class="line">        train_loss += loss.item()</span><br><span class="line">        <span class="comment"># è®¡ç®—åˆ†ç±»çš„å‡†ç¡®ç‡</span></span><br><span class="line">        _, pred = out.<span class="built_in">max</span>(<span class="number">1</span>)  <span class="comment"># æ‰¾å‡ºå¼ é‡outæœ€å¤§å€¼å¯¹åº”ç´¢å¼•ä½œä¸ºé¢„æµ‹å€¼</span></span><br><span class="line">        num_correct = (pred == label).<span class="built_in">sum</span>().item()</span><br><span class="line">        acc = num_correct / img.shape[<span class="number">0</span>]</span><br><span class="line">        train_acc += acc</span><br><span class="line"></span><br><span class="line">    losses.append(train_loss / <span class="built_in">len</span>(train_loader))</span><br><span class="line">    acces.append(train_acc / <span class="built_in">len</span>(train_loader))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># åœ¨æµ‹è¯•é›†ä¸Šæ£€éªŒæ•ˆæœ</span></span><br><span class="line">    eval_loss = <span class="number">0</span></span><br><span class="line">    eval_acc = <span class="number">0</span></span><br><span class="line">    <span class="comment"># å°†æ¨¡å‹æ”¹ä¸ºé¢„æµ‹æ¨¡å¼</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">for</span> img, label <span class="keyword">in</span> test_loader:</span><br><span class="line">        img = img.to(device)</span><br><span class="line">        label = label.to(device)</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># å‰å‘ä¼ æ’­</span></span><br><span class="line">        out = model(img)</span><br><span class="line">        loss = criterion(out, label)</span><br><span class="line">        <span class="comment"># è®°å½•è¯¯å·®</span></span><br><span class="line">        eval_loss += loss.item()</span><br><span class="line">        <span class="comment"># è®°å½•å‡†ç¡®ç‡</span></span><br><span class="line">        _, pred = out.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">        num_correct = (pred == label).<span class="built_in">sum</span>().item()</span><br><span class="line">        acc = num_correct / img.shape[<span class="number">0</span>]</span><br><span class="line">        eval_acc += acc</span><br><span class="line"></span><br><span class="line">    eval_losses.append(eval_loss / <span class="built_in">len</span>(test_loader))</span><br><span class="line">    eval_acces.append(eval_acc / <span class="built_in">len</span>(test_loader))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch: &#123;&#125;, Train Loss: &#123;:.4f&#125;, Train Acc: &#123;:.4f&#125;, Test Loss: &#123;:.4f&#125;, Test Acc: &#123;:.4f&#125;&#x27;</span></span><br><span class="line">          .<span class="built_in">format</span>(epoch, train_loss / <span class="built_in">len</span>(train_loader), train_acc / <span class="built_in">len</span>(train_loader),</span><br><span class="line">                  eval_loss / <span class="built_in">len</span>(test_loader), eval_acc / <span class="built_in">len</span>(test_loader)))</span><br></pre></td></tr></table></figure><pre><code>epoch: 0, Train Loss: 1.0274, Train Acc: 0.7921, Test Loss: 0.5553, Test Acc: 0.9008epoch: 1, Train Loss: 0.4833, Train Acc: 0.8995, Test Loss: 0.3530, Test Acc: 0.9259epoch: 2, Train Loss: 0.3504, Train Acc: 0.9187, Test Loss: 0.2769, Test Acc: 0.9384epoch: 3, Train Loss: 0.2838, Train Acc: 0.9328, Test Loss: 0.2301, Test Acc: 0.9483epoch: 4, Train Loss: 0.2431, Train Acc: 0.9408, Test Loss: 0.1980, Test Acc: 0.9530epoch: 5, Train Loss: 0.2202, Train Acc: 0.9463, Test Loss: 0.1964, Test Acc: 0.9534epoch: 6, Train Loss: 0.2188, Train Acc: 0.9464, Test Loss: 0.1913, Test Acc: 0.9537epoch: 7, Train Loss: 0.2159, Train Acc: 0.9471, Test Loss: 0.1882, Test Acc: 0.9551epoch: 8, Train Loss: 0.2131, Train Acc: 0.9487, Test Loss: 0.1869, Test Acc: 0.9540epoch: 9, Train Loss: 0.2107, Train Acc: 0.9490, Test Loss: 0.1835, Test Acc: 0.9559epoch: 10, Train Loss: 0.2081, Train Acc: 0.9500, Test Loss: 0.1846, Test Acc: 0.9552epoch: 11, Train Loss: 0.2090, Train Acc: 0.9492, Test Loss: 0.1855, Test Acc: 0.9558epoch: 12, Train Loss: 0.2091, Train Acc: 0.9483, Test Loss: 0.1841, Test Acc: 0.9558epoch: 13, Train Loss: 0.2076, Train Acc: 0.9493, Test Loss: 0.1871, Test Acc: 0.9544epoch: 14, Train Loss: 0.2066, Train Acc: 0.9491, Test Loss: 0.1833, Test Acc: 0.9562epoch: 15, Train Loss: 0.2086, Train Acc: 0.9491, Test Loss: 0.1837, Test Acc: 0.9560epoch: 16, Train Loss: 0.2074, Train Acc: 0.9496, Test Loss: 0.1827, Test Acc: 0.9559epoch: 17, Train Loss: 0.2076, Train Acc: 0.9488, Test Loss: 0.1835, Test Acc: 0.9559epoch: 18, Train Loss: 0.2076, Train Acc: 0.9494, Test Loss: 0.1845, Test Acc: 0.9558epoch: 19, Train Loss: 0.2074, Train Acc: 0.9497, Test Loss: 0.1844, Test Acc: 0.9551</code></pre><h3 id="6-2-å¯è§†åŒ–è®­ç»ƒåŠæµ‹è¯•æŸå¤±å€¼"><a href="#6-2-å¯è§†åŒ–è®­ç»ƒåŠæµ‹è¯•æŸå¤±å€¼" class="headerlink" title="6.2 å¯è§†åŒ–è®­ç»ƒåŠæµ‹è¯•æŸå¤±å€¼"></a>6.2 å¯è§†åŒ–è®­ç»ƒåŠæµ‹è¯•æŸå¤±å€¼</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">&#x27;train loss&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.plot(np.arange(<span class="built_in">len</span>(losses)), losses)</span><br><span class="line">plt.legend([<span class="string">&#x27;Train Loss&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;train acces&#x27;</span>)</span><br><span class="line">plt.plot(np.arange(<span class="built_in">len</span>(acces)),acces,color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;acces&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Train acces&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201114172141.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨TensoråŠAutogradå®ç°æœºå™¨å­¦ä¹ </title>
      <link href="/2020/11/14/%E4%BD%BF%E7%94%A8Tensor%E5%8F%8AAutograd%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/11/14/%E4%BD%BF%E7%94%A8Tensor%E5%8F%8AAutograd%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨TensoråŠAutogradå®ç°æœºå™¨å­¦ä¹ "><a href="#ä½¿ç”¨TensoråŠAutogradå®ç°æœºå™¨å­¦ä¹ " class="headerlink" title="ä½¿ç”¨TensoråŠAutogradå®ç°æœºå™¨å­¦ä¹ "></a>ä½¿ç”¨TensoråŠAutogradå®ç°æœºå™¨å­¦ä¹ </h1><p>è¡¨è¾¾å¼ï¼š$y=3x^2+2$</p><p>æ¨¡å‹ï¼š$y=wx^2+b$</p><p>æŸå¤±å‡½æ•°ï¼š$Loss=\frac{1}{2}\sum_{i=1}^{100}(wx^2_i+b-y_i)^2$</p><p>å¯¹æŸå¤±å‡½æ•°æ±‚å¯¼ï¼š<br>$\frac{\partial Loss}{\partial w}=\sum_{i=1}^{100}(wx^2_i+b-y_i)^2x^2_i$</p><p>$\frac{\partial Loss}{\partial b}=\sum_{i=1}^{100}(wx^2_i+b-y_i)^2$</p><p>åˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•å­¦ä¹ å‚æ•°ï¼Œå­¦ä¹ ç‡ä¸º:lr</p><p>$w_1-=lr*\frac{\partial Loss}{\partial w}$</p><p>$b_1-=lr*\frac{\partial Loss}{\partial b}$</p><h3 id="1-ç”Ÿæˆè®­ç»ƒæ•°æ®"><a href="#1-ç”Ÿæˆè®­ç»ƒæ•°æ®" class="headerlink" title="1.ç”Ÿæˆè®­ç»ƒæ•°æ®"></a>1.ç”Ÿæˆè®­ç»ƒæ•°æ®</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">100</span>)</span><br><span class="line">dtype = torch.<span class="built_in">float</span></span><br><span class="line"><span class="comment"># ç”Ÿæˆxåæ ‡æ•°æ®ï¼Œxä¸ºtensorï¼Œè½¬æˆ100x1çš„å½¢çŠ¶</span></span><br><span class="line"><span class="comment"># dim = 1è¡¨ç¤ºåˆ—</span></span><br><span class="line">x = torch.unsqueeze(torch.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">100</span>), dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(x)</span></span><br><span class="line"><span class="comment"># ç”Ÿæˆyåæ ‡æ•°æ®ï¼Œyä¸ºtensorï¼Œ100x1çš„å½¢çŠ¶ï¼Œå¹¶ä¸”åŠ ä¸€ç‚¹å™ªå£°</span></span><br><span class="line">y = <span class="number">3</span>*x.<span class="built_in">pow</span>(<span class="number">2</span>)+<span class="number">2</span> + <span class="number">0.2</span>*torch.rand(x.size())</span><br><span class="line"><span class="comment"># æŠŠtensorè½¬æˆnumpyç”»å›¾</span></span><br><span class="line">plt.scatter(x.numpy(), y.numpy())</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201114110727.png" alt="png"></p><h3 id="2-åˆå§‹åŒ–æƒé‡å‚æ•°"><a href="#2-åˆå§‹åŒ–æƒé‡å‚æ•°" class="headerlink" title="2.åˆå§‹åŒ–æƒé‡å‚æ•°"></a>2.åˆå§‹åŒ–æƒé‡å‚æ•°</h3><blockquote><p>torch.randå’Œtorch.randnæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ</p><ul><li>torch.randå‡åŒ€åˆ†å¸ƒï¼Œtorch.randnæ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒã€‚</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># éšå³åˆå§‹åŒ–å‚æ•°ï¼Œå‚æ•°w,bæ˜¯éœ€è¦å­¦ä¹ çš„ï¼Œæ‰€ä»¥requires_grad=True</span></span><br><span class="line"></span><br><span class="line">w = torch.randn(<span class="number">1</span>, <span class="number">1</span>, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(w)</span></span><br><span class="line">b = torch.zeros(<span class="number">1</span>, <span class="number">1</span>, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(b)</span></span><br></pre></td></tr></table></figure><pre><code>tensor([[0.]], requires_grad=True)</code></pre><h3 id="3-è®­ç»ƒæ¨¡å‹"><a href="#3-è®­ç»ƒæ¨¡å‹" class="headerlink" title="3.è®­ç»ƒæ¨¡å‹"></a>3.è®­ç»ƒæ¨¡å‹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.001</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8000</span>):</span><br><span class="line">    <span class="comment"># å‰å‘ä¼ æ’­ mm()çŸ©é˜µä¹˜æ³•</span></span><br><span class="line">    y_pred = x.<span class="built_in">pow</span>(<span class="number">2</span>).mm(w)+b</span><br><span class="line">    <span class="comment"># æŸå¤±å‡½æ•°</span></span><br><span class="line">    loss = <span class="number">0.5</span>*(y_pred-y)**<span class="number">2</span></span><br><span class="line">    loss = loss.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># è‡ªåŠ¨è®¡ç®—æ¢¯åº¦</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># æ‰‹åŠ¨æ›´æ–°å‚æ•°ï¼Œéœ€è¦ä½¿ç”¨torch.no_grad()åŒ…å›´ï¼Œä½¿ä¸Šä¸‹æ–‡ä¸­åˆ‡æ–­è‡ªåŠ¨æ±‚å¯¼çš„è®¡ç®—</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w -= lr*w.grad</span><br><span class="line">        b -= lr*b.grad</span><br><span class="line">        <span class="comment"># æ¢¯åº¦æ¸…é›¶</span></span><br><span class="line">        w.grad.zero_()</span><br><span class="line">        b.grad.zero_()</span><br></pre></td></tr></table></figure><h3 id="4-å¯è§†åŒ–è®­ç»ƒç»“æœ"><a href="#4-å¯è§†åŒ–è®­ç»ƒç»“æœ" class="headerlink" title="4.å¯è§†åŒ–è®­ç»ƒç»“æœ"></a>4.å¯è§†åŒ–è®­ç»ƒç»“æœ</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x.numpy(), y_pred.detach().numpy(), <span class="string">&#x27;r-&#x27;</span>, label=<span class="string">&#x27;predict&#x27;</span>)</span><br><span class="line"><span class="comment"># è°ƒç”¨detach()ä¸å†è®¡ç®—å¼ é‡æ¢¯åº¦</span></span><br><span class="line">plt.scatter(x.numpy(), y.numpy(), color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;true&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">2</span>, <span class="number">6</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># é¢„æµ‹ç»“æœ</span></span><br><span class="line"><span class="built_in">print</span>(w, b)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201114110730.png" alt="png"></p><pre><code>tensor([[2.9668]], requires_grad=True) tensor([[2.1138]], requires_grad=True)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GCN</title>
      <link href="/2020/11/12/GCN/"/>
      <url>/2020/11/12/GCN/</url>
      
        <content type="html"><![CDATA[<h1 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h1><blockquote><p>GCNï¼šå›¾å·ç§¯ç½‘ç»œ</p><p>SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKSï¼šåŸºäºå›¾å·ç§¯ç½‘ç»œçš„åŠç›‘ç£åˆ†ç±»</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><ul><li>åœ¨å›¾ç»“æ„æ•°æ®ä¸­ï¼Œä¸€éƒ¨èŠ‚ç‚¹å·²çŸ¥æ ‡ç­¾ï¼Œå‰©ä¸‹çš„èŠ‚ç‚¹æ ‡ç­¾æœªçŸ¥ï¼Œä½¿ç”¨å·²çŸ¥æ ‡ç­¾çš„èŠ‚ç‚¹è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œï¼Œä½¿ç”¨ç½‘ç»œæ¨¡å‹å¯¹æ— æ ‡ç­¾çš„èŠ‚ç‚¹è¿›è¡Œåˆ†ç±»ã€‚</li></ul><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><ul><li>æå‡ºäº†ä¸€ç§å¯æ‰©å±•çš„åŸºäºå›¾ç»“æ„æ•°æ®çš„åŠç›‘ç£åˆ†ç±»æ–¹æ³•ã€‚</li><li>åˆ†å±‚ä¼ æ’­è§„åˆ™ï¼šé€šè¿‡è°±å›¾å·ç§¯ï¼ˆspectral graph convolutionsï¼‰ çš„å±€éƒ¨ä¸€é˜¶è¿‘ä¼¼ï¼Œæ¥ç¡®å®šå·ç§¯ç½‘ç»œç»“æ„ã€‚</li></ul><h3 id="f-X-A"><a href="#f-X-A" class="headerlink" title="$f(X,A)$"></a>$f(X,A)$</h3><ul><li><p>ä½¿ç”¨ç¥ç»ç½‘ç»œ$f(X,A)$å¯¹å›¾çš„ç»“æ„è¿›è¡Œç¼–ç ï¼Œå¯¹æ‰€æœ‰å¸¦æ ‡ç­¾çš„èŠ‚ç‚¹è¿›è¡Œæœ‰ç›‘ç£è®­ç»ƒã€‚</p></li><li><p>é¿å…æ˜¾å¼åœ°å¯¹åŸºäºå›¾çš„æŸå¤±å‡½æ•°è¿›è¡Œæ­£åˆ™åŒ–è®¡ç®—</p></li><li><p>åœ¨å›¾çš„é‚»æ¥çŸ©é˜µä¸Šè°ƒèŠ‚$f (â‹…)$ ï¼Œå…è®¸æ¨¡å‹ä»ç›‘ç£æŸå¤±$\mathcal{L}_{0}$ä¸­åˆ†å¼€æ¢¯åº¦ä¿¡æ¯ï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ æ‰€æœ‰èŠ‚ç‚¹çš„è¡¨ç¤ºã€‚</p></li><li><blockquote><p>Xï¼šè¾“å…¥æ•°æ®</p><p>Aï¼šå›¾é‚»æ¥çŸ©é˜µ</p></blockquote></li></ul><h3 id="FAST-APPROXIMATE-CONVOLUTIONS-ON-GRAPHS"><a href="#FAST-APPROXIMATE-CONVOLUTIONS-ON-GRAPHS" class="headerlink" title="FAST APPROXIMATE CONVOLUTIONS ON GRAPHS"></a>FAST APPROXIMATE CONVOLUTIONS ON GRAPHS</h3><ul><li>å›¾å·ç§¯çš„å‰å‘ä¼ æ’­å…¬å¼ï¼š</li></ul><script type="math/tex; mode=display">H^{(l+1)}=Ïƒ(\tilde D^{\frac{1}{2}}\tilde A \tilde D ^{-\frac{1}{2}}H^{(l)}W^{(l)})</script><h4 id="SPECTRAL-GRAPH-CONVOLUTIONS"><a href="#SPECTRAL-GRAPH-CONVOLUTIONS" class="headerlink" title="SPECTRAL GRAPH CONVOLUTIONS"></a>SPECTRAL GRAPH CONVOLUTIONS</h4><blockquote><p>é¢‘è°±å›¾å½¢å·ç§¯</p><p>åŠç›‘ç£åˆ†ç±»å›¾å·ç§¯ç½‘ç»œæ˜¯åœ¨å…ˆå‰çš„é¢‘è°±å·ç§¯ç½‘ç»œçš„åŸºç¡€ä¸Šé€šè¿‡å±€éƒ¨ä¸€é˜¶è¿‘ä¼¼å¾—åˆ°çš„</p></blockquote><ul><li><p>å¯¹äºä¸€ä¸ªè¾“å…¥ä¿¡å· $x \in \mathbb{R}^N$ ï¼Œåœ¨å‚…é‡Œå¶åŸŸä¸­å–ä¸€ä¸ª$\theta \in \mathbb{R}^N$ä¸ºå‚æ•°çš„æ»¤æ³¢å™¨$g_{\theta} = diag(\theta)$ã€‚</p><blockquote><p>å°†å›¾å·ç§¯é€šè¿‡å‚…é‡Œå¶å˜æ¢æ‹“å±•åˆ°å›¾çš„é¢‘åŸŸä¸­ã€‚</p><p>ç¬¬ä¸€ä»£GCNå›¾å·ç§¯å…¬å¼</p><p>ç¼ºç‚¹ï¼šè®¡ç®—å¤æ‚</p></blockquote></li></ul><script type="math/tex; mode=display">gÎ¸â‹†x=U_{gÎ¸}U^âŠ¤_{x}</script><ul><li><p>å°†$g_{\theta}(\Lambda)$ç”¨åˆ‡æ¯”é›ªå¤«å¤šé¡¹å¼ï¼ˆChebyshevï¼‰è¿›è¡ŒKé˜¶é€¼è¿‘ã€‚</p><blockquote><p>æ”¹è¿›çš„å·ç§¯æ ¸ï¼š</p></blockquote></li></ul><script type="math/tex; mode=display">g_{Î¸â€˜}â€‹(Î›)â‰ˆ\sum_{k=0}^KÎ¸_k^â€²T_k(\tilde Î›)</script><ul><li><p>å°†è¯¥å·ç§¯æ ¸ä»£å…¥å›¾å·ç§¯çš„å…¬å¼ï¼š</p><blockquote><p>å°†å‚æ•°å‡å°‘åˆ°äº†Kä¸ªï¼Œå¹¶ä¸”ä¸å†éœ€è¦å¯¹æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µåšç‰¹å¾åˆ†è§£ã€‚</p></blockquote></li></ul><script type="math/tex; mode=display">g_{Î¸â€˜}â‹†*â‰ˆ\sum_{k=0}^KÎ¸_k^â€²T_k(\tilde L)x</script><h4 id="LAYER-WISE-LINEAR-MODEL"><a href="#LAYER-WISE-LINEAR-MODEL" class="headerlink" title="LAYER-WISE LINEAR MODEL"></a>LAYER-WISE LINEAR MODEL</h4><blockquote><p>çº¿æ€§æ¨¡å‹</p></blockquote><script type="math/tex; mode=display">g_{Î¸â€²}âˆ—x=\sum _{k=0}^KÎ¸^â€²kT_k(\tilde L)x</script><blockquote><ul><li>é™åˆ¶å‚æ•°æ•°é‡å¯ä»¥è¿›ä¸€æ­¥è§£å†³è¿‡æ‹Ÿåˆå¹¶å°†å„å±‚çš„è¿ç®—é‡æœ€å°åŒ–ï¼Œä½¿å¾—å¯ä»¥é€šè¿‡å †å å¤šä¸ªGCNæ¥è·å¾—ä¸€ä¸ªæ›´æ·±çš„æ¨¡å‹ï¼Œæå–ç‰¹å¾ã€‚</li><li>ä¸ºè§£å†³æ•°å€¼ä¸ç¨³å®šæ€§å’Œæ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±ï¼Œè¿›è¡Œäº†å†å½’ä¸€åŒ–ã€‚</li><li>é™åˆ¶å‚æ•°çš„æ•°é‡ä»¥è§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜ï¼Œå¹¶æœ€å°åŒ–æ¯å±‚çš„è¿ç®—æ•°é‡(ä¾‹å¦‚çŸ©é˜µä¹˜æ³•)ã€‚</li></ul></blockquote><h2 id="SEMI-SUPERVISED-NODE-CLASSIFICATION"><a href="#SEMI-SUPERVISED-NODE-CLASSIFICATION" class="headerlink" title="SEMI-SUPERVISED NODE CLASSIFICATION"></a>SEMI-SUPERVISED NODE CLASSIFICATION</h2><blockquote><p>åŠç›‘ç£èŠ‚ç‚¹åˆ†ç±»</p></blockquote><ul><li>ä½¿ç”¨å·²çŸ¥çš„æ•°æ®$X$å’Œé‚»æ¥çŸ©é˜µ$A$æ¥è®­ç»ƒå›¾å·ç§¯ç½‘ç»œ $f(X, A)$ã€‚</li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201111095929.png" alt="image-20201110211205798" style="zoom: 50%;" /></p><blockquote><p>GCNç½‘ç»œç¤ºæ„å›¾</p><ul><li><p>è¾“å…¥å±‚æ‹¥æœ‰Cä¸ªè¾“å…¥ï¼Œä¸­é—´æœ‰è‹¥å¹²éšè—å±‚ï¼Œåœ¨è¾“å‡ºå±‚æœ‰Fä¸ªç‰¹å¾æ˜ å°„ã€‚</p></li><li><p>å›¾çš„ç»“æ„åœ¨å±‚ä¹‹é—´å…±äº«ã€‚</p></li><li><p>æ ‡ç­¾ç”¨$Y_{i}$ è¡¨ç¤ºã€‚</p></li></ul></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201111100059.png" alt="image-20201110211553795" style="zoom:50%;" /></p><blockquote><p>ä¸¤å±‚GCNåœ¨Coraæ•°æ®é›†ä¸Šï¼ˆä½¿ç”¨äº†5%çš„æ ‡ç­¾ï¼‰è®­ç»ƒå¾—åˆ°çš„éšè—å±‚æ¿€æ´»å€¼çš„å½¢è±¡åŒ–è¡¨ç¤ºï¼Œé¢œè‰²è¡¨ç¤ºæ–‡æ¡£ç±»åˆ«ã€‚</p></blockquote><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><p>Citeseer,Cora ,Pubmed ,NELL</p><blockquote><p>å¼•æ–‡ç½‘ç»œæ•°æ®é›†ï¼šCiteseer,Cora,Pubmed</p></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201111102914.png" alt="image-20201110211901273" style="zoom:50%;" /></p><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><blockquote><p>æ¯”è¾ƒæ¨¡å‹ï¼š</p><p>æµå½¢æ­£åˆ™åŒ–(ManiReg)ã€åŠç›‘ç£åµŒå…¥(SemiEmb)ã€æ ‡ç­¾ä¼ æ’­(LP)ã€åŸºäºè·³è·ƒæ–‡æ³•çš„å›¾åµŒå…¥(DeepWalk)ã€è¿­ä»£åˆ†ç±»ç®—æ³•(ICA)ã€ä¸¤ä¸ªLogisticå›å½’åˆ†ç±»å™¨ã€‚</p></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201111102922.png" alt="image-20201110213407738" style="zoom: 50%;" /></p><ul><li><p>GCNåœ¨å››ä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°éƒ½æ¯”è¾ƒçªå‡ºï¼Œåˆ†ç±»å‡†ç¡®æ€§è¾ƒé«˜ã€‚</p></li><li><p>æå‡ºçš„GCNæ¨¡å‹èƒ½å¤ŸåŒæ—¶å¯¹å›¾ç»“æ„å’ŒèŠ‚ç‚¹ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œå¯¹åŠç›‘ç£åˆ†ç±»æ˜¯æœ‰ç”¨çš„ã€‚</p></li></ul><h2 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h2><h3 id="æœ‰ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’ŒåŠç›‘ç£å­¦ä¹ çš„åˆ†ç±»"><a href="#æœ‰ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’ŒåŠç›‘ç£å­¦ä¹ çš„åˆ†ç±»" class="headerlink" title="æœ‰ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’ŒåŠç›‘ç£å­¦ä¹ çš„åˆ†ç±»"></a>æœ‰ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’ŒåŠç›‘ç£å­¦ä¹ çš„åˆ†ç±»</h3><ul><li>ç›‘ç£å­¦ä¹ æ˜¯ä½¿ç”¨å·²çŸ¥æ­£ç¡®ç­”æ¡ˆçš„ç¤ºä¾‹æ¥è®­ç»ƒç½‘ç»œçš„ã€‚</li><li>æ— ç›‘ç£å­¦ä¹ é€‚ç”¨äºå…·æœ‰æ•°æ®é›†ä½†æ— æ ‡ç­¾çš„æƒ…å†µã€‚</li><li>åŠç›‘ç£å­¦ä¹ åœ¨è®­ç»ƒé˜¶æ®µç»“åˆäº†å¤§é‡æœªæ ‡è®°çš„æ•°æ®å’Œå°‘é‡æ ‡ç­¾æ•°æ®ã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> KGE </tag>
            
            <tag> KG </tag>
            
            <tag> GCN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linuxå®‰è£…nodejs&amp;å‡çº§</title>
      <link href="/2020/11/10/Linux%E5%AE%89%E8%A3%85nodejs&amp;%E5%8D%87%E7%BA%A7/"/>
      <url>/2020/11/10/Linux%E5%AE%89%E8%A3%85nodejs&amp;%E5%8D%87%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="Linuxå®‰è£…nodejs-amp-å‡çº§"><a href="#Linuxå®‰è£…nodejs-amp-å‡çº§" class="headerlink" title="Linuxå®‰è£…nodejs&amp;å‡çº§"></a>Linuxå®‰è£…nodejs&amp;å‡çº§</h1><h2 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h2><ol><li><p>å‘½ä»¤çª—å£</p><p><code>yum install nodejs</code></p></li><li><p>å®˜ç½‘ï¼ˆæ¨èï¼‰</p><p>å®˜ç½‘ï¼š<a href="https://nodes.org/en/">https://nodes.org/en/</a></p><p>a. ä¸‹è½½åè§£å‹ï¼š</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf node.tar.xz</span><br></pre></td></tr></table></figure><p>b. åˆ›å»ºè½¯è¿æ¥å…¨å±€è®¿é—®:</p><p>å¯æ‰§è¡Œæ–‡ä»¶ä½äº/binç›®å½•ä¸‹</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s å½“å‰è·¯å¾„/npm /usr/bin/npm</span><br><span class="line">ln -s å½“å‰è·¯å¾„/node /usr/bin/node</span><br></pre></td></tr></table></figure><p>c. æµ‹è¯•</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure></li></ol><h2 id="å‡çº§"><a href="#å‡çº§" class="headerlink" title="å‡çº§"></a>å‡çº§</h2><p><code>npm install n -g</code></p><p>å®‰è£…ç¨³å®šç‰ˆ</p><p><code>n stable</code></p><h2 id="éªŒè¯"><a href="#éªŒè¯" class="headerlink" title="éªŒè¯"></a>éªŒè¯</h2><p><code>node -v</code></p><p><code>npm -v</code></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201113162015.png" alt="image-20201113162015591"></p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos </tag>
            
            <tag> nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä½¿ç”¨Numpyå®ç°æœºå™¨å­¦ä¹ </title>
      <link href="/2020/11/08/%E4%BD%BF%E7%94%A8Numpy%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/11/08/%E4%BD%BF%E7%94%A8Numpy%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="ä½¿ç”¨Numpyå®ç°æœºå™¨å­¦ä¹ "><a href="#ä½¿ç”¨Numpyå®ç°æœºå™¨å­¦ä¹ " class="headerlink" title="ä½¿ç”¨Numpyå®ç°æœºå™¨å­¦ä¹ "></a>ä½¿ç”¨Numpyå®ç°æœºå™¨å­¦ä¹ </h1><p>è¡¨è¾¾å¼ï¼š$y=3x^2+2$</p><p>æ¨¡å‹ï¼š$y=wx^2+b$</p><p>æŸå¤±å‡½æ•°ï¼š$Loss=\frac{1}{2}\sum_{i=1}^{100}(wx^2_i+b-y_i)^2$</p><p>å¯¹æŸå¤±å‡½æ•°æ±‚å¯¼ï¼š<br>$\frac{\partial Loss}{\partial w}=\sum_{i=1}^{100}(wx^2_i+b-y_i)^2x^2_i$</p><p>$\frac{\partial Loss}{\partial b}=\sum_{i=1}^{100}(wx^2_i+b-y_i)^2$</p><p>åˆ©ç”¨æ¢¯åº¦ä¸‹é™æ³•å­¦ä¹ å‚æ•°ï¼Œå­¦ä¹ ç‡ä¸º:lr</p><p>$w_1-=lr*\frac{\partial Loss}{\partial w}$</p><p>$b_1-=lr*\frac{\partial Loss}{\partial b}$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h3 id="1-ç”Ÿæˆè®­ç»ƒæ•°æ®"><a href="#1-ç”Ÿæˆè®­ç»ƒæ•°æ®" class="headerlink" title="1.ç”Ÿæˆè®­ç»ƒæ•°æ®"></a>1.ç”Ÿæˆè®­ç»ƒæ•°æ®</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#è®¾ç½®éšæœºç§å­ï¼Œç”ŸæˆåŒä¸€ä»½æ•°æ®</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">100</span>).reshape(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># yåœ¨çœŸå®å€¼ä¸Šå¢åŠ å™ªå£°</span></span><br><span class="line">y = <span class="number">3</span>*np.power(x, <span class="number">2</span>)+<span class="number">2</span>+<span class="number">0.2</span>*np.random.rand(x.size).reshape(<span class="number">100</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="2-æŸ¥çœ‹x-yåˆ†å¸ƒ"><a href="#2-æŸ¥çœ‹x-yåˆ†å¸ƒ" class="headerlink" title="2.æŸ¥çœ‹x,yåˆ†å¸ƒ"></a>2.æŸ¥çœ‹x,yåˆ†å¸ƒ</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201114102842.png" alt="png"></p><h3 id="3-åˆå§‹åŒ–æƒé‡å‚æ•°"><a href="#3-åˆå§‹åŒ–æƒé‡å‚æ•°" class="headerlink" title="3.åˆå§‹åŒ–æƒé‡å‚æ•°"></a>3.åˆå§‹åŒ–æƒé‡å‚æ•°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># éšå³åˆå§‹åŒ–å‚æ•°</span></span><br><span class="line">w1 = np.random.rand(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">b1 = np.random.rand(<span class="number">1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="4-æ±‚è§£æ¨¡å‹"><a href="#4-æ±‚è§£æ¨¡å‹" class="headerlink" title="4.æ±‚è§£æ¨¡å‹"></a>4.æ±‚è§£æ¨¡å‹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.001</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">800</span>):</span><br><span class="line">    <span class="comment"># å‰å‘ä¼ æ’­</span></span><br><span class="line">    y_pred = np.power(x, <span class="number">2</span>)*w1+b1</span><br><span class="line">    <span class="comment"># å®šä¹‰æŸå¤±å‡½æ•°</span></span><br><span class="line">    loss = <span class="number">0.5</span> * (y_pred-y)**<span class="number">2</span></span><br><span class="line">    <span class="comment"># print(loss)</span></span><br><span class="line">    <span class="comment"># å¯¹å„ç»´åº¦æ±‚å’Œ</span></span><br><span class="line">    loss = loss.<span class="built_in">sum</span>()</span><br><span class="line">    <span class="comment"># è®¡ç®—æ¢¯åº¦(æ±‚å¯¼)</span></span><br><span class="line">    grad_w = np.<span class="built_in">sum</span>((y_pred-y)*np.power(x, <span class="number">2</span>))</span><br><span class="line">    grad_b = np.<span class="built_in">sum</span>((y_pred-y))</span><br><span class="line">    <span class="comment"># ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼Œä½¿å¾—lossæœ€å°</span></span><br><span class="line">    w1 -= lr*grad_w</span><br><span class="line">    b1 -= lr*grad_b</span><br></pre></td></tr></table></figure><h3 id="5-ç»“æœå¯è§†åŒ–"><a href="#5-ç»“æœå¯è§†åŒ–" class="headerlink" title="5.ç»“æœå¯è§†åŒ–"></a>5.ç»“æœå¯è§†åŒ–</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y_pred, <span class="string">&#x27;r-&#x27;</span>, label=<span class="string">&#x27;predict&#x27;</span>)</span><br><span class="line">plt.scatter(x, y, color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;true&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">2</span>, <span class="number">6</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># é¢„æµ‹å€¼</span></span><br><span class="line"><span class="built_in">print</span>(w1, b1)</span><br></pre></td></tr></table></figure><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201114102850.png" alt="png"></p><pre><code>[[2.98927619]] [[2.09818307]]</code></pre>]]></content>
      
      
      <categories>
          
          <category> æœºå™¨å­¦ä¹  </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> Numpy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç”¨tensorboardXå¯è§†åŒ–ç¥ç»ç½‘ç»œ</title>
      <link href="/2020/11/08/%E7%94%A8tensorboardX%E5%8F%AF%E8%A7%86%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/11/08/%E7%94%A8tensorboardX%E5%8F%AF%E8%A7%86%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="ç”¨tensorboardXå¯è§†åŒ–ç¥ç»ç½‘ç»œ"><a href="#ç”¨tensorboardXå¯è§†åŒ–ç¥ç»ç½‘ç»œ" class="headerlink" title="ç”¨tensorboardXå¯è§†åŒ–ç¥ç»ç½‘ç»œ"></a>ç”¨tensorboardXå¯è§†åŒ–ç¥ç»ç½‘ç»œ</h1><p>å®‰è£…ï¼š<code>pip install tensorboardX</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;runs/scalar_example&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;quadratic&#x27;</span>, i**<span class="number">2</span>, global_step=i)</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;exponential&#x27;</span>, <span class="number">2</span>**i, global_step=i)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">writer = SummaryWriter(<span class="string">&#x27;runs/another_scalar_example&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;quadratic&#x27;</span>, i**<span class="number">3</span>, global_step=i)</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;exponential&#x27;</span>, <span class="number">3</span>**i, global_step=i)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="1-å¯åŠ¨tensorboardæœåŠ¡"><a href="#1-å¯åŠ¨tensorboardæœåŠ¡" class="headerlink" title="1.å¯åŠ¨tensorboardæœåŠ¡"></a>1.å¯åŠ¨tensorboardæœåŠ¡</h2><ul><li>cdåˆ°runsç›®å½•æ‰€åœ¨çš„åŒçº§ç›®å½•ï¼Œåœ¨å‘½ä»¤è¡Œè¾“å…¥å¦‚ä¸‹å‘½ä»¤ï¼Œlogdirç­‰å¼å³è¾¹å¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ã€‚<br><code>tensorboard --logdir=runs --port 6006</code></li></ul><h2 id="2-webå±•ç¤º"><a href="#2-webå±•ç¤º" class="headerlink" title="2.webå±•ç¤º"></a>2.webå±•ç¤º</h2><ul><li><a href="http://localhost:6006/">http://localhost:6006/</a></li></ul><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201115115708.png" alt="image-20201115115702543"></p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> å·¥å…· </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jupyter Notebook å®ç°ä»£ç æç¤ºè‡ªåŠ¨è¡¥å…¨å’Œä»£ç æ ¼å¼åŒ–</title>
      <link href="/2020/11/06/jupyter_%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/11/06/jupyter_%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="Jupyter-Notebook-å®ç°ä»£ç æç¤ºè‡ªåŠ¨è¡¥å…¨å’Œä»£ç æ ¼å¼åŒ–"><a href="#Jupyter-Notebook-å®ç°ä»£ç æç¤ºè‡ªåŠ¨è¡¥å…¨å’Œä»£ç æ ¼å¼åŒ–" class="headerlink" title="Jupyter Notebook å®ç°ä»£ç æç¤ºè‡ªåŠ¨è¡¥å…¨å’Œä»£ç æ ¼å¼åŒ–"></a>Jupyter Notebook å®ç°ä»£ç æç¤ºè‡ªåŠ¨è¡¥å…¨å’Œä»£ç æ ¼å¼åŒ–</h1><h2 id="å®‰è£…æ’ä»¶nbextensions"><a href="#å®‰è£…æ’ä»¶nbextensions" class="headerlink" title="å®‰è£…æ’ä»¶nbextensions"></a>å®‰è£…æ’ä»¶nbextensions</h2><h3 id="1-å®‰è£…jupyter-contrib-nbextensions"><a href="#1-å®‰è£…jupyter-contrib-nbextensions" class="headerlink" title="1.å®‰è£…jupyter_contrib_nbextensions"></a>1.å®‰è£…jupyter_contrib_nbextensions</h3><p><code>pip install --user jupyter_contrib_nbextensions -i https://pypi.mirrors.ustc.edu.cn/simple</code></p><p><code>jupyter contrib nbextension install --user</code></p><h3 id="2-å®‰è£…nbextensions-configurator"><a href="#2-å®‰è£…nbextensions-configurator" class="headerlink" title="2.å®‰è£…nbextensions_configurator"></a>2.å®‰è£…nbextensions_configurator</h3><p><code>pip install --user jupyter_nbextensions_configurator</code><br><code>jupyter nbextensions_configurator enable --user</code></p><p>å¦‚æœå‡ºé”™æç¤º<code>â€œException: Jupyter command jupyter-contrib not found.â€</code></p><ul><li>åˆ™ä½¿ç”¨condaå¼ºåˆ¶å®‰è£…ï¼Œ<code>conda install -c conda-forge jupyter_nbextensions_configurator</code></li></ul><h2 id="é…ç½®"><a href="#é…ç½®" class="headerlink" title="é…ç½®"></a>é…ç½®</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201113101420.png" alt="image-20201113101420701"></p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> é…ç½® </tag>
            
            <tag> Jupyter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HOLE</title>
      <link href="/2020/11/05/HOLE/"/>
      <url>/2020/11/05/HOLE/</url>
      
        <content type="html"><![CDATA[<h1 id="HOLE"><a href="#HOLE" class="headerlink" title="HOLE"></a>HOLE</h1><blockquote><p>Holographic Embeddings of Knowledge Graphs</p><p>åŸºäºå‘é‡çš„å¾ªç¯ç›¸å…³</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><ul><li>æå‡ºå…¨æ¯åµŒå…¥(holographic embeddingsï¼ŒHOLE)æ¥å­¦ä¹ æ•´ä¸ªçŸ¥è¯†å›¾çš„ç»„æˆå‘é‡ç©ºé—´è¡¨ç¤ºã€‚</li><li>åœ¨ç»„åˆå‘é‡ç©ºé—´æ¨¡å‹çš„æ¡†æ¶å†…ç ”ç©¶ä»çŸ¥è¯†å›¾è°±å­¦ä¹ çš„é—®é¢˜ã€‚</li></ul><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><h3 id="compositional-vector-space-models"><a href="#compositional-vector-space-models" class="headerlink" title="compositional vector space models"></a>compositional vector space models</h3><ol><li><strong>ç»„åˆå‘é‡ç©ºé—´æ¨¡å‹</strong></li></ol><script type="math/tex; mode=display">Pr(\phi_p(s,o)=1|\Theta)=\sigma(\eta_{spo})=\sigma(\mathbf{r}_p^T(\mathbf{e}_sâ—¦\mathbf{e}_o))</script><blockquote><p><script type="math/tex">\phi_p(s,o)</script>ï¼šç‰¹å¾å‡½æ•°</p><p>â—¦ ï¼šå¤åˆç®—å­ï¼Œä»åµŒå…¥$\mathbf{e}_s$ï¼Œ$\mathbf{e}_o$åˆ›å»º$ï¼ˆsï¼Œoï¼‰$çš„å¤åˆå‘é‡è¡¨ç¤ºã€‚</p></blockquote><ol><li><strong>é€šè¿‡æœ€å¤§é™åº¦åœ°å‡å°‘ï¼ˆæ­£åˆ™åŒ–ï¼‰logisticæŸå¤±æ¥å®ç°æœ€å¥½åœ°è§£é‡Šæ•°æ®é›†çš„å®ä½“å’Œå…³ç³»çš„è¡¨ç¤ºã€‚</strong></li></ol><script type="math/tex; mode=display">\min\sum_{i=1}^mlog(1+exp(-y_i\eta_i))+\lambda||\Theta||_2^2</script><blockquote><p>å¯¹äºå…³ç³»æ•°æ®ï¼Œæœ€å°åŒ– logistic æŸå¤±å…·æœ‰é¢å¤–çš„ä¼˜åŠ¿ï¼Œå®ƒå¯ä»¥å¸®åŠ©ä¸ºå¤æ‚çš„å…³ç³»æ¨¡å¼æ‰¾åˆ°ä½ç»´çš„åµŒå…¥ã€‚</p></blockquote><ol><li><strong>KGsåªå­˜å‚¨æ­£ç¡®ä¸‰å…ƒç»„ï¼Œè¿™ç§æƒ…å†µä¸‹å¯ä»¥ä½¿ç”¨ pairwise ranking lossã€‚</strong></li></ol><script type="math/tex; mode=display">\min_\Theta\sum_{i\in{D_+}}\sum_{j\in{D_-}}\max(0,\gamma+\sigma(\eta_j)-\sigma(\eta_i))</script><blockquote><p>ä¾‹å¦‚å°†ç°æœ‰ä¸‰å…ƒç»„çš„æ¦‚ç‡æ’åºä¸ºé«˜äºä¸å­˜åœ¨ä¸‰å…ƒç»„çš„æ¦‚ç‡ã€‚</p><p>d+ï¼Œdâˆ’ï¼šè¡¨ç¤ºå­˜åœ¨å’Œä¸å­˜åœ¨çš„ä¸‰å…ƒç»„çš„é›†åˆã€‚</p><p>$\eta_j&gt;0$ï¼šæŒ‡å®šè¾¹è·çš„å®½åº¦ã€‚</p></blockquote><h3 id="Holographic-Embeddings-HOLE"><a href="#Holographic-Embeddings-HOLE" class="headerlink" title="Holographic Embeddings(HOLE)"></a>Holographic Embeddings(HOLE)</h3><blockquote><p>ä¸ºäº†å°†å¼ é‡ç§¯çš„è¡¨è¾¾èƒ½åŠ›ä¸TransEçš„æ•ˆç‡å’Œç®€å•æ€§ç»“åˆèµ·æ¥ï¼Œä½¿ç”¨å‘é‡çš„å¾ªç¯ç›¸å…³æ¥è¡¨ç¤ºå®ä½“å¯¹ã€‚</p><p>åœ¨HOLEä¸­ï¼Œä¸åªæ˜¯å­˜å‚¨å…³è”ï¼Œè€Œæ˜¯å­¦ä¹ èƒ½æœ€å¥½åœ°è§£é‡Šæ‰€è§‚å¯Ÿåˆ°æ•°æ®çš„åµŒå…¥ã€‚</p></blockquote><pre><code>1. å¤åˆç®—å­</code></pre><script type="math/tex; mode=display">aâ—¦b=a\ast b</script><blockquote><p>$\mathbf{*}$ï¼šè¡¨ç¤ºå¾ªç¯ç›¸å…³</p></blockquote><ol><li>ä¸‰å…ƒç»„çš„æ¦‚ç‡æ¨¡å‹</li></ol><script type="math/tex; mode=display">Pr(\phi_p(s,o)=1|\Theta)=\sigma(\mathbf{r}_p^T(\mathbf{e}_s\ast \mathbf{e}_o))</script><blockquote><p>ä½¿ç”¨å¤åˆç®—å­ç›¸å¯¹äºå·ç§¯çš„ä¼˜ç‚¹</p><ul><li>Non-commutativeï¼šå¯¹å»ºæ¨¡æœ‰å‘å›¾çš„éå¯¹ç§°æ€§å¾ˆæœ‰å¿…è¦ã€‚</li><li>Similiarity Componentï¼šå¯¹å®ä½“ç›¸ä¼¼æ€§çš„å…³ç³»å»ºæ¨¡æœ‰å¸®åŠ©ã€‚</li></ul></blockquote><ol><li><p>SGD</p><blockquote><p>ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™</p></blockquote></li></ol><script type="math/tex; mode=display">\mathbf{e}_o^{t+1}\leftarrow\mathbf{e}_o^{t}-\mu\frac{\partial L}{\partial f}\frac{\partial f}{\partial \eta}(\mathbf{r}_p^t\ast e_s^t)</script><blockquote><p>$\mu$ï¼šå­¦ä¹ ç‡</p></blockquote><ol><li>æ–¹æ³•</li></ol><ul><li><p>æŠŠå®ä½“å’Œå…³ç³»éƒ½è¡¨ç¤ºä¸ºå‘é‡ã€‚ç»™å®šä¸€ä¸ªäº‹å®$(h,r,t)$ï¼Œé¦–å…ˆä½¿ç”¨å¾ªç¯ç›¸å…³æ“ä½œå°†å®ä½“è¡¨ç¤ºå½¢å¼ç»„æˆ$h*tâˆˆR$ã€‚</p></li><li><p>ç„¶åå°†ç»„åˆå‘é‡ä¸å…³ç³»è¡¨ç¤ºå½¢å¼åŒ¹é…ï¼Œä»¥å¯¹äº‹å®è¿›è¡Œè¯„åˆ†ã€‚</p></li></ul><h2 id="æ•°æ®é›†"><a href="#æ•°æ®é›†" class="headerlink" title="æ•°æ®é›†"></a>æ•°æ®é›†</h2><ul><li>WN18</li><li>FB15K</li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><blockquote><p> å…¬å¹³èµ·è§ï¼Œè¯„ä»·æ—¶ä½¿ç”¨ç›¸åŒçš„æŸå¤±å’Œä¼˜åŒ–æ–¹æ³•å¯¹å‚ä¸æ¯”è¾ƒçš„æ¨¡å‹é‡æ–°è®­ç»ƒã€‚</p></blockquote><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201020191901057.png" alt="image-20201020191901057"></p><blockquote><p>Filterï¼šç”±äºå¯¹äºç»™å®šçš„ predicate-objectï¼Œæµ‹è¯•é›†ä¸­å¯ä»¥å­˜åœ¨å¤šä¸ªæ­£ç¡®çš„ä¸‰å…ƒç»„ï¼Œå› æ­¤ä»$R_pï¼ˆs^{â€˜},o)=1$ and $ s\neq s^{â€˜}$çš„æ’åºä¸­åˆ é™¤æ‰€æœ‰å®ä¾‹ï¼Œåªè€ƒè™‘æµ‹è¯•å®ä¾‹åœ¨æ‰€æœ‰é”™è¯¯å®ä¾‹ä¸­çš„æ’åºã€‚åŒç†ä»$R_pï¼ˆs,o^{â€˜})=1$ and $ o\neq o^{â€˜}$çš„æ’åºä¸­åˆ é™¤æ‰€æœ‰å®ä¾‹ã€‚</p></blockquote><ul><li>åœ¨WN18æ•°æ®é›†çš„æµ‹è¯•ä¸­ï¼ŒHOLEçš„è¡¨ç°éƒ½æœ€ä¸ºå‡ºè‰²ã€‚</li><li>åœ¨FB15kæ•°æ®é›†è¡¨ç°ä¹Ÿä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œä½†æ˜¯æ•ˆæœä¸æ˜¯å¾ˆæ˜¾è‘—ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201020193457298.png" alt="image-20201020193457298"></p><ul><li>ä¸Rescalç›¸æ¯”ï¼ŒHOLEçš„å‚æ•°å‡å°‘å¾ˆå¤šã€‚å°½ç®¡embeddingçš„ç»´æ•°dæ¯”rescalçš„å¤§ï¼Œä½†ç”±äºå…¶å­˜å‚¨å¤æ‚åº¦ä»…çº¿æ€§åœ°ä¾èµ–äºdï¼Œæ‰€ä»¥æ€»ä½“å‚æ•°æ•°ç›®æ˜¾è‘—å‡å°‘ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201020193748054.png" alt="image-20201020193748054"></p><blockquote><p>$locatedIn(c,r)$ï¼šcï¼šcountries(å›½å®¶)ï¼Œrï¼šregions(åœ°åŒº)ã€‚</p><p>$locatedIn(c,s)$ï¼šsï¼šsubregions(æ¬¡åŒºåŸŸ)ã€‚</p></blockquote><ol><li><p>ä»»åŠ¡S1</p><p>è®¾ç½®ï¼šå¯¹äºtest/validä¸­ï¼Œåªå°†$locatedIn(c,r)$çš„countriesè®¾ç½®ä¸ºmissingã€‚</p><p>æ€§èƒ½ï¼šä¸¢å¤±çš„ä¸‰å…ƒç»„å‡ ä¹å¯ä»¥å®Œç¾é¢„æµ‹ã€‚</p></li><li><p>ä»»åŠ¡S2</p><p>è®¾ç½®ï¼šå°†$locatedIn(c,s)$ä¸­countrieså’Œsubregionsè®¾ç½®ä¸ºmissingã€‚</p><p>æ€§èƒ½ï¼šç›¸å¯¹äºå…¶ä»–æ•°æ®é›†è¡¨ç°æœ€å¥½ã€‚</p></li><li><p>ä»»åŠ¡S3</p><p>è®¾ç½®ï¼šå°†$locatedIn(n,r)$ä¸­countriesnçš„neighborsï¼Œregionsè®¾ç½®ä¸ºmissingã€‚</p><p>æ€§èƒ½ï¼šé¢„æµ‹éš¾åº¦æœ€å¤§ï¼Œä½†ç›¸å¯¹äºå…¶ä»–æ•°æ®é›†è¡¨ç°è¾ƒå¥½ã€‚</p></li></ol><blockquote><p>RESCALå’ŒER-MLPè¾ƒå·®çš„ç»“æœå¾ˆå¯èƒ½æ˜¯è¿‡æ‹Ÿåˆå¯¼è‡´ã€‚</p></blockquote><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><ul><li>HOLE å®ƒåˆ©ç”¨å‘é‡çš„å¾ªç¯ç›¸å…³æ€§æ¥åˆ›å»ºäºŒå…ƒå…³ç³»æ•°æ®çš„ç»„åˆè¡¨ç¤ºã€‚é€šè¿‡ä½¿ç”¨ç›¸å…³æ€§ä½œä¸ºç»„åˆç®—å­ï¼Œå¯ä»¥æ•è·ä¸°å¯Œçš„äº¤äº’ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆçš„è®¡ç®—ï¼Œæ˜“äºè®­ç»ƒï¼Œå¹¶å¯æ‰©å±•åˆ°éå¸¸å¤§çš„æ•°æ®é›†ã€‚</li><li>å¾ªç¯ç›¸å…³å¯¹æˆå¯¹çš„ç›¸äº’ä½œç”¨è¿›è¡Œå‹ç¼©ã€‚å› æ­¤ï¼ŒHolEå¯¹æ¯ä¸ªå…³ç³»åªéœ€è¦$O(d)$å‚æ•°ï¼Œå¹¶ä¸”å¾ªç¯ç›¸å…³æ˜¯ä¸ç¬¦åˆäº¤æ¢å¾‹çš„ï¼Œå³$h<em>t$ä¸ç­‰äº$t</em>h$ã€‚æ‰€ä»¥HolEèƒ½å¤Ÿ<strong>å¯¹ä¸å¯¹ç§°å…³ç³»è¿›è¡Œå»ºæ¨¡</strong>ã€‚</li></ul><h2 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h2><ol><li><strong>å¾ªç¯ç›¸å…³çš„ä¼˜åŠ¿ï¼š</strong></li></ol><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201020202711290.png" alt="image-20201020202711290"></p><ul><li>ä¸å¼ é‡ç§¯ç›¸æ¯”ï¼Œå¾ªç¯ç›¸å…³å…·æœ‰ä¸å¢åŠ å¤åˆè¡¨ç¤ºçš„ç»´æ•°çš„é‡è¦ä¼˜ç‚¹ã€‚</li><li>ç©ºé—´å¤æ‚åº¦åœ¨å®ä½“è¡¨ç¤ºçš„ç»´åº¦dä¸­æ˜¯çº¿æ€§çš„ï¼Œè¿è¡Œæ—¶å¤æ‚åº¦åœ¨dä¸­æ˜¯å¯¹æ•°çº¿æ€§çš„ã€‚å¯¹æ€»ä½“å‚æ•°çš„æ•°é‡å’Œè¿è¡Œæ•ˆç‡éƒ½æœ‰æ˜¾è‘—å½±å“ã€‚</li><li>ç»„åˆè¡¨ç¤ºä¸å…¶æ„æˆçš„è¡¨ç¤ºå…·æœ‰ç›¸åŒçš„ç»´æ•°ã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> KGE </tag>
            
            <tag> KG </tag>
            
            <tag> HOLE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorchè‡ªåŠ¨æ±‚å¯¼</title>
      <link href="/2020/11/03/PyTorch%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/"/>
      <url>/2020/11/03/PyTorch%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<h1 id="æ ‡é‡åå‘ä¼ æ’­"><a href="#æ ‡é‡åå‘ä¼ æ’­" class="headerlink" title="æ ‡é‡åå‘ä¼ æ’­"></a>æ ‡é‡åå‘ä¼ æ’­</h1><blockquote><p>å½“ç›®æ ‡å¼ é‡ä¸ºæ ‡é‡æ—¶ï¼Œbackward()æ— éœ€ä¼ å…¥å‚æ•°ã€‚</p></blockquote><ul><li>ä¾‹å­ï¼šå‡è®¾$w,x,b$éƒ½æ˜¯æ ‡é‡ï¼Œ$z=wx+b$ ï¼Œå¯¹æ ‡é‡$z$è°ƒç”¨backward()æ–¹æ³•ã€‚</li></ul><h2 id="è‡ªåŠ¨æ±‚å¯¼çš„ä¸»è¦æ­¥éª¤"><a href="#è‡ªåŠ¨æ±‚å¯¼çš„ä¸»è¦æ­¥éª¤" class="headerlink" title="è‡ªåŠ¨æ±‚å¯¼çš„ä¸»è¦æ­¥éª¤"></a>è‡ªåŠ¨æ±‚å¯¼çš„ä¸»è¦æ­¥éª¤</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure><h3 id="1-å®šä¹‰å¶å­ç»“ç‚¹ï¼Œç®—å­èŠ‚ç‚¹"><a href="#1-å®šä¹‰å¶å­ç»“ç‚¹ï¼Œç®—å­èŠ‚ç‚¹" class="headerlink" title="1.å®šä¹‰å¶å­ç»“ç‚¹ï¼Œç®—å­èŠ‚ç‚¹"></a>1.å®šä¹‰å¶å­ç»“ç‚¹ï¼Œç®—å­èŠ‚ç‚¹</h3><blockquote><p>å¦‚æœéœ€è¦å¯¹Tensoræ±‚å¯¼ï¼Œrequires_gradè¦è®¾ç½®ä¸ºTrueã€‚</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰è¾“å…¥å¼ é‡x</span></span><br><span class="line">x = torch.Tensor([<span class="number">2</span>])</span><br><span class="line"><span class="comment"># åˆå§‹åŒ–æƒé‡å‚æ•°w,åç½®b,#è®¾ç½®requires_gradä¸ºTrueï¼Œä½¿ç”¨è‡ªåŠ¨æ±‚å¯¼</span></span><br><span class="line">w = torch.randn(<span class="number">1</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.randn(<span class="number">1</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># è®¾ç½®å‰å‘ä¼ æ’­</span></span><br><span class="line">y = torch.mul(w,x)</span><br><span class="line">z = torch.add(y,b)</span><br><span class="line"><span class="comment"># æŸ¥çœ‹requires_gradå±æ€§</span></span><br><span class="line"><span class="built_in">print</span>(x.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(y.requires_grad)</span><br><span class="line"><span class="comment"># å› ä¸ºä¸w,bå…·æœ‰yä¾èµ–å…³ç³»ï¼Œæ‰€ä»¥x,yçš„requires_gradä¹Ÿæ˜¯Trueã€‚</span></span><br></pre></td></tr></table></figure><pre><code>FalseTrue</code></pre><h3 id="2-æŸ¥çœ‹å¶å­ç»“ç‚¹ï¼Œéå¶å­ç»“ç‚¹çš„å…¶ä»–å±æ€§"><a href="#2-æŸ¥çœ‹å¶å­ç»“ç‚¹ï¼Œéå¶å­ç»“ç‚¹çš„å…¶ä»–å±æ€§" class="headerlink" title="2.æŸ¥çœ‹å¶å­ç»“ç‚¹ï¼Œéå¶å­ç»“ç‚¹çš„å…¶ä»–å±æ€§"></a>2.æŸ¥çœ‹å¶å­ç»“ç‚¹ï¼Œéå¶å­ç»“ç‚¹çš„å…¶ä»–å±æ€§</h3><ul><li>grad_fn:è¡¨ç¤ºæ¢¯åº¦å‡½æ•°<blockquote><p>é€šè¿‡è¿ç®—åˆ›å»ºçš„Tensor(éå¶å­ç»“ç‚¹)ä¼šè‡ªåŠ¨è¢«èµ‹äºˆgrad_fnå±æ€§ã€‚<br>å¶å­ç»“ç‚¹çš„grad_fnä¸ºNoneã€‚</p></blockquote></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æŸ¥çœ‹éå¶å­ç»“ç‚¹y,zçš„requires_gradå±æ€§ã€‚</span></span><br><span class="line"><span class="built_in">print</span>(y.requires_grad)</span><br><span class="line"><span class="comment"># æŸ¥çœ‹å„èŠ‚ç‚¹æ˜¯ä¸æ˜¯å¶å­èŠ‚ç‚¹</span></span><br><span class="line"><span class="built_in">print</span>(x.is_leaf)</span><br><span class="line"><span class="built_in">print</span>(y.is_leaf)</span><br><span class="line"><span class="comment"># å¶å­ç»“ç‚¹ï¼šx,w,b</span></span><br><span class="line"><span class="comment"># éå¶å­ç»“ç‚¹ï¼šy,z</span></span><br><span class="line"><span class="comment"># æŸ¥çœ‹å¶å­ç»“ç‚¹çš„grad_fnå±æ€§</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;xçš„grad_fnå±æ€§ï¼š&quot;</span>,x.grad_fn)</span><br><span class="line"><span class="comment"># æŸ¥çœ‹éå¶å­ç»“ç‚¹çš„grad_fnå±æ€§</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;yçš„grad_fnå±æ€§ï¼š&quot;</span>,y.grad_fn)</span><br></pre></td></tr></table></figure><pre><code>TrueTrueFalsexçš„grad_fnå±æ€§ï¼š Noneyçš„grad_fnå±æ€§ï¼š &lt;MulBackward0 object at 0x7fe83935dbb0&gt;</code></pre><h3 id="3-è‡ªåŠ¨æ±‚å¯¼ï¼Œå®ç°æ¢¯åº¦åå‘ä¼ æ’­"><a href="#3-è‡ªåŠ¨æ±‚å¯¼ï¼Œå®ç°æ¢¯åº¦åå‘ä¼ æ’­" class="headerlink" title="3.è‡ªåŠ¨æ±‚å¯¼ï¼Œå®ç°æ¢¯åº¦åå‘ä¼ æ’­"></a>3.è‡ªåŠ¨æ±‚å¯¼ï¼Œå®ç°æ¢¯åº¦åå‘ä¼ æ’­</h3><blockquote><p>éå¶å­èŠ‚ç‚¹çš„æ¢¯åº¦è°ƒç”¨backward()ä¹‹åï¼Œæ¢¯åº¦å°†è¢«æ¸…ç©ºã€‚</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åŸºäºzå¯¹å¼ é‡è¿›è¡Œåå‘ä¼ æ’­ï¼Œæ‰§è¡Œbackwardä¹‹åè®¡ç®—å›¾ä¼šæ¸…ç©ºã€‚</span></span><br><span class="line">z.backward()</span><br><span class="line"><span class="comment"># å¦‚æœéœ€è¦å¤šæ¬¡backward()éœ€è¦è®¾ç½®å‚æ•°retain_graphä¸ºTrueã€‚æ­¤æ—¶æ¢¯åº¦æ˜¯ç´¯åŠ çš„ã€‚</span></span><br><span class="line"><span class="comment"># z.backward(retain_graph=True)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æŸ¥çœ‹å¶å­ç»“ç‚¹çš„æ¢¯åº¦ã€‚</span></span><br><span class="line"><span class="comment"># å› ä¸ºxæœªè®¾ç½®requires_gradå±æ€§,é»˜è®¤ä¸ºFalseï¼Œä¸æ±‚å¯¼ï¼Œæ‰€ä»¥gradä¸ºNoneã€‚</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;xçš„æ¢¯åº¦æ˜¯ï¼š&quot;</span>,x.grad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;wçš„æ¢¯åº¦æ˜¯ï¼š&quot;</span>,w.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æŸ¥çœ‹éå¶å­ç»“ç‚¹çš„æ¢¯åº¦</span></span><br><span class="line"><span class="comment"># éå¶å­èŠ‚ç‚¹çš„æ¢¯åº¦è°ƒç”¨backward()ä¹‹åï¼Œæ¢¯åº¦å°†è¢«æ¸…ç©ºã€‚æ•…y,zæ­¤æ—¶æ²¡æœ‰æ¢¯åº¦ã€‚</span></span><br><span class="line"><span class="comment"># print(&quot;yçš„æ¢¯åº¦æ˜¯ï¼š&quot;,y.grad)</span></span><br><span class="line"><span class="comment"># print(&quot;zçš„æ¢¯åº¦æ˜¯ï¼š&quot;,z.grad)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>xçš„æ¢¯åº¦æ˜¯ï¼š Nonewçš„æ¢¯åº¦æ˜¯ï¼š tensor([2.])</code></pre><h1 id="éæ ‡é‡åå‘ä¼ æ’­"><a href="#éæ ‡é‡åå‘ä¼ æ’­" class="headerlink" title="éæ ‡é‡åå‘ä¼ æ’­"></a>éæ ‡é‡åå‘ä¼ æ’­</h1><blockquote><p>Pytorchåªå…è®¸æ ‡é‡å¯¹å¼ é‡è¿›è¡Œæ±‚å¯¼</p></blockquote><h2 id="æ­¥éª¤"><a href="#æ­¥éª¤" class="headerlink" title="æ­¥éª¤"></a>æ­¥éª¤</h2><h3 id="1-å®šä¹‰å¶å­ç»“ç‚¹ï¼Œè®¡ç®—ç»“ç‚¹"><a href="#1-å®šä¹‰å¶å­ç»“ç‚¹ï¼Œè®¡ç®—ç»“ç‚¹" class="headerlink" title="1.å®šä¹‰å¶å­ç»“ç‚¹ï¼Œè®¡ç®—ç»“ç‚¹"></a>1.å®šä¹‰å¶å­ç»“ç‚¹ï¼Œè®¡ç®—ç»“ç‚¹</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰å¶å­å¼ é‡xï¼Œå½¢çŠ¶ä¸º1x2</span></span><br><span class="line">x = torch.tensor([[<span class="number">2</span>,<span class="number">3</span>]],dtype=torch.<span class="built_in">float</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># åˆå§‹åŒ–é›…å¯æ¯”çŸ©é˜µ</span></span><br><span class="line">J = torch.zeros(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(J[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># åˆå§‹åŒ–ç›®æ ‡å¼ é‡ï¼Œå½¢çŠ¶ä¸º1x2</span></span><br><span class="line">y = torch.zeros(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># å®šä¹‰yä¸xä¹‹é—´çš„æ˜ å°„å…³ç³»</span></span><br><span class="line"><span class="comment"># y1 = x1**2+3*x2</span></span><br><span class="line"><span class="comment"># y2 = x2**2+2*x1</span></span><br><span class="line">y[<span class="number">0</span>,<span class="number">0</span>]=x[<span class="number">0</span>,<span class="number">0</span>]**<span class="number">2</span>+<span class="number">3</span>*x[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">y[<span class="number">0</span>,<span class="number">1</span>]=x[<span class="number">0</span>,<span class="number">1</span>]**<span class="number">2</span>+<span class="number">2</span>*x[<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><pre><code>tensor([[2., 3.]], requires_grad=True)tensor([0., 0.])tensor([[13., 13.]], grad_fn=&lt;CopySlices&gt;)</code></pre><h3 id="2-è°ƒç”¨backward-è·å–yå¯¹xçš„æ¢¯åº¦"><a href="#2-è°ƒç”¨backward-è·å–yå¯¹xçš„æ¢¯åº¦" class="headerlink" title="2.è°ƒç”¨backward()è·å–yå¯¹xçš„æ¢¯åº¦"></a>2.è°ƒç”¨backward()è·å–yå¯¹xçš„æ¢¯åº¦</h3><blockquote><p>éœ€è¦é‡å¤ä½¿ç”¨backward()æ—¶,retain_graph=True</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç”Ÿæˆy1å¯¹xçš„æ¢¯åº¦</span></span><br><span class="line">y.backward(torch.Tensor([[<span class="number">1</span>,<span class="number">0</span>]]),retain_graph=<span class="literal">True</span>)</span><br><span class="line">J[<span class="number">0</span>]=x.grad</span><br><span class="line"><span class="comment"># å› ä¸ºæ¢¯åº¦æ˜¯ç´¯åŠ çš„ï¼Œæ‰€ä»¥éœ€è¦æ¸…é™¤å¯¹xçš„æ¢¯åº¦</span></span><br><span class="line">x.grad = torch.zeros_like(x.grad)</span><br><span class="line"><span class="comment"># ç”Ÿæˆy2å¯¹xçš„æ¢¯åº¦</span></span><br><span class="line">y.backward(torch.Tensor([[<span class="number">0</span>,<span class="number">1</span>]]))</span><br><span class="line">J[<span class="number">1</span>]=x.grad</span><br><span class="line"><span class="comment"># é›…å¯æ¯”çŸ©é˜µçš„å€¼</span></span><br><span class="line"><span class="built_in">print</span>(J)</span><br></pre></td></tr></table></figure><pre><code>tensor([[4., 3.],        [2., 6.]])</code></pre>]]></content>
      
      
      <categories>
          
          <category> PyTorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TransE</title>
      <link href="/2020/10/29/TransE/"/>
      <url>/2020/10/29/TransE/</url>
      
        <content type="html"><![CDATA[<h1 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h1><blockquote><p> ã€ŠTranslating Embeddings for Modeling Multi-relational Dataã€‹</p></blockquote><h2 id="ä»»åŠ¡"><a href="#ä»»åŠ¡" class="headerlink" title="ä»»åŠ¡"></a>ä»»åŠ¡</h2><ul><li><strong>åœ¨ä½ç»´å‘é‡ç©ºé—´ä¸­ï¼Œå°†å¤šç§å…³ç³»çš„å›¾è°±ä¸­çš„å®ä½“å’Œå…³ç³»åœ¨ä¸€ä¸ªä½ç»´ç©ºé—´ä¸­è¿›è¡Œè¡¨ç¤ºï¼Œè·å¾—æ¯ä¸ªå®ä½“çš„è¡¨å¾ç»“æœã€‚</strong></li><li><strong>æå‡ºä¸€ç§æ˜“äºè®­ç»ƒçš„è§„èŒƒæ¨¡å‹ï¼Œè¯¥æ¨¡å‹åŒ…å«æ•°é‡è¾ƒå°‘çš„å‚æ•°ï¼Œå¹¶ä¸”å¯ä»¥æ‰©å±•åˆ°éå¸¸å¤§çš„çŸ¥è¯†åº“ã€‚</strong></li><li><strong>å¯¹çŸ¥è¯†å›¾è°±ä¸­çš„å¤šå…ƒå…³ç³»æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼Œåœ¨ä¸å¼•å…¥é¢å¤–çŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œé«˜æ•ˆçš„å®ç°çŸ¥è¯†è¡¥å…¨ï¼Œå…³ç³»é¢„æµ‹ã€‚</strong></li></ul><h2 id="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"><a href="#æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰" class="headerlink" title="æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰"></a>æ–¹æ³•ï¼ˆæ¨¡å‹ï¼‰</h2><p><strong>TransEï¼šåŸºäºèƒ½é‡çš„æ¨¡å‹ï¼Œç”¨äºå­¦ä¹ å®ä½“çš„ä½ç»´åµŒå…¥ã€‚</strong></p><ol><li><p>å…³ç³»ä½œä¸ºå‘é‡ç©ºé—´è½¬å˜çš„æ¡¥æ¢ï¼šå¦‚æœä¸‰å…ƒç»„<code>(h,l,t)</code>æˆç«‹ï¼Œåˆ™å¤´å®ä½“embeddingå’Œå…³ç³»embeddingç›¸åŠ çº¦ç­‰äºå°¾å®ä½“çš„embeddingã€‚</p><blockquote><p>$h+l â‰ˆ t$</p></blockquote></li><li><p>åˆ©ç”¨ç©ºé—´ä¼ é€’ä¸å˜å½¢ï¼Œæ‰¾åˆ°ä¸€ä¸ªå®ä½“å’Œå‘é‡ç©ºé—´ï¼Œä½¿å¾—æ•´å…³ç³»ä¸‰å…ƒç»„ä¹‹é—´çš„åŠ¿èƒ½å·®å€¼æœ€å°ã€‚</p><blockquote><p>$min(t âˆ’ ( h + l ))$</p></blockquote></li><li><p>æ¨¡å‹</p></li></ol><ul><li><p>ç»™å®šä¸€ä¸ªè®­ç»ƒé›† S ï¼Œä¸‰å…ƒç»„è¡¨ç¤ºä¸º $( h , l , t )$ï¼Œå…¶ä¸­ $h , t âˆˆ E ,l âˆˆ L$ ï¼Œå®ä½“å’Œå…³ç³»çš„åµŒå…¥ç»´åº¦è®¾ä¸º kï¼Œå¸Œæœ› $h + l$ ä¸ $t$èƒ½å¤Ÿå°½å¯èƒ½çš„ç›¸ä¼¼ï¼Œå› æ­¤å®šä¹‰ä¸€ä¸ªèƒ½é‡å‡½æ•°ï¼š</p><p>$d ( h + l , t ) = [ ( h + l ) âˆ’ t ]^2 = âˆ£âˆ£hâˆ£âˆ£^2_2 + âˆ£âˆ£ l âˆ£âˆ£^2_2 + âˆ£ âˆ£ t âˆ£ âˆ£_2^2 âˆ’ 2 ( h^T t + l^ T ( t âˆ’ h ) ) $</p><blockquote><p>æ¬§å¼è·ç¦»</p></blockquote></li><li><p>ä¸ºäº†è®­ç»ƒå®ä½“embeddingå’Œå…³ç³»embeddingï¼Œéœ€è¦å¼•å…¥è´Ÿæ ·æœ¬ã€‚ç›®æ ‡æ˜¯å°½å¯èƒ½å¯¹æ­£æ ·æœ¬ä¸­æœ€å°åŒ– $d ( h + l , t )$ ï¼Œè´Ÿæ ·æœ¬ä¸­åˆ™å°½å¯èƒ½æœ€å¤§åŒ–$d ( h â€² + l , t â€² )$ $ã€‚hâ€™,tâ€™$ è¡¨ç¤ºä¸å±äºæŸä¸ªä¸‰å…ƒç»„çš„å®ä½“ã€‚å› æ­¤å¯ä»¥å¾—å‡ºåŸºäºé—´è·æ’åºæ ‡å‡†ç›®æ ‡ä¼˜åŒ–å‡½æ•°ï¼ˆ<strong>æŸå¤±å‡½æ•°</strong>ï¼‰ï¼š</p><p>$L=\sum<em>{(h,â„“,t)âˆˆS}\sum</em>{(hâ€²,â„“,tâ€²)âˆˆS<em>{(h,â„“,t)}^â€²}[Î³+d(h+â„“,t)âˆ’d(hâ€²+â„“,tâ€²)]</em>+$</p><blockquote><p>å…¶ä¸­ $[x]_+$è¡¨ç¤º $x$ ä¸­æ­£ä¾‹çš„éƒ¨åˆ†ï¼Œ$Î³ &gt; 0$ è¡¨ç¤ºè·ç¦»å› å­ã€‚</p><p>é€šè¿‡æœ€å°åŒ–æ­£æ ·æœ¬çš„æŸå¤±ï¼Œæœ€å¤§åŒ–è´Ÿæ ·æœ¬çš„è·ç¦»ï¼Œè¾¾åˆ°ä¼˜åŒ–åµŒå…¥è¡¨ç¤ºçš„ç›®çš„ã€‚</p></blockquote></li><li><p>é”™è¯¯ä¸‰å…ƒç»„ç”Ÿæˆï¼šå°†æ­£ç¡®ä¸‰å…ƒç»„çš„å¤´æˆ–è€…å°¾æ›¿æ¢æˆå…¶ä»–çš„ï¼ˆæ¯æ¬¡åªèƒ½é€‰æ‹©å¤´æˆ–è€…å°¾è¿›è¡Œæ›¿æ¢ï¼Œä¸åŒæ—¶æ›¿æ¢ï¼‰ï¼Œå¾—åˆ°é”™è¯¯çš„ä¸‰å…ƒç»„ã€‚</p><p>$S_{(h,l,t)}^â€²={(hâ€²,l,t)âˆ£hâ€²âˆˆE}âˆª{(h,l,tâ€²)âˆ£tâ€²âˆˆE}$</p></li></ul><h2 id="æµ‹è¯•æ•°æ®é›†"><a href="#æµ‹è¯•æ•°æ®é›†" class="headerlink" title="æµ‹è¯•æ•°æ®é›†"></a>æµ‹è¯•æ•°æ®é›†</h2><ul><li><p>FreeBase</p></li><li><p>WordNet</p><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201015110914232.png" alt="image-20201015110914232" style="zoom: 67%;" /></p></li></ul><h2 id="æ€§èƒ½æ°´å¹³"><a href="#æ€§èƒ½æ°´å¹³" class="headerlink" title="æ€§èƒ½æ°´å¹³"></a>æ€§èƒ½æ°´å¹³</h2><h3 id="é“¾æ¥é¢„æµ‹"><a href="#é“¾æ¥é¢„æµ‹" class="headerlink" title="é“¾æ¥é¢„æµ‹"></a>é“¾æ¥é¢„æµ‹</h3><h4 id="è¯„ä»·æ–¹æ³•"><a href="#è¯„ä»·æ–¹æ³•" class="headerlink" title="è¯„ä»·æ–¹æ³•"></a>è¯„ä»·æ–¹æ³•</h4><ul><li>å¯¹äºæ¯ä¸ªä¸‰å…ƒç»„ï¼Œéƒ½å°†å¤´éƒ¨ç§»é™¤å¹¶ä¾æ¬¡æ›¿æ¢ä¸ºå­—å…¸ä¸­çš„ä»»æ„ä¸€ä¸ªå®ä½“ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/iNIU4QHVtgja9xs.png" alt="image-20201014211344062"></p><ul><li><p>rawï¼šåŸå§‹æ•°æ®</p></li><li><p>filteredï¼šç§»é™¤é”™è¯¯ä¸‰å…ƒç»„</p><blockquote><p>æŸäº›é”™è¯¯çš„ä¸‰å…ƒç»„ä¼šå˜æˆæœ‰æ•ˆçš„ä¸‰å…ƒç»„ã€‚åœ¨æµ‹è¯•ä¸­ï¼Œå¯èƒ½ä¼šå‡ºç°æŸäº›é”™è¯¯ä¸‰å…ƒç»„æ’åºæ¯”æµ‹è¯•é›†ä¸‰å…ƒç»„é å‰çš„æƒ…å†µï¼Œä½†æ˜¯è¿™äº›ä¸‰å…ƒç»„éƒ½æ˜¯çœŸå®çš„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªç¼ºé™·å¯¹è¯„ä»·æŒ‡æ ‡å¸¦æ¥çš„å½±å“ï¼Œä»æ•°æ®é›†ä¸­åˆ é™¤é”™è¯¯çš„ä¸‰å…ƒç»„ã€‚</p></blockquote></li></ul><h4 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h4><p>â€‹    <strong>åœ¨åŸå§‹æ•°æ®é›†å’Œå»é™¤é”™è¯¯çš„ä¸‰å…ƒç»„ä¹‹åçš„æ•°æ®é›†ä¸Šï¼ŒTransEå‡å…·æœ‰è¾ƒä½çš„å¹³å‡æ’åå’Œè¾ƒé«˜çš„hits@10æ’åã€‚</strong></p><h3 id="å››ç§ç±»å‹çš„å®ä½“é¢„æµ‹-1-1-1-N-N-1-N-N"><a href="#å››ç§ç±»å‹çš„å®ä½“é¢„æµ‹-1-1-1-N-N-1-N-N" class="headerlink" title="å››ç§ç±»å‹çš„å®ä½“é¢„æµ‹[1-1,1-N,N-1,N-N]"></a>å››ç§ç±»å‹çš„å®ä½“é¢„æµ‹<code>[1-1,1-N,N-1,N-N</code>]</h3><ul><li>æ ¹æ®å¤´å®ä½“å’Œå°¾å®ä½“çš„å¯¹åº”å…³ç³»åˆ’åˆ†ã€‚</li><li>ç»™å®šå…³ç³»å’Œå®ä½“é¢„æµ‹å¦ä¸€ä¸ªå®ä½“ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/erLSYdn6y9WxqPb.png" alt="image-20201014212035697"></p><h4 id="ç»“è®º-1"><a href="#ç»“è®º-1" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h4><p>â€‹    <strong>TransEåœ¨1-1çš„æƒ…å†µä¸‹é¢„æµ‹æ•ˆæœè¾ƒå¥½ã€‚</strong></p><h3 id="TransEåœ¨FB15kæµ‹è¯•é›†ä¸Šçš„æ ·ä¾‹é¢„æµ‹"><a href="#TransEåœ¨FB15kæµ‹è¯•é›†ä¸Šçš„æ ·ä¾‹é¢„æµ‹" class="headerlink" title="TransEåœ¨FB15kæµ‹è¯•é›†ä¸Šçš„æ ·ä¾‹é¢„æµ‹"></a>TransEåœ¨FB15kæµ‹è¯•é›†ä¸Šçš„æ ·ä¾‹é¢„æµ‹</h3><ul><li>ç²—ä½“æ˜¯æµ‹è¯•å…ƒç»„æ­£ç¡®çš„å°¾éƒ¨ï¼Œæ–œä½“æ˜¯è®­ç»ƒé›†ä¸Šå…¶å®ƒæ­£ç¡®çš„å°¾éƒ¨ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/h58lkvSjyUdVc3s.png" alt="image-20201014212836465"></p><h4 id="ç»“è®º-2"><a href="#ç»“è®º-2" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h4><p>â€‹    <strong>ç»™å®šä¸€ä¸ªå¤´éƒ¨å’Œä¸€ä¸ªæ ‡ç­¾ï¼Œæ’åœ¨æœ€é«˜ä½çš„å°¾éƒ¨è¢«é¢„æµ‹å‡ºæ¥ã€‚</strong></p><h3 id="ä¸åŒæ¨¡å‹åœ¨ä¸åŒæ ·æœ¬æ•°é‡ä¸‹çš„æ€§èƒ½"><a href="#ä¸åŒæ¨¡å‹åœ¨ä¸åŒæ ·æœ¬æ•°é‡ä¸‹çš„æ€§èƒ½" class="headerlink" title="ä¸åŒæ¨¡å‹åœ¨ä¸åŒæ ·æœ¬æ•°é‡ä¸‹çš„æ€§èƒ½"></a>ä¸åŒæ¨¡å‹åœ¨ä¸åŒæ ·æœ¬æ•°é‡ä¸‹çš„æ€§èƒ½</h3><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201014213239556.png" alt="image-20201014213239556"></p><ul><li>å·¦å›¾è¡¨ç¤ºæµ‹è¯•é›†ä¸­å¹³å‡æ’åï¼šå½“è®­ç»ƒé›†è¶Šå¤§ï¼ŒTransEçš„å¹³å‡æ’åä¸‹é™çš„æœ€å¿«ã€‚</li><li>å³å›¾è¡¨ç¤ºhits@10ä¸­æ­£ç¡®çš„æ¯”ä¾‹ï¼šå½“è®­ç»ƒé›†è¶Šå¤§ï¼Œhits@10å æ¯”ä¸Šå‡çš„æœ€å¿«ã€‚</li><li>ç»“æœè¡¨æ˜TransEå¯¹æ ·æœ¬é¢„æµ‹çš„æ€§èƒ½æœ€ä¼˜ã€‚</li></ul><h2 id="ç»“è®º-3"><a href="#ç»“è®º-3" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p><strong>TransEæ¨¡å‹å¯ä»¥ä½¿ç”¨æœ€å°çš„å‚æ•°é‡å¾—åˆ°çŸ¥è¯†å›¾è°±çš„å®ä½“å’Œå…³ç³»å‘é‡è¡¨ç¤ºã€‚</strong></p><p><strong>TransEæ¨¡å‹çš„å‚æ•°è¾ƒå°‘ï¼Œè®¡ç®—çš„å¤æ‚åº¦æ˜¾è‘—é™ä½ï¼Œå¹¶ä¸”åœ¨å¤§è§„æ¨¡ç¨€ç–çŸ¥è¯†åº“ä¸Šä¹ŸåŒæ ·å…·æœ‰è¾ƒå¥½çš„æ€§èƒ½ä¸å¯æ‰©å±•æ€§ã€‚</strong></p><h2 id="ä¸è¶³å’Œæ”¹è¿›"><a href="#ä¸è¶³å’Œæ”¹è¿›" class="headerlink" title="ä¸è¶³å’Œæ”¹è¿›"></a>ä¸è¶³å’Œæ”¹è¿›</h2><h4 id="ä¸è¶³"><a href="#ä¸è¶³" class="headerlink" title="ä¸è¶³"></a>ä¸è¶³</h4><ul><li>åœ¨å¤„ç†å¤æ‚å…³ç³»<code>[1-N,N-1,N-N</code>]æ—¶ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæ¯”è¾ƒé€‚åˆå¤„ç†<code>1-1</code>çš„å…³ç³»ã€‚</li><li>ä¸èƒ½å¤Ÿå¾ˆå¥½çš„å¤„ç†æ›´å¤æ‚çš„çŸ¥è¯†ç½‘ç»œã€‚</li></ul><h4 id="æ”¹è¿›"><a href="#æ”¹è¿›" class="headerlink" title="æ”¹è¿›"></a>æ”¹è¿›</h4><ul><li>TransHæ¨¡å‹ï¼šä¸ºäº†è§£å†³TransEæ¨¡å‹åœ¨å¤„ç†ä¸€å¯¹å¤š ã€ å¤šå¯¹ä¸€ ã€å¤šå¯¹å¤šå¤æ‚å…³ç³»æ—¶çš„å±€é™æ€§ï¼ŒTransHæ¨¡å‹æå‡ºè®©ä¸€ä¸ªå®ä½“åœ¨ä¸åŒçš„å…³ç³»ä¸‹æ‹¥æœ‰ä¸åŒçš„è¡¨ç¤ºã€‚</li><li>TransRæ¨¡å‹ï¼šä¸€ä¸ªå®ä½“æ˜¯å¤šç§å±æ€§çš„ç»¼åˆä½“ï¼Œä¸åŒå…³ç³»å…³æ³¨å®ä½“çš„ä¸åŒå±æ€§ã€‚ä¸åŒçš„å…³ç³»æ‹¥æœ‰ä¸åŒçš„è¯­ä¹‰ç©ºé—´ã€‚</li><li>TransDæ¨¡å‹ï¼šç»™å®šä¸‰å…ƒç»„(h, r, t) , TransDæ¨¡å‹è®¾ç½®äº†2ä¸ªåˆ†åˆ«å°†å¤´å®ä½“å’Œå°¾å®ä½“æŠ•å½±åˆ°å…³ç³»ç©ºé—´çš„æŠ•å½±çŸ©é˜µã€‚</li><li>TranSparseæ¨¡å‹ï¼šTranSparseæ˜¯é€šè¿‡åœ¨æŠ•å½±çŸ©é˜µä¸Šå¼ºåŒ–ç¨€ç–æ€§æ¥ç®€åŒ–TransRçš„å·¥ä½œã€‚é€šè¿‡å¼•å…¥ç¨€ç–æŠ•å½±çŸ©é˜µï¼ŒTransSparseæ¨¡å‹å‡å°‘äº†å‚æ•°ä¸ªæ•°ã€‚</li><li>TransMæ¨¡å‹ï¼šé™¤äº†å…è®¸å®ä½“åœ¨æ¶‰åŠä¸åŒå…³ç³»æ—¶å…·æœ‰ä¸åŒçš„åµŒå…¥ä¹‹å¤–ï¼Œæé«˜TransEæ¨¡å‹æ€§èƒ½å¯ä»¥ä»é™ä½h+râ‰ˆtçš„è¦æ±‚ç ”ç©¶å¼€å§‹ã€‚TransMæ¨¡å‹å°†ä¸ºæ¯ä¸ªäº‹å®ï¼ˆh,r,tï¼‰åˆ†é…ç‰¹å®šçš„å…³ç³»æƒé‡theta_rã€‚</li><li>TransFæ¨¡å‹ï¼šTransFåªéœ€è¦tä¸h+rä½äºåŒä¸€ä¸ªæ–¹å‘ï¼ŒåŒæ—¶hä¸t-rä¹Ÿä½äºåŒä¸€ä¸ªæ–¹å‘ã€‚</li><li>ManifoldEæ¨¡å‹ï¼šManifoldEæ¨¡å‹å¯¹äºæ¯ä¸ªäº‹å®ä¸‰å…ƒç»„$ï¼ˆh,r,tï¼‰$å°†$h+râ‰ˆt$è½¬æ¢ä¸º(h+r-t)çš„L2èŒƒå¼çº¦ç­‰äºtheta_rçš„å¹³æ–¹ã€‚</li><li>TransAæ¨¡å‹ï¼šTransAæ¨¡å‹ä¸ºæ¯ä¸ªå…³ç³»rå¼•å…¥ä¸€ä¸ªå¯¹ç§°çš„éè´ŸçŸ©é˜µMrï¼Œå¹¶ä½¿ç”¨è‡ªé€‚åº”é©¬æ°è·ç¦»å®šä¹‰è¯„åˆ†å‡½æ•°ã€‚é€šè¿‡å­¦ä¹ è·ç¦»åº¦é‡Mr, TransAåœ¨å¤„ç†å¤æ‚å…³ç³»æ—¶æ›´åŠ çµæ´»ã€‚</li></ul><h2 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h2><ol><li><strong>Mean Rank å’Œ hit@10</strong></li></ol><p>åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œå¯¹äºä¸€ä¸ªä¸‰å…ƒç»„ï¼Œæˆ‘ä»¬å°†å¤´å®ä½“æˆ–å°¾å®ä½“æ›¿æ¢æˆä»»æ„ä¸€ç§å…¶ä»–çš„å®ä½“ï¼Œå¾—åˆ°ï¼ˆn-1ï¼‰ä¸ªæ–°çš„å…³ç³»ä¸‰å…ƒç»„ï¼Œç„¶åå¯¹è¿™äº›ä¸‰å…ƒç»„è®¡ç®—å®ä½“å…³ç³»è·ç¦»ï¼Œå°†è¿™n-1ä¸ªä¸‰å…ƒç»„æŒ‰ç…§è·ç¦»ä»å°åˆ°å¤§æ’åˆ—ã€‚</p><ul><li><p>å¯¹Mean Rankçš„ç†è§£</p><p>åœ¨æµ‹è¯•é›†é‡Œï¼Œæ±‚çœŸå®çš„å®ä½“åœ¨n-1ä¸ªå…ƒç´ ä¸­çš„æ’åï¼Œå¾—å‡ºå¹³å‡åˆ°ç¬¬å¤šå°‘ä¸ªæ‰èƒ½åŒ¹é…åˆ°æ­£ç¡®çš„ç»“æœã€‚</p></li><li><p>å¯¹hit@10çš„ç†è§£</p><p>åœ¨è¿™ä¸ªæ’å¥½åºçš„n-1å…ƒç´ ä¸­ï¼Œä»ç¬¬ä¸€ä¸ªå¼€å§‹éå†ï¼Œçœ‹ä»ç¬¬ä¸€ä¸ªåˆ°ç¬¬åä¸ªæ˜¯å¦èƒ½å¤Ÿé‡åˆ°çœŸå®çš„å®ä½“ï¼Œå¦‚æœé‡åˆ°äº†å°±å°† $hit@10 +1$ã€‚</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> KGE </tag>
            
            <tag> KG </tag>
            
            <tag> TransE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ä¸œæ²¹æ•™åŠ¡APPä½¿ç”¨è¯´æ˜</title>
      <link href="/2020/10/26/dyjw/"/>
      <url>/2020/10/26/dyjw/</url>
      
        <content type="html"><![CDATA[<h3 id="è¯·å¤§å®¶åŠ¡å¿…å‡çº§åˆ°1-0ï¼ˆæ­£å¼ç‰ˆï¼‰åŠä»¥åç‰ˆæœ¬"><a href="#è¯·å¤§å®¶åŠ¡å¿…å‡çº§åˆ°1-0ï¼ˆæ­£å¼ç‰ˆï¼‰åŠä»¥åç‰ˆæœ¬" class="headerlink" title="è¯·å¤§å®¶åŠ¡å¿…å‡çº§åˆ°1.0ï¼ˆæ­£å¼ç‰ˆï¼‰åŠä»¥åç‰ˆæœ¬"></a>è¯·å¤§å®¶åŠ¡å¿…å‡çº§åˆ°1.0ï¼ˆæ­£å¼ç‰ˆï¼‰åŠä»¥åç‰ˆæœ¬</h3><h3 id="ä¸‹è½½åœ°å€æ±‡æ€»"><a href="#ä¸‹è½½åœ°å€æ±‡æ€»" class="headerlink" title="ä¸‹è½½åœ°å€æ±‡æ€»"></a>ä¸‹è½½åœ°å€æ±‡æ€»</h3><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201027141834.png" alt="image-20201027141828935"></p><h2 id="é—®é¢˜æ±‡æ€»"><a href="#é—®é¢˜æ±‡æ€»" class="headerlink" title="é—®é¢˜æ±‡æ€»"></a>é—®é¢˜æ±‡æ€»</h2><ol><li>è´¦å·å¯†ç ä¸æ­£ç¡®<br>æ•™åŠ¡ç³»ç»Ÿå‡çº§æ”¹ç‰ˆï¼Œåˆæ¬¡ç™»é™†è¯·ç™»å½•æ•™åŠ¡ç®¡ç†ç³»ç»Ÿç½‘é¡µç‰ˆé‡ç½®å¯†ç ã€‚</li><li>éªŒè¯ç åˆ·æ–°ä¸å‡ºæ¥<br>ç™»å½• <code>jwgl.nepu.edu.cn</code> çœ‹çœ‹è‡ªå·±æœ‰æ²¡æœ‰å› ä¸ºè®¿é—®æ¬¡æ•°è¿‡å¤šç¦æ­¢è®¿é—®ï¼ç­‰è§£ç¦å°±å¥½å•¦ï¼ ï¼ˆæˆ–è€…æ›´æ¢ç½‘ç»œç¯å¢ƒï¼Œæ›´æ¢ipï¼‰</li><li>ç»©ç‚¹æ€ä¹ˆå˜ä½äº†<br>æ•™åŠ¡å¤„æ›´æ–°äº†ç»©ç‚¹è®¡ç®—è§„åˆ™ï¼ï¼ˆå¤§å®¶éƒ½ä½äº†æ²¡å…³ç³»/ç‹—å¤´ï¼‰<h2 id="æ›´æ–°æ—¥å¼"><a href="#æ›´æ–°æ—¥å¼" class="headerlink" title="æ›´æ–°æ—¥å¼"></a>æ›´æ–°æ—¥å¼</h2></li></ol><h3 id="v1-5æ­£å¼ç‰ˆï¼š2020-10-26ä¸­åˆ"><a href="#v1-5æ­£å¼ç‰ˆï¼š2020-10-26ä¸­åˆ" class="headerlink" title="v1.5æ­£å¼ç‰ˆï¼š2020.10.26ä¸­åˆ"></a>v1.5æ­£å¼ç‰ˆï¼š2020.10.26ä¸­åˆ</h3><ul><li>ä¸ºæ–¹ä¾¿å¤§å®¶è®¡ç®—ç»¼æµ‹ï¼Œå¹³å‡åˆ†è®¡ç®—ä¸­å»é™¤â€œå…¬é€‰â€ç±»å‹çš„è¯¾ç¨‹ã€‚ä¸æ™ºè‚²æˆç»©ç®—æ³•ä¸€è‡´ã€‚<h3 id="v1-4æ­£å¼ç‰ˆï¼š2020-10-25æ™šä¸Š"><a href="#v1-4æ­£å¼ç‰ˆï¼š2020-10-25æ™šä¸Š" class="headerlink" title="v1.4æ­£å¼ç‰ˆï¼š2020.10.25æ™šä¸Š"></a>v1.4æ­£å¼ç‰ˆï¼š2020.10.25æ™šä¸Š</h3></li><li>ä¼˜åŒ–é¡µé¢äº¤äº’é€»è¾‘</li><li>ä¿®æ”¹ç™»å½•ç•Œé¢</li><li>ä¿®å¤å·²çŸ¥bug<h3 id="v1-3æ­£å¼ç‰ˆï¼š2020-10-25æ—©æ™¨"><a href="#v1-3æ­£å¼ç‰ˆï¼š2020-10-25æ—©æ™¨" class="headerlink" title="v1.3æ­£å¼ç‰ˆï¼š2020.10.25æ—©æ™¨"></a>v1.3æ­£å¼ç‰ˆï¼š2020.10.25æ—©æ™¨</h3></li><li>æ–°å¢å®˜æ–¹è¯¾è¡¨</li><li>ä¿®æ”¹ç¨‹åºå›¾æ ‡</li><li>ä¿®å¤å…¶ä»–å·²çŸ¥bug<h3 id="v1-1æ­£å¼ç‰ˆï¼š2020-10-24ä¸‹åˆ"><a href="#v1-1æ­£å¼ç‰ˆï¼š2020-10-24ä¸‹åˆ" class="headerlink" title="v1.1æ­£å¼ç‰ˆï¼š2020.10.24ä¸‹åˆ"></a>v1.1æ­£å¼ç‰ˆï¼š2020.10.24ä¸‹åˆ</h3></li><li>ä¿®å¤éƒ¨åˆ†åŒå­¦ å…¨éƒ¨å­¦æœŸ æˆç»©æŸ¥è¯¢å¤±è´¥çš„é—®é¢˜</li><li><p>ä¿®å¤å…¶ä»–å·²çŸ¥bug</p><h3 id="v1-1æ­£å¼ç‰ˆï¼š2020-10-24å‡Œæ™¨"><a href="#v1-1æ­£å¼ç‰ˆï¼š2020-10-24å‡Œæ™¨" class="headerlink" title="v1.1æ­£å¼ç‰ˆï¼š2020.10.24å‡Œæ™¨"></a>v1.1æ­£å¼ç‰ˆï¼š2020.10.24å‡Œæ™¨</h3></li><li><p><strong>åº”ç”¨å†…é™†ç»­æ¨é€æ›´æ–°ï¼Œæœ¬æ¬¡ä¸ºå¼ºåˆ¶æ›´æ–°ï¼Œv1.0ç‰ˆæœ¬åœ¨åº”ç”¨å†…æ›´æ–°åæ–¹å¯æ­£å¸¸ä½¿ç”¨ã€‚</strong> </p></li><li>ä¿®å¤éƒ¨åˆ†æœºå‹æˆç»©æŸ¥è¯¢å¤±è´¥çš„é—®é¢˜ã€‚</li><li>ä¿®å¤å…¶ä»–å·²çŸ¥bug</li></ul><h3 id="v1-0æ­£å¼ç‰ˆï¼š2020-10-23æ™šä¸Š"><a href="#v1-0æ­£å¼ç‰ˆï¼š2020-10-23æ™šä¸Š" class="headerlink" title="v1.0æ­£å¼ç‰ˆï¼š2020.10.23æ™šä¸Š"></a>v1.0æ­£å¼ç‰ˆï¼š2020.10.23æ™šä¸Š</h3><ul><li><strong>é‡å¤§å‡çº§ï¼š</strong> ç»ˆäºæ”¯æŒè½¯ä»¶å†…æ›´æ–°äº†ï¼ï¼ï¼ä¸ç”¨å»ç™¾åº¦äº‘ä¸‹è½½æ–°ç‰ˆäº†ï¼åé¢æœ‰æ›´æ–°ä¼šè‡ªåŠ¨æ¨é€ï¼ˆåº”ç”¨å•†åº—å®¡æ ¸å¤ªæ…¢äº†ã€‚ï¼‰</li><li>é€‚é…å‡ æ¬¾æ‰‹æœºå±å¹•æ¯”ä¾‹</li><li>ä¿®å¤å…¶ä»–å·²çŸ¥bug<h3 id="beta5ç‰ˆæœ¬ï¼š2020-10-23ä¸­åˆ"><a href="#beta5ç‰ˆæœ¬ï¼š2020-10-23ä¸­åˆ" class="headerlink" title="beta5ç‰ˆæœ¬ï¼š2020.10.23ä¸­åˆ"></a>beta5ç‰ˆæœ¬ï¼š2020.10.23ä¸­åˆ</h3></li><li><strong>é‡å¤§æ›´æ–°</strong>ï¼šä¿®å¤éƒ¨åˆ†æœºå‹é—ªé€€bug</li><li>ä¿®å¤å†å¹´å¹³å‡ç»©ç‚¹æ˜¾ç¤ºé”™è¯¯çš„é—®é¢˜</li><li>ä¿®å¤appå†…æ‰“å¼€csdnä¹‹åæ— æ³•è¿”å›çš„é—®é¢˜</li><li>ä¿®å¤å…¶ä»–å·²çŸ¥bug<h3 id="beta5ç‰ˆæœ¬ï¼š2020-10-22æ·±å¤œ"><a href="#beta5ç‰ˆæœ¬ï¼š2020-10-22æ·±å¤œ" class="headerlink" title="beta5ç‰ˆæœ¬ï¼š2020.10.22æ·±å¤œ"></a>beta5ç‰ˆæœ¬ï¼š2020.10.22æ·±å¤œ</h3></li><li>æ–°å¢ç™»å½•é¡µé¢è¾“å…¥éªŒè¯ç ä¹‹åå›è½¦é”®ç™»å½•ã€‚</li><li>ä¿®å¤äº†é¦–é¡µå­¦ç§‘æ•°æ˜¾ç¤ºçš„é—®é¢˜ã€‚</li><li>ä¿®å¤éƒ¨åˆ†è¿›è¡Œé—ªé€€çš„é—®é¢˜ã€‚</li><li><p>ä¿®å¤å…¶ä»–å·²çŸ¥bug</p><h3 id="beta4ç‰ˆæœ¬ï¼š2020-10-22æ™šä¸Š"><a href="#beta4ç‰ˆæœ¬ï¼š2020-10-22æ™šä¸Š" class="headerlink" title="beta4ç‰ˆæœ¬ï¼š2020.10.22æ™šä¸Š"></a>beta4ç‰ˆæœ¬ï¼š2020.10.22æ™šä¸Š</h3></li><li><p>æ–°å¢æˆç»©åˆ†æ</p></li><li>æ–°å¢é¦–é¡µæ™ºè‚²æˆç»©å±•ç¤º</li><li>ä¿®å¤ç½‘é¡µå†…æ— æ³•è·³è½¬APP</li><li><p>ä¿®å¤å…¶ä»–å·²çŸ¥bug</p><h3 id="beta3ç‰ˆæœ¬ï¼š2020-10-22ä¸‹åˆ"><a href="#beta3ç‰ˆæœ¬ï¼š2020-10-22ä¸‹åˆ" class="headerlink" title="beta3ç‰ˆæœ¬ï¼š2020.10.22ä¸‹åˆ"></a>beta3ç‰ˆæœ¬ï¼š2020.10.22ä¸‹åˆ</h3></li><li><p>æ–°å¢ç»©ç‚¹æŸ¥è¯¢</p></li><li><p>ä¿®å¤äº†å·²çŸ¥bug</p><h3 id="beta2ç‰ˆæœ¬ï¼š2020-10-22æ—©æ™¨"><a href="#beta2ç‰ˆæœ¬ï¼š2020-10-22æ—©æ™¨" class="headerlink" title="beta2ç‰ˆæœ¬ï¼š2020.10.22æ—©æ™¨"></a>beta2ç‰ˆæœ¬ï¼š2020.10.22æ—©æ™¨</h3></li><li><p>ä¿®å¤äº†å½“å‰å­¦æœŸæˆç»©æ— æ³•æŸ¥è¯¢çš„é—®é¢˜</p></li></ul><h2 id="åŠŸèƒ½ä»‹ç»"><a href="#åŠŸèƒ½ä»‹ç»" class="headerlink" title="åŠŸèƒ½ä»‹ç»"></a>åŠŸèƒ½ä»‹ç»</h2><h3 id="æˆç»©æŸ¥è¯¢"><a href="#æˆç»©æŸ¥è¯¢" class="headerlink" title="æˆç»©æŸ¥è¯¢"></a>æˆç»©æŸ¥è¯¢</h3><ul><li>é»˜è®¤æ˜¾ç¤ºå½“å‰å­¦æœŸæˆç»©</li><li>ä¸åŒé¢œè‰²ä»£è¡¨ä¸åŒçš„åˆ†æ•°æ®µ<blockquote><p> <60åˆ†ï¼šçº¢è‰² 60-70åˆ†ï¼šæ©™è‰² 70-90åˆ†ï¼šç»¿è‰²  \>90åˆ†ï¼šè“è‰²</p><h3 id="æˆç»©åˆ†æ"><a href="#æˆç»©åˆ†æ" class="headerlink" title="æˆç»©åˆ†æ"></a>æˆç»©åˆ†æ</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201112142338.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5ODI3Njc3,size_16,color_FFFFFF,t_70#pic_center" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p></blockquote></li><li>çºµåæ ‡ï¼šè¯¾ç¨‹æ•°é‡</li><li>æ¨ªåæ ‡ï¼šåˆ†æ•°æ®µ<blockquote><p>6ï¼šå°äº60åˆ†çš„è¯¾ç¨‹æ•°<br>7ï¼š60-70åˆ†<br>ä»¥æ­¤ç±»æ¨</p></blockquote></li></ul><h3 id="ç»©ç‚¹"><a href="#ç»©ç‚¹" class="headerlink" title="ç»©ç‚¹"></a>ç»©ç‚¹</h3><ul><li>ç»©ç‚¹è®¡ç®—ä½¿ç”¨æ–°ç®—æ³•ï¼Œä¸æ•™åŠ¡å¤„æ˜¾ç¤ºç»“æœä¸€è‡´ã€‚<h3 id="é€šçŸ¥å…¬å‘Š"><a href="#é€šçŸ¥å…¬å‘Š" class="headerlink" title="é€šçŸ¥å…¬å‘Š"></a>é€šçŸ¥å…¬å‘Š</h3></li><li>ä¸ºäº†æ–¹ä¾¿å¤§å®¶æŸ¥çœ‹æ•™åŠ¡å¤„çš„é€šçŸ¥å…¬å‘Šï¼Œå°†å®ƒå•ç‹¬æ‹¿åˆ°Appé‡Œã€‚</li></ul><h4 id="ç”¨æˆ·éœ€çŸ¥"><a href="#ç”¨æˆ·éœ€çŸ¥" class="headerlink" title="ç”¨æˆ·éœ€çŸ¥"></a>ç”¨æˆ·éœ€çŸ¥</h4><p><strong>ä¸ºå¾—åˆ°ç”¨æˆ·æ³¨å†Œé‡ï¼Œä¼šæ”¶é›†ç™»å½•æˆåŠŸçš„å­¦å·ï¼ï¼ï¼ä»…æ”¶é›†å­¦å·ï¼</strong></p>]]></content>
      
      
      <categories>
          
          <category> å·¥å…·&amp;æ•™ç¨‹ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ•™ç¨‹ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>çŸ¥è¯†å›¾è°±åµŒå…¥(KGE)ï¼šæ–¹æ³•å’Œåº”ç”¨çš„ç»¼è¿°</title>
      <link href="/2020/10/14/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B5%8C%E5%85%A5%EF%BC%9A%E6%96%B9%E6%B3%95%E5%92%8C%E5%BA%94%E7%94%A8%E7%9A%84%E7%BB%BC%E8%BF%B0/"/>
      <url>/2020/10/14/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B5%8C%E5%85%A5%EF%BC%9A%E6%96%B9%E6%B3%95%E5%92%8C%E5%BA%94%E7%94%A8%E7%9A%84%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="1-çŸ¥è¯†å›¾è°±-KG"><a href="#1-çŸ¥è¯†å›¾è°±-KG" class="headerlink" title="1. çŸ¥è¯†å›¾è°±(KG)"></a>1. çŸ¥è¯†å›¾è°±(KG)</h2><ul><li>ç”±å®ä½“(èŠ‚ç‚¹)å’Œå…³ç³»(ä¸åŒç±»å‹çš„è¾¹)ç»„æˆçš„å¤šå…³ç³»å›¾ã€‚</li><li>æ¯æ¡è¾¹éƒ½è¡¨ç¤ºä¸ºå½¢å¼(å¤´å®ä½“ã€å…³ç³»ã€å°¾å®ä½“)çš„ä¸‰ä¸ªéƒ¨åˆ†ï¼Œä¹Ÿç§°ä¸ºäº‹å®</li></ul><h3 id="1-1-é—®é¢˜"><a href="#1-1-é—®é¢˜" class="headerlink" title="1.1 é—®é¢˜"></a>1.1 é—®é¢˜</h3><ul><li>è¿™ç±»ä¸‰å…ƒç»„çš„åº•å±‚ç¬¦å·ç‰¹æ€§é€šå¸¸ä½¿KGså¾ˆéš¾æ“ä½œ</li></ul><h3 id="1-2-è§£å†³ï¼š"><a href="#1-2-è§£å†³ï¼š" class="headerlink" title="1.2 è§£å†³ï¼š"></a>1.2 è§£å†³ï¼š</h3><ul><li>æå‡ºäº†ä¸€ç§æ–°çš„ç ”ç©¶æ–¹å‘â€”â€”çŸ¥è¯†å›¾è°±åµŒå…¥ã€‚</li></ul><h3 id="1-3-å…³é”®æ€æƒ³"><a href="#1-3-å…³é”®æ€æƒ³" class="headerlink" title="1.3 å…³é”®æ€æƒ³"></a>1.3 å…³é”®æ€æƒ³</h3><ul><li>åµŒå…¥KGçš„ç»„ä»¶ï¼ŒåŒ…æ‹¬å°†å®ä½“å’Œå…³ç³»è½¬åŒ–ä¸ºè¿ç»­çš„å‘é‡ç©ºé—´ï¼Œä»è€Œç®€åŒ–æ“ä½œï¼ŒåŒæ—¶ä¿ç•™KGçš„åŸæœ‰çš„ç»“æ„ã€‚</li></ul><h2 id="2-èåˆäº‹å®ä¿¡æ¯"><a href="#2-èåˆäº‹å®ä¿¡æ¯" class="headerlink" title="2. èåˆäº‹å®ä¿¡æ¯"></a>2. èåˆäº‹å®ä¿¡æ¯</h2><h3 id="2-1-å¹³ç§»è·ç¦»æ¨¡å‹"><a href="#2-1-å¹³ç§»è·ç¦»æ¨¡å‹" class="headerlink" title="2.1 å¹³ç§»è·ç¦»æ¨¡å‹"></a>2.1 å¹³ç§»è·ç¦»æ¨¡å‹</h3><ul><li>å¹³ç§»è·ç¦»æ¨¡å‹åˆ©ç”¨äº†åŸºäºè·ç¦»çš„è¯„åˆ†å‡½æ•°ï¼Œé€šè¿‡ä¸¤ä¸ªå®ä½“ä¹‹é—´çš„è·ç¦»å¯¹äº‹å®çš„åˆç†æ€§è¿›è¡Œåº¦é‡ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163514.png" alt="img" style="zoom:67%;" /></p><h4 id="2-1-1-TransEæ¨¡å‹"><a href="#2-1-1-TransEæ¨¡å‹" class="headerlink" title="2.1.1 TransEæ¨¡å‹"></a>2.1.1 TransEæ¨¡å‹</h4><ul><li>å¹³ç§»ä¸å˜ç°è±¡</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163506.png" alt=""></p><ul><li><p><strong>TransEæ¨¡å‹ï¼š</strong>å°†çŸ¥è¯†åº“ä¸­çš„å…³ç³»çœ‹ä½œå®ä½“é—´çš„æŸç§å¹³ç§»å‘é‡ã€‚</p></li><li><p>å¯¹äºæ¯ä¸ªäº‹å®ä¸‰å…ƒç»„(h,r,t)ï¼ŒTransEæ¨¡å‹å°†å®ä½“å’Œå…³ç³»è¡¨ç¤ºä¸ºåŒä¸€ç©ºé—´ä¸­ï¼ŒæŠŠå…³ç³»å‘é‡rçœ‹ä½œä¸ºå¤´å®ä½“å‘é‡hå’Œå°¾å®ä½“å‘é‡tä¹‹é—´çš„å¹³ç§»å³ $h+râ‰ˆt$ã€‚</p></li><li><p>å¯ä»¥å°†r,çœ‹ä½œä»håˆ°tçš„ç¿»è¯‘</p></li><li><p>çŸ¥è¯†åº“ä¸­çš„å®ä½“å…³ç³»ç±»å‹å¯åˆ†ä¸º ä¸€å¯¹ä¸€ ã€ä¸€å¯¹å¤š ã€ å¤šå¯¹ä¸€ ã€å¤šå¯¹å¤š4 ç§ç±»å‹ï¼Œè€Œå¤æ‚å…³ç³»ä¸»è¦æŒ‡çš„æ˜¯ ä¸€å¯¹å¤š ã€ å¤šå¯¹ä¸€ ã€å¤šå¯¹å¤šçš„ 3 ç§å…³ç³»ç±»å‹ã€‚</p><h5 id="ä¼˜ç‚¹"><a href="#ä¼˜ç‚¹" class="headerlink" title="ä¼˜ç‚¹"></a>ä¼˜ç‚¹</h5><ul><li>TransEæ¨¡å‹çš„å‚æ•°è¾ƒå°‘ï¼Œè®¡ç®—çš„å¤æ‚åº¦æ˜¾è‘—é™ä½ï¼Œå¹¶ä¸”åœ¨å¤§è§„æ¨¡ç¨€ç–çŸ¥è¯†åº“ä¸Šä¹ŸåŒæ ·å…·æœ‰è¾ƒå¥½çš„æ€§èƒ½ä¸å¯æ‰©å±•æ€§ã€‚</li></ul><h5 id="ç¼ºç‚¹"><a href="#ç¼ºç‚¹" class="headerlink" title="ç¼ºç‚¹"></a>ç¼ºç‚¹</h5><ul><li>TransEæ¨¡å‹ä¸èƒ½ç”¨åœ¨å¤„ç†å¤æ‚å…³ç³»ä¸Šã€‚</li></ul></li></ul><h4 id="2-1-2-TransHæ¨¡å‹"><a href="#2-1-2-TransHæ¨¡å‹" class="headerlink" title="2.1.2 TransHæ¨¡å‹"></a>2.1.2 TransHæ¨¡å‹</h4><ul><li>ä¸ºäº†è§£å†³TransEæ¨¡å‹åœ¨å¤„ç†ä¸€å¯¹å¤š ã€ å¤šå¯¹ä¸€ ã€å¤šå¯¹å¤šå¤æ‚å…³ç³»æ—¶çš„å±€é™æ€§ã€‚</li><li>TransHæ¨¡å‹æå‡ºè®©ä¸€ä¸ªå®ä½“åœ¨ä¸åŒçš„å…³ç³»ä¸‹æ‹¥æœ‰ä¸åŒçš„è¡¨ç¤ºã€‚</li><li>å¯¹äºå…³ç³»rï¼ŒTransHæ¨¡å‹åŒæ—¶ä½¿ç”¨å¹³ç§»å‘é‡rå’Œè¶…å¹³é¢çš„æ³•å‘é‡w_ræ¥è¡¨ç¤ºå®ƒã€‚å¯¹äºä¸€ä¸ªä¸‰å…ƒç»„(h, r, t) , TransHé¦–å…ˆå°†å¤´å®ä½“å‘é‡hå’Œå°¾å®ä½“å‘é‡rï¼Œæ²¿æ³•çº¿wrï¼Œå½±åˆ°å…³ç³»rå¯¹åº”çš„è¶…å¹³é¢ä¸Šï¼Œç”¨hâŠ¥å’ŒtâŠ¥è¡¨ç¤ºå¦‚ä¸‹ï¼š</li></ul><p><img src="https://i.loli.net/2020/10/14/rXvZCSqBY8EhcMV.png" alt=""></p><ul><li><p>TransH ä½¿ä¸åŒçš„å®ä½“åœ¨ä¸åŒçš„å…³ç³»ä¸‹æ‹¥æœ‰äº†ä¸åŒçš„è¡¨ç¤ºå½¢å¼ï¼Œä½†ç”±äºå®ä½“å‘é‡è¢«æŠ•å½±åˆ°äº†å…³ç³»çš„è¯­ä¹‰ç©ºé—´ä¸­ï¼Œæ•…å®ƒä»¬å…·æœ‰ç›¸åŒçš„ç»´åº¦</p><h5 id="ç¼ºç‚¹ï¼š"><a href="#ç¼ºç‚¹ï¼š" class="headerlink" title="ç¼ºç‚¹ï¼š"></a>ç¼ºç‚¹ï¼š</h5><ul><li>è™½ç„¶TransHæ¨¡å‹ä½¿æ¯ä¸ªå®ä½“åœ¨ä¸åŒå…³ç³»ä¸‹æ‹¥æœ‰äº†ä¸åŒçš„è¡¨ç¤ºï¼Œå®ƒä»ç„¶å‡è®¾å®ä½“å’Œå…³ç³»å¤„äºç›¸åŒçš„è¯­ä¹‰ç©ºé—´ä¸­ï¼Œè¿™ä¸€å®šç¨‹åº¦ä¸Šé™åˆ¶äº†TransHçš„è¡¨ç¤ºèƒ½åŠ›ã€‚</li></ul></li></ul><h4 id="2-1-3-TransRæ¨¡å‹"><a href="#2-1-3-TransRæ¨¡å‹" class="headerlink" title="2.1.3 TransRæ¨¡å‹"></a>2.1.3 TransRæ¨¡å‹</h4><ul><li>TransRæ¨¡å‹è®¤ä¸ºï¼Œä¸€ä¸ªå®ä½“æ˜¯å¤šç§å±æ€§çš„ç»¼åˆä½“ï¼Œä¸åŒå…³ç³»å…³æ³¨å®ä½“çš„ä¸åŒå±æ€§ã€‚</li><li>ä¸åŒçš„å…³ç³»æ‹¥æœ‰ä¸åŒçš„è¯­ä¹‰ç©ºé—´ã€‚</li><li>å¯¹äºæ¯ä¸€ä¸ªå…³ç³»rï¼ŒTransRå®šä¹‰æŠ•å½±çŸ©é˜µMrï¼Œå°†å®ä½“å‘é‡ä»å®ä½“ç©ºé—´æŠ•å½±åˆ°å…³ç³»rçš„å­ç©ºé—´ï¼Œç”¨hâŠ¥å’ŒtâŠ¥è¡¨ç¤ºå¦‚ä¸‹ï¼š</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163454.png" alt=""></p><ul><li><p>ç„¶åä½¿ $hâŠ¥+râ‰ˆtâŠ¥$</p><h5 id="ç¼ºç‚¹ï¼š-1"><a href="#ç¼ºç‚¹ï¼š-1" class="headerlink" title="ç¼ºç‚¹ï¼š"></a>ç¼ºç‚¹ï¼š</h5><ul><li><p>åœ¨åŒä¸€ä¸ªå…³ç³»ä¸‹ï¼šå¤´ã€å°¾å®ä½“å…±äº«ç›¸åŒçš„æŠ•å½±çŸ©é˜µã€‚ç„¶è€Œï¼Œä¸€ä¸ªå…³ç³»çš„å¤´ã€å°¾å®ä½“çš„ç±»å‹æˆ–å±æ€§å¯èƒ½å·®å¼‚å·¨å¤§ã€‚ä¾‹å¦‚ï¼Œå¯¹äºä¸‰å…ƒç»„(ç¾å›½ï¼Œæ€»ç»Ÿï¼Œå¥¥å·´é©¬)ï¼Œç¾å›½å’Œå¥¥å·´é©¬çš„ç±»å‹å®Œå…¨ä¸åŒï¼Œä¸€ä¸ªæ˜¯å›½å®¶ï¼Œä¸€ä¸ªæ˜¯äººç‰©ã€‚</p></li><li><p>ä»å®ä½“ç©ºé—´åˆ°å…³ç³»ç©ºé—´çš„æŠ•å½±æ˜¯å®ä½“å’Œå…³ç³»ä¹‹é—´çš„äº¤äº’è¿‡ç¨‹ï¼Œå› æ­¤TransRè®©æŠ•å½±çŸ©é˜µä»…ä¸å…³ç³»æœ‰å…³æ˜¯ä¸åˆç†çš„ã€‚</p></li><li>ä¸TransEå’ŒTransHç›¸æ¯”ï¼ŒTransRç”±äºå¼•å…¥äº†ç©ºé—´æŠ•å½±ï¼Œä½¿å¾—TransRæ¨¡å‹å‚æ•°æ€¥å‰§å¢åŠ ï¼Œè®¡ç®—å¤æ‚åº¦å¤§å¤§æé«˜ã€‚</li></ul></li></ul><h4 id="2-1-4-TransDæ¨¡å‹"><a href="#2-1-4-TransDæ¨¡å‹" class="headerlink" title="2.1.4 TransDæ¨¡å‹"></a>2.1.4 TransDæ¨¡å‹</h4><ul><li>ç»™å®šä¸‰å…ƒç»„(h, r, t) , TransDæ¨¡å‹è®¾ç½®äº†2ä¸ªåˆ†åˆ«å°†å¤´å®ä½“å’Œå°¾å®ä½“æŠ•å½±åˆ°å…³ç³»ç©ºé—´çš„æŠ•å½±çŸ©é˜µMr1å’ŒMr2ã€‚å…·ä½“å®šä¹‰å¦‚ä¸‹:</li></ul><p><img src="https://i.loli.net/2020/10/14/kcstuVaQUAvE97y.png" alt="img"></p><ul><li>å°¾å®ä½“ç”¨hâŠ¥å’ŒtâŠ¥è¡¨ç¤ºå¦‚ä¸‹ï¼š</li></ul><p><img src="https://i.loli.net/2020/10/14/ERAcGWmow7drZ9x.png" alt="img"></p><h4 id="2-1-5-TranSparseæ¨¡å‹"><a href="#2-1-5-TranSparseæ¨¡å‹" class="headerlink" title="2.1.5 TranSparseæ¨¡å‹"></a>2.1.5 TranSparseæ¨¡å‹</h4><ul><li>TranSparseæ˜¯é€šè¿‡åœ¨æŠ•å½±çŸ©é˜µä¸Šå¼ºåŒ–ç¨€ç–æ€§æ¥ç®€åŒ–TransRçš„å·¥ä½œã€‚å®ƒæœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼šTranSparse (å…±äº«)å’ŒTranSparse (å•ç‹¬)ã€‚</li><li>TranSparse (å…±äº«)å¯¹æ¯ä¸ªå…³ç³»rä½¿ç”¨ç›¸åŒçš„ç¨€ç–æŠ•å½±çŸ©é˜µ$M_r(theta_r)$ å³ï¼š</li></ul><p><img src="https://i.loli.net/2020/10/14/FSqw6I5lgOH7rsc.png" alt="img"></p><ul><li>TranSparse (å•ç‹¬)å¯¹äºå¤´å®ä½“å’Œå°¾å®ä½“åˆ†åˆ«ä½¿ç”¨2ä¸ªä¸åŒçš„æŠ•å½±çŸ©é˜µ$M_r1(theta_r1$)å’Œ$M_r2(theta_r2)$ã€‚</li></ul><p><img src="https://i.loli.net/2020/10/14/LcQ2gVtk7HBiaJN.png" alt="img"></p><ul><li><p>è¿™é‡Œçš„$theta_r$ã€$theta_r1$å’Œ$theta_r2$è¡¨ç¤ºè¿™äº›æŠ•å½±çŸ©é˜µçš„ç¨€ç–åº¦ã€‚</p><h5 id="ä¼˜ç‚¹ï¼š"><a href="#ä¼˜ç‚¹ï¼š" class="headerlink" title="ä¼˜ç‚¹ï¼š"></a>ä¼˜ç‚¹ï¼š</h5><ul><li>TransSparseæ¨¡å‹é€šè¿‡å¼•å…¥ç¨€ç–æŠ•å½±çŸ©é˜µï¼ŒTransSparseæ¨¡å‹å‡å°‘äº†å‚æ•°ä¸ªæ•°ã€‚</li></ul></li></ul><h4 id="2-1-6-TransMæ¨¡å‹"><a href="#2-1-6-TransMæ¨¡å‹" class="headerlink" title="2.1.6 TransMæ¨¡å‹"></a>2.1.6 TransMæ¨¡å‹</h4><ul><li>é™¤äº†å…è®¸å®ä½“åœ¨æ¶‰åŠä¸åŒå…³ç³»æ—¶å…·æœ‰ä¸åŒçš„åµŒå…¥ä¹‹å¤–ï¼Œæé«˜TransEæ¨¡å‹æ€§èƒ½å¯ä»¥ä»é™ä½h+râ‰ˆtçš„è¦æ±‚ç ”ç©¶å¼€å§‹ã€‚TransMæ¨¡å‹å°†ä¸ºæ¯ä¸ªäº‹å®ï¼ˆh,r,tï¼‰åˆ†é…ç‰¹å®šçš„å…³ç³»æƒé‡theta_rã€‚</li><li>é€šè¿‡å¯¹ä¸€å¯¹å¤šã€å¤šå¯¹ä¸€å’Œå¤šå¯¹å¤šåˆ†é…è¾ƒå°çš„æƒé‡ï¼ŒTransMæ¨¡å‹ä½¿å¾—tåœ¨ä¸Šè¿°çš„å¤æ‚å…³ç³»ä¸­ç¦»h+ræ›´è¿œã€‚</li></ul><h4 id="2-1-7-ManifoldEæ¨¡å‹"><a href="#2-1-7-ManifoldEæ¨¡å‹" class="headerlink" title="2.1.7 ManifoldEæ¨¡å‹"></a>2.1.7 ManifoldEæ¨¡å‹</h4><ul><li>ManifoldEæ¨¡å‹å¯¹äºæ¯ä¸ªäº‹å®ä¸‰å…ƒç»„$ï¼ˆh,r,tï¼‰$å°†$h+râ‰ˆt$è½¬æ¢ä¸º(h+r-t)çš„L2èŒƒå¼çº¦ç­‰äºtheta_rçš„å¹³æ–¹ã€‚</li><li>ManifoldEæŠŠtè¿‘ä¼¼åœ°ä½äºæµå½¢ä½“ä¸Šï¼Œå³ä¸€ä¸ªä»¥h+rä¸ºä¸­å¿ƒåŠå¾„ä¸ºtheta_rçš„è¶…çƒä½“ï¼Œè€Œä¸æ˜¯æ¥è¿‘h+rçš„ç²¾ç¡®ç‚¹ã€‚</li></ul><h4 id="2-1-8-TransFæ¨¡å‹"><a href="#2-1-8-TransFæ¨¡å‹" class="headerlink" title="2.1.8 TransFæ¨¡å‹"></a>2.1.8 TransFæ¨¡å‹</h4><ul><li>TransFåªéœ€è¦tä¸h+rä½äºåŒä¸€ä¸ªæ–¹å‘ï¼ŒåŒæ—¶hä¸t-rä¹Ÿä½äºåŒä¸€ä¸ªæ–¹å‘ã€‚</li></ul><h4 id="2-1-9-TransAæ¨¡å‹"><a href="#2-1-9-TransAæ¨¡å‹" class="headerlink" title="2.1.9 TransAæ¨¡å‹"></a>2.1.9 TransAæ¨¡å‹</h4><ul><li><p>TransAæ¨¡å‹ä¸ºæ¯ä¸ªå…³ç³»rå¼•å…¥ä¸€ä¸ªå¯¹ç§°çš„éè´ŸçŸ©é˜µMrï¼Œå¹¶ä½¿ç”¨è‡ªé€‚åº”é©¬æ°è·ç¦»å®šä¹‰è¯„åˆ†å‡½æ•°ã€‚</p></li><li><p>é€šè¿‡å­¦ä¹ è·ç¦»åº¦é‡Mr, TransAåœ¨å¤„ç†å¤æ‚å…³ç³»æ—¶æ›´åŠ çµæ´»ã€‚</p><h5 id="é—®é¢˜ï¼š"><a href="#é—®é¢˜ï¼š" class="headerlink" title="é—®é¢˜ï¼š"></a>é—®é¢˜ï¼š</h5><ul><li>è¯„åˆ†å‡½æ•°åªé‡‡ç”¨L1æˆ–L2è·ç¦»ï¼Œçµæ´»æ€§ä¸å¤Ÿã€‚</li><li>è¯„åˆ†å‡½æ•°è¿‡äºç®€å•ï¼Œå®ä½“å’Œå…³ç³»å‘é‡çš„æ¯ä¸€ç»´ç­‰åŒè€ƒè™‘ã€‚</li></ul><h5 id="è§£å†³"><a href="#è§£å†³" class="headerlink" title="è§£å†³"></a>è§£å†³</h5><ul><li>æå‡ºTransAæ¨¡å‹ï¼Œå°†è¯„åˆ†å‡½æ•°ä¸­çš„è·ç¦»åº¦é‡æ”¹ç”¨é©¬æ°è·ç¦»ï¼Œå¹¶ä¸ºæ¯ä¸€ç»´å­¦ä¹ ä¸åŒçš„æƒé‡ã€‚</li></ul><h5 id="ç¤ºä¾‹"><a href="#ç¤ºä¾‹" class="headerlink" title="ç¤ºä¾‹"></a>ç¤ºä¾‹</h5><ul><li>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œ$( h_1, r_1, t_1)$å’Œ$(h_2,r_2,t_2)$ä¸¤ä¸ªåˆæ³•çš„äº‹å®ä¸‰å…ƒç»„ï¼Œt3æ˜¯é”™è¯¯çš„å°¾å®ä½“ã€‚å¦‚æœä½¿ç”¨æ¬§æ°è·ç¦»ï¼Œå¦‚å›¾(a)æ‰€ç¤ºï¼Œé”™è¯¯çš„å®ä½“t3ä¼šè¢«é¢„æµ‹å‡ºæ¥ã€‚è€Œå¦‚å›¾(b)æ‰€ç¤ºï¼ŒTransAæ¨¡å‹é€šè¿‡å¯¹å‘é‡ä¸åŒç»´åº¦è¿›è¡ŒåŠ æƒï¼Œæ­£ç¡®çš„å®ä½“ç”±äºåœ¨xè½´æˆ–è€…yè½´ä¸Šè·ç¦»è¾ƒè¿‘ï¼Œä»è€Œèƒ½å¤Ÿè¢«æ­£ç¡®é¢„æµ‹ã€‚</li></ul><p><img src="https://i.loli.net/2020/10/14/R5O6apo914qAnYG.png" alt="img"></p></li></ul><h3 id="2-2-é«˜æ–¯åµŒå…¥æ¨¡å‹"><a href="#2-2-é«˜æ–¯åµŒå…¥æ¨¡å‹" class="headerlink" title="2.2 é«˜æ–¯åµŒå…¥æ¨¡å‹"></a>2.2 é«˜æ–¯åµŒå…¥æ¨¡å‹</h3><h4 id="2-2-1-KG2Eæ¨¡å‹"><a href="#2-2-1-KG2Eæ¨¡å‹" class="headerlink" title="2.2.1 KG2Eæ¨¡å‹"></a>2.2.1 KG2Eæ¨¡å‹</h4><ul><li>çŸ¥è¯†åº“ä¸­çš„å…³ç³»å’Œå®ä½“çš„è¯­ä¹‰æœ¬èº«å…·æœ‰ä¸ç¡®å®šæ€§ï¼Œè€Œè¿‡å»æ¨¡å‹ä¸­éƒ½å¿½ç•¥è¿™ä¸ªå› ç´ ã€‚</li><li>KG2Eä½¿ç”¨é«˜æ–¯åˆ†å¸ƒæ¥è¡¨ç¤ºå®ä½“å’Œå…³ç³»ã€‚</li><li>å…¶ä¸­é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼è¡¨ç¤ºçš„æ˜¯å®ä½“æˆ–å…³ç³»åœ¨è¯­ä¹‰ç©ºé—´ä¸­çš„ä¸­å¿ƒä½ç½®ï¼Œè€Œé«˜æ–¯åˆ†å¸ƒçš„åæ–¹å·®åˆ™è¡¨ç¤ºè¯¥å®ä½“æˆ–å…³ç³»çš„ä¸ç¡®å®šåº¦ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022101036.png" alt="img"></p><blockquote><p>æ¯ä¸ªåœ†åœˆä»£è¡¨ä¸åŒå®ä½“ä¸å…³ç³»çš„è¡¨ç¤ºï¼Œå®ƒä»¬åˆ†åˆ«ä¸â€æ¯”å°”Â·å…‹æ—é¡¿â€æ„æˆä¸‰å…ƒç»„ï¼Œå…¶ä¸­åœ†åœˆå¤§å°è¡¨ç¤ºçš„æ˜¯ä¸åŒå®ä½“æˆ–å…³ç³»çš„ä¸ç¡®å®šåº¦ï¼Œå¯ä»¥çœ‹åˆ°â€å›½ç±â€çš„ä¸ç¡®å®šåº¦è¿œè¿œå¤§äºå…¶ä»–å…³ç³»ã€‚</p></blockquote><h4 id="TransGæ¨¡å‹"><a href="#TransGæ¨¡å‹" class="headerlink" title="TransGæ¨¡å‹"></a>TransGæ¨¡å‹</h4><ul><li>TransGä¹Ÿæ˜¯å¯¹é«˜æ–¯åˆ†å¸ƒçš„å®ä½“è¿›è¡Œäº†å»ºæ¨¡ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/640.png" alt="img"></p><ul><li>TransGæå‡ºä½¿ç”¨é«˜æ–¯æ··åˆæ¨¡å‹æè¿°å¤´ã€å°¾å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚è¯¥æ¨¡å‹è®¤ä¸ºï¼Œä¸€ä¸ªå…³ç³»ä¼šå¯¹åº”å¤šç§è¯­ä¹‰ï¼Œæ¯ç§è¯­ä¹‰ç”¨ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒæ¥åˆ»ç”»ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022101508.png" alt="img"></p><ul><li>ä¼ ç»Ÿæ¨¡å‹å’ŒTransGæ¨¡å‹æ¯”è¾ƒ</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022101740.png" alt="img"></p><blockquote><p>å…¶ä¸­ä¸‰è§’å½¢è¡¨ç¤ºæ­£ç¡®çš„å°¾å®ä½“ï¼Œåœ†å½¢è¡¨ç¤ºé”™è¯¯çš„å°¾å®ä½“ã€‚å›¾(a)ä¸­ä¸ºä¼ ç»Ÿæ¨¡å‹ç¤ºä¾‹ï¼Œç”±äºå°†å…³ç³»rçš„æ‰€æœ‰è¯­ä¹‰æ··ä¸ºä¸€è°ˆï¼Œå¯¼è‡´é”™è¯¯çš„å®ä½“æ— æ³•è¢«åŒºåˆ†å¼€ã€‚è€Œå›¾(b)æ‰€ç¤ºï¼ŒTransGæ¨¡å‹é€šè¿‡è€ƒè™‘å…³ç³»rçš„ä¸åŒè¯­ä¹‰ï¼Œå½¢æˆå¤šä¸ªé«˜æ–¯åˆ†å¸ƒï¼Œå°±èƒ½å¤ŸåŒºåˆ†å‡ºæ­£ç¡®å’Œé”™è¯¯å®ä½“ã€‚</p></blockquote><h2 id="3-è¯­ä¹‰åŒ¹é…æ¨¡å‹"><a href="#3-è¯­ä¹‰åŒ¹é…æ¨¡å‹" class="headerlink" title="3 è¯­ä¹‰åŒ¹é…æ¨¡å‹"></a>3 è¯­ä¹‰åŒ¹é…æ¨¡å‹</h2><ul><li>ä½¿ç”¨åŸºäºç›¸ä¼¼åº¦çš„è¯„åˆ†å‡½æ•°ã€‚</li><li>é€šè¿‡åŒ¹é…å®ä½“çš„æ½œåœ¨è¯­ä¹‰å’Œå‘é‡ç©ºé—´è¡¨ç¤ºä¸­åŒ…å«çš„å…³ç³»æ¥åº¦é‡äº‹å®çš„å¯ä¿¡æ€§ã€‚</li></ul><h3 id="3-1-RESCALæ¨¡å‹åŠå…¶æ‰©å±•"><a href="#3-1-RESCALæ¨¡å‹åŠå…¶æ‰©å±•" class="headerlink" title="3.1 RESCALæ¨¡å‹åŠå…¶æ‰©å±•"></a>3.1 RESCALæ¨¡å‹åŠå…¶æ‰©å±•</h3><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163554.png" alt="img" style="zoom: 67%;" /></p><h4 id="3-1-1-RESCALæ¨¡å‹"><a href="#3-1-1-RESCALæ¨¡å‹" class="headerlink" title="3.1.1 RESCALæ¨¡å‹"></a>3.1.1 RESCALæ¨¡å‹</h4><ul><li>RESCAL(åˆç§°åŒçº¿æ€§æ¨¡å‹)é€šè¿‡ä½¿ç”¨ä¸€ä¸ªå‘é‡è¡¨ç¤ºæ¯ä¸ªå®ä½“æ¥è·å¾—å®ƒçš„æ½œåœ¨è¯­ä¹‰ã€‚</li><li>æ¯ä¸ªå…³ç³»éƒ½è¡¨ç¤ºä¸ºä¸€ä¸ªçŸ©é˜µï¼Œè¯¥çŸ©é˜µå¯¹æ½œåœ¨å› ç´ ä¹‹é—´çš„æˆå¯¹äº¤äº’ä½œç”¨è¿›è¡Œäº†å»ºæ¨¡ã€‚å®ƒæŠŠäº‹å®$ï¼ˆh,r,tï¼‰$è¯„åˆ†å‡½æ•°å®šä¹‰ä¸ºä¸€ä¸ªåŒçº¿æ€§å‡½æ•°ã€‚</li></ul><h4 id="3-1-2-DistMultæ¨¡å‹"><a href="#3-1-2-DistMultæ¨¡å‹" class="headerlink" title="3.1.2 DistMultæ¨¡å‹"></a>3.1.2 DistMultæ¨¡å‹</h4><ul><li>DistMulté€šè¿‡å°†Mré™åˆ¶ä¸ºå¯¹è§’çŸ©é˜µæ¥ç®€åŒ–RESCALã€‚(Mrå…³ç³»çŸ©é˜µ)</li><li>è¯„åˆ†å‡½æ•°åªæ•è·æ²¿åŒä¸€ç»´åº¦çš„hå’Œtåˆ†é‡ä¹‹é—´çš„æˆå¯¹äº¤äº’ä½œç”¨(å‚é˜…å›¾5 b)ï¼Œå¹¶å°†æ¯ä¸€ä¸ªå…³ç³»çš„å‚æ•°æ•°é‡å‡å°‘è‡³O(d)ã€‚</li><li>ç„¶è€Œï¼Œå› ä¸ºå¯¹äºä»»æ„çš„hå’Œtï¼Œ$h^Tdiag(r)t = t^Tdiag(r)h$éƒ½æ˜¯æˆç«‹çš„ï¼Œè¿™ç§è¿‡åº¦ç®€åŒ–çš„æ¨¡å‹<strong>åªèƒ½å¤„ç†å¯¹ç§°çš„å…³ç³»</strong>ï¼Œè¿™æ˜¾ç„¶å¯¹äºä¸€èˆ¬çš„KGsæ˜¯ä¸èƒ½å®Œå…¨é€‚ç”¨çš„ã€‚</li></ul><h4 id="3-1-3-HolEæ¨¡å‹"><a href="#3-1-3-HolEæ¨¡å‹" class="headerlink" title="3.1.3 HolEæ¨¡å‹"></a>3.1.3 HolEæ¨¡å‹</h4><ul><li>HolEå°†RESCALçš„è¡¨è¾¾èƒ½åŠ›ä¸DistMultçš„æ•ˆç‡å’Œç®€å•æ€§ç›¸ç»“åˆã€‚</li><li>æŠŠå®ä½“å’Œå…³ç³»éƒ½è¡¨ç¤ºä¸º$R_d$ä¸­çš„å‘é‡ã€‚ç»™å®šä¸€ä¸ªäº‹å®$(h,r,t)$ï¼Œé¦–å…ˆä½¿ç”¨å¾ªç¯ç›¸å…³æ“ä½œå°†å®ä½“è¡¨ç¤ºå½¢å¼ç»„æˆ$h*tâˆˆR$ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022104059.png" alt="img"></p><ul><li>ç„¶åå°†ç»„åˆå‘é‡ä¸å…³ç³»è¡¨ç¤ºå½¢å¼åŒ¹é…ï¼Œä»¥å¯¹äº‹å®è¿›è¡Œè¯„åˆ†ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/640-20201022104132055.png" alt="img"></p><ul><li>å¾ªç¯ç›¸å…³å¯¹æˆå¯¹çš„ç›¸äº’ä½œç”¨è¿›è¡Œå‹ç¼©ã€‚å› æ­¤ï¼ŒHolEå¯¹æ¯ä¸ªå…³ç³»åªéœ€è¦$O(d)$å‚æ•°ï¼Œè¿™æ¯”RESCALæ›´æœ‰æ•ˆã€‚ä¸æ­¤åŒæ—¶ï¼Œå› ä¸ºå¾ªç¯ç›¸å…³æ˜¯ä¸ç¬¦åˆäº¤æ¢å¾‹çš„ï¼Œå³$h<em>t$ä¸ç­‰äº$t</em>h$ã€‚æ‰€ä»¥HolEèƒ½å¤ŸåƒRESCALé‚£æ ·<strong>å¯¹ä¸å¯¹ç§°å…³ç³»è¿›è¡Œå»ºæ¨¡</strong>ã€‚</li></ul><h4 id="3-1-4-ComplExæ¨¡å‹"><a href="#3-1-4-ComplExæ¨¡å‹" class="headerlink" title="3.1.4 ComplExæ¨¡å‹"></a>3.1.4 ComplExæ¨¡å‹</h4><ul><li>ComplExé€šè¿‡å¼•å…¥å¤å€¼åµŒå…¥æ¥æ‰©å±•DistMultï¼Œä»¥ä¾¿æ›´å¥½åœ°å¯¹éå¯¹ç§°å…³ç³»è¿›è¡Œå»ºæ¨¡ã€‚</li><li>åœ¨ComplExä¸­ï¼Œå®ä½“å’Œå…³ç³»åµŒå…¥hï¼Œr, tä¸å†å­˜åœ¨äºå®ç©ºé—´ä¸­ï¼Œè€Œæ˜¯å­˜åœ¨äºå¤ç©ºé—´ä¸­ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163603.png" alt="img" style="zoom:150%;" /></p><blockquote><p> è¯„åˆ†å‡½æ•°</p><p>è¿™ä¸ªè¯„åˆ†å‡½æ•°ä¸å†æ˜¯å¯¹ç§°çš„ï¼Œæ¥è‡ªéå¯¹ç§°å…³ç³»çš„äº‹å®å¯ä»¥æ ¹æ®æ¶‰åŠå®ä½“çš„é¡ºåºå¾—åˆ°ä¸åŒçš„åˆ†æ•°ã€‚</p></blockquote><h4 id="3-1-5-ANALOGYæ¨¡å‹"><a href="#3-1-5-ANALOGYæ¨¡å‹" class="headerlink" title="3.1.5 ANALOGYæ¨¡å‹"></a>3.1.5 ANALOGYæ¨¡å‹</h4><ul><li>ANALOGY æ‰©å±•äº†RESCALï¼Œä»è€Œè¿›ä¸€æ­¥å¯¹å®ä½“å’Œå…³ç³»çš„ç±»æ¯”å±æ€§è¿›è¡Œå»ºæ¨¡ã€‚</li><li>å®ƒéµå¾ªRESCALå¹¶ä½¿ç”¨åŒçº¿æ€§è¯„åˆ†å‡½æ•°ã€‚</li><li>å°½ç®¡ANALOGYè¡¨ç¤ºå…³ç³»ä¸ºçŸ©é˜µï¼Œè¿™äº›çŸ©é˜µå¯ä»¥åŒæ—¶å¯¹è§’åŒ–æˆä¸€ç»„ç¨€ç–çš„å‡†å¯¹è§’çŸ©é˜µï¼Œç”±æ¯ä¸ªåªæœ‰$O(d)$è‡ªç”±å‚æ•°ã€‚</li></ul><h3 id="3-2-åŸºäºç¥ç»ç½‘ç»œåŒ¹é…"><a href="#3-2-åŸºäºç¥ç»ç½‘ç»œåŒ¹é…" class="headerlink" title="3.2 åŸºäºç¥ç»ç½‘ç»œåŒ¹é…"></a>3.2 åŸºäºç¥ç»ç½‘ç»œåŒ¹é…</h3><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022110857.png" style="zoom:80%;" /></p><h4 id="3-2-1-è¯­ä¹‰åŒ¹é…èƒ½é‡æ¨¡å‹-SME"><a href="#3-2-1-è¯­ä¹‰åŒ¹é…èƒ½é‡æ¨¡å‹-SME" class="headerlink" title="3.2.1 è¯­ä¹‰åŒ¹é…èƒ½é‡æ¨¡å‹(SME)"></a>3.2.1 è¯­ä¹‰åŒ¹é…èƒ½é‡æ¨¡å‹(SME)</h4><ul><li>SMEé‡‡ç”¨ç¥ç»ç½‘ç»œç»“æ„è¿›è¡Œè¯­ä¹‰åŒ¹é…ã€‚</li><li>ç»™å®šä¸€ä¸ªäº‹å®ä¸‰å…ƒç»„$ï¼ˆh,r,tï¼‰$ï¼Œå®ƒé¦–å…ˆå°†å®ä½“å’Œå…³ç³»æŠ•å½±åˆ°è¾“å…¥å±‚ä¸­çš„åµŒå…¥å‘é‡ã€‚ç„¶åï¼Œå°†å…³ç³»rä¸å¤´å®ä½“hç»„åˆå¾—åˆ°$g_u(h,r)$ï¼Œå¹¶ä¸å°¾å®ä½“tç»„åˆï¼Œå¾—åˆ°éšè—å±‚ä¸­çš„$g_v(t,r)$ã€‚åˆ™è¯¥äº‹å®çš„åˆ†æ•°æœ€ç»ˆç”±å®ƒä»¬çš„ç‚¹ç§¯å®šä¹‰ä¸ºåŒ¹é…çš„$g_u$å’Œ$g_v$ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022104846.png" style="zoom:150%;" /></p><ul><li>SMEæœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼šçº¿æ€§ç‰ˆæœ¬å’ŒåŒçº¿æ€§ç‰ˆæœ¬ã€‚</li></ul><h4 id="3-2-2-ç¥ç»å¼ é‡ç½‘ç»œæ¨¡å‹-NTN"><a href="#3-2-2-ç¥ç»å¼ é‡ç½‘ç»œæ¨¡å‹-NTN" class="headerlink" title="3.2.2 ç¥ç»å¼ é‡ç½‘ç»œæ¨¡å‹(NTN)"></a>3.2.2 ç¥ç»å¼ é‡ç½‘ç»œæ¨¡å‹(NTN)</h4><ul><li>NTNæ˜¯å¦å¤–ä¸€ç§ç¥ç»ç½‘ç»œç»“æ„ï¼Œç»™å®šä¸€ä¸ªäº‹å®ï¼Œå®ƒé¦–å…ˆå°†å®ä½“æŠ•å½±åˆ°è¾“å…¥å±‚ä¸­çš„åµŒå…¥å‘é‡ã€‚ç„¶åï¼Œå°†è¿™ä¸¤ä¸ªå®ä½“h,tç”±å…³ç³»ç‰¹æœ‰çš„å¼ é‡$M_r$(ä»¥åŠå…¶ä»–å‚æ•°)ç»„åˆï¼Œå¹¶æ˜ å°„åˆ°ä¸€ä¸ªéçº¿æ€§éšè—å±‚ã€‚æœ€åï¼Œä¸€ä¸ªç‰¹å®šäºå…³ç³»çš„çº¿æ€§è¾“å‡ºå±‚ç»™å‡ºäº†è¯„åˆ†ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022110255.png" alt="img"></p><ul><li>å°½ç®¡NTNæ˜¯è¿„ä»Šä¸ºæ­¢æœ€å…·è¡¨è¾¾èƒ½åŠ›çš„æ¨¡å‹ï¼Œä½†æ˜¯ï¼Œç”±äºå®ƒçš„æ¯ä¸ªå…³ç³»çš„éœ€è¦O(d^2*k)ä¸ªå‚æ•°ï¼Œå¹¶ä¸”ä¸èƒ½ç®€å•æœ‰æ•ˆåœ°å¤„ç†å¤§å‹çš„KGsã€‚</li></ul><h4 id="3-2-3-å¤šå±‚æ„ŸçŸ¥æœº-MLP"><a href="#3-2-3-å¤šå±‚æ„ŸçŸ¥æœº-MLP" class="headerlink" title="3.2.3 å¤šå±‚æ„ŸçŸ¥æœº(MLP)"></a>3.2.3 å¤šå±‚æ„ŸçŸ¥æœº(MLP)</h4><ul><li>MLPæ˜¯ä¸€ç§æ›´ç®€å•çš„æ–¹æ³•ï¼Œåœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæ¯ä¸ªå…³ç³»(ä»¥åŠå®ä½“)éƒ½æ˜¯ç”±ä¸€ä¸ªå‘é‡ç»„åˆè€Œæˆçš„ã€‚</li><li>ç»™å®šä¸€ä¸ªäº‹å®$ï¼ˆh,r,tï¼‰$å°†åµŒå…¥å‘é‡hã€rå’Œtè¿æ¥åœ¨è¾“å…¥å±‚ä¸­ï¼Œå¹¶æ˜ å°„åˆ°éçº¿æ€§çš„éšè—å±‚ã€‚ç„¶åç”±çº¿æ€§è¾“å‡ºå±‚ç”Ÿæˆåˆ†æ•°ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163615.png" alt="img"></p><blockquote><p>å…¶ä¸­$M_1ã€M_2ã€M_3$æ˜¯ç¬¬ä¸€å±‚çš„æƒé‡ï¼Œwæ˜¯ç¬¬äºŒå±‚çš„æƒé‡ï¼Œè¿™äº›éƒ½æ˜¯åœ¨ä¸åŒçš„å…³ç³»ä¸­å…±äº«çš„ã€‚</p></blockquote><h4 id="3-2-4-ç¥ç»å…³è”æ¨¡å‹-NAM"><a href="#3-2-4-ç¥ç»å…³è”æ¨¡å‹-NAM" class="headerlink" title="3.2.4 ç¥ç»å…³è”æ¨¡å‹(NAM)"></a>3.2.4 ç¥ç»å…³è”æ¨¡å‹(NAM)</h4><ul><li>NAMä½¿ç”¨â€œæ·±åº¦â€æ¶æ„è¿›è¡Œè¯­ä¹‰åŒ¹é…ï¼Œç»™å®šä¸€ä¸ªäº‹å®ï¼Œå®ƒé¦–å…ˆå°†å¤´å®ä½“çš„åµŒå…¥å‘é‡å’Œè¾“å…¥å±‚ä¸­çš„å…³ç³»è¿æ¥èµ·æ¥ï¼Œä»è€Œç»™å‡º$z_0=[h,r]$ã€‚ç„¶åè¾“å…¥$z_0$è¾“å…¥åˆ°ä¸€ä¸ªç”±Lä¸ªçº¿æ€§éšå±‚ç»„æˆçš„æ·±ç¥ç»ç½‘ç»œä¸­ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022110719.png" alt="img"></p><blockquote><p>å…¶ä¸­$M<em>(l)$å’Œb</em>(l)åˆ†åˆ«è¡¨ç¤ºç¬¬lå±‚çš„æƒé‡çŸ©é˜µå’Œåå·®ã€‚</p></blockquote><ul><li>åœ¨å‰é¦ˆè¿‡ç¨‹ä¹‹åï¼Œé€šè¿‡åŒ¹é…æœ€åä¸€ä¸ªéšè—å±‚çš„è¾“å‡ºå’Œå°¾å®ä½“çš„åµŒå…¥å‘é‡æ¥ç»™å‡ºåˆ†æ•°ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022110834.png" alt="img"></p><h2 id="4-èåˆé™„åŠ ä¿¡æ¯"><a href="#4-èåˆé™„åŠ ä¿¡æ¯" class="headerlink" title="4 èåˆé™„åŠ ä¿¡æ¯"></a>4 èåˆé™„åŠ ä¿¡æ¯</h2><ul><li>ç›®å‰ä»‹ç»çš„æ–¹æ³•ä»…ä½¿ç”¨KGä¸­è§‚å¯Ÿåˆ°çš„äº‹å®æ¥æ‰§è¡ŒåµŒå…¥ä»»åŠ¡ã€‚äº‹å®ä¸Šï¼Œå¯ä»¥åˆå¹¶è®¸å¤šé™„åŠ ä¿¡æ¯æ¥è¿›ä¸€æ­¥æ”¹è¿›ä»»åŠ¡ï¼Œä¾‹å¦‚å®ä½“ç±»å‹ã€å…³ç³»è·¯å¾„ã€æ–‡æœ¬æè¿°ä»¥åŠé€»è¾‘è§„åˆ™ã€‚</li></ul><h3 id="4-1-å®ä½“ç±»å‹"><a href="#4-1-å®ä½“ç±»å‹" class="headerlink" title="4.1 å®ä½“ç±»å‹"></a>4.1 å®ä½“ç±»å‹</h3><ul><li>å³å®ä½“æ‰€å±çš„è¯­ä¹‰ç±»åˆ«ã€‚</li><li>å®ä½“ç±»å‹ä¹Ÿå¯ä»¥ä½œä¸ºä¸åŒå…³ç³»çš„å¤´éƒ¨å’Œå°¾éƒ¨ä½ç½®çš„çº¦æŸï¼Œä¾‹å¦‚å…³ç³»DirectorOfçš„å¤´å®ä½“çš„ç±»å‹åº”è¯¥æ˜¯äººï¼Œå°¾å®ä½“çš„ç±»å‹åº”è¯¥æ˜¯ç”µå½±ä½œå“ã€‚</li></ul><h4 id="4-1-1è¯­ä¹‰å¹³æ»‘åµŒå…¥-SSE-æ¨¡å‹"><a href="#4-1-1è¯­ä¹‰å¹³æ»‘åµŒå…¥-SSE-æ¨¡å‹" class="headerlink" title="4.1.1è¯­ä¹‰å¹³æ»‘åµŒå…¥(SSE)æ¨¡å‹"></a>4.1.1è¯­ä¹‰å¹³æ»‘åµŒå…¥(SSE)æ¨¡å‹</h4><ul><li><p>å®ƒè¦æ±‚ç›¸åŒç±»å‹çš„å®ä½“åœ¨åµŒå…¥ç©ºé—´ä¸­å½¼æ­¤é‚»è¿‘ã€‚</p></li><li><p>SSEé‡‡ç”¨ä¸¤ç§æµå½¢å­¦ä¹ ç®—æ³•ï¼Œå³æ‹‰æ™®æ‹‰æ–¯ç‰¹å¾æ˜ å°„å’Œå±€éƒ¨çº¿æ€§åµŒå…¥æ¥å¯¹è¿™ç§å…‰æ»‘æ€§å‡è®¾è¿›è¡Œå»ºæ¨¡ã€‚</p><blockquote><p>æ‹‰æ™®æ‹‰æ–¯ç‰¹å¾æ˜ å°„ï¼šè¦æ±‚ä¸€ä¸ªå®ä½“å’ŒåŒä¸€ç±»åˆ«ä¸­çš„æ¯ä¸€ä¸ªå…¶ä»–å®ä½“é‚»è¿‘ã€‚</p><p>å±€éƒ¨çº¿æ€§åµŒå…¥ï¼šä¸€ä¸ªå®ä½“è§†ä¸ºå…¶æœ€è¿‘é‚»å±…çš„çº¿æ€§ç»„åˆï¼Œå³åŒä¸€ç±»åˆ«å†…çš„å®ä½“ã€‚</p></blockquote></li><li><p>SSEçš„ä¸€ä¸ªä¸»è¦é™åˆ¶æ˜¯å®ƒå‡è®¾å®ä½“çš„è¯­ä¹‰èŒƒç•´æ˜¯æ— å±‚æ¬¡çš„ï¼Œæ¯ä¸ªå®ä½“å®Œå…¨å±äºä¸€ä¸ªç±»åˆ«ã€‚æ˜¾ç„¶ï¼Œåœ¨å…¸å‹çš„ç°å®ä¸–ç•Œä¸­ï¼Œæƒ…å†µå¹¶éå¦‚æ­¤ã€‚</p></li></ul><h4 id="4-1-2-TKRLæ¨¡å‹"><a href="#4-1-2-TKRLæ¨¡å‹" class="headerlink" title="4.1.2 TKRLæ¨¡å‹"></a>4.1.2 TKRLæ¨¡å‹</h4><ul><li>å®ƒå¯ä»¥å¤„ç†åˆ†å±‚å®ä½“ç±»åˆ«å’Œå¤šä¸ªç±»åˆ«æ ‡ç­¾ã€‚</li><li>TKRLæ˜¯ä¸€ä¸ªå…·æœ‰ç‰¹å®šç±»å‹å®ä½“æŠ•å½±çš„å¹³ç§»è·ç¦»æ¨¡å‹ã€‚ç»™å®šä¸€ä¸ªäº‹å®$(h,r,t)$ï¼Œå®ƒé¦–å…ˆç”¨ç‰¹å®šç±»å‹çš„æŠ•å½±çŸ©é˜µé¢„æµ‹hå’Œtï¼Œç„¶åå°†rå»ºæ¨¡ä¸ºä¸¤ä¸ªæŠ•å½±å®ä½“ä¹‹é—´çš„å¹³ç§»ã€‚</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022112809.png" alt="img"></p><blockquote><p>è¯„åˆ†å‡½æ•°</p><p>å…¶ä¸­$M_rh$å’Œ$M_rt$æ˜¯hå’Œtçš„æŠ•å½±çŸ©é˜µï¼Œä¸ºäº†å¤„ç†å¤šä¸ªç±»åˆ«æ ‡ç­¾ï¼Œ$M_r$hè¡¨ç¤ºä¸ºæ‰€æœ‰å¯èƒ½çš„ç±»å‹çŸ©é˜µçš„åŠ æƒå’Œã€‚</p></blockquote><ul><li>è™½ç„¶TKRLåœ¨é“¾è·¯é¢„æµ‹å’Œä¸‰å…ƒç»„åˆ†ç±»ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œä½†ç”±äºå®ƒå°†æ¯ä¸ªç±»åˆ«ä¸ç‰¹å®šçš„æŠ•å½±çŸ©é˜µç›¸å…³è”ï¼Œå› æ­¤å…·æœ‰è¾ƒé«˜çš„ç©ºé—´å¤æ‚åº¦ã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡é˜…è¯» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> KG </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
