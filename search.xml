<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>迁移微信聊天记录至移动硬盘</title>
      <link href="/2023/01/23/%E8%BF%81%E7%A7%BB%E5%BE%AE%E4%BF%A1%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95%E8%87%B3%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98/"/>
      <url>/2023/01/23/%E8%BF%81%E7%A7%BB%E5%BE%AE%E4%BF%A1%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95%E8%87%B3%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98/</url>
      
        <content type="html"><![CDATA[<h3 id="1-定位到聊天记录备份文件夹"><a href="#1-定位到聊天记录备份文件夹" class="headerlink" title="1. 定位到聊天记录备份文件夹"></a>1. 定位到聊天记录备份文件夹</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /Users/maqi/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/Backup</span><br></pre></td></tr></table></figure><h3 id="2-迁移至移动硬盘"><a href="#2-迁移至移动硬盘" class="headerlink" title="2. 迁移至移动硬盘"></a>2. 迁移至移动硬盘</h3><p><code>command+c</code>复制里面的32位字符的文件夹，<code>command+shift+v</code>移动文件夹到移动硬盘的任意文件夹中。<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301231115991.png" alt=""></p><h3 id="3-创建软连接"><a href="#3-创建软连接" class="headerlink" title="3. 创建软连接"></a>3. 创建软连接</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /Volumes/移动硬盘的路径/32位字符文件夹 /Users/maqi/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/Backup</span><br></pre></td></tr></table></figure><h3 id="4-重新签名微信"><a href="#4-重新签名微信" class="headerlink" title="4. 重新签名微信"></a>4. 重新签名微信</h3><p>退出微信，在终端app中输入下面的内容并回车。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo codesign --sign - --force --deep /Applications/WeChat.app</span><br></pre></td></tr></table></figure><br>再次打开微信点击查看备份文件，会要求授权，同意之后就可以随意的备份了！</p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微信 </tag>
            
            <tag> 微信聊天记录备份 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NEU-LAB服务器配置</title>
      <link href="/2023/01/20/NEU-LAB%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/"/>
      <url>/2023/01/20/NEU-LAB%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="197-219-216-64-197"><a href="#197-219-216-64-197" class="headerlink" title="197 - 219.216.64.197"></a>197 - 219.216.64.197</h2><blockquote><p>两张 A6000</p></blockquote><h3 id="端口管理"><a href="#端口管理" class="headerlink" title="端口管理"></a>端口管理</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-port=7030/tcp --permanent</span><br><span class="line">sudo firewall-cmd --zone=public --add-port=7031/tcp --permanent</span><br><span class="line">sudo firewall-cmd --zone=public --add-port=7032/tcp --permanent</span><br><span class="line">sudo firewall-cmd --zone=public --add-port=80/tcp --permanent</span><br><span class="line">sudo firewall-cmd --zone=public --add-port=22/tcp --permanent</span><br><span class="line">sudo firewall-cmd --zone=public --add-port=21/tcp --permanent</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 重新载入配置</span></span><br><span class="line">sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><h3 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h3><h4 id="配置"><a href="#配置" class="headerlink" title="配置:"></a>配置:</h4><p><strong>问题描述:</strong><br>NVIDIA RTX A6000 with CUDA capability sm_86 is not compatible with the current PyTorch ins.</p><p><strong>问题解决:</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch==<span class="number">1.10</span><span class="number">.0</span>+cu113 torchvision==<span class="number">0.11</span><span class="number">.1</span>+cu113 torchaudio==<span class="number">0.10</span><span class="number">.0</span>+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html</span><br></pre></td></tr></table></figure></p><h4 id="测试："><a href="#测试：" class="headerlink" title="测试："></a>测试：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.cuda.is_available()</span><br><span class="line"><span class="comment"># 返回True 接着用下列代码进一步测试</span></span><br><span class="line">torch.zeros(<span class="number">1</span>).cuda()</span><br></pre></td></tr></table></figure><h3 id="创建只读用户"><a href="#创建只读用户" class="headerlink" title="创建只读用户"></a>创建只读用户</h3><h4 id="1-创建用户和登录shell"><a href="#1-创建用户和登录shell" class="headerlink" title="1. 创建用户和登录shell"></a>1. 创建用户和登录shell</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo useradd -d /data0/gpu_monitor -s /bin/bash -m gpu_monitor</span><br><span class="line">sudo passwd gpu_monitor</span><br><span class="line"><span class="meta">#</span><span class="bash"> 密码</span></span><br><span class="line">neu.</span><br></pre></td></tr></table></figure><h4 id="2-创建用户shell执行命令目录"><a href="#2-创建用户shell执行命令目录" class="headerlink" title="2. 创建用户shell执行命令目录"></a>2. 创建用户shell执行命令目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /data0/gpu_monitor/.bin</span><br></pre></td></tr></table></figure><h4 id="3-root修改用户的shell配置文件"><a href="#3-root修改用户的shell配置文件" class="headerlink" title="3. root修改用户的shell配置文件"></a>3. root修改用户的shell配置文件</h4><p>root用户修改配置文件权限<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo chown root. /data0/gpu_monitor/.profile</span><br><span class="line">sudo chmod 755 /data0/gpu_monitor/.profile</span><br></pre></td></tr></table></figure></p><p>修改bash配置文件，这一步就是为了让新建用户引用新的shell脚本目录，这样用户可以使用哪些命令就往里面加哪些，可以自己控制。把原来的PATH路径注释掉，使用新的PATH路径。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /data0/gpu_monitor/.profile</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 末尾添加</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> PATH=<span class="variable">$PATH</span>:<span class="variable">$HOME</span>/.bin:<span class="variable">$HOME</span>/bin <span class="comment"># 把原来的PATH路径注释掉，使用新的PATH路径。</span></span></span><br><span class="line"></span><br><span class="line">PATH=$HOME/.bin</span><br><span class="line">export PATH</span><br></pre></td></tr></table></figure></p><h4 id="4-root用户将允许执行的命令链接到-HOME-bin目录"><a href="#4-root用户将允许执行的命令链接到-HOME-bin目录" class="headerlink" title="4. root用户将允许执行的命令链接到$HOME/.bin目录"></a>4. root用户将允许执行的命令链接到$HOME/.bin目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /usr/bin/wc /data0/gpu_monitor/.bin/wc  </span><br><span class="line">sudo ln -s /usr/bin/tail /data0/gpu_monitor/.bin/tail  </span><br><span class="line">sudo ln -s /bin/more /data0/gpu_monitor/.bin/more  </span><br><span class="line">sudo ln -s /bin/cat /data0/gpu_monitor/.bin/cat  </span><br><span class="line">sudo ln -s /bin/grep /data0/gpu_monitor/.bin/grep  </span><br><span class="line">sudo ln -s /bin/find /data0/gpu_monitor/.bin/find  </span><br><span class="line">sudo ln -s /bin/pwd /data0/gpu_monitor/.bin/pwd  </span><br><span class="line">sudo ln -s /bin/ls /data0/gpu_monitor/.bin/ls  </span><br><span class="line">sudo ln -s /bin/less /data0/gpu_monitor/.bin/less  </span><br><span class="line">sudo ln -s /bin/tar /data0/gpu_monitor/.bin/tar</span><br></pre></td></tr></table></figure><h4 id="5-切换到只读账号使环境变量生效"><a href="#5-切换到只读账号使环境变量生效" class="headerlink" title="5. 切换到只读账号使环境变量生效"></a>5. 切换到只读账号使环境变量生效</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">su gpu_monitor</span><br><span class="line"></span><br><span class="line">source /data0/gpu_monitor/.profile</span><br></pre></td></tr></table></figure><h4 id="6-更改文件夹权限"><a href="#6-更改文件夹权限" class="headerlink" title="6. 更改文件夹权限"></a>6. 更改文件夹权限</h4><p>如有指定文件夹权限的需要可使用<code>chmod</code>修改<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod a+rwx -R</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>服务器配置jupyter</title>
      <link href="/2023/01/10/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEjupyter/"/>
      <url>/2023/01/10/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEjupyter/</url>
      
        <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>安装 Jupyter 可以使用 Conda 或者 pip</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">conda install jupyter  <span class="comment"># 安装 jupyter</span></span><br><span class="line">conda install ipython   <span class="comment"># 安装 ipython</span></span><br><span class="line"></span><br><span class="line">pip install jupyter  <span class="comment"># 安装 jupyter</span></span><br><span class="line">pip install ipython   <span class="comment"># 安装 ipython</span></span><br><span class="line"></span><br><span class="line">jupyter-notebook --generate-config  <span class="comment"># 在家目录下生成配置文件</span></span><br><span class="line"><span class="comment"># 配置文件地址: /data0/maqi/.jupyter/jupyter_notebook_config.py</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入 jupyter --version 出现消息，代表安装成功</span></span><br></pre></td></tr></table></figure><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><h3 id="更改配置文件"><a href="#更改配置文件" class="headerlink" title="更改配置文件"></a>更改配置文件</h3><ol><li>生成密码<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd  </span><br><span class="line">passwd() <span class="comment">#输入密码并按回车确认</span></span><br><span class="line"><span class="comment"># 输入密码后，会生成秘钥，稍后用到，秘钥带上sha1</span></span><br></pre></td></tr></table></figure></li><li>修改配置<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;</span><br><span class="line">c.NotebookApp.allow_root = True</span><br><span class="line">c.NotebookApp.ip = &#x27;*&#x27;</span><br><span class="line">c.NotebookApp.notebook_dir = &#x27;/home/user/anaconda3/bin/jupyter&#x27;</span><br><span class="line">c.NotebookApp.open_browser = False</span><br><span class="line">c.NotebookApp.password = &#x27;生成的的密码 sha1..&#x27;</span><br><span class="line">c.NotebookApp.port = 7031</span><br><span class="line">c.NotebookApp.allow_remote_access = True</span><br><span class="line">&quot; &gt;&gt; /data0/maqi/.jupyter/jupyter_notebook_config.py  # jupyter配置文件的路径</span><br></pre></td></tr></table></figure></li></ol><h3 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h3><ol><li><p>开启端口</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 添加</span></span><br><span class="line">sudo firewall-cmd --zone=public --add-port=7031/tcp --permanent</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重新载入配置</span></span><br><span class="line">sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure></li><li><p>启动jupyter</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook</span><br><span class="line"></span><br><span class="line">nohup jupyter notebook &gt; jupyter.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></li><li><p>输入密码<br>密码为加密前的明文</p></li></ol><h3 id="更换内核为conda环境"><a href="#更换内核为conda环境" class="headerlink" title="更换内核为conda环境"></a>更换内核为conda环境</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 退出上一个添加过的虚拟环境</span><br><span class="line">conda deactivate</span><br><span class="line"> </span><br><span class="line">#进入想添加的环境</span><br><span class="line">conda activate pytorch</span><br><span class="line"> </span><br><span class="line"># 安装jupyter 和 notebook(这一步可能能省掉，没有测试，不确定)</span><br><span class="line">pip install jupyter notebook</span><br><span class="line"> </span><br><span class="line">#安装ipykernel，并进行相关操作</span><br><span class="line">pip install --user ipykernel</span><br><span class="line"> </span><br><span class="line">#若想多个环境集成，--user必填。有这个选项后配置文件皆写入到当前用户目录下，不受环境切换影响</span><br><span class="line">python -m ipykernel install --user --name=&quot;想展示的名字&quot;</span><br><span class="line"> </span><br><span class="line"># 查看jupyter是否已添加虚拟环境</span><br><span class="line">jupyter kernelspec list</span><br></pre></td></tr></table></figure><ol><li><p>查看内核</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(MTM) maqi@u747:~$jupyter kernelspec list</span><br><span class="line">Available kernels:</span><br><span class="line">  mtm        /data0/maqi/.local/share/jupyter/kernels/mtm</span><br><span class="line">  python3    /data0/maqi/.conda/envs/MTM/share/jupyter/kernels/python3</span><br></pre></td></tr></table></figure></li><li><p>查看内核配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /data0/maqi/.local/share/jupyter/kernels/mtm/kernel.json</span><br></pre></td></tr></table></figure></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> &quot;argv&quot;: [</span><br><span class="line">  &quot;/data0/maqi/.conda/envs/MTM/bin/python&quot;,</span><br><span class="line">  &quot;-m&quot;,</span><br><span class="line">  &quot;ipykernel_launcher&quot;,</span><br><span class="line">  &quot;-f&quot;,</span><br><span class="line">  &quot;&#123;connection_file&#125;&quot;</span><br><span class="line"> ],</span><br><span class="line"> &quot;display_name&quot;: &quot;MTM&quot;,</span><br><span class="line"> &quot;language&quot;: &quot;python&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>切换内核</li></ol><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301101531595.png" alt=""></p><h3 id="已配置"><a href="#已配置" class="headerlink" title="已配置"></a>已配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">http://219.216.64.197:7031</span><br><span class="line">123456</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jupyter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>服务器配置nginx</title>
      <link href="/2023/01/09/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEnginx/"/>
      <url>/2023/01/09/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AEnginx/</url>
      
        <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol><li><p>apt-get安装<a href="https://so.csdn.net/so/search?q=nginx&amp;spm=1001.2101.3001.7020">nginx</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 切换至root用户</span></span><br><span class="line">sudo su user</span><br><span class="line">sudo apt-get install nginx</span><br></pre></td></tr></table></figure></li><li><p>查看nginx是否安装成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -v</span><br></pre></td></tr></table></figure></li><li><p><a href="https://so.csdn.net/so/search?q=%E5%90%AF%E5%8A%A8nginx&amp;spm=1001.2101.3001.7020">启动nginx</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure></li><li><p>启动后，在网页重输入ip地址，即可看到nginx的欢迎页面。至此<a href="https://so.csdn.net/so/search?q=nginx%E5%AE%89%E8%A3%85&amp;spm=1001.2101.3001.7020">nginx安装</a>成功<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301091225775.png" alt=""></p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2></li><li><p>配置文件路径：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/nginx/nginx.conf </span><br></pre></td></tr></table></figure><p>配置<code>http&#123;&#125;</code>中的server</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost;</span><br><span class="line">    client_max_body_size 10M;</span><br><span class="line"></span><br><span class="line">    #charset koi8-r;</span><br><span class="line">    #access_log  /var/log/nginx/log/host.access.log  main;</span><br><span class="line"></span><br><span class="line">    error_page  404              /404.html;</span><br><span class="line"></span><br><span class="line">    error_page 405 =200 @405;</span><br><span class="line">    location @405 &#123;</span><br><span class="line">         root /usr/share/nginx/html;</span><br><span class="line">         proxy_method GET;</span><br><span class="line">         proxy_pass http://localhost;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    # redirect server error pages to the static page /50x.html</span><br><span class="line">    #</span><br><span class="line">    error_page   500 502 503 504  /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    root /data0/maqi/maqi_web/gpumonitor/dist;</span><br><span class="line">    location / &#123;</span><br><span class="line">            root /data0/maqi/maqi_web/gpumonitor/dist;</span><br><span class="line">            index index.html;</span><br><span class="line">            try_files $uri $uri/ /index.html;</span><br><span class="line">            expires -1;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>路径映射</p><blockquote><p><a href="obsidian://open?vault=SecondBrain&amp;file=%E5%B7%A5%E5%85%B7%26%E6%95%99%E7%A8%8B%2F%E4%BD%BF%E7%94%A8Nginx%E9%85%8D%E7%BD%AE%E5%90%8C%E4%B8%80%E7%AB%AF%E5%8F%A3%E8%AE%BF%E9%97%AE%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6">多路径映射</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location / &#123;</span><br><span class="line">            root /data0/maqi/maqi_web/gpumonitor/dist;</span><br><span class="line">            index index.html;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></blockquote></li><li><p>对配置文件进行校验<br>保存配置文件之后执行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -t</span><br></pre></td></tr></table></figure></li><li><p>重启nginx</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure></li></ol><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><ol><li><p><a href="https://so.csdn.net/so/search?q=%E5%90%AF%E5%8A%A8nginx&amp;spm=1001.2101.3001.7020">启动nginx</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure></li><li><p>重启nginx</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure></li><li><p>重新加载配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
            <tag> 开发工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法笔记-C++专题（更新中）</title>
      <link href="/2023/01/02/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0-C++%E4%B8%93%E9%A2%98/"/>
      <url>/2023/01/02/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0-C++%E4%B8%93%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="算法笔记-C-专题"><a href="#算法笔记-C-专题" class="headerlink" title="算法笔记-C++专题"></a>算法笔记-C++专题</h1><p>记录刷题过程中遇到的重要知识点和新知识！</p><h2 id="C-专题"><a href="#C-专题" class="headerlink" title="C++专题"></a>C++专题</h2><h3 id="小知识点"><a href="#小知识点" class="headerlink" title="小知识点"></a>小知识点</h3><h4 id="定义链表"><a href="#定义链表" class="headerlink" title="定义链表"></a>定义链表</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 单链表</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ListNode</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> val;  <span class="comment">// 节点上存储的元素</span></span><br><span class="line">    ListNode *next;  <span class="comment">// 指向下一个节点的指针</span></span><br><span class="line">    <span class="built_in">ListNode</span>(<span class="keyword">int</span> x) : <span class="built_in">val</span>(x), <span class="built_in">next</span>(<span class="literal">NULL</span>) &#123;&#125;  <span class="comment">// 节点的构造函数</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>初始化<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ListNode* head = new ListNode(5);</span><br></pre></td></tr></table></figure></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ListNode* head = new ListNode();</span><br><span class="line">head-&gt;val = 5;</span><br></pre></td></tr></table></figure><h4 id="最大最小值"><a href="#最大最小值" class="headerlink" title="最大最小值"></a>最大最小值</h4><pre><code>int maxval=INT_MIN; //最小值int minval= INT_MAX;</code></pre><h4 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a>数据类型转换</h4><p>int转striing</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int n=10;</span><br><span class="line">string s =to_string(n);</span><br></pre></td></tr></table></figure><p> string转int</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stoi(s)</span><br></pre></td></tr></table></figure><ul><li>atoi()和stoi()</li></ul><blockquote><p>atoi()的参数是 const char<em> ,因此对于一个字符串str我们必须调用 <strong>c_str()</strong>的方法把这个string转换成 const char\</em>类型的</p><p>而stoi()的参数是const string<em>,不需要转化为 const char\</em>；</p></blockquote><ul><li>空指针</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nullptr</span><br></pre></td></tr></table></figure><h4 id="选择子集"><a href="#选择子集" class="headerlink" title="选择子集"></a>选择子集</h4><ul><li>这里介绍一种用独热编码的形式选择子集的方法，时间复杂度较高，但做法还是比较巧妙，值得学习的。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">int start_num = 1&lt;&lt;n;//n位2进制编码 用来表示子集的选择情况</span><br><span class="line">        for(int i=0;i&lt;start_num;i++)&#123;</span><br><span class="line">            int temp=0;</span><br><span class="line">            for(int j=0;j&lt;n;j++)&#123;</span><br><span class="line">                if((i&gt;&gt;j)&amp;1==1)&#123;</span><br><span class="line">                    //如果当前位被选中</span><br><span class="line">                    // 做接下来的事情</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><blockquote><p>代码里可以直观的看到(n=8举例)</p><p>i 从 0000 0000 递增到 0000 0011 ——&gt;1111 1111（共2^n次循环）</p><p>在这个过程中 j 从 0到n，也就是说 i (0000 0011) 右移 0-n次，右移完成后与最低位 0000 0001做与运算，如果为1，说明当前位置被选中，也就是num[j]当前i的轮次被选中的元素。</p></blockquote><h4 id="向上取整"><a href="#向上取整" class="headerlink" title="向上取整"></a>向上取整</h4><ul><li>n/size() 向上取整</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(n + size - 1) / size; // -1 是为了避免整除情况结果1加1</span><br></pre></td></tr></table></figure><ul><li>向下取证</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int 类型即可</span><br></pre></td></tr></table></figure><h4 id="随机数"><a href="#随机数" class="headerlink" title="随机数"></a>随机数</h4><ul><li>随机种子</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">srand((unsigned)time(NULL));</span><br></pre></td></tr></table></figure><ul><li>随机数</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int index =rand()%n;</span><br></pre></td></tr></table></figure><ul><li>均匀分布的随机浮点数</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mt19937 gen&#123;random_device&#123;&#125;()&#125;;</span><br><span class="line">uniform_real_distribution&lt;double&gt; dis(a,b); //生成[a,b)范围的随机浮点数</span><br><span class="line"></span><br><span class="line">//用法</span><br><span class="line">double x = dis(gen), y = dis(gen);</span><br></pre></td></tr></table></figure><ul><li>正态分布 </li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">normal_distribution</span><br></pre></td></tr></table></figure><ul><li>二项分布</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bernoulli_distribution</span><br></pre></td></tr></table></figure><h4 id="判断字母-大小写转换"><a href="#判断字母-大小写转换" class="headerlink" title="判断字母 大小写转换"></a>判断字母 大小写转换</h4><ul><li>判断是字母</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">isalpha(temp)</span><br></pre></td></tr></table></figure><ul><li>转为小写字母</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tolower(&#x27;A&#x27;)</span><br></pre></td></tr></table></figure><h4 id="判断是否为数字"><a href="#判断是否为数字" class="headerlink" title="判断是否为数字"></a>判断是否为数字</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">isdigit(str)</span><br></pre></td></tr></table></figure><h4 id="判断字母大小写"><a href="#判断字母大小写" class="headerlink" title="判断字母大小写"></a>判断字母大小写</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">islower(&#x27;a&#x27;)</span><br><span class="line">isupper(word[1])</span><br></pre></td></tr></table></figure><h4 id="中位数"><a href="#中位数" class="headerlink" title="中位数"></a>中位数</h4><ul><li>对数组排序后 向下取整的下标就是中位数所在的下标</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = nums[n / 2]</span><br></pre></td></tr></table></figure><h4 id="取模"><a href="#取模" class="headerlink" title="取模"></a>取模</h4><p>c++ 取模长 需要将负数加模长变为正数再去求摸</p><pre><code>if(i&gt;0 &amp;&amp; (&#39;a&#39;-&#39;z&#39; +26 )%26==1 )</code></pre><h4 id="构建无向图"><a href="#构建无向图" class="headerlink" title="构建无向图"></a>构建无向图</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建无向图</span></span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">adj</span>(n);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">auto</span> i: edges)&#123;</span><br><span class="line">            adj[i[<span class="number">0</span>]].<span class="built_in">push_back</span>(i[<span class="number">1</span>]);</span><br><span class="line">            adj[i[<span class="number">1</span>]].<span class="built_in">push_back</span>(i[<span class="number">0</span>]);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h3 id="STL"><a href="#STL" class="headerlink" title="STL"></a>STL</h3><h4 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h4><ul><li><strong>c.begin()</strong> 返回一个迭代器，它指向容器c的第一个元素</li><li><strong>c.end()</strong> 返回一个迭代器，它指向容器c的最后一个元素的下一个位置</li><li><strong>c.rbegin()</strong> 返回一个逆序迭代器，它指向容器c的最后一个元素</li><li><strong>c.rend()</strong> 返回一个逆序迭代器，它指向容器c的第一个元素前面的位置</li><li><strong>*iter</strong>取当前迭代器的值</li></ul><h4 id="排序-sort"><a href="#排序-sort" class="headerlink" title="排序 sort()"></a>排序 sort()</h4><ul><li>排序的规则是首先按照单词的长度升序排序，如果单词的长度相同则按照字典序降序排序。</li><li>自定义sort函数，第一个参数需要排在第二个参数前面时返回true，表示不调整相关位置。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sort(words.begin(), words.end(), [](const string &amp; a, const string &amp; b) &#123;</span><br><span class="line">            if (a.size() != b.size()) &#123;</span><br><span class="line">                return a.size() &lt; b.size();</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                return a &gt; b;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure><ul><li>按绝对值排序 </li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sort(vals.begin(), vals.end(), [](int a, int b) &#123; return abs(a) &lt; abs(b); &#125;);//这样写可以省个函数名</span><br></pre></td></tr></table></figure><h4 id="反转-reverse"><a href="#反转-reverse" class="headerlink" title="反转 reverse()"></a>反转 reverse()</h4><blockquote><p>vector string 等反转使用</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reverse(nums.begin(),nums.end());//全部反转</span><br><span class="line">reverse(nums.begin(),nums.begin()+k);//反转头</span><br><span class="line">reverse(nums.begin()+k,nums.end());//反转尾</span><br></pre></td></tr></table></figure><p>源码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void reverse(vector&lt;int&gt;&amp; nums, int start, int end) &#123;</span><br><span class="line">        while (start &lt; end) &#123;</span><br><span class="line">            swap(nums[start], nums[end]);</span><br><span class="line">            start += 1;</span><br><span class="line">            end -= 1;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="最大值-最小值"><a href="#最大值-最小值" class="headerlink" title="最大值/最小值"></a>最大值/最小值</h4><ul><li>max_element(requests.begin(), requests.end())</li></ul><blockquote><p>返回数组requests 中[0, end)之间的最大值的迭代器，</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// *表示取迭代器的值</span><br><span class="line">int maxRequest = *max_element(requests.begin(), requests.end());</span><br></pre></td></tr></table></figure><ul><li>min_element(a, a+6)</li></ul><blockquote><p>返回的值减去数组头地址即为该最大值在数组的序号，即下标。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int loc = min_element(a, a+6) - a;</span><br><span class="line">int min_val = a[loc];</span><br></pre></td></tr></table></figure><p>如果要取最大最小值，直接用*取迭代器的值就行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*min_element(a, a+6)</span><br></pre></td></tr></table></figure><ul><li>例</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int minValue2 = *min_element(v.begin(), v.end());</span><br><span class="line">int maxValue2 = *max_element(v.begin(), v.end());</span><br></pre></td></tr></table></figure><h4 id="累加accumulate"><a href="#累加accumulate" class="headerlink" title="累加accumulate()"></a>累加accumulate()</h4><ul><li>累加求和</li></ul><blockquote><p>accumulate带有三个形参：头两个形参指定要累加的元素范围，第三个形参则是累加的初值。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int sum = accumulate(vec.begin() , vec.end() , 0);  </span><br></pre></td></tr></table></figure><blockquote><p> accumulate函数将它的一个内部变量设置为指定的初始值，然后在此初值上累加输入范围内所有元素的值。accumulate算法返回累加的结果，其返回类型就是其第三个实参的类型。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">string sum = accumulate(v.begin() , v.end() , string(&quot; &quot;));  </span><br><span class="line">// 这个函数调用的效果是：从空字符串开始，把vec里的每个元素连接成一个字符串。</span><br></pre></td></tr></table></figure><ul><li>自定义</li></ul><blockquote><p>与sort()类似 可自定义累加规则</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">struct Grade  </span><br><span class="line">&#123;  </span><br><span class="line">    string name;  </span><br><span class="line">    int grade;  </span><br><span class="line">&#125;;</span><br><span class="line">int sum = accumulate(subject, subject + 3, 0, [](int a, Grade b)&#123;return a + b.grade;&#125;); //a值是前面计算的中间结果</span><br></pre></td></tr></table></figure><h4 id="vector"><a href="#vector" class="headerlink" title="vector"></a>vector</h4><ul><li><strong>vector排序：</strong><code>sort(nums.begin(),nums.end());</code></li></ul><p>升序：<code>sort(vec.begin(), vec.end(), less&lt;int&gt;());</code></p><p>降序：<code>sort(vec.begin(), vec.end(), greater&lt;int&gt;());</code></p><ul><li><p><strong>vector数组的长度：</strong><code>vector.length;</code> 或者 <code>vector.size();</code></p></li><li><p><strong>初始化vector</strong></p><p><code>vector&lt;bool&gt; a(b.size(),false);</code></p><p><code>vector&lt;string&gt;  honor&#123;&quot;Gold Medal&quot;,&quot;Silver Medal&quot;,&quot;Bronze Medal&quot;&#125;;</code></p><p><strong>二维数组初始化</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;vector&lt;int&gt;&gt; dp(a.size(),vector&lt;int&gt;(n,0));</span><br><span class="line"></span><br><span class="line">dp[0][0]=0;//可以使用 该方式赋值 访问。</span><br></pre></td></tr></table></figure><p><strong>reserve</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vals.reserve(cnt.size());</span><br></pre></td></tr></table></figure></li><li><p>return</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">return &#123;&#125;; //返回空数组</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">return &#123;1,4&#125;;//快速返回数组 相当于初始化一个数组</span><br></pre></td></tr></table></figure><ul><li>反转 reverse()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reverse(num.begin(),num.end());</span><br></pre></td></tr></table></figure><ul><li>删除 erase()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num.erase(num.begin()+i*2+1-i);</span><br><span class="line">// 值得注意的是 删除后 数组的长度会发生变化</span><br><span class="line">num.erase(num.end()-1);</span><br></pre></td></tr></table></figure><ul><li>插入 insert()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//插入元素i到指定位置</span><br><span class="line">p.insert(p.begin(),i);</span><br></pre></td></tr></table></figure><ul><li>查找 find()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 查找元素i是否在p中出现 (注意返回的是迭代器)</span><br><span class="line">vector&lt;int&gt;::iterator it = find(p.begin(),p.end(),i);</span><br><span class="line">if (it==p.end())</span><br><span class="line">//不存在</span><br></pre></td></tr></table></figure><ul><li>下标 distance()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//it为迭代器 计算it指向元素的下标index</span><br><span class="line">int dis = distance(p.begin(), it);</span><br></pre></td></tr></table></figure><ul><li>清空 clear()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ret.clear();</span><br></pre></td></tr></table></figure><ul><li>拷贝 assign()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nums.assign(newArr.begin(), newArr.end());</span><br></pre></td></tr></table></figure><ul><li>最后一个下标</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nums.back()</span><br></pre></td></tr></table></figure><ul><li>重新设置大小 resize()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum.resize((n + size - 1) / size); // n/size 向上取整</span><br></pre></td></tr></table></figure><ul><li>删除最后一个元素 pop_back()</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nums.pop_back();</span><br></pre></td></tr></table></figure><h4 id="set和unordered-set"><a href="#set和unordered-set" class="headerlink" title="set和unordered_set"></a>set和unordered_set</h4><blockquote><p>哈希集合</p></blockquote><ul><li><strong>set和unordered_set</strong>：其中unordered_set对元素不进行排序</li></ul><p><strong>find(key)：</strong>查找以值为 key 的元素，如果找到，则返回一个指向该元素的正向迭代器；反之，则返回一个指向容器中最后一个元素之后位置的迭代器（如end() 方法返回的迭代器）。</p><p><strong>count(key)：</strong>在容器中查找值为 key 的元素的个数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">unordered_set&lt;string&gt; cnt;</span><br><span class="line">cnt.emplace(&quot;&quot;);</span><br><span class="line">if (cnt.count(word.substr(0, word.size() - 1))) &#123;</span><br><span class="line">     cnt.emplace(word);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>emplace() 插入</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnt.emplace(word);</span><br></pre></td></tr></table></figure><ul><li>insert() 插入</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnt.insert(root-&gt;val);</span><br></pre></td></tr></table></figure><ul><li>erase() 删除</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//删除 set 容器中值为 val 的元素</span><br><span class="line">size_type erase (const value_type&amp; val);</span><br><span class="line">//删除 position 迭代器指向的元素</span><br><span class="line">iterator  erase (const_iterator position);</span><br><span class="line">//删除 [first,last) 区间内的所有元素</span><br><span class="line">iterator  erase (const_iterator first, const_iterator last);</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;set&gt;</span><br><span class="line">#include &lt;string&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    //创建并初始化 set 容器</span><br><span class="line">    std::set&lt;int&gt;myset&#123;1,2,3,4,5&#125;;</span><br><span class="line">    cout &lt;&lt; &quot;myset size = &quot; &lt;&lt; myset.size() &lt;&lt; endl;</span><br><span class="line">   </span><br><span class="line">    //1) 调用第一种格式的 erase() 方法</span><br><span class="line">    int num = myset.erase(2); //删除元素 2，myset=&#123;1,3,4,5&#125;</span><br><span class="line">    cout &lt;&lt; &quot;1、myset size = &quot; &lt;&lt; myset.size() &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;num = &quot; &lt;&lt; num &lt;&lt; endl;</span><br><span class="line">    //2) 调用第二种格式的 erase() 方法</span><br><span class="line">    set&lt;int&gt;::iterator iter = myset.erase(myset.begin()); //删除元素 1，myset=&#123;3,4,5&#125;</span><br><span class="line">    cout &lt;&lt; &quot;2、myset size = &quot; &lt;&lt; myset.size() &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;iter-&gt;&quot; &lt;&lt; *iter &lt;&lt; endl;</span><br><span class="line">    //3) 调用第三种格式的 erase() 方法</span><br><span class="line">    set&lt;int&gt;::iterator iter2 = myset.erase(myset.begin(), --myset.end());//删除元素 3,4，myset=&#123;5&#125;</span><br><span class="line">    cout &lt;&lt; &quot;3、myset size = &quot; &lt;&lt; myset.size() &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;iter2-&gt;&quot; &lt;&lt; *iter2 &lt;&lt; endl;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>clear() 删除所有元素</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//清空 myset 容器</span><br><span class="line">myset.clear();</span><br></pre></td></tr></table></figure><h4 id="map和unordered-map"><a href="#map和unordered-map" class="headerlink" title="map和unordered_map"></a>map和unordered_map</h4><blockquote><p>哈希表</p></blockquote><p>map是有序的，红黑树实现。</p><p>unordered_map是无序的，内部实现了一个哈希表。</p><p>map int 初始值 0；</p><ul><li><strong>插入 insert()：</strong></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">order_list.insert(pair&lt;char, int&gt;(score[i], i));</span><br></pre></td></tr></table></figure><p>也可以通过键值对赋值：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">unordered_map&lt;int,int&gt; map;</span><br><span class="line">map[nums[i]]=i;</span><br></pre></td></tr></table></figure><ul><li><p><strong>删除 erase()</strong></p></li><li><p><strong>统计 count()：</strong></p></li></ul><blockquote><p>注意count()的参数是map的key</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//判断 order_list 中是否出现过 x</span><br><span class="line">order_list.count(x)</span><br><span class="line"></span><br><span class="line">index_set.count(list2[i]) &gt; 0 //表示该元素出现过</span><br></pre></td></tr></table></figure><ul><li><strong>遍历：</strong></li></ul><p>方法一：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">unordered_map&lt;string, int&gt; cnt;</span><br><span class="line">// &amp; 引用</span><br><span class="line">for (auto &amp; [key,val] : cnt) &#123;</span><br><span class="line">          if (key.substr(0, prefix.size()) == prefix) &#123;</span><br><span class="line">              res += val;</span><br><span class="line">          &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (auto &amp;[x, _] : map) &#123;</span><br><span class="line">   vals.push_back(x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>方法二：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">std::map&lt;int, TaskInfo*&gt;::iterator iter;</span><br><span class="line">for (iter=maps.begin(); iter!=maps.end(); iter++)</span><br><span class="line">   &#123;</span><br><span class="line">       printf(&quot;%d, %s&quot;, iter-&gt;first, iter-&gt;second);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>示例</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">unordered_map&lt;int,int&gt; map;</span><br><span class="line">       for(int i=0;i&lt;nums.size();i++)&#123;</span><br><span class="line">           if(map.count(target-nums[i])&gt;0)</span><br><span class="line">               return &#123;map[target-nums[i]],i&#125;;</span><br><span class="line">           else </span><br><span class="line">               map[nums[i]]=i;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><h4 id="advance-函数"><a href="#advance-函数" class="headerlink" title="advance()函数"></a>advance()函数</h4><p>advance() 函数用于将迭代器前进（或者后退）指定长度的距离，其语法格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">template &lt;class InputIterator, class Distance&gt;</span><br><span class="line">    void advance (InputIterator&amp; it, Distance n);</span><br><span class="line">    </span><br><span class="line">举例：</span><br><span class="line">list&lt;int&gt; lst(nums.begin(), nums.end());</span><br><span class="line">        for (int i = 0;i&lt;this-&gt;back.size();i++)</span><br><span class="line">            &#123;</span><br><span class="line">                // 使用list的迭代器</span><br><span class="line">                auto it = lst.begin();</span><br><span class="line">                // 选择随机数</span><br><span class="line">                int j = rand()%(lst.size());</span><br><span class="line">                cout&lt;&lt;j;</span><br><span class="line">                // 将迭代器向后移动j位</span><br><span class="line">                advance(it,j);</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><h4 id="string"><a href="#string" class="headerlink" title="string"></a>string</h4><ul><li>干货</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">int string::find(char);     // 字符串中找第一个字符的索引</span><br><span class="line">string string::substr(int); // 从当前索引开始的子串</span><br><span class="line">position=s.find(&quot;b&quot;,n);     //从字符串s 下标n开始，查找字符串b ,返回b 在s 中的下标</span><br><span class="line">没找到的话返回string::npos</span><br><span class="line">position = s.find(&quot;jkff&quot;);</span><br><span class="line">position != string::npos</span><br><span class="line">返回子串出现在母串中的首次出现的位置，和最后一次出现的位置:</span><br><span class="line">position = s.find_first_of(char);</span><br><span class="line">position = s.find_last_of(char);</span><br></pre></td></tr></table></figure><ul><li>初始化</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">string sgood=&quot;abs&quot;;</span><br><span class="line">string sgood_rev(sgood.rbegin(), sgood.rend());</span><br></pre></td></tr></table></figure><ul><li>反转</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reverse(ans.begin(), ans.end());</span><br><span class="line">或者</span><br><span class="line">string sgood=&quot;abs&quot;;</span><br><span class="line">string sgood_rev(sgood.rbegin(), sgood.rend());</span><br></pre></td></tr></table></figure><ul><li>截取字符串</li><li>substr(开始位置，数量)</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s.substr(left, right-left);//从left(包括)截取长度为right-left个字符 不包括右边界</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">word.substr(0, word.size())</span><br></pre></td></tr></table></figure><p>从indexa开始截断：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">string a1 = a.substr(indexa,a.size()-indexa);</span><br></pre></td></tr></table></figure><ul><li>查找字符串find()</li></ul><blockquote><p>查找字符串a是否包含子串b,不是用strA.find(strB) &gt; 0 而是 strA.find(strB) != string:npos。</p><p>其中string:npos是个特殊值，说明查找没有匹配。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(s + s).find(goal) != string::npos</span><br></pre></td></tr></table></figure><ul><li>查找字符第一次出现的位置</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int pos1 = str_log1.find_first_of(&quot; &quot;);</span><br></pre></td></tr></table></figure><ul><li>拼接字符串</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">string code;</span><br><span class="line">code.append(MORSE[c - &#x27;a&#x27;]);</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code +=&quot;aaa&quot;;</span><br></pre></td></tr></table></figure><ul><li>生成连续字符</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">string(cnt, &#x27;a&#x27;)</span><br></pre></td></tr></table></figure><h4 id="array"><a href="#array" class="headerlink" title="array"></a>array</h4><p>初始化</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">std::array&lt;int, 5&gt; arr = &#123;1, 2, 3, 4, 5&#125;;</span><br><span class="line">std::array&lt;double, 100&gt; data &#123;&#125;; //初始化为0.0</span><br><span class="line"></span><br><span class="line">values.fill(3.1415926); //通过调用数组对象的成员函数 fill()，可以将所有元素设成给定值。</span><br></pre></td></tr></table></figure><ul><li>空格分割字符串，使用stringstream</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">int main()&#123;</span><br><span class="line">    //用于存放分割后的字符串 </span><br><span class="line">    vector&lt;string&gt; res;</span><br><span class="line">    //待分割的字符串，含有很多空格 </span><br><span class="line">    string word=&quot;   Hello, I want   to learn C++!   &quot;;</span><br><span class="line">    //暂存从word中读取的字符串 </span><br><span class="line">    string result;</span><br><span class="line">    //将字符串读到input中 </span><br><span class="line">    stringstream input(word);</span><br><span class="line">    //依次输出到result中，并存入res中 </span><br><span class="line">    while(input&gt;&gt;result)</span><br><span class="line">        res.push_back(result);</span><br><span class="line">    //输出res </span><br><span class="line">    for(int i=0;i&lt;res.size();i++)&#123;</span><br><span class="line">        cout&lt;&lt;res[i]&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>字符串遍历</li></ul><blockquote><p>for (char ch: s)</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">unordered_map&lt;char, int&gt; c;</span><br><span class="line">for (char ch: s) &#123;</span><br><span class="line">       ++c[ch];</span><br><span class="line">     &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>isalnum(char c ) 判断是否是字母或数字</li><li>isalpha() 判断是否是字母</li><li>isdigit() 判断是否是数字</li><li>tolower() 转小写 ；touper() 转大写</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = tolower(a);</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">string ans;</span><br><span class="line">for(char c : s)&#123;</span><br><span class="line">      ans += tolower(c);</span><br><span class="line">   &#125;</span><br><span class="line">return ans;</span><br></pre></td></tr></table></figure><h4 id="优先队列-priority-queue"><a href="#优先队列-priority-queue" class="headerlink" title="优先队列 priority_queue"></a>优先队列 priority_queue</h4><ol><li>定义 <code>priority_queue&lt;Type, Container, Functional&gt;</code></li></ol><blockquote><p>STL里面默认用的是vector</p><p><a href="https://blog.csdn.net/weixin_36888577/article/details/79937886">引用</a></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">priority_queue&lt;pii, vector&lt;pii&gt;, greater&lt;pii&gt;&gt; pq;</span><br></pre></td></tr></table></figure><ol><li>方法</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pq.empty() </span><br><span class="line">pq.top()</span><br><span class="line">pq.emplace()</span><br><span class="line">pq.pop()</span><br></pre></td></tr></table></figure><p><strong>优先队列没有 insert() 方法</strong></p><ul><li>示例</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;&gt;&gt; busy; //greater 升序 队头最小</span><br><span class="line">//pair 插入，插入对应位置就行 不用make_pair()</span><br><span class="line">busy.emplace(arrival[i]+load[i],2);</span><br><span class="line">//当然 使用make_pair()也行</span><br><span class="line">busy.emplace(make_pair(arrival[i]+load[i],*machine));</span><br></pre></td></tr></table></figure><h4 id="pair"><a href="#pair" class="headerlink" title="pair"></a>pair</h4><p>配合vector使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;pair&lt;int, int&gt;&gt; arr;</span><br></pre></td></tr></table></figure><ul><li>make_pair(1,2)</li></ul><h4 id="stack"><a href="#stack" class="headerlink" title="stack"></a>stack</h4><ul><li><strong>栈是以底层容器完成其所有的工作，对外提供统一的接口，底层容器是可插拔的（也就是说我们可以控制使用哪种容器来实现栈的功能）。</strong></li><li>所以STL中栈往往不被归类为容器，而被归类为container adapter（容器适配器）。</li><li>栈的底层实现可以是vector，deque，list 都是可以的， 主要就是数组和链表的底层实现。</li><li>栈提供push 和 pop 等等接口，所有元素必须符合先进后出规则，所以栈不提供走访功能，也不提供迭代器(iterator)。 不像是set 或者map 提供迭代器iterator来遍历所有元素。</li><li>**SGI STL，如果没有指定底层实现的话，默认是以deque为缺省情况下栈的底层结构。deque是一个双向队列，只要封住一端，只开通另一端就可以实现栈的逻辑了。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stack&lt;int&gt; dataStack;</span><br><span class="line"></span><br><span class="line">stack&lt;int&gt; stack1,stack2;</span><br></pre></td></tr></table></figure><ul><li>push() 入栈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataStack.push(val);</span><br></pre></td></tr></table></figure><ul><li>pop() 出栈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataStack.pop()</span><br></pre></td></tr></table></figure><ul><li>top() 栈顶元素</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataStack.top()</span><br></pre></td></tr></table></figure><ul><li>empty() 判断是否为空栈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if(stack2.empty())</span><br></pre></td></tr></table></figure><h4 id="queue"><a href="#queue" class="headerlink" title="queue"></a>queue</h4><ul><li>STL 队列不被归类为容器，而被归类为container adapter（ 容器适配器）。</li><li>队列中先进先出的数据结构，不允许有遍历行为，不提供迭代器, <strong>SGI STL中队列一样是以deque为缺省情况下的底部结构。</strong></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">queue&lt;int&gt; queue1;</span><br><span class="line">queue&lt;int&gt; queue2;</span><br></pre></td></tr></table></figure><ul><li>front() 相当于stack的top(),取队首元素</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">queue1.front()</span><br></pre></td></tr></table></figure><ul><li><p>back() 取队尾元素</p></li><li><p>push() 在末尾加入一个元素</p></li><li>pop() 删除第一个元素</li><li><p>empty()</p></li><li><p>插入元素用 emplace</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">queue1.emplace(1);</span><br></pre></td></tr></table></figure><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><h4 id="1-判断大小写"><a href="#1-判断大小写" class="headerlink" title="1.判断大小写"></a>1.判断大小写</h4><p><code>islower(&#39;a&#39;)</code></p><p><code>isupper(word[1])</code></p><h4 id="2-异或"><a href="#2-异或" class="headerlink" title="2. 异或"></a>2. 异或</h4><p><code>^</code>运算符</p><blockquote><ul><li>异或运算，相异为真，相同为假，所以 a^a = 0 ;0^a = a</li><li>因为异或运算 满足交换律 a\^b^a = a\^a^b = b 所以数组经过异或运算，单独的值就剩下了</li></ul></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">    public int singleNumber(int[] nums) &#123;</span><br><span class="line">        int reduce = 0;</span><br><span class="line">        for (int num : nums) &#123;</span><br><span class="line">            reduce =  reduce ^ num;</span><br><span class="line">        &#125;</span><br><span class="line">        return reduce;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-引用-amp"><a href="#3-引用-amp" class="headerlink" title="3.引用 &amp;"></a>3.引用 &amp;</h4><p>用 char <strong>&amp;c</strong> 可以修改原变量的内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for(char &amp;c : s)&#123;</span><br><span class="line">    c =  tolower(c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>实例</li></ul><blockquote><p>使用<code>vector&lt;int&gt;&amp; ans</code>可以修改原变量的内容，因此可以使用void返回值。</p><p>例题：<a href="https://leetcode-cn.com/problems/n-ary-tree-preorder-traversal/submissions/">589. N 叉树的前序遍历</a></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">//递归的思想实现</span><br><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    void get_val(Node* root,vector&lt;int&gt;&amp; ans)&#123;</span><br><span class="line">        if(root==nullptr)&#123;</span><br><span class="line">            return ;</span><br><span class="line">        &#125;</span><br><span class="line">        ans.push_back(root-&gt;val);</span><br><span class="line">        //遍历孩子节点</span><br><span class="line">        for(auto child : root-&gt;children)&#123;</span><br><span class="line">             get_val(child,ans);</span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;</span><br><span class="line">    vector&lt;int&gt; preorder(Node* root) &#123;</span><br><span class="line">        vector&lt;int&gt; ans;</span><br><span class="line">        get_val(root,ans);</span><br><span class="line">        return ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="4-把数字字符串转换成int输出"><a href="#4-把数字字符串转换成int输出" class="headerlink" title="4.把数字字符串转换成int输出"></a>4.把数字字符串转换成int输出</h4><ul><li><p><strong>atoi()</strong>的参数是 const char<em> ,因此对于一个字符串str我们必须调用 c_str()的方法把这个string转换成 const char</em> 类型的,</p></li><li><p><strong>stoi()</strong>的参数是const string*,不需要转化为 const char*</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">string date = &quot;2019-01-09&quot;</span><br><span class="line">int year = stoi(date.substr(0, 4));</span><br></pre></td></tr></table></figure><h4 id="5-数字范围"><a href="#5-数字范围" class="headerlink" title="5.数字范围"></a>5.数字范围</h4><blockquote><p>位运算要加括号<code>if((num &amp; MASK2) == MASK1)</code></p></blockquote><ul><li>int</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INT_MAX</span><br></pre></td></tr></table></figure><h4 id="6-位运算"><a href="#6-位运算" class="headerlink" title="6.位运算"></a>6.位运算</h4><ul><li>异或</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a^b // 相同为0 不同为1 </span><br></pre></td></tr></table></figure><ul><li>左移乘2</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">step &lt;&lt;= 1; //步长 * 2</span><br><span class="line">n &gt;&gt;= 1;  //总数 / 2</span><br><span class="line">u &lt;&lt; 1 | 1; //✖️2➕1</span><br></pre></td></tr></table></figure><ul><li>如何循环int的每一位</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">int n=10;</span><br><span class="line">for(int i=0;n&gt;&gt;i;i++)&#123;</span><br><span class="line">//这里 n&gt;&gt;i 为0时 for循环结束</span><br><span class="line">//m这里表示n的第i位</span><br><span class="line">int m = (n&gt;&gt;i)&amp;1; //与1做与运算 可以取出最低位</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>移位</li></ul><p>看一道例题：</p><ol><li><a href="https://leetcode-cn.com/problems/reverse-bits/">颠倒二进制位</a></li></ol><blockquote><p>颠倒给定的 32 位无符号整数的二进制位。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    uint32_t reverseBits(uint32_t n) &#123;</span><br><span class="line"></span><br><span class="line">        //思路：</span><br><span class="line">        //依次从n的尾部遍历,直到其前全为0</span><br><span class="line">        //1.将n与1做与操作,取到尾部的数字: n &amp; 1</span><br><span class="line">        //2.将与完1后的结果的尾,左移到前面对应位置： (n &amp; 1) &lt;&lt; (31 - i)</span><br><span class="line">        //3.将上述结果赋值给res,每次res都需要与上一次res做或操作才能保留每次拉到前面的数</span><br><span class="line">        //4.每次需要将n做逻辑右移,尾部去掉,前面补零的操作</span><br><span class="line"></span><br><span class="line">        int res = 0;</span><br><span class="line"></span><br><span class="line">        for (int i = 0; i &lt; 32; i++) &#123;</span><br><span class="line">            //取得每次颠倒的结果</span><br><span class="line">            res = res | ((n &amp; 1) &lt;&lt; (31 - i));</span><br><span class="line">            </span><br><span class="line">            //n逻辑右移</span><br><span class="line">            n = n &gt;&gt; 1;</span><br><span class="line">            </span><br><span class="line">            //若全剩下0则直接可以返回</span><br><span class="line">            if (n == 0)&#123;</span><br><span class="line">                break;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return res;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul><li>快速生成掩码</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">static const int MASK1 = 1 &lt;&lt; 7;//2^7 1000 0000</span><br><span class="line">static const int MASK2 = (1 &lt;&lt; 7) + (1 &lt;&lt; 6); //2^7+2^61100 0000</span><br></pre></td></tr></table></figure><ul><li><p>循环取int的最低位</p><blockquote><p><a href="https://leetcode-cn.com/problems/binary-gap/">https://leetcode-cn.com/problems/binary-gap/</a></p><p>学习 for 循环的写法</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">int binaryGap(int n) &#123;</span><br><span class="line">        //右移</span><br><span class="line">        int max_dis=0;</span><br><span class="line">        int last=-1;</span><br><span class="line">        for(int i=0;n;i++)&#123;</span><br><span class="line">            //取最低位</span><br><span class="line">            if(n&amp;1 )&#123;</span><br><span class="line">                if(last!=-1)</span><br><span class="line">                    max_dis=max(max_dis,i-last);</span><br><span class="line">                last =i;</span><br><span class="line">            &#125;</span><br><span class="line">            n&gt;&gt;=1;</span><br><span class="line">        &#125;</span><br><span class="line">    return max_dis;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="7-is-sorted-判断排序规则"><a href="#7-is-sorted-判断排序规则" class="headerlink" title="7.is_sorted() 判断排序规则"></a>7.is_sorted() 判断排序规则</h4><ol><li>is_sorted()</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//判断 [first, last) 区域内的数据是否符合 std::less&lt;T&gt; 排序规则，即是否为升序序列</span><br><span class="line">bool is_sorted (ForwardIterator first, ForwardIterator last);</span><br><span class="line">//判断 [first, last) 区域内的数据是否符合 comp 排序规则  </span><br><span class="line">bool is_sorted (ForwardIterator first, ForwardIterator last, Compare comp);</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">is_sorted(nums.begin(), nums.end()) //升序</span><br><span class="line">is_sorted(nums.rbegin(), nums.rend()) //降序</span><br></pre></td></tr></table></figure><ol><li>is_sorted_until()</li></ol><p>和 is_sorted() 函数相比，is_sorted_until() 函数不仅能检测出某个序列是否有序，还会返回一个正向迭代器，该迭代器指向的是当前序列中第一个破坏有序状态的元素。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//排序规则为默认的升序排序</span><br><span class="line">ForwardIterator is_sorted_until (ForwardIterator first, ForwardIterator last);</span><br></pre></td></tr></table></figure><h4 id="8-统计1的个数"><a href="#8-统计1的个数" class="headerlink" title="8.统计1的个数"></a>8.统计1的个数</h4><ul><li>__builtin_popcount()</li></ul><blockquote><p>是一个gcc内建的函数，内部实现是用查表实现的。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int a=__builtin_popcount(n);</span><br></pre></td></tr></table></figure><p>也可以用lowbit 统计最低位1的个数。</p>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 算法 </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法笔记-Python专题（更新中）</title>
      <link href="/2023/01/02/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0-Python%E4%B8%93%E9%A2%98/"/>
      <url>/2023/01/02/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0-Python%E4%B8%93%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="算法笔记-Python专题"><a href="#算法笔记-Python专题" class="headerlink" title="算法笔记-Python专题"></a>算法笔记-Python专题</h1><p>记录刷题过程中遇到的重要知识点和新知识！</p><h2 id="Python专题"><a href="#Python专题" class="headerlink" title="Python专题"></a>Python专题</h2><h3 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">maxVal = -inf</span><br></pre></td></tr></table></figure><h3 id="参数传递的方式"><a href="#参数传递的方式" class="headerlink" title="参数传递的方式"></a>参数传递的方式</h3><ul><li><p>值传递：<br>将实参的值传递给形参，函数体中对形参进行了修改不会影响实参。</p></li><li><p><a href="https://so.csdn.net/so/search?q=%E5%BC%95%E7%94%A8%E4%BC%A0%E9%80%92&amp;spm=1001.2101.3001.7020">引用传递</a>（地址传递）：<br>将实参的引用或者<a href="https://so.csdn.net/so/search?q=%E5%86%85%E5%AD%98&amp;spm=1001.2101.3001.7020">内存</a>地址传递给形参，函数体中对形参的修改会影响到实参。</p></li></ul><p><strong>函数传参时要注意：</strong></p><ul><li>引用类型需要为可变数据类型，不可变类型原始值不会更改</li><li>不可变数据类型变量传到函数中，实际上是传递了变量的地址，函数体内对参数进行修改会指向新的地址，不影响参数地址，因此值不会发生变化</li><li>对于可变数据类型，由于修改其中的元素不会改变其内存地址，所以函数体内对变量的修改会影响变量的值。</li></ul><p>可变类型:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=[inf]</span><br></pre></td></tr></table></figure><br>不可变类型：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a=<span class="number">1</span></span><br></pre></td></tr></table></figure></p><h3 id="常用模板"><a href="#常用模板" class="headerlink" title="常用模板"></a>常用模板</h3><h4 id="初始化mxn的数组"><a href="#初始化mxn的数组" class="headerlink" title="初始化mxn的数组"></a>初始化mxn的数组</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ans = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m)]</span><br></pre></td></tr></table></figure><h4 id="无向图构建邻接表"><a href="#无向图构建邻接表" class="headerlink" title="无向图构建邻接表"></a>无向图构建邻接表</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">g = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(vals))]</span><br><span class="line"><span class="keyword">for</span> x, y <span class="keyword">in</span> edges:</span><br><span class="line">     g[x].append(vals[y])</span><br><span class="line">     g[y].append(vals[x])</span><br></pre></td></tr></table></figure><h4 id="前缀和"><a href="#前缀和" class="headerlink" title="前缀和"></a>前缀和</h4><p>sum[i]表示[0,i-1]的前缀和（第一位为0）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sums = [<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    sums.append(sums[-<span class="number">1</span>] + nums[i])</span><br></pre></td></tr></table></figure></p><h4 id="链表模板"><a href="#链表模板" class="headerlink" title="链表模板"></a>链表模板</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ListNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val, <span class="built_in">next</span>=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.<span class="built_in">next</span> = <span class="built_in">next</span></span><br></pre></td></tr></table></figure><h4 id="翻转字符数组"><a href="#翻转字符数组" class="headerlink" title="翻转字符数组"></a>翻转字符数组</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#翻转字符数组</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">reverse_string</span>(<span class="params">self, nums, left, right</span>):</span></span><br><span class="line">            <span class="keyword">while</span> left &lt; right:</span><br><span class="line">                nums[left], nums[right] = nums[right], nums[left]</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h4 id="向下取整"><a href="#向下取整" class="headerlink" title="向下取整"></a>向下取整</h4><p>a/b向下取整</p><script type="math/tex; mode=display">⌊\frac{a+b−1}{b}⌋</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> (a + b - <span class="number">1</span>) // b</span><br></pre></td></tr></table></figure><h3 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h3><h4 id="最小公倍数-lcm"><a href="#最小公倍数-lcm" class="headerlink" title="最小公倍数 lcm"></a>最小公倍数 lcm</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="number">1</span></span><br><span class="line">res = lcm(res, nums[j])</span><br><span class="line">`````</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 最大公因数</span></span><br><span class="line">``</span><br><span class="line">```python</span><br><span class="line">g = <span class="number">0</span></span><br><span class="line">g = gcd(g, nums[j])</span><br><span class="line">`````</span><br><span class="line"></span><br><span class="line"><span class="comment">### List</span></span><br><span class="line"></span><br><span class="line">列表的复制</span><br></pre></td></tr></table></figure><p>new = old[:]<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### 切片</span><br><span class="line">- 切片的索引可以自动分割字符串</span><br><span class="line">- 一个字符一个单元，如果长度超过索引范围，仍会11切割并扩充原始位置的容量</span><br><span class="line">```python</span><br><span class="line">a = [&#x27;1&#x27;, &#x27;1&#x27;, 1]</span><br><span class="line">a[0:2]=&quot;ab&quot; # 会以1为单位分割字符串,并插入到0开始的区间</span><br><span class="line">a = [&#x27;a&#x27;, &#x27;b&#x27;, 1]</span><br></pre></td></tr></table></figure></p><h4 id="extend"><a href="#extend" class="headerlink" title="extend()"></a>extend()</h4><p>在同维度扩充列表：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="number">1</span>]</span><br><span class="line">b=[<span class="number">4</span>]</span><br><span class="line">a.extend(b)</span><br><span class="line">a = [<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="number">1</span>, <span class="number">4</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h4 id="拷贝"><a href="#拷贝" class="headerlink" title="拷贝[:]"></a>拷贝[:]</h4><p><strong>递归时要拷贝list的值！！！<code>[:]</code></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res.append(cur_path[:])</span><br></pre></td></tr></table></figure></p><h4 id="join"><a href="#join" class="headerlink" title="join"></a>join</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentences = [&quot;i like dog&quot;, &quot;i love coffee&quot;, &quot;i hate milk&quot;]</span><br></pre></td></tr></table></figure><p>“ “.join(sentences) 将列表拼接成一个句子 ‘i like dog i love coffee i hate milk’</p><h4 id="循环中修改list"><a href="#循环中修改list" class="headerlink" title="循环中修改list"></a>循环中修改list</h4><ul><li>list的遍历过程中，必须使用pop()删除元素，remove删除的是指定元素，在循环过程中改变列表，循环的索引不会变，但对应的值发生了改变，因此要用pop(0)手动维护弹出顺序。</li></ul><h4 id="常用接口"><a href="#常用接口" class="headerlink" title="常用接口"></a>常用接口</h4><p>最大值:max()<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">max</span>([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">34</span>])</span><br></pre></td></tr></table></figure></p><p>索引:index()<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a.index(<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><h3 id="defaultdict"><a href="#defaultdict" class="headerlink" title="defaultdict"></a>defaultdict</h3><p>defaultdict的作用是在于，当字典里的key不存在但被查找时，返回的不是keyError而是一个默认值。</p><ul><li>defaultdict 效率相比于Counter还是高不少的</li><li>初始化需要指定数据类型<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 键值对初始值为0</span></span><br><span class="line">a = defaultdict(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">a.get(key) <span class="comment">#如果存在k 返回v 否则返回None</span></span><br></pre></td></tr></table></figure></li></ul><p>默认列表为[]：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tickets_dict = defaultdict(<span class="built_in">list</span>)  </span><br><span class="line"><span class="keyword">for</span> ticket <span class="keyword">in</span> tickets:  </span><br><span class="line">tickets_dict[ticket[<span class="number">0</span>]].append(ticket[<span class="number">1</span>])  </span><br></pre></td></tr></table></figure></p><h3 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a>Counter</h3><p>统计字符数/哈希，初始值为0``<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cnt = collections.Counter()</span><br><span class="line">cnt[i]+=<span class="number">1</span></span><br><span class="line">`````</span><br><span class="line"></span><br><span class="line">也可以手动实现：</span><br><span class="line">```python</span><br><span class="line"><span class="comment">#要统计元素出现频率</span></span><br><span class="line"></span><br><span class="line">map_ = &#123;&#125; <span class="comment">#nums[i]:对应出现的次数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">map_[nums[i]] = map_.get(nums[i], <span class="number">0</span>) + <span class="number">1</span> <span class="comment"># 给一个缺省值0</span></span><br></pre></td></tr></table></figure></p><h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cnt = Counter(nums)  </span><br><span class="line">cnt = <span class="built_in">sorted</span>(cnt.items(), key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">False</span>) <span class="comment"># 默认 False 升序</span></span><br><span class="line"><span class="comment"># cnt 排序之后为元组</span></span><br><span class="line">cnt[<span class="number">0</span>][<span class="number">1</span>] <span class="comment"># 第一个键值对的值</span></span><br></pre></td></tr></table></figure><h3 id="while-amp-else"><a href="#while-amp-else" class="headerlink" title="while &amp; else"></a>while &amp; else</h3><p>while 后面的else 作用是指，当while 循环正常执行完，中间没有被break 中止的话，就会执行else后面的语句<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> count &lt;= <span class="number">5</span> :</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Loop&quot;</span>,count)</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;循环正常执行完啦&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-----out of while loop ------&quot;</span>)</span><br></pre></td></tr></table></figure></p><h3 id="all-函数"><a href="#all-函数" class="headerlink" title="all()函数"></a>all()函数</h3><p>all() 函数用于判断给定的可迭代参数 iterable 中的所有元素是否都为 TRUE，如果是返回 True，否则返回 False。</p><ul><li>列表list，元素都不为 False、None、0、’’，{}、()、Set() 返回True<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">all</span>([<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>]) <span class="literal">False</span></span><br><span class="line"><span class="built_in">all</span>([<span class="number">1</span>,<span class="number">1</span>,<span class="string">&#x27;&#x27;</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure></li></ul><h3 id="bisect库"><a href="#bisect库" class="headerlink" title="bisect库"></a>bisect库</h3><blockquote><p>科普环节：这个模块叫做 bisect 因为其使用了基本的二分（bisection）算法。</p></blockquote><p>一旦决定使用二分搜索时，立马要想到使用这个模块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> bisect</span><br><span class="line"> </span><br><span class="line">x_insert_point = bisect.bisect_left(L,x) <span class="comment">#在L中查找x，x存在时返回x左侧的位置，x不存在返回应该插入的位置</span></span><br><span class="line">x_insert_point = bisect.bisect_right(L,x)  <span class="comment">#在L中查找x，x存在时返回x右侧的位置，x不存在返回应该插入的位置</span></span><br><span class="line">x_insort_left = bisect.insort_left(L,x)  <span class="comment">#将x插入到列表L中，x存在时插入在左侧</span></span><br><span class="line">x_insort_rigth = bisect.insort_right(L,x) <span class="comment">#将x插入到列表L中，x存在时插入在右侧　　　　</span></span><br></pre></td></tr></table></figure><h3 id="deque"><a href="#deque" class="headerlink" title="deque()"></a>deque()</h3><p>python中的队列<code>from collections import deque</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">que = deque()</span><br></pre></td></tr></table></figure><p>添加：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">que.append(x) <span class="comment">#右边</span></span><br><span class="line">que.appendleft(x) <span class="comment">#左边</span></span><br></pre></td></tr></table></figure><br>弹出：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">que.popleft()</span><br></pre></td></tr></table></figure><br>断是否为空：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">que.empty()</span><br></pre></td></tr></table></figure><br>队列长度：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(que)</span><br></pre></td></tr></table></figure><br>队首：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">que[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><br>队尾：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">que[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p><blockquote><p>同理，可实现列表的索引操作，但是切片不可行</p></blockquote><h3 id="heap"><a href="#heap" class="headerlink" title="heap"></a>heap</h3><p>heapq 库是<a href="https://so.csdn.net/so/search?q=Python%E6%A0%87%E5%87%86%E5%BA%93&amp;spm=1001.2101.3001.7020">Python标准库</a>之一，提供了构建<strong>小顶堆的方法和一些对小顶堆</strong>的基本操作方法(如入堆，出堆等)，可以用于实现堆排序算法。</p><ul><li>数据结构用list模拟 <code>pri_que = []  # 小顶堆</code></li><li>小顶堆先弹出的是最小的，弹出的顺序是升序的</li></ul><p>创建：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pri_que = []  <span class="comment"># 小顶堆 </span></span><br></pre></td></tr></table></figure><br>添加：<br><strong>heap为定义堆，item增加的元素</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heap.heappush(pri_que,item)</span><br></pre></td></tr></table></figure><br>将列表转为堆<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heapq.heapify(<span class="built_in">list</span>)</span><br></pre></td></tr></table></figure><br>删除最小值</p><ul><li>因为堆的特征是heap[0]永远是最小的元素，所以一般都是删除第一个元素。小顶堆实现。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heapq.heappop(pri_que)</span><br></pre></td></tr></table></figure>删除最小元素值，添加新的元素值item<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heapq.heapreplace(pri_que，item)</span><br></pre></td></tr></table></figure>查询堆中的最大元素，n表示查询元素个数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heapq.nlargest(n,pri_que)</span><br></pre></td></tr></table></figure>查询堆中的最小元素，n表示查询元素的个数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heapq.nsmallest(n,pri_que)</span><br></pre></td></tr></table></figure></li></ul><p><strong>示例</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对频率排序  </span></span><br><span class="line"><span class="comment"># 定义一个小顶堆，大小为k  </span></span><br><span class="line">pri_que = []  <span class="comment"># 小顶堆  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 用固定大小为k的小顶堆，扫描所有频率的数值  </span></span><br><span class="line"><span class="keyword">for</span> key, freq <span class="keyword">in</span> map_.items():  </span><br><span class="line">    heapq.heappush(pri_que, (freq, key))  <span class="comment"># 按freq排序</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(pri_que) &gt; k:  <span class="comment"># 如果堆的大小大于了K，则队列弹出，保证堆的大小一直为k  </span></span><br><span class="line">        heapq.heappop(pri_que)</span><br></pre></td></tr></table></figure></p><h4 id="查找最大或最小的-N-个元素-top-k"><a href="#查找最大或最小的-N-个元素-top-k" class="headerlink" title="查找最大或最小的 N 个元素 top-k"></a>查找最大或最小的 N 个元素 top-k</h4><p>heapq 模块有两个函数：nlargest() 和 nsmallest() 可以完美解决这个问题。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line">nums = [<span class="number">1</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">23</span>, <span class="number">7</span>, -<span class="number">4</span>, <span class="number">18</span>, <span class="number">23</span>, <span class="number">42</span>, <span class="number">37</span>, <span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(heapq.nlargest(<span class="number">3</span>, nums))   <span class="comment"># [42, 37, 23]</span></span><br><span class="line"><span class="built_in">print</span>(heapq.nsmallest(<span class="number">3</span>, nums))  <span class="comment"># [-4, 1, 2]</span></span><br></pre></td></tr></table></figure><br>topk的下标：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">top5_index = heapq.nlargest(<span class="number">5</span>, <span class="built_in">range</span>(<span class="built_in">len</span>(heap)), heap.__getitem__)  <span class="comment">#前5的下标</span></span><br><span class="line">top5_index  <span class="comment">#[8, 9, 3, 7, 6]</span></span><br></pre></td></tr></table></figure></p><h3 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h3><ul><li>numpy.random.choice</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">numpy.random.choice(a, size=<span class="literal">None</span>, replace=<span class="literal">True</span>, p=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#从a(只要是ndarray都可以，但必须是一维的)中随机抽取数字，并组成指定大小(size)的数组</span></span><br><span class="line"><span class="comment">#replace:True表示可以取相同数字，False表示不可以取相同数字</span></span><br><span class="line"><span class="comment">#数组p：与数组a相对应，表示取数组a中每个元素的概率，默认为选取每个元素的概率相同。</span></span><br></pre></td></tr></table></figure><ul><li>np.eye(nums)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">np.eye(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">Out[<span class="number">22</span>]: </span><br><span class="line">array([[<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure><ul><li>取最内层指定位置元素</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">np.eye(<span class="number">3</span>)[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">Out[<span class="number">23</span>]: <span class="number">0.0</span></span><br><span class="line"><span class="comment"># 表示取0行的第二个元素</span></span><br></pre></td></tr></table></figure><ul><li>嵌套列表取指定位置向量</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.eye(<span class="number">3</span>)[[<span class="number">0</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">Out[<span class="number">24</span>]: </span><br><span class="line">array([[<span class="number">1.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">       [<span class="number">0.</span>, <span class="number">1.</span>, <span class="number">0.</span>]])</span><br></pre></td></tr></table></figure><h3 id="字符串-amp-数组互转"><a href="#字符串-amp-数组互转" class="headerlink" title="字符串&amp;数组互转"></a>字符串&amp;数组互转</h3><h4 id="ord"><a href="#ord" class="headerlink" title="ord()"></a>ord()</h4><p>返回值是对应的十进制整数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line"><span class="number">97</span></span><br></pre></td></tr></table></figure><h4 id="isdigit"><a href="#isdigit" class="headerlink" title="isdigit()"></a>isdigit()</h4><p>判断字符串是否为数字<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a=<span class="string">&#x27;123&#x27;</span></span><br><span class="line"><span class="keyword">if</span> a.isdigit():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;a是数字&quot;</span> )</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;a不是数字&quot;</span>)</span><br></pre></td></tr></table></figure></p><h3 id="cls和self"><a href="#cls和self" class="headerlink" title="cls和self"></a>cls和self</h3><p><strong>self和cls的区别</strong></p><ul><li>self表示一个具体的实例本身。需要实例化之后才能调用。</li><li>cls表示这个类本身，直接类对象调用【类方法.方法名】/实例化后调用均可。</li></ul><h3 id="解包和压缩"><a href="#解包和压缩" class="headerlink" title="解包和压缩"></a>解包和压缩</h3><h4 id="转置"><a href="#转置" class="headerlink" title="转置"></a>转置</h4><p>``<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转置</span></span><br><span class="line">trans_grid = <span class="built_in">list</span>(<span class="built_in">zip</span>(*grid))</span><br><span class="line">`````</span><br><span class="line"></span><br><span class="line"><span class="comment">### 排列组合</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### 组合 combinations()</span></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="built_in">list</span>(itertools.combinations(<span class="built_in">range</span>(<span class="number">1</span>,n+<span class="number">1</span>), k)) <span class="comment"># 组合范围 组合大小</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法笔记-算法&amp;数据结构（更新中）</title>
      <link href="/2023/01/02/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0-%E7%AE%97%E6%B3%95&amp;%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
      <url>/2023/01/02/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0-%E7%AE%97%E6%B3%95&amp;%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="算法笔记-算法-amp-数据结构"><a href="#算法笔记-算法-amp-数据结构" class="headerlink" title="算法笔记-算法&amp;数据结构"></a>算法笔记-算法&amp;数据结构</h1><p>记录刷题过程中遇到的重要知识点和新知识！</p><h2 id="算法-amp-数据结构"><a href="#算法-amp-数据结构" class="headerlink" title="算法&amp;数据结构"></a>算法&amp;数据结构</h2><h3 id="二分"><a href="#二分" class="headerlink" title="二分"></a>二分</h3><ul><li><p><strong>左闭右闭风格</strong> [left,right]<br>``</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (left &lt;= right) // 当left==right，区间[left, right]依然有效，所以用 &lt;=</span><br><span class="line">   </span><br><span class="line">right = middle - <span class="number">1</span>; // target 在左区间，所以[left, middle - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">left = middle + <span class="number">1</span>; // target 在右区间，所以[middle + <span class="number">1</span>, right]</span><br></pre></td></tr></table></figure></li><li><p>找中间位置 靠右的元素</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mid = left + (right - left)/<span class="number">2</span>;  <span class="comment"># 防止溢出</span></span><br><span class="line">与</span><br><span class="line">mid = (left+right)/<span class="number">2</span>;  一致</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>完整写法<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">    <span class="comment"># 二分查找  </span></span><br><span class="line">    left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span>  </span><br><span class="line">    <span class="keyword">while</span> left &lt;= right:  </span><br><span class="line">        middle = left + (right - left) // <span class="number">2</span>  </span><br><span class="line">        <span class="keyword">if</span> nums[middle] == target:  </span><br><span class="line">            <span class="keyword">return</span> middle  </span><br><span class="line">        <span class="keyword">elif</span> nums[middle] &gt; target:  <span class="comment"># 在左区间  </span></span><br><span class="line">            right = middle - <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            left = middle + <span class="number">1</span>  </span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="bissect库"><a href="#bissect库" class="headerlink" title="bissect库"></a>bissect库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">search</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">    <span class="comment"># 二分查找右侧插入的位置</span></span><br><span class="line">    idx = bisect.bisect_right(nums,target)</span><br><span class="line">    <span class="keyword">return</span> idx-<span class="number">1</span> <span class="keyword">if</span> nums[idx-<span class="number">1</span>]==target <span class="keyword">else</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure><p><em>以下为c++风格</em></p><ul><li><p><strong>upper_bound( begin,end,num)</strong>：返回的是数值 <strong>第一个</strong> 出现的位置。从数组的begin位置到end-1位置二分查找第一个<strong>大于</strong>num的数字，找到返回该数字的地址，不存在则返回end。</p><p>通过返回的地址减去起始地址begin,得到找到数字在数组中的下标。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int pos = upper_bound(times.begin(), times.end(), t) - times.begin() - 1;</span><br><span class="line">// - 1 表示t应该插入的位置</span><br><span class="line">// 不减1 代表边界下标</span><br><span class="line">// 因为返回的地址是 第一个 大于t 的下标</span><br></pre></td></tr></table></figure></li><li><p><strong>lower_bound( begin,end,num)</strong>：返回的是数值 <strong>最后一个</strong> 出现的位置。从数组的begin位置到end-1位置二分查找第一个<strong>大于或等于</strong>num的数字，找到返回该数字的地址，不存在则返回end。</p><p>通过返回的地址减去起始地址begin,得到找到数字在数组中的下标。</p></li><li><p><strong>binary_search(起始地址，结束地址，要查找的数值)</strong>  :返回的是是否存在这么一个数，是一个bool值。</p></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204011411201.png" alt="image-20220401141135142" style="zoom: 33%;" /></p><blockquote><p>举例</p><p>x[a,b]是一个区间</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int l = lower_bound(pos.begin(), pos.end(), x[0]) - pos.begin(); // 第一次出现的位置</span><br><span class="line"></span><br><span class="line">int r = upper_bound(pos.begin(), pos.end(), x[1]) - pos.begin();</span><br><span class="line">--r; // 最后一次出现的位置</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>手写实现</li><li>中间节点为 <code>int i = left + (right - left ) / 2;</code></li></ul><blockquote><p><strong>if(count&gt;=k) right=mid;</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">int left =1,right=m*n;</span><br><span class="line">        while(left &lt; right)&#123;</span><br><span class="line">            int mid = left+(right -left)/2;</span><br><span class="line">            //计算[1,mid]区间 满足的数量</span><br><span class="line">            int count=0;</span><br><span class="line">            for(int i=1;i&lt;m+1;i++)&#123;</span><br><span class="line">                //统计当前行有多少满足&lt;mid的</span><br><span class="line">                count+=min((int)mid/i,n);</span><br><span class="line">            &#125;</span><br><span class="line">            if(count&gt;=k) right=mid;</span><br><span class="line">            else left=mid+1;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><ul><li>找到第一个小于目标值的位置</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">int first_low(vector&lt;int&gt; num_list, int t) &#123;</span><br><span class="line">        int left = 0, right = num_list.size() - 1;</span><br><span class="line">        int res = right;</span><br><span class="line">        while (left &lt; right) &#123;</span><br><span class="line">            int mid = left + (right - left)/ 2;</span><br><span class="line">            if ( t &lt;= num_list[mid]) &#123;</span><br><span class="line">                right = mid - 1;</span><br><span class="line">                res = mid;</span><br><span class="line">            &#125; else&#123;</span><br><span class="line">                left = mid+1;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if (t &lt;= num_list[res]) return res;</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ul><li>最后一个大于目标值的位置 下一个位置可插入</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">int first_low(vector&lt;int&gt; num_list, int t) &#123;</span><br><span class="line">    int left = 0, right = num_list.size() - 1;</span><br><span class="line">    int res = right;</span><br><span class="line">    while (left &lt; right) &#123;</span><br><span class="line">        int mid = left + (right - left)/ 2;</span><br><span class="line">        if ( t &gt;= num_list[mid]) &#123;</span><br><span class="line">            left = mid + 1;</span><br><span class="line">            res = mid;</span><br><span class="line">        &#125; else&#123;</span><br><span class="line">            right = mid -1;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if (t &lt;= num_list[res]) return res;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h3><h4 id="快慢指针"><a href="#快慢指针" class="headerlink" title="快慢指针"></a>快慢指针</h4><ul><li><strong>元素相对位置不变化</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeElement</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], val: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">    <span class="comment"># 双指针  </span></span><br><span class="line">    slow = <span class="number">0</span>  </span><br><span class="line">    n = <span class="built_in">len</span>(nums)  </span><br><span class="line">    <span class="comment">#慢指针维护插入位置</span></span><br><span class="line">    <span class="keyword">for</span> fast <span class="keyword">in</span> <span class="built_in">range</span>(n):  </span><br><span class="line">        <span class="keyword">if</span> nums[fast] != val:  </span><br><span class="line">            nums[slow] = nums[fast]  </span><br><span class="line">            slow += <span class="number">1</span>  </span><br><span class="line">    <span class="keyword">return</span> slow</span><br></pre></td></tr></table></figure></li></ul><ul><li>或者是a指针先移动n步，再与b指针同时移动<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> gap:</span><br><span class="line">    gap-=<span class="number">1</span></span><br><span class="line">    chain1=chain1.<span class="built_in">next</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="相向指针"><a href="#相向指针" class="headerlink" title="相向指针"></a>相向指针</h4><ul><li>相向双指针方法，基于元素顺序可以改变的题目描述改变了元素相对位置，确保了移动最少元素</li><li><strong>相对位置可改变</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeElement</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], val: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">    <span class="comment"># 双向指针  </span></span><br><span class="line">    left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span>  </span><br><span class="line">    <span class="keyword">while</span> left &lt;= right:  </span><br><span class="line">        <span class="comment"># 找到左边待插入位置  </span></span><br><span class="line">        <span class="keyword">while</span> left &lt;= right <span class="keyword">and</span> nums[left] != val:  </span><br><span class="line">            left += <span class="number">1</span>  </span><br><span class="line">        <span class="comment"># 找到右边符合条件的位置  </span></span><br><span class="line">        <span class="keyword">while</span> left &lt;= right <span class="keyword">and</span> nums[right] == val:  </span><br><span class="line">            right -= <span class="number">1</span>  </span><br><span class="line">        <span class="comment"># 交换元素  </span></span><br><span class="line">        <span class="keyword">if</span> left &lt; right:  </span><br><span class="line">            nums[left] = nums[right]  </span><br><span class="line">            left += <span class="number">1</span>  </span><br><span class="line">            right -= <span class="number">1</span>  </span><br><span class="line">    <span class="keyword">return</span> left</span><br></pre></td></tr></table></figure></li></ul><h4 id="三数之和"><a href="#三数之和" class="headerlink" title="三数之和"></a>三数之和</h4><p><a href="https://leetcode.cn/problems/3sum/description/">15. 三数之和</a><br>关键思路：排序后使用三个指针 遍历n次，分别指向 i,i+1,len-1，通过和的情况控制指针的移动方向。<br>需要注意的是去重，如果当前元素已使用，并且后面存在连续的相同值，应该跳过，因为对于排序的数组而言，值相同意味着枚举的情况也相同。</p><p>与<a href="https://leetcode.cn/problems/4sum-ii/">四数相加II</a>不同的是，需要去重，使用哈希表对元组去重并不方便，因此考虑使用双指针。</p><p><strong>关键代码：</strong><br>集合去重：</p><ul><li>至少遍历一次后再对集合去重，否则会丢失未枚举过的集合。</li><li>我们要求的是对集合去重，而不是去重集合中的元素，因此要写成nums[i] == nums[i - 1]的形式。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 避免重复 从值不相同的位置开始     </span></span><br><span class="line"><span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>]:  </span><br><span class="line">   <span class="keyword">continue</span>  </span><br></pre></td></tr></table></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">threeSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="comment"># 排序后使用双指针  </span></span><br><span class="line">        ans = []  </span><br><span class="line">        nums.sort()  </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):  </span><br><span class="line">            <span class="keyword">if</span> nums[<span class="number">0</span>] &gt; <span class="number">0</span>:  </span><br><span class="line">                <span class="keyword">return</span> []  </span><br><span class="line">            <span class="comment"># 避免重复 从值不相同的位置开始  </span></span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>]:  </span><br><span class="line">                <span class="keyword">continue</span>  </span><br><span class="line">            left = i + <span class="number">1</span>  </span><br><span class="line">            right = <span class="built_in">len</span>(nums) - <span class="number">1</span>  </span><br><span class="line">            <span class="keyword">while</span> left &lt; right:  </span><br><span class="line">                <span class="keyword">if</span> nums[i] + nums[left] + nums[right] == <span class="number">0</span>:  </span><br><span class="line">                    ans.append([nums[i], nums[left], nums[right]])  </span><br><span class="line">                    <span class="comment"># 去重  </span></span><br><span class="line">                    <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> nums[left] == nums[left + <span class="number">1</span>]:  </span><br><span class="line">                        left += <span class="number">1</span>  </span><br><span class="line">                    <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> nums[right] == nums[right - <span class="number">1</span>]:  </span><br><span class="line">                        right -= <span class="number">1</span>  </span><br><span class="line">                    left += <span class="number">1</span>  </span><br><span class="line">                    right -= <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">                <span class="keyword">elif</span> nums[i] + nums[left] + nums[right] &gt; <span class="number">0</span>:  </span><br><span class="line">                    right -= <span class="number">1</span>  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    left += <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure><ul><li>四数之和也是类似的解法，只是在三数之和的基础上套了一层for循环，只需要注意去重条件和目标值就好了。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fourSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="comment"># 排序后使用双指针  </span></span><br><span class="line">        ans = []  </span><br><span class="line">        nums.sort()  </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):  </span><br><span class="line">            <span class="comment"># 剪枝  </span></span><br><span class="line">            <span class="keyword">if</span> nums[<span class="number">0</span>] &gt; target &gt;= <span class="number">0</span>:  </span><br><span class="line">                <span class="keyword">return</span> []  </span><br><span class="line">            <span class="comment"># 避免重复 从第一个不重复的位置开始  </span></span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>]:  </span><br><span class="line">                <span class="keyword">continue</span>  </span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(nums)):  </span><br><span class="line">                <span class="comment"># 注意去重时间 要在遍历完至少一次后再去重，因为题目要求的是相同元素的集合去重 而不是限制去重相同元素  </span></span><br><span class="line">                <span class="keyword">if</span> j &gt; i + <span class="number">1</span> <span class="keyword">and</span> nums[j] == nums[j - <span class="number">1</span>]:  </span><br><span class="line">                    <span class="keyword">continue</span>  </span><br><span class="line">                t = nums[i] + nums[j]  </span><br><span class="line">                left = j + <span class="number">1</span>  </span><br><span class="line">                right = <span class="built_in">len</span>(nums) - <span class="number">1</span>  </span><br><span class="line">                <span class="keyword">while</span> left &lt; right:  </span><br><span class="line">                    <span class="keyword">if</span> t + nums[left] + nums[right] == target:  </span><br><span class="line">                        ans.append([nums[i], nums[j], nums[left], nums[right]])  </span><br><span class="line">                        <span class="comment"># 去重  </span></span><br><span class="line">                        <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> nums[left] == nums[left + <span class="number">1</span>]:  </span><br><span class="line">                            left += <span class="number">1</span>  </span><br><span class="line">                        <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> nums[right] == nums[right - <span class="number">1</span>]:  </span><br><span class="line">                            right -= <span class="number">1</span>  </span><br><span class="line">                        left += <span class="number">1</span>  </span><br><span class="line">                        right -= <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">                    <span class="keyword">elif</span> t + nums[left] + nums[right] &gt; target:  </span><br><span class="line">                        right -= <span class="number">1</span>  </span><br><span class="line">                    <span class="keyword">else</span>:  </span><br><span class="line">                        left += <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure></li></ul><h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><ul><li>核心之处在于，控制窗口大小的动态变化<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> 右边界</span><br><span class="line"><span class="keyword">while</span> ...</span><br><span class="line"><span class="comment"># 左边界变化的逻辑写在while</span></span><br><span class="line">左边界++</span><br></pre></td></tr></table></figure></li><li><p>如果数量或者种类有限制，缩放窗口时应该控制</p></li><li><p>在指定字符的情况下，我们可以计算其最大连续数目。具体地，我们使用滑动窗口的方法，从左到右枚举右端点，维护区间中另一种字符的数量为 sum，当 sum 超过 k，我们需要让左端点右移，直到 sum≤k。移动过程中，我们记录滑动窗口的最大长度，即为指定字符的最大连续数目。</p></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">maxConsecutiveChar</span><span class="params">(string&amp; answerKey, <span class="keyword">int</span> k, <span class="keyword">char</span> ch)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = answerKey.<span class="built_in">length</span>();</span><br><span class="line">        <span class="keyword">int</span> ans = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> left = <span class="number">0</span>, right = <span class="number">0</span>, sum = <span class="number">0</span>; right &lt; n; right++) &#123;</span><br><span class="line">            sum += answerKey[right] != ch;</span><br><span class="line">            <span class="keyword">while</span> (sum &gt; k) &#123;</span><br><span class="line">                sum -= answerKey[left++] != ch;</span><br><span class="line">                <span class="comment">//将当前区间 不相符的字符计数 计数下标落在最右侧端点</span></span><br><span class="line">            &#125;</span><br><span class="line">            ans = <span class="built_in">max</span>(ans, right - left + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="求长度最小的子数组"><a href="#求长度最小的子数组" class="headerlink" title="求长度最小的子数组"></a>求长度最小的子数组</h4><p><a href="https://leetcode.cn/problems/minimum-size-subarray-sum/description/">209. 长度最小的子数组</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minSubArrayLen</span>(<span class="params">self, target: <span class="built_in">int</span>, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">    <span class="comment"># 滑动窗口 一重循环 控制窗口的结束位置  </span></span><br><span class="line">    i, sums = <span class="number">0</span>, <span class="number">0</span>  </span><br><span class="line">    ans = <span class="built_in">len</span>(nums) + <span class="number">1</span>  </span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):  </span><br><span class="line">        sums += nums[j]  </span><br><span class="line">        <span class="comment"># 判断是否可以缩放滑窗大小  </span></span><br><span class="line">        <span class="keyword">while</span> sums &gt;= target:  </span><br><span class="line">            cur_len = j - i + <span class="number">1</span>  </span><br><span class="line">            ans = cur_len <span class="keyword">if</span> cur_len &lt; ans <span class="keyword">else</span> ans  </span><br><span class="line">            sums -= nums[i]  </span><br><span class="line">            i += <span class="number">1</span> <span class="comment"># 更新区间</span></span><br><span class="line">    <span class="keyword">return</span> ans <span class="keyword">if</span> ans &lt; <span class="built_in">len</span>(nums) + <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span></span><br></pre></td></tr></table></figure></p><p><a href="https://leetcode.cn/problems/minimum-window-substring/description/">76. 最小覆盖子串</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minWindow</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span>  </span><br><span class="line">    n = s.__len__()  </span><br><span class="line">    cnt = &#123;k: <span class="number">0</span> <span class="keyword">for</span> k <span class="keyword">in</span> t&#125;  </span><br><span class="line">    need = Counter(t)  </span><br><span class="line">    i = <span class="number">0</span>  </span><br><span class="line">    gap = n + <span class="number">1</span>  </span><br><span class="line">    valid = <span class="number">0</span>  </span><br><span class="line">    res = <span class="string">&#x27;&#x27;</span>  </span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):  </span><br><span class="line">        <span class="keyword">if</span> s[j] <span class="keyword">in</span> cnt:  </span><br><span class="line">            cnt[s[j]] += <span class="number">1</span>  </span><br><span class="line">            <span class="keyword">if</span> need[s[j]] == cnt[s[j]]:  </span><br><span class="line">                valid += <span class="number">1</span>  </span><br><span class="line">        <span class="comment"># 判断是否缩放区间  </span></span><br><span class="line">        <span class="keyword">while</span> valid == <span class="built_in">len</span>(need):  </span><br><span class="line">            <span class="keyword">if</span> s[i] <span class="keyword">in</span> cnt:  </span><br><span class="line">                <span class="comment"># 更新计数  </span></span><br><span class="line">                <span class="keyword">if</span> need[s[i]] == cnt[s[i]]:  </span><br><span class="line">                    valid -= <span class="number">1</span>  </span><br><span class="line">                cnt[s[i]] -= <span class="number">1</span>  </span><br><span class="line">            <span class="comment"># 更新字符串  </span></span><br><span class="line">            <span class="keyword">if</span> j - i + <span class="number">1</span> &lt; gap:  </span><br><span class="line">                gap = j - i + <span class="number">1</span>  </span><br><span class="line">                res = s[i:i + gap]  </span><br><span class="line">            i += <span class="number">1</span> <span class="comment">#更新区间</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p><h3 id="螺旋矩阵大模拟"><a href="#螺旋矩阵大模拟" class="headerlink" title="螺旋矩阵大模拟"></a>螺旋矩阵大模拟</h3><h4 id="方阵"><a href="#方阵" class="headerlink" title="方阵"></a>方阵</h4><p>总体思路：确定循环的圈数 维护每一圈的开始坐标 以左闭右开作为每次循环的边界条件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateMatrix</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="comment"># 构建模拟矩阵  </span></span><br><span class="line">        matrix = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]  </span><br><span class="line">        <span class="comment"># 一圈一圈填充 总循环圈数  </span></span><br><span class="line">        loops = n // <span class="number">2</span>  </span><br><span class="line">        <span class="comment"># n为奇数时需要填中心点  </span></span><br><span class="line">        mid = n // <span class="number">2</span>  </span><br><span class="line">        <span class="comment"># 起始点  </span></span><br><span class="line">        start_x, start_y, count = <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>  </span><br><span class="line">        <span class="comment"># 左闭右开的原则 上右下左依次填充 每次循环宽度减 1  </span></span><br><span class="line">        <span class="keyword">for</span> offset <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, loops + <span class="number">1</span>):  </span><br><span class="line">            <span class="comment"># n-offset 左闭右开  </span></span><br><span class="line">            <span class="comment"># 上行 从右到左填充            </span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start_y, n - offset):  </span><br><span class="line">                matrix[start_x][i] = count  </span><br><span class="line">                count += <span class="number">1</span>  </span><br><span class="line">            <span class="comment"># 右列 从上到下  </span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start_x, n - offset):  </span><br><span class="line">                matrix[i][n - offset] = count  </span><br><span class="line">                count += <span class="number">1</span>  </span><br><span class="line">            <span class="comment"># 下行 从右到左  </span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - offset, start_y, -<span class="number">1</span>):  </span><br><span class="line">                matrix[n - offset][i] = count  </span><br><span class="line">                count += <span class="number">1</span>  </span><br><span class="line">            <span class="comment"># 左列 从下到上  </span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - offset, start_x, -<span class="number">1</span>):  </span><br><span class="line">                matrix[i][start_y] = count  </span><br><span class="line">                count += <span class="number">1</span>  </span><br><span class="line">            start_x += <span class="number">1</span>  </span><br><span class="line">            start_y += <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">if</span> n % <span class="number">2</span> != <span class="number">0</span>:  </span><br><span class="line">            matrix[mid][mid] = count  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> matrix</span><br></pre></td></tr></table></figure></p><h4 id="普通矩阵"><a href="#普通矩阵" class="headerlink" title="普通矩阵"></a>普通矩阵</h4><p>比较通用的解法，从右上角剥离：<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212151525846.png" alt="|395"></p><p><a href="https://leetcode.cn/problems/spiral-matrix/description/">54.螺旋数组</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spiralOrder</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span>  </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> matrix <span class="keyword">or</span> <span class="keyword">not</span> matrix[<span class="number">0</span>]:  </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>()  </span><br><span class="line">    res = []  </span><br><span class="line">    m = <span class="built_in">len</span>(matrix)  </span><br><span class="line">    n = <span class="built_in">len</span>(matrix[<span class="number">0</span>])  </span><br><span class="line">    max_len = m * n  </span><br><span class="line">    <span class="comment"># 维护边界 上下左右  </span></span><br><span class="line">    left, right = <span class="number">0</span>, n - <span class="number">1</span>  </span><br><span class="line">    top, bottom = <span class="number">0</span>, m - <span class="number">1</span>  </span><br><span class="line">    <span class="comment"># 从上到下 从右到左剥离矩阵  </span></span><br><span class="line">    <span class="comment"># 左闭右闭 所以要+1 -1控制边界    while len(res) &lt; max_len:  </span></span><br><span class="line">        <span class="comment"># 上行 从左到右  </span></span><br><span class="line">        <span class="keyword">if</span> top &lt;= bottom:  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(left, right + <span class="number">1</span>):  </span><br><span class="line">                res.append(matrix[top][i])  </span><br><span class="line">            top += <span class="number">1</span>  </span><br><span class="line">        <span class="comment"># 右列 从上到下  </span></span><br><span class="line">        <span class="keyword">if</span> left &lt;= right:  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(top, bottom + <span class="number">1</span>):  </span><br><span class="line">                res.append(matrix[i][right])  </span><br><span class="line">            right -= <span class="number">1</span>  </span><br><span class="line">        <span class="comment"># 下行 从右向左</span></span><br><span class="line">        <span class="keyword">if</span> top &lt;= bottom:  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(right, left - <span class="number">1</span>, -<span class="number">1</span>):  </span><br><span class="line">                res.append(matrix[bottom][i])  </span><br><span class="line">            bottom -= <span class="number">1</span>  </span><br><span class="line">        <span class="comment"># 左列 从下向上</span></span><br><span class="line">        <span class="keyword">if</span> left &lt;= right:  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bottom, top - <span class="number">1</span>, -<span class="number">1</span>):  </span><br><span class="line">                res.append(matrix[i][left])  </span><br><span class="line">            left += <span class="number">1</span>  </span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h3 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ListNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val, <span class="built_in">next</span>=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.<span class="built_in">next</span> = <span class="built_in">next</span></span><br></pre></td></tr></table></figure><p><strong>虚拟头结点</strong> </p><ul><li>可以处理删除真实头节点的场景，这样不用特判断，最终返回 dummy_head-&gt;next 即可。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dummy_head = ListNode(<span class="built_in">next</span>=head)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> dummyNode.<span class="built_in">next</span>;</span><br></pre></td></tr></table></figure><strong>终止条件</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> cur!=<span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> cur.<span class="built_in">next</span>!=<span class="literal">None</span></span><br></pre></td></tr></table></figure></li></ul><p><a href="https://leetcode.cn/problems/remove-linked-list-elements/description/">203. 移除链表元素</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeElements</span>(<span class="params">self, head: <span class="type">Optional</span>[ListNode], val: <span class="built_in">int</span></span>) -&gt; <span class="type">Optional</span>[ListNode]:</span>  </span><br><span class="line">    <span class="comment"># 虚拟头节点</span></span><br><span class="line">        dummy_head = ListNode(<span class="built_in">next</span>=head)  </span><br><span class="line">        cur = dummy_head  </span><br><span class="line">        <span class="keyword">while</span> cur.<span class="built_in">next</span> != <span class="literal">None</span>:  </span><br><span class="line">            <span class="keyword">if</span> cur.<span class="built_in">next</span>.val == val:  </span><br><span class="line">                cur.<span class="built_in">next</span> = cur.<span class="built_in">next</span>.<span class="built_in">next</span>  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                cur = cur.<span class="built_in">next</span>  </span><br><span class="line">        <span class="keyword">return</span> dummy_head.<span class="built_in">next</span></span><br></pre></td></tr></table></figure></p><p>递归写法，最后处理头节点<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeElements</span>(<span class="params">self, head: <span class="type">Optional</span>[ListNode], val: <span class="built_in">int</span></span>) -&gt; <span class="type">Optional</span>[ListNode]:</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> head==<span class="literal">None</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">head.<span class="built_in">next</span> = self.removeElements(head.<span class="built_in">next</span>,val)</span><br><span class="line"><span class="keyword">return</span> head.<span class="built_in">next</span> <span class="keyword">if</span> head.val==val <span class="keyword">else</span> head</span><br></pre></td></tr></table></figure></p><h4 id="链表的增删改查"><a href="#链表的增删改查" class="headerlink" title="链表的增删改查"></a>链表的增删改查</h4><p>除了查找操作，都需要从虚拟头节点开始<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLinkedList</span>:</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span>  </span><br><span class="line">        self.size = <span class="number">0</span>  </span><br><span class="line">        <span class="comment"># 虚拟头节点</span></span><br><span class="line">        self.dummy_head = Node(<span class="number">0</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span>(<span class="params">self, index: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">    <span class="comment"># 下标从0开始 所以应该加上等号</span></span><br><span class="line">        <span class="keyword">if</span> index &lt; <span class="number">0</span> <span class="keyword">or</span> index &gt;= self.size:  </span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>  </span><br><span class="line">        cur = self.dummy_head.<span class="built_in">next</span>  </span><br><span class="line">        <span class="keyword">while</span> index:  </span><br><span class="line">            cur = cur.<span class="built_in">next</span>  </span><br><span class="line">            index -= <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">return</span> cur.val  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addAtHead</span>(<span class="params">self, val: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span>  </span><br><span class="line">        node = Node(val)  </span><br><span class="line">        node.<span class="built_in">next</span> = self.dummy_head.<span class="built_in">next</span>  </span><br><span class="line">        self.dummy_head.<span class="built_in">next</span> = node  </span><br><span class="line">        self.size += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addAtTail</span>(<span class="params">self, val: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span> </span><br><span class="line">    <span class="comment"># 从虚拟头节点开始 </span></span><br><span class="line">        node = Node(val)  </span><br><span class="line">        pre = self.dummy_head  </span><br><span class="line">        <span class="keyword">while</span> pre.<span class="built_in">next</span>:  </span><br><span class="line">            pre = pre.<span class="built_in">next</span>  </span><br><span class="line">        pre.<span class="built_in">next</span> = node  </span><br><span class="line">        self.size += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addAtIndex</span>(<span class="params">self, index: <span class="built_in">int</span>, val: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span>  </span><br><span class="line">        <span class="keyword">if</span> index == self.size:  </span><br><span class="line">            self.addAtTail(val)  </span><br><span class="line">            <span class="keyword">return</span>  </span><br><span class="line">        <span class="keyword">if</span> index &lt; <span class="number">0</span>:  </span><br><span class="line">            self.addAtHead(val)  </span><br><span class="line">            <span class="keyword">return</span>  </span><br><span class="line">        <span class="keyword">if</span> index &gt; self.size:  </span><br><span class="line">            <span class="keyword">return</span>  </span><br><span class="line">        <span class="comment"># 插入到index前  </span></span><br><span class="line">        pre = self.dummy_head  </span><br><span class="line">        <span class="keyword">while</span> index:  </span><br><span class="line">            pre = pre.<span class="built_in">next</span>  </span><br><span class="line">            index -= <span class="number">1</span>  </span><br><span class="line">        node = Node(val)  </span><br><span class="line">        node.<span class="built_in">next</span> = pre.<span class="built_in">next</span>  </span><br><span class="line">        pre.<span class="built_in">next</span> = node  </span><br><span class="line">        self.size += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteAtIndex</span>(<span class="params">self, index: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span>  </span><br><span class="line">        <span class="keyword">if</span> index &lt; <span class="number">0</span> <span class="keyword">or</span> index &gt;= self.size:  </span><br><span class="line">            <span class="keyword">return</span>  </span><br><span class="line">        pre = self.dummy_head  </span><br><span class="line">        <span class="keyword">while</span> index:  </span><br><span class="line">            pre = pre.<span class="built_in">next</span>  </span><br><span class="line">            index -= <span class="number">1</span>  </span><br><span class="line">        pre.<span class="built_in">next</span> = pre.<span class="built_in">next</span>.<span class="built_in">next</span>  </span><br><span class="line">        self.size -= <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># Your MyLinkedList object will be instantiated and called as such:  </span></span><br><span class="line"><span class="comment"># obj = MyLinkedList()  </span></span><br><span class="line"><span class="comment"># param_1 = obj.get(index)  </span></span><br><span class="line"><span class="comment"># obj.addAtHead(val)  </span></span><br><span class="line"><span class="comment"># obj.addAtTail(val)  </span></span><br><span class="line"><span class="comment"># obj.addAtIndex(index,val)  </span></span><br><span class="line"><span class="comment"># obj.deleteAtIndex(index)</span></span><br></pre></td></tr></table></figure></p><h4 id="反转链表"><a href="#反转链表" class="headerlink" title="反转链表"></a>反转链表</h4><p>使用双指针的写法，pre维护下一步需要反向链接的节点，cur维护当前节点，并控制向后移动，由于cur反向链接的时候会丢失原来的链接关系，因此需要备份到tmp<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reverseList</span>(<span class="params">self, head: <span class="type">Optional</span>[ListNode]</span>) -&gt; <span class="type">Optional</span>[ListNode]:</span>  </span><br><span class="line">    <span class="comment"># 双指针  </span></span><br><span class="line">    pre, tmp = <span class="literal">None</span>, <span class="literal">None</span>  </span><br><span class="line">    cur = head  </span><br><span class="line">    <span class="keyword">while</span> cur:  </span><br><span class="line">        <span class="comment"># cur指针向后移动  </span></span><br><span class="line">        <span class="comment"># cur指针反向指向pre        </span></span><br><span class="line">        tmp = cur.<span class="built_in">next</span>  <span class="comment"># 备份当前位置指向的下一个节点 便于向后移动  </span></span><br><span class="line">        cur.<span class="built_in">next</span> = pre  <span class="comment"># 反向链接  </span></span><br><span class="line">        pre = cur  <span class="comment"># 更新当前位置  </span></span><br><span class="line">        cur = tmp  <span class="comment"># 向后移动  </span></span><br><span class="line">    <span class="keyword">return</span> pre</span><br></pre></td></tr></table></figure></p><h4 id="两两交换链表中的节点"><a href="#两两交换链表中的节点" class="headerlink" title="两两交换链表中的节点"></a>两两交换链表中的节点</h4><p><a href="https://leetcode.cn/problems/swap-nodes-in-pairs/">24. 两两交换链表中的节点</a><br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212161533485.png" alt=""><br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212161547343.png" alt=""><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">swapPairs</span>(<span class="params">self, head: <span class="type">Optional</span>[ListNode]</span>) -&gt; <span class="type">Optional</span>[ListNode]:</span>  </span><br><span class="line">    dymm_head = ListNode()  </span><br><span class="line">    dymm_head.<span class="built_in">next</span> = head  </span><br><span class="line">    <span class="comment"># 能够两两交换需要满足 下一个节点和下下一个节点不为空  </span></span><br><span class="line">    cur = dymm_head  </span><br><span class="line">    <span class="keyword">while</span> cur.<span class="built_in">next</span> != <span class="literal">None</span> <span class="keyword">and</span> cur.<span class="built_in">next</span>.<span class="built_in">next</span> != <span class="literal">None</span>:  </span><br><span class="line">        <span class="comment"># 备份两阶段指向关系  </span></span><br><span class="line">        temp1 = cur.<span class="built_in">next</span>  </span><br><span class="line">        temp2 = cur.<span class="built_in">next</span>.<span class="built_in">next</span>.<span class="built_in">next</span>  </span><br><span class="line">        <span class="comment"># 链接交换关系  </span></span><br><span class="line">        <span class="comment"># 左边是目标链接关系 右边往上填空即可</span></span><br><span class="line">        cur.<span class="built_in">next</span> = cur.<span class="built_in">next</span>.<span class="built_in">next</span>  </span><br><span class="line">        cur.<span class="built_in">next</span>.<span class="built_in">next</span> = temp1  </span><br><span class="line">        cur.<span class="built_in">next</span>.<span class="built_in">next</span>.<span class="built_in">next</span> = temp2  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 移动两位 准备下一轮交换  需使用更新后的cur</span></span><br><span class="line">        cur = cur.<span class="built_in">next</span>.<span class="built_in">next</span>  </span><br><span class="line">    <span class="keyword">return</span> dymm_head.<span class="built_in">next</span></span><br></pre></td></tr></table></figure></p><h4 id="快慢指针-1"><a href="#快慢指针-1" class="headerlink" title="快慢指针"></a>快慢指针</h4><p>终止条件：fast.next != None<br>相当于快指针和慢指针的间隔始终为n+1<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">removeNthFromEnd</span>(<span class="params">self, head: <span class="type">Optional</span>[ListNode], n: <span class="built_in">int</span></span>) -&gt; <span class="type">Optional</span>[ListNode]:</span>  </span><br><span class="line">    <span class="comment"># 使用快慢指针  </span></span><br><span class="line">    <span class="comment"># fast先移动n+1步 再与slow同时移动 当fast到达终点时 slow指向倒数n+1个节点 执行删除操作    dymm_head = ListNode()  </span></span><br><span class="line">    dymm_head.<span class="built_in">next</span> = head  </span><br><span class="line">    fast, slow = dymm_head, dymm_head  </span><br><span class="line">    <span class="keyword">while</span> n <span class="keyword">and</span> fast.<span class="built_in">next</span> != <span class="literal">None</span>:  </span><br><span class="line">        fast = fast.<span class="built_in">next</span>  </span><br><span class="line">        n -= <span class="number">1</span>  </span><br><span class="line">    <span class="comment"># fast再多移动一步 方便slow定位到倒数n+1节点  </span></span><br><span class="line">    <span class="keyword">while</span> fast.<span class="built_in">next</span> != <span class="literal">None</span>:  </span><br><span class="line">        fast = fast.<span class="built_in">next</span>  </span><br><span class="line">        slow = slow.<span class="built_in">next</span>  </span><br><span class="line">    slow.<span class="built_in">next</span> = slow.<span class="built_in">next</span>.<span class="built_in">next</span>  </span><br><span class="line">    <span class="keyword">return</span> dymm_head.<span class="built_in">next</span></span><br></pre></td></tr></table></figure></p><h4 id="寻找环的入口"><a href="#寻找环的入口" class="headerlink" title="寻找环的入口"></a>寻找环的入口</h4><p>仍然是快慢指针的思想<br><a href="https://leetcode.cn/problems/linked-list-cycle-ii/">142. 环形链表 II</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detectCycle</span>(<span class="params">self, head: <span class="type">Optional</span>[ListNode]</span>) -&gt; <span class="type">Optional</span>[ListNode]:</span>  </span><br><span class="line">    <span class="comment"># 快慢指针  </span></span><br><span class="line">    <span class="comment"># 快指针每次移动2 慢指针每次移动1    </span></span><br><span class="line">    <span class="comment"># 第一次相交之后 慢指针停留 新指针从头开始 速度为1    </span></span><br><span class="line">    <span class="comment"># 二次相遇时即为入口  </span></span><br><span class="line">    fast, slow = head, head  </span><br><span class="line">    <span class="comment"># 因为要走两步 所以要判断next.next</span></span><br><span class="line">    <span class="keyword">while</span> fast != <span class="literal">None</span> <span class="keyword">and</span> fast.<span class="built_in">next</span> != <span class="literal">None</span>:  </span><br><span class="line">        fast = fast.<span class="built_in">next</span>.<span class="built_in">next</span>  </span><br><span class="line">        slow = slow.<span class="built_in">next</span>  </span><br><span class="line">        <span class="comment"># 第一次相遇  </span></span><br><span class="line">        <span class="keyword">if</span> fast == slow:  </span><br><span class="line">            p = head  </span><br><span class="line">            q = slow  </span><br><span class="line">            <span class="keyword">while</span> p != q:  </span><br><span class="line">            <span class="comment"># 第二次相遇</span></span><br><span class="line">                p = p.<span class="built_in">next</span>  </span><br><span class="line">                q = q.<span class="built_in">next</span>  </span><br><span class="line">            <span class="keyword">return</span> p  </span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure></p><h3 id="KMP算法"><a href="#KMP算法" class="headerlink" title="KMP算法"></a>KMP算法</h3><p>KMP的经典思想就是:<strong>当出现字符串不匹配时，可以记录一部分之前已经匹配的文本内容，利用这些信息避免从头再去做匹配。</strong><br>时间复杂度：其中n为文本串长度，m为模式串长度，因为在匹配的过程中，根据前缀表不断调整匹配的位置，可以看出匹配的过程是O(n)，之前还要单独生成next数组，时间复杂度是O(m)。所以整个KMP算法的时间复杂度是O(n+m)的。</p><p><em>前缀：<strong>是指不包含最后一个字符的所有以第一个字符开头的连续子串</strong><br>后缀：<strong>是指不包含第一个字符的所有以最后一个字符结尾的连续子串</strong></em></p><blockquote><p>前后缀的顺序都是正序，比如aabaa ，长度为4的 前缀有aaba 后缀有abaa</p></blockquote><h4 id="前缀表的作用"><a href="#前缀表的作用" class="headerlink" title="前缀表的作用"></a>前缀表的作用</h4><ul><li>next数组就是一个前缀表</li><li><strong>前缀表是用来回退的，它记录了模式串与主串(文本串)不匹配的时候，模式串应该从哪里开始重新匹配。</strong></li><li>长度为前1个字符的子串<code>a</code>，最长相同前后缀的长度为0。（注意字符串的<strong>前缀是指不包含最后一个字符的所有以第一个字符开头的连续子串</strong>；<strong>后缀是指不包含第一个字符的所有以最后一个字符结尾的连续子串</strong>。）</li><li>前缀表的作用<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212182201295.png" alt=""><blockquote><p><strong>下标5之前这部分的字符串（也就是字符串aabaa）的最长相等的前缀 和 后缀字符串是 子字符串aa ，因为找到了最长相等的前缀和后缀，匹配失败的位置是后缀子串的后面(f)，那么我们找到与其相同的前缀的后面(b)重新匹配就可以了。</strong></p><p>简单来说，即便aa后面的f匹配失败，但是f之前的aa是匹配成功的，而f之前的aa又与b前面的aa相同，即为最长相等子串，前缀表中记录的正是这一信息，下次匹配直接从相同的前缀下一位匹配就好，因为b之前的前缀aa一定是可以匹配上的，不然f之前的aa也不会匹配，更不会到f这边才发生匹配失败的错误。</p><p>所以前缀表具有告诉我们当前位置匹配失败，跳到之前已经匹配过的地方的能力。</p></blockquote></li></ul><h4 id="生成前缀表-next数组"><a href="#生成前缀表-next数组" class="headerlink" title="生成前缀表/next数组"></a>生成前缀表/next数组</h4><p>针对模式串的操作<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212182211529.png" alt="|610"><br>模式串与前缀表对应位置的数字表示的就是：<strong>下标i之前（包括i）的字符串中，有多大长度的相同前缀后缀。</strong><br>例如：i=4，对应字符串aabaa，对大相等的前后缀分别是aa,aa，为2.</p><ul><li><strong>代码：</strong><br><strong>构造next数组其实就是计算模式串s，前缀表的过程。</strong> 主要有如下三步：</li></ul><ol><li>初始化</li><li>处理前后缀不相同的情况</li><li>处理前后缀相同的情况</li></ol><p><strong>next数组不减1的写法</strong>，这样可以保证next数组存的就是会退后前缀的下一个位置，可以直接开始新一轮匹配<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getnext</span>(<span class="params">self, s</span>):</span>  </span><br><span class="line">    <span class="comment"># 模式串  </span></span><br><span class="line">    len_s = <span class="built_in">len</span>(s)  </span><br><span class="line">    <span class="built_in">next</span> = [<span class="string">&#x27;&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(len_s)]  <span class="comment"># 与模式串长度相同  </span></span><br><span class="line">    j = <span class="number">0</span> <span class="comment"># 控制模式穿next数组更新</span></span><br><span class="line">    <span class="built_in">next</span>[<span class="number">0</span>] = <span class="number">0</span>  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, len_s):  </span><br><span class="line">    <span class="comment"># i从1开始查找</span></span><br><span class="line">        <span class="keyword">while</span> j &gt; <span class="number">0</span> <span class="keyword">and</span> s[i] != s[j]:  </span><br><span class="line">            <span class="comment"># j要保证大于0，因为下面有取j-1作为数组下标的操作  </span></span><br><span class="line">            j = <span class="built_in">next</span>[j - <span class="number">1</span>]  <span class="comment"># 注意这里，是要找前一位 对应的回退位置了  </span></span><br><span class="line">        <span class="keyword">if</span> s[i] == s[j]:  </span><br><span class="line">            j += <span class="number">1</span>  <span class="comment"># 匹配成功进行下一位匹配</span></span><br><span class="line">        <span class="built_in">next</span>[i] = j  <span class="comment">#更新最长前缀长度 注意是for循环中i得下标</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">next</span></span><br></pre></td></tr></table></figure></p><h4 id="前缀表的用法-使用next数组来做匹配"><a href="#前缀表的用法-使用next数组来做匹配" class="headerlink" title="前缀表的用法/使用next数组来做匹配"></a>前缀表的用法/使用next数组来做匹配</h4><p>当找到的不匹配的位置， 那么此时要看当前字符的<strong>前一个字符</strong>的前缀表的数值是多少。</p><blockquote><p>为什么要前一个字符的前缀表的数值呢，因为要找前面字符串的最长相同的前缀和后缀。找到最长相同的前缀后再从下一位开始匹配。</p></blockquote><ul><li><p><strong>next数组既可以就是前缀表，也可以是前缀表统一减一</strong>，没特殊的作用，但会导致代码写法不同。</p></li><li><p><strong>KMP代码</strong><br><strong>next数组不减1的写法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">strStr</span>(<span class="params">self, haystack: <span class="built_in">str</span>, needle: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">    a = <span class="built_in">len</span>(needle)  <span class="comment"># 模式串  </span></span><br><span class="line">    b = <span class="built_in">len</span>(haystack)  <span class="comment"># 文本串  </span></span><br><span class="line">    <span class="keyword">if</span> a == <span class="number">0</span>:  </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>  </span><br><span class="line">    <span class="built_in">next</span> = self.getnext(needle)  </span><br><span class="line">    j = <span class="number">0</span> <span class="comment"># 控制模式串</span></span><br><span class="line">    <span class="comment"># 外层循环遍历文本串 O(n)  </span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(b):  </span><br><span class="line">        <span class="keyword">while</span> j &gt; <span class="number">0</span> <span class="keyword">and</span> needle[j] != haystack[i]:  </span><br><span class="line">            j = <span class="built_in">next</span>[j - <span class="number">1</span>]  <span class="comment"># 未匹配成功 回退到上一个位置存储的前缀下标  </span></span><br><span class="line">        <span class="keyword">if</span> needle[j] == haystack[i]:  </span><br><span class="line">            j += <span class="number">1</span>  <span class="comment"># 匹配成功后移  </span></span><br><span class="line">        <span class="keyword">if</span> j == a:  </span><br><span class="line">            <span class="comment"># 匹配到末尾 完全匹配上了  </span></span><br><span class="line">            <span class="keyword">return</span> i - a + <span class="number">1</span> <span class="comment">#返回匹配开始的下标</span></span><br><span class="line">     <span class="keyword">return</span> -<span class="number">1</span>       </span><br></pre></td></tr></table></figure></li></ul><h4 id="找到最小重复子串"><a href="#找到最小重复子串" class="headerlink" title="找到最小重复子串"></a>找到最小重复子串</h4><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212191009906.png" alt=""></p><ul><li><strong>最长相等前后缀的规则</strong>，当一个字符串由重复子串组成的，最长相等前后缀不包含的子串就是最小重复子串。</li><li>如果<code>len % (len - next[-1]) == 0</code> ，则说明数组的长度正好可以被 (数组长度-最长相等前后缀的长度) 整除 ，说明该字符串有重复的子字符串。<blockquote><p>解释：<br><strong>数组长度减去最长相同前后缀的长度相当于是第一个周期的长度，也就是一个周期的长度，如果这个周期可以被整除，就说明整个数组就是这个周期的循环。</strong><br>这个周期对应的就是最小重复子串:<br>长度<code>len - next[-1]</code>，区间<code>[0:len - next[-1]]</code></p></blockquote></li></ul><p>最长相等前后缀长度：存储在next数组最后一位，<code>next[-1]</code></p><ul><li><strong>next数组最后一位不是0就是最长相等前后缀长度。</strong>（0的话其实就代表没有公共子串）</li></ul><h3 id="栈和队列"><a href="#栈和队列" class="headerlink" title="栈和队列"></a>栈和队列</h3><p>栈：先进后出<br>队列：先进先出</p><ul><li><a href="https://leetcode.cn/problems/implement-queue-using-stacks/description/"> 使用栈模拟队列</a><br>关键思想：使用两个栈分别维护新增和删除元素<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyQueue</span>:</span>  </span><br><span class="line">    <span class="comment"># 使用list模拟栈   </span></span><br><span class="line">    <span class="comment"># 使用栈模拟队列  </span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span>  </span><br><span class="line">        self.stack_in = []  <span class="comment"># 进栈  </span></span><br><span class="line">        self.stack_out = []  <span class="comment"># 出栈  </span></span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span>(<span class="params">self, x: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span>  </span><br><span class="line">        <span class="comment"># 加到队列结尾  </span></span><br><span class="line">        self.stack_in.append(x)  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">        <span class="comment"># 弹出队首的元素  </span></span><br><span class="line">        <span class="comment"># 由于队列是先进先出 所以队首为最早加入的元素        if self.empty():  </span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span>  </span><br><span class="line">        <span class="keyword">if</span> self.stack_out:  </span><br><span class="line">            <span class="keyword">return</span> self.stack_out.pop()  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="comment"># 将入栈的的元素反向添加到出栈 用栈得先进后出 模拟队列的先进先出  </span></span><br><span class="line">            self.stack_out.extend(self.stack_in[::-<span class="number">1</span>])  </span><br><span class="line">            self.stack_in = []  </span><br><span class="line">            <span class="keyword">return</span> self.stack_out.pop()  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">peek</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">        <span class="comment"># 查看对首的元素 并不弹出 可以看到 与pop相比 少了弹出的操作  </span></span><br><span class="line">        this_pop = self.pop()  </span><br><span class="line">        <span class="keyword">if</span> this_pop:  </span><br><span class="line">            self.stack_out.append(this_pop)  </span><br><span class="line">            <span class="keyword">return</span> this_pop  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">empty</span>(<span class="params">self</span>) -&gt; <span class="built_in">bool</span>:</span>  </span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> self.stack_in <span class="keyword">and</span> <span class="keyword">not</span> self.stack_out</span><br></pre></td></tr></table></figure></li></ul><h4 id="使用队列模拟栈"><a href="#使用队列模拟栈" class="headerlink" title="使用队列模拟栈"></a>使用队列模拟栈</h4><p>关键思想：使用队列的循环插入弹出，模拟栈的先进先出<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyStack</span>:</span>  </span><br><span class="line">    <span class="comment"># 使用deque实现stack  </span></span><br><span class="line">    <span class="comment"># 先进先出 -&gt; 先进后出    </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span>  </span><br><span class="line">        self.que = deque()  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span>(<span class="params">self, x: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span>  </span><br><span class="line">        self.que.append(x)  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">        <span class="comment"># 弹出最晚添加的  </span></span><br><span class="line">        <span class="comment"># 将队列原有的n-1个元素去除 放到最后一个元素后面 弹出原先的最后一个元素即可        </span></span><br><span class="line">        <span class="keyword">if</span> self.empty():  </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span>  </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.que) - <span class="number">1</span>):  </span><br><span class="line">            self.que.append(self.que.popleft())  </span><br><span class="line">        <span class="keyword">return</span> self.que.popleft()  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">top</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">        <span class="comment"># 查看栈顶的元素 即最新加入的元素  </span></span><br><span class="line">        <span class="keyword">return</span> self.que[-<span class="number">1</span>]  </span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">empty</span>(<span class="params">self</span>) -&gt; <span class="built_in">bool</span>:</span>  </span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> self.que</span><br></pre></td></tr></table></figure></p><h4 id="单调队列"><a href="#单调队列" class="headerlink" title="单调队列"></a>单调队列</h4><p>使用deque实现单调队列</p><ul><li>队列出口维护最大或者最小值</li><li>每次入队都要保证单调性<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyQueue</span>:</span>  <span class="comment"># 单调队列（从大到小  </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span>  </span><br><span class="line">        self.queue = deque()  <span class="comment"># 这里需要使用deque实现单调队列，直接使用list会超时  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 每次弹出的时候，比较当前要弹出的数值是否等于队列出口元素的数值，如果相等则弹出。（为什么要判断值与队头相等，我理解的是，窗口要向后滑一位，因此要确保上一个窗口的开头元素要被弹出，因为只有他不会属于移动后的窗口）    </span></span><br><span class="line">    <span class="comment"># 同时pop之前判断队列当前是否为空。    </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span>(<span class="params">self, value</span>):</span>  </span><br><span class="line">        <span class="keyword">if</span> self.queue <span class="keyword">and</span> value == self.queue[<span class="number">0</span>]:  </span><br><span class="line">            self.queue.popleft()  <span class="comment"># list.pop()时间复杂度为O(n),这里需要使用collections.deque()  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 如果push的数值大于入口元素的数值，那么就将队列后端的数值弹出，直到push的数值小于等于队列入口元素的数值为止。    </span></span><br><span class="line">    <span class="comment"># 这样就保持了队列里的数值是单调从大到小的了。    </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span>(<span class="params">self, value</span>):</span>  </span><br><span class="line">        <span class="keyword">while</span> self.queue <span class="keyword">and</span> value &gt; self.queue[-<span class="number">1</span>]:  </span><br><span class="line">            self.queue.pop()  <span class="comment"># 弹右侧 保证当前队列单调递减</span></span><br><span class="line">        self.queue.append(value)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 查询当前队列里的最大值 直接返回队列前端也就是front就可以了。  </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">front</span>(<span class="params">self</span>):</span>  </span><br><span class="line">        <span class="keyword">return</span> self.queue[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></li></ul><p><a href="https://leetcode.cn/problems/sliding-window-maximum/description/">239.滑动窗口最大值</a><br>单调队列实现<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSlidingWindow</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span>  </span><br><span class="line">        que = MyQueue()  </span><br><span class="line">        result = []  </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):  <span class="comment"># 先将前k的元素放进队列  第一个窗口</span></span><br><span class="line">            que.push(nums[i])  </span><br><span class="line">        result.append(que.front())  <span class="comment"># result 记录前k的元素的最大值  </span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k, <span class="built_in">len</span>(nums)):  <span class="comment"># i维护窗口结束下标</span></span><br><span class="line">            que.pop(nums[i - k])  <span class="comment"># 滑动窗口移除最前面元素(上一个窗口开头的元素) </span></span><br><span class="line">            que.push(nums[i])  <span class="comment"># 滑动窗口前加入最后面的元素(当前窗口最新加入的元素)</span></span><br><span class="line">            result.append(que.front())  <span class="comment"># 记录对应的最大值  </span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p><h4 id="单调栈"><a href="#单调栈" class="headerlink" title="单调栈"></a>单调栈</h4><p>单调栈一般都会有特点，一个连续序列，对于每个序列都要找左边或右边最大或最小。说白了，如果你读题后有这样的感觉，一字长龙队，问队里每个人你最远能看到都有谁的头比你高或比你低，那9成是单调栈，而且是最高是递减栈，最低是递增栈。</p><h4 id="优先队列-披着队列外衣的堆"><a href="#优先队列-披着队列外衣的堆" class="headerlink" title="优先队列 (披着队列外衣的堆)"></a>优先队列 (披着队列外衣的堆)</h4><p><strong>堆</strong><br><strong>堆是一棵完全二叉树，树中每个结点的值都不小于（或不大于）其左右孩子的值。</strong> 如果父亲结点是大于等于左右孩子就是大顶堆，小于等于左右孩子就是小顶堆。</p><ul><li><strong>优先级队列其实是一个堆，堆就是一棵完全二叉树，同时保证父子节点的顺序关系。</strong></li><li>优先级队列对外接口只是从队头取元素，从队尾添加元素，再无其他取元素的方式，看起来就是一个队列。</li><li>优先级队列内部元素是自动依照元素的权值排列。</li></ul><p><strong>场景：</strong></p><ol><li>要统计元素出现频率（可以使用map来进行统计）</li><li>对频率排序（对频率进行排序，可以使用一种 容器适配器<strong>优先级队列</strong>。）</li><li>找出前K个高频元素<blockquote><p>a.  不用对整个数组进行排序， 只需要维护k个有序的序列就可以了，所以使用优先级队列是最优的。<br>b. <strong>要用小顶堆，因为要统计最大前k个元素，只有小顶堆每次将最小的元素弹出，最后小顶堆里积累的才是前k个最大元素。</strong><br>c. 找出前K个高频元素，因为小顶堆先弹出的是最小的，所以倒序来输出到数组</p></blockquote></li></ol><p><a href="https://leetcode.cn/problems/top-k-frequent-elements/description/">347. 前 K 个高频元素</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">topKFrequent</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span>  </span><br><span class="line">        <span class="comment"># 要统计元素出现频率  </span></span><br><span class="line">        map_ = &#123;&#125;  <span class="comment"># nums[i]:对应出现的次数  </span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):  </span><br><span class="line">            map_[nums[i]] = map_.get(nums[i], <span class="number">0</span>) + <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 对频率排序  </span></span><br><span class="line">        <span class="comment"># 定义一个小顶堆，大小为k        </span></span><br><span class="line">        pri_que = []  <span class="comment"># 小顶堆  </span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 用固定大小为k的小顶堆，扫描所有频率的数值        </span></span><br><span class="line">        <span class="keyword">for</span> key, freq <span class="keyword">in</span> map_.items():  </span><br><span class="line">            heapq.heappush(pri_que, (freq, key))  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(pri_que) &gt; k:  <span class="comment"># 如果堆的大小大于了K，则队列弹出，保证堆的大小一直为k  </span></span><br><span class="line">                heapq.heappop(pri_que)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 找出前K个高频元素，因为小顶堆先弹出的是最小的，所以倒序来输出到数组  </span></span><br><span class="line">        result = [<span class="number">0</span>] * k  </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):  </span><br><span class="line">            result[i] = heapq.heappop(pri_que)[<span class="number">1</span>]  <span class="comment"># (freq key)  </span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><p><strong>但凡遇到在动态过程中取最值的要求，肯定要使用有序数据结构，我们常用的数据结构就是二叉堆和平衡二叉搜索树了</strong>。</p><h3 id="图"><a href="#图" class="headerlink" title="图"></a>图</h3><h4 id="广度优先搜索-BFS"><a href="#广度优先搜索-BFS" class="headerlink" title="广度优先搜索 BFS"></a>广度优先搜索 BFS</h4><p>使用广度优先搜索可以计算出<strong>无向图</strong>中根结点到任意节点的<strong>     </strong>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建无向图</span></span><br><span class="line"><span class="comment">//共n个节点</span></span><br><span class="line">vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">adj</span>(n);</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> i: edges)&#123;</span><br><span class="line">            adj[i[<span class="number">0</span>]].<span class="built_in">push_back</span>(i[<span class="number">1</span>]);</span><br><span class="line">            adj[i[<span class="number">1</span>]].<span class="built_in">push_back</span>(i[<span class="number">0</span>]);</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">//访问标记</span></span><br><span class="line"><span class="function">vector&lt;<span class="keyword">bool</span>&gt; <span class="title">visit</span><span class="params">(n,<span class="literal">false</span>)</span></span>;</span><br><span class="line">queue&lt;<span class="keyword">int</span>&gt; q;</span><br><span class="line"><span class="comment">//开始位置为节点0</span></span><br><span class="line">q.<span class="built_in">emplace</span>(<span class="number">0</span>);</span><br><span class="line">visit[<span class="number">0</span>]=<span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> dist=<span class="number">1</span>; <span class="comment">//层数</span></span><br><span class="line"><span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line">    <span class="keyword">int</span> q_size = q.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;q_size;i++)&#123;</span><br><span class="line">          <span class="keyword">int</span> front=q.<span class="built_in">front</span>();</span><br><span class="line">          q.<span class="built_in">pop</span>();</span><br><span class="line">          <span class="keyword">for</span>(<span class="keyword">auto</span> point:adj[front])&#123;</span><br><span class="line">             <span class="keyword">if</span>(visit[point])&#123;</span><br><span class="line">                 <span class="keyword">continue</span>;</span><br><span class="line">               &#125;</span><br><span class="line">              q.<span class="built_in">emplace</span>(point);</span><br><span class="line">              <span class="comment">//自定义操作</span></span><br><span class="line">              visit[point]=<span class="literal">true</span>;</span><br><span class="line">           &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      dist++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>遍历二叉树</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">findTarget</span><span class="params">(TreeNode *root, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        queue&lt;TreeNode *&gt; que;</span><br><span class="line">        <span class="comment">// 将根结点加入队列</span></span><br><span class="line">        que.<span class="built_in">push</span>(root);</span><br><span class="line">        <span class="keyword">while</span> (!que.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        <span class="comment">// 从队列中取出队头</span></span><br><span class="line">            TreeNode *node = que.<span class="built_in">front</span>();</span><br><span class="line">            que.<span class="built_in">pop</span>();</span><br><span class="line">            <span class="comment">// 写下自定义操作</span></span><br><span class="line">            <span class="comment">//如果左右孩子不为空 依次将左右孩子加入队列</span></span><br><span class="line">            <span class="keyword">if</span> (node-&gt;left != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                que.<span class="built_in">push</span>(node-&gt;left);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (node-&gt;right != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                que.<span class="built_in">push</span>(node-&gt;right);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="深度优先搜索-DFS"><a href="#深度优先搜索-DFS" class="headerlink" title="深度优先搜索 DFS"></a>深度优先搜索 DFS</h4><ul><li>遍历二叉树</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">findTarget</span><span class="params">(TreeNode* root, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="literal">nullptr</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"><span class="comment">//写下需要的操作</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">findTarget</span>(root-&gt;left,  k)|| <span class="built_in">findTarget</span>(root-&gt;right,  k);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="两点连通性问题"><a href="#两点连通性问题" class="headerlink" title="两点连通性问题"></a>两点连通性问题</h4><p>两点连通性问题为经典问题，一般我们可以使用广度优先搜索或深度优先搜索，以及并查集来解决。</p><ul><li>BFS 相对于DFS更好理解一点，顺着思路就可以写代码<br>关键思路：</li></ul><ol><li>构建邻接表</li><li>层序遍历的同时控制访问状态（更新队列的时候，更新访问状态）</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">validPath</span>(<span class="params">self, n: <span class="built_in">int</span>, edges: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], source: <span class="built_in">int</span>, destination: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span>  </span><br><span class="line">        <span class="comment"># 构建邻接表  </span></span><br><span class="line">        g = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]  </span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> edges:  </span><br><span class="line">            g[x].append(y)  </span><br><span class="line">            g[y].append(x)</span><br><span class="line">              </span><br><span class="line">        que = deque()  </span><br><span class="line">        visited = [<span class="literal">False</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]  </span><br><span class="line">        que.append(source)  </span><br><span class="line">        visited[source] = <span class="literal">True</span></span><br><span class="line">          </span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(que) &gt; <span class="number">0</span>:  </span><br><span class="line">            <span class="comment"># 弹出队首节点  </span></span><br><span class="line">            cur = que.popleft()  </span><br><span class="line">            <span class="keyword">if</span> cur == destination:  </span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span>  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                <span class="comment"># 添加邻接节点  </span></span><br><span class="line">                <span class="keyword">for</span> node <span class="keyword">in</span> g[cur]:  </span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> visited[node]:  </span><br><span class="line">                        que.append(node)  </span><br><span class="line">                        visited[cur] = <span class="literal">True</span>  </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h4 id="图的DFS遍历"><a href="#图的DFS遍历" class="headerlink" title="图的DFS遍历"></a>图的DFS遍历</h4><blockquote><p>例如岛屿数量问题</p><ol><li>岛屿数量</li></ol></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(vector&lt;vector&lt;<span class="keyword">char</span>&gt;&gt;&amp; grid, <span class="keyword">int</span> r, <span class="keyword">int</span> c)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 行列范围</span></span><br><span class="line">        <span class="keyword">int</span> nr = grid.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">int</span> nc = grid[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//将已经便利过的岛屿标记为2</span></span><br><span class="line">        grid[r][c] = <span class="string">&#x27;2&#x27;</span>;</span><br><span class="line">        <span class="comment">//判断边界情况</span></span><br><span class="line">        <span class="keyword">if</span> (r - <span class="number">1</span> &gt;= <span class="number">0</span> &amp;&amp; grid[r<span class="number">-1</span>][c] == <span class="string">&#x27;1&#x27;</span>) <span class="built_in">dfs</span>(grid, r - <span class="number">1</span>, c);</span><br><span class="line">        <span class="keyword">if</span> (r + <span class="number">1</span> &lt; nr &amp;&amp; grid[r+<span class="number">1</span>][c] == <span class="string">&#x27;1&#x27;</span>) <span class="built_in">dfs</span>(grid, r + <span class="number">1</span>, c);</span><br><span class="line">        <span class="keyword">if</span> (c - <span class="number">1</span> &gt;= <span class="number">0</span> &amp;&amp; grid[r][c<span class="number">-1</span>] == <span class="string">&#x27;1&#x27;</span>) <span class="built_in">dfs</span>(grid, r, c - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span> (c + <span class="number">1</span> &lt; nc &amp;&amp; grid[r][c+<span class="number">1</span>] == <span class="string">&#x27;1&#x27;</span>) <span class="built_in">dfs</span>(grid, r, c + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">numIslands</span><span class="params">(vector&lt;vector&lt;<span class="keyword">char</span>&gt;&gt;&amp; grid)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// dfs遍历</span></span><br><span class="line">        <span class="keyword">int</span> nr = grid.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">if</span> (!nr) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> nc = grid[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">int</span> num_islands = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//遍历所有点 可搜索的次数就是独立块的数量</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> r = <span class="number">0</span>; r &lt; nr; ++r) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> c = <span class="number">0</span>; c &lt; nc; ++c) &#123;</span><br><span class="line">                <span class="comment">// dfs搜索未访问过的岛屿</span></span><br><span class="line">                <span class="keyword">if</span> (grid[r][c] == <span class="string">&#x27;1&#x27;</span>) &#123;</span><br><span class="line">                    ++num_islands;</span><br><span class="line">                    <span class="built_in">dfs</span>(grid, r, c);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> num_islands;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul><li>对于边界情况的处理</li></ul><blockquote><p>可以用 <code>direc[4][2] = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;</code> 去遍历四个方向</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> direc[<span class="number">4</span>][<span class="number">2</span>] = &#123;&#123;<span class="number">0</span>, <span class="number">1</span>&#125;, &#123;<span class="number">0</span>, <span class="number">-1</span>&#125;, &#123;<span class="number">1</span>, <span class="number">0</span>&#125;, &#123;<span class="number">-1</span>, <span class="number">0</span>&#125;&#125;;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> nx = direc[i][<span class="number">0</span>] + x, ny = direc[i][<span class="number">1</span>] + y;</span><br><span class="line">            <span class="keyword">if</span> (!(nx &gt;= <span class="number">0</span> &amp;&amp; nx &lt; m &amp;&amp; ny &gt;= <span class="number">0</span> &amp;&amp; ny &lt; n &amp;&amp; grid[nx][ny] == originalColor)) &#123;</span><br><span class="line">                isBorder = <span class="literal">true</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!visited[nx][ny]) &#123;</span><br><span class="line">                visited[nx][ny] = <span class="literal">true</span>;</span><br><span class="line">                <span class="built_in">dfs</span>(grid, nx, ny, visited, borders, originalColor);</span><br><span class="line">            &#125;                </span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h3 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h3><p>定义:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, value</span>):</span></span><br><span class="line">        self.value = value</span><br><span class="line">        self.left = <span class="literal">None</span></span><br><span class="line">        self.right = <span class="literal">None</span></span><br></pre></td></tr></table></figure></p><h4 id="满二叉树"><a href="#满二叉树" class="headerlink" title="满二叉树"></a>满二叉树</h4><p>满二叉树：如果一棵二叉树只有度为0的结点和度为2的结点，并且度为0的结点在同一层上，则这棵二叉树为满二叉树。<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212242102752.png" alt="|410"></p><h4 id="完全二叉树"><a href="#完全二叉树" class="headerlink" title="完全二叉树"></a>完全二叉树</h4><p>完全二叉树的定义如下：在完全二叉树中，除了最底层节点可能没填满外，其余每层节点数都达到最大值，并且最下面一层的节点都集中在该层最左边的若干位置。若最底层为第 h 层，则该层包含 1~ 2^(h-1)  个节点。<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212242103160.png" alt=""></p><ul><li><strong>优先级队列其实是一个堆，堆就是一棵完全二叉树，同时保证父子节点的顺序关系。</strong></li></ul><h4 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h4><p>前面介绍的树，都没有数值的，而二叉搜索树是有数值的了，<strong>二叉搜索树是一个有序树</strong>，满足左小右大。</p><ul><li>若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；</li><li>若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；</li><li>它的左、右子树也分别为二叉排序树</li></ul><p><strong>后序遍历（左右中）就是天然的回溯过程，可以根据左右子树的返回值，来处理中节点的逻辑。</strong></p><p><strong>中序遍历下，输出的二叉搜索树节点的数值是有序序列。</strong><br><code>[3,6,9,10,14,16,19]</code><br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212242108741.png" alt=""><br><a href="https://leetcode.cn/problems/search-in-a-binary-search-tree/description/">700. 二叉搜索树中的搜索</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">searchBST</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode], val: <span class="built_in">int</span></span>) -&gt; <span class="type">Optional</span>[TreeNode]:</span></span><br><span class="line">        <span class="comment"># 左小右大</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> root.val == val:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        <span class="keyword">elif</span> root.val &lt; val:</span><br><span class="line">            <span class="keyword">return</span> self.searchBST(root.right,val)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.searchBST(root.left,val)</span><br></pre></td></tr></table></figure></p><h5 id="记录pre节点处理BST"><a href="#记录pre节点处理BST" class="headerlink" title="记录pre节点处理BST"></a>记录pre节点处理BST</h5><ul><li>根绝BST左小右大的性质，可以记录pre节点完成一些逻辑<br><a href="https://leetcode.cn/problems/find-mode-in-binary-search-tree/description/">501. 二叉搜索树中的众数</a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMode</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span>  </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inorder</span>(<span class="params">root</span>):</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> res, pre, cnt, max_cnt  </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">            inorder(root.left)  </span><br><span class="line">  </span><br><span class="line">            <span class="comment"># 处理根节点  </span></span><br><span class="line">            <span class="keyword">if</span> pre <span class="keyword">is</span> <span class="literal">None</span>:  </span><br><span class="line">                cnt = <span class="number">1</span>  </span><br><span class="line">            <span class="keyword">elif</span> pre.val == root.val:  </span><br><span class="line">                cnt += <span class="number">1</span>  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                cnt = <span class="number">1</span>  </span><br><span class="line">            <span class="keyword">if</span> cnt &gt; max_cnt:  </span><br><span class="line">                max_cnt = cnt  </span><br><span class="line">                res.clear()  </span><br><span class="line">                res.append(root.val)  </span><br><span class="line">            <span class="keyword">elif</span> cnt == max_cnt:  </span><br><span class="line">                res.append(root.val)  </span><br><span class="line">            pre = root <span class="comment"># 更新pre节点</span></span><br><span class="line">            inorder(root.right)  </span><br><span class="line">  </span><br><span class="line">        res = []  </span><br><span class="line">        cnt = <span class="number">1</span>  <span class="comment"># 计数  </span></span><br><span class="line">        max_cnt = -inf  </span><br><span class="line">        pre = <span class="literal">None</span>  <span class="comment"># 记录前一个节点  </span></span><br><span class="line">        inorder(root)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></li></ul><h5 id="二叉搜索树中的插入操作"><a href="#二叉搜索树中的插入操作" class="headerlink" title="二叉搜索树中的插入操作"></a>二叉搜索树中的插入操作</h5><ul><li>递归到空节点插入</li><li><strong>只需要在叶子上添加就可以的，不涉及到结构的调整</strong></li></ul><p><a href="https://leetcode.cn/problems/insert-into-a-binary-search-tree/description/">701.二叉搜索树中的插入操作</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insertIntoBST</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode], val: <span class="built_in">int</span></span>) -&gt; <span class="type">Optional</span>[TreeNode]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> TreeNode(val)</span><br><span class="line">        <span class="keyword">elif</span> root.val &gt; val:</span><br><span class="line">            root.left = self.insertIntoBST(root.left,val)</span><br><span class="line">        <span class="keyword">elif</span> root.val &lt; val:</span><br><span class="line">            root.right = self.insertIntoBST(root.right,val)</span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure></p><h5 id="删除二叉搜索树中的节点"><a href="#删除二叉搜索树中的节点" class="headerlink" title="删除二叉搜索树中的节点"></a>删除二叉搜索树中的节点</h5><p>分5种情况讨论：</p><ol><li>未找到待删除节点，返回None</li><li>左右节点都为空，直接删除返回None</li><li>当前节点的左子树为空，返回当前的右子树</li><li>当前节点的右子树为空，返回当前的左子树</li><li>当前节点左右子树都非空，找到大于左子树的第一个最小的节点，即<strong>右子树中最左边的节点</strong>node，将当前节点的左子树挂在node的左孩子上，再用当前节点的右子树替换掉当前节点，返回当前的右子树，完成当前节点的删除</li></ol><p>450.删除二叉搜索树中的节点<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteNode</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode], key: <span class="built_in">int</span></span>) -&gt; <span class="type">Optional</span>[TreeNode]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root : </span><br><span class="line">            <span class="keyword">return</span>  <span class="literal">None</span> <span class="comment"># 节点为空，返回</span></span><br><span class="line">        <span class="keyword">if</span> root.val &lt; key :</span><br><span class="line">            root.right = self.deleteNode(root.right, key)</span><br><span class="line">        <span class="keyword">elif</span> root.val &gt; key :</span><br><span class="line">            root.left = self.deleteNode(root.left, key)</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># 找到待删除节点</span></span><br><span class="line">            <span class="comment"># 当前节点的左子树为空，返回当前的右子树</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.left : </span><br><span class="line">                <span class="keyword">return</span> root.right</span><br><span class="line">            <span class="comment"># 当前节点的右子树为空，返回当前的左子树</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.right: </span><br><span class="line">                <span class="keyword">return</span> root.left</span><br><span class="line">            <span class="comment"># 左右子树都不为空，找到右孩子的最左节点 记为node</span></span><br><span class="line">            <span class="comment"># 大于左子树的第一个最小的节点 即右子树中最左边的节点</span></span><br><span class="line">            node = root.right</span><br><span class="line">            <span class="keyword">while</span> node.left :</span><br><span class="line">                node = node.left</span><br><span class="line">            <span class="comment"># 将当前节点的左子树挂在p的左孩子上</span></span><br><span class="line">            node.left = root.left</span><br><span class="line">            <span class="comment"># 当前节点的右子树替换掉当前节点，完成当前节点的删除</span></span><br><span class="line">            root = root.right</span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure></p><h5 id="修剪二叉树"><a href="#修剪二叉树" class="headerlink" title="修剪二叉树"></a>修剪二叉树</h5><p>BST的节点是左小右大的，因此不能单独的删除某个节点，其子树（左小右大）上并非都能够满足条件，因此应该递归的寻找到合适的节点返回<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212312001884.png" alt=""></p><p><a href="https://leetcode.cn/problems/trim-a-binary-search-tree/description/">669. 修剪二叉搜索树</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">trimBST</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode], low: <span class="built_in">int</span>, high: <span class="built_in">int</span></span>) -&gt; <span class="type">Optional</span>[TreeNode]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> root.val &lt; low:</span><br><span class="line">            <span class="comment"># 左子树肯定更小 将右子树修剪后挂到当前位置</span></span><br><span class="line">            right = self.trimBST(root.right,low,high)</span><br><span class="line">            <span class="keyword">return</span> right</span><br><span class="line">        <span class="keyword">elif</span> root.val &gt; high:</span><br><span class="line">            <span class="comment"># 将左子树修剪后挂在当前位置</span></span><br><span class="line">            left = self.trimBST(root.left,low,high)</span><br><span class="line">            <span class="keyword">return</span> left</span><br><span class="line"></span><br><span class="line">        root.left = self.trimBST(root.left,low,high)</span><br><span class="line">        root.right =  self.trimBST(root.right,low,high)</span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure></p><h5 id="将有序数组转成BST"><a href="#将有序数组转成BST" class="headerlink" title="将有序数组转成BST"></a>将有序数组转成BST</h5><ul><li>实际上就是 [[算法笔记-算法&amp;数据结构#构造二叉树]] 的思路</li><li>确定根节点，切分数组，递归构造左右子树</li><li>需要注意的是，构造平衡BST，只需要每次取数组中间元素即可</li></ul><p><a href="https://leetcode.cn/problems/convert-sorted-array-to-binary-search-tree/description/">108. 将有序数组转换为二叉搜索树</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortedArrayToBST</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">Optional</span>[TreeNode]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums)==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="comment"># 取根节点索引 数组中间值</span></span><br><span class="line">        root_index = <span class="built_in">len</span>(nums)//<span class="number">2</span></span><br><span class="line">        root_val = nums[root_index]</span><br><span class="line">        root = TreeNode(root_val)</span><br><span class="line">        <span class="comment"># 分割</span></span><br><span class="line">        nums_left = nums[:root_index]</span><br><span class="line">        nums_right = nums[root_index+<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 递归构建左右子树</span></span><br><span class="line">        root.left = self.sortedArrayToBST(nums_left)</span><br><span class="line">        root.right = self.sortedArrayToBST(nums_right)</span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure></p><h5 id="把二叉搜索树转换为累加树"><a href="#把二叉搜索树转换为累加树" class="headerlink" title="把二叉搜索树转换为累加树"></a>把二叉搜索树转换为累加树</h5><ul><li>中序遍历的反向过程，右中左</li><li>从图中也可以看到，累加的过程是从右下角开始的<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212312037866.png" alt=""></li></ul><p><a href="https://leetcode.cn/problems/convert-bst-to-greater-tree/description/">538. 把二叉搜索树转换为累加树</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">convertBST</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">Optional</span>[TreeNode]:</span>  </span><br><span class="line">        <span class="comment"># 实际上是有序数组从后向前加和  </span></span><br><span class="line">        <span class="comment"># 正好是中序遍历的逆向过程def inorder(root):  </span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> pre  </span><br><span class="line">            <span class="comment"># 逆向中序遍历 右中左  </span></span><br><span class="line">            inorder(root.right)  </span><br><span class="line">            root.val += pre  </span><br><span class="line">            pre = root.val  </span><br><span class="line">            inorder(root.left)  </span><br><span class="line">  </span><br><span class="line">        pre = <span class="number">0</span>  <span class="comment"># 记录上一个节点的值  </span></span><br><span class="line">        inorder(root)  </span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure></p><h4 id="平衡二叉搜索树"><a href="#平衡二叉搜索树" class="headerlink" title="平衡二叉搜索树"></a>平衡二叉搜索树</h4><p>平衡二叉搜索树：又被称为AVL（Adelson-Velsky and Landis）树，且具有以下性质：</p><ul><li>它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212242114594.png" alt=""></li></ul><h4 id="二叉树遍历——递归"><a href="#二叉树遍历——递归" class="headerlink" title="二叉树遍历——递归"></a>二叉树遍历——递归</h4><ul><li>递归加上<code>@functools.lru_cache</code>可以加速</li><li>在 Python 的 3.2 +版本中，引入了一个非常优雅的缓存机制，即 <code>functool</code> 模块中的 <code>lru_cache</code> 装饰器，可以直接将函数或类方法的结果缓存住，后续调用则直接返回缓存的结果。</li><li>但是参数不能有list</li></ul><h5 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h5><ul><li>回溯是递归的副产品，只要有递归就会有回溯。<h6 id="递归-回溯写法"><a href="#递归-回溯写法" class="headerlink" title="递归+回溯写法"></a>递归+回溯写法</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">traversal</span>(root-&gt;left, depth + <span class="number">1</span>); <span class="comment">// 隐藏着回溯</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 相当于</span></span><br><span class="line">depth++;</span><br><span class="line"><span class="built_in">traversal</span>(root-&gt;left, depth);</span><br><span class="line">depth--;</span><br></pre></td></tr></table></figure></li></ul><p><strong>递归时要拷贝list的值！！！<code>[:]</code></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res.append(cur_path[:])</span><br></pre></td></tr></table></figure></p><h6 id="搜索一条边的写法"><a href="#搜索一条边的写法" class="headerlink" title="搜索一条边的写法"></a>搜索一条边的写法</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (递归函数(root-&gt;left)) <span class="keyword">return</span> ;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (递归函数(root-&gt;right)) <span class="keyword">return</span> ;</span><br></pre></td></tr></table></figure><h6 id="搜索整个树写法"><a href="#搜索整个树写法" class="headerlink" title="搜索整个树写法"></a>搜索整个树写法</h6><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">left = 递归函数(root-&gt;left);  <span class="comment">// 左</span></span><br><span class="line">right = 递归函数(root-&gt;right); <span class="comment">// 右</span></span><br><span class="line">left与right的逻辑处理;         <span class="comment">// 中 </span></span><br></pre></td></tr></table></figure><p>区别：<br><strong>在递归函数有返回值的情况下：如果要搜索一条边，递归函数返回值不为空的时候，立刻返回，如果搜索整个树，直接用一个变量left、right接住返回值，这个left、right后序还有逻辑处理的需要，也就是后序遍历中处理中间节点的逻辑（也是回溯）</strong>。</p><h5 id="如何选择使用哪种遍历方式"><a href="#如何选择使用哪种遍历方式" class="headerlink" title="如何选择使用哪种遍历方式"></a>如何选择使用哪种遍历方式</h5><ul><li>首先应该明确节点的处理顺序，是需要自上而下（前序遍历），还是自底向上（后序遍历），还是从左向右（中序）</li><li>甚至可以使用反中序（自右向左）[[算法笔记-算法&amp;数据结构#把二叉搜索树转换为累加树]]</li><li>尤其在二叉搜索树(BST)中，中序遍历用的较多，因为左中右的遍历顺序，正好是一个有序数组</li></ul><h6 id="前序遍历"><a href="#前序遍历" class="headerlink" title="前序遍历"></a>前序遍历</h6><ul><li>根左右<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preorder</span>(<span class="params">self, root, res</span>):</span>  </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:  </span><br><span class="line">        <span class="keyword">return</span>  </span><br><span class="line">    res.append(root.val)  <span class="comment"># 根  </span></span><br><span class="line">    self.preorder(root.left, res)  <span class="comment"># 左  </span></span><br><span class="line">    self.preorder(root.right, res)  <span class="comment"># 右</span></span><br></pre></td></tr></table></figure></li></ul><h6 id="中序遍历"><a href="#中序遍历" class="headerlink" title="中序遍历"></a>中序遍历</h6><p><strong>中序遍历下，输出的二叉搜索树节点的数值是有序序列。</strong></p><ul><li>左根右<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inorder</span>(<span class="params">self, root, res</span>):</span>  </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:  </span><br><span class="line">        <span class="keyword">return</span>  </span><br><span class="line">    <span class="comment"># 左根右  </span></span><br><span class="line">    self.inorder(root.left, res)  </span><br><span class="line">    res.append(root.val)  </span><br><span class="line">    self.inorder(root.right, res)</span><br></pre></td></tr></table></figure></li></ul><h6 id="后序遍历"><a href="#后序遍历" class="headerlink" title="后序遍历"></a>后序遍历</h6><p><strong>后序遍历（左右中）就是天然的回溯过程，可以根据左右子树的返回值，来处理中节点的逻辑。</strong></p><ul><li>左右根<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postorder</span>(<span class="params">self, root, res</span>):</span>  </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:  </span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 左右根</span></span><br><span class="line">    self.postorder(root.left, res)  </span><br><span class="line">    self.postorder(root.right, res)  </span><br><span class="line">    res.append(root.val)</span><br></pre></td></tr></table></figure></li></ul><h4 id="二叉树的遍历——迭代"><a href="#二叉树的遍历——迭代" class="headerlink" title="二叉树的遍历——迭代"></a>二叉树的遍历——迭代</h4><ul><li>层序遍历，用栈模拟遍历过程，添加空指针标记上一个元素是待处理的节点。</li><li>迭代法的由于使用栈实现，左右节点添加顺序应改反过来</li><li>每添加完根节点后添加空节点做标记<code>st.push(node);st.push(NULL);</code></li><li>因此，只有遇到空节点的时候，才将下一个节点放进结果集</li></ul><h5 id="前序遍历-1"><a href="#前序遍历-1" class="headerlink" title="前序遍历"></a>前序遍历</h5><ul><li>右左根<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">preorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; result;</span><br><span class="line">        stack&lt;TreeNode*&gt; st;</span><br><span class="line">        <span class="keyword">if</span> (root != <span class="literal">NULL</span>) st.<span class="built_in">push</span>(root);</span><br><span class="line">        <span class="keyword">while</span> (!st.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            TreeNode* node = st.<span class="built_in">top</span>();</span><br><span class="line">            <span class="keyword">if</span> (node != <span class="literal">NULL</span>) &#123;</span><br><span class="line">                st.<span class="built_in">pop</span>();</span><br><span class="line">                <span class="keyword">if</span> (node-&gt;right) st.<span class="built_in">push</span>(node-&gt;right);  <span class="comment">// 右</span></span><br><span class="line">                <span class="keyword">if</span> (node-&gt;left) st.<span class="built_in">push</span>(node-&gt;left);    <span class="comment">// 左</span></span><br><span class="line">                st.<span class="built_in">push</span>(node);                          <span class="comment">// 中</span></span><br><span class="line">                st.<span class="built_in">push</span>(<span class="literal">NULL</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                st.<span class="built_in">pop</span>();</span><br><span class="line">                node = st.<span class="built_in">top</span>();</span><br><span class="line">                st.<span class="built_in">pop</span>();</span><br><span class="line">                result.<span class="built_in">push_back</span>(node-&gt;val);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li></ul><h5 id="中序遍历-1"><a href="#中序遍历-1" class="headerlink" title="中序遍历"></a>中序遍历</h5><ul><li>右根左<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">inorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; result;</span><br><span class="line">        stack&lt;TreeNode*&gt; st;</span><br><span class="line">        <span class="keyword">if</span> (root != <span class="literal">NULL</span>) st.<span class="built_in">push</span>(root);</span><br><span class="line">        <span class="keyword">while</span> (!st.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            TreeNode* node = st.<span class="built_in">top</span>();</span><br><span class="line">            <span class="keyword">if</span> (node != <span class="literal">NULL</span>) &#123;</span><br><span class="line">                st.<span class="built_in">pop</span>(); <span class="comment">// 将该节点弹出，避免重复操作，下面再将右中左节点添加到栈中</span></span><br><span class="line">                <span class="keyword">if</span> (node-&gt;right) st.<span class="built_in">push</span>(node-&gt;right);  <span class="comment">// 添加右节点（空节点不入栈）</span></span><br><span class="line"></span><br><span class="line">                st.<span class="built_in">push</span>(node);                          <span class="comment">// 根</span></span><br><span class="line">                st.<span class="built_in">push</span>(<span class="literal">NULL</span>); <span class="comment">// 中节点访问过，但是还没有处理，加入空节点做为标记。</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (node-&gt;left) st.<span class="built_in">push</span>(node-&gt;left);    <span class="comment">// 添加左节点（空节点不入栈）</span></span><br><span class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">// 只有遇到空节点的时候，才将下一个节点放进结果集</span></span><br><span class="line">                st.<span class="built_in">pop</span>();           <span class="comment">// 将空节点弹出</span></span><br><span class="line">                node = st.<span class="built_in">top</span>();    <span class="comment">// 重新取出栈中元素</span></span><br><span class="line">                st.<span class="built_in">pop</span>();</span><br><span class="line">                result.<span class="built_in">push_back</span>(node-&gt;val); <span class="comment">// 加入到结果集</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li></ul><h5 id="后序遍历-1"><a href="#后序遍历-1" class="headerlink" title="后序遍历"></a>后序遍历</h5><ul><li>根右左<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">postorderTraversal</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; result;</span><br><span class="line">        stack&lt;TreeNode*&gt; st;</span><br><span class="line">        <span class="keyword">if</span> (root != <span class="literal">NULL</span>) st.<span class="built_in">push</span>(root);</span><br><span class="line">        <span class="keyword">while</span> (!st.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            TreeNode* node = st.<span class="built_in">top</span>();</span><br><span class="line">            <span class="keyword">if</span> (node != <span class="literal">NULL</span>) &#123;</span><br><span class="line">                st.<span class="built_in">pop</span>();</span><br><span class="line">                st.<span class="built_in">push</span>(node);                          <span class="comment">// 根</span></span><br><span class="line">                st.<span class="built_in">push</span>(<span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (node-&gt;right) st.<span class="built_in">push</span>(node-&gt;right);  <span class="comment">// 右</span></span><br><span class="line">                <span class="keyword">if</span> (node-&gt;left) st.<span class="built_in">push</span>(node-&gt;left);    <span class="comment">// 左</span></span><br><span class="line"></span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                st.<span class="built_in">pop</span>();</span><br><span class="line">                node = st.<span class="built_in">top</span>();</span><br><span class="line">                st.<span class="built_in">pop</span>();</span><br><span class="line">                result.<span class="built_in">push_back</span>(node-&gt;val);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li></ul><h4 id="层序遍历"><a href="#层序遍历" class="headerlink" title="层序遍历"></a>层序遍历</h4><p><strong>队列先进先出，符合一层一层遍历的逻辑，而用栈先进后出适合模拟深度优先遍历也就是递归的逻辑。</strong></p><p><a href="https://leetcode.cn/problems/binary-tree-level-order-traversal/">102.二叉树的层序遍历</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">levelOrder</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="comment"># 层序遍历  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:  </span><br><span class="line">            <span class="keyword">return</span> []  </span><br><span class="line">        que = deque()  </span><br><span class="line">        que.append(root)  </span><br><span class="line">        <span class="comment"># que =deque([root])  要加[]</span></span><br><span class="line">        res = <span class="built_in">list</span>()  </span><br><span class="line">        <span class="keyword">while</span> que:  </span><br><span class="line">            size = <span class="built_in">len</span>(que)  <span class="comment"># 要提前计算当前层要遍历几个节点</span></span><br><span class="line">            temp = <span class="built_in">list</span>()  </span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(size):  </span><br><span class="line">                cur = que.popleft()  </span><br><span class="line">                temp.append(cur.val)  </span><br><span class="line">                <span class="keyword">if</span> cur.left:  </span><br><span class="line">                    que.append(cur.left)  </span><br><span class="line">                <span class="keyword">if</span> cur.right:  </span><br><span class="line">                    que.append(cur.right)  </span><br><span class="line">            res.append(temp)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p><h4 id="翻转二叉树"><a href="#翻转二叉树" class="headerlink" title="翻转二叉树"></a>翻转二叉树</h4><p>想要翻转它，其实就把每一个节点的左右孩子交换一下就可以了。</p><ul><li><strong>这道题目使用前序遍历和后序遍历都可以，唯独中序遍历不方便，因为中序遍历会把某些节点的左右孩子翻转了两次</strong></li></ul><p><a href="https://leetcode.cn/problems/invert-binary-tree/description/">226. 翻转二叉树</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">invertTree</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">Optional</span>[TreeNode]:</span>  </span><br><span class="line">        <span class="comment"># 前序遍历  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:  </span><br><span class="line">            <span class="keyword">return</span> root  </span><br><span class="line">        root.left, root.right = root.right, root.left  </span><br><span class="line">        self.invertTree(root.left)  </span><br><span class="line">        self.invertTree(root.right)  </span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure></p><h4 id="左节点之和"><a href="#左节点之和" class="headerlink" title="左节点之和"></a>左节点之和</h4><p><a href="https://leetcode.cn/problems/sum-of-left-leaves/description/">404. 左叶子之和</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sumOfLeftLeaves</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="built_in">int</span>:</span>  </span><br><span class="line">        <span class="comment"># 一定要满足左叶子节点条件   </span></span><br><span class="line">        <span class="comment"># 左节点不为空 且 左节点没有左右孩子  </span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:  </span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>  </span><br><span class="line">        <span class="comment"># 后序遍历  </span></span><br><span class="line">        left_tree_val = self.sumOfLeftLeaves(root.left)  </span><br><span class="line">        right_tree_val = self.sumOfLeftLeaves(root.right)  </span><br><span class="line">        cur_node_val = <span class="number">0</span>  </span><br><span class="line">        <span class="keyword">if</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.left.left <span class="keyword">and</span> <span class="keyword">not</span> root.left.right:  </span><br><span class="line">            cur_node_val = root.left.val  </span><br><span class="line">        <span class="keyword">return</span> left_tree_val + right_tree_val + cur_node_val</span><br></pre></td></tr></table></figure></p><h4 id="记录路径"><a href="#记录路径" class="headerlink" title="记录路径"></a>记录路径</h4><p><a href="https://leetcode.cn/problems/path-sum-ii/description/">113. 路径总和 II</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pathSum</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode], targetSum: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">preorder</span>(<span class="params">root, targetSum, cur_path, cur_sum</span>):</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> res  </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:  </span><br><span class="line">                <span class="keyword">if</span> cur_sum + root.val == targetSum:  </span><br><span class="line">                    res.append(cur_path[:])  </span><br><span class="line">            <span class="keyword">if</span> root.left:  </span><br><span class="line">                cur_path.append(root.left.val)  </span><br><span class="line">                preorder(root.left, targetSum, cur_path, cur_sum + root.val)  </span><br><span class="line">                cur_path.pop()  </span><br><span class="line">            <span class="keyword">if</span> root.right:  </span><br><span class="line">                cur_path.append(root.right.val)  </span><br><span class="line">                preorder(root.right, targetSum, cur_path, cur_sum + root.val)  </span><br><span class="line">                cur_path.pop()  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:  </span><br><span class="line">            <span class="keyword">return</span> []  </span><br><span class="line">        res = <span class="built_in">list</span>()  </span><br><span class="line">        preorder(root, targetSum, [root.val], <span class="number">0</span>)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p><h4 id="构造二叉树"><a href="#构造二叉树" class="headerlink" title="构造二叉树"></a>构造二叉树</h4><h5 id="中序-后序"><a href="#中序-后序" class="headerlink" title="中序+后序"></a>中序+后序</h5><ul><li>以 后序数组 的最后一个元素为切割点，先切中序数组，根据中序数组，反过来再切后序数组。</li><li>一层一层切下去，每次后序数组最后一个元素就是根节点元素。</li><li><strong>有一个很重要的点，就是中序数组大小一定是和后序数组的大小相同的，左右子树当然也是（这是必然）。</strong></li><li>因此，中序数组我们都切成了左中序数组和右中序数组了，那么后序数组就可以按照左中序数组的大小来切割，切成左后序数组和右后序数组。<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212292114192.png" alt=""></li></ul><p>106.从中序与后序遍历序列构造二叉树<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">buildTree</span>(<span class="params">self, inorder: <span class="type">List</span>[<span class="built_in">int</span>], postorder: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="comment"># 第一步: 特殊情况讨论: 树为空. (递归终止条件)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> postorder: </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第二步: 后序遍历的最后一个就是当前的中间节点. </span></span><br><span class="line">        root_val = postorder[-<span class="number">1</span>]</span><br><span class="line">        root = TreeNode(root_val)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第三步: 找切割点. </span></span><br><span class="line">        separator_idx = inorder.index(root_val)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第四步: 切割inorder数组. 得到inorder数组的左,右半边. </span></span><br><span class="line">        inorder_left = inorder[:separator_idx]</span><br><span class="line">        inorder_right = inorder[separator_idx + <span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第五步: 切割postorder数组. 得到postorder数组的左,右半边.</span></span><br><span class="line">        <span class="comment"># ⭐️ 重点1: 中序数组大小一定跟后序数组大小是相同的. </span></span><br><span class="line">        postorder_left = postorder[:<span class="built_in">len</span>(inorder_left)]</span><br><span class="line">        postorder_right = postorder[<span class="built_in">len</span>(inorder_left): <span class="built_in">len</span>(postorder) - <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第六步: 递归 构建左右子树</span></span><br><span class="line">        root.left = self.buildTree(inorder_left, postorder_left)</span><br><span class="line">        root.right = self.buildTree(inorder_right, postorder_right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root </span><br></pre></td></tr></table></figure></p><h5 id="前序-中序"><a href="#前序-中序" class="headerlink" title="前序+中序"></a>前序+中序</h5><ul><li>根据前序数组找到根节点，切割中序数组</li><li>按切割后的左右中序数组大小对应切割，除当前根节点之外的其他元素</li><li>递归构建二叉树</li></ul><p>105.从前序与中序遍历序列构造二叉树<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">buildTree</span>(<span class="params">self, preorder: <span class="type">List</span>[<span class="built_in">int</span>], inorder: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="comment"># 第一步: 特殊情况讨论: 树为空. 或者说是递归终止条件</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> preorder: </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第二步: 前序遍历的第一个就是当前的中间节点. </span></span><br><span class="line">        root_val = preorder[<span class="number">0</span>]</span><br><span class="line">        root = TreeNode(root_val)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第三步: 找切割点. </span></span><br><span class="line">        separator_idx = inorder.index(root_val)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第四步: 切割inorder数组. 得到inorder数组的左,右半边. </span></span><br><span class="line">        inorder_left = inorder[:separator_idx]</span><br><span class="line">        inorder_right = inorder[separator_idx + <span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第五步: 切割preorder数组. 得到preorder数组的左,右半边.</span></span><br><span class="line">        <span class="comment"># ⭐️ 重点1: 中序数组大小一定跟前序数组大小是相同的. </span></span><br><span class="line">        preorder_left = preorder[<span class="number">1</span>:<span class="number">1</span> + <span class="built_in">len</span>(inorder_left)]</span><br><span class="line">        preorder_right = preorder[<span class="number">1</span> + <span class="built_in">len</span>(inorder_left):]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第六步: 递归</span></span><br><span class="line">        root.left = self.buildTree(preorder_left, inorder_left)</span><br><span class="line">        root.right = self.buildTree(preorder_right, inorder_right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure></p><h4 id="合并二叉树"><a href="#合并二叉树" class="headerlink" title="合并二叉树"></a>合并二叉树</h4><p><a href="https://leetcode.cn/problems/merge-two-binary-trees/description/">617. 合并二叉树</a><br>递归的方式合并到tree1<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mergeTrees</span>(<span class="params">self, root1: <span class="type">Optional</span>[TreeNode], root2: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">Optional</span>[TreeNode]:</span></span><br><span class="line">        <span class="comment"># 前序遍历</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root1:</span><br><span class="line">            <span class="keyword">return</span> root2</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root2:</span><br><span class="line">            <span class="keyword">return</span> root1</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 处理合并新的根节点</span></span><br><span class="line">        root1.val = root1.val+root2.val</span><br><span class="line">        <span class="comment"># 合并左子树</span></span><br><span class="line">        root1.left = self.mergeTrees(root1.left,root2.left)</span><br><span class="line">        <span class="comment"># 合并右子树</span></span><br><span class="line">        root1.right = self.mergeTrees(root1.right,root2.right)</span><br><span class="line">        <span class="keyword">return</span> root1  </span><br></pre></td></tr></table></figure></p><h4 id="最近公共祖先"><a href="#最近公共祖先" class="headerlink" title="最近公共祖先"></a>最近公共祖先</h4><ul><li>从下向上找</li><li>后序遍历（左右中）就是天然的回溯过程，可以根据左右子树的返回值，来处理中节点的逻辑。</li></ul><p><a href="https://leetcode.cn/problems/lowest-common-ancestor-of-a-binary-tree/description/">236. 二叉树的最近公共祖先</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lowestCommonAncestor</span>(<span class="params">self, root: <span class="string">&#x27;TreeNode&#x27;</span>, p: <span class="string">&#x27;TreeNode&#x27;</span>, q: <span class="string">&#x27;TreeNode&#x27;</span></span>) -&gt; &#x27;TreeNode&#x27;:</span>  </span><br><span class="line">        <span class="keyword">if</span> root == p <span class="keyword">or</span> root == q <span class="keyword">or</span> root == <span class="literal">None</span>:  </span><br><span class="line">            <span class="keyword">return</span> root  </span><br><span class="line">        <span class="comment"># 后序遍历 天然的自下而上的回溯过程 处理完左右子树再处理根节点  </span></span><br><span class="line">        left = self.lowestCommonAncestor(root.left, p, q)  </span><br><span class="line">        right = self.lowestCommonAncestor(root.right, p, q)  </span><br><span class="line">        <span class="comment"># 处理根节点  </span></span><br><span class="line">        <span class="keyword">if</span> left <span class="keyword">and</span> right:  <span class="comment"># 找到了  </span></span><br><span class="line">            <span class="keyword">return</span> root  </span><br><span class="line">        <span class="keyword">elif</span> left <span class="keyword">and</span> <span class="keyword">not</span> right:  <span class="comment"># 在左子树  </span></span><br><span class="line">            <span class="keyword">return</span> left  </span><br><span class="line">        <span class="keyword">elif</span> <span class="keyword">not</span> left <span class="keyword">and</span> right:  <span class="comment"># 在右子树  </span></span><br><span class="line">            <span class="keyword">return</span> right  </span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 没找到  </span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure></p><ul><li>对于二叉搜索树，如果当前节点的值在区间[p,q]，那么说明当前节点就是「分岔点」。此时，p 和 q 要么在当前节点的不同的子树中，要么其中一个就是当前节点。</li><li>因此第一次找到的位于区间[p,q]的节点就是最近公共祖先。</li></ul><p><a href="https://leetcode.cn/problems/lowest-common-ancestor-of-a-binary-search-tree/description/">235. 二叉搜索树的最近公共祖先</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lowestCommonAncestor</span>(<span class="params">self, root: <span class="string">&#x27;TreeNode&#x27;</span>, p: <span class="string">&#x27;TreeNode&#x27;</span>, q: <span class="string">&#x27;TreeNode&#x27;</span></span>) -&gt; &#x27;TreeNode&#x27;:</span>  </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:  </span><br><span class="line">            <span class="keyword">return</span>  </span><br><span class="line">            <span class="comment"># 利用BST的性质  </span></span><br><span class="line">        <span class="keyword">if</span> root.val &gt; p.val <span class="keyword">and</span> root.val &gt; q.val:  </span><br><span class="line">            <span class="comment"># 太大了 在左边寻找  </span></span><br><span class="line">            <span class="keyword">return</span> self.lowestCommonAncestor(root.left, p, q)  </span><br><span class="line">        <span class="keyword">elif</span> root.val &lt; p.val <span class="keyword">and</span> root.val &lt; q.val:  </span><br><span class="line">            <span class="comment"># 太小了 在右边寻找  </span></span><br><span class="line">            <span class="keyword">return</span> self.lowestCommonAncestor(root.right, p, q)  </span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure></p><h3 id="回溯"><a href="#回溯" class="headerlink" title="回溯"></a>回溯</h3><ul><li>回溯是递归的副产品，只要有递归就会有回溯</li><li><strong>回溯法解决的问题都可以抽象为树形结构</strong></li><li>回溯算法需要的参数可不像二叉树递归的时候那么容易一次性确定下来，所以一般是先写逻辑，然后需要什么参数，就填什么参数。</li><li>返回值一般void</li><li><strong>可以剪枝的地方就在递归中每一层的for循环所选择的起始位置</strong>。</li></ul><p>回溯法一般是在集合中递归搜索，集合的大小构成了树的宽度，递归的深度构成的树的深度。<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301011131971.png" alt=""><br>注意图中，特意举例集合大小和孩子的数量是相等的！</p><p>回溯法，一般可以解决如下几种问题：</p><ul><li>组合问题：N个数里面按一定规则找出k个数的集合</li><li>切割问题：一个字符串按一定规则有几种切割方式</li><li>子集问题：一个N个数的集合里有多少符合条件的子集</li><li>排列问题：N个数按一定规则全排列，有几种排列方式</li><li>棋盘问题：N皇后，解数独等等</li></ul><p>模板：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backtracking</span><span class="params">(参数)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (终止条件) &#123;</span><br><span class="line">        存放结果;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (选择：本层集合中元素（树中节点孩子的数量就是集合的大小）) &#123;</span><br><span class="line">        处理节点;</span><br><span class="line">        <span class="built_in">backtracking</span>(路径，选择列表); <span class="comment">// 递归</span></span><br><span class="line">        回溯，撤销处理结果</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>说明：</p><ul><li>先判断终止条件</li><li>for循环就是遍历集合区间，可以理解<strong>一个节点有多少个孩子，这个for循环就执行多少次</strong>。</li><li>backtracking这里自己调用自己，实现<strong>递归</strong>。<br>剪枝：</li><li><strong>可以剪枝的地方就在递归中每一层的for循环所选择的起始位置</strong>。</li></ul><p>可以从图中看出<strong>for循环可以理解是横向遍历，backtracking（递归）就是纵向遍历</strong>，这样就把这棵树全遍历完了，一般来说，搜索叶子节点就是找的其中一个结果了。</p><h4 id="组合问题"><a href="#组合问题" class="headerlink" title="组合问题"></a>组合问题</h4><h5 id="组合"><a href="#组合" class="headerlink" title="组合"></a>组合</h5><p>图解：<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301011200190.png" alt=""></p><p><a href="https://leetcode.cn/problems/combinations/description/">77. 组合</a><br><code>start_index</code>比较重要，记录开始计算的位置，避免重复的组合出现<br>拷贝<code>path</code>要使用<code>[:]</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combine</span>(<span class="params">self, n: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="comment"># 每次回溯记录开始取数的位置 避免重复  </span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">n, k, start_index</span>):</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> path, res  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(path) == k:  </span><br><span class="line">                res.append(path[:])  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">            <span class="comment"># 遍历子树  </span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start_index, n + <span class="number">1</span>):  </span><br><span class="line">                path.append(i)  <span class="comment"># 处理节点   </span></span><br><span class="line">                backtracing(n, k, i + <span class="number">1</span>)  <span class="comment"># 递归 注意是i+1 i已经处理过了  </span></span><br><span class="line">                path.pop()  <span class="comment"># 回溯 撤销节处理的节点  </span></span><br><span class="line">  </span><br><span class="line">        res = []  </span><br><span class="line">        path = []  </span><br><span class="line">        backtracing(n, k, <span class="number">1</span>)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><h5 id="电话号码的字母组合"><a href="#电话号码的字母组合" class="headerlink" title="电话号码的字母组合"></a>电话号码的字母组合</h5><p><a href="https://leetcode.cn/problems/letter-combinations-of-a-phone-number/description/">17. 电话号码的字母组合</a></p><ul><li>在for循环外控制当前遍历的集合</li><li>在for循环内控制递归的层级<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">letterCombinations</span>(<span class="params">self, digits: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracking</span>(<span class="params">digits, start_index</span>):</span></span><br><span class="line">            <span class="keyword">nonlocal</span> path,res,letterMap</span><br><span class="line">            <span class="keyword">if</span> start_index == <span class="built_in">len</span>(digits):</span><br><span class="line">                res.append(<span class="string">&#x27;&#x27;</span>.join(path))</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">                <span class="comment"># 当前字符集</span></span><br><span class="line">            cur_digits = letterMap[<span class="built_in">int</span>(digits[start_index])] <span class="comment"># 控制当前集合</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> cur_digits:</span><br><span class="line">                path.append(i) <span class="comment"># 当前集合都是同样的层数</span></span><br><span class="line">                backtracking(digits, start_index + <span class="number">1</span>)</span><br><span class="line">                path.pop()</span><br><span class="line"></span><br><span class="line">        letterMap = [</span><br><span class="line">            <span class="string">&quot;&quot;</span>,  <span class="comment"># 0</span></span><br><span class="line">            <span class="string">&quot;&quot;</span>,  <span class="comment"># 1</span></span><br><span class="line">            <span class="string">&quot;abc&quot;</span>,  <span class="comment"># 2</span></span><br><span class="line">            <span class="string">&quot;def&quot;</span>,  <span class="comment"># 3</span></span><br><span class="line">            <span class="string">&quot;ghi&quot;</span>,  <span class="comment"># 4</span></span><br><span class="line">            <span class="string">&quot;jkl&quot;</span>,  <span class="comment"># 5</span></span><br><span class="line">            <span class="string">&quot;mno&quot;</span>,  <span class="comment"># 6</span></span><br><span class="line">            <span class="string">&quot;pqrs&quot;</span>,  <span class="comment"># 7</span></span><br><span class="line">            <span class="string">&quot;tuv&quot;</span>,  <span class="comment"># 8</span></span><br><span class="line">            <span class="string">&quot;wxyz&quot;</span>,  <span class="comment"># 9</span></span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">if</span> digits==<span class="string">&quot;&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        path = []</span><br><span class="line">        res = []</span><br><span class="line">        backtracking(digits, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></li></ul><h5 id="组合总和-可重复"><a href="#组合总和-可重复" class="headerlink" title="组合总和-可重复"></a>组合总和-可重复</h5><ul><li>元素可以重复使用，关键点在于，递归时，从当前节点<code>i</code>单开始，表示当前节点可以被多次使用（下次递归，从当前节点开始，则是重复使用）</li><li>题目要求只是<strong>同一个</strong> 数字可以 <strong>无限制重复被选取</strong>，递归的过程仍然是数组缩小的，因此仍需要<code>start_index</code>避免路径重复</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301011346262.png" alt=""></p><p><a href="https://leetcode.cn/problems/combination-sum/description/">39. 组合总和</a> ^idxxj5<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combinationSum</span>(<span class="params">self, candidates: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">candidates, target, sum_num, start_index</span>):</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> res, path  </span><br><span class="line">            <span class="keyword">if</span> sum_num == target:  </span><br><span class="line">                res.append(path[:])  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">            <span class="keyword">elif</span> sum_num &gt; target:  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start_index, <span class="built_in">len</span>(candidates)):  </span><br><span class="line">                path.append(candidates[i])  </span><br><span class="line">                sum_num += candidates[i]  </span><br><span class="line">                backtracing(candidates, target, sum_num, i)  <span class="comment"># 关键点 用i 而不是i+1 表示当前节点可以重复  </span></span><br><span class="line">                sum_num -= candidates[i]  </span><br><span class="line">                path.pop()  </span><br><span class="line">  </span><br><span class="line">        res = []  </span><br><span class="line">        path = []  </span><br><span class="line">        backtracing(candidates, target, <span class="number">0</span>, <span class="number">0</span>)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p><h5 id="组合去重"><a href="#组合去重" class="headerlink" title="组合去重"></a>组合去重</h5><p>相比于[[算法笔记-算法&amp;数据结构#^idxxj5]]不同之处在于，数组中有重复元素，要避免组合重复应该在遍历的过程中，<strong>控制在同一层中，相同的元素只使用一次</strong>，而不能简单的对原数组去重，因为向下递归的过程，要合法的用到所有元素。</p><blockquote><p>还可参考使用set()去重：[[算法笔记-算法&amp;数据结构#递增子序列]]<br>还可以使用used数组去重：[[算法笔记-算法&amp;数据结构#全排列去重]]</p><p>需要注意的是：<strong>使用set去重的版本相对于used数组的版本效率都要低很多</strong></p><pre><code>    1. 主要是因为程序运行的时候对unordered_set 频繁的insert，unordered_set需要做哈希映射（也就是把key通过hash function映射为唯一的哈希值）相对费时间，而且insert的时候其底层的符号表也要做相应的扩充，也是费时的。    2. **而使用used数组在时间复杂度上几乎没有额外负担！使用set去重，不仅时间复杂度高了，空间复杂度也高了**</code></pre></blockquote><ul><li>关键点在于：先对原数组 <strong>排序</strong> 将相同的元素放在一起 方便去重 </li><li>循环时控制<strong>同一层</strong>，不能遍历 相同的的元素。<em>同一层：同一个for循环就是一层</em></li><li>每个元素只能使用一次，递归时用<code>i+1</code>即可<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> i &gt; start_index <span class="keyword">and</span> candidates[i] == candidates[i - <span class="number">1</span>]:  </span><br><span class="line"><span class="keyword">continue</span>  </span><br></pre></td></tr></table></figure><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301011515253.png" alt=""></li></ul><p><a href="https://leetcode.cn/problems/combination-sum-ii/description/">40. 组合总和 II</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">combinationSum2</span>(<span class="params">self, candidates: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">candidates, target, sum_num, start_index</span>):</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> res, path  </span><br><span class="line">            <span class="keyword">if</span> sum_num == target:  </span><br><span class="line">                res.append(path[:])  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">            <span class="keyword">elif</span> sum_num &gt; target:  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start_index, <span class="built_in">len</span>(candidates)):  </span><br><span class="line">                <span class="comment"># 为避免集合重复 同一层不遍历相同的元素  </span></span><br><span class="line">                <span class="keyword">if</span> i &gt; start_index <span class="keyword">and</span> candidates[i] == candidates[i - <span class="number">1</span>]:  </span><br><span class="line">                    <span class="keyword">continue</span>  </span><br><span class="line">                path.append(candidates[i])  </span><br><span class="line">                sum_num += candidates[i]  </span><br><span class="line">                backtracing(candidates, target, sum_num, i + <span class="number">1</span>)  <span class="comment"># 关键点 用i+1 每个节点只能使用一次  </span></span><br><span class="line">                path.pop()  </span><br><span class="line">                sum_num -= candidates[i]  </span><br><span class="line">  </span><br><span class="line">        res = []  </span><br><span class="line">        path = []  </span><br><span class="line">        candidates.sort()  <span class="comment"># 排序 将相同的元素放在一起 方便去重  </span></span><br><span class="line">        backtracing(candidates, target, <span class="number">0</span>, <span class="number">0</span>)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p><h4 id="切割问题"><a href="#切割问题" class="headerlink" title="切割问题"></a>切割问题</h4><p>切割逻辑：</p><ul><li>在同一层循环，从当前轮的起始位置依次向后切割<blockquote><p>在<code>for (int i = start_index; i &lt; s.size(); i++)</code>循环中，我们 start_index，那么 <code>[start_index, i]</code> 就是要截取的子串。</p></blockquote></li><li>递归时带上下一次切分的开始位置</li><li>终止条件，切割点移到末尾<code>start_index == len(s)</code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">path.append(s[start_index:i + <span class="number">1</span>])  </span><br><span class="line">backtracing(s, i + <span class="number">1</span>)  </span><br></pre></td></tr></table></figure></li></ul><h5 id="分割回文串"><a href="#分割回文串" class="headerlink" title="分割回文串"></a>分割回文串</h5><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301011617508.png" alt=""></p><p><a href="https://leetcode.cn/problems/palindrome-partitioning/description/">131. 分割回文串</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partition</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">str</span>]]:</span>  </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">s, start_index</span>):</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> res, path  </span><br><span class="line">            <span class="keyword">if</span> start_index == <span class="built_in">len</span>(s):  </span><br><span class="line">                res.append(path[:])  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">            <span class="comment"># 分割  </span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start_index, <span class="built_in">len</span>(s)):  </span><br><span class="line">                temp = s[start_index:i + <span class="number">1</span>]  </span><br><span class="line">                <span class="keyword">if</span> temp == temp[::-<span class="number">1</span>]: <span class="comment"># 正反序相同就是回文串</span></span><br><span class="line">                    path.append(temp)  </span><br><span class="line">                    backtracing(s, i + <span class="number">1</span>)  </span><br><span class="line">                    path.pop()  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    <span class="keyword">continue</span>  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(s) &lt; <span class="number">2</span>:  </span><br><span class="line">            <span class="keyword">return</span> [[s]]  </span><br><span class="line">        res = []  </span><br><span class="line">        path = []  </span><br><span class="line">        backtracing(s, <span class="number">0</span>)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p><h5 id="还原ip"><a href="#还原ip" class="headerlink" title="还原ip"></a>还原ip</h5><ul><li>与[[算法笔记-算法&amp;数据结构#切割问题]]不同之处在于，这个道题限制了递归的深度为4，因此在递归的处理逻辑中应该加上。</li><li>除此之外，分割字符依然是在同一层<code>for</code>里按位切割</li><li>递归结束条件除了深度为4，还要满足遍历到字符串结束位置</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301011750122.png" alt=""></p><p><a href="https://leetcode.cn/problems/restore-ip-addresses/description/">93. 复原 IP 地址</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">restoreIpAddresses</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span>  </span><br><span class="line">        <span class="comment"># 递归深度四层  </span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">check</span>(<span class="params">s</span>):</span>  </span><br><span class="line">            <span class="comment"># 验证字符串是否合法  </span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(s) &gt; <span class="number">1</span> <span class="keyword">and</span> s[<span class="number">0</span>] == <span class="string">&#x27;0&#x27;</span>:  </span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span>  </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> s.isdigit():  </span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span>  </span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt;= <span class="built_in">int</span>(s) &lt;= <span class="number">255</span>:  </span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span>  </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span>  </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">s, start_index, depth</span>):</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> res, path  </span><br><span class="line">            <span class="keyword">if</span> depth == <span class="number">4</span> <span class="keyword">and</span> start_index == <span class="built_in">len</span>(s):  </span><br><span class="line">                cur_path = <span class="string">&#x27;.&#x27;</span>.join(path[:])  </span><br><span class="line">                res.append(cur_path)  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">            <span class="keyword">elif</span> depth &gt; <span class="number">4</span>:  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">                <span class="comment"># 切割字符串  </span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start_index, <span class="built_in">len</span>(s)):  </span><br><span class="line">                temp = s[start_index:i + <span class="number">1</span>]  </span><br><span class="line">                <span class="keyword">if</span> check(temp):  </span><br><span class="line">                    path.append(temp)  </span><br><span class="line">                    backtracing(s, i + <span class="number">1</span>, depth + <span class="number">1</span>)  </span><br><span class="line">                    path.pop()  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    <span class="keyword">break</span>  </span><br><span class="line">  </span><br><span class="line">        res = []  </span><br><span class="line">        path = []  </span><br><span class="line">        backtracing(s, <span class="number">0</span>, <span class="number">0</span>)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p><h4 id="子集问题"><a href="#子集问题" class="headerlink" title="子集问题"></a>子集问题</h4><ul><li>与之前处理组合和切割问题，记录子节点不同，子集问题需要<strong>记录所有节点</strong>。</li></ul><h6 id="查找子集"><a href="#查找子集" class="headerlink" title="查找子集"></a>查找子集</h6><p><a href="https://leetcode.cn/problems/subsets/description/">78.子集</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsets</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">nums, start_index</span>):</span></span><br><span class="line">            <span class="keyword">nonlocal</span> res, path</span><br><span class="line">            <span class="comment"># 记录所有节点</span></span><br><span class="line">            res.append(path[:])</span><br><span class="line">            <span class="keyword">if</span> start_index == <span class="built_in">len</span>(nums):</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start_index, <span class="built_in">len</span>(nums)):</span><br><span class="line">                path.append(nums[i])</span><br><span class="line">                backtracing(nums, i + <span class="number">1</span>)  <span class="comment"># 递归到下一层</span></span><br><span class="line">                path.pop()</span><br><span class="line"></span><br><span class="line">        res = []</span><br><span class="line">        path = []</span><br><span class="line">        backtracing(nums, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p><p><strong>加上去重逻辑：</strong></p><ul><li>排序后控制，同一层中，相同的元素只递归一次<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> i &gt; start_index <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>]:  </span><br><span class="line"><span class="keyword">continue</span>  </span><br></pre></td></tr></table></figure><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301011912014.png" alt=""></li></ul><p><a href="https://leetcode.cn/problems/subsets-ii/description/">90. 子集 II</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsetsWithDup</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="comment"># 需要排序去重  </span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">nums, start_index</span>):</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> res, path  </span><br><span class="line">            res.append(path[:])  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(nums) == start_index:  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start_index, <span class="built_in">len</span>(nums)):  </span><br><span class="line">                <span class="keyword">if</span> i &gt; start_index <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>]:  </span><br><span class="line">                    <span class="keyword">continue</span>  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    path.append(nums[i])  </span><br><span class="line">                    backtracing(nums, i + <span class="number">1</span>)  </span><br><span class="line">                    path.pop()  </span><br><span class="line">  </span><br><span class="line">        res = []  </span><br><span class="line">        path = []  </span><br><span class="line">        nums.sort()  </span><br><span class="line">        backtracing(nums, <span class="number">0</span>)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p><h5 id="递增子序列"><a href="#递增子序列" class="headerlink" title="递增子序列"></a>递增子序列</h5><ul><li>与[[算法笔记-算法&amp;数据结构#查找子集]]不同之处在于，本题<strong>去重</strong>时不能对原数组排序，因此在递归时判断当前元素是否与上一次递归的元素相同，变得不可行。<br>原先的去重方法：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> i &gt; start_index <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>]:  </span><br><span class="line"><span class="keyword">continue</span>  </span><br></pre></td></tr></table></figure></li><li>考虑到原数组无序，我们的目的是，同层递归时不能递归之前已递归过的元素，否则必然重复。因此使用一个set()记录本层使用过的元素。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> i &gt; start_index <span class="keyword">and</span> nums[i] <span class="keyword">in</span> used:  </span><br><span class="line">    <span class="keyword">continue</span>  </span><br></pre></td></tr></table></figure></li><li>值得注意的是<code>used.add(nums[i])</code>结束后不需要手动弹出进行回溯，因为used是一个局部变量，仅在本层生效。</li></ul><p><a href="https://leetcode.cn/problems/non-decreasing-subsequences/description/">491. 递增子序列</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findSubsequences</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">nums, start_index</span>):</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> res, path  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(path) &gt; <span class="number">1</span>:  </span><br><span class="line">                res.append(path[:])  </span><br><span class="line">            used = <span class="built_in">set</span>()  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start_index, <span class="built_in">len</span>(nums)):  </span><br><span class="line">                <span class="comment"># 去重 同层不能有重复元素 因为不能对原nums排序，因此要记录本层使用过的节点  </span></span><br><span class="line">                <span class="keyword">if</span> i &gt; start_index <span class="keyword">and</span> nums[i] <span class="keyword">in</span> used:  </span><br><span class="line">                    <span class="keyword">continue</span>  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">len</span>(path) == <span class="number">0</span>:  </span><br><span class="line">                        path.append(nums[i])  </span><br><span class="line">                        used.add(nums[i])  <span class="comment"># 不用pop nums[i] 因为set每层都会初始化定义，使用范围仅限本层  </span></span><br><span class="line">                        backtracing(nums, i + <span class="number">1</span>)  </span><br><span class="line">                        path.pop()  </span><br><span class="line">                    <span class="keyword">elif</span> <span class="built_in">len</span>(path) &gt; <span class="number">0</span>:  </span><br><span class="line">                        <span class="keyword">if</span> path[-<span class="number">1</span>] &lt;= nums[i]:  </span><br><span class="line">                            path.append(nums[i])  </span><br><span class="line">                            used.add(nums[i])  </span><br><span class="line">                            backtracing(nums, i + <span class="number">1</span>)  </span><br><span class="line">                            path.pop()  </span><br><span class="line">                        <span class="keyword">else</span>:  </span><br><span class="line">                            <span class="keyword">continue</span>  </span><br><span class="line">  </span><br><span class="line">        res = []  </span><br><span class="line">        path = []  </span><br><span class="line">        backtracing(nums, <span class="number">0</span>)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p><h4 id="排列问题"><a href="#排列问题" class="headerlink" title="排列问题"></a>排列问题</h4><ul><li><strong>首先排列是有序的，也就是说 [1,2] 和 [2,1] 是两个集合，这和之前分析的子集以及组合所不同的地方</strong>。</li><li>排列每次用到的数组都是除自身已使用元素之外的其他元素，因此不必记录切割位置start_index，只需要记录当前分支，哪些元素已经使用过了，因此使用一个<strong>全局访问标记数组</strong>记录当前路径元素的使用情况。</li><li>既然是全局访问标记数组，因此要弹出递归前加入的元素，进行回溯<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">used[i] = <span class="literal">True</span></span><br><span class="line">backtracing(nums, used)</span><br><span class="line">used[i] = <span class="literal">False</span></span><br></pre></td></tr></table></figure></li></ul><h5 id="全排列"><a href="#全排列" class="headerlink" title="全排列"></a>全排列</h5><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301012034900.png" alt=""></p><ul><li><strong>used数组，其实就是记录此时path里都有哪些元素使用了，一个排列里一个元素只能使用一次</strong>。</li></ul><ol><li>全排列<a href="https://labuladong.github.io/article/?qno=46">labuladong 题解</a><a href="https://leetcode.cn/problems/permutations/description/#">思路</a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">permute</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        <span class="comment"># 所有结果长度都为最长 </span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">nums, used</span>):</span></span><br><span class="line">            <span class="keyword">nonlocal</span> res, path</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(path) == <span class="built_in">len</span>(nums):</span><br><span class="line">                res.append(path[:])</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">                <span class="keyword">if</span> used[i]:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    path.append(nums[i])</span><br><span class="line">                    used[i] = <span class="literal">True</span></span><br><span class="line">                    backtracing(nums, used)</span><br><span class="line">                    used[i] = <span class="literal">False</span></span><br><span class="line">                    path.pop()</span><br><span class="line"></span><br><span class="line">        res = []</span><br><span class="line">        path = []</span><br><span class="line">        used = [<span class="literal">False</span>] * <span class="built_in">len</span>(nums)</span><br><span class="line">        backtracing(nums, used)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></li></ol><h5 id="全排列去重"><a href="#全排列去重" class="headerlink" title="全排列去重"></a>全排列去重</h5><p>数组去重写法：</p><ul><li><p>其中<code>if (i &gt; 0 and nums[i] == nums[i - 1] and not used[i - 1])</code>限制同一层不能遍历相同元素。</p><blockquote><p><strong>如果<code>nums[i] == nums[i - 1]</code> 并且 <code>used[i - 1] == false</code>，就说明：前一个树枝，使用了candidates[i - 1]，也就是说同一树层使用过candidates[i - 1]</strong>。</p><p>当然也可以在树枝上去重，但不如在层上去重效率高。<br>set()去重参考：[[算法笔记-算法&amp;数据结构#组合去重]]</p></blockquote></li><li><p><code>used[i]</code>限制递归分支不能用已使用元素</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (i &gt; <span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>] <span class="keyword">and</span> <span class="keyword">not</span> used[i - <span class="number">1</span>]) <span class="keyword">or</span> used[i]:  </span><br><span class="line">        <span class="keyword">continue</span>  </span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202301012119677.png" alt=""></p><ul><li>used[i - 1] == true，说明<strong>同一树枝</strong>candidates[i - 1]使用过</li><li>used[i - 1] == false，说明<strong>同一树层</strong>candidates[i - 1]使用过</li></ul><ol><li><p>全排列 II<a href="https://labuladong.github.io/article/?qno=47">labuladong 题解</a><br>使用数组去重</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">permuteUnique</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="comment"># 去重  </span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">nums, used</span>):</span>  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(path) == <span class="built_in">len</span>(nums):  </span><br><span class="line">                res.append(path[:])  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):  </span><br><span class="line">                <span class="keyword">if</span> (i &gt; <span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>] <span class="keyword">and</span> <span class="keyword">not</span> used[i - <span class="number">1</span>]) <span class="keyword">or</span> used[i]:  </span><br><span class="line">                    <span class="keyword">continue</span>  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    path.append(nums[i])  </span><br><span class="line">                    used[i] = <span class="literal">True</span>  </span><br><span class="line">                    backtracing(nums, used)  </span><br><span class="line">                    used[i] = <span class="literal">False</span>  </span><br><span class="line">                    path.pop()  </span><br><span class="line">  </span><br><span class="line">        res = []  </span><br><span class="line">        path = []  </span><br><span class="line">        nums.sort()  </span><br><span class="line">        used = [<span class="literal">False</span>] * <span class="built_in">len</span>(nums)  </span><br><span class="line">        backtracing(nums, used)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></li><li><p>全排列 II<a href="https://labuladong.github.io/article/?qno=47">labuladong 题解</a><br>使用set去重：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">permuteUnique</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span>  </span><br><span class="line">        <span class="comment"># 去重    </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">nums, used</span>):</span>  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(path) == <span class="built_in">len</span>(nums):  </span><br><span class="line">                res.append(path[:])  </span><br><span class="line">                <span class="keyword">return</span>  </span><br><span class="line">            cur_used = <span class="built_in">set</span>()  </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):  </span><br><span class="line">                <span class="keyword">if</span> nums[i] <span class="keyword">in</span> cur_used <span class="keyword">or</span> used[i]:  </span><br><span class="line">                    <span class="keyword">continue</span>  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    path.append(nums[i])  </span><br><span class="line">                    used[i] = <span class="literal">True</span>  </span><br><span class="line">                    cur_used.add(nums[i])  </span><br><span class="line">                    backtracing(nums, used)  </span><br><span class="line">                    used[i] = <span class="literal">False</span>  </span><br><span class="line">                    path.pop()  </span><br><span class="line">  </span><br><span class="line">        res = []  </span><br><span class="line">        path = []  </span><br><span class="line">        nums.sort()  </span><br><span class="line">        used = [<span class="literal">False</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums))]  </span><br><span class="line">        backtracing(nums, used)  </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></li></ol><h4 id="棋盘问题"><a href="#棋盘问题" class="headerlink" title="棋盘问题"></a>棋盘问题</h4><h5 id="重新安排行程"><a href="#重新安排行程" class="headerlink" title="重新安排行程"></a>重新安排行程</h5><ul><li>list的遍历过程中，必须使用pop()删除元素，remove删除的是指定元素，在循环过程中改变列表，循环的索引不会变，但对应的值发生了改变，因此要用pop(0)手动维护弹出顺序。</li><li>关键点在于将出发到达的关系转换成一个可递归的结构：<code>map&lt;出发机场，[到达机场列表]&gt;</code></li><li>从起点寻找终点，在将终点作为起点，继续递归的过程</li><li>递归过程中要将使用的机场立刻删除pop(0)，不然会陷入死循环</li><li>题目要求是字典序，因此要对<code>[到达机场列表]</code>排个序</li><li>题目要求有一条路径就可以，因此不用遍历整棵树，设置一个bool类型返回值就可以</li></ul><p><a href="https://leetcode.cn/problems/reconstruct-itinerary/description/">332. 重新安排行程</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findItinerary</span>(<span class="params">self, tickets: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">str</span>]]</span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span>  </span><br><span class="line">        <span class="comment"># 不需要遍历整棵树 找到一条符合的就可以返回了 因此使用bool返回值  </span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">backtracing</span>(<span class="params">start_point</span>):</span>  </span><br><span class="line">            <span class="keyword">nonlocal</span> path, total, tickets_dict  </span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(path) == total + <span class="number">1</span>:  </span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span>  </span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> tickets_dict[start_point]: </span><br><span class="line">        <span class="comment"># 这里必须使用pop,remove删除的是指定元素，在循环过程中改变列表，循环的索引不会变，但对应的值发生了改变，因此要用pop(0)手动维护弹出顺序</span></span><br><span class="line">                end_point = tickets_dict[start_point].pop(<span class="number">0</span>)  <span class="comment"># 弹出最左边航班 表示已使用  </span></span><br><span class="line">                <span class="comment"># tickets_dict[start_point].remove(end_point)                </span></span><br><span class="line">                path.append(end_point)  </span><br><span class="line">                <span class="keyword">if</span> backtracing(end_point):  </span><br><span class="line">                    <span class="comment"># 只要找到一个就可以返回了  </span></span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span>  </span><br><span class="line">                path.pop()  </span><br><span class="line">                tickets_dict[start_point].append(end_point)  <span class="comment">#恢复已使用机场</span></span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 构建 map&lt;出发机场,[到达机场]&gt;的数据结构  </span></span><br><span class="line">        <span class="comment"># 从出发机场开始向下递归，回溯得到结果        </span></span><br><span class="line">        tickets_dict = defaultdict(<span class="built_in">list</span>)  </span><br><span class="line">        <span class="keyword">for</span> ticket <span class="keyword">in</span> tickets:  </span><br><span class="line">            tickets_dict[ticket[<span class="number">0</span>]].append(ticket[<span class="number">1</span>])  </span><br><span class="line">        <span class="comment"># 排序  </span></span><br><span class="line">        <span class="keyword">for</span> airpoint <span class="keyword">in</span> tickets_dict:  </span><br><span class="line">            tickets_dict[airpoint].sort()  </span><br><span class="line">        path = [<span class="string">&quot;JFK&quot;</span>]  </span><br><span class="line">        total = <span class="built_in">len</span>(tickets)  </span><br><span class="line">        backtracing(<span class="string">&quot;JFK&quot;</span>)  </span><br><span class="line">        <span class="keyword">return</span> path</span><br></pre></td></tr></table></figure></p><h3 id="字典树"><a href="#字典树" class="headerlink" title="字典树"></a>字典树</h3><blockquote><p>字典树中 父结点的孩子节点的个数等于字符集的大小。</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 字典树</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.children = [None] * <span class="number">26</span> # 孩子节点的数量</span><br><span class="line">        self.isEnd = False</span><br><span class="line"></span><br><span class="line">    def <span class="built_in">insert</span>(self, word: str) -&gt; None:</span><br><span class="line">        node = self</span><br><span class="line">        <span class="keyword">for</span> ch in word:</span><br><span class="line">            num = <span class="built_in">ord</span>(ch)-<span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>) <span class="meta"># asscii </span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.children[num]: # 孩子节点对应位置为空 说明此处没有元素 执行插入</span><br><span class="line">                node.children= <span class="built_in">TreeNode</span>()</span><br><span class="line">            # 插入完成 或者 此处已有元素 进入下一层</span><br><span class="line">            node = node.children[num]</span><br><span class="line">        node.isEnd =True # 插入完成 设置为叶子结点</span><br></pre></td></tr></table></figure><ul><li>十叉树</li></ul><blockquote><p><a href="https://leetcode-cn.com/problems/k-th-smallest-in-lexicographical-order/">440. 字典序的第K小数字</a></p><p>对于根结点i,孩子节点的数值为 $[10<em>i,…10</em>i+9]$</p><p>进入子树的方式也很简单 只需要把根节点x10即可。</p></blockquote><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20220323100541.png" alt="image-20220323100541771" style="zoom: 33%;" /></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">findKthNumber</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//第一位相同再按照后面的位数排</span></span><br><span class="line">        <span class="comment">//十叉树</span></span><br><span class="line">        <span class="comment">//对于根结点i,孩子节点的数值为 10*i,...10*i+9</span></span><br><span class="line">        <span class="comment">//每个子树包含的节点数为 当前最左侧左孩子 和最右侧右孩子限定的范围 比如子树10的孩子范围（字典序）为(10,11)即[100,101...109]</span></span><br><span class="line">        <span class="comment">//通过前序遍历 可以顺序访问字典序</span></span><br><span class="line">        <span class="keyword">int</span> cur = <span class="number">1</span>; <span class="comment">//根结点</span></span><br><span class="line">        k--;</span><br><span class="line">        <span class="keyword">while</span>(k&gt;<span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">long</span> <span class="keyword">long</span> child_num=<span class="number">0</span>,first_child=cur,last_child=cur+<span class="number">1</span>;</span><br><span class="line">            <span class="comment">//统计该子树下的节点数</span></span><br><span class="line">            <span class="keyword">while</span>(first_child&lt;=n)&#123;</span><br><span class="line">                child_num += <span class="built_in">min</span>((<span class="keyword">long</span> <span class="keyword">long</span>)n+<span class="number">1</span>,last_child) - first_child;  <span class="comment">//右孩子不能超过数组范围</span></span><br><span class="line">                first_child *=<span class="number">10</span>; <span class="comment">//进入下一层</span></span><br><span class="line">                last_child *=<span class="number">10</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(child_num &lt;= k)&#123;</span><br><span class="line">                <span class="comment">//不在当前子树</span></span><br><span class="line">                cur++;</span><br><span class="line">                k-=child_num;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="comment">//在子树中</span></span><br><span class="line">                cur*=<span class="number">10</span>; <span class="comment">//进入子树 </span></span><br><span class="line">                k--;<span class="comment">//减掉根结点</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> cur;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="2的幂"><a href="#2的幂" class="headerlink" title="2的幂"></a>2的幂</h3><blockquote><p>一个数是2的幂，当且仅当n是正整数，并且n的二进制表示中只包含1个1。</p><p>那么如何计算呢，有以下两个结论。</p></blockquote><ol><li><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211028163510.png" alt="image-20211028163510268"></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># n和n-1做与运算 如果结果为0 则n为2的幂</span><br><span class="line">n &amp; (n - 1) == 0 </span><br></pre></td></tr></table></figure><ol><li><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20211028163553.png" alt="image-20211028163553103"></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># n和-n做与运算 结果为n本身 则n为2的幂</span><br><span class="line">n &amp; (-n) == n </span><br></pre></td></tr></table></figure><h3 id="判断质数"><a href="#判断质数" class="headerlink" title="判断质数"></a>判断质数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">bool isPrime(int x) &#123;</span><br><span class="line">if(x &lt; 2) return false;</span><br><span class="line">        for (int i = 2; i * i &lt;= x; ++i) &#123;</span><br><span class="line">        //i * i &lt;= x 不满足时 说明不可能有比i大的数作为x的因数 而比i小的数 前面已经判断过了 因此不必重复判断</span><br><span class="line">            if (x % i == 0) &#123;</span><br><span class="line">                return false;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Fisher-Yates-洗牌算法"><a href="#Fisher-Yates-洗牌算法" class="headerlink" title="Fisher-Yates 洗牌算法"></a>Fisher-Yates 洗牌算法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 循环n次</span><br><span class="line">for (int i = 0; i &lt; nums.size(); ++i) &#123;</span><br><span class="line"># 在[i,n)区间抽取随机下标j,作为待交换的元素下标</span><br><span class="line">          int j = i + rand() % (nums.size() - i);</span><br><span class="line">          // nums[i,n-1]为待乱序的数组 [0,i-1]的部分为乱序后的数组。</span><br><span class="line">          //交换 i j，把随机抽取的元素j放到i的位置。</span><br><span class="line">          swap(nums[i], nums[j]);</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><h3 id="公共父节点"><a href="#公共父节点" class="headerlink" title="公共父节点"></a>公共父节点</h3><p>以完全二叉树为例：<br>先查找较长节点的路径，再查找较短节点的路径，直到遇到形同的节点，即为公共父节点，剩下的部分为公共长度。</p><ul><li>较长的路径要维护完整，即要添加第一个点 <code>patha.add(a)</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cycleLengthQueries</span>(<span class="params">self, n: <span class="built_in">int</span>, queries: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span>  </span><br><span class="line">        <span class="comment"># 寻找公共父节点  </span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_dis</span>(<span class="params">a, b</span>):</span>  </span><br><span class="line">            patha = <span class="built_in">set</span>()  </span><br><span class="line">            patha.add(a)  <span class="comment"># 这里比较重要</span></span><br><span class="line">            <span class="comment"># 1是完全二叉树的根节点  </span></span><br><span class="line">            <span class="comment"># 从a开始向上查找公共父节点            while a != 1:  </span></span><br><span class="line">                <span class="comment"># 向上找  </span></span><br><span class="line">                <span class="keyword">if</span> a % <span class="number">2</span> == <span class="number">0</span>:  </span><br><span class="line">                    a /= <span class="number">2</span>  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    a = (a - <span class="number">1</span>) / <span class="number">2</span>  </span><br><span class="line">                patha.add(a)  </span><br><span class="line">            <span class="comment"># 从b开始向上查找公共父节点  </span></span><br><span class="line">            father = -<span class="number">1</span>  </span><br><span class="line">            dis_b = <span class="number">0</span>  </span><br><span class="line">            <span class="keyword">while</span> b != <span class="number">1</span>:  </span><br><span class="line">                <span class="comment"># 向上找  </span></span><br><span class="line">                <span class="keyword">if</span> b % <span class="number">2</span> == <span class="number">0</span>:  </span><br><span class="line">                    b /= <span class="number">2</span>  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    b = (b - <span class="number">1</span>) / <span class="number">2</span>  </span><br><span class="line">                dis_b += <span class="number">1</span>  </span><br><span class="line">                <span class="keyword">if</span> b <span class="keyword">in</span> patha:  </span><br><span class="line">                    father = b  </span><br><span class="line">                    <span class="keyword">break</span>  </span><br><span class="line">            <span class="comment"># 计算公共长度  </span></span><br><span class="line">            dis_con = <span class="number">0</span>  </span><br><span class="line">            <span class="keyword">while</span> father != -<span class="number">1</span> <span class="keyword">and</span> father != <span class="number">1</span>:  </span><br><span class="line">                <span class="comment"># 向上找  </span></span><br><span class="line">                <span class="keyword">if</span> father % <span class="number">2</span> == <span class="number">0</span>:  </span><br><span class="line">                    father /= <span class="number">2</span>  </span><br><span class="line">                <span class="keyword">else</span>:  </span><br><span class="line">                    father = (father - <span class="number">1</span>) / <span class="number">2</span>  </span><br><span class="line">                dis_con += <span class="number">1</span>  </span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(patha) + dis_b - dis_con  </span><br><span class="line">  </span><br><span class="line">        ans = []  </span><br><span class="line">        <span class="keyword">for</span> query <span class="keyword">in</span> queries:  </span><br><span class="line">            <span class="keyword">if</span> query[<span class="number">0</span>] &lt; query[<span class="number">1</span>]:  </span><br><span class="line">                ans.append(get_dis(query[<span class="number">0</span>], query[<span class="number">1</span>]))  </span><br><span class="line">            <span class="keyword">else</span>:  </span><br><span class="line">                ans.append(get_dis(query[<span class="number">1</span>], query[<span class="number">0</span>]))  </span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure><h3 id="二叉搜索树-1"><a href="#二叉搜索树-1" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h3><blockquote><p>左子树严格小于根结点 右子树严格大于根结点</p><p>二叉搜索树的中序遍历是升序排列的，我们可以将该二叉搜索树的中序遍历的结果记录下来，得到一个升序数组。</p><p>对于普通的二叉树，可以通过先序遍历+中序遍历 或者 中序遍历+后序遍历 确定这颗二叉树。</p><p>而对于二叉搜索树，有严格的顺序关系，中序遍历是有序的，因此可以通过先序遍历或者后序遍历得到中序遍历的排序结果。</p></blockquote><ul><li>迭代</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    TreeNode* searchBST(TreeNode* root, int val) &#123;</span><br><span class="line">        //遍历二叉搜索树</span><br><span class="line">        // 左子树严格小于根结点 右子树严格大于根结点</span><br><span class="line">        if (root==nullptr)</span><br><span class="line">            return NULL;</span><br><span class="line">        if (root-&gt;val == val)</span><br><span class="line">            return root;     </span><br><span class="line">        return searchBST(val &lt; root-&gt;val ? root-&gt;left : root-&gt;right, val);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul><li>递归</li></ul><blockquote><p>递归性能好 空间复杂度低</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    TreeNode *searchBST(TreeNode *root, int val) &#123;</span><br><span class="line">        while (root) &#123;</span><br><span class="line">            if (val == root-&gt;val) &#123;</span><br><span class="line">                return root;</span><br><span class="line">            &#125;</span><br><span class="line">            root = val &lt; root-&gt;val ? root-&gt;left : root-&gt;right;</span><br><span class="line">        &#125;</span><br><span class="line">        return nullptr;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="前序遍历-2"><a href="#前序遍历-2" class="headerlink" title="前序遍历"></a>前序遍历</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void findTarget(TreeNode* root, vector&lt;int&gt; &amp;ans) &#123;</span><br><span class="line">       if(root==nullptr)</span><br><span class="line">           return;</span><br><span class="line">//写下需要的操作</span><br><span class="line">       ans.emplace_back(root-&gt;val);</span><br><span class="line">       findTarget(root-&gt;left, ans);</span><br><span class="line">       findTarget(root-&gt;right, ans);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h3 id="中序遍历-2"><a href="#中序遍历-2" class="headerlink" title="中序遍历"></a>中序遍历</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void inorder(TreeNode *node, vector&lt;int&gt; &amp;res) &#123;</span><br><span class="line">        if (node) &#123;</span><br><span class="line">            inorder(node-&gt;left, res);</span><br><span class="line">            res.push_back(node-&gt;val);</span><br><span class="line">            inorder(node-&gt;right, res);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="二叉树序列化"><a href="#二叉树序列化" class="headerlink" title="二叉树序列化"></a>二叉树序列化</h3><h4 id="二叉搜索树-2"><a href="#二叉搜索树-2" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition for a binary tree node.</span><br><span class="line"> * struct TreeNode &#123;</span><br><span class="line"> *     int val;</span><br><span class="line"> *     TreeNode *left;</span><br><span class="line"> *     TreeNode *right;</span><br><span class="line"> *     TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;</span><br><span class="line"> * &#125;;</span><br><span class="line"> */</span><br><span class="line">class Codec &#123;</span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">    void postorder(TreeNode* root,vector&lt;int&gt; &amp;nodes)&#123;</span><br><span class="line">        if(root==nullptr) return;</span><br><span class="line">        postorder(root-&gt;left,nodes);</span><br><span class="line">        postorder(root-&gt;right,nodes);</span><br><span class="line">        nodes.emplace_back(root-&gt;val);</span><br><span class="line">    &#125;</span><br><span class="line">    vector&lt;int&gt; (string data,char dec)&#123;</span><br><span class="line">        //通过 dec 分割字符串</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        int start=0,cur_pos=0;</span><br><span class="line">        while(cur_pos&lt;data.size())&#123;</span><br><span class="line">             while(cur_pos&lt;data.size() &amp;&amp; data[cur_pos]==dec) cur_pos++;</span><br><span class="line">            start=cur_pos;//更新子字符串的起始位置</span><br><span class="line">            while(cur_pos&lt;data.size() &amp;&amp; data[cur_pos]!=dec) cur_pos++; //找到字符串结束位置</span><br><span class="line">            //截取字符串</span><br><span class="line">            res.emplace_back(stoi(data.substr(start,cur_pos-start)));</span><br><span class="line">        &#125;</span><br><span class="line">        return res;</span><br><span class="line">    &#125;</span><br><span class="line">    // Encodes a tree to a single string.</span><br><span class="line">    string serialize(TreeNode* root) &#123;</span><br><span class="line">        vector&lt;int&gt; nodes;</span><br><span class="line">        postorder(root,nodes);</span><br><span class="line">        // 将后序遍历的数组转为字符串</span><br><span class="line">        string ans=&quot;&quot;;</span><br><span class="line">        if(nodes.size()==0) return ans;</span><br><span class="line">        else&#123;</span><br><span class="line">            for(int i=0;i&lt;nodes.size()-1;i++)</span><br><span class="line">                ans+=to_string(nodes[i])+&quot;,&quot;;</span><br><span class="line">            ans+=to_string(nodes.back());</span><br><span class="line">        &#125;</span><br><span class="line">        return ans;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // Decodes your encoded data to tree.</span><br><span class="line">    TreeNode* deserialize(string data) &#123;</span><br><span class="line">        //将字符串转为 数组</span><br><span class="line">        vector&lt;int&gt; nodes = split(data,&#x27;,&#x27;);</span><br><span class="line">        // for(auto c:nodes) cout&lt;&lt;c&lt;&lt;&quot;. &quot;;</span><br><span class="line">        //重建二叉搜索树 </span><br><span class="line">        //整个树的根节点为后序遍历数组的最后一位 递归建树 左&lt;根&lt;右</span><br><span class="line">        // TreeNode* root = new TreeNode(nodes.back());</span><br><span class="line">        stack&lt;int&gt; st;//栈 正好可以倒序遍历 后序遍历数组</span><br><span class="line">        for (auto &amp; node : nodes) &#123;</span><br><span class="line">            st.emplace(node); </span><br><span class="line">        &#125;</span><br><span class="line">        return construct_tree(INT_MIN, INT_MAX, st);</span><br><span class="line">    &#125;</span><br><span class="line">    TreeNode* construct_tree(int lower,int upper,stack&lt;int&gt;&amp; st)&#123;</span><br><span class="line">        if(st.empty() || st.top()&lt;lower || st.top()&gt; upper) return nullptr;</span><br><span class="line">        int node = st.top();</span><br><span class="line">        st.pop();</span><br><span class="line">        TreeNode* root = new TreeNode(node);</span><br><span class="line">        //先建立右子树</span><br><span class="line">        //因为序列化数组为后序遍历 顺序为左右根 加入栈之后应为根右左</span><br><span class="line">        root-&gt;right =  construct_tree(node,upper,st);</span><br><span class="line">        root-&gt;left =  construct_tree(lower,node,st);</span><br><span class="line">        return root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a>贪心</h3><ol><li>K 次取反后最大化的数组和</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int largestSumAfterKNegations(vector&lt;int&gt;&amp; nums, int k) &#123;</span><br><span class="line">        int min_abs = 100;</span><br><span class="line">        int sum=0;</span><br><span class="line">        // 找出绝对值最小的数</span><br><span class="line">        for(auto num:nums)&#123;</span><br><span class="line">            if(abs(num)&lt;min_abs)</span><br><span class="line">                min_abs = abs(num);</span><br><span class="line">            sum+=num;</span><br><span class="line">        &#125;</span><br><span class="line">        sort(nums.begin(),nums.end());</span><br><span class="line">        // 判断负数和k的数量关系</span><br><span class="line">        for(int i=0;i&lt;nums.size()&amp;&amp; k;i++,k--)</span><br><span class="line">        &#123;</span><br><span class="line">            if(nums[i]&gt;0)</span><br><span class="line">                break;</span><br><span class="line">            // 负数 反转</span><br><span class="line">            sum+=2*abs(nums[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        // 判断k的大小 如果k&gt;0 说明 负数数量小于k 所有的📖都已经变成正数 则对剩余次数 反转 考虑k的奇偶性</span><br><span class="line">        // 偶数 不处理 奇数 反转绝对值最小的数为负数</span><br><span class="line">        if(k&gt;0 &amp;&amp; k%2!=0)</span><br><span class="line">        &#123;</span><br><span class="line">            sum -= 2*min_abs;</span><br><span class="line">        &#125;</span><br><span class="line">return sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="快速乘"><a href="#快速乘" class="headerlink" title="快速乘"></a>快速乘</h3><p>快速幂 使用迭代实现</p><blockquote><p>注意 转成 long long 不然负数会溢出 int</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    // 快速幂</span><br><span class="line">    // 迭代实现 将n转成二进制表示</span><br><span class="line">    double quickMul(double x,long long N)</span><br><span class="line">    &#123;</span><br><span class="line">        double ans = 1.0;</span><br><span class="line">        // 贡献的初始值为 x</span><br><span class="line">        double x_contribute = x;</span><br><span class="line">        // 在对 N 进行二进制拆分的同时计算答案</span><br><span class="line">        while(N&gt;0)</span><br><span class="line">        &#123;</span><br><span class="line">            if(N&amp;1)//最低位为1</span><br><span class="line">            &#123;</span><br><span class="line">               ans*=x_contribute; </span><br><span class="line">            &#125;</span><br><span class="line">            // 右移一位</span><br><span class="line">            x_contribute*=x_contribute;</span><br><span class="line">            N=N&gt;&gt;1;</span><br><span class="line">        &#125;</span><br><span class="line">        return ans;</span><br><span class="line">    &#125;</span><br><span class="line">    double myPow(double x, int n) &#123;</span><br><span class="line">        long long N = n;</span><br><span class="line">        return N &gt;= 0 ? quickMul(x, N) : 1.0 / quickMul(x, -N);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="闰年"><a href="#闰年" class="headerlink" title="闰年"></a>闰年</h3><p>计算闰年的简单方法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">year-(最近的上一个闰年+1)/4</span><br><span class="line"># 可以计算出year距离待计算日期之间有几次闰年</span><br></pre></td></tr></table></figure><h3 id="前缀和"><a href="#前缀和" class="headerlink" title="前缀和"></a>前缀和</h3><p>比如对于字符串<code>s = &quot;||**||**|*&quot;</code>,通过计算前缀和方式就可以计算出该位置之前有多少个”*“，通过区间相减很容易得出范围内”*“的数量。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">int n = s.length();</span><br><span class="line">vector&lt;int&gt; preSum(n);</span><br><span class="line">//计算前缀和 </span><br><span class="line">for (int i = 0, sum = 0; i &lt; n; i++) &#123;</span><br><span class="line">    if (s[i] == &#x27;*&#x27;) &#123;</span><br><span class="line">      sum++;</span><br><span class="line">     &#125;</span><br><span class="line">    preSum[i] = sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="线段树"><a href="#线段树" class="headerlink" title="线段树"></a>线段树</h3><blockquote><p><a href="https://leetcode-cn.com/problems/range-sum-query-mutable/solution/qu-yu-he-jian-suo-shu-zu-ke-xiu-gai-by-l-76xj/">例题1</a></p></blockquote><h4 id="数组分段"><a href="#数组分段" class="headerlink" title="数组分段"></a>数组分段</h4><ul><li>数组分块大小：<code>int  n = sqrt(数组.size())</code></li></ul><p>线段树 segmentTree 是一个二叉树，每个结点保存数组 nums 在区间 $[s,e]$ 的最小值、最大值或者总和等信息。</p><p>时间复杂度：O(n)</p><p>空间复杂度：O(n) n为数组长度</p><p>线段树的所有操作复杂度为 O(logn)，</p><ul><li>经验</li></ul><blockquote><p>这是一道很经典的题目，通常还能拓展出一大类问题。</p><p>针对不同的题目，我们有不同的方案可以选择（假设我们有一个数组）：</p><p>数组不变，求区间和：「前缀和」、「树状数组」、「线段树」<br>多次修改某个数（单点），求区间和：「树状数组」、「线段树」<br>多次修改某个区间，输出最终结果：「差分」<br>多次修改某个区间，求区间和：「线段树」、「树状数组」（看修改区间范围大小）<br>多次将某个区间变成同一个数，求区间和：「线段树」、「树状数组」（看修改区间范围大小）</p></blockquote><ul><li>创建线段树 数组实现</li></ul><blockquote><p>线段树可以用树也可以用数组（堆式存储）来实现。对于数组实现，假设根结点的下标为 0，如果一个结点在数组的下标为 $node$，那么它的左子结点下标为 $node×2+1$，右子结点下标为 $node×2+2$。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">void build(int node, int s, int e, vector&lt;int&gt; &amp;nums) &#123;</span><br><span class="line">        if (s == e) &#123;</span><br><span class="line">            segmentTree[node] = nums[s];</span><br><span class="line">            return;</span><br><span class="line">        &#125;</span><br><span class="line">        int m = s + (e - s) / 2;</span><br><span class="line">        build(node * 2 + 1, s, m, nums);//左节点部分</span><br><span class="line">        build(node * 2 + 2, m + 1, e, nums);//右节点部分</span><br><span class="line">        segmentTree[node] = segmentTree[node * 2 + 1] + segmentTree[node * 2 + 2];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="树状数组"><a href="#树状数组" class="headerlink" title="树状数组"></a>树状数组</h3><blockquote><p><a href="https://www.bilibili.com/video/BV1pE41197Qj?spm_id_from=333.337.search-card.all.click">视频讲解</a></p><p>树状数组下标要从1开始</p></blockquote><h4 id="lowBit"><a href="#lowBit" class="headerlink" title="lowBit"></a>lowBit</h4><p>非负整数n在二进制表示下最低位1及其后面的0构成的数值</p><p>寻找最后一位1<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int lowBit(int x) &#123;</span><br><span class="line">    return x &amp; -x;// -x 表示x 取反加1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>将最后一位1变成0<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x &amp; (x-1)</span><br></pre></td></tr></table></figure></p><p>模版：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;<span class="keyword">int</span>&gt; tree;</span><br><span class="line">    vector&lt;<span class="keyword">int</span>&gt; &amp;nums;</span><br><span class="line"><span class="comment">//取最低位的1 对应的值，具体为什么这么做，可以看视频里表讲解那块儿</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lowBit</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x &amp; -x;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//更新index节点的值 后续节点也要更新 父节点的下标是 当前节点的index加当前index的LowBit值</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> index, <span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (index &lt; tree.<span class="built_in">size</span>()) &#123;</span><br><span class="line">            tree[index] += val;</span><br><span class="line">            index += <span class="built_in">lowBit</span>(index);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//查询前缀和 当前节点index的前缀和为左上角所有满足 index-LOwBit(index)下标的节点和</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">prefixSum</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (index &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            sum += tree[index];</span><br><span class="line">            index -= <span class="built_in">lowBit</span>(index);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="树的直径"><a href="#树的直径" class="headerlink" title="树的直径"></a>树的直径</h3><p><a href="https://leetcode-cn.com/problems/minimum-height-trees/solution/zui-xiao-gao-du-shu-by-leetcode-solution-6v6f/">数学思想：</a></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204061028280.png" alt="image-20220406102802138" style="zoom:33%;" /></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204061029776.png" alt="image-20220406102907649" style="zoom:33%;" /></p><h3 id="矩阵切分"><a href="#矩阵切分" class="headerlink" title="矩阵切分"></a>矩阵切分</h3><p>对矩阵来说(0,0)表示左上角的起点，将矩阵切分只需要给定左上角坐标和需要切分的长度即可。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204291021320.png" alt="image-20220429102133207" style="zoom: 50%;" /></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dfs(grid, x, y, len/2),//左上</span><br><span class="line">dfs(grid, x, y + len/2, len/2),//左下</span><br><span class="line">dfs(grid, x+len/2, y, len/2),</span><br><span class="line">dfs(grid, x+len/2, y+len/2, len/2)</span><br></pre></td></tr></table></figure><h3 id="三角形面积"><a href="#三角形面积" class="headerlink" title="三角形面积"></a>三角形面积</h3><p>顶点：<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202205151003385.png" alt="image-20220515100340328" style="zoom:50%;" /></p><p>面积公式：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202205151003110.png" alt="image-20220515100328908" style="zoom:50%;" /></p><p>代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 已知三个顶点的面积公式</span><br><span class="line">    double triangleArea(int x1, int y1, int x2, int y2, int x3, int y3) &#123;</span><br><span class="line">        return 0.5 * abs(x1 * y2 + x2 * y3 + x3 * y1 - x1 * y3 - x2 * y1 - x3 * y2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 算法 </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SVN常用命令</title>
      <link href="/2023/01/02/SVN%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2023/01/02/SVN%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h1 id="svn"><a href="#svn" class="headerlink" title="svn"></a>svn</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">下载：</span><br><span class="line">svn checkout svn://172.16.101.54/insight-backend-web</span><br><span class="line"></span><br><span class="line">上传：</span><br><span class="line">svn ci -m &quot;maqi upload&quot; </span><br><span class="line"></span><br><span class="line">更新：</span><br><span class="line">svn update</span><br><span class="line"></span><br><span class="line">新增：</span><br><span class="line">svn add &#123;src&#125;</span><br><span class="line"></span><br><span class="line">删除：</span><br><span class="line">svn delete &#123;src&#125; --force</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 开发工具 </tag>
            
            <tag> svn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Asimok的面经</title>
      <link href="/2022/12/17/Asimok%E7%9A%84%E9%9D%A2%E7%BB%8F/"/>
      <url>/2022/12/17/Asimok%E7%9A%84%E9%9D%A2%E7%BB%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><h2 id="常用工具"><a href="#常用工具" class="headerlink" title="常用工具"></a>常用工具</h2><h3 id="GIT"><a href="#GIT" class="headerlink" title="GIT"></a>GIT</h3><h4 id="GIT-amp-SVN"><a href="#GIT-amp-SVN" class="headerlink" title="GIT&amp;SVN"></a>GIT&amp;SVN</h4><p><a href="https://www.cnblogs.com/Eva0110/p/14951778.html">https://www.cnblogs.com/Eva0110/p/14951778.html</a></p><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><h4 id="svn"><a href="#svn" class="headerlink" title="svn"></a>svn</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">下载：</span><br><span class="line">svn checkout svn://172.16.101.54/insight-backend-web</span><br><span class="line"></span><br><span class="line">上传：</span><br><span class="line">svn ci -m &quot;maqi upload&quot; </span><br><span class="line"></span><br><span class="line">更新：</span><br><span class="line">svn update</span><br><span class="line"></span><br><span class="line">新增：</span><br><span class="line">svn add &#123;src&#125;</span><br><span class="line"></span><br><span class="line">删除：</span><br><span class="line">svn delete dist --force</span><br></pre></td></tr></table></figure><h4 id="git"><a href="#git" class="headerlink" title="git"></a>git</h4><h2 id="机器学习-算法工程师常考面试题"><a href="#机器学习-算法工程师常考面试题" class="headerlink" title="机器学习/算法工程师常考面试题"></a>机器学习/算法工程师常考面试题</h2>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 算法 </tag>
            
            <tag> C++ </tag>
            
            <tag> 面经 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Obsidian迁移hexo</title>
      <link href="/2022/12/17/Obsidian%E8%BF%81%E7%A7%BBhexo%E8%84%9A%E6%9C%AC/"/>
      <url>/2022/12/17/Obsidian%E8%BF%81%E7%A7%BBhexo%E8%84%9A%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<h2 id="迁移脚本"><a href="#迁移脚本" class="headerlink" title="迁移脚本"></a>迁移脚本</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copyfile  </span><br><span class="line">  </span><br><span class="line">source_dir = <span class="string">&quot;/Users/maqi/SecondBrain/&quot;</span>  </span><br><span class="line">target_dir = <span class="string">&quot;/Users/maqi/Public/blog/temp/&quot;</span>  </span><br><span class="line">dirs = os.listdir(source_dir)  </span><br><span class="line"><span class="keyword">for</span> cur_dir <span class="keyword">in</span> dirs:  </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> cur_dir.__contains__(<span class="string">&#x27;.&#x27;</span>):  </span><br><span class="line">        cur_path = os.path.join(source_dir, cur_dir)  </span><br><span class="line">        files = os.listdir(cur_path)  </span><br><span class="line">        <span class="keyword">for</span> file <span class="keyword">in</span> files:  </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> files.__contains__(<span class="string">&#x27;.&#x27;</span>):  </span><br><span class="line">                copyfile(os.path.join(cur_path, file), os.path.join(target_dir, file))</span><br></pre></td></tr></table></figure><h2 id="批量重命名"><a href="#批量重命名" class="headerlink" title="批量重命名"></a>批量重命名</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os  </span><br><span class="line">  </span><br><span class="line">source_dir = <span class="string">&quot;/Users/maqi/SecondBrain/机器学习&amp;深度学习的副本&quot;</span>  </span><br><span class="line">target_dir = <span class="string">&quot;/Users/maqi/SecondBrain/机器学习&amp;深度学习的副本&quot;</span>  </span><br><span class="line">target_categories = <span class="string">&quot;categories: 机器学习&amp;深度学习\n&quot;</span>  </span><br><span class="line">files = os.listdir(source_dir)  </span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> files:  </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(source_dir, file), <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">        content = f.readlines()  </span><br><span class="line">        content[<span class="number">3</span>] = target_categories  </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(source_dir, file), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">        f.writelines(content)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 脚本 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>iterm2配置</title>
      <link href="/2022/12/17/iterm2%E9%85%8D%E7%BD%AE/"/>
      <url>/2022/12/17/iterm2%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="How-to-install"><a href="#How-to-install" class="headerlink" title="How to install"></a>How to install</h1><h2 id="iTerm2"><a href="#iTerm2" class="headerlink" title="iTerm2"></a>iTerm2</h2><pre><code>brew cask install iterm2</code></pre><p>Or, if you do not have homebrew (you should ;)): <a href="http://www.iterm2.com/downloads.html">Download</a> and install iTerm2 </p><p>iTerm2 has better color fidelity than the built in Terminal, so your themes will look better.</p><p>Get the iTerm color settings</p><ul><li><a href="https://raw.githubusercontent.com/mbadolato/iTerm2-Color-Schemes/master/schemes/Solarized%20Dark%20-%20Patched.itermcolors">Solarized Dark theme</a> (patched version to fix the bright black value)</li><li><a href="https://raw.githubusercontent.com/altercation/solarized/master/iterm2-colors-solarized/Solarized%20Light.itermcolors">Solarized Light theme</a></li><li><a href="http://iterm2colorschemes.com/">More themes @ iterm2colorschemes</a></li></ul><p>Just save it somewhere and open the file(s). The color settings will be imported into iTerm2. Apply them in iTerm through iTerm → preferences → profiles → colors → load presets. You can create a different profile other than <code>Default</code> if you wish to do so.</p><h1 id="Oh-My-Zsh"><a href="#Oh-My-Zsh" class="headerlink" title="Oh My Zsh"></a>Oh My Zsh</h1><p>More info here: <a href="https://github.com/robbyrussell/oh-my-zsh">https://github.com/robbyrussell/oh-my-zsh</a></p><h2 id="Install-with-curl"><a href="#Install-with-curl" class="headerlink" title="Install with curl"></a>Install with curl</h2><pre><code>sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;</code></pre><p>When the installation is done, edit <code>~/.zshrc</code> and set <code>ZSH_THEME=&quot;agnoster&quot;</code> for the default look. Or better yet, go for Powerlevel10k.</p><h2 id="Powerlevel9k-Powerlevel10k"><a href="#Powerlevel9k-Powerlevel10k" class="headerlink" title="Powerlevel9k / Powerlevel10k"></a>Powerlevel9k / Powerlevel10k</h2><p>Why Powerlevel10k? Well, because it’s a drop-in replacement for Powerlevel9k, just a lot faster to render your prompt. <code>ls</code> feels fast again!</p><p>So if you prefer the Powerlevel10k look with added info such as exit codes and timestamps on the right, run:</p><pre><code>git clone https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k</code></pre><p>Then edit your <code>~/.zshrc</code> and set <code>ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot;</code>. Once you do so, when you start a new terminal session, the Powerlevel10 configure wizard will be launched to set your prompt, beware, there are many many options!</p><p>Powerlevel10k offers a whole lot more and is extremely configurable, best is to <a href="https://github.com/romkatv/powerlevel10k#extremely-customizable">check its project page</a>.</p><p>If you want to trigger the configuration wizard immediately, simply run <code>p10k configure</code> to discover all options, which are plentiful.</p><h2 id="Install-a-patched-font"><a href="#Install-a-patched-font" class="headerlink" title="Install a patched font"></a>Install a patched font</h2><p>If you did not go with Powerlevel9k or you want another font, read on:</p><ul><li><a href="https://github.com/powerline/fonts/blob/master/SourceCodePro/Source%20Code%20Pro%20for%20Powerline.otf">Source Code Pro</a></li><li><a href="https://github.com/Falkor/dotfiles/blob/master/fonts/SourceCodePro%2BPowerline%2BAwesome%2BRegular.ttf">Source Code Pro + Font Awesome</a>, this one is needed if you want the icons from Font Awesome as shown in the screenshot for Powerlevel10k.</li><li><a href="https://github.com/powerline/fonts">Others @ powerline fonts</a></li></ul><p>Open the downloaded font and press “Install Font”.</p><p>Set this font in iTerm2 (iTerm → Preferences → Profiles → Text → Font), in the dropdown select the desired Font. You will see it change on the fly.</p><p>Restart iTerm2 for all changes to take effect.</p><h1 id="Further-tweaking"><a href="#Further-tweaking" class="headerlink" title="Further tweaking"></a>Further tweaking</h1><p>Things like</p><ul><li>auto suggestions</li><li>word jumping with arrow keys / natural text editing</li><li>shorter prompt style</li><li>syntax highlighting</li><li>visual studio code config</li></ul><p>can be found in the section below.</p><h2 id="Auto-suggestions-for-Oh-My-Zsh"><a href="#Auto-suggestions-for-Oh-My-Zsh" class="headerlink" title="Auto suggestions (for Oh My Zsh)"></a>Auto suggestions (for Oh My Zsh)</h2><p><img src="https://gist.githubusercontent.com/kevin-smets/9722391f8b3e4fa436b1c1dcf05ecd88/raw/fba93f6061a73eaedefad2e8c6266ab4ed90fbbf/autocomplete.png" alt="Auto suggestions"></p><p>Just follow these steps: <a href="https://github.com/zsh-users/zsh-autosuggestions/blob/master/INSTALL.md#oh-my-zsh">https://github.com/zsh-users/zsh-autosuggestions/blob/master/INSTALL.md#oh-my-zsh</a></p><p>If the auto suggestions do not appear to show, it could be a problem with your color scheme. Under “iTerm → Preferences → Profiles → Colors tab”, check the value of Black Bright, that is the color your auto suggestions will have. It will be displayed on top of the Background color. If there is not enough contrast between the two, you won’t see the suggestions even if they’re actually there..</p><h2 id="Enable-word-jumps-and-word-deletion-aka-natural-text-selection"><a href="#Enable-word-jumps-and-word-deletion-aka-natural-text-selection" class="headerlink" title="Enable word jumps and word deletion, aka natural text selection"></a>Enable word jumps and word deletion, aka natural text selection</h2><p>By default, word jumps (option + → or ←) and word deletions (option + backspace) do not work. To enable these, go to “iTerm → Preferences → Profiles → Keys → Presets… → Natural Text Editing → Boom! Head explodes”</p><h2 id="Custom-prompt-styles"><a href="#Custom-prompt-styles" class="headerlink" title="Custom prompt styles"></a>Custom prompt styles</h2><p>By default, your prompt will now show “user@hostname” in the prompt. This will make your prompt rather bloated. To remove this you can add the line <code>DEFAULT_USER=$(whoami)</code>to <code>~/.zshrc</code>.</p><p>For further customisation of your prompt, you can follow a great guide here: <a href="https://code.tutsplus.com/tutorials/how-to-customize-your-command-prompt--net-24083">https://code.tutsplus.com/tutorials/how-to-customize-your-command-prompt--net-24083</a></p><h2 id="Syntax-highlighting"><a href="#Syntax-highlighting" class="headerlink" title="Syntax highlighting"></a>Syntax highlighting</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install zsh-syntax-highlighting</span><br></pre></td></tr></table></figure><p>If you do not have or do not like homebrew, follow <a href="https://github.com/zsh-users/zsh-syntax-highlighting/blob/master/INSTALL.md">the installation instructions</a> instead.</p><p>After installation, add the following line</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /usr/local/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh</span><br></pre></td></tr></table></figure><p>to <strong>the end</strong> of your <code>.zshrc</code> file. After that, it’s best to restart your terminal. Sourcing your <code>~/.zshrc</code> does not seem to work well with this plugin.</p><h2 id="Visual-Studio-Code-config"><a href="#Visual-Studio-Code-config" class="headerlink" title="Visual Studio Code config"></a>Visual Studio Code config</h2><p>Installing a patched font will mess up the integrated terminal in VS Code unless you use the proper settings. You’ll need to go to settings (CMD + ,) and add or edit the following values:</p><ul><li>for Source Code Pro + Font Awesome: <code>&quot;terminal.integrated.fontFamily&quot;: &quot;&#39;SourceCodePro+Powerline+Awesome Regular&#39;&quot;</code>. The single quotes are important! Restart VS Code after the config change.</li><li>for Source Code Pro: <code>&quot;terminal.integrated.fontFamily&quot;: &quot;Source Code Pro for Powerline&quot;</code></li><li>for Meslo: <code>&quot;terminal.integrated.fontFamily&quot;: &quot;Meslo LG M for Powerline&quot;</code></li><li>for other fonts you’ll need to check the font name in Font Book. You can right click on them on select “Show in Finder” to get the exact name.</li></ul><p>You can also set the fontsize e.g.: <code>&quot;terminal.integrated.fontSize&quot;: 14</code></p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 环境配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Article Reranking by Memory-Enhanced Key Sentence Matching for Detecting Previously Fact-Checked Claims</title>
      <link href="/2022/12/05/Article%20Reranking%20by%20Memory-Enhanced%20Key%20Sentence%20Matching%20for%20Detecting%20Previously%20Fact-Checked%20Claims/"/>
      <url>/2022/12/05/Article%20Reranking%20by%20Memory-Enhanced%20Key%20Sentence%20Matching%20for%20Detecting%20Previously%20Fact-Checked%20Claims/</url>
      
        <content type="html"><![CDATA[<h1 id="Article-Reranking-by-Memory-Enhanced-Key-Sentence-Matching-for-Detecting-Previously-Fact-Checked-Claims"><a href="#Article-Reranking-by-Memory-Enhanced-Key-Sentence-Matching-for-Detecting-Previously-Fact-Checked-Claims" class="headerlink" title="Article Reranking by Memory-Enhanced Key Sentence Matching for Detecting Previously Fact-Checked Claims"></a>Article Reranking by Memory-Enhanced Key Sentence Matching for Detecting Previously Fact-Checked Claims</h1><blockquote><p> 论文：<a href="https://paperswithcode.com/paper/article-reranking-by-memory-enhanced-key-1">Article Reranking by Memory-Enhanced Key Sentence Matching for Detecting Previously Fact-Checked Claims</a><br> 代码：<a href="https://github.com/ictmcg/mtm">https://github.com/ictmcg/mtm</a><br> 会议：<a href="https://paperswithcode.com/conference/acl-2021-5">ACL 2021</a><br> 参考：<a href="https://zhuanlan.zhihu.com/p/393615707">https://zhuanlan.zhihu.com/p/393615707</a><br> 飞书：<a href="https://zlc6vppbrn.feishu.cn/docx/QHgRdU0CtoLBipxyx86cZ807nec">https://zlc6vppbrn.feishu.cn/docx/QHgRdU0CtoLBipxyx86cZ807nec</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>以前经过事实核查的假声明仍然可以在社交媒体上传播。 为了减轻它们的持续传播，检测以前经过事实核查的声明是必不可少的。 在典型的两阶段检索框架中，现有的工作是检索事实核查文章（FC-articles）进行检测，重点是对候选文章进行重新排序。然而，由于它们忽略了语料库冠词的以下特点，它们的表现可能受到限制：</p><ol><li>经常引用声明来描述被检查的事件，除了提供语义之外，还提供词汇信息。</li><li>介绍或揭穿声明的句子模板在文章中很常见，提供模式信息。<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NzJkMTA1OTE2MmM5YTUzZTM1Nzc2NzcxNWM4ZDY4M2ZfYmFqNjdCejQxenB6RTZSUENhSTB6OHJBcGJwZVN1M25fVG9rZW46Ym94Y24zMGdOQTNkZktPNk9WZkZVdHljZ01iXzE2NzAyMTQ3ODU6MTY3MDIxODM4NV9WNA" alt=""></li></ol><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>本文提出了一种新的重排序器MTM（MemoryEnhanced Transformers for Matching）,利用事件（词汇和语义）和模式信息选择关键句子对FC（fact-checking）文章进行排序。</p><ul><li>对于事件信息，我们建议微调Transformer with regression of ROUGE.</li><li>对于模式信息，我们生成模式向量作为存储库，与包含模式的部分进行匹配。<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=OWQwYzg1MTIwNjAzMDFlMmQ5NTVlYzEwMDRhNTMxMGRfeEZHQjhyODhrcDRDczhGNkREMkNVME53cHU1TWVUUUtfVG9rZW46Ym94Y252V2p6SG1YcUZaanZEWGVGUHFVNXFoXzE2NzAyMTQ4MDM6MTY3MDIxODQwM" alt=""><br>通过融合事件和模式信息，我们选择关键语句来表示一篇文章，然后使用声明、关键语句和模式来预测文章是否对给定的声明进行了事实检验。</li></ul><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjZhODdiOTc5ODQwYTFhYTYxZjUxOGJlZTE4YTg5YWNfdlBRN2IwbmdlQ0g3cFlIUTBrWnVWcFhtVVJKVlIzb2lfVG9rZW46Ym94Y252V2p6SG1YcUZaanZEWGVGUHFVNXFoXzE2NzAyMjE2NTI6MTY3MDIyNTI1Ml9WNA" alt=""></p><h3 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h3><p>$q :声明\ k1:候选集\  D:FC-articles$D  由BM25检索得到<br>$文档S句子集合：S = {s_1, …, s_l}$<br>实现：<strong>Memory-enhanced Transformers for Matching (MTM)</strong></p><ol><li><p>关键句识别</p><blockquote><p>对于每一个句子，从Rouge-Guided Transformer(ROT)和Pattern Memory Bank(PMB)中得到claim-sentence相关性得分。 分数表明句子与声明和模式向量的相似性，即成为关键句子的可能性。</p></blockquote></li><li><p>文档相关性预测</p><blockquote><p>选择top-k2句子用于与声明和模式向量的更复杂的交互和聚合。 聚合向量用于最终预测。</p></blockquote></li></ol><h3 id="Key-Sentence-Identiﬁcation"><a href="#Key-Sentence-Identiﬁcation" class="headerlink" title="Key Sentence Identiﬁcation"></a>Key Sentence Identiﬁcation</h3><h4 id="ROUGE-guided-Transformer-ROT"><a href="#ROUGE-guided-Transformer-ROT" class="headerlink" title="ROUGE-guided Transformer (ROT)"></a>ROUGE-guided Transformer (ROT)</h4><blockquote><p>用来评估声明q和句子s的相关性，包括词汇和语义。<br>使用单层Transformer来获得Q和S的初始语义表示，该层使用BERT的第一个块初始化。</p></blockquote><script type="math/tex; mode=display">z_{q,s} = Transformer ([CLS]\ q\ [SEP] s) \tag{1}</script><p>为了使ROT能够考虑词相关性，使用ROUGE指导Transformer微调。</p><blockquote><p>直观上认为，词汇关联可以用表征重叠来表征，而Rouge正是用表征重叠来衡量的。<br>我们最小化q和s，预测结果 和 ROUGE-2之间的均方误差，以优化ROT。</p><script type="math/tex; mode=display">\hat{R}(q, s) = MLP (z_{q,s}([CLS])) \tag{2}</script><script type="math/tex; mode=display">L_R = \| \hat{R} (q, s) − R_2(q, s)\|^2_2 + λ_R\|∆θ\|^2_2 \tag{3}</script><ol><li>第一部分是回归损失 。</li><li>第二部分限制参数的变化，因为要保持捕捉语义关联的能力。 $λ_R$是一个控制因子，Δθ表示参数的变化。</li></ol></blockquote><h4 id="Pattern-Memory-Bank-PMB"><a href="#Pattern-Memory-Bank-PMB" class="headerlink" title="Pattern Memory Bank (PMB)"></a>Pattern Memory Bank (PMB)</h4><ul><li>聚类的方式<br><del>暂时用不到，设计比较复杂，之后有兴趣可以回过头看原文。</del></li></ul><h4 id="Key-Sentence-Selection"><a href="#Key-Sentence-Selection" class="headerlink" title="Key Sentence Selection"></a>Key Sentence Selection</h4><p>一个句子是否被选为关键句是通过结合声明和模式句子相关性得分来确定的。 前者用ROT训练的q和s的距离计算公式(8)，后者用PMB中最近的模式向量与残差嵌入之间的距离计算。 分数缩放为[0,1]。 对于d中的每个句子s，相关性得分计算如下：</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=OTdkZjhlOThiYjZhMjc0Mjg0ZDZhMDViZGI0ZjBkNTNfSVZtakE5NzVRSWZFM01FQWZ3WjMyMGdxSHQwNEtZRnVfVG9rZW46Ym94Y25qRk84TWNiVUdZaXdPVXlmbXJQdnRkXzE2NzAyMTQ4MDM6MTY3MDIxODQwM19WNA" alt=""><br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=MWRhOWYzNDY0MzYxYzhmOTgxNTNhMjY5NWFkMmUxNmNfMG8ycU1MbGtnQWJmS0tMM3BTMXd1a0NUMUZpVTJzMDJfVG9rZW46Ym94Y25DVzZwVmVXQktvbWhsQjI1dTVROFViXzE2NzAyMTQ4MDM6MTY3MDIxODQwM19WNA" alt=""><br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjgwOTJjNjY4ZTNlNzQzZjdmYjY0MzIwNGMxNDg5MDBfN2F3eUVaTkpjRGM0eFZ1V1RCMEpmRHRQRGFMeGRlMXRfVG9rZW46Ym94Y25jZ3NWUktMSG9IOFF5MVpXeWcxRnJnXzE2NzAyMTQ4MDM6MTY3MDIxODQwM19WNA" alt=""></p><p>按照相关性得分选出top-k2关键句：<script type="math/tex">K = {s^{key}_i \ (q, d)}^{k_2}_{i=1}</script></p><h3 id="Article-Relevance-Prediction-ARP"><a href="#Article-Relevance-Prediction-ARP" class="headerlink" title="Article Relevance Prediction (ARP)"></a>Article Relevance Prediction (ARP)</h3><h4 id="Sentence-representation"><a href="#Sentence-representation" class="headerlink" title="Sentence representation"></a>Sentence representation</h4><p>使用multi-layer Transformer建模更复杂的声明和关键句之间的相互作用。</p><script type="math/tex; mode=display">z'_{q,s^{key}} = MultiTransformer(z_{q,s^{key}} ) \tag{11}</script><blockquote><p>$z_{q,s^{key}}$：ROT的输出</p></blockquote><p>再分别计算 $z_{q,s^{key}}$中q和s的所有输出token向量的平均值，得到固定大小的句子向量 $q’ $和$$s^{key’}$。</p><h4 id="Weighted-memory-aware-aggregation"><a href="#Weighted-memory-aware-aggregation" class="headerlink" title="Weighted memory-aware aggregation"></a>Weighted memory-aware aggregation</h4><p>对于最终预测，我们使用分数加权的记忆感知聚合。 为了让预测器知道模式信息，我们将相应的最近模式向量append到声明和关键句向量：</p><p>直观上，分数较高的句子应该多加关注，因此公式（12）的按照公式（10）的相关得分加权。</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ODU4YWFmZDRiMjE4ZTM2ZDM4NTNmZGExMDgwNzk1MzlfbUhFRkJKaGE1ZkhQVW9QSlB1RDJMRVF2eHhzYXh1Q3BfVG9rZW46Ym94Y25FakJWZU5kT0RMUWphemhiekhVVTk2XzE2NzAyMTQ4MDM6MTY3MDIxODQwM19WNA" alt=""></p><p>使用MLP预测得到q,d相关性概率，$\hat{y} _{q,d} &gt; 0.5$认为相关。</p><p>交叉熵损失函数：</p><script type="math/tex; mode=display">L_M = CrossEntropy(\hat{y}_{q,d}, y_{q,d}) \tag{15}</script><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 假新闻检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Generalizing to the Future Mitigating Entity Bias in Fake News Detection</title>
      <link href="/2022/12/05/Generalizing%20to%20the%20Future%20Mitigating%20Entity%20Bias%20in%20Fake%20News%20Detection/"/>
      <url>/2022/12/05/Generalizing%20to%20the%20Future%20Mitigating%20Entity%20Bias%20in%20Fake%20News%20Detection/</url>
      
        <content type="html"><![CDATA[<h1 id="Generalizing-to-the-Future-Mitigating-Entity-Bias-in-Fake-News-Detection"><a href="#Generalizing-to-the-Future-Mitigating-Entity-Bias-in-Fake-News-Detection" class="headerlink" title="Generalizing to the Future Mitigating Entity Bias in Fake News Detection"></a>Generalizing to the Future Mitigating Entity Bias in Fake News Detection</h1><blockquote><p>论文：<a href="https://arxiv.org/abs/2204.09484">Generalizing to the Future:Mitigating Entity Bias in Fake News Detection</a><br>代码：<a href="https://github.com/ictmcg/endef-sigir2022">https://github.com/ictmcg/endef-sigir2022</a><br>会议：SIGIR 2022<br>飞书：<a href="https://zlc6vppbrn.feishu.cn/docx/doxcnGnsfAAZXGYBUlKaqWYX4mg">https://zlc6vppbrn.feishu.cn/docx/doxcnGnsfAAZXGYBUlKaqWYX4mg</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>现有的假新闻检测方法忽略了真实数据中的非预期实体偏差，严重影响了模型对未来数据的泛化能力。 例如，2010-2017年，包含“唐纳德·特朗普”实体的97%的新闻在我们的数据中是真实的，但这一比例在2018年降至仅33%。 这将导致在前一个场景中训练的模型很难推广到后一个场景，因为它倾向于预测关于唐纳德·特朗普的新闻是真实的，以降低训练损失。</p><p>本文提出了一个实体去偏框架(ENDEF)，该框架从因果角度出发，通过减轻实体偏差，虚假新闻检测模型推广到未来数据中。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212051436587.png" alt=""><br>基于实体、新闻内容和新闻真实性之间的因果关系图，分别对训练过程中各个原因（实体和内容）的贡献进行建模。 在推理阶段，我们去除实体的直接影响，以减轻实体偏差。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在中英文数据集上进行的大量离线实验表明，该框架在很大程度上提高了基本假新闻检测器的性能，在线测试也验证了其在实际应用中的优越性。</p><p>是第一个明确提高假新闻检测模型对未来数据泛化能力的工作。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 假新闻检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-span Style Extraction for Generative Reading Comprehension</title>
      <link href="/2022/12/05/Multi-span%20Style%20Extraction%20for%20Generative%20Reading%20Comprehension/"/>
      <url>/2022/12/05/Multi-span%20Style%20Extraction%20for%20Generative%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-span-Style-Extraction-for-Generative-Reading-Comprehension"><a href="#Multi-span-Style-Extraction-for-Generative-Reading-Comprehension" class="headerlink" title="Multi-span Style Extraction for Generative Reading Comprehension"></a>Multi-span Style Extraction for Generative Reading Comprehension</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2009.07382">https://arxiv.org/abs/2009.07382</a><br> 代码：<a href="https://github.com/chunchiehy/musst">https://github.com/chunchiehy/musst</a><br> 会议：AAAI-2021<br> 飞书：<a href="https://zlc6vppbrn.feishu.cn/docx/doxcnnIj90LvJt2BV33MMNyEKbh">https://zlc6vppbrn.feishu.cn/docx/doxcnnIj90LvJt2BV33MMNyEKbh</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>生成式机器阅读理解（MRC）的答案通常分布在输入问题和文档中，正确答案由单个或多个片段组成。对于答案为单个片段的MRC任务通常称为抽取式MRC，并且已有大量性能优异的single-span抽取模型，但当场景切换到生成式任务时通常会产生不完整的答案或引入多余的词，因此本文的目标是将single-span提取方法扩展到multi-span，使用生成式MRC的方法解决multi-span的QA问题。<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NjVjZmI0NWM0MWRlNTkxNWY1Njk4YzIxYTNhOTI5OGFfSWpIbXlNejIyWXV6ZG9lYTJVdDlmWWxDQVdSYnBTM1ZfVG9rZW46Ym94Y24ydUJlbk81QUptV21LYXhDWGFLM1hWXzE2NzAyMjI1NjI6MTY3MDIyNjE2Ml9WNA" alt="|540"></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p><strong>MUSST</strong> for MUlti-Span STyle extraction<br>由3个模块组成：passage ranker, multi-span answer annotator, question-answering module</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=N2E5NmRiOWQzMjFkNmQyYmE3YjM5ZjY2MDgwMGI0ZmRfOUxveU53RFVqUE0zdG9PdEs5SFZKUUU1dDJsUjZ4NnFfVG9rZW46Ym94Y255R0JwTWNYU0tjNVNRdWJ3Y0daaHdjXzE2NzAyMjI1OTg6MTY3MDIyNjE5OF9WNA" alt="|"></p><h3 id="Passage-ranker"><a href="#Passage-ranker" class="headerlink" title="Passage ranker"></a>Passage ranker</h3><p><strong>问题定义：</strong></p><script type="math/tex; mode=display">P(y|Q, P; θ)</script><blockquote><p>表示在给定问题Q时，P可能包含答案的概率分布， θ是模型参数。</p></blockquote><p>输入形式：$[CLS]\ Q\ [SEP]\ P_i \ [SEP]$<br>使用最后一层的[CLS]作为输入的聚合表示。</p><p><strong>Ranker：</strong></p><script type="math/tex; mode=display">s = softmax(W_2tanh(W_1c + b_1) + b_2) ∈ R^2 \\ u_i= s_0\ and \ r_i= s_1</script><p>使用两个全连接层作为预测模块，表示问题和段落的相关性。</p><blockquote><p>其中$r_i,u_i$分别表示问答对$(Q, P_i)$的相关度和非相关度，s是一个二维向量。<br>对同一个问题Q，计算所有段落的相关性并作了如下的归一化：</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202212051445773.png" alt="|225"></p><p>损失函数：</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ODQ4NTk0ZDEzZjMxYWZmZjZiZjhhYWQzNTZmNGM5YzlfODk5dXVzemx4ZTZRNGc0MTRBU1J1bDJ5YkQ2djZIdGdfVG9rZW46Ym94Y250cFk3MW9QUWg4NmVrRlRyTnJvMWRiXzE2NzAyMjI2OTI6MTY3MDIyNjI5Ml9WNA" alt="625|550"></p><blockquote><p>T：训练集中问题的总数</p><p>r()：表示相关性得分</p><p>u()：表示非相关性得分</p></blockquote><p>训练过程中，每个问题Q都有n个question-passage pair组成候选集合，正例表示为与问题相关的段落，负例则从集合中随机采样未选中的question-passage pair。</p><p><strong>trick：</strong><br>动态采样：在每个epoch训练开始时重采样了负例，以避免在每个epoch对问题使用相同的训练样例。</p><h3 id="Question-answering-module"><a href="#Question-answering-module" class="headerlink" title="Question-answering module"></a>Question-answering module</h3><p><strong>问题定义：</strong><br>给定Q和P计算答案A的概率分布$P(y|Q, P) $。</p><p><strong>Question-passage reader：</strong><br>reader的结构设计与ranker类似，都是用预训练模型当encoder，不同的是ranker只用到了[CLS]，而reader用到了最后一层的所有输出做预测：</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=OTBhODg3NTExYjk1ZWJhZGZmNGYyODNlYzM0YWQ1ZTRfTm5OdXl0a0lkbUxyTzdUVDNhbkZ6bVBhVVlXSjZFNjhfVG9rZW46Ym94Y25GRDRDclZCbXRkOE1zSEdpTUg0dG9jXzE2NzAyMjM0MjU6MTY3MDIyNzAyNV9WNA" alt="|400"></p><p><strong>Multi-span style answer generator：</strong></p><p>token作为头尾的概率：</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=MzJiMjQ4M2FiYmJmNWEwMWZmMDRmNzhkYTk4Mzg3MjRfam1HRlR3WEZ1TkdYdjRUdmJ1bzVubTNaUzVzRWFIQ3FfVG9rZW46Ym94Y25xVlo2aDZYeGl6ZXkyMzRHRENmYVNkXzE2NzAyMjM0MjU6MTY3MDIyNzAyNV9WNA" alt="|400"></p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NWI3NGU1MjU3NGJjOTc2ZWVhYzlmOTFkYTY1YzIyZjBfZEtkWmt5Rldoc0lucG8wVzExMURET2JJMHRBa01EczZfVG9rZW46Ym94Y256Z1hPRVFGWlQzMFBtNVFmdk1JUk1oXzE2NzAyMjM0MjU6MTY3MDIyNzAyNV9WNA" alt="|400"></p><p><strong>Training and inference：</strong></p><p>这里值得学习的是，在预处理时加入了一个virtual span，跨度为整个输入序列，这种方法使模型能够在预测期间生成多种答案跨度，virtual span作为停止符。</p><p><strong>损失函数：</strong></p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=YTdiMzk4YWIyY2Y4OGZiODA3ZTRmM2YyNzkwYWNmNDVfMjY4aUNpaWhPN1NJQUhrbWRYRVN1OWZySjBnY052bnFfVG9rZW46Ym94Y25jYUJFbGNpc1JDT1NIQmdrOUh2WWJiXzE2NzAyMjM0MjU6MTY3MDIyNzAyNV9WNA" alt="400"></p><p>选span的依据是头尾span乘积最大。</p><p>为了缓解生成span重复问题，在每个预测时间步j时，模型在计算token新的开始和结束位置的概率分布时mask掉之前时间步的预测过的span位置。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>MS MARCO v2.1 dataset<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NTkwZTZhZGE4ZmQzMzZlMmZmY2RkY2Y3MmEyZDU1N2FfMTVZSjh0QVpMVXZ3U1FoSkVhMU1sWHNRUjZ6aE9QdWRfVG9rZW46Ym94Y25ZMG02c3dLWGlxWG1Xd3hDZkVORjRlXzE2NzAyMjM1MjU6MTY3MDIyNzEyNV9WNA" alt="|550"></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=MmE1NDU3OGQ5NmI5NDdhNDVmYzE1YTM0NTM1ZDVkYTlfTHFpTUV4S3RwQnlFS2VLV2lVRUhSa3dYcTRoZURVeG1fVG9rZW46Ym94Y25mSE5hSGI1YkVidlYwVG9ZNGhMTHVnXzE2NzAyMjM1NDg6MTY3MDIyNzE0OF9WNA" alt="|600"></p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=MjIzN2MxMTkzYTUwMDhkMjJjYjQzOWNkZGEwNzBhYTBfZDY4YUdFSFRndEh2ZU5IVTdLSldDcEk2aEtQZzRxUUlfVG9rZW46Ym94Y25JcW1NbmtjZHlOMHltVWo5WUJoYk9iXzE2NzAyMjM1NDg6MTY3MDIyNzE0OF9WNA" alt="|750"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文提出的多跨度提取框架（MUSST），能够缓解生成式模型生成不完整答案或引入单跨度提取模型遇到的冗余单词的问题。并且在只有ranker分类器的支持下，模型性能也不错，可以看出，段落重排序任务是比较重要的。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 不连续MRC </tag>
            
            <tag> multi-span </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Optimal Partial Transport Based Sentence Selection for Long-form Document Matching</title>
      <link href="/2022/12/05/Optimal%20Partial%20Transport%20Based%20Sentence%20Selection%20for%20Long-form%20Document%20Matching/"/>
      <url>/2022/12/05/Optimal%20Partial%20Transport%20Based%20Sentence%20Selection%20for%20Long-form%20Document%20Matching/</url>
      
        <content type="html"><![CDATA[<h1 id="Optimal-Partial-Transport-Based-Sentence-Selection-for-Long-form-Document-Matching"><a href="#Optimal-Partial-Transport-Based-Sentence-Selection-for-Long-form-Document-Matching" class="headerlink" title="Optimal Partial Transport Based Sentence Selection for Long-form Document Matching"></a>Optimal Partial Transport Based Sentence Selection for Long-form Document Matching</h1><blockquote><p> 论文：<a href="https://aclanthology.org/2022.coling-1.208.pdf">Optimal Partial Transport Based Sentence Selection for Long-form Document Matching</a><br> 代码：<a href="https://github.com/ruc-wjyu/OPT-Match">https://github.com/ruc-wjyu/OPT-Match</a> (暂未开源)<br> 会议：COLING 2022<br> 飞书：<a href="https://zlc6vppbrn.feishu.cn/docx/HIyLd9808oq3yvxzz3BcTJEUn1g">https://zlc6vppbrn.feishu.cn/docx/HIyLd9808oq3yvxzz3BcTJEUn1g</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>传统的长文档匹配方法首先在跨文档句子对之间进行对齐，然后聚合所有句子级的匹配信号。但是，这种方法可能会出现问题，尽管两个文档整体上匹配良好，但大多数句子仍然可能不同，因为文档之间的对齐是部分的。那些不同的句子会导致虚假的句子级匹配信号，可能会掩盖真实的句子，从而增加学习匹配功能的难度。因此，准确选择文档匹配的关键句子是以一个关键问题。</p><p>本文提出了一种新颖的匹配方法OPT-Match，该组件选择在匹配中起主要作用的句子。利用OPT的部分传输特性，选择的关键句子不仅可以有效地提高匹配精度，还可以解释匹配结果的合理性。</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=YjljZGFkMzgwYzJhMjM1NDZmNDI1N2QwNDFhNjAwZDlfTk1HNVJkeVI1QzNmZkhVNHE5RGZPZHgxcm40TnRtOTVfVG9rZW46Ym94Y243WDNNUENoZE1RdVoxckJDRjJhSjZmXzE2NzAyMjQxMDQ6MTY3MDIyNzcwNF9WNA" alt="|580"></p><p>文档1重点介绍了药用和芳香植物行业的未来机会。文档2研究了spicata的外部储存。大多数句子都不相似，但文件1引用了文件2，因为它们都以药用和芳香植物为例。传统的，基于句子的匹配策略无法识别相关关系。</p><h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><h4 id="现有匹配策略"><a href="#现有匹配策略" class="headerlink" title="现有匹配策略"></a>现有匹配策略</h4><ol><li>基于句子的短文本匹配 </li><li>映射到语义空间后进行层次匹配（词，句子，文章）</li></ol><p>但是，这些方法忽略了长文档通常包含多个段落和句子，这些段落和句子包含复杂的语义。对长文档匹配来说，文档对之间的对齐是局部的，关键句子之间的一些匹配信号可以确定文档级别的匹配结果。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>模型结构：<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=YjY1ODM1OTM4MmM0MDA2OWE0MTc0YWNkZjU2YWQzMzNfTGRQWlAzWUV5OXc5VVZ2OEJWVFlIaHN5aHpHQ3J6ZzlfVG9rZW46Ym94Y25wM2YydmlUbG1WeWVZVjFKRnJxd09oXzE2NzAyMjQxNjQ6MTY3MDIyNzc2NF9WNA" alt="|405"></p><h3 id="方法特性"><a href="#方法特性" class="headerlink" title="方法特性"></a>方法特性</h3><ul><li>OPT-Match通过限制要传输的块来建模文档对齐的部分性质</li><li>OPT-Match允许源域和目标域不一定具有相同的块，这与两个文档的长度可能相差很大的现象非常吻合。但是，基于OT的方法无法考虑这一点</li><li>OPT-Match是一种与模型无关的方法，可以轻松地将其插入各种文档匹配模型中</li></ul><h3 id="Proposed-OPT-Match-Method"><a href="#Proposed-OPT-Match-Method" class="headerlink" title="Proposed OPT-Match Method"></a>Proposed OPT-Match Method</h3><h4 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h4><script type="math/tex; mode=display">D = {(X_i, Y_i, z_i)}\tag{1}</script><blockquote><p>分别代表源文档，目标文档，标签（表示二者语义关系）<br>$X_i,Y_i$由连续的句子组成</p></blockquote><p><strong>学习目标：</strong></p><script type="math/tex; mode=display">X ×Y → Z \tag{2}</script><blockquote><p>将输入文档中的所有句子作为输入，输出它们之间关系的预测</p></blockquote><p><strong>主要思想：</strong><br>从源文档中选择出关键句进行匹配，而不是所有句子。</p><h4 id="The-Principle-of-Our-Method"><a href="#The-Principle-of-Our-Method" class="headerlink" title="The Principle of Our Method"></a>The Principle of Our Method</h4><p><strong>sentence selection method:</strong></p><p>定义源文档和目标文档概率分布的最小传输距离为：</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=MTljMzE4MTg1YWEwYThiNjJmMGEzYzZmNGFiYWY2MmNfSUJ3bzZSdGZ4N0pHaWcwbDJycFZSVzJtTk9LT1d0TE5fVG9rZW46Ym94Y25tcEZSYlJxclI5N3VrRTJMQnlSRnNoXzE2NzAyMjQxNjQ6MTY3MDIyNzc2NF9WNA" alt="|460"></p><blockquote><p>$T$:表示 $\mu\ v$ 的联合分布</p></blockquote><script type="math/tex; mode=display">µ = T1_N \    ν = T^⊤1_M</script><script type="math/tex; mode=display">C = [c(s^X_ m,s^Y _n )] \tag{4}</script><blockquote><p>$C$：句子级的损失矩阵<br>$c(s^X_ m,s^Y _n )$: 表示两个句子之间的差异</p></blockquote><h4 id="Optimal-Transport缺陷"><a href="#Optimal-Transport缺陷" class="headerlink" title="Optimal Transport缺陷"></a>Optimal Transport缺陷</h4><ol><li>需要µ，ν分布大小相同，因此很难适应不同句子数量的文档匹配，并且通常情况下，文档中的句子数量可能会有很大差异，并且冗长的文档通常包含更多的语义。</li><li>OT要求源点必须精确映射到目标。但是，在文档匹配中，只有来自源文档的一些关键句子与来自目标文档的关键句子对齐，因此应该只有一部分来自源的块被传输到目标。</li><li>OT聚合所有句子级对齐信号，这些信号会在匹配的过程中引入噪声。</li></ol><h4 id="OPT-based-Sentence-level-Alignment"><a href="#OPT-based-Sentence-level-Alignment" class="headerlink" title="OPT-based Sentence-level Alignment"></a>OPT-based Sentence-level Alignment</h4><p>目标：解决OT的三个缺陷</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NWU5Njk2MGI0MGZiNzc5MjlmZGZmODJhNzM3YTJkZjBfb01mZnlPRFRjS3p2VFpmaGZybmlua2FONEY4T240d1pfVG9rZW46Ym94Y25zZkJURTNpSmhTS0FzM0FMTlc5dGliXzE2NzAyMjQxNjQ6MTY3MDIyNzc2NF9WNA" alt="|400"></p><ul><li><p>缺陷1<br>OT中要求 $\mu v$具有相同的维度，因此首先要解决维度限制，设 $µ = 1_M\  ν = 1_N$</p><blockquote><p>其中 $1_M$表示维度为M的全1向量</p></blockquote></li><li><p>缺陷2<br>OT要求源点必须精确映射到目标。因此设置了需要传输的比例 $ϵ$，以控制文档对齐的程度。直观地说，使用较低的$ϵ$，OPT-Match 会更多地关注强对齐的句子对，同时过滤掉更多的虚假对齐信号。</p></li><li><p>cost matrix C<br>为了衡量两个交叉文档句子之间的差异，定义了代价矩阵$C$。<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NTc1NDFhMjZlYTVhYzBiNDk5ZWNjMGU3MmI5NjI2ZjRfMnEwVmhyc2Ywa2l0WFA0U29DUDlDbVJsbVFxa3pEeTJfVG9rZW46Ym94Y252THR4eFJGOVNVUzN5Q21oV2pFbWZkXzE2NzAyMjQxNjQ6MTY3MDIyNzc2NF9WNA" alt="|375"></p></li></ul><p>目标：期望将以更低的成本运输更多相似的句子对，因此也具有更强的对齐关系。</p><p>解决方法：<br>最优化转移策略中引入entropic regularizer E(T)，实现两个分布的快速近似</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ZmZkOTMzNWI2MTlkY2VhNzIwMTJiMmI3YjAyOWUzZDdfYWpZTGE2dGNHZkJPZXdwU1Via2FZOExuUUV0UXRadHZfVG9rZW46Ym94Y25LWDFQY1NGWUoxYmhRVElOU3doWmlmXzE2NzAyMjQxNjQ6MTY3MDIyNzc2NF9WNA" alt="|400"></p><blockquote><p>λ：权重系数<br>使用Bregman-Dykstra算法迭代计算 $T^*$<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=Yzk2OTRlZjRiYTYzODBiMjExZGVmYzFkOTU5YmIyZmVfenJncFJTZ0FDSTBuQmY3UmhmMTRhNnM4NFJMODVNVXJfVG9rZW46Ym94Y244V1dseE1KTDVMQ0FUaE13Vm1BM0tiXzE2NzAyMjQxNjQ6MTY3MDIyNzc2NF9WNA" alt="|410"></p></blockquote><p>初始化</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=MDliYjU1NDFkZWJhOGUyZmZlNjdjZjg4ZmU4ZTlkOTRfU0ZuU0I2dGtva1FyQVM2bkVRczliQlFCZzdVWVRPWktfVG9rZW46Ym94Y240cmpWbkgxV3FwNk9TSUZjNnV1UndlXzE2NzAyMjQxNjQ6MTY3MDIyNzc2NF9WNA" alt="|310"></p><blockquote><p>$T^<em>$表示在约束条件下，转移的概率，在句子对齐方案中 $T^</em>$可以视为源句和目标句之间的对齐程度，该方案下仅突出显示强对齐的句子。</p></blockquote><h4 id="Sentence-Selection"><a href="#Sentence-Selection" class="headerlink" title="Sentence Selection"></a>Sentence Selection</h4><ul><li>缺陷3<br>OT聚合所有句子级对齐信号，这些信号会在匹配的过程中引入噪声，因此设计两个算法选择与 $T^*$相关的 $S^X, S^Y$做匹配。</li></ul><h4 id="Hard-Selection"><a href="#Hard-Selection" class="headerlink" title="Hard Selection"></a>Hard Selection</h4><blockquote><p>encoding前</p></blockquote><p>从源文档和目标文档中分别选择了最佳传输策略中对齐度最高的k个句子，并丢弃其余句子，其中k是一个超参数，代表关键句子的理想数量。选择源文档中与 $T^<em>*1_N$相关的top-k句子，放置到 $S^X$。类似地，对于目标文档，选择 $1^⊤_M</em>T^*$top-k句子放置到 $S^Y$。</p><h4 id="Soft-Selection"><a href="#Soft-Selection" class="headerlink" title="Soft Selection"></a>Soft Selection</h4><blockquote><p>encoding后</p></blockquote><p>将 $T^*$作为采样概率，使用Gumbel softmax对关键句子采样，可微<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NDE5ZGZkOGJiNmJlNWU4ZGQ2ZmM3YjZlZWM1OGMxZjdfaXNtUEYzdEJicU1CZWR5SGxEZ01NSVVkNUxiTml3OHpfVG9rZW46Ym94Y25xQmVkMXpacTYzVDU0RHp2VXN1dkN1XzE2NzAyMjQxNjQ6MTY3MDIyNzc2NF9WNA" alt="|410"></p><blockquote><p>$U(0,1)$：表示0，1之间的均匀分布<br>$prob_i$：句子选中的概率</p></blockquote><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjE4MDYwODU1ZTc5MGFkMWIxN2Y0Yzc3MDlhMjdmN2FfNWpia25oUzl6eUE1Y1BQblR6TDMzQmxGbHFqNjluQUdfVG9rZW46Ym94Y25kTXJvQUFHU3lYVnlOMVBLMlNCbWpnXzE2NzAyMjQxNjQ6MTY3MDIyNzc2NF9WNA" alt="|375"></p><blockquote><p>得到每个句子的权重系数，用于选择关键句</p></blockquote><h4 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h4><p>OPT-Match只作为句子选择模块，训练目标与原模型相同， 一般损失函数为交叉熵：</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ODczNjJlNTYxNmQ2NGZmNGUzNDYwYTY3MThmYWMyMDdfY1BTamVMSE53TjJPME5mcU5RZ0lFMHJ6Y21VMHhkVUNfVG9rZW46Ym94Y255emZmRFVpTU9EMDRlY3B3aXBMR29jXzE2NzAyMjQxNjQ6MTY3MDIyNzc2NF9WNA" alt="|435"></p><blockquote><p>M：表示匹配组件<br>$z_i$：真实标签</p></blockquote><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>Long-Form文档匹配数据集：</p><ul><li><p>Citation recommendations<br>任务：预测一篇论文是否引用另一篇论文。<br>相关数据集：<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NGU2NzkwZDY1ZmM2MDU3MGI3OTBlMjU4OWFkZThlZTJfYzg1TUxYOVQyeE9kb1JhRnZEd2dMU0FubnY1dHlTOGNfVG9rZW46Ym94Y25TaGxGZVA4clNiWjlDbEhucEtLcGRiXzE2NzAyMjQ3ODg6MTY3MDIyODM4OF9WNA" alt=""></p></li><li><p>Plagiarism detection<br>任务：检测源文档中的span是否抄袭目标文档中的span（查重？）<br>相关数据集：<br>PAN</p></li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=OWY2NGZhODJmZjQxODI2NWFiODdjYzZlODVhMThiY2FfUjdaSkttNXd3eW14cXk0aDJNUkJhbVozRDhSZkNQNUlfVG9rZW46Ym94Y25qTFJCQnBlb2RQa0pJMXRTd2dCcVBoXzE2NzAyMjQ3ODg6MTY3MDIyODM4OF9WNA" alt=""></p><ul><li>硬匹配效果普遍偏好，原因在于，soft-selection本质上计算每个句子的权重系数，不能完全过滤掉文档中的噪声。</li><li>BERT及其变体以token为单位建模，因此只选择了硬匹配的方式</li><li>BERT及其变体 (例如Transformer-XL和Longformer) 在PAN上的性能要差得多，原因在于，PAN文档较长(&gt; 1500 words)，直接截断会带入大量噪音，但OPT-Match模块不受文档长度的影响。并且OPT-Match通过选择关键句子进行匹配可以成功滤除文档中的噪声。</li><li>文档越长性能越好</li></ul><blockquote><p>使用acc和F1作为评估指标，因为所有数据集都有用于文档匹配的二分类标签。</p><p>使用MRR作为句子选择的评估指标，因为句子选择被视为排名任务。</p></blockquote><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><h3 id="主要贡献："><a href="#主要贡献：" class="headerlink" title="主要贡献："></a>主要贡献：</h3><ul><li>强调了长格式文档匹配中关键句子选择的重要性</li><li>提出了一个广泛适用的组件，称为OPT-Match，该组件通过进行部分文档对齐来选择用于文档匹配的关键句子</li><li>实验结果表明，在四个公开数据集上，OPT-Match改进了现有的文档匹配模型，并且OPT-Match选择的句子与人工一致</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 长文本 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>组会报告</title>
      <link href="/2022/12/05/%E7%BB%84%E4%BC%9A%E6%8A%A5%E5%91%8A/"/>
      <url>/2022/12/05/%E7%BB%84%E4%BC%9A%E6%8A%A5%E5%91%8A/</url>
      
        <content type="html"><![CDATA[<h2 id="1-RocketQA系列搜索技术相关论文"><a href="#1-RocketQA系列搜索技术相关论文" class="headerlink" title="1. RocketQA系列搜索技术相关论文"></a>1. RocketQA系列搜索技术相关论文</h2><p><a href="https://zlc6vppbrn.feishu.cn/docx/doxcnzGc77PTCEGzCqLWt3onTph">https://zlc6vppbrn.feishu.cn/docx/doxcnzGc77PTCEGzCqLWt3onTph</a></p><h2 id="2-长文本"><a href="#2-长文本" class="headerlink" title="2. 长文本"></a>2. 长文本</h2><p><a href="https://zlc6vppbrn.feishu.cn/docx/ZL9fdzLeIoYUhyxnO7hcNFPlnZc">https://zlc6vppbrn.feishu.cn/docx/ZL9fdzLeIoYUhyxnO7hcNFPlnZc</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 组会报告 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Read before Generate! Faithful Long Form Question Answering with Machine Reading</title>
      <link href="/2022/12/05/Read%20before%20Generate!%20Faithful%20Long%20Form%20Question%20Answering%20with%20Machine%20Reading/"/>
      <url>/2022/12/05/Read%20before%20Generate!%20Faithful%20Long%20Form%20Question%20Answering%20with%20Machine%20Reading/</url>
      
        <content type="html"><![CDATA[<h1 id="Read-before-Generate-Faithful-Long-Form-Question-Answering-with-Machine-Reading"><a href="#Read-before-Generate-Faithful-Long-Form-Question-Answering-with-Machine-Reading" class="headerlink" title="Read before Generate! Faithful Long Form Question Answering with Machine Reading"></a>Read before Generate! Faithful Long Form Question Answering with Machine Reading</h1><blockquote><p> 论文：<a href="https://aclanthology.org/2022.findings-acl.61.pdf">https://aclanthology.org/2022.findings-acl.61.pdf</a><br> 会议：ACL2021<br> 飞书：<a href="https://zlc6vppbrn.feishu.cn/docx/P45VdH0vmosFNMxwMyxc3R5Anif">https://zlc6vppbrn.feishu.cn/docx/P45VdH0vmosFNMxwMyxc3R5Anif</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>长文本问答 (LFQA) 旨在为给定问题生成段落长度的答案。当前使用大型预训练模型生成的LFQA工作可以有效地产生流畅且较为相关的内容，但对长文本问答来说，不同的文档可能包含冗余，互补或矛盾的信息，主要的挑战在于如何生成具有较少空洞内容的高置信度(faithful)答案。</p><p><strong>关键思想：</strong>本文提出了一个新的端到端框架，该框架对答案生成和机器阅读进行联合建模，使用与答案相关的细粒度的显著信息来增强生成模型，这些信息可以被视为对事实的强调。</p><p>a fluent and relevant but unfaithful answer：</p><blockquote><p>unfaithful answer 会误导读者</p></blockquote><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ZGI0ZTMzMTcyZWY4NjMxODJmZWNjYjg4MDAwZGI5MmFfVDhDajhJenJVSGVPSFlxUDdqMk9uWGV6VFl1YXhqdVFfVG9rZW46Ym94Y25PVjl2RENpcU1pQWE5VVg0eGd4eGJVXzE2NzAyMjUyMzM6MTY3MDIyODgzM19WNA" alt="|510"></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>本文将基于Seq2Seq的生成器与机器阅读理解 (reader) 模块相结合。reader会为每个句子生成作为证据的概率得分，该分数将与生成器集成在一起，用于最终的分布预测。</p><p>模型结构：<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ZTI4NzA3NDk3NjU3ZTk2YzhlMGJhOGMyZjZlYWJjYTRfNm1heEh6Qk8xOTBjbmlVblZtUk5LY0lkWGlyWXRlQUhfVG9rZW46Ym94Y25YeFA4MlVEQkJ3UXg0NWFaVUw1VTZlXzE2NzAyMjUyNTc6MTY3MDIyODg1N19WNA" alt=""></p><p>为了对给定的通用领域问题生成深入的长答案，首先使用检索器从大量的外部知识中检索相关信息。然后，reader和generation模块将多个检索到的文档以及问题作为输入以生成答案。</p><p><strong>reader模块</strong>: 为每个文档中的每个句子计算证据得分。<br><strong>generator模块:</strong> 采用预训练的Seq2Seq语言模型，将句子证据得分融合到其生成过程中。</p><h3 id="Supporting-document-retriever"><a href="#Supporting-document-retriever" class="headerlink" title="Supporting document retriever"></a>Supporting document retriever</h3><p>使用DPR检索相关文档<br>retriever根据文档的相关性对文档进行排名：<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ZGE1MTA1MWI2ZWM5OWE0NWU1MTE4YmI1ZGYxNzZiYzFfR1Q0aFdXaThZeEwxaXRvNWh2Vk1rdzJiSG5pNTl1N21fVG9rZW46Ym94Y25EczVwa1lFSWJPMlkxVXZhc2pXZjVZXzE2NzAyMjUyNTc6MTY3MDIyODg1N19WNA" alt="|440"><br>对于问题Q,使用 $D = {D_1,D_2, …,D_k}$表示top-k相关文档。</p><h3 id="Document-reader"><a href="#Document-reader" class="headerlink" title="Document reader"></a>Document reader</h3><p>由于没有用于长答案的标注标签，因此检索到的文档可能包含与答案相关的补充，矛盾或冗余信息。因此，使用阅读器模块来预测每个文档中句子的证据概率。</p><h4 id="Evidence-span-prediction"><a href="#Evidence-span-prediction" class="headerlink" title="Evidence span prediction"></a>Evidence span prediction</h4><p>输入： $D_i \&amp; Q$<br>输出： $D_i$中可能是evidence spans的开始和结束位置，每个输出token有两个概率分布， $P^s_i (w_s) \ and \ P^e _i (w_s)$,分别表示token $w_s$作为头和尾token的概率</p><h4 id="Sentence-evidence-probability"><a href="#Sentence-evidence-probability" class="headerlink" title="Sentence evidence probability"></a>Sentence evidence probability</h4><p>句子级的概率更适合长文本任务，支持句可以为每个答案跨度提供所需的最小上下文信息，这一点非常重要，尤其是在多文档生成中。</p><p>文档中第i个句子的概率表示为 $P^i_{ rea}(S)$，由该句子中所有token的证据概率加和得到。</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ODIxYTc5MTg4NDMzZjllODczMWEwNDEzOTUxNjBmYjJfc3J3OUpleFBKYkN2d0dZcVBxb0Uza2VUbjd0RHlkY0tfVG9rZW46Ym94Y25KTW9SQU1KcWdzdWxqdG1QTHhGMlBoXzE2NzAyMjUyNTc6MTY3MDIyODg1N19WNA" alt="|415"></p><blockquote><p>$P_{rea}(S)$：表示经过归一化后，所有top-k句子的证据概率</p></blockquote><h4 id="Multi-task-MRC"><a href="#Multi-task-MRC" class="headerlink" title="Multi-task MRC"></a>Multi-task MRC</h4><p>由于LFQA数据没有gold answer span，因此选择SpanBert在MRQA,sQuAD,NewsQA,TriviaQA,SearchQA,HotpotQA,NatualQuestions上进行多任务微调，在下游任务上实现远程监督训练。</p><h3 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h3><h4 id="FiD-BART"><a href="#FiD-BART" class="headerlink" title="FiD-BART"></a>FiD-BART</h4><p>选择BART作为生成任务的backbone，本文提出FiD-BART(Fusion-in-Decoder)，以使BART能够处理多个长文档输入。FiD-BART在编码器中独立处理每个文档，同时在解码器中联合执行交叉注意力。</p><ul><li>Encoder<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NzViZjBjOTZkM2QyZjhjZjEzYzhiNTRjOTg3ZTY3YjdfMm5PNGZKM1Q1M1JvOHBDNzlPSnVtMDhMNjd6RHBLNUZfVG9rZW46Ym94Y25qSTNNOGZxUnRxeEZVOU12bHIwZWNmXzE2NzAyMjUyNTc6MTY3MDIyODg1N19WNA" alt="|450"></li></ul><blockquote><p>$h<em>{enc}^i$：文档 $D_i$作为encoder输入得到的最后一层隐藏层表示<br>$h</em>{enc}$：top-k文档encoder输出的拼接</p></blockquote><ul><li>Decoder</li></ul><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=OTQ2N2NjNGEyM2UyZjFkOTY2OWI1ZjE0Y2Y5MjQ4ZTJfR3hQUXZvRWxCWFFZbHF5Q3pqdkMyQXdVT2VST01tTzNfVG9rZW46Ym94Y25wVWNnVkV5eDJ5bnhqYThTbkJsdlpjXzE2NzAyMjUyNTc6MTY3MDIyODg1N19WNA" alt="|400"></p><blockquote><p>$h<em>l$：表示decoder的第l层<br>$h</em>{dec}$：表示decoder的最后一层输出</p></blockquote><p><em>计算时间与输入数量线性相关</em></p><h4 id="Reader-before-generator"><a href="#Reader-before-generator" class="headerlink" title="Reader-before-generator"></a>Reader-before-generator</h4><p>使用指针网，将证据概率融入到生成过程中。</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NmFmZjNiYzE2MzU2ODMyY2UzODU5NDQ3Mzk4YjY2ZDhfQjFOR3VyV3ViZEVIbm95R2d3bTdXc1JkanljbWJveE5fVG9rZW46Ym94Y253V01Bdk1KZXJCWUxmbWh6eTZGaU9lXzE2NzAyMjUyNTc6MTY3MDIyODg1N19WNA" alt="|400"></p><blockquote><p>$A$：attention分布<br>$h<em>c$：上下文向量<br>$p</em>{gen}$：生成概率<br>$W_c,W_g$：可训练参数</p></blockquote><p>$p_{gen}$用于选择：</p><ol><li>生成器从vocab中采样单词（词表）</li><li>根据证据分布 $P_{rea}(w)$从输入序列复制单词（输入序列）<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjVkNzhmMTQ0OWMyNWEzOTE5ZTA0MjQxNjkyMTJmYzZfTlp2eHg2Y2JxY0xqZ2tSMHNWNEdFOHMwZldZWndyeTlfVG9rZW46Ym94Y25Xa1ZxNVliZmVncVJqRmVDV244U3ljXzE2NzAyMjUyNTc6MTY3MDIyODg1N19WNA" alt="|410"></li></ol><h3 id="Pre-training"><a href="#Pre-training" class="headerlink" title="Pre-training"></a>Pre-training</h3><p>为了进一步提高检索文档的能力，提出了retrieval-augmented recovery (RAR)预训练任务，期望模型能够依赖更多的外部知识生成事实性陈述。</p><p><strong>任务定义：</strong><br>给定原始文本：S<br>从外部知识(BM25)中检索top-k文档： $D_1,D_2, …,D_N$<br>构造伪查询Q：替换S中30%的单词为[MASK]</p><p>任务：使用伪查询Q和top-k文档恢复S<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ODUyZWEzZWQ1ZjBhZTFiYmVjN2VhMmM0YTJjMzcyMjBfYUlqVFlKOTlucjVYWlF4RzF4dE5Id0lMa0c1SUpDNTNfVG9rZW46Ym94Y25PTWFkaUw0SXhURVNPWWtCNVVmWnFnXzE2NzAyMjUyNTc6MTY3MDIyODg1N19WNA" alt="|390"></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>LI5</li></ul><ol><li>唯一可公开获得的大规模LFQA数据集</li><li>272,634个train样例和1,507个dev样例</li><li>答案平均长度130个单词</li></ol><ul><li>MS MARCO</li></ul><ol><li>来自Bing查询</li><li>本文使用passage ranking track训练模型，该赛道比NLG更加抽象，并且更依赖多文档信息。</li><li>train样例大约500,000，dev样例6980</li></ol><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>评价指标：<br>F1 score and ROUGE-L</p><h3 id="模型性能"><a href="#模型性能" class="headerlink" title="模型性能"></a>模型性能</h3><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=YjFmMWM5MGU2MmZmYjVjNzY0Y2RjOGEwNDBhYTMwMmRfZmNSNmkwdmpjNkJpQzFqRk9YVmcya1ZDVGhudUttQnVfVG9rZW46Ym94Y25idEFyaWoyTTVPbHRVZmh0UmltaldnXzE2NzAyMjU4OTc6MTY3MDIyOTQ5N19WNA" alt="|450"></p><h3 id="Fine-grained-Comparison"><a href="#Fine-grained-Comparison" class="headerlink" title="Fine-grained Comparison"></a>Fine-grained Comparison</h3><p>将MARCO数据集按照检索到的文档质量拆分为不同的子集，验证文档的质量对生成质量的影响。</p><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=NGYwN2FiMWJiNWRiNDZhYTA4OGRjNWM2YTNlZjlmZDJfZzV0akJMcUtNNzZLTkdoTFZ4dExKZklpVUJiZGJWNGZfVG9rZW46Ym94Y256bFNjaHlYRFRkMVd0TFdlMU5EU2xiXzE2NzAyMjU4OTc6MTY3MDIyOTQ5N19WNA" alt="|480"></p><blockquote><p>RBG在完整MS-MARCO评估集中Rouge-L只比FiD领先0.1，但从表3中可以看出，随着评估子集检索质量的提高，性能差距继续增加。表明RBG在提供高质量的检索文档时更加有效。</p></blockquote><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=Y2I1OGZkMDRlYzM0MWJhNDRiZTRlNzlkMGY2ZWQwMDdfRE5KVXBMUkI1bUluSmo1RGg2a096QWhyVnltMlBzT1FfVG9rZW46Ym94Y25hQmlaWUN3aVdnem1Ub3BNWVdiV0tlXzE2NzAyMjU4OTc6MTY3MDIyOTQ5N19WNA" alt="|485"></p><h4 id="文档质量对生成结果的影响"><a href="#文档质量对生成结果的影响" class="headerlink" title="文档质量对生成结果的影响"></a>文档质量对生成结果的影响</h4><p><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=ZjFlZTk5NjRjMmI2NWU1ODhjMzAxY2JlZTI3ZjBlMTJfSDB2blVhRHJTTkRDOVczQUZrQlhFR0NIaWk3OTVhelFfVG9rZW46Ym94Y25WTG1qTE80dFNyYjRnRnVsZ2hEOG9oXzE2NzAyMjU4OTc6MTY3MDIyOTQ5N19WNA" alt="|445"></p><ul><li>检索得到的高质量文档能够提高生成质量</li><li>检索的文档并不是越多越好</li></ul><h3 id="Zero-shot-on-extractive-QA-tasks"><a href="#Zero-shot-on-extractive-QA-tasks" class="headerlink" title="Zero-shot on extractive QA tasks"></a>Zero-shot on extractive QA tasks</h3><p>评价指标：模型生成的长答案中是否包含NQ和HotpotQA中的短答案<br><img src="https://zlc6vppbrn.feishu.cn/space/api/box/stream/download/asynccode/?code=MGU3ZjMzZDEwZTkwOTBiZjYyNTBiODM4OGI3NDhkNjZfYmtiN1BBUWp6akluc2dIME1rRnFxdDFheFFaRW16OFBfVG9rZW46Ym94Y25jS1M5M2RLQkpUZFZlT1ZpM2NubXpjXzE2NzAyMjU4OTc6MTY3MDIyOTQ5N19WNA" alt="|450"></p><blockquote><p>模型在需要综合复杂信息的问题上生成faithful答案的能力更强。</p></blockquote><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>主要贡献：</p><ul><li>本文是截至当前第一个尝试解决LFQA中的faithful挑战的人。</li><li>为开放域LFQA提出了一个新的端到端框架，该框架在reader模块的句子证据得分的指导下生成答案。</li><li>本文的方法可以提高生成答案的事实正确性，同时仍保持较高的信息性。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 长文本 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph Convolutional Networks for Text Classification</title>
      <link href="/2022/04/28/Graph%20Convolutional%20Networks%20for%20Text%20Classification/"/>
      <url>/2022/04/28/Graph%20Convolutional%20Networks%20for%20Text%20Classification/</url>
      
        <content type="html"><![CDATA[<h1 id="Graph-Convolutional-Networks-for-Text-Classification"><a href="#Graph-Convolutional-Networks-for-Text-Classification" class="headerlink" title="Graph Convolutional Networks for Text Classification"></a>Graph Convolutional Networks for Text Classification</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/1809.05679">https://arxiv.org/abs/1809.05679</a></p><p> 代码：<a href="https://github.com/yao8839836/text_gcn">https://github.com/yao8839836/text_gcn</a></p><blockquote><p><a href="https://github.com/codeKgu/text-gcn">https://github.com/codeKgu/text-gcn</a></p><p><a href="https://github.com/chengsen/pytorch_textgcn">https://github.com/chengsen/pytorch_textgcn</a></p></blockquote><p> 会议：AAAI 2019</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>文本分类是自然语言处理中一个重要的经典问题。有许多研究将卷积神经网络应用于分类。然而，只有有限的研究探索了更灵活的图卷积神经网络来完成这项任务。在这项工作中，使用图卷积网络进行文本分类。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>基于单词共现和文档-单词关系为语料库构建单个文本图，然后为语料库训练文本图卷积网络（Text-GCN）。Text-GCN使用word和document的独热表示进行初始化，然后在文档的已知类标签的监督下，联合学习word和document的嵌入。</p><h3 id="Graph-Convolutional-Networks-GCN"><a href="#Graph-Convolutional-Networks-GCN" class="headerlink" title="Graph Convolutional Networks (GCN)"></a>Graph Convolutional Networks (GCN)</h3><p>GCN是一个多层神经网络，它直接在图上运行，并根据节点的邻居属性获取节点的嵌入向量。</p><p>符号定义：<br>图$G=(V,E)$</p><blockquote><p> 其中$V$和$E$分别是节点和边的集合。</p><p>假设每个节点都与自身相连，即$(v,v)∈E$ 。</p><p>$X∈ R^{n×m}$：包含所有n个节点及其特征的矩阵，其中m是特征向量的维数。</p><p>A：G的邻接矩阵。</p><p>D：A的出度矩阵。</p></blockquote><p>GCN只能捕获具有一层卷积的近邻信息。当多个GCN层堆叠时，更大邻域的信息将被聚合。对于单层GCN，新的k-dimensional节点的特征矩阵$L$计算方式如下：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204282143438.png" alt="image-20220428214318357" style="zoom: 33%;" /></p><blockquote><p>其中<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204282144487.png" alt="image-20220428214405461" style="zoom: 25%;" />是归一化操作。</p><p>ρ：激活函数，本文用的RELU。</p></blockquote><p>堆叠多层GCN:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204282150487.png" alt="image-20220428215057462" style="zoom:33%;" /></p><blockquote><p>j表示层号。</p></blockquote><h3 id="Text-Graph-Convolutional-Networks-Text-GCN"><a href="#Text-Graph-Convolutional-Networks-Text-GCN" class="headerlink" title="Text Graph Convolutional Networks (Text GCN)"></a>Text Graph Convolutional Networks (Text GCN)</h3><p>本文构建了一个包含单词节点和文档节点的大型异构文本图，这样可以显式地建模全局单词共现，并且可以轻松地调整图卷积。</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204282154020.png" alt="image-20220428215400982"></p><blockquote><p>节点定义： 文本图中的节点数$| V |$是文档数（语料库大小）加上不同单词数（词表大小）。</p><p>边的定义：document-word edges and word-word edges</p></blockquote><p>文档节点和单词节点之间的边的权重是文档中单词的TF-IDF值。我们发现使用TF-IDF权重比仅使用术语频率更好。为了利用全局词共现信息，对语料库中的所有文档使用固定大小的滑动窗口来收集共现统计信息。我们使用 point-wise mutual information（PMI）来计算两个词节点之间的权重。</p><blockquote><p>PMI是一种常用的词关联度量方法。</p><p>正的PMI值意味着语料库中单词的高度语义相关性，而负的PMI值意味着语料库中几乎没有语义相关性。因此，本文只在PMI值为正的词对之间添加边。</p><p>在初步实验中，发现使用PMI比使用单词共现计数获得更好的结果。</p></blockquote><p>形式上，节点$i$和节点$j$之间的边的权重定义为：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204282210907.png" alt="image-20220428221055846" style="zoom:33%;" /></p><p>PMI计算：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204282215083.png" alt="image-20220428221533060" style="zoom:33%;" /></p><blockquote><p>$#W(i)$是语料库中包含单词$i$的滑动窗口数量</p><p>$#W(i,j)$是同时包含单词$i,j$的滑动窗口数量</p><p>$#W$是滑动窗口的数量</p></blockquote><p>构建好文本图之后输入到两层GCN，通过Softmax分类器做最终分类。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204282235363.png" alt="image-20220428223552336" style="zoom:33%;" /></p><p>交叉熵损失函数：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204282238985.png" alt="image-20220428223801962" style="zoom:33%;" /></p><p>使用两层GCN的解释：<br>两层GCN允许消息在最多两步之外的节点之间传递。因此，尽管图中没有直接的文档边，但两层GCN允许成对文档之间进行信息交换。在初步实验中<br>发现，两层GCN的性能优于单层GCN，而多层GCN并不能提高性能。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>20-Newsgroups (20NG)</p><p>Ohsumed</p><p>R52 and R8 of Reuters(路透社) 21578</p><p>Movie Review (MR)</p><blockquote><p>具体数据集的介绍，可以去论文相关部分。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204282302421.png" alt="image-20220428230227396"></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204282304569.png" alt="image-20220428230415541"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文贡献：</p><ul><li>提出了一种新的用于文本分类的图神经网络方法。这是第一次将整个语料库建模为一个异构图，并使用图神经网络联合学习单词和文档嵌入的研究。</li><li>在几个基准数据集上的结果表明，本文的文本分类方法，无需使用预先训练的单词嵌入或外部知识，该方法还可以自动学习预测词和文档嵌入。</li></ul><p>此外，实验结果表明，随着训练数据百分比的降低，文本GCN相对于最先进的比较方法的改进变得更加显著，这表明文本GCN对文本分类中较少训练数据的鲁棒性。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> GCN </tag>
            
            <tag> 文本分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Iterative GNN-based Decoder for Question Generation</title>
      <link href="/2022/04/25/Iterative%20GNN-based%20Decoder%20for%20Question%20Generatio.pdf/"/>
      <url>/2022/04/25/Iterative%20GNN-based%20Decoder%20for%20Question%20Generatio.pdf/</url>
      
        <content type="html"><![CDATA[<h1 id="Iterative-GNN-based-Decoder-for-Question-Generation"><a href="#Iterative-GNN-based-Decoder-for-Question-Generation" class="headerlink" title="Iterative GNN-based Decoder for Question Generation"></a>Iterative GNN-based Decoder for Question Generation</h1><blockquote><p> 论文：<a href="https://aclanthology.org/2021.emnlp-main.201/">https://aclanthology.org/2021.emnlp-main.201/</a></p><p> 代码：<a href="https://github.com/sion-zcfei/IGND/issues/1">https://github.com/sion-zcfei/IGND/issues/1</a> 但仓库目前(2022-4-25)是空的</p><p> 会议：EMNLP 2021</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>自然问题生成（Natural question generation，QG）旨在从文章中生成问题，生成的问题从文章中得到回答。大多数具有最先进性能的模型在每个解码步骤都会建模先前生成的文本。但是先前的工作存在两个问题：</p><ol><li>他们忽略了隐藏在先前生成的文本中的丰富结构信息。</li><li>他们忽略了拷贝的单词对文章的影响。</li></ol><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251033597.png" alt="image-20220425103342573" style="zoom:33%;" /></p><p>从上图中可以看到，拷贝的单词 donald davies 对下一个拷贝的单词 develop 有较大的贡献。复制的单词donald davies是文章的主体，而答案routing methodology 是本文的客体，他们之间包含结构信息。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>为了解决上述两个问题，在本文中，设计了一个基于迭代图网络的解码器（IGND），使用图神经网络在每个解码步骤对上一代的结构信息进行建模。观察到，从一篇文章中抄袭的单词在整个问题的语义中起着决定性的作用，因此对复制的单词信息进行建模，以获取结构信息，并利用它们对文章的影响。将角色标签引入到段落图中，其中所有单词都有角色标签 no-copy，只有答案单词有标签 answer。IGND在每个解码步骤更新角色标签。例如，当此节点中的单词在此解码步骤复制到问题时，角色标记将更改为 copied。然后，通过一种新的双向门控图神经网络（Bi-GGNN）对信息进行聚合。此外，我们还提出了一种关系图编码器，该编码器使用类似的bi-GGNN来捕获一段文章的依赖关系，从而提高生成效率。此外，本文的图模型捕捉到了文章中促进生成的依赖关系。</p><h3 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h3><p>文章：<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251100454.png" style="zoom: 25%;" /></p><p>答案：$X^a=$<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251102754.png" alt="image-20220425110210731" style="zoom:25%;" /></p><p>生成问题序列：$\hat Y = $<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251103181.png" alt="image-20220425110324161" style="zoom:25%;" /></p><p>极大似然估计：<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251103824.png" alt="image-20220425110358802" style="zoom:25%;" /></p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251202941.png" alt="image-20220425120244918" style="zoom: 33%;" /></p><h3 id="Graph2Seq-Model-with-Iterative-Graph-Network-based-Decoder"><a href="#Graph2Seq-Model-with-Iterative-Graph-Network-based-Decoder" class="headerlink" title="Graph2Seq Model with Iterative Graph Network-based Decoder"></a>Graph2Seq Model with Iterative Graph Network-based Decoder</h3><p>与RNN相比，GNN可以有效地利用丰富的隐藏文本结构信息，如语法信息。此外，还可以对序列词之间的全局关系进行建模，以改进表示。本文构造了一个基于依赖树的有向加权文本图G。在段落图中，每个段落词被视为一个节点，两个词之间的依赖关系被视为一条边。</p><p>Graph2Seq通过dependency relations编码段落图，使用IGND解码问题序列。</p><h4 id="Relational-Encoder"><a href="#Relational-Encoder" class="headerlink" title="Relational Encoder"></a>Relational Encoder</h4><p>答案信息对于生成高质量的答案和回答相关问题至关重要。依赖关系将答案和文章单词联系起来。为了使用依赖关系，本文提出了关系嵌入，为每个单词聚合全局依赖关系。</p><p>使用双向LSTM得到隐藏状态$H$：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251204454.png" alt="image-20220425120421432" style="zoom:33%;" /></p><blockquote><p>解释：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251205994.png" alt="image-20220425120559973" style="zoom:33%;" /></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251211037.png" alt="image-20220425121112000" style="zoom:33%;" /></p></blockquote><p>answer-aware weighted context hidden states $H^p$:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251207407.png" alt="image-20220425120709385" style="zoom:33%;" /></p><p>使用GGNN从文本图学习 graph embedding。它在每次迭代中融合来自传入和传出方向的中间节点嵌入（出度和入度）。在bi-GGNN中，每个节点的passage embeddings被初始化为passage embeddings $H^p$，关系嵌入被随机初始化。图参数在计算的每一跳都是共享的。在图中的每个节点上，我们使用平均聚合器聚合相邻节点的passage embedding，得到聚合向量。</p><p>聚合向量：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251216152.png" alt="image-20220425121626129" style="zoom:33%;" /></p><p>同样的方式可以得到relation embedding的聚合向量：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251218423.png" alt="image-20220425121834395" style="zoom:33%;" /></p><p>在每一跳将聚和在两个方向上的信息融合在一起：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251219286.png" alt="image-20220425121929263" style="zoom:33%;" /></p><p>使用GRU更新节点嵌入，合并聚合信息：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251235185.png" alt="image-20220425123542163" style="zoom:33%;" /></p><p>经过n跳的计算，获得最终的上下文嵌入，关系嵌入，结合文本信息和语法信息的节点嵌入计算如下：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251237930.png" alt="image-20220425123756909" style="zoom:33%;" /></p><p>最终通过最大池化，可以得到一个图级嵌入：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251239924.png" alt="image-20220425123908897" style="zoom:33%;" /></p><h3 id="Iterative-Graph-Network-based-Decoder"><a href="#Iterative-Graph-Network-based-Decoder" class="headerlink" title="Iterative Graph Network-based Decoder"></a>Iterative Graph Network-based Decoder</h3><p>传统QG任务的解码部分，使用一种具有copy机制的基于注意的LSTM解码器。为了解决这个问题，我们设计了基于迭代图网络的解码器（IGND）。</p><p>给节点添加role tag信息，每个节点都有一个角色标签，该标签在每个解码步骤都会更新，包括 answer, copied and no-copy。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251251256.png" alt="image-20220425125149233" style="zoom:33%;" /></p><p>角色标签可以引导模型合并依赖关系，以生成答案相关问题。</p><p>在解码的每个时间步 t，节点嵌入会被重新初始化：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251254528.png" alt="image-20220425125410504" style="zoom:33%;" /></p><blockquote><p>其中，$h^n_i$是通过等式（18）计算的passage graph的节点嵌入，$r_i^t$是步骤$t$中节点$i$的角色标签嵌入。</p></blockquote><p>此外，采用bi-GGNN和平均聚合器来聚合节点嵌入。经过n跳计算，得到了最终的节点嵌入<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251256991.png" alt="image-20220425125649965" style="zoom:33%;" />。</p><p>对于每个解码步骤$m$，LSTM读取前一个单词$w<em>{t-1}$的嵌入、先前的previous attentional context vector $c</em>{t−1}$和之前的隐藏状态$s_{t−1}$，计算其当前隐藏状态。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251259970.png" alt="image-20220425125905944" style="zoom:33%;" /></p><p>在时间步t，注意力权重和上下文向量计算如下：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251311438.png" alt="image-20220425131128409" style="zoom:33%;" /></p><p>由于注意权重衡量每个输入单词与部分解码状态的相关性，并结合生成的单词信息，将$α_t$视为复制概率:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251314905.png" alt="image-20220425131414878" style="zoom:33%;" /></p><p>最终的单词预测概率：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251315845.png" alt="image-20220425131520814" style="zoom:33%;" /></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251315811.png" alt="image-20220425131544777" style="zoom:33%;" /></p><p>损失函数，negative log likelihood：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251316640.png" alt="image-20220425131624611" style="zoom:33%;" /></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>SQuAD </p><p>MS MARCO</p><blockquote><p>包含100000个带有相应答案和段落的查询。所有问题都是从真实的匿名用户查询中抽取的，上下文段落是从真实的web文档中提取的。</p><p>本文选取了MARCO数据集的一个子集，其中答案是段落中的子跨度，以构建句子级数据集。其中包含46109、4539和4539个sentence-question-answer triples，分别用于训练、验证和测试。</p></blockquote><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204251336592.png" alt="image-20220425133601566"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文贡献：</p><ul><li>设计了一个基于迭代图网络的解码器（IGND）来捕获生成中的结构信息，并在每个解码步骤对复制的词进行建模。</li><li>我们提出了一个关系图编码器来编码段落中的依赖关系，并建立答案和段落之间的联系。</li><li>提出的模型专注于句子级QG任务，获得了最优的分数，并且在 standard SQuAD and MARCO benchmarks for QG 上优于现有方法。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> QG </tag>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RikiNet Reading Wikipedia Pages for Natural Question Answering</title>
      <link href="/2022/04/14/RikiNet%20Reading%20Wikipedia%20Pages%20for%20Natural%20Question%20Answering/"/>
      <url>/2022/04/14/RikiNet%20Reading%20Wikipedia%20Pages%20for%20Natural%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="RikiNet-Reading-Wikipedia-Pages-for-Natural-Question-Answering"><a href="#RikiNet-Reading-Wikipedia-Pages-for-Natural-Question-Answering" class="headerlink" title="RikiNet: Reading Wikipedia Pages for Natural Question Answering"></a>RikiNet: Reading Wikipedia Pages for Natural Question Answering</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2004.14560">https://arxiv.org/abs/2004.14560</a></p><p> 会议：ACL 2020</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>阅读长文档来回答open-domain问题在自然语言理解中仍然具有挑战性。本文介绍了一种新的模型，称为RikiNet，它通过阅读维基百科页面来自然地回答问题。<br>RikiNet包含一个dynamic paragraph dual-attention reader和一个multi-level cascaded(级联) answer predictor。阅读器通过一套互补的注意机制动态地表达文档和问题。然后将这些表示输入预测器，以级联方式获得短答案的范围、长答案的段落和答案类型。</p><p>NQ数据集相对于之前阅读理解任务数据集的两个挑战：</p><ul><li>首先，NQ没有为每个问答（QA）对提供一个相对较短的段落，而是提供了一个完整的维基百科页面，与其他数据集相比，该页面要长得多。</li><li>其次，NQ任务不仅要求模型像以前的MRC任务一样找到问题的答案跨度（称为短答案），还要求模型找到包含回答问题所需信息的段落（称为长答案）。</li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>RikiNet采用了动态段落双注意力（DPDA）阅读器，该阅读器包含多个DPDA块。在每个DPDA块中，迭代地执行dual-attention来表示文档和问题，并使用带有动态注意力掩码的段落自注意来融合每个段落中的关键标记。生成的上下文感知问题表示、question-aware token-level和段落级别表示被输入预测器以获得答案。</p><p>设计DPDA的动机：</p><ul><li>尽管整个维基百科页面包含大量文本，但大多数答案只与一段中的几个单词相关。</li><li>最后的段落表示法可以自然地用于预测长答案（对应段落）。</li></ul><p>任务定义：</p><p>给定一个自然问题q，一个相关的Wikipedia页面p（在谷歌搜索引擎返回的前5个搜索结果中），该模型输出Wikipedia页面p中的一个段落作为长答案，其中包含足够的信息来推断问题的答案，以及长答案中的一个实体跨度作为短答案回答问题。</p><p>5种答案类型：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">“NULL” (no answer)</span><br><span class="line">“SHORT” (has short answer)</span><br><span class="line">“LONG”(only has long answer)</span><br><span class="line">“YES” </span><br><span class="line">“NO”</span><br></pre></td></tr></table></figure><p>问题定义：</p><p>将NQ data pair (q, p)转换为6元组： (q, d, c, s, e, t)</p><blockquote><p>q：wordpiece IDs of question</p><p>d：wordpiece IDs of document span</p><p>c：长答案所在段落索引</p><p>s,e：短答案的起止位置</p><p>t：问题类型</p></blockquote><p>RikiNet takes d and q as inputs, and jointly predicts c, s, e, t.</p><p>RikiNet：Reads the Wikipedia pages for natural question answering.</p><p>模型结构：</p><p>两个模块：</p><ul><li>dynamic paragraph dual-attention reader </li><li>the multi-level cascaded answer predictor</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204141034102.png" alt="image-20220414103422056"></p><h3 id="Dynamic-Paragraph-Dual-Attention-Reader"><a href="#Dynamic-Paragraph-Dual-Attention-Reader" class="headerlink" title="Dynamic Paragraph Dual-Attention Reader"></a>Dynamic Paragraph Dual-Attention Reader</h3><p>动态段落双重注意力（DPDA）阅读器旨在表示文档跨度d和问题q。它输出上下文感知的问题表示、token-level的问题感知的文档表示和段落级文档表示，所有这些都将被输入预测器以获得长答案和短答案。</p><h4 id="Encoding-Question-and-Document-Span"><a href="#Encoding-Question-and-Document-Span" class="headerlink" title="Encoding Question and Document Span"></a>Encoding Question and Document Span</h4><p>使用BERT做Encoding，长段落用滑动窗口切分成document span.</p><p>[CLS],q,[SEP],d,[SEP]</p><h4 id="Dynamic-Paragraph-Dual-Attention-Block"><a href="#Dynamic-Paragraph-Dual-Attention-Block" class="headerlink" title="Dynamic Paragraph Dual-Attention Block"></a>Dynamic Paragraph Dual-Attention Block</h4><p>DPDA reader包含多个DPDA blocks，每个DPDA block包括三部分：the dual-attention layer, the paragraph dynamic self-attention layer, and the question self-attention layer。</p><p>最后一层DPDA输出问题和文档的表示。</p><p><strong>Dual-Attention Layer</strong></p><p>使用dual-attention mechanism加强从问题到段落以及从段落到问题的信息融合。</p><p>通过增加注意力的深度来进一步调整它，然后再进行残差连接和层的归一化。</p><p><strong>Question Self-Attention Layer</strong></p><p>This layer uses a transformer self-attention block to further enrich the question representation.</p><p><strong>Paragraph Dynamic Self-Attention Layer</strong></p><p>This layer is responsible for gathering information on the key tokens in each paragraph.</p><h3 id="Multi-level-Cascaded-Answer-Predictor"><a href="#Multi-level-Cascaded-Answer-Predictor" class="headerlink" title="Multi-level Cascaded Answer Predictor"></a>Multi-level Cascaded Answer Predictor</h3><p>由于NQ任务的性质，短答案总是包含在长答案中，因此使用长答案的预测来促进获得短答案的过程是有意义的。</p><p>该预测器将token representation,$D(T)$、paragraph representation $L$ 和question embedding $q$ 作为输入，以级联方式预测四个输出：（1）长答案→ （2） 短答案范围的起始位置→ （3） 短答案跨度的结束位置→ （4） 答案类型。也就是说，前面的结果将用于下一个任务，如符号所示“→”。</p><p><strong>Long Answer Prediction</strong></p><p>采用了一个全连接层F，使用TANH激活函数，作为长答案预测层。</p><p>输入：paragraph representation</p><p><strong>Short Answer Prediction</strong></p><p>预测短答案的起止位置。</p><p>输入：long-answer prediction representation 和 token representation</p><p><strong>Answer Type Prediction</strong></p><p>输入：question embedding $q$ ，token representation，short-answer prediction representation</p><p>将question embedding $q$ 作为答案类型预测的辅助信息。</p><p><strong>交叉熵损失函数</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204141456583.png" alt="image-20220414145618534" style="zoom:33%;" /></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>Natural Questions (NQ)</li></ul><blockquote><p>NQ数据集的公开发布包括307373个训练示例和7830个验证集数据示例（dev）。NQ提供了一个包含7842个示例的blind test set，只能通过公共排行榜提交来访问。</p></blockquote><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204141505602.png" alt="image-20220414150522573"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>RikiNet由一个动态段落双注意阅读器和一个多级级联答案预测器组成，前者学习标记级、段落级和问题表示，后者以级联方式联合预测长答案和短答案。在自然问题(NQ)数据集上，RikiNet是第一个超越单一人类得分的单一模型。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 长文本 </tag>
            
            <tag> NQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VAULT VAriable Unified Long Text Representation for Machine Reading Comprehension</title>
      <link href="/2022/04/14/VAULT%20VAriable%20Unified%20Long%20Text%20Representation%20for%20Machine%20Reading%20Comprehension/"/>
      <url>/2022/04/14/VAULT%20VAriable%20Unified%20Long%20Text%20Representation%20for%20Machine%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="VAULT-VAriable-Unified-Long-Text-Representation-for-Machine-Reading-Comprehension"><a href="#VAULT-VAriable-Unified-Long-Text-Representation-for-Machine-Reading-Comprehension" class="headerlink" title="VAULT: VAriable Unified Long Text Representation for Machine Reading Comprehension"></a>VAULT: VAriable Unified Long Text Representation for Machine Reading Comprehension</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2105.03229">https://arxiv.org/abs/2105.03229</a></p><p> 会议：ACL 2021</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        现有的机器阅读理解（MRC）模型需要复杂的模型体系结构，才能有效地对<strong>具有段落表示和分类的</strong>长文本进行建模，从而使推理的计算效率不高。在这项工作中，本文提出了VAULT：一种轻量级、并行高效的MRC段落表示方法，基于长文档输入的上下文表示，使用一种新的基于高斯分布的目标进行训练，该目标密切关注ground-truth的部分正确实例。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>传统的QA，模型训练时，答案范围的标注非对即错，过于绝对。实际上，与真实答案重叠的跨度应被视为部分正确。基于此，本文将真实答案跨度的起始和结束位置视为类高斯分布，而不是单点，并使用统计距离优化模型。</p><p>模型：VAULT（(VAriable Unified Long Text representation），因为它可以在任何位置处理可变数量和长度的段落，使用相同的统一模型结构来处理长文本。</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132117010.png" alt="image-20220413211727987" style="zoom:50%;" /></p><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><h4 id="A-Base-“Paragraph”-Predictor-Model"><a href="#A-Base-“Paragraph”-Predictor-Model" class="headerlink" title="A Base “Paragraph” Predictor Model"></a>A Base “Paragraph” Predictor Model</h4><p>假设：通过建模更长的上下文，即使是简单的段落表示也可以有效地表示段落。</p><p>使用Longformerm建模输入，Longformer provides a much larger maximum input length of 4,096。</p><h4 id="Position-aware-Paragraph-Representation-PAPR"><a href="#Position-aware-Paragraph-Representation-PAPR" class="headerlink" title="Position-aware Paragraph Representation (PAPR):"></a>Position-aware Paragraph Representation (PAPR):</h4><p>为了解决许多流行的非结构化文本（如维基百科页面），某些相关信息的展示方式相对标准的问题（例如，生日通常在第一段，而配偶姓名则在“个人生活”段），本文通过在每个段落的开头用特殊的atomic标记（$[paragration=i]$）标记段落，指示段落在文本中的位置，为基础模型提供了它正在阅读的文本部分的表示。通过这种输入表示，可以使用特殊段落标记输出嵌入直接做长答案分类。</p><p>paragraph answer的计算：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132136004.png" alt="image-20220413213639971"></p><blockquote><p>P：文本中的所有段落</p><p>组成P的相关token：$h^p_i$</p></blockquote><p>给定上下文$c$，计算段落$l_i$的概率：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132140144.png" alt="image-20220413214057122"></p><p>流程：首先在所有候选段落中选择logit最高的段落候选段落。然后，使用标准的指针网络在选定的段落答案候选中提取跨度答案。</p><h4 id="Gaussian-Prior-Optimization-GPO"><a href="#Gaussian-Prior-Optimization-GPO" class="headerlink" title="Gaussian Prior Optimization (GPO)"></a>Gaussian Prior Optimization (GPO)</h4><blockquote><p>高斯先验优化</p></blockquote><p>传统的跨度提取模型通过极大似然估计优化了答案跨度与真实答案跨度的预测起点和终点位置的概率。MLE方法提高了真实答案位置的概率，同时抑制了所有其他位置的概率。但实际情况并非这样绝对，本文假设，接近真实答案的位置相对于较远位置的token要给较高的置信度，因为提取的答案会与真实答案部分重叠。</p><p>真实答案范围：$s \in {start, end}$</p><p>高斯分布：$N (y_s, σ)$</p><blockquote><p>均值：真实答案的位置，$y_s$</p><p>方差：超参数</p></blockquote><p>概率密度：<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132212045.png" alt="image-20220413221241008" style="zoom: 50%;" /></p><p>真实答案在$y_s$位置的类高斯分布：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132214120.png" alt="image-20220413221456088"></p><blockquote><p>用T重新缩放</p></blockquote><p>损失函数：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132218131.png" alt="image-20220413221833105"></p><p>使用KL散度增强训练的MLE（极大似然估计）目标。</p><blockquote><p>构建的分布：<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132221093.png" style="zoom: 50%;" /></p><p>模型的预测：<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132222933.png" alt="image-20220413222200912" style="zoom:50%;" /></p></blockquote><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>一个基于维基百科（Natural Questions，NQ）</li></ul><blockquote><p>NQ试图通过提供较长的维基百科文件作为语境和真实的用户搜索引擎查询作为问题，使机器阅读理解（MRC）更加真实，并旨在避免观察偏差：如果问题是在用户看到段落后创建的，那么问题和答案语境之间的词汇重叠会经常发生。</p><p>NQ由出现在谷歌搜索日志中的crowdsourced-annotated full维基百科页面组成，其中包含两个任务：短答案（SA）和长答案（LA，例如段落）的起始和结束偏移量（如果存在）</p></blockquote><ul><li>另一个基于技术说明（TechQA）</li></ul><blockquote><p>TechQA是从客户支持领域（customer support domain）的真实用户问题发展而来的，每个问题都有50个文档，其中大多数文档都有答案——答案比标准的MRC数据集（如SQuAD）长很多（~3-5倍）。</p></blockquote><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132039857.png" alt="image-20220413203938826"></p><blockquote><p>VAULT可以从文章较后位置预测答案，但现有模型从一般答案最容易出现的第一段预测答案。</p></blockquote><ul><li>在NQ数据集上</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132232399.png" alt="image-20220413223233371"></p><blockquote><p>短答案和长答案</p></blockquote><ul><li>TechQA</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204132233698.png" alt="image-20220413223325674"></p><blockquote><p>HA F1 (denotes Has Answer)</p></blockquote><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在这项工作中，介绍并检验了一个功能强大但简单的长文本阅读理解模型，称之为VAULT，基于这样一个假设：如果序列长度较大，长答案可以有效分类，而无需计算繁重的基于图的模型。</p><p>本文贡献：</p><ul><li>本文介绍了一种新颖、有效但简单的段落表示法。</li><li>在训练期间，引入软标签，以利用来自local contexts的信息，接近正确答案，这对于MRC来说是新颖的。</li><li>本文的模型提供了与NQ上的SOTA系统类似的性能，同时速度提高了16倍，并且有效地适应了一个新领域：TechQA。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 长文本 </tag>
            
            <tag> Longformer </tag>
            
            <tag> 高斯分布 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>READTWICE Reading Very Large Documents with Memories</title>
      <link href="/2022/04/13/READTWICE%20Reading%20Very%20Large%20Documents%20with%20Memories/"/>
      <url>/2022/04/13/READTWICE%20Reading%20Very%20Large%20Documents%20with%20Memories/</url>
      
        <content type="html"><![CDATA[<h1 id="READTWICE-Reading-Very-Large-Documents-with-Memories"><a href="#READTWICE-Reading-Very-Large-Documents-with-Memories" class="headerlink" title="READTWICE: Reading Very Large Documents with Memories"></a>READTWICE: Reading Very Large Documents with Memories</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2105.04241">https://arxiv.org/abs/2105.04241</a></p><p> 会议：NAACL 2021</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>知识密集型任务（如问答）通常需要吸收大量输入（如书籍或文章集）不同部分的信息。本文提出<strong>READTWICE</strong>，它结合了以前的几种方法的优点，用Transformers建模long-range dependencies。其主要思想是以小段并行方式阅读文本，将每个段汇总到一个内存表中，以便在第二次阅读文本时使用。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>主要思想：</p><p>将一个长文本输入当作一个较短的文本片段的集合，独立地、并行地读取。然后，编码器再次读取每个片段，使用其他片段的压缩信息做增强。</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204131104502.png" alt="image-20220413110449460"></p><blockquote><p>memory module that holds compressed information from all segments. That compressed information is used only once: in the second pass.</p></blockquote><ul><li><p>在第一次读取中，每个段都用标准的BERT进行独立编码。然后，从每个片段中提取memories，并将其收集到一个全局内存池中。</p><blockquote><p> 每个段限制在512toekns</p></blockquote></li><li><p>对于第二次读取，首先使用MemoryAttention层（上层是residual connection and a LayerNorm layer）合并来自前段内contextual token embeddings和全局内存的信息。合并后的结果由另一个只有两个Transformers层的BERT小模型读取，以产生最终输出。因为第一次读取已经生成了丰富的上下文嵌入，而第二次只需要读内存的信息。</p></li></ul><p>用公式说明：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204131349047.png" alt="image-20220413134913023" style="zoom:33%;" /></p><blockquote><p>$x_i$ 表示分成的段i，$x_1, . . . , x_N$</p></blockquote><p>三种类型的memorie：</p><ul><li><p>READTWICE (CLS)。使用与段$x_i$相关的CLS标记表示，作为该段的摘要。</p></li><li><p>READTWICE (STS)。为了获得更精细的记忆，为每个连续的，长度位32个tokens的span提取一个记忆向量。每个span的第一个和最后一个标记的上下文嵌入被连接起来，并线性地投射到标记向量空间中的一个点，作为跨度表示。投射矩阵是从头到尾学习的。</p></li><li><p>READTWICE(E)。在基于跨度的记忆的另一个变体中，记忆entity mention spans的表示。为了获得这些跨度，首先用一个外部的命名实体识别系统对每个片段进行注释。然后，每个实体提及的跨度以与READTWICE（STS）相同的方式进行编码。</p><blockquote><p>这样做是出于直觉的考虑到：长距离的依赖性主要发生在实体之间。</p></blockquote></li></ul><h3 id="MemoryAttention"><a href="#MemoryAttention" class="headerlink" title="MemoryAttention"></a>MemoryAttention</h3><p>让单个片段的上下文tokens embedding 通过内存表上的dot-product attention与其他片段的记忆交互。</p><p>attention 权重定义：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204131453801.png" alt="image-20220413145358775" style="zoom:33%;" /></p><blockquote><p>$h_{ij}$：段落i的第j个token</p><p>m：memory table entry</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204131456469.png" alt="image-20220413145604446" style="zoom:33%;" /></p><blockquote><p>$r_{i,m_s}$：学习到的片段$i$和记忆$M_m$之间相对距离的position score</p><p>w：是一组按距离索引的权重</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204131500507.png" alt="image-20220413150019484" style="zoom:33%;" /></p><blockquote><p>将距离的阈值限制在[−B, B]之间</p></blockquote><p>MemoryAttention layer output：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204131502050.png" alt="image-20220413150241031" style="zoom:33%;" /></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li><p>HotpotQA (HQA) </p></li><li><p>TriviaQA (TQA) </p></li><li><p>NarrativeQA (NQA)</p><blockquote><p>NQA会询问有关整本书的问题，需要QA系统来建模非常长的依赖关系。</p></blockquote></li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><ul><li>HotpotQA</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204131513925.png" alt="image-20220413151357899" style="zoom: 33%;" /></p><ul><li>NarrativeQA</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204131525501.png" alt="image-20220413152520478"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>READTWICE在多个QA任务中表现良好，尤其是在NarrativeQA中，实体之间的远距离依赖似乎非常重要。该方法概念简单，易于实现，能够阅读整本书。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> HotpotQA </tag>
            
            <tag> 长文本 </tag>
            
            <tag> NarrativeQA </tag>
            
            <tag> TrivalQA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EQG-RACE Examination-Type Question Generation</title>
      <link href="/2022/04/07/EQG-RACE%20Examination-Type%20Question%20Generation/"/>
      <url>/2022/04/07/EQG-RACE%20Examination-Type%20Question%20Generation/</url>
      
        <content type="html"><![CDATA[<h1 id="EQG-RACE-Examination-Type-Question-Generation"><a href="#EQG-RACE-Examination-Type-Question-Generation" class="headerlink" title="EQG-RACE: Examination-Type Question Generation"></a>EQG-RACE: Examination-Type Question Generation</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2012.06106">https://arxiv.org/abs/2012.06106</a></p><p> 代码：<a href="https://github.com/jemmryx/EQG-RACE">https://github.com/jemmryx/EQG-RACE</a></p><p> 会议：AAAI-2021</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        本文提出了一种创新的考试型问题生成方法（EQG-RACE），基于从RACE提取的数据集生成类似考试的问题。EQG-RACE中采用了两个主要的策略来处理离散的答案信息和长语境中的推理:</p><ul><li>一个粗略的答案和关键句子标签方案被用来加强输入的表述。</li><li>一个答案引导的图卷积网络（AG-GCN）被设计用来捕捉揭示句子间和句子内关系的结构信息。</li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>构建数据集的两个挑战：</p><ul><li>首先，答案往往是完整的句子（或长短语），而不是包含在输入序列中的短文本跨度，这使得之前的答案标签方法失效。</li><li>其次，上下文段落较长，问题是通过多个句子的深度推理而产生的，这使得像LSTM这样的顺序编码方法无法发挥作用。</li></ul><p>解决方案：</p><ul><li>为了解决第一个问题，本文采用了一种远距离监督的方法来寻找关键的答案词和关键的句子，然后将它们融入词的表示中。</li><li>为了解决第二个问题，并对句子内部和句子之间的推理关系进行建模，本文设计了一个Answerguided Graph Convolutional Network（AG-GCN）来捕捉结构信息。</li></ul><h3 id="Model-Description"><a href="#Model-Description" class="headerlink" title="Model Description"></a>Model Description</h3><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072001392.png" alt="image-20220407200108365"></p><p>​        首先，根据答案信息对段落关键词进行注释。输入的段落被送入一个答案引导的GCN，以获得以答案为中心的语境嵌入。然后，单词嵌入、关键词标签嵌入、GCN嵌入和预训练嵌入的特征被连接起来，作为双向LSTM编码器的输入，将一个门控的自意机制被应用于passage隐藏状态。经过上述步骤，融合段落和答案的隐藏状态，以获得答案感知的上下文表征。最后，用一个基于注意力的解码器在maxout-pointer机制的帮助下依次生成问题。</p><p>目标：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204071958010.png" alt="image-20220407195804980" style="zoom:33%;" /></p><blockquote><p>给定文章p和相关答案a提出问题q。</p></blockquote><p>Baseline Model：gated self-attention maxout-pointer model</p><p><strong>encoder</strong>：use two-layer bi-directional LSTMs</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072018923.png" alt="image-20220407201811875" style="zoom:33%;" /></p><blockquote><p>$h^p<em>t$ and $h</em>{t−1}$ are LSTM hidden states, and $e^p_t $ is word embedding</p></blockquote><p>gated self-attention mechanism：</p><blockquote><p>用来将passage的隐藏层表示H，聚合intra-passage（文档内）依赖，得到encoder output $ \hat H$：</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072024430.png" alt="image-20220407202443397" style="zoom:33%;" /></p><blockquote><p>其中$g_t$是一个可学习的门控参数，用来平衡$f$ ，$h$对编码器输出$ \hat H$的贡献度。</p></blockquote><p><strong>decoder</strong> ：another two-layer uni-directional（单向） LSTM。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072039440.png" alt="image-20220407203928403" style="zoom:33%;" /></p><blockquote><p>通过注意力机制聚合$\hat H$得到上下文向量$c_t$。</p></blockquote><p>maxout-pointer mechanism计算目标单词$y_t$的概率分布：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072041186.png" alt="image-20220407204148130" style="zoom:33%;" /></p><h3 id="Keywords-Tagging"><a href="#Keywords-Tagging" class="headerlink" title="Keywords Tagging"></a>Keywords Tagging</h3><blockquote><p>标签”A”的优先级高于”S”，如果单词同时出现两个标签，则打上”A”标签</p><p>如果同时不出现，word打上”O”标签</p></blockquote><p><strong>标记答案：</strong></p><p>将文章中出现的答案词标记为”A”</p><p><strong>标记关键句：</strong></p><blockquote><p>根据文章回答特定的问题，答案往往在某几个关键句中，而不是全文。</p><p>关键句中所有单词都被打上”S”标签。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072056004.png" alt="image-20220407205618974" style="zoom:33%;" /></p><blockquote><p>$S_t$：表示文章中的第t句</p><p>$A_i$：答案文本</p></blockquote><p>融合关键词信息之后，encoder的输入可以改写为：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072101059.png" alt="image-20220407210128032" style="zoom:33%;" /></p><blockquote><p>将Keywords tagging $k^p_t$ 和word embeddings $e^p_t$连接，作为输入特征的增强表示。</p></blockquote><p>回答RACE中的问题，涉及不同的认知技能，通常需要对句子内部和句子之间的复杂关系进行深入推理，传统的CNN，RNN无法胜任，本文提出Answer-guided Graph Convolution Network (AG-GCN)编码文章。</p><p>图结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072117893.png" alt="image-20220407211715866" style="zoom: 25%;" /></p><blockquote><p>句子标签策略：</p><p>$S_B(Begining)$ ：represents sentences containing words in $A_f$ </p><p>$S_I(Inside)$： represents sentences that connect any two important sentences S_B;也就是说，$S_i$位于两个$S_B$之间。</p><p> others are represented as $S_O(Out)$</p><p> “isolated” nodes：本文认为$S_O$中的节点是 “孤立的 “节点，因为它们不包含以答案为中心的信息，不能对两个基本句子之间的推理过程做出贡献。</p></blockquote><p>构建步骤：</p><ul><li><p>第1步：对上下文段落中的每个句子进行依赖性分析。</p></li><li><p>第2步：通过连接处于句子边界和相邻的节点，将相邻句子的依赖树连接起来，建立一个段落级的依赖解析图。</p></li><li>第3步：通过粗略的答案标签方法检索关键的答案词$A_f$，并从段落级图中删除 “孤立的 “节点和它们的边来构建答案引导图。</li></ul><p><strong>encoding process：</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072131305.png" alt="image-20220407213157251" style="zoom:33%;" /></p><blockquote><p>A：图的邻接矩阵</p><p>D is a diagonal matrix and INis the identity matrix</p><p>初始$g_0$初始化为单位矩阵E</p></blockquote><p>encoder的输入（公式15）可以再次被改写为：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072136555.png" alt="image-20220407213621528" style="zoom:33%;" /></p><blockquote><p>将Keywords tagging $k^p_t$ 和word embeddings $e^p_t$和GCN的输出$g_t^p$连接，作为输入特征的增强表示。</p></blockquote><h3 id="Exploring-Pre-training-Embeddings"><a href="#Exploring-Pre-training-Embeddings" class="headerlink" title="Exploring Pre-training Embeddings"></a>Exploring Pre-training Embeddings</h3><p>由于EQG-RACE数据集的样本相对较少，直接用深层神经网络可能会出问题，因此使用预训练模型的embeddings作为encoder输入的补充。公式（19）可以继续被改写为：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072142575.png" alt="image-20220407214255551" style="zoom:33%;" /></p><blockquote><p>$p^p_t$：可使用像BERT、ELMO等预训练模型的embedding</p></blockquote><h3 id="Passage-answer-Fusion"><a href="#Passage-answer-Fusion" class="headerlink" title="Passage-answer Fusion"></a>Passage-answer Fusion</h3><p>为了很好地捕捉段落P和答案A之间的相互依赖关系，融合answer representation $h^A$ 和 passage representation $h^p_t$  得到 answer-aware representations作为</p><p>encoder输出：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072145696.png" alt="image-20220407214552664" style="zoom:33%;" /></p><blockquote><p>$h^A$：答案隐藏层表示</p></blockquote><p>小技巧：</p><blockquote><p>在解码过程中，第一个疑问词是整个生成问题中最重要的部分之一。因此，本文没有使用段落编码器的最后一个隐藏状态 $h^p_t$，而是利用答案编码器的状态$h^A$作为解码器的初始化，在这种设置下，解码器可能会产生更多关注答案的问句。</p></blockquote><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>SQuAD和本文提出的EQG-RACE数据集详细比较：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204071040832.png" alt="image-20220407104026771"></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072152178.png" alt="image-20220407215249123"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>Case Study:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204072159280.png" alt="image-20220407215911252"></p><p>​        本文提出EQG-RACE来自动生成考试类问题，重建了原始的RACE数据集，以适应问题的生成。为了处理上下文段落中离散的答案信息，提出了一个粗略的答案和关键句子标签方案来定位与答案有关的内容。此外，还设计了一个答案引导图来捕捉以答案为重点的结构信息，作为seq2seq模型的补充。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> QG </tag>
            
            <tag> GCN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RoR Read-over-Read for Long Document Machine Reading Comprehension</title>
      <link href="/2022/04/05/RoR%20Read-over-Read%20for%20Long%20Document%20Machine%20Reading%20Comprehension/"/>
      <url>/2022/04/05/RoR%20Read-over-Read%20for%20Long%20Document%20Machine%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="RoR-Read-over-Read-for-Long-Document-Machine-Reading-Comprehension"><a href="#RoR-Read-over-Read-for-Long-Document-Machine-Reading-Comprehension" class="headerlink" title="RoR: Read-over-Read for Long Document Machine Reading Comprehension"></a>RoR: Read-over-Read for Long Document Machine Reading Comprehension</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2109.04780">https://arxiv.org/abs/2109.04780</a></p><p> 代码：<a href="https://github.com/jd-ai-research-nlp/ror">https://github.com/jd-ai-research-nlp/ror</a></p><p> 会议：EMNLP2021</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        基于Transformer的预训练语言模型，例如BERT，由于编码长度的限制（如512个WordPiece tokens），一个长文档通常被分割成多个独立阅读的块。这导致阅读领域被限制在个别的块上，没有信息协作的长文档机器阅读理解。为了解决这个问题，本文提出了RoR，一种read-over-read的方法，它将阅读领域从块扩展到文档。</p><p>​        为了处理超过长度限制的长文件，一个常用的方法是将文件分成多个独立的块，然后分别从每个块中预测答案。这些答案中得分最高的跨度被选为最终答案。这种方法很直接，但会导致两个问题：</p><ol><li>阅读领域被限制在区域块中，而不是完整的文件。</li><li>答案的分数不具有可比性，因为它们没有在块中进行<strong>全局标准化</strong>。</li></ol><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>​        具体来说，RoR包括一个块阅读器和一个文档阅读器（两者都基于预训练模型）。分块阅读器首先预测每个分块中的区域答案。然后通过最小跨度覆盖算法将这些答案压缩成一个新的文件，保证其序列长度短于限制（即512）。通过这种方式，所有的区域性答案都可以在一个文件中被规范化，保证只需编码一次。这个文件作为原始文件的高度压缩版本，由文档阅读器进一步读取，以预测一组全局答案。由于块阅读器和全局阅读器从不同的角度提供了高置信度的答案，本文充分地利用这两者来预测最终的答案。具体来说，在预测了区域和全局答案的跨度后，本文提出了一个投票策略，并利用它来重新排序。这个投票策略是基于这样的想法：一个候选的区域或全局答案跨度与其他答案跨度重叠得更多，就更可能是正确的。</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204051541991.png" alt="image-20220405154135927" style="zoom: 50%;" /></p><h3 id="Framework-Overview"><a href="#Framework-Overview" class="headerlink" title="Framework Overview"></a>Framework Overview</h3><p>文本对：$(P, q)$</p><p>分块：${(P_1, q), …, (P_N, q)}$</p><p>regional answers，块阅读器预测的答案：<img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204052226598.png" alt="image-20220405222644529" style="zoom: 33%;" /></p><p>使用minimum span coverage  (MSC)算法将regional answers压缩，得到$P^q$，TriviaQA数据集中的大多数答案都是无法反映足够上下文信息的命名实体。因此，对于TriviaQA数据集，本文使用区域答案所在的句子压缩到$P^q$。</p><p>document reader使用$P^q$，预测得到全局答案：${g<em>i}^T</em>{i=1}$</p><blockquote><p>T：每个块预测答案数的上限。</p></blockquote><h3 id="Chunk-Reader"><a href="#Chunk-Reader" class="headerlink" title="Chunk Reader"></a>Chunk Reader</h3><h4 id="Text-Encoder"><a href="#Text-Encoder" class="headerlink" title="Text-Encoder"></a>Text-Encoder</h4><p>输入：$X = [[CLS]; q; [SEP]; P]$</p><h4 id="Answer-Prediction"><a href="#Answer-Prediction" class="headerlink" title="Answer Prediction"></a>Answer Prediction</h4><ul><li>预测答案的span只需要token level feature。</li></ul><p>计算span开始和结束位置的概率：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204051629618.png" alt="image-20220405162901586" style="zoom: 33%;" /></p><blockquote><p>$h_s$：span开始位置的token表示</p><p>从公式（2）可以看到，开始和结束位置的预测过程并不独立，结束位置的概率分布计算取决于起始位置。</p></blockquote><p>使用交叉熵损失函数：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204051634260.png" style="zoom:33%;" /></p><blockquote><p>$y^s_j\ y^e_j$：表示真实答案的范围。</p></blockquote><ul><li>Sentence level answer</li></ul><p>可以根据$[CLS]$预测对话任务的下一步动作，由于当前任务不涉及对话，详细实现可以再去看原文对应部分。</p><h4 id="Answer-Calibration"><a href="#Answer-Calibration" class="headerlink" title="Answer Calibration"></a>Answer Calibration</h4><p>由于区域答案中得分最高的跨度有时不是F1得分最高的跨度，因此通过answer calibration mechanism提高区域答案准确度。</p><p>首先计算候选答案的跨度表示，这是一个加权自对准向量：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204051650050.png" alt="image-20220405165033023" style="zoom:33%;" /></p><blockquote><p>$[s_t:e_t]$表示候选答案的范围。</p><p>$C_t$是候选答案的跨度表示。</p><p>候选答案集合：$c = [c_1, …, c_T]$</p></blockquote><p>通过multi-SelfAtt捕捉候选答案之间的相似性和差异：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204051653975.png" alt="image-20220405165319951" style="zoom:33%;" /></p><blockquote><p>t是预测候选答案的位置编码，t值越小，原始预测分数越高，可帮助模型识别候选答案的重要性。</p></blockquote><p>使用交叉熵损失函数：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204051657102.png" alt="image-20220405165743065" style="zoom: 33%;" /></p><blockquote><p>$y_j^{ac}$：人工指定为，在候选答案中F1分属最高的span。</p><p>如果F1的最高分是0，而相应的问题是可以回答的，就随机地用gold span替换一个候选答案。</p></blockquote><h3 id="Document-Reader"><a href="#Document-Reader" class="headerlink" title="Document Reader"></a>Document Reader</h3><p>长文本通过Minimum Span Coverage (MSC) 算法压缩到512个token以内，得到$P^q$，MSC保证$P^q$覆盖所有regional span，并充分压缩，确保只需要一次编码。</p><p>encoder输入：$X = [[CLS]; q; [SEP]; P^q]$</p><p>因为输入的文本经过了聚合，所以答案标签也要有所变化，定义为 $P^q$ and the original gold span的最长公共子序列。</p><h3 id="Voting-Strategy"><a href="#Voting-Strategy" class="headerlink" title="Voting Strategy"></a>Voting Strategy</h3><p>假设：块读器和文档阅读器共同预测到的跨度更可能是正确的。</p><p>投票策略：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204052122666.png" alt="image-20220405212231633" style="zoom:33%;" /></p><blockquote><p>$|x_i∩ x_j|$：表示两个答案span的共有单词。</p><p>F1值可以理解为两个答案的相似度。</p></blockquote><p>根据得分重排序：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204052125091.png" alt="image-20220405212543065" style="zoom:33%;" /></p><blockquote><p>$S(X)$：表示原始的预测分数。</p><p>$\gamma$：；两个得分的权重。</p></blockquote><h3 id="Training-and-Inference"><a href="#Training-and-Inference" class="headerlink" title="Training and Inference"></a>Training and Inference</h3><p>联合学习：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204052129323.png" alt="image-20220405212905280" style="zoom:33%;" /></p><blockquote><p>$L_c$：块阅读器的损失，其中$L_s$是用来做对话任务的。</p><p>$L_d$：文档阅读器的损失。</p></blockquote><p>训练流程：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204052146814.png" alt="image-20220405214627780" style="zoom: 50%;" /></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>两个长文本数据集</p><ul><li>QuAC (Question Answering in Context)</li></ul><blockquote><p>QuAC是一个大型数据集，用于模拟寻求信息的对话。它的问题往往更加开放、无法回答，或者只有在对话环境中才有意义。</p></blockquote><ul><li>TriviaQA</li></ul><blockquote><p>TriviaQA是一个大规模的开放域MRC数据集，需要跨句推理才能找到答案。它包含来自维基百科和Web域的数据，在本文的工作中使用了维基百科子集。</p></blockquote><p>数据集分析：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204052156328.png" alt="image-20220405215638287" style="zoom:33%;" /></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>在QuAC数据集上的性能：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204052202757.png" alt="image-20220405220201730" style="zoom:33%;" /></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文贡献：</p><ul><li><p>提出了一个包含增强型块阅读器和文档阅读器的read-over-read pipeline，它能够解决现有模型中长文档阅读限制的问题。</p></li><li><p>提出了一种投票策略，对来自区域块和浓缩文档的答案进行排序，克服了从不同来源汇总答案的主要缺点（不能全局标准化的缺点）。</p></li><li>对长文档基准进行了广泛的实验以验证本文模型的有效性。特别是在QuAC数据集上，本文的模型在排行榜的所有评估指标上都取得了最先进的结果。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 长文本 </tag>
            
            <tag> QuAC </tag>
            
            <tag> TriviaQA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Block-Skim Efficient Question Answering for Transformer</title>
      <link href="/2022/04/03/Block-Skim%20Efficient%20Question%20Answering%20for%20Transformer/"/>
      <url>/2022/04/03/Block-Skim%20Efficient%20Question%20Answering%20for%20Transformer/</url>
      
        <content type="html"><![CDATA[<h1 id="Block-Skim-Efficient-Question-Answering-for-Transformer"><a href="#Block-Skim-Efficient-Question-Answering-for-Transformer" class="headerlink" title="Block-Skim: Efficient Question Answering for Transformer"></a>Block-Skim: Efficient Question Answering for Transformer</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2112.08560">https://arxiv.org/abs/2112.08560</a></p><p> 会议：AAAI 2022</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        NLP任务中使用的公共Transformer编码器处理所有层中上下文段落中所有输入tokens的隐藏状态。然而，与序列分类等其他任务不同，回答提出的问题不一定需要上下文段落中的所有tokens。基于这个动机，本文提出了<strong>Block-Skim</strong>，它学习在更高的隐藏层中跳过不必要的上下文，以提高和加速Transformer的性能。Block-Skim的关键思想是确定<strong>必须进一步处理的上下文</strong>，以及<strong>在推理过程中可以在早期安全地丢弃的上下文</strong>。关键的是，作者发现这样的信息可以从Transformer模型中的self-attention weights中得到。作者早期在较低层进一步修剪与不必要位置相对应的隐藏状态，显著节省了推理时间。</p><p>目标效果示例：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204022011353.png" alt="image-20220402201149292" style="zoom: 33%;" /></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>Layer 4 和 Layer 9的答案相关和不相关tokens权重比较:</p><blockquote><p>箱型图：上面的是答案相关的tokens所占权重，中间线条为中位数。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204022113452.png" alt="image-20220402211354421" style="zoom: 25%;" /></p><ul><li><p>在较后面的层，答案相关的tokens注意力权重显著大于答案不相关tokens的注意力权重。</p></li><li><p>在早期的层，如第4层，答案相关的tokens和无关的tokens注意力权重强度是无法区分的。</p><blockquote><p>所以在早期阶段，使用注意权重值作为答案相关性标准可能会有问题。</p></blockquote></li></ul><p>使用CNN预测块与答案的相关性：</p><blockquote><p>目的是为了找到与答案相关的块，并跳过不相关的块。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204022126185.png" alt="image-20220402212624152" style="zoom:33%;" /></p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204022144512.png" alt="image-20220402214420476"></p><p>由于attention feature map大小是动态变化的，将完整的 attention feature map 输入到CNN是比较困难的，本文采用一个比较简单的办法，直接将attention feature map的对角阵(diagonal region)作为输入。从图3也可以看出来，和完整的 attention feature map 作为输入相比，性能几乎一致，所以对角线上的注意力权重能够包含足够的信息。这样做之后，输入变得很小，计算效率自然显著提升。</p><blockquote><p>以句子为单位，或通过依存句法树分析语义关系，再去分割块。直接按固定token分割，必然会出现语义不连贯的问题。</p></blockquote><h3 id="Transformer-with-Block-Skim"><a href="#Transformer-with-Block-Skim" class="headerlink" title="Transformer with Block-Skim"></a>Transformer with Block-Skim</h3><p>遇到的问题：</p><ul><li><p>用正确答案训练块相关性预测器，对于多跳问题可能会出问题，因为解答多跳问题需要答案标签意外的信息，为了解决这个问题，本文提出了一个端到端的多目标联合训练范式（joint training paradigm）。</p></li><li><p>在推理阶段，Block-Skim模型的预测被增强，以过滤输入序列中不相关信息进行加速。这导致了训练和推理模型之间的不匹配。在训练过程中skimming blocks使联合训练不稳定。</p></li></ul><p>解决办法：</p><h4 id="1-Single-Task-Multi-Objective-Joint-Training"><a href="#1-Single-Task-Multi-Objective-Joint-Training" class="headerlink" title="1. Single-Task Multi-Objective Joint Training"></a>1. Single-Task Multi-Objective Joint Training</h4><p>在用Block-Skim模块增强的模型中，有两种类型的分类器：</p><ul><li>QA classifier at the last layer</li><li>block-level relevance classifier at each layer</li></ul><p>只计算passage中的tokens。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204022248239.png" alt="image-20220402224820193" style="zoom:25%;" /></p><p>总的损失是两个分类器的和：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204022251031.png" alt="image-20220402225136994" style="zoom:25%;" /></p><blockquote><p>$\alpha $：是和谐系数，超参数可调。</p><p>β：平衡系数β来调整正负相关区块的损失，因为通常没有答案标记的区块（即负区块）比包含答案标记的区块多得多。</p></blockquote><p>Block-Skim is a convenient plugin module：</p><ul><li>首先，它不影响骨干模型的计算，因为它只是用额外的参数对骨干模型的注意值分布进行规范化。换句话说，用BlockSkim训练的模型可以在去掉它后使用。</li><li>其次，引入的Block-Skim目标既不需要额外的训练信号，也不会降低QA的准确性。</li></ul><p><strong>该联合训练方法也可以解决多跳QA任务中的挑战。</strong></p><h4 id="2-Inference-with-Block-Skim"><a href="#2-Inference-with-Block-Skim" class="headerlink" title="2. Inference with Block-Skim"></a>2. Inference with Block-Skim</h4><p>在联合训练过程中加入了块级相关性分类损失，但实际上并没有丢弃任何块，因为它可能会skip答案块而使QA任务训练变得不稳定。所以只在推理过程中用Block-Skim模块来减少不相关信息，以节省计算量并避免对底层Transformer的严重改变。</p><p>在推理计算过程中，通过块的粒度来分割输入序列，根据skimming module的结果选择跳过的块。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>SQuAD 1.1</li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204031033587.png" alt="image-20220403103337523"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文贡献：</p><ul><li>第一次证明了注意力图对于确定答案在输入中的位置是有效的。</li><li>提出了Block-Skim，它利用注意机制改进和加速QA任务中的Transformer模型。关键是在处理过程中从注意机制中提取信息，并智能地预测要skim哪些块。</li><li>在几种基于Transformer的模型架构和QA数据集上评估了Block-Skim，并证明了其效率和通用性。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> QA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>English Machine Reading Comprehension Datasets A Survey</title>
      <link href="/2022/04/01/English%20Machine%20Reading%20Comprehension%20Datasets%20A%20Survey/"/>
      <url>/2022/04/01/English%20Machine%20Reading%20Comprehension%20Datasets%20A%20Survey/</url>
      
        <content type="html"><![CDATA[<h1 id="English-Machine-Reading-Comprehension-Datasets-A-Survey"><a href="#English-Machine-Reading-Comprehension-Datasets-A-Survey" class="headerlink" title="English Machine Reading Comprehension Datasets: A Survey"></a>English Machine Reading Comprehension Datasets: A Survey</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2101.10421">https://arxiv.org/abs/2101.10421</a></p><p> 代码：<a href="https://github.com/dariad/rczoo">https://github.com/dariad/rczoo</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>本文调查了60个英语机器阅读理解数据集，以期为其他对此问题感兴趣的研究人员提供一个方便的资源。本文根据问答形式对数据集进行分类，并在不同维度上进行比较，包括规模、数据源、创建方法、人类评估水平、数据集是否已“解决”、排行榜的可用性、最常见的第一个问题token，以及数据集是否公开可用。</p><p><strong>数据集使用的领域以及数据集之间的交集</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204011605932.png" alt="image-20220401160519889"></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>以英文MRC数据集发布时间线；</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203312151200.png" alt="image-20220331215114161" style="zoom: 50%;" /></p><h3 id="Question-Answer-and-Passage-Types"><a href="#Question-Answer-and-Passage-Types" class="headerlink" title="Question, Answer, and Passage Types"></a>Question, Answer, and Passage Types</h3><ul><li><p>问题类型分为：Statement, Query, and Question</p></li><li><p>答案类型分为：Cloze, Multiple Choice,Boolean, Extractive, Generative</p></li></ul><blockquote><p>现有数据集的详细分类在下文的表1。</p></blockquote><p>问题和答案之间的层次结构和关系：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204011427020.png" alt="image-20220401142705990" style="zoom:50%;" /></p><h4 id="Answer-Type"><a href="#Answer-Type" class="headerlink" title="Answer Type"></a>Answer Type</h4><h5 id="Cloze"><a href="#Cloze" class="headerlink" title="Cloze"></a>Cloze</h5><p>代表数据集：</p><ul><li>ReciteQA</li><li>CliCR</li></ul><h5 id="Selective-or-Multiple-Choice-MC"><a href="#Selective-or-Multiple-Choice-MC" class="headerlink" title="Selective or Multiple Choice (MC)"></a>Selective or Multiple Choice (MC)</h5><ul><li>MCTest</li></ul><h5 id="Boolean"><a href="#Boolean" class="headerlink" title="Boolean"></a>Boolean</h5><ul><li><p>BoolQ</p></li><li><p>PubMedQuestions</p><blockquote><p>除了’’YSE/NO”之外，还包括“Cannot be answered” 或 “Maybe” 类型。</p></blockquote></li></ul><h5 id="Extractive-or-Span-Extractive"><a href="#Extractive-or-Span-Extractive" class="headerlink" title="Extractive or Span Extractive"></a>Extractive or Span Extractive</h5><ul><li>SQuAD</li></ul><h5 id="Generative-or-Free-Form-Answer"><a href="#Generative-or-Free-Form-Answer" class="headerlink" title="Generative or Free Form Answer"></a>Generative or Free Form Answer</h5><ul><li>NarrativeQA</li></ul><h4 id="Question-Type"><a href="#Question-Type" class="headerlink" title="Question Type"></a>Question Type</h4><h5 id="Statement"><a href="#Statement" class="headerlink" title="Statement"></a>Statement</h5><blockquote><p> 该问题是一个陈述句，用于完形填空和问答题</p></blockquote><ul><li>SearchQA</li></ul><h5 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h5><blockquote><p>比较标准的问答形式</p><p>分为：事实类（Who? Where? What? When?) ，非事实类(How? Why?），YES/NO</p></blockquote><h5 id="Query"><a href="#Query" class="headerlink" title="Query"></a>Query</h5><blockquote><p>这个问题是为了获得一个物体的属性而提出的</p></blockquote><h4 id="Passage-Type"><a href="#Passage-Type" class="headerlink" title="Passage Type"></a>Passage Type</h4><ul><li><p>Simple Evidence</p></li><li><p>Multihop Reasoning</p><blockquote><p>例如 HotpotQA</p></blockquote></li><li><p>Extended Reasoning</p><blockquote><p>需要一些常识或者额外知识进行推理</p><p>例如Cosmos</p></blockquote></li></ul><h4 id="Conversational-MRC"><a href="#Conversational-MRC" class="headerlink" title="Conversational MRC"></a>Conversational MRC</h4><blockquote><p>问题及其答案将成为后续问题的一部分。</p></blockquote><p>Conversational or Dialog datasets</p><ul><li>ShARC</li></ul><h3 id="所有数据集及其相关属性"><a href="#所有数据集及其相关属性" class="headerlink" title="所有数据集及其相关属性"></a>所有数据集及其相关属性</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204011535521.png" alt="image-20220401153549488"></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204011536535.png" alt="image-20220401153614491"></p><blockquote><p>36/60的数据源来自Wikipedia</p></blockquote><h3 id="长度分析"><a href="#长度分析" class="headerlink" title="长度分析"></a>长度分析</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204011610244.png" alt="image-20220401161058193"></p><blockquote><p>问题长度一般在5-20个tokens。</p></blockquote><p><strong>数据集中的问题数量与其词汇量之间存在中度相关性</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204011614083.png" alt="image-20220401161438045"></p><h3 id="根据第一个token细分"><a href="#根据第一个token细分" class="headerlink" title="根据第一个token细分"></a>根据第一个token细分</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202204011631578.png" alt="image-20220401163113540" style="zoom:33%;" /></p><p><strong>评价指标根据答案类型和任务类型选择。</strong></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>主要贡献：</p><ol><li>描述并梳理了MRC数据集根据问题和答案类型而变化的方式；</li><li>提供表格和图形格式的分析，便于数据集之间的比较；</li><li>通过提供系统的比较，并通过报告数据集的“解决”状态，将社区的注意力吸引到不太受欢迎且相对未被研究的数据集上；</li><li>包含每个数据集的统计数据，如实例数、平均问题/段落/答案长度、词汇大小和文本域，可用于估计训练MRC系统的计算需求。</li></ol><blockquote><p>基于Wikipedia的数据集要慎用，因为BERT等预训练语言模型使用大量Wikipedia语料训练，无法确定回答问题的能力来自底层模型还是当前模型。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> 数据集 </tag>
            
            <tag> 综述 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Extract Integrate Compete Towards Verification Style Reading Comprehension</title>
      <link href="/2022/03/29/Extract%20Integrate%20Compete%20Towards%20Verification%20Style%20Reading%20Comprehension/"/>
      <url>/2022/03/29/Extract%20Integrate%20Compete%20Towards%20Verification%20Style%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="Extract-Integrate-Compete-Towards-Verification-Style-Reading-Comprehension"><a href="#Extract-Integrate-Compete-Towards-Verification-Style-Reading-Comprehension" class="headerlink" title="Extract, Integrate, Compete:Towards Verification Style Reading Comprehension"></a>Extract, Integrate, Compete:Towards Verification Style Reading Comprehension</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2109.05149">https://arxiv.org/abs/2109.05149</a></p><p> 代码：<a href="https://github.com/luciusssss/VGaokao">https://github.com/luciusssss/VGaokao</a></p><p> 会议：EMNLP 2021</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        本文提出了一个新的验证式阅读理解数据集，名为VGaokao。与现有的研究不同，新的数据集最初是为母语人士的评估而设计的，因此需要更高级的语言理解技能。为了应对高考中的挑战，我们提出了一种新的Extract-Integrate-Compete方法，该方法通过一种新的查询更新机制迭代选择补充证据，并自适应地提取支持证据，然后通过两两竞争来推动模型学习相似文本片段之间的细微差异。<br>​        高考涉及更多的词汇和更复杂的句子结构。此外，高考中近一半的陈述需要多重证据来证实。但是高考中的大多数陈述既不是绝对正确的，也不是绝对错误的，这需要模型仔细比较一种陈述与另一种陈述，根据给定的段落选择最合适的答案。</p><p>根本目的：</p><ul><li>从文章中提取证据，并根据检索到的证据和其他选项验证陈述。</li></ul><p>数据集中样例的推理过程：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203281627558.png" alt="image-20220328162754502" style="zoom: 33%;" /></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>​        图1展示了一个使用 <strong>soft masking</strong> 来突出显示在当前迭代之前尚未找到相应证据的tokens的示例。在证据提取之后，模型自适应地过滤无关的证据句子，并动态地确定要整合的证据片段的数量。然后根据检索到的证据对每个问题中的选项进行验证，并以成对方式进行比较，以选择最合理的答案。</p><h3 id="Extract-Integrate-Compete-Approach"><a href="#Extract-Integrate-Compete-Approach" class="headerlink" title="Extract-Integrate-Compete Approach"></a>Extract-Integrate-Compete Approach</h3><p>模型分为三个阶段：</p><ul><li>iterative evidence extraction（证据迭代提取）</li><li>adaptive evidence integration（自适应证据整合）</li><li>pairwise option competition</li></ul><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203282301994.png" alt="image-20220328230138970"></p><h4 id="iterative-evidence-extraction"><a href="#iterative-evidence-extraction" class="headerlink" title="iterative evidence extraction"></a>iterative evidence extraction</h4><p>任务定义：</p><p>evidence sentences ：${s_1, s_2, · · · , s_n}$</p><p>query：$q$ </p><p>evidence candidate：$s_i$</p><p>查询和候选证据的相关得分：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203282310775.png" alt="image-20220328231011749" style="zoom:25%;" /></p><blockquote><p>该方法独立处理每个候选证据，并生成排名列表。然而，当一个查询需要多个证据句时，独立选择排名前$k$的句子可能会忽略证据句之间的互补关系，从而产生较差的结果。</p></blockquote><p>本文采取迭代的方法，当检索到新的证据时，query representation会被更新。</p><blockquote><p>为了强调证据句之间的互补关系，同时避免过多的重叠，我们建议使用掩蔽策略来降低查询与其检索到的证据片段之间的相关性。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203282313363.png" alt="image-20220328231355338" style="zoom:25%;" /></p><blockquote><p>$e^t$：在t时间步，检索出来的证据。</p><p>$c_i^t$：证据中的第$i$个$tokens$。</p></blockquote><p>为了寻找补充证据片段，本文建议减少$q$中已被检索到的证据语句等覆盖部分的影响，以便下一步的查询表示$q_{t+1}$将更多地关注尚未找到相应证据的部分。具体的做法就是使用<strong>掩码策略</strong>。</p><p>两种掩码策略：</p><ul><li>Hard Masking </li><li>Soft Masking</li></ul><h5 id="Hard-Masking"><a href="#Hard-Masking" class="headerlink" title="Hard Masking"></a>Hard Masking</h5><p>在第$t$时间步迭代之后，只丢弃出现查询$q$中的出现在时间步$t$ evidence的tokens。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203282327171.png" alt="image-20220328232755145" style="zoom:25%;" /></p><blockquote><p>$\beta ^{i+1}_t$：表示第t次迭代，查询q中第i个tokens的权重。</p><p>如果q中的i-th tokens在证据$e^t$中，权重被置为0，意味着该tokens的向量表示置为0，即被查询q丢弃。</p></blockquote><p>根据检索到的证据更新查询q的表示：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203282339267.png" alt="image-20220328233950209" style="zoom:25%;" /></p><blockquote><p>更新每个tokens的表示。</p></blockquote><p>经过Hard Masking 新的查询表示仅限于关注尚未匹配的标记。</p><h5 id="Soft-Masking"><a href="#Soft-Masking" class="headerlink" title="Soft Masking"></a>Soft Masking</h5><p>与Hard Masking强硬的将tokens的权重置为0不同，Soft Masking，如其名，字面意义上的Soft，该策略在下一步表示中减少已被检索tokens的权重。</p><p>具体来说：查询q的i-th tokens 的权重与其在检索到的证据集中最相似的标记的匹配分数成反比。相似度使用简单的点积相似度，“反比”如何数学化的表示呢，很简单，将最高相似度变为相反数，再过一遍softmax，负数占的权重自然而然的变小了。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203282346268.png" alt="image-20220328234632237" style="zoom:25%;" /></p><blockquote><p>这里有一个猜想，用指数做底，可能是由于权重会出现负数。</p><p>否定上一条猜想，公式(4)不就是softmax吗？</p><p>其中λ用于人为调整想要扩大匹配tokens和未匹配tokens之间的权重差距的程度。</p></blockquote><p>根据检索到的证据更新查询q的表示：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203282339267.png" alt="image-20220328233950209" style="zoom:25%;" /></p><blockquote><p>与Soft Masking 一样，都是根据q更新后的rokens权重来得到新的查询表示。</p></blockquote><h4 id="Adaptive-Evidence-Integration"><a href="#Adaptive-Evidence-Integration" class="headerlink" title="Adaptive Evidence Integration"></a>Adaptive Evidence Integration</h4><blockquote><p>该证据集成器将候选证据链作为一个整体进行度量，并自适应地过滤在后续迭代中引入的无关证据片段。</p><p>use Sentence-BERT to measure the relevance between the query and the evidence chains in the adaptive integrator.</p></blockquote><p>实际上，不同的查询需要不同数量的证据。固定证据句的数量可能会给需要更少或更多证据句的查询带来噪音。为了缓解这个问题，本文引入了一个证据集成模块来自适应地确定每个查询需要多少补充证据。</p><ul><li>具体来说，经过t步BeamSearch，可以获得由t个不同的证据句子组成的多个证据链。在每条链中，根据证据句<strong>在原文中的顺序重新排列</strong>和连接证据句，以期维持证据句之间潜在的语义关系。</li><li>然后，把从不同检索步骤中获得的综合证据链输入到重新排序器（reranker）中，进一步比较它们与查询q的语义相似性。得分最高的证据链将被选为查询的q的最终证据链。</li></ul><h4 id="Pairwise-Option-Competition"><a href="#Pairwise-Option-Competition" class="headerlink" title="Pairwise Option Competition"></a>Pairwise Option Competition</h4><blockquote><p>use Chinese RoBERTa-wwm-ext-Large with Transformers toolkit.</p></blockquote><p>高考数据集，难度较大，需要仔细区分几个选项，才能得出最终答案。</p><ul><li>对于一个需要选择与文章最一致的选项的问题</li></ul><p>Pairwise Option Competition 的 hinge loss：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203291332643.png" alt="image-20220329133236611" style="zoom:25%;" /></p><blockquote><p>$g(·)$：是预训练模型计算证据集c，对声明d的支持度。</p><p>对于一个需要选择与文章最一致的选项的问题，$d^+$表示正确的选项，$d^-_i$表示一些错误选项。这些选项$d$都需要与他们的证据集$c^+, c^−_i$一一配对。</p></blockquote><ul><li>对于一个需要选择最矛盾选项的问题</li></ul><p>hinge loss :</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203291341997.png" alt="image-20220329134131969" style="zoom:25%;" /></p><blockquote><p>$d^-$表示最矛盾的选项，$d^+_i$表示一些正确选项。这些选项$d$都需要与他们的证据集$c^-, c^+_i$一一配对。</p></blockquote><p>在推理过程中，选择得分最高的选项作为问题的答案。同样地，选择得分最低的选项来回答文章与提问最矛盾的选项。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>VGaokao: verification style reading comprehension dataset.</p><p>特点：</p><ul><li>在高考的汉语测试中，大约一半的阅读理解题要求学生选择与给定文章最一致或最矛盾的陈述（即四个选项中的一个选项）。(为什么用“最”呢，因为答案正确与否并不是绝对的。)</li><li>评估学生从长文章中提取和整合信息的能力，以及分析某些语言现象或几个相似句子之间的语义关系的能力。</li></ul><p>根据上述对高考数据集问题的描述，称该问题为 verification style questions。</p><p>数据集大小：</p><ul><li>2,786 passages </li><li>3,512 questions</li><li>1.6 evidence sentences for each option</li></ul><p>数据集分析：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203282237920.png" alt="image-20220328223700890" style="zoom:33%;" /></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203291402699.png" alt="image-20220329140212671" style="zoom:33%;" /></p><blockquote><p>RoBERTa-Large-Chunk simply chunks passages into pieces.</p></blockquote><ul><li>使用三个指标来评估带有golden evdience 语句的子集上的证据质量：精确度（P）、召回率（R）和F1（F1）。</li><li>预测答案的准确性（Acc）用于评估问题层面的性能。</li></ul><p>针对Soft Masking 的消融实验：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203291420957.png" alt="image-20220329142023923" style="zoom:33%;" /></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>case study:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203291419920.png" alt="image-20220329141913894"></p><p>实验表明，本文的方法在检索到补充证据的情况下，优于高考上的各种基线，同时具有效率和可解释性的优点。</p><p>主要贡献：</p><ul><li>提出了一个新的验证式阅读理解数据集VGaokao，它嵌入了更高级的语言理解技能。</li><li>提出了一种新的抽取-集成-竞争(Extract-Integrate-Compete)方法，通过一种新的查询更新机制从长文章中迭代选择补充证据。基于hinge loss 的competition组件可以推动模型捕捉不同选择之间的细粒度差异。</li><li>实验表明，本文的方法在VGaokao上的证据检索F1和QA准确率都优于各种基线模型，同时显示了效率和可解释性的优点。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 数据集 </tag>
            
            <tag> VGaokao </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Native Chinese Reader A Dataset Towards Native-Level Chinese Machine Reading Comprehension</title>
      <link href="/2022/03/29/Native%20Chinese%20Reader%20A%20Dataset%20Towards%20Native-Level%20Chinese%20Machine%20Reading%20Comprehension/"/>
      <url>/2022/03/29/Native%20Chinese%20Reader%20A%20Dataset%20Towards%20Native-Level%20Chinese%20Machine%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="Native-Chinese-Reader-A-Dataset-Towards-Native-Level-Chinese-Machine-Reading-Comprehension"><a href="#Native-Chinese-Reader-A-Dataset-Towards-Native-Level-Chinese-Machine-Reading-Comprehension" class="headerlink" title="Native Chinese Reader: A Dataset Towards Native-Level Chinese Machine Reading Comprehension"></a>Native Chinese Reader: A Dataset Towards Native-Level Chinese Machine Reading Comprehension</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2112.06494">https://arxiv.org/abs/2112.06494</a></p><p> 数据集官网：<a href="https://sites.google.com/">https://sites.google.com/</a> view/native-chinese-reader/</p><p> 会议：NeurIPS 2021</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        本文介绍了一个新的机器阅读理解（MRC）数据集，即Native Chinese Reader（NCR），其中包含大量现代汉语和古典汉语的文章。NCR是从中国高中语文课程的试题中收集的，该试题旨在评估中国本土年轻人的语言能力。现有的中文MRC数据集要么是特定领域的，要么只关注现代汉语中几百个字符的短上下文。相比之下，NCR包含8390份文本，平均长度为1024个字符，涵盖了广泛的中国写作风格，包括现代文章、古典文学和古典诗歌。这些文本中总共有20477个问题需要很强的推理能力和常识才能找到正确答案。</p><p>现有数据集为构建与母语为汉语的人具有相同语言水平的MRC模型来说有几点局限性：</p><ul><li>文本长度太短，例如，多项选择数据集$C^3_M$，平均文档长度仅为180字符。甚至在完形填空数据集中长度也仅为500 characters。</li><li>问题难度不够。大多数现有数据集要么是抽取的，要么是特定领域的（例如，关注惯用语或简单事实）。</li><li>现有的数据集都没有考虑中国古典文献和古典诗歌的阅读理解。</li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>Native Chinese Reader（NCR）</p><ul><li><p>NCR包含8390份文本，平均长度为1024个字符，涵盖了广泛的中国写作风格，包括现代文章、古典文学和古典诗歌。</p></li><li><p>这些文本中总共有20477个问题需要很强的推理能力和常识才能找到正确答案。</p></li><li>平均长度为1024个字符。</li><li>NCR中四分之一的文档是用文言文编写的。</li><li>NCR中大约10%的经典文献是诗歌。</li><li>training/validation/test set中负例的占比分别是56.49%、57.63%和56.14%。负例指：“不正确” (“incorrect”), “不符合” (“incompatible”) or “不恰当” (“inappropriate”)。因此也需要模型有一定的推理能力。</li></ul><blockquote><p>高考中文言文是必考项目，所以说还是挺重要的吧。</p><p>idioms：成语，也算是文言文的一种形式。</p></blockquote><p>$C^3$ </p><ul><li>虽然提供基于考试的自由形式多项选择题，但是它们是为非母语人士设计的，因此不需要母语水平的推理能力和常识来回答问题。</li><li>平均文档长度仅为180字符</li></ul><h4 id="NCR与其他数据集的比较："><a href="#NCR与其他数据集的比较：" class="headerlink" title="NCR与其他数据集的比较："></a>NCR与其他数据集的比较：</h4><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203291706195.png" alt="image-20220329170653169"></p><h4 id="中文多选数据集分析比较："><a href="#中文多选数据集分析比较：" class="headerlink" title="中文多选数据集分析比较："></a>中文多选数据集分析比较：</h4><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203292046027.png" alt="image-20220329204610985"></p><ul><li>可以观察到现代中国文章的长度是古典中国文献的两倍以上。与其他中文MRC数据集相比，NCR要长一个数量级，甚至包括那些非常简洁的文言文文档。</li><li>NCR还包含更长的问题和答案选项。</li></ul><p>验证集和测试集文档长度：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203292056479.png" alt="image-20220329205603444"></p><h4 id="写作风格："><a href="#写作风格：" class="headerlink" title="写作风格："></a>写作风格：</h4><p>文言文（D1），现代中文（D2）</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203292059621.png" alt="image-20220329205950589"></p><p><strong>文言文写作风格</strong></p><p>​        这部分论文介绍比较详细，总的来说，文言文有区别于现在的句型，比如改变字符的顺序，在理解主语和宾语时经常省略主语和宾语。大多数文言词都是用一个汉字来表达的，因此不受词类的限制等等。</p><p><strong>中文写作风格</strong></p><p>对于NCR中的现代汉语文档而言，除了平均长度较长带来的挑战外，相关问题还更多地关注更深层的隐喻和潜在思想，这通常需要结合历史和文化知识进行非琐碎的推理。比如从整篇文章中推断答案，可能要求读者对作者的个人经历和时代背景有很强的了解。需要一定的额外背景知识。</p><h4 id="文本类型分类"><a href="#文本类型分类" class="headerlink" title="文本类型分类"></a>文本类型分类</h4><p><strong>文言文和现代文在长度上的分界线</strong></p><blockquote><p>以长度为10计算。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203292118431.png" alt="image-20220329211818382"></p><h4 id="问题分类"><a href="#问题分类" class="headerlink" title="问题分类"></a>问题分类</h4><blockquote><p>分为5类</p></blockquote><ol><li>匹配问题：查询文档中明确描述的事实。正确答案可以直接从文件中的一小段或一句话中获得。请注意，不同的选项可以引用不同的跨度。</li><li>语义问题：询问句子中单词或字符的语义，包括反义词、同义词、修辞和分词。</li><li>摘要问题：要求读者理解整个文件中陈述的所有事实，以便选择所需的选项，该选项提供正确或错误的事实摘要。</li><li>推理问题：要求读者进行非琐碎（non-trivial）的推理，以推断文件中未明确说明的结论。NCR中的推理问题通常要求读者具备丰富的背景知识和常识。</li><li>情绪问题：询问作者在文件中表达的隐含情绪。NCR中的情感问题通常需要了解意象、象征意义，甚至作者的社会政治观点。</li></ol><p><strong>问题类型分布：</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203292140581.png" alt="image-20220329214006535" style="zoom: 33%;" /></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>本文把随机猜测和确定性选择作为基线。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203292147726.png" alt="image-20220329214703687"></p><blockquote><p>Competition 是比赛的最优结果。</p></blockquote><p>不同写作风格下的性能：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203292151998.png" alt="image-20220329215102958"></p><p>不同类型问题下，人与机器的性能对比：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203292206755.png" alt="image-20220329220649716"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>​        作者团队使用流行的中文预训练模型实现了多个基线模型，并使用NCR数据集启动了一个在线竞赛，以检查当前方法的局限性。最佳模型的测试准确率为59%，而人工评估的平均准确率为79%，这表明当前的MRC模型与母语为汉语的人之间存在显著的性能差距，这为未来的研究提供了巨大的机会，并有望推动中国自然语言理解的前沿。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> NCR </tag>
            
            <tag> NeurIPS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>No Answer is Better Than Wrong Answer A Reflection Model for Document Level Machine Reading Comprehension</title>
      <link href="/2022/03/27/No%20Answer%20is%20Better%20Than%20Wrong%20Answer%20A%20Reflection%20Model%20for%20Document%20Level%20Machine%20Reading%20Comprehension/"/>
      <url>/2022/03/27/No%20Answer%20is%20Better%20Than%20Wrong%20Answer%20A%20Reflection%20Model%20for%20Document%20Level%20Machine%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="No-Answer-is-Better-Than-Wrong-Answer-A-Reflection-Model-for-Document-Level-Machine-Reading-Comprehension"><a href="#No-Answer-is-Better-Than-Wrong-Answer-A-Reflection-Model-for-Document-Level-Machine-Reading-Comprehension" class="headerlink" title="No Answer is Better Than Wrong Answer: A Reflection Model for Document Level Machine Reading Comprehension"></a>No Answer is Better Than Wrong Answer: A Reflection Model for Document Level Machine Reading Comprehension</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2009.12056">https://arxiv.org/abs/2009.12056</a></p><p> 会议：EMNLP 2020</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        自然问题（Natural Questions，NQ）基准集(benchmark set)给机器阅读理解带来了新的挑战：答案不仅具有不同的粒度（长和短），而且具有更丰富的类型（包括<strong>无答案</strong>、是/否、单跨度和多跨度）。本文通过系统地处理所有答案类型，提出了一种称为反射网(Reflection Net)的新方法，该方法利用两步训练过程来识别无答案和错误答案情况。</p><p>谷歌提出的这个新数据集为MRC带来的挑战有两个方面：</p><ul><li>答案是以两级粒度提供的，即长答案（例如，文档中的一段）和短答案（例如，一段中的一个或多个实体）。该任务要求模型在文档级和文章级搜索答案。</li><li>在NQ任务中有更丰富的答案类型（包括<strong>无答案</strong>、是/否、单跨度和多跨度）。</li></ul><p>从给的case看，划分答案类型的标准以short_answer为主。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203261642436.png" alt="image-20220326164258390" style="zoom: 33%;" /></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>​        本文的目标是挑战丰富的答案类型，尤其是没有答案的类型。作者首先训练了一个处理所有类型答案的MRC模型。然后，利用经过训练的MRC模型来推断所有的训练数据，训练第二个模型，称为反射模型，将预测的答案、其上下文和MRC头部特征作为输入，以预测更准确的置信度得分，从而区分正确答案和错误答案。</p><p>设计反射模型的原因有三个：</p><ul><li>MRC置信度的计算通常是基于Logit的启发式，它不是标准化的，不同问题之间也不具有很强的可比性。</li><li>对于长文本来说，负例占的比例太高，会被大量的down sampled，在预测阶段，训练数据和训练数据分布不同，但模型可能会以较高的置信度给出错误答案。</li><li>MRC模型学习问题、类型和答案之间关系的表示，但不知道预测答案的正确性。</li></ul><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>模型由两部分组成：</p><ul><li>MRC model：预测答案</li><li>Reflection model：计算预测答案的置信度</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271518676.png" alt="image-20220327151837647"></p><h3 id="MRC-model"><a href="#MRC-model" class="headerlink" title="MRC model"></a>MRC model</h3><p>MRC model基于pre-trained transformers，使用滑动窗口处理长文本问题，滑动窗口中包含答案的划分为正例，反之为负例。但是对于一个长文本，负例的比例是远远高于正例的，所以本文这块采用了下采样( down-sample )。</p><p>输入：</p><script type="math/tex; mode=display">l = (t, s, e, ms)</script><blockquote><p>t：答案类型，包括 no-answer的情况</p><p>s,e：表示signal-span的开始和结束位置</p><p>ms:“：当答案是multi-span时，ms表示答案的序列标签</p></blockquote><p>对于multi-span类型，使用BIO的标注策略(关于BIO之前论文有介绍，检索关键词BIO即可)。</p><script type="math/tex; mode=display">ms = (n_1, . . . , n_T), where\ n_i∈ {B, I, O}</script><p>Embedding还是BERT那一套，答案类型的分类通过隐藏层输出的第一个token，[CLS]，经过softmax得到各类概率。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271407543.png" alt="image-20220327140727515" style="zoom: 25%;" /></p><p>那是如何得到各类概率的呢，$h(x_1)$时$H<em>1$维的张量，$H$事隐藏层维度，$W_o$是$K</em>H$维的，做矩阵乘法之后得到$K$维的输出，$K$就是答案的类别数。</p><p>损失函数：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271414325.png" alt="image-20220327141429299" style="zoom: 25%;" /></p><h4 id="signal-span"><a href="#signal-span" class="headerlink" title="signal-span"></a>signal-span</h4><p>对于signal-span只需要预测头尾位置，损失函数为头尾的加和。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271418365.png" alt="image-20220327141818336" style="zoom: 25%;" /></p><blockquote><p>S,E都是可学习参数</p></blockquote><h4 id="Multi-Spans"><a href="#Multi-Spans" class="headerlink" title="Multi Spans"></a>Multi Spans</h4><blockquote><p>将multi-span类型看作序列标注问题。</p></blockquote><p>为了使损失与答案类型和单跨度的损失相比较，没有使用传统的CRF或其他序列标记损失，而是将每个标记的隐藏层输出表示直接通过线性层，分类为B、I、O标签。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271456921.png" alt="image-20220327145606896" style="zoom:25%;" /></p><blockquote><p>表示每个token标记为B,I,O的概率。</p></blockquote><p>损失函数：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271500304.png" alt="image-20220327150001282" style="zoom:25%;" /></p><p>整个MRC model的损失函数：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271500381.png" alt="image-20220327150030356" style="zoom:25%;" /></p><p>除此之外，MRC model还应该给出每个预测答案的置信度：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271504330.png" alt="image-20220327150421301" style="zoom:25%;" /></p><blockquote><p>$x_1$表示[cls] tokens。</p></blockquote><h3 id="Reflection-Model"><a href="#Reflection-Model" class="headerlink" title="Reflection Model"></a>Reflection Model</h3><p>反射模型的目标是得到更精确的置信度分数，它可以区分正确答案和两种类型的错误答案。第一个是预测$has-ans$问题的错误答案，第二个是预测$no-ans$问题的答案。</p><h4 id="Training-Data-Generation"><a href="#Training-Data-Generation" class="headerlink" title="Training Data Generation"></a>Training Data Generation</h4><p>让MRC model推理所有的训练数据，选择<strong>top-1置信分数的答案作为实例</strong>，对于所选实例，<strong>MRC model 预测的答案、相应头部特征和正确性标签</strong>（如果预测答案与真相答案相同，则标签为1；否则为0）一起作为反射模型的训练样例。</p><blockquote><p>MRC模型必须为每个问题预测一个长文档的所有滑动窗口实例，但反射模型只需要推断一个包含MRC模型预测答案的实例。因此，反射模型的计算量很小。</p></blockquote><p>训练阶段，使用训练好的MRC model作参数初始化。</p><p>头部特征一般选 MRC model 的上几层，将[CLS]的隐藏层输出表示与头部特征拼接，用于最终置信度预测。具体头部特征如下：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271533338.png" alt="image-20220327153324293"></p><p>Embedding：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271538990.png" alt="image-20220327153804964" style="zoom:25%;" /></p><p>Ans元素：</p><ul><li>将答案类型标记添加到[cls]标记中</li><li>将位置标记添加到相应的位置标记中</li><li>并将空标记添加到其他标记中。</li></ul><blockquote><p> $f_i$是对应于上述token$x_i$的Ans元素之一。</p></blockquote><p>拿到Embedding之后，还是经过Transformer得到隐藏层表示：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271547787.png" alt="image-20220327154719762" style="zoom:25%;" /></p><p>得到隐藏层表示后，将[CLS]和头部特征拼接，输入到线性层：</p><blockquote><p>反射模型将所选实例x和预测答案作为输入。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271550144.png" alt="image-20220327155005118" style="zoom:25%;" /></p><blockquote><p>激活函数是GLUE。</p></blockquote><p>置信度$p_r$实际上就是一个概率：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271552631.png" alt="image-20220327155216575" style="zoom:25%;" /></p><p>损失函数：</p><blockquote><p>二分类交叉熵损失函数</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271554711.png" alt="image-20220327155417685" style="zoom:25%;" /></p><p>MRC model预测正确时，y = 1。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>Natural Questions (NQ) dataset：</p><ul><li><p>consists of 307,373 training examples, 7,830 development examples and 7,842 blind test examples used for leaderboard</p></li><li><p>including no-answer (51%), multi-span short answer (3.5%), and yes/no (1%) answer.</p></li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><blockquote><p>(R@P=90, R@P=75, R@P=50）表示固定精度下的召回率。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/img/MacBookPro/202203271600167.png" alt="image-20220327160031134"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>​        本文是首次在NQ任务中对所有答案类型进行建模。本文提出了一种系统的方法来处理MRC中丰富的答案类型。设计了一个反射模型来解决无答案/错误答案的情况。其关键思想是训练第二阶段模型，并根据其内容、上下文和MRC模型的状态，预测答案的置信度得分。该方法在NQ集上实现了最先进的结果。由F1和R@P=90来看，在长答案和短答案上，本文的方法比以前的顶级系统有很大的优势。</p><p>​        </p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> QA </tag>
            
            <tag> Natural Questions </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Retrieval-Free Knowledge-Grounded Dialogue Response Generation</title>
      <link href="/2022/03/21/Retrieval-Free%20Knowledge-Grounded%20Dialogue%20Response%20Generation/"/>
      <url>/2022/03/21/Retrieval-Free%20Knowledge-Grounded%20Dialogue%20Response%20Generation/</url>
      
        <content type="html"><![CDATA[<h1 id="Retrieval-Free-Knowledge-Grounded-Dialogue-Response-Generation"><a href="#Retrieval-Free-Knowledge-Grounded-Dialogue-Response-Generation" class="headerlink" title="Retrieval-Free Knowledge-Grounded Dialogue Response Generation"></a>Retrieval-Free Knowledge-Grounded Dialogue Response Generation</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2105.06232">https://arxiv.org/abs/2105.06232</a></p><p> AAAI 2021</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        为了使产生的对话响应多样化和丰富，近年来对基于知识的对话研究，现有的方法通过检索大量语料库中的相关句子，并使用显式的额外信息增强对话来解决基于知识对话任务的挑战。尽管取得了成功，但是现有的工作在推理效率上存在缺陷。本文提出了一种端到端的框架KnowExpert，它绕过显式检索过程，通过轻量级适配器将知识注入预训练语言模型，并适应基于知识的对话任务。</p><p>本文对话生成模型与以往增强对话生成方法的区别：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220321104413.png" alt="image-20220321104413318" style="zoom: 25%;" /></p><p>以往的解决方案包括：</p><blockquote><p>在该方案中，知识检索和知识选择被认为构成了知识概念化的过程。</p></blockquote><ul><li>知识检索，用于从大型语料库（如维基百科）检索相关知识句子；</li><li>知识选择，用于选择最相关的知识句子进行生成；</li><li>知识增强生成，用于增强检索到的知识和对话历史，以生成更知识化的响应。</li></ul><p>传统基于检索的方法有很明显的缺陷：</p><ul><li>首先，语料库中的知识检索需要一个模型来搜索大量数据，这需要大量的内存资源来存储整个知识库，并需要额外的处理时间来检索知识和进行进一步的知识选择；</li><li>第二，向语言生成模型添加知识作为附加上下文也会导致大量计算开销，这会减慢语言生成过程。</li></ul><blockquote><p>对话生成的过程，其实跟日常对话中的场景类似，不会有人愿意花很长时间等一个人回复吧，所以生成效率很重要！！！</p></blockquote><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>​        本文通过使用与训练语言模型中的隐性知识来解决基于知识的对话挑战，作为开放领域聊天场景下的知识概念化过程。与图1所示的现有工作方案相比，绕过了检索步骤，提出了一个端到端的框架KnowExpert，将知识库注入预先训练的LMs(language models)的内存中，并利用潜在主题整合所学知识，以生成基于知识的对话。在该模型中，轻量级适配器连接在预训练的GPT-2中，充当知识专家。</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220321105838.png" alt="WX20220321-105809@2x"></p><h3 id="任务定义"><a href="#任务定义" class="headerlink" title="任务定义"></a>任务定义</h3><p>对话数据集：${D^n}^N_{n=1}$</p><p>第$t$轮对话历史：$D<em>t = {(U_i, S_i)}^t</em>{i=1}$，其中$U_t$表示用户对话，$S_t$表示系统响应。</p><p>语料库：${K_m}^M-{m=1}$，其中$K_m$表示知识片。</p><p>输入：$X<em>t= (D</em>{t−1}, U_t)$</p><p>通过向模型参数$Θ$中注入知识来绕过检索过程，以仅基于对话历史生成响应：$\tilde s<em>t= f</em>Θ(X_t)$</p><h3 id="KnowExpert"><a href="#KnowExpert" class="headerlink" title="KnowExpert"></a>KnowExpert</h3><blockquote><p>在响应生成过程中，通过主题信息的引导，引入主题模型来唤起存储在GPT-2中的知识。</p></blockquote><p>KnowExpert有两部分组成：</p><ul><li>a GPT-2 with lightweight adapters </li><li>a contextual topic model</li></ul><h4 id="GPT-2-with-Adapters"><a href="#GPT-2-with-Adapters" class="headerlink" title="GPT-2 with Adapters"></a>GPT-2 with Adapters</h4><p>​        为了与知识相结合，将轻型适配器插入每个GPT-2层。适配器具有两层线性结构，能够快速适应目标。给定GPT-2 第$i$层的隐藏表示，表示为$H_i∈ R^{j×h}$，其中$h$和j分别是隐藏维度和当前生成步骤，适配器可以表示为：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220321153830.png" alt="image-20220321153830650" style="zoom: 25%;" /></p><blockquote><p>LN(·) is layer normalization</p><p>插入L个knowledge adapters，充当不同主题领域的知识专家</p></blockquote><h4 id="Topic-Modeling"><a href="#Topic-Modeling" class="headerlink" title="Topic Modeling"></a>Topic Modeling</h4><p>​        在KnowExpert中，主题模型用于在响应生成过程中向GPT-2通知更相关的“主题”，从而归纳出更适合上下文的知识。采用了上下文主题模型（CTM），其性能优于传统的主题模型。CTM将预先训练好的Sentence-Transformers嵌入表示与神经主题模型Neural-ProdLDA相结合，后者利用词袋（BoW）实现更连贯的表示。在给定知识库的情况下，以L个主题簇的数目训练主题模型。</p><p>​        一旦训练完成，话题模型将用于获得对话历史中pre-clustered topics的概率分布。这些概率被用作知识专家的相似性权重$w=(w_1，w_2，…，w_L)$，以计算其隐藏状态的加权和，如图2所示。</p><p>W在两个不同的设置，在这两种设置下训练的模型分别表示为$KE_w \ KE_o$。</p><ul><li>Weighted-sum setting，将每一个知识专家的输出权重加和，通过隐藏状态传递给下一个GPT-2层。</li><li>One-hot setting，只考虑知识专家输出的最大权重。</li></ul><h3 id="Learning-Procedure"><a href="#Learning-Procedure" class="headerlink" title="Learning Procedure"></a>Learning Procedure</h3><p>如图三所示，分为独立的三个步骤训练。</p><h4 id="Topic-Modeling-Training"><a href="#Topic-Modeling-Training" class="headerlink" title="Topic Modeling Training"></a>Topic Modeling Training</h4><ul><li>微调Sentence-Transformer</li><li>使用MSE loss评估两个句子嵌入之间的差异，为模型提供监督信号</li></ul><h4 id="Knowledge-Experts-Training"><a href="#Knowledge-Experts-Training" class="headerlink" title="Knowledge Experts Training"></a>Knowledge Experts Training</h4><p>用知识库训练一组插入到GPT-2(frozen backbone)中的L个主题特定的知识适配器，以生成知识句子。</p><ul><li>使用negative log-likelihood训练</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220321163940.png" alt="image-20220321163940338" style="zoom: 25%;" /></p><ul><li>将知识嵌入到经过训练的知识专家中，并从基于知识的对话任务中获益。在这种情况下，需要进行以对话为导向(dialogue-oriented)的训练。基于此，本文将知识句子的格式从纯文本转换为伪会话风格，以缩小知识专家培训和任务适应之间的差距。转换过程如图4所示。</li></ul><h4 id="Task-Adaptation"><a href="#Task-Adaptation" class="headerlink" title="Task Adaptation"></a>Task Adaptation</h4><ul><li>插入知识专家</li><li>微调GPT-2</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220321164844.png" alt="image-20220321164844563" style="zoom:25%;" /></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>knowledgegrounded dialogue datasets：</p><ul><li>Wizard of Wikipedia (WoW)</li><li>CMU Document Grounded Conversations (CMU DoG)</li></ul><p>数据集处理：</p><blockquote><p>我们随机选择20%的话语，并在每个对话中用最近的选择话语替换它们，以避免适配器过度匹配句子的顺序。</p><p>每个句子都要作为 system utterance 和 user utterance参与训练，确保所有句子都被训练为系统语料。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220321145752.png" alt="WX20220321-145729@2x"></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220321155013.png" alt="WX20220321-154924@2x"></p><p>生成响应的示例：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220321170301.png" alt="WX20220321-170205@2x"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>这是在开放域聊天场景下首次尝试在不使用检索的情况下解决基于知识的对话生成任务。</p><p>KnowExperty的推理过程效率更高的原因：不需要额外的知识句子作为输入的一个组成部分，从大规模语料库中检索额外的知识是一个耗时的过程。</p><p>本文的贡献有三个方面：</p><ul><li>率先探索了在开放领域聊天场景下，将先验知识注入到基于知识的对话生成任务的生成模型中；</li><li>本文模型进行知识概念化，没有显式的知识检索过程，无论知识库的大小，该过程都有恒定的推理时间；</li><li>模型的性能与一些强基线相当，并显示了纯生成方法在任务中的潜力。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Dialogue </tag>
            
            <tag> GPT-2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Get To The Point Summarization with Pointer-Generator Networks</title>
      <link href="/2022/03/14/Get%20To%20The%20Point%20Summarization%20with%20Pointer-Generator%20Networks/"/>
      <url>/2022/03/14/Get%20To%20The%20Point%20Summarization%20with%20Pointer-Generator%20Networks/</url>
      
        <content type="html"><![CDATA[<h1 id="Get-To-The-Point-Summarization-with-Pointer-Generator-Networks"><a href="#Get-To-The-Point-Summarization-with-Pointer-Generator-Networks" class="headerlink" title="Get To The Point: Summarization with Pointer-Generator Networks"></a>Get To The Point: Summarization with Pointer-Generator Networks</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/1704.04368">https://arxiv.org/abs/1704.04368</a></p><p> 代码：<a href="https://github.com/abisee/pointer-generator">https://github.com/abisee/pointer-generator</a></p></blockquote><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>摘要技术整体分为两种: </p><ol><li>抽取式extractive </li><li>生成式astractive 。    </li></ol><p>​        抽取式比较简单，目前的performance也一般比较高，因为它是直接从原文抽取一些段落。但是想要生成高质量的摘要，必须具备一些复杂的摘要能力(如释义(paraphasing), 概括(generalization), 与现实世界知识的融合(incorporation of real-world knowledge)，这些只有通过生成式模型才可能得以实现。<br>​        鉴于生成式摘要任务的困难性，早期的摘要技术一般都是抽取式的，然而随着seq2sq架构的出现(Sutskever et al., 2014)，使用这种架构来读取与自由地生成文本就变得可行了。虽然这种模型很有前景，但存在本文摘要中所说的那三种缺点。<br>​        虽然最近的生成式摘要方面的工作专注于标题生成任务(headline generation)（将一个或两个句子减少到单个标题），但此文作者认为较长文本的摘要更具挑战性（需要更高级别的抽象同时避免重复）并最终更有用。</p><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>在生成式摘要任务中，对于传统的seq2seq+attention的模型架构，作者提出它们有以下缺点:</p><ul><li>难以准确复述原文细节</li><li>无法处理原文中的未登录词(OOV)</li><li>在生成的摘要中存在一些重复的部分</li></ul><p>本文提出了一种新颖的架构来增强标准的seq2seq+attention模型，采用了两种正交(互相之间不存在交集)的新颖手段:</p><ul><li>使用指针生成器网络(<strong>pointer-generator network</strong>)，通过指针从原文中拷贝词，这种方式的高明之处在于正确复述原文信息的同时，也能使用生成器生成一些新的词。</li><li>使用覆盖率(coverage) 机制，追踪哪些信息已经在摘要中了，通过这种方式以期避免生成具有重复片段的摘要。</li></ul><p>不同模型的摘要生成效果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220311110522.png" alt="QQ20220311-110456@2x" style="zoom: 33%;" /></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><h3 id="seq2seq-attention-model"><a href="#seq2seq-attention-model" class="headerlink" title="seq2seq+attention model"></a>seq2seq+attention model</h3><p>本文的Baseline model</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220311110722.png" alt="image-20220311110722271"></p><ul><li>encoder部分，本文采用单个 <strong>双向LSTM</strong>(bidirectional LSTM) 单元构成的层，训练数据中的文档中的<strong>token(词语或一些切割后的符号)</strong> $w_i$ 作为encoder的输入，产生一个encoder的隐藏层状态 $h_i$ 的序列。</li><li><p>decoder部分，本文采用单个 <strong>单向LSTM</strong>(unidirectional LSTM) 单元构成的层，时刻 $t$ 时接收上一个词的嵌入(embedding) (训练阶段这是前一个参考摘要中的词，测试阶段这是前一个decoder产生的词)，生成解码状态  $s_t$。</p></li><li><p>注意力分布 $a^t$ 的计算：</p></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220312164830.png" alt="image-20220312164830443" style="zoom:33%;" /></p><blockquote><p> 其中 $v , W<em>h , W_s , b</em>{attn}$ 都是可学习参数。</p></blockquote><ul><li>注意力分布可以看作是建立在源文本(上图中的source text)中所有词上的一个概率分布，告诉decoder该看向哪里去生成下一个词。接下来，注意力分布用于产生encoder隐藏状态的加权和，即上下文向量(context vector)  $h_t^*$。</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220312165200.png" alt="image-20220312165200280" style="zoom:33%;" /></p><ul><li>依靠这个上下文向量  $h<em>t^*$ 和decoder的隐层向量 $s_t$  ，共同决定$t$时刻 预测在词表上的概率分布 $P</em>{vocab}$ 。</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220312165648.png" alt="image-20220312165648820" style="zoom:33%;" /></p><blockquote><p>其中  $V, V’, b, b’$ 都是可学习参数。</p></blockquote><ul><li>$P_{vocab}$ 是建立在整个词表上的概率分布，提供最终的预测词分布 $P(w)$ :</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220312165931.png" alt="image-20220312165931380" style="zoom:33%;" /></p><ul><li>训练阶段，时刻 $t$ 的损失函数是生成目标词$w_t^*$ 的负对数似然概率 $loss_t$ :</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220312170047.png" alt="image-20220312170047713" style="zoom:33%;" /></p><ul><li>那么对于一条序列来说，将每个词的损失计算平均即得到这条序列的损失 $loss$:</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220312170122.png" alt="image-20220312170122720" style="zoom:33%;" /></p><h3 id="pointer-generator-network"><a href="#pointer-generator-network" class="headerlink" title="pointer-generator network"></a>pointer-generator network</h3><p>指针生成器网络是一个上面的baseline模型和指针网络(<strong>pointer network</strong>)的混合模型，模型架构如图:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220312170914.png" alt="image-20220312170914267"></p><ul><li><p>其中注意力分布  $a^t$ 与上下文向量 $h_t^*$ 的计算公式与上文相同。(见公式(1), (2), (3))</p></li><li><p>在时刻 $t$ ，由上下文向量 $h<em>t^*$    ，decoder状态向量 $s_t$ ，decoder输入 $x_t$ 共同计算 生成概率 $p</em>{gen}$ 。</p></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220313103242.png" alt="image-20220313103242563" style="zoom:33%;" /></p><blockquote><p>其中 $w<em>{h^*}, w_s, w_x $ 与标量 $b</em>{ptr}$ 都是可学习参数,$\sigma$ 是sigmoid函数。</p></blockquote><ul><li><p>这个$p<em>{gen}$的计算相当关键，它被用作一个两种决策的软连接: 通过P</em>{vocab} 从词表中生成一个词, 还是从输入序列的注意力分布 a^t 中进行采样得到一个词。同时，对于每一篇文档，用扩展后的词表(extended vocabulary) 来表示整个词表和这篇文档中的词的并集(解决OOV问题)。</p></li><li><p>得到如下在扩展词表上建立的概率分布:</p></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220313103659.png" alt="image-20220313103659217" style="zoom: 33%;" /></p><blockquote><p>如果$w$是一个未登录词(OOV)，$P<em>{vocab}(w)$ 就为 0；如果$w$在这篇文档中出现，但未在词表中出现，那么 $\sum</em>{i:w_i=w}a_i^t$ 就将为 0。</p></blockquote><ul><li>能生成未登录词是pointer-generator网络的一个主要优势，损失函数的计算和上文公式中的(7), (8)相同，但注意对应的 P ( w ) P(w) P(w)计算过程要替换成公式(9)。</li></ul><h3 id="覆盖机制-coverage-mechanism"><a href="#覆盖机制-coverage-mechanism" class="headerlink" title="覆盖机制(coverage mechanism)"></a>覆盖机制(coverage mechanism)</h3><p>采用覆盖模型来解决生成摘要中出现重复片段的问题。</p><ul><li>在此覆盖率模型中，本文保留了一个 覆盖率向量(coverage vector) $c^t$  ，它是在之前所有decoder步骤上的注意力分布的求和:</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220313104934.png" alt="image-20220313104934530" style="zoom:33%;" /></p><ul><li>直观上看，$c^t$是源文档单词的 非标准化(unnormalized) 分布，表示到目前为止这些单词从注意力机制积累的覆盖程度。注意$c^0$是一个零向量，因为在第一步，对于源文档没有被覆盖的部分。覆盖率向量也被用来作为注意力机制的额外输入，将公式$(1)$变化为:</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220313105648.png" alt="image-20220313105648609" style="zoom:33%;" /></p><blockquote><p>其中 $w_c$ 是一个可学习的参数，具有和向量 $v$ 一样的长度。</p></blockquote><ul><li>这确保了注意力机制做当前的决策时（下一步选择关注哪个词）会考量其先前的决定。这种方案使得对于注意力机制来说避免重复关注同一块地方的问题，因此能避免生成重复摘要的问题。</li><li>此外，通过实验发现额外定义一个 覆盖率损失(coverage loss) 来惩罚将注意力重复放在同一区域的行为是非常必要的:</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220313105824.png" alt="image-20220313105824431" style="zoom: 33%;" /></p><blockquote><p>注意这个损失是 有界(bounded) 的:<img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220313105935.png" alt="image-20220313105935119" style="zoom: 25%;" /></p></blockquote><p><strong>最终的复合损失函数(composite loss function):</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220313110025.png" alt="image-20220313110025442" style="zoom:33%;" /></p><blockquote><p>其中 $\lambda$ 是一个超参数，权衡两种损失的代价。</p></blockquote><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>CNN/Daily Mail数据集</li></ul><blockquote><p>包括在线新闻文章(平均每篇文章781个token)及其对应的摘要(平均长度为3.75个句子，56个token)。<br>训练集：287,226条<br>验证集：13,368条<br>测试集：11,490条</p></blockquote><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220314142904.png" alt="QQ20220314-142832@2x"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>​        本文提出的指针生成器网络解决seq2seq模型生成句子中经常有重复片段现象，通过指针从源文本中复制单词以解决OOV问题，并且有能力生成新词。在长文本数据集上摘要生成能力表现不错。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 指针网 </tag>
            
            <tag> 摘要生成 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pointer Networks - 指针网</title>
      <link href="/2022/03/05/Pointer%20Networks%20%E6%8C%87%E9%92%88%E7%BD%91/"/>
      <url>/2022/03/05/Pointer%20Networks%20%E6%8C%87%E9%92%88%E7%BD%91/</url>
      
        <content type="html"><![CDATA[<h1 id="Pointer-Networks-指针网"><a href="#Pointer-Networks-指针网" class="headerlink" title="Pointer Networks - 指针网"></a>Pointer Networks - 指针网</h1><blockquote><p>参考资料：</p><ul><li><a href="https://blog.csdn.net/qq_38556984/article/details/107574587">https://blog.csdn.net/qq_38556984/article/details/107574587</a></li><li><a href="https://www.cnblogs.com/zingp/p/11571593.html">https://www.cnblogs.com/zingp/p/11571593.html</a></li></ul></blockquote><ul><li>指针生成网络属于生成式模型。</li></ul><h2 id="为什么会提出指针网"><a href="#为什么会提出指针网" class="headerlink" title="为什么会提出指针网"></a>为什么会提出指针网</h2><ul><li>Pointer network 主要用在解决组合优化类问题(TSP, Convex Hull等等)，实际上是Sequence to Sequence learning中encoder RNN和decoder RNN的扩展。</li><li>传统的seq2seq模型是无法解决输出序列的词汇表会随着输入序列长度的改变而改变的问题的，如寻找凸包等。因为对于这类问题，输出往往是输入集合的子集。</li></ul><p><strong><em>重点是seq2seq模型的输出序列长度不会变！</em></strong></p><p>因此，PN就被提出来了！</p><p>​        传统带有注意力机制的seq2seq模型输出的是针对<strong>输出</strong>词汇表的一个概率分布，而Pointer Networks输出的则是针对<strong>输入</strong>文本序列的概率分布。其实我们可以发现，因为输出元素来自输入元素的特点，Pointer Networks特别适合用来直接复制输入序列中的某些元素给输出序列。</p><p>​        比如在做生成的时候，正确的输出中，部分词不在词表中，如果只依靠基础模型的输出，得不到OOV(词汇不足)的词，这时候指针网就发挥作用了，直接将该词copy过来作为输出。当然直接拷贝会存在一些问题，因此加了选择策略，决定当前预测是直接从源文本中复制一个词过来还是从词汇表中生成一个词出来。</p><p>​        还看到一种生成拷贝策略：当某个词是输入序列独有的则该词的生成概率为0，复制概率不变；若某个词是输出词汇表独有的则该词的复制概率为0，而生成概率不变；若某个词既存在于输入序列又存在于输出词汇表则生成概率和复制概率都不变。最后，将生成概率和复制概率加和得到最终的概率。</p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><ul><li>seq2seq模型生成风格自由，但往往存在两大缺陷：1、模型容易不准确地再现事实细节，也就是说模型生成的摘要不准确；2、往往会重复，也就是会重复生成一些词或者句子。</li><li>指针网络相对可控，信息来源于输入的信息范围，是天生的复制粘贴利器。但是他也有个弊端，就是说无法生成输入范围以外的词汇，这样就有很大的限制。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Pointer Networks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TDEER An Efficient Translating Decoding Schema for Joint Extraction of Entities and Relations</title>
      <link href="/2022/03/05/TDEER%20An%20Efficient%20Translating%20Decoding%20Schema%20for%20Joint%20Extraction%20of%20Entities%20and%20Relations/"/>
      <url>/2022/03/05/TDEER%20An%20Efficient%20Translating%20Decoding%20Schema%20for%20Joint%20Extraction%20of%20Entities%20and%20Relations/</url>
      
        <content type="html"><![CDATA[<p>指针网</p><ul><li>Bowen Yu, Zhenyu Zhang, Xiaobo Shu, Tingwen Liu, Yubin Wang, Bin Wang, and Sujian Li. 2020. Joint extraction of entities and relations based on a novel decomposition strategy. In Proceedings of the 24th European Conference on Artificial Intelligence, pages 2282–2289.</li><li><a href="https://zhuanlan.zhihu.com/p/34499027">https://zhuanlan.zhihu.com/p/34499027</a></li><li>Zhepei Wei, Jianlin Su, Yue Wang, Yuan Tian, and Yi Chang. 2020. A novel cascade binary tagging framework for relational triple extraction. In Pro- ceedings of the 58th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 1476– 1488.</li></ul><h1 id="TDEER-An-Efficient-Translating-Decoding-Schema-for-Joint-Extraction-of-Entities-and-Relations"><a href="#TDEER-An-Efficient-Translating-Decoding-Schema-for-Joint-Extraction-of-Entities-and-Relations" class="headerlink" title="TDEER: An Efficient Translating Decoding Schema for Joint Extraction of Entities and Relations"></a>TDEER: An Efficient Translating Decoding Schema for Joint Extraction of Entities and Relations</h1><blockquote><p>论文：<a href="https://aclanthology.org/2021.emnlp-main.635/">https://aclanthology.org/2021.emnlp-main.635/</a></p><p>代码：<a href="https://github.com/4ai/tdeer">https://github.com/4ai/tdeer</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        在实体关系抽取中，通用的方法是通过预测实体对来获得相应的关系，进而得到关系三元组。然后如何有效地处理这一任务仍然具有挑战性，尤其是对于<strong>重叠三元组</strong>问题。因此，为了解决这个问题，作者提出了基于翻译解码机制的实体关系联合抽取模型（TDEER: Translating Decoding Schema for Joint Extraction of Entities and Relations）。</p><p>​        该模型代表翻译解码模式，用于实体和关系的联合抽取。与常用的翻译解码模式不同，本文提出的翻译解码模式将这种关系视为从主体实体到客体实体的翻译操作，即TDEER将三元组解码为<code>subject + relation → objects</code>。TDEER可以自然地处理重叠三元组问题，因为翻译解码模式可以识别所有可能的三元组，包括重叠和非重叠三元组。为了增强模型的鲁棒性，引入了负样本，以减少不同阶段的误差积累。</p><p>实体对的几种情况：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305153736.png" alt="image-20220305153735935" style="zoom: 50%;" /></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>本文提出了一个三阶段模型，<strong>TDEER</strong>。</p><ul><li>在第一阶段，TDEER使用基于跨度的<strong>实体标记模型</strong>来提取所有主体实体和客体实体。</li><li>在第二阶段，TDEER采用多标签分类策略来检测所有相关关系。在第三阶段，TDEER通过提出的翻译-解码模式，迭代主体实体和关系对，以识别各自的客体实体。</li></ul><p>TDEER主体结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305153945.png" alt="QQ20220305-153900@2x"></p><h3 id="Input-Layer"><a href="#Input-Layer" class="headerlink" title="Input Layer"></a>Input Layer</h3><p>在BERT模型的基础上，模型首先编码句子文本，在BERT模型的输出得到，CLS以及句子中每个词的对应的上下文向量表示。</p><script type="math/tex; mode=display">X=BERT(T)</script><h3 id="Entity-Tagging-Model"><a href="#Entity-Tagging-Model" class="headerlink" title="Entity Tagging Model"></a>Entity Tagging Model</h3><p>​        采用<strong>基于跨度的标记模型(span-based tagging model)</strong>去获得句子中的实体以及它们的位置。使用了两个二元分类器分别预测主体实体的起始位置和结束位置以及客体实体的起始位置和结束位置。使用的激活函数为sigmoid。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305154528.png" alt="image-20220305154528828" style="zoom: 25%;" /></p><p>通过最小化如下损失函数训练：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305155622.png" alt="image-20220305155621999" style="zoom:25%;" /></p><blockquote><p>其中：<img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305155728.png" alt="image-20220305155728368" style="zoom:25%;" /></p></blockquote><h3 id="Relation-Detector"><a href="#Relation-Detector" class="headerlink" title="Relation Detector"></a>Relation Detector</h3><p>​        在关系探测阶段，为了识别句子中的相关关系，在CLS向量表示的基础上采用了一种<strong>多标签分类策略</strong>来分类得到句子中的关系。使用的激活函数为sigmoid。</p><p>多标签分类：（关系）</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305160044.png" alt="image-20220305160044672" style="zoom:25%;" /></p><blockquote><p>$σ(·)$ denotes sigmoid function</p></blockquote><p>二元交叉熵损失函数：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305160209.png" alt="image-20220305160209126" style="zoom:25%;" /></p><blockquote><p> $y_i\in{0, 1}$ indicates the ground truth label of relations.</p></blockquote><h3 id="Translating-Decoding-Schema"><a href="#Translating-Decoding-Schema" class="headerlink" title="Translating Decoding Schema"></a>Translating Decoding Schema</h3><p>​        在基于翻译机制的解码模式阶段，本文提出的方法对探测到的主体实体集合和关系集合进行<strong>迭代配对</strong>，然后去预测客体实体的开始位置。对于每个主体实体和关系对，首先将主体实体和关系的表示结合起来。接下来，使用注意力机制来获得一个选择性的表示，这会给客体实体的可能位置分配更高的权重。最后，将选择性表示传递给一个全连接层来获得输出，即得到的客体实体的位置。</p><p>使用一个全连接层编码关系：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305162535.png" alt="image-20220305162535448" style="zoom:25%;" /></p><blockquote><p>这里主体实体和关系的匹配规则：第i个主体实体依次和所有关系组合。</p></blockquote><p>TDEER通过加法操作将主体实体的表示和关系表示连接起来:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305162658.png" alt="image-20220305162657988" style="zoom:25%;" /></p><p>注意力机制：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305161028.png" alt="image-20220305161028970" style="zoom:25%;" /></p><blockquote><p>$d_k$ is the dimension of the attention key</p></blockquote><p>TDEER采用二元分类器来识别给定当前主体实体和关系的客体实体的起始位置：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305162211.png" alt="image-20220305162211729" style="zoom:25%;" /></p><p>对应的损失函数：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305162302.png" alt="image-20220305162302028" style="zoom:25%;" /></p><p>如果没有起始位置匹配上，则当前主体实体和关系没有三元组。</p><h3 id="Negative-Sample-Strategy"><a href="#Negative-Sample-Strategy" class="headerlink" title="Negative Sample Strategy"></a>Negative Sample Strategy</h3><p>​        在TDEER中，翻译解码器依赖于实体标记和关系检测器，因此翻译检测器可能从上游组件接收错误实体或关系。因此，本文引入了一种负采样策略来检测和减轻来自上游组件的误差。</p><h3 id="Joint-Training"><a href="#Joint-Training" class="headerlink" title="Joint Training"></a>Joint Training</h3><p>联合训练了基于跨度的实体标记模型、关系检测器和翻译解码器。联合损失函数的定义如下：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305163010.png" alt="image-20220305163010784" style="zoom:25%;" /></p><blockquote><p>三个系数都为常量。</p></blockquote><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>NYT</li><li>WebNLG</li><li>NYT11</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305163052.png" alt="image-20220305163052836" style="zoom:50%;" /></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220305163131.png" alt="image-20220305163131520" style="zoom:50%;" /></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>主要贡献：</p><ol><li>本文提出了一种新的翻译-解码模式，用于从非结构化文本中联合提取实体和关系。</li><li>TDEER可以有效地处理棘手的重叠三元组问题。</li><li>TDEER的速度大约是当前SOTA型号的2倍。</li></ol><p>所提出的负样本策略用于缓解误差累积问题，虽然有效的，但它可能会增加训练时间。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> RE </tag>
            
            <tag> NYT </tag>
            
            <tag> WebNLG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NumNet Machine Reading Comprehension with Numerical Reasoning</title>
      <link href="/2022/02/11/NumNet%20Machine%20Reading%20Comprehension%20with%20Numerical%20Reasoning/"/>
      <url>/2022/02/11/NumNet%20Machine%20Reading%20Comprehension%20with%20Numerical%20Reasoning/</url>
      
        <content type="html"><![CDATA[<h1 id="NumNet-Machine-Reading-Comprehension-with-Numerical-Reasoning"><a href="#NumNet-Machine-Reading-Comprehension-with-Numerical-Reasoning" class="headerlink" title="NumNet Machine Reading Comprehension with Numerical Reasoning"></a>NumNet Machine Reading Comprehension with Numerical Reasoning</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/1910.06701">https://arxiv.org/abs/1910.06701</a></p><p> 代码：<a href="https://github.com/ranqiu92/NumNet">https://github.com/ranqiu92/NumNet</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        MRC不可避免的要涉及到数值推理的问题，机器不仅要能够比较数字相对的大小，还要能够知道和哪些数字做比较并进行推理，这就需要把数字相对的大小等等知识注入模型。但在之前大多数机器阅读理解模型中，基本上都将数字与非数字单词同等对待，无法获知数字的大小关系，也不能完成诸如计数、加减法等数学运算。正是基于这一原因，微信AI团队提出了一种数字感知的图神经网络（numerically-aware graph neural network，NumGNN），并基于此提出<strong>NumNet</strong>。</p><p>将数值推理集成到机器阅读理解模型中。两个关键因素：</p><ol><li>数值比较：问题的答案可以通过在文档中进行数值比较，如排序和比较，直接获得。例如，在表1中，对于第一个问题，如果MRC系统知道“49 &gt; 47 &gt; 36 &gt; 31 &gt; 22”的事实，它可以很容易地提取出第二长的场地目标是47码。</li><li>数值条件：问题的答案不能通过文献中简单的数值比较直接得到，往往需要数值比较才能理解文本。例如，对于表1中的第二个问题，MRC系统需要知道哪个年龄组占人口的7%以上才能计算组数。</li></ol><p>例子：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210170203.png" alt="image-20220210170203895"></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>模型结构：</p><p>分为<strong>编码模块</strong>、<strong>推理模块</strong>和<strong>预测模块</strong>。利用图的拓扑结构编码数字间的大小关系，将文章和问题中的数字作为图结点，在具有$&gt;$和$\leq$关系的数字间建立有向边，从而将数字的大小关系作为先验知识注入模型。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210165728.png" alt="image-20220210165728786"></p><blockquote><p> 在上图Reasoning Module中，数字是一个节点，数字之间的黑色实线代表大于关系，黑色虚线代表小于等于关系。</p></blockquote><p>​        具体来讲，给定一个问题和一段文本，先把问题里面的数字和文本里面的数字都抽出来。每个数字就是图上一个节点，同时对于任意两个数字，假如A数字和B数字，如果A大于B的话，那么A和B中间加一条有向边，表示数字A和B之间是A大于B的关系。如果A小于等于B，则会加另外一种有向边，把它们两个连接起来。通过这种操作，用图的拓谱结构把数字相对大小知识注入模型。另一方面，是结合文本信息去做更复杂的数学推理，具体的实现方式是使用图卷积神经网络在前述图结构上执行推理，从而获得更复杂的数学推理功能。</p><h3 id="Encoding-Module"><a href="#Encoding-Module" class="headerlink" title="Encoding Module"></a>Encoding Module</h3><p>和传统的编码层一样，使用了QANet和NAQANet，将问题和信息片段转换为向量空间表示，具体公式如下：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210171253.png" alt="image-20220210171253903" style="zoom:33%;" /></p><p>之后定义了启发式的运算，在这里指的是加入了注意力计算：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210171324.png" alt="image-20220210171324695" style="zoom:33%;" /></p><blockquote><p>Q：代表question</p><p>P：代表passage</p><p>QANet-Emb-Enc(·)代表QANet中的”stacked embedding encoder layer”， 由convolution,self-attention,feed-forward层组成。</p><p>QANet-Att(·)代表QANet中的”context-query attention layer”，是一个passage-question的注意力层。</p></blockquote><h3 id="Reasoning-Module"><a href="#Reasoning-Module" class="headerlink" title="Reasoning Module"></a>Reasoning Module</h3><p>在推理模块中，是基于GNN(图神经网络)对于有向图 [公式] 进行推理的，有以下公式：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210171545.png" alt="image-20220210171545439" style="zoom:33%;" /></p><blockquote><p>其中$W^M$是一个共享矩阵。</p><p>$U$是相应数字节点的表示。</p><p>QANet-Mod-Enc(·)是指在QANet中定义的”model encoder layer”。</p></blockquote><p>因为$U$只有包含数字的表示，为了获取span-style(指答案之间有非数字词语的存在)的答案，这里将$U$和$M^P$拼接起来来产生数字启发式的passage表示$M_0$：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210171820.png" alt="image-20220210171820192" style="zoom:33%;" /></p><blockquote><p>这里$[·；·]$代表矩阵拼接。</p><p>$W[k]$代表矩阵$W$的第k列，$I{(i)}$代表passage数字$w^p_i$的索引。</p><p>$W_0$是一个权重矩阵。</p><p>$b_0$ 是一个偏置向量。</p></blockquote><h3 id="Prediction-Module"><a href="#Prediction-Module" class="headerlink" title="Prediction Module"></a>Prediction Module</h3><p>预测模块遵循了NAQANet，将答案分为四种类型，使用了一种特殊的输出层来计算答案的条件概率$Pr(answer|type)$ :</p><ul><li><p>Passage span:答案出现在passage里，并且答案概率等于开始位置与结束位置的乘积。</p></li><li><p>Question span：答案出现在question里，并且答案概率等于开始位置与结束位置的乘积。</p></li><li><p>Count：答案可以通过计数来获取，并且当做是0-9十个数字的多分类问题（十分类），因为这样做的原因是由0-9可以得出计数的问题涵盖了DROP数据集Count 类型问题的绝大数。</p></li><li><p>Arithmetic expression：答案是算数问题表达式的结果，比如1+1=？。表达式通过3个步骤生成：</p><p>(1) 提取passage中所有的数字。</p><p>(2) 给每个数字赋予符号(+,- ,0),0在这里指的是不进行操作;。</p><p>(3) 对带符号数字进行求和，(2)中的符号为数字的系数。<br>同时，额外的输出层是用来计算答案类型$Pr(type)$的概率。在训练阶段，答案的概率是所有答案的联合概率$\sum_{type}Pr(type)·Pr(answer|type)$ 。在测试阶段，模型会优先选择答案类型概率最大然后再去预测相应的最佳答案。预测模块很大程度上继承了NAQANet，另外文中也提到了NumNet与NAQANet的最大区别是：<strong>多了推理模块</strong>。</p></li></ul><h3 id="数字启发的图构建"><a href="#数字启发的图构建" class="headerlink" title="数字启发的图构建"></a>数字启发的图构建</h3><p>question和passage中的数字作为节点，分别记为$V^Q$和$V^P$,所以所有节点集合$V=V^Q \or V^P$。</p><p>节点之间的边包括两种关系：</p><ul><li>Greater Relation Edge：大于</li><li>Lower or Equal Relation Edge：小于等于。</li></ul><p>实际上出现在两种边集合中的数字是等价的，但是为了避免潜在的歧义性，当每一个数字出现一次时添加一个不同的节点。</p><h3 id="数字推理"><a href="#数字推理" class="headerlink" title="数字推理"></a>数字推理</h3><h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><p>对于每一个节点$v_i^P \in V^P$,它的表示是矩阵$M^P$相对应的第$i$列，记为 $v_i^P=M^P[I^P(v_i^P)]$ ,其中$I^P(v_i^P)$代表了$v_i^P$的索引。同理，对于问题中的节点，对于$v_i^Q$是做同样的初始化。</p><h4 id="一步推理"><a href="#一步推理" class="headerlink" title="一步推理"></a>一步推理</h4><p>给定图$G$和节点表示$v$,文章使用GNN进行推理，步骤有三：</p><ul><li>节点关联度量<br>对于生成答案，通常只有很少的数字是相关的，所以通过sigmoid函数来计算数字权重，同时也可以过滤掉一些不相关数字，对于给定节点$v_i$,权重计算如下：</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210180401.png" alt="image-20220210180401920" style="zoom:33%;" /></p><ul><li>信息传递<br>信息传递函数如下：</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210180524.png" alt="image-20220210180524274" style="zoom:33%;" /></p><ul><li>节点表示更新</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210180633.png" alt="image-20220210180633836" style="zoom:33%;" /></p><p>完整的单步推理过程可定义成如下函数：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210180734.png" alt="image-20220210180734244" style="zoom:33%;" /></p><h4 id="多步推理"><a href="#多步推理" class="headerlink" title="多步推理"></a>多步推理</h4><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210180804.png" alt="image-20220210180804782" style="zoom:33%;" /></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>数据集：DROP<br>评价指标：EM和F1</p><blockquote><p>DROP数据集，由AI2（ Allen Institute for Artificial Intelligence）实验室提出，主要考察的是模型做类似数学运算相关的操作能力。</p><p>与 SQUAD数据集中大多都是“姚明的妻子是谁？”的题不同，其中的问题会涉及到数学算的情况。</p></blockquote><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210180947.png" alt="image-20220210180947027" style="zoom:33%;" /></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>​        在实践中，机器阅读理解（MRC）问题自然需要诸如加法、减法、分类和计数等数字推理技能。然而，这些技能在大多数现有的MRC模型中没有被明确考虑。在这项工作中，本文提出了一个名为NumNet的数字MRC模型，它在阅读段落的同时进行明确的数字推理。具体来说，NumNet将问题和段落中的数字关系编码为一个图作为其拓扑结构，并利用数字感知的图形神经网络对该图形进行数字推理。</p><p>case study</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210181650.png" alt="image-20220210181650121"></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> DROP </tag>
            
            <tag> NLP </tag>
            
            <tag> NumNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Giving BERT a Calculator Finding Operations and Arguments with Reading Comprehension.pdf</title>
      <link href="/2022/02/10/Giving%20BERT%20a%20Calculator%20Finding%20Operations%20and%20Arguments%20with%20Reading%20Comprehension.pdf/"/>
      <url>/2022/02/10/Giving%20BERT%20a%20Calculator%20Finding%20Operations%20and%20Arguments%20with%20Reading%20Comprehension.pdf/</url>
      
        <content type="html"><![CDATA[<h1 id="Giving-BERT-a-Calculator-Finding-Operations-and-Arguments-with-Reading-Comprehension-pdf"><a href="#Giving-BERT-a-Calculator-Finding-Operations-and-Arguments-with-Reading-Comprehension-pdf" class="headerlink" title="Giving BERT a Calculator Finding Operations and Arguments with Reading Comprehension.pdf"></a>Giving BERT a Calculator Finding Operations and Arguments with Reading Comprehension.pdf</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/1909.00109">https://arxiv.org/abs/1909.00109</a></p><p> <strong>IJCNLP 2019</strong></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        阅读理解模型已经成功地应用于抽取式文本答案，但目前还不清楚如何最好地将这些模型推广到抽象的数字答案。本文提出一个基于BERT的阅读理解模型，能够进行轻量级的数字推理。用一组预定义的可执行 “程序 “来增强该模型，这些程序包括简单的算术和提取。该模型不需要直接学习操作数字，而是可以选择一个程序并执行它。在最近为挑战阅读理解模型而设计的Discrete Reasoning Over Passages（DROP）数据集上，实验显示通过增加shallow programs，性能提升33%，该模型在训练的例子很少的情况下，在数学单词问题的设置中，学习在适当的时候预测新的运算。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210135534.png" alt="image-20220210135534145" style="zoom:33%;" /></p><p>从上面的例子可以看出，正确答案需要通过数值计算得到。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>​        在这项工作中，扩展了一个具有数字推理能力的抽取式MRC系统，该模型在$Operation(args, …)$形式的简单程序中进行挑选，其中可能的操作包括<strong>跨度提取、回答是或不是以及算术运算</strong>。对于数学运算，参数是指向文本中的数字的指针。通过这种方式，实际进行计算的负担从神经网络转移到计算器工具上。该程序还提供了浅层次的可解释性，反映了答案所需的一些推理。例如，在上表中，该模型预测了段落中两个数字的减法（<strong>Diff</strong>），并执行它以产生最终的答案。</p><p>​        模型通过选择得分最高的推导（programe）并执行它来预测答案。</p><p><strong>Derivations</strong>： We define the space of possible derivations D as follows：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210143809.png" alt="image-20220210143809710"></p><h4 id="Literals"><a href="#Literals" class="headerlink" title="Literals"></a>Literals</h4><p>当作多分类问题处理：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210145442.png" alt="image-20220210145442915" style="zoom:33%;" /></p><h4 id="Numeric-operations"><a href="#Numeric-operations" class="headerlink" title="Numeric operations"></a>Numeric operations</h4><p>二元运算：</p><p><img src="/Users/maqi/Library/Application Support/typora-user-images/image-20220210145609105.png" alt="image-20220210145609105" style="zoom:33%;" /></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210150020.png" alt="image-20220210150020113" style="zoom:33%;" /></p><blockquote><p>$h_i$：每个numeric argument第一个token的向量表示。</p><p>$h_d$：二元运算参数。</p><p>op：运算类型。</p></blockquote><p>一元运算：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210150318.png" alt="image-20220210150317974" style="zoom:33%;" /></p><h4 id="Text-spans"><a href="#Text-spans" class="headerlink" title="Text spans"></a>Text spans</h4><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210150438.png" alt="image-20220210150438838" style="zoom:33%;" /></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210150455.png" alt="image-20220210150455126" style="zoom:33%;" /></p><blockquote><p>$i,j$：表示span开始和结束位置。</p></blockquote><h4 id="Compositions-of-compositions"><a href="#Compositions-of-compositions" class="headerlink" title="Compositions of compositions"></a>Compositions of compositions</h4><p>对于组合类型，为其子集打分。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p><strong>DROP</strong>：(Discrete Reasoning over Paragraphs)，是一项需要离散推理的阅读理解任务。</p><p>类型分布：</p><ul><li>Date (1.6%)</li><li>Number (62%) </li><li>Span (32%) </li><li>Spans (4.4%)</li></ul><p><strong>Illinois math word problems dataset</strong></p><p>其中包含需要乘法和除法<em>(DROP中没有的运算)</em>以及加法和减法的答案，比例大致相同。</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210151750.png" alt="image-20220210151750820"></p><p>在Illinois math word problems数据集上，处理乘除法问题。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210153618.png" alt="image-20220210153618603" style="zoom: 33%;" /></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>基于BERT的抽取式模型：</p><ol><li>预测带参数的一元和二元数学运算，在DROP数据集上有了明显的改善。</li><li>该模型可以顺利地处理更传统的阅读理解输入，以及具有新操作的数学问题。与<em>CoQA</em>数据集的协同训练提高了DROP的性能。DROP+CoQA训练的模型从未见过乘法或除法的例子，但在数学单词问题的设置中，可以学习在适当的时候预测这两种操作（Roy和Roth，2015），但训练的例子非常少。</li></ol><p>​        该模型能够在一个统一的模型中处理传统的事实性问题和需要符号推理的问题。可以在DROP数据集上，解答阅读理解和数字推理的混合问题，还可以在CoQA上做标准的阅读理解，并在数学单词问题上做重点数字推理。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> DROP </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Question Directed Graph Attention Network for Numerical Reasoning over Text</title>
      <link href="/2022/02/09/Question%20Directed%20Graph%20Attention%20Network%20for%20Numerical%20Reasoning%20over%20Text/"/>
      <url>/2022/02/09/Question%20Directed%20Graph%20Attention%20Network%20for%20Numerical%20Reasoning%20over%20Text/</url>
      
        <content type="html"><![CDATA[<h1 id="Question-Directed-Graph-Attention-Network-for-Numerical-Reasoning-over-Text"><a href="#Question-Directed-Graph-Attention-Network-for-Numerical-Reasoning-over-Text" class="headerlink" title="Question Directed Graph Attention Network for Numerical Reasoning over Text"></a>Question Directed Graph Attention Network for Numerical Reasoning over Text</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/2009.07448">https://arxiv.org/abs/2009.07448</a></p><p> EMNLP2020</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>对文本进行数字推理，如加法、减法、排序和计数，是一项具有挑战性的机器阅读理解任务，因为它需要自然语言理解和算术计算。为了应对这一挑战，本文提出了一种异构图表示，用于这种推理所需的文章和问题的上下文，并设计了一个问题导向图注意网络来驱动该上下文图上的多步数值推理。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>本文认为QANET和NumNet对于复杂的数值推理是不够的，因为它们缺少数值推理的两个关键要素:</p><ul><li>Number Type and Entity Mention：NumNet中的数字比较图无法识别不同的数字类型，缺少文档中提到的连接数字节点的实体信息。</li><li>Direct Interaction with Question：NumNet中的图推理模块忽略了直接的问题表示形式，这在定位问题所指向的重要数字作为数字推理的枢纽时可能会遇到困难。</li></ul><p>数字和实体之间的关联是学习数字推理模型的一个强有力的正则化：数字之间的比较和加/减法通常适用于那些具有相同类型或指代相同实体的数字。举两个例子：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220209125818.png" alt="image-20220209125818672"></p><p>​        其中有不同类型的实体和数字。两者都用不同的颜色强调:<code>实体（黄色）、数字（红色）、百分比（蓝色）、日期（深蓝）、序数（蓝绿）</code>。本文明确地将类型信息编码到模型中，并利用问题表示来进行推理过程。可以看到，第一段由5个”people counting“类型的数字，当给定数字类型时，如果模型学习提取以这个“population”问题为条件的“people counting”，推理难度将大大降低。<br>​        此外，图表中的实体提供了关于文章和问题之间相关性的明确信息。问题中的实体可能出现在文章中的几个句子中，表明每个数字如何通过这些桥接实体彼此关联，这有助于QA模型更好地收集和汇总信息以进行数字推理。 此外还可以观察到，当问题实体同时出现在一个句子中（第一段的最后一个句子）时，这可能暗示答案可以从该句子中得出。 第二个示例说明了跨度提取中的情况。 同样，当数字和“ Stephen Gostkowski”之间的相关关系明确时，该模型也会受益。</p><p>​        为了明确地将类型和实体信息集成到模型中，本文构建了一个异构有向图（下图，对应上表），其中节点由实体和不同类型的数字组成，而边可以编码不同类型的关系。图的节点由问题和文章中的实体和数字组成。同一类型的数字彼此紧密相连。一个句子中共同出现的数字和实体也是相互联系的。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210010018.png" alt="image-20220210010018594"></p><p>​        红色节点是数字，深蓝色节点是日期，其他节点是实体。边编码数字和实体之间的关系：具有相同数字类型(例如日期)的数字被连接在一起。该图将数字和同一个句子中的实体连接起来，以表示它们的同现。</p><p>​        在step-1中，模型关注包含Spanish 和 Portuguese实体的子图，因为它们在问题中被提及。在更新中，模型学习区分数字和日期，并提取与问题相关的数字。在step-2中，数字的表示由来自实体的消息以及进行推理的问题来更新。</p><p>​        基于这种异构图，本文<strong>提出了一种问题导向图注意网络(QDGA T)</strong>，用于数值型MRC任务。由于与答案相关的数字可以由问题来引导，QDGAT在图推理过程中结合了问题的上下文编码。更具体地说，QDGAT使用上下文编码器，例如BERT和RoBERTa ，来提取问题和段落中的数字和实体的表示，作为图中每个节点的初始嵌入。通过异构图，QDGAT学会从以问题为条件的图中收集信息，用于数值推理。每个节点也由基于问题的上下文感知表示来描述，并且节点的表示通过消息传递迭代来更新。在用图神经网络进行多次消息传递迭代后，QDGAT逐渐聚合节点信息来回答问题。从这个意义上说，QDGAT以一种更符合人类感知和推理的方式抽象了段落和问题的表示，使模型产生了一种更可解释的推理模式。</p><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h4 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h4><p>在MRC任务中，每个数据样本由一个段落 $P$ 和一个相关的问题 $Q$ 组成。MRC模型的目标是根据 $P$ 回答问题 $Q$ ，给出答案 $A$ 。除了像标准MRC任务一样预测文本跨度之外，在数字推理的情况下，答案 $A$ 也可以是从算术计算(如排序、计数、加法和减法)中导出的数字。</p><h4 id="Overall-Framework"><a href="#Overall-Framework" class="headerlink" title="Overall Framework"></a>Overall Framework</h4><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210010810.png" alt="image-20220210010810801"></p><p>​        该模型由三个主要组件组成，representation extractor module, reasoning module, prediction module。representation extractor 负责语义理解。在extractor上，构造了一个具有类型化数字和相关实体的异构图。</p><h4 id="Word-Representation-Extractor"><a href="#Word-Representation-Extractor" class="headerlink" title="Word Representation Extractor"></a>Word Representation Extractor</h4><p>RoBERTa处理passage和question，输入形式<code>[CLS] Q [SEP] P [SEP]</code>串联：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210010942.png" alt="image-20220210010942220" style="zoom:33%;" /></p><h4 id="Graph-Construction"><a href="#Graph-Construction" class="headerlink" title="Graph Construction"></a>Graph Construction</h4><p>​        该模块从文本数据构建异构类型的图形。图 $G=(V,E)$包含数字 $N$和实体 $T$，两者都由外部<strong>命名实体识别系统（CoreNLP）</strong>识别，节点 $V  = {undefined N ,T}$，其边 $E$ 编码数字类型的信息和数字与实体的关系。</p><p>​        具体来说，NER将文本中的每个token标记为21个预定义类别之一。标记为NUMBER, PERCENT, MONEY, TIME, DATE, DURATION, ORDINAL 的被视为数字。此外，本文增加了一个额外的标记YARD并且利用了一个数字提取器去提取剩余的数字，它们也被标记为NUMBER。</p><blockquote><p>数字提取器word2num：<a href="https://pypi.org/project/word2number/">https://pypi.org/project/word2number/</a></p></blockquote><p>​        所有这些标记用8种数字类型 $V_N=(NUMBER,PERCENT,MONEY,TIME,DATE, DURATION,ORDINAL,YARD)$构成数字集 $N$。至于其他已识别的标记，将它们映射到标签ENTIT_Y中，以构建类型集为 $V_T  = {undefined  \ ENTIT_Y }$的实体集 $T$，来表示节点的类型。类型信息可以直接通知模型找到与问题相关的数字，从而降低推理难度。边$E$编码数字和实体之间的关系，对应两种情况。</p><ol><li>The edge between the numbers</li><li>The edge between the entity and the number</li></ol><p>​        第一种情况的边将相同类型的数字聚集在一起，这提供了一个明显的线索来帮助对这些数字进行推理。在第二种边大致表示数字和实体之间的相关性。总的来说，该图有9个关系$R$，即8个数字类型关系和1个ENT+DIGIT关系。</p><h4 id="Numerical-Reasoning-Module"><a href="#Numerical-Reasoning-Module" class="headerlink" title="Numerical Reasoning Module"></a>Numerical Reasoning Module</h4><p>数字推理模块，即<strong>QDGAT</strong>，建立在表示和图提取器的基础上。基于图 $G=(V,E)$，QDGAT网络可以表示为:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210012059.png" alt="image-20220210012059801" style="zoom:33%;" /></p><blockquote><p>$W^M$是投影矩阵</p><p>$MEAN$表示为mean pooling<br>$W^c$投影问题表示的平均向量以导出$c$</p><p>$c$是用于指导QDGAT中推理的问题语言嵌入</p><p>QDGAT然后对表示$M^P \ M^Q$和以问题导向$c$为条件的图$G$进行推理</p></blockquote><h4 id="Prediction-Module"><a href="#Prediction-Module" class="headerlink" title="Prediction Module"></a>Prediction Module</h4><p>预测模块将图推理网络$U$的输出作为最终预测。目前NAQANet和NumNet+中的答案类型一般分为三类:</p><ol><li>跨度提取</li><li>计数</li><li>算术表达式</li></ol><p>本文为这些答案类型实现了单独的模块，它们都以图网络$U$和问题嵌入$c$的输出作为输入。具体如下:</p><ul><li>跨度提取:有三个跨度提取任务，即单篇文章跨度、多篇文章跨度、单问题跨度。单个跨度提取的概率是由问题或段落中开始和结束位置的<strong>概率的乘积</strong>导出的。</li><li>计数:这个问题被认为是一个<strong>10类</strong>分类问题(0-9)，它涵盖了DROP数据集中大约97%的计数问题。</li><li>算术表达式:答案由一个算数表达式给出，<strong>在DROP数据集中，只涉及加法和减法运算</strong>。本文通过将每个数字分类为(1，0，+1)中的一个来实现这一点，然后将其用作数值表达式中数字的<strong>系数</strong>，以得出最终答案。</li></ul><p>本文使用一个独特的分类网络将数据样本分类为五种细粒度类型$T$之一。每个类型求解器使用一个唯一的输出层来计算条件答案概率 $p(A|T)$。</p><h4 id="Question-Directed-Graph-Attention-Network"><a href="#Question-Directed-Graph-Attention-Network" class="headerlink" title="Question Directed Graph Attention Network"></a>Question Directed Graph Attention Network</h4><p>​        基于异构图$G$，QDGAT对问题进行上下文感知的数值推理，通过在数字和实体之间传递消息的多次迭代来收集关系信息。它通过图中的边动态地确定与哪些对象交互，并通过图发送消息来传播关系信息。为了实现这一点，用上下文化的问题表示来扩充推理模块。例如，在表1的例子中，任务是找出有多少西班牙人和葡萄牙人受伤或死亡。实体和数字被显式标记，并在异构图中建模，如图1所示。QDGAT能够提取相关的实体，即西班牙语和葡萄牙语，条件是 $c$。在与这两个实体相关的数字中，其中一些是日期类型的，而其他的是关于人的。但是，应该只关注问题所要求的与人有关的数字。然后，模型对这些数字进行推理，得出答案计算的表达式。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>DROP：DROP是通过在维基百科的段落上众包问答对来构建的，在最初的train/dev/test部分包含/ 9536 / 9622个样本。使用精确匹配(EM)和F1分数作为评估指标。</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210015145.png" style="zoom: 33%;" /></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>QDGAT在与数字和日期相关的问题上工作得更好，与span提取相比，这需要更具体的数字推理。</p><p>在这项工作中，本文提出了一种名为QDGAT的新型方法，用于机器阅读理解任务中的数字推理。我们的方法不仅建立了一个包含不同类型的数字、实体和关系的更紧凑的图，可以作为其他复杂推理任务的通用方法，而且还将推理的条件直接放在问题语言嵌入上，通过图和被迭代传递的改变信息来调节注意力，实现推理。</p><p><strong>case study</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220210015251.png" alt="image-20220210015251686"></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> DROP </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Multi-Type Multi-Span Network for Reading Comprehension that Requires Discrete Reasoning</title>
      <link href="/2022/01/26/A%20Multi-Type%20Multi-Span%20Network%20for%20Reading%20Comprehension%20that%20Requires%20Discrete%20Reasoning%20/"/>
      <url>/2022/01/26/A%20Multi-Type%20Multi-Span%20Network%20for%20Reading%20Comprehension%20that%20Requires%20Discrete%20Reasoning%20/</url>
      
        <content type="html"><![CDATA[<h1 id="A-Multi-Type-Multi-Span-Network-forReading-Comprehension-that-Requires-Discrete-Reasoning"><a href="#A-Multi-Type-Multi-Span-Network-forReading-Comprehension-that-Requires-Discrete-Reasoning" class="headerlink" title="A Multi-Type Multi-Span Network forReading Comprehension that Requires Discrete Reasoning"></a>A Multi-Type Multi-Span Network forReading Comprehension that Requires Discrete Reasoning</h1><blockquote><p> 论文：<a href="https://arxiv.org/abs/1908.05514">https://arxiv.org/abs/1908.05514</a></p><p> 代码：<a href="https://github.com/huminghao16/MTMSN">https://github.com/huminghao16/MTMSN</a></p><p> 复现：<a href="https://github.com/Asimok/DROP">https://github.com/Asimok/DROP</a></p><p> 由于学校VPN暂时禁用，无法继续做实验，复现的实验只做了2/3</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        在QA场景中，当答案涉及各种类型，或离散（多个span为正确答案）时，模型需要更高的推理能力，本文提出了多类型多跨度网络（MTMSN），包含多种答案类型（如跨度、计数、否定和算术表达）的多类型答案预测器，与一个动态产生一个或多个span的多跨度提取模块。</p><p>​        此外，还提出了一种算术表达式重排机制，对表达式候选者进行排序，以进一步确认预测结果。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220126104449.png" alt="image-20220126104449279"></p><p>使用BERT做解码器，使用Transformer Block将word embedding映射到contextual enmbedding。</p><p>预测4种答案类型：</p><blockquote><p>(1) span from the text; (2) arithmetic expression; (3) count number; (4) negation on numbers</p></blockquote><p>模型首先根据passage-question pair预测答案类型，在根据不同答案类型做对应的答案预测。</p><blockquote><p>对于multispan extraction模型可以预测出答案span的数量。</p><p>对于算数类问题，不直接使用最大概率的算数表达式，而是通过beam search对候选表达式重排序后确认预测答案。</p></blockquote><p>模型在弱监督信号下训练，使所有可能的注释的边际似然函数概率最大化。</p><p>输入序列：[CLS] token, the tokenized question, a [SEP] token, the tokenized passage, and a final [SEP] token.</p><p>embeddings：</p><script type="math/tex; mode=display">H_i= TransformerBlock(H_i−1)</script><h3 id="Multi-Type-Answer-Predictor"><a href="#Multi-Type-Answer-Predictor" class="headerlink" title="Multi-Type Answer Predictor"></a>Multi-Type Answer Predictor</h3><blockquote><p>直接从输入序列(question + passage)中提取答案片段。</p></blockquote><p>与QANet model类似，使用最后4个block作为上下文表示，M0, M1, M2, M3。</p><h4 id="Answer-type-prediction"><a href="#Answer-type-prediction" class="headerlink" title="Answer type prediction"></a>Answer type prediction</h4><p>分割$M_2$，作为$Q_2$和$P_2$的上下文表示：</p><script type="math/tex; mode=display">α^Q= softmax(W^QQ_2) \\ h^Q_2= α^QQ_2</script><blockquote><p>$P_2$的表示方法类似。</p></blockquote><script type="math/tex; mode=display">p^{type}= softmax(FFN([h^Q_2; h^P_2; h^{CLS}]))</script><blockquote><p>$h^{CLS}$是最后一层的第一个向量。</p><p>FFN：feed-forward network，激活函数：GeLU</p></blockquote><p>GeLU activation：</p><script type="math/tex; mode=display">GELU(x)=xΦ(x)</script><blockquote><p>其中$Φ(x) $是标准正态分布</p><p>这么选择是因为神经元的输入趋向于正态分布，使得当输入x减小的时候，输入会有一个更高的概率被dropout掉，这样的激活变换就会随机依赖于输入了。</p></blockquote><h4 id="Span"><a href="#Span" class="headerlink" title="Span"></a>Span</h4><p>为了在不同layer的问题表述中总结问题信息，使用3个向量，$g^{Q_0}, g^{Q_1}, g^{Q_2}$，计算过程如下：</p><script type="math/tex; mode=display">β^Q= softmax(FFN(Q_2) \\g^Q_2= β^QQ_2</script><blockquote><p>$g^{Q_0}, g^{Q_1}$计算过程类似。</p><p>计算token作为开始和结束位置的概率。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220126131243.png" alt="image-20220126131243755" style="zoom: 33%;" /></p><h4 id="Arithmetic-expression"><a href="#Arithmetic-expression" class="headerlink" title="Arithmetic expression"></a>Arithmetic expression</h4><p>处理 (plus, minus, or zero)三种运算。</p><p>拼接$M_2,M_3$得到文章中出现数字的上下文表示：</p><script type="math/tex; mode=display">U = (u_1, ..., u_N)</script><blockquote><p>文章中出现N个数字。</p></blockquote><p>计算每个位置的sign（plus, minus or zero）:</p><script type="math/tex; mode=display">p^{sign}_i = softmax(FFN([u_i; h^{Q_2}; h^{P_2}; h^{CLS}]))</script><blockquote><p>实质上仍然是一个分类问题，sign=0猜测，该位置的数字对表达式不起作用。</p></blockquote><h4 id="Count"><a href="#Count" class="headerlink" title="Count"></a>Count</h4><p>仍然是一个多分类问题，$h_U$为文章中出现的所有数字的summarizes。-</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220127103025.png" alt="image-20220127103025838" style="zoom:33%;" /></p><h4 id="Negation"><a href="#Negation" class="headerlink" title="Negation"></a>Negation</h4><p>第i个数字是否作为否定句处理：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220128104735.png" alt="image-20220128104735702" style="zoom:33%;" /></p><h3 id="Multi-Span-Extraction"><a href="#Multi-Span-Extraction" class="headerlink" title="Multi-Span Extraction"></a>Multi-Span Extraction</h3><p>处理multi-span情况时，转换为预测span的数量，可以看做一个多分类问题。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220128105111.png" alt="image-20220128105111878" style="zoom:33%;" /></p><p>为得到无重叠的span，使用non-maximum suppression (NMS) 算法,重叠率计算使用 text-level F1 function.</p><p>具体来说，通过计算$p^{start}_k,p^{end}l$得到$span (k, l)$，按概率降序排序后，按概率从原始集合中迁移到新的集合，重复操作至原始集合为空，或者新集合已达到超参数限制的span最大数量，在此过程中，要将重叠的span去除。</p><h3 id="Arithmetic-Expression-Reranking"><a href="#Arithmetic-Expression-Reranking" class="headerlink" title="Arithmetic Expression Reranking"></a>Arithmetic Expression Reranking</h3><p>由于表达式本身是数字的粗粒度语义信息，并没有结合上下文信息，因此会导致错误的表达式，具有最大概率的sign是负数或零，导致大的负值。</p><p>为解决这个问题使用beam search来产生排名靠前的算术表达式进行重排序。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220128112256.png" alt="image-20220128112255991" style="zoom:33%;" /></p><blockquote><p>number vectors $V_i$</p><p>sign embeddings $C_i$</p></blockquote><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>Drop数据集QA根据答案类型分类：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220128113154.png" alt="image-20220128113154491" style="zoom:50%;" /></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>实验结果：<img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220128112912.png" alt="image-20220128112912361"></p><p>消融实验：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220128112951.png" alt="image-20220128112951079"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>MTMSN，是一个用于阅读理解的多类型多跨度网络，需要对段落内容进行离散推理。<br>使用多类型的答案预测器以处理否定句类型的问题，提出了一个多跨度的提取方法以产生多个答案，并设计了一个算术表达式重排机制以进一步确认预测结果。</p><p>该模型主要实现了复杂的数字推理。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> DROP </tag>
            
            <tag> MTMSN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>不连续MRC实验</title>
      <link href="/2022/01/10/%E4%B8%8D%E8%BF%9E%E7%BB%ADMRC%E5%AE%9E%E9%AA%8C/"/>
      <url>/2022/01/10/%E4%B8%8D%E8%BF%9E%E7%BB%ADMRC%E5%AE%9E%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="不连续MRC实验"><a href="#不连续MRC实验" class="headerlink" title="不连续MRC实验"></a>不连续MRC实验</h1><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda create -n drop python=3.7</span><br><span class="line">pip3 install torch torchvision torchaudio</span><br><span class="line">pip3 install transformers</span><br></pre></td></tr></table></figure><h2 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h2><blockquote><p>数据集：DROP <a href="https://huggingface.co/datasets/drop">https://huggingface.co/datasets/drop</a></p><p>数据预处理：参考NAQAnet，将文档中的word num转为int num，转换目前只支持整数。</p><p>NAQAnet 中对数字的处理可以借鉴。</p><p>TDEER中 对span的提取思路可以借鉴，特别是 In the second stage 对 start 和 end 的分类预测。</p></blockquote><h2 id="代码结构"><a href="#代码结构" class="headerlink" title="代码结构"></a>代码结构</h2><h3 id="tool"><a href="#tool" class="headerlink" title="tool"></a>tool</h3><h4 id="log"><a href="#log" class="headerlink" title="log"></a>log</h4><blockquote><p>加入 emit，print不会受到 tqdm 进度表的影响。</p><p>使用偏函数也可以重写logger，但是定制化程度不高，这里使用自定义的get_logger类，今后在其他项目中也可以直接使用。</p></blockquote><h3 id="dataset-readers"><a href="#dataset-readers" class="headerlink" title="dataset_readers"></a>dataset_readers</h3><p>踩坑记录：</p><ol><li>tokenizer</li></ol><blockquote><p>使用 Transformers 的 tokenizer分词并做embedding，当padding=’max_length’时，padding才会补充到指定长度。</p><p>在使用tokenizer的时候也可以指定参数，return_tensors=’pt’,这样就不用手动将list转tensor了。</p><p>tokenizer(sent, max_length=max_length, padding=’max_length’, truncation=True)</p></blockquote><ol><li>tensor</li></ol><blockquote><p>torch.stack() 每次都在<strong>新的</strong>指定的维度上进行拼接，迭代使用的时候需要注意。</p><p>torch.cat() 在已有的维度上连接，需要注意的是，连接后不会扩充维度，需要手动的reshape。</p></blockquote><ol><li>TensorDataset</li></ol><blockquote><p>TensorDataset 可以将tensor序列化保存，避免多次重复预处理，同样使用torch.save()保存，当然，list，dict，都可以使用torch.save()保存，方便下次在该节点继续操作。</p><p>torch.save({“dataset”: TensorDataset, “examples”: _examples}, temp_file_path)</p></blockquote><ol><li>位置匹配</li></ol><blockquote><p>最开始使用spacy，简单的使用空格分词，并查找答案 span 的位置，但在后面使用transformers的tokenizer做embedding的时候意识到，拆词方式不同，预处理阶段生成的answer span也会有偏差，所以一致使用tokenizer分词。</p><p>除了eval_examples中的span是以char为单位，其余span都是以word为单位。</p></blockquote><p><strong>数据集封装格式：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">_dataset = TensorDataset(</span><br><span class="line">    torch.tensor(passage_text_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(passage_text_attention_mask, dtype=torch.long),</span><br><span class="line">    torch.tensor(question_text_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(question_text_attention_mask, dtype=torch.long),</span><br><span class="line">    torch.tensor(start_indices_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(start_indices_attention_mask, dtype=torch.long),</span><br><span class="line">    torch.tensor(end_indices_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(end_indices_attention_mask, dtype=torch.long),</span><br><span class="line">    torch.tensor(counts_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(count_attention_mask, dtype=torch.long),</span><br><span class="line">    torch.tensor(id_input_ids, dtype=torch.long),</span><br><span class="line">    torch.tensor(id_attention_mask, dtype=torch.long)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>修改后的Dataloader:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input_ids, input_mask, segment_ids, number_indices, start_indices, end_indices, number_of_answers, input_counts, add_sub_expressions, negations</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">feature = &#123;</span><br><span class="line">    &quot;unique_id&quot;: example[&#x27;question_id&#x27;],</span><br><span class="line">    &quot;example_index&quot;: example_index,</span><br><span class="line">    &quot;tokens&quot;: input_tokens,</span><br><span class="line">    &quot;input_ids&quot;: input_ids,</span><br><span class="line">    &quot;input_mask&quot;: input_mask,</span><br><span class="line">    &quot;segment_ids&quot;: segment_ids,</span><br><span class="line">    &quot;number_indices&quot;: number_index,</span><br><span class="line">    &quot;start_indices&quot;: start_indices,</span><br><span class="line">    &quot;end_indices&quot;: end_indices,</span><br><span class="line">    &quot;number_of_answers&quot;: number_of_answers,</span><br><span class="line">    &quot;add_sub_expressions&quot;: add_sub_expressions,</span><br><span class="line">    &quot;input_counts&quot;: input_counts,</span><br><span class="line">    &quot;negations&quot;: negations&#125;</span><br></pre></td></tr></table></figure><p>查阅DROP相关论文 确定对不同anser_type的处理方式</p><p><a href="https://paperswithcode.com/sota/question-answering-on-drop-test">https://paperswithcode.com/sota/question-answering-on-drop-test</a></p><p><a href="https://paperswithcode.com/dataset/drop">https://paperswithcode.com/dataset/drop</a></p><h2 id="排行榜"><a href="#排行榜" class="headerlink" title="排行榜"></a>排行榜</h2><p>DROP数据集性能排行榜：<a href="https://paperswithcode.com/sota/question-answering-on-drop-test">https://paperswithcode.com/sota/question-answering-on-drop-test</a></p><p>paperswithcode与DROP相关论文：<a href="https://paperswithcode.com/dataset/drop">https://paperswithcode.com/dataset/drop</a></p><h2 id="新工具"><a href="#新工具" class="headerlink" title="新工具"></a>新工具</h2><p>Adapter Transformers</p><p>介绍：<a href="https://zhuanlan.zhihu.com/p/373424011">https://zhuanlan.zhihu.com/p/373424011</a></p><p>源码：<a href="https://github.com/Adapter-Hub/adapter-transformers">https://github.com/Adapter-Hub/adapter-transformers</a></p><p>预训练模型：<a href="https://huggingface.co/AdapterHub/bert-base-uncased-pf-drop">https://huggingface.co/AdapterHub/bert-base-uncased-pf-drop</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><strong>TASE</strong>-(paper) - A Simple and Effective Model for Answering Multi-span Questions <strong>EMNLP 2020</strong></li></ol><p>​        GitHub：<a href="https://github.com/llamazing/numnet_plus">https://github.com/llamazing/numnet_plus</a></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220110113838.png" alt="image-20220110113838743"></p><ol><li><strong>MTMSN</strong>-(paper) - A Multi-Type Multi-Span Network for Reading Comprehension that Requires Discrete Reasoning <strong>EMNLP 2019</strong></li></ol><p>​        GitHub：<a href="https://github.com/huminghao16/MTMSN">https://github.com/huminghao16/MTMSN</a></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220110113857.png" alt="image-20220110113857713"></p><ol><li><strong>MetaQA</strong>-(paper) - MetaQA: Combining Expert Agents for Multi-Skill Question Answering <strong>Submitted on 3 Dec 2021</strong>比较新 且 <strong>代码结构类似</strong></li></ol><p>​        GitHub： <a href="https://github.com/ukplab/metaqa">https://github.com/ukplab/metaqa</a></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220110102212.png" alt="image-20220110102212928" style="zoom: 25%;" /></p><ol><li><p><strong>NAQANet</strong> <strong>性能较低</strong> 但代码实现可参考</p><p>GitHub：<a href="https://github.com/francescomontagna/NAQANet-PyTorch">https://github.com/francescomontagna/NAQANet-PyTorch</a></p><p>原始数据使用的是 drop_dataset_train_standardized.json 和 drop_dataset_dev_standardized.json</p></li></ol><h1 id="探索"><a href="#探索" class="headerlink" title="探索"></a>探索</h1><h2 id="QA-SOTA"><a href="#QA-SOTA" class="headerlink" title="QA SOTA"></a>QA SOTA</h2><p>​    <a href="https://paperswithcode.com/task/question-answering">https://paperswithcode.com/task/question-answering</a></p><p>​    <a href="https://paperswithcode.com/paper/quality-question-answering-with-long-input">https://paperswithcode.com/paper/quality-question-answering-with-long-input</a></p><p>   <code>Current models perform poorly on this task (55.4%) and significantly lag behind human performance (93.5%).</code></p><h2 id="Question-Answering"><a href="#Question-Answering" class="headerlink" title="Question Answering"></a>Question Answering</h2><h3 id="Question-Answering-on-HotpotQA"><a href="#Question-Answering-on-HotpotQA" class="headerlink" title="Question Answering on HotpotQA"></a>Question Answering on HotpotQA</h3><blockquote><p>Leaderboard : <a href="https://paperswithcode.com/sota/question-answering-on-hotpotqa">https://paperswithcode.com/sota/question-answering-on-hotpotqa</a></p></blockquote><p><strong>BigBird-etc</strong>     NeurIPS 2020</p><p>​    Big Bird: Transformers for Longer Sequences</p><p>​     <a href="https://paperswithcode.com/paper/big-bird-transformers-for-longer-sequences">https://paperswithcode.com/paper/big-bird-transformers-for-longer-sequences</a></p><p><strong>AISO    </strong>EMNLP 2021</p><p>​    Adaptive Information Seeking for Open-Domain Question Answering</p><p>​    <a href="https://paperswithcode.com/paper/adaptive-information-seeking-for-open-domain">https://paperswithcode.com/paper/adaptive-information-seeking-for-open-domain</a></p><p><strong>IRRR+</strong>    EMNLP 2021</p><p>​    Answering Open-Domain Questions of Varying Reasoning Steps from Text</p><p>​    <a href="https://paperswithcode.com/paper/retrieve-rerank-read-then-iterate-answering">https://paperswithcode.com/paper/retrieve-rerank-read-then-iterate-answering</a></p><p>​    Construct a new benchmark, called BeerQA : <a href="https://beerqa.github.io/">https://beerqa.github.io/</a></p><p><strong>Recursive Dense Retriever</strong>    ICLR 2021</p><p>​    Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval</p><p>​    <a href="https://paperswithcode.com/paper/answering-complex-open-domain-questions-with">https://paperswithcode.com/paper/answering-complex-open-domain-questions-with</a></p><p><strong>Transformer-XH-final</strong>    ICLR2020</p><p>​    Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention</p><p>​    <a href="https://paperswithcode.com/paper/transformer-xh-multi-evidence-reasoning-with">https://paperswithcode.com/paper/transformer-xh-multi-evidence-reasoning-with</a></p><h3 id="Generative-Question-Answering-on-CoQA"><a href="#Generative-Question-Answering-on-CoQA" class="headerlink" title="Generative Question Answering on CoQA"></a>Generative Question Answering on CoQA</h3><p><strong>ERNIE-GEN</strong> </p><p>​    ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation</p><p>​    <a href="https://paperswithcode.com/paper/ernie-gen-an-enhanced-multi-flow-pre-training">https://paperswithcode.com/paper/ernie-gen-an-enhanced-multi-flow-pre-training</a></p><p>​    <code>span-by-span generation flow</code></p><h3 id="Mathematical-Question-Answering-on-Geometry3K"><a href="#Mathematical-Question-Answering-on-Geometry3K" class="headerlink" title="Mathematical Question Answering on Geometry3K"></a>Mathematical Question Answering on Geometry3K</h3><blockquote><p>Geometry problem</p></blockquote><p><strong>Inter-GPS </strong> ACL2021</p><p>​    Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning</p><p>​    <a href="https://paperswithcode.com/paper/inter-gps-interpretable-geometry-problem">https://paperswithcode.com/paper/inter-gps-interpretable-geometry-problem</a></p><h3 id="Open-Domain-Question-Answering-on-SearchQA"><a href="#Open-Domain-Question-Answering-on-SearchQA" class="headerlink" title="Open-Domain Question Answering on SearchQA"></a>Open-Domain Question Answering on SearchQA</h3><p><strong>Locality-Sensitive Hashing</strong>    ICLR2020</p><p>​    Reformer: The Efficient Transformer<br>​<br>​    <a href="https://paperswithcode.com/paper/reformer-the-efficient-transformer-1">https://paperswithcode.com/paper/reformer-the-efficient-transformer-1</a><br>​<br>​    <code>much more memory-efficient and much faster on long sequences</code></p><h3 id="Open-Domain-Question-Answering-on-Natural-Questions"><a href="#Open-Domain-Question-Answering-on-Natural-Questions" class="headerlink" title="Open-Domain Question Answering on Natural Questions"></a>Open-Domain Question Answering on Natural Questions</h3><blockquote><p><a href="https://paperswithcode.com/sota/open-domain-question-answering-on-natural">https://paperswithcode.com/sota/open-domain-question-answering-on-natural</a></p></blockquote><p><strong>R2-D2</strong>    </p><p>​    Pruning the Index Contents for Memory Efficient Open-Domain QA<br>​<br>​    <a href="https://paperswithcode.com/paper/pruning-the-index-contents-for-memory">https://paperswithcode.com/paper/pruning-the-index-contents-for-memory</a></p><p><strong>R2-D2 \w HN-DPR</strong> EMNLP2021</p><p>​    R2-D2: A Modular Baseline for Open-Domain Question Answering<br>​    <a href="https://paperswithcode.com/paper/r2-d2-a-modular-baseline-for-open-domain">https://paperswithcode.com/paper/r2-d2-a-modular-baseline-for-open-domain</a></p><p><strong>BPR </strong> ACL2021</p><p>​    Efficient Passage Retrieval with Hashing for Open-domain Question Answering<br>​<br>​    <a href="https://paperswithcode.com/paper/efficient-passage-retrieval-with-hashing-for">https://paperswithcode.com/paper/efficient-passage-retrieval-with-hashing-for</a><br>​<br><code>同等性能下大幅减小内存开销</code></p><h3 id="Open-Domain-Question-Answering-on-KILT-ELI5"><a href="#Open-Domain-Question-Answering-on-KILT-ELI5" class="headerlink" title="Open-Domain Question Answering on KILT: ELI5"></a>Open-Domain Question Answering on KILT: ELI5</h3><blockquote><p>knowledge-intensive language tasks (KILT)</p><p><a href="https://eval.ai/web/challenges/challenge-page/689/overview">https://eval.ai/web/challenges/challenge-page/689/overview</a></p></blockquote><p> <strong>arxiv.org/abs/2103.06332</strong> NAACL2021</p><p>​    Hurdles to Progress in Long-form Question Answering</p><p>​    <a href="https://paperswithcode.com/paper/hurdles-to-progress-in-long-form-question">https://paperswithcode.com/paper/hurdles-to-progress-in-long-form-question</a></p><p>​    <code>The task of long-form question answering (LFQA)</code></p><p><strong>T5-base</strong> NAACL2021</p><p>​    KILT: a Benchmark for Knowledge Intensive Language Tasks</p><p>​    <a href="https://paperswithcode.com/paper/kilt-a-benchmark-for-knowledge-intensive">https://paperswithcode.com/paper/kilt-a-benchmark-for-knowledge-intensive</a></p><h2 id="长文本处理"><a href="#长文本处理" class="headerlink" title="长文本处理"></a>长文本处理</h2><ol><li><p>Big Bird: Transformers for Longer Sequences </p><p><a href="https://paperswithcode.com/paper/big-bird-transformers-for-longer-sequences">https://paperswithcode.com/paper/big-bird-transformers-for-longer-sequences</a></p></li><li><p>QuALITY: Question Answering with Long Input Texts, Yes!</p></li></ol><h2 id="Reading-Comprehension"><a href="#Reading-Comprehension" class="headerlink" title="Reading Comprehension"></a>Reading Comprehension</h2><blockquote><p>LeaderBoards : <a href="https://paperswithcode.com/task/reading-comprehension">https://paperswithcode.com/task/reading-comprehension</a></p></blockquote><h3 id="Reading-Comprehension-on-ReClor"><a href="#Reading-Comprehension-on-ReClor" class="headerlink" title="Reading Comprehension on ReClor"></a>Reading Comprehension on ReClor</h3><blockquote><p>logical reasoning QA datasets, ReClor and LogiQA</p><p>LeaderBoard:<a href="https://paperswithcode.com/sota/reading-comprehension-on-reclor">https://paperswithcode.com/sota/reading-comprehension-on-reclor</a></p></blockquote><p><strong>RoBERTa-single</strong> NeurIPS2021</p><p>​    Fact-driven Logical Reasoning</p><p>​    <a href="https://paperswithcode.com/paper/fact-driven-logical-reasoning">https://paperswithcode.com/paper/fact-driven-logical-reasoning</a></p><p>​    <code>covering both global and local knowledge pieces</code></p><p><strong>DAGN</strong> NAACL2020</p><p>​    DAGN: Discourse-Aware Graph Network for Logical Reasoning</p><p>​    <a href="https://paperswithcode.com/paper/dagn-discourse-aware-graph-network-for">https://paperswithcode.com/paper/dagn-discourse-aware-graph-network-for</a></p><p>​    <code>Recent QA with logical reasoning questions requires passage-level relations among the sentences.</code></p><p>​    <code>for solving logical reasoning QA</code></p><p>​    <code>discourse-aware graph network (DAGN)</code></p><p><strong>ReClor</strong>  ICLR2020</p><p>​    ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning</p><p>​    <a href="https://paperswithcode.com/paper/reclor-a-reading-comprehension-dataset-1">https://paperswithcode.com/paper/reclor-a-reading-comprehension-dataset-1</a></p><p>​    <code>introduce a new Reading Comprehension dataset requiring logical reasoning (ReClor)</code></p><h3 id="Reading-Comprehension-on-AdversarialQA"><a href="#Reading-Comprehension-on-AdversarialQA" class="headerlink" title="Reading Comprehension on AdversarialQA"></a>Reading Comprehension on AdversarialQA</h3><p><strong>AdversarialQA</strong></p><p>​    Beat the AI: Investigating Adversarial Human Annotation for Reading Comprehension</p><p>​    <a href="https://paperswithcode.com/paper/beat-the-ai-investigating-adversarial-human">https://paperswithcode.com/paper/beat-the-ai-investigating-adversarial-human</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> Drop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>leetcode每日一题（更新中）</title>
      <link href="/2022/01/04/leetcode%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/"/>
      <url>/2022/01/04/leetcode%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="简单"><a href="#简单" class="headerlink" title="简单"></a>简单</h1><h2 id="剑指-Offer-10-I-斐波那契数列"><a href="#剑指-Offer-10-I-斐波那契数列" class="headerlink" title="剑指 Offer 10- I. 斐波那契数列"></a>剑指 Offer 10- I. 斐波那契数列</h2><blockquote><p>不能使用简单递归 会超时</p><p>使用动态规划求解</p><p>由于 F(n) 只和 F(n−1) 与 F(n−2) 有关，因此可以使用「滚动数组思想」把空间复杂度优化成 O(1)。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def fib(self, n: int) -&gt; int:</span><br><span class="line">        # 计算过程中，答案需要取模  1e9+7</span><br><span class="line">        MOD = 10 ** 9 + 7</span><br><span class="line">        if n &lt; 2:</span><br><span class="line">            return n</span><br><span class="line">        else:</span><br><span class="line">            # 使用滚动数组减小空间复杂度</span><br><span class="line">            # f0=0 f1=1</span><br><span class="line">            p = 0</span><br><span class="line">            q = 0</span><br><span class="line">            r = 1</span><br><span class="line">            for i in range(2, n + 1):</span><br><span class="line">                p = q</span><br><span class="line">                q = r</span><br><span class="line">                r = (p + q) % MOD</span><br><span class="line">            return r</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    n = 100</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.fib(n)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="剑指-Offer-II-069-山峰数组的顶部"><a href="#剑指-Offer-II-069-山峰数组的顶部" class="headerlink" title="剑指 Offer II 069. 山峰数组的顶部"></a>剑指 Offer II 069. 山峰数组的顶部</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def peakIndexInMountainArray(self, arr: List[int]) -&gt; int:</span><br><span class="line">        s_len = len(arr)</span><br><span class="line">        left=0</span><br><span class="line">        right=s_len-2</span><br><span class="line">        ans=1</span><br><span class="line">        while left &lt;= right:</span><br><span class="line">            mid = (left+right)//2</span><br><span class="line">            if arr[mid]&gt;arr[mid+1]:</span><br><span class="line">                ans = mid</span><br><span class="line">                right = mid - 1 </span><br><span class="line">            else:</span><br><span class="line">                left =mid +1</span><br><span class="line">        return ans</span><br></pre></td></tr></table></figure><h2 id="141-环形链表"><a href="#141-环形链表" class="headerlink" title="141. 环形链表"></a>141. 环形链表</h2><blockquote><p><strong>STL容器</strong></p><p>set和unordered_set：其中unordered_set对元素不进行排序</p><p>find(key)：查找以值为 key 的元素，如果找到，则返回一个指向该元素的正向迭代器；反之，则返回一个指向容器中最后一个元素之后位置的迭代器（如end() 方法返回的迭代器）。</p><p>count(key)：在容器中查找值为 key 的元素的个数。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Definition for singly-linked list.</span><br><span class="line"> * struct ListNode &#123;</span><br><span class="line"> *     int val;</span><br><span class="line"> *     ListNode *next;</span><br><span class="line"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span><br><span class="line"> * &#125;;</span><br><span class="line"> */</span><br><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    bool hasCycle(ListNode *head) &#123;</span><br><span class="line">        // 遍历链表 将访问过的节点存到哈希表 如果节点被多次访问 则存在环    </span><br><span class="line">        set&lt;ListNode*&gt; nodes;</span><br><span class="line">        while(head!=nullptr)</span><br><span class="line">        &#123;</span><br><span class="line">            // 如果set中找不到指定元素 返回nodes.end()</span><br><span class="line">            if(nodes.find(head)!=nodes.end())</span><br><span class="line">                return true;</span><br><span class="line">            // count(head) 在容器中查找值为 key 的元素的个数。</span><br><span class="line">            // if (nodes.count(head)) &#123;</span><br><span class="line">            //     return true;</span><br><span class="line">            // &#125;</span><br><span class="line">            nodes.insert(head);</span><br><span class="line">            head=head-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="268-丢失的数字"><a href="#268-丢失的数字" class="headerlink" title="268. 丢失的数字"></a>268. 丢失的数字</h2><blockquote><p>stl中vector的排序<code>sort(nums.begin(), nums.end());</code></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int missingNumber(vector&lt;int&gt;&amp; nums) &#123;</span><br><span class="line">        // 先排序 </span><br><span class="line">        sort(nums.begin(), nums.end());</span><br><span class="line">        // for (int v:nums)</span><br><span class="line">        //     cout&lt;&lt;v;</span><br><span class="line">        // 遍历对应位置 索引与数组值不对应 则返回该索引</span><br><span class="line">        for (int i=0;i&lt;nums.size();i++)&#123;</span><br><span class="line">            if (nums[i]!=i)</span><br><span class="line">                return i;</span><br><span class="line">        &#125;</span><br><span class="line">        return nums.size();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="405-数字转换为十六进制数"><a href="#405-数字转换为十六进制数" class="headerlink" title="405. 数字转换为十六进制数"></a>405. 数字转换为十六进制数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    </span><br><span class="line">    def toHex(self, num: int) -&gt; str:</span><br><span class="line">        CONV = &quot;0123456789abcdef&quot;</span><br><span class="line">        ans =[]</span><br><span class="line">        # 32位二进制数 转成十六进制 共8位 4*8</span><br><span class="line">        for _ in range(8): </span><br><span class="line">            temp = num % 16</span><br><span class="line">            num = num//16</span><br><span class="line">            ans.append(temp)</span><br><span class="line">            if not num:</span><br><span class="line">                break</span><br><span class="line">        # 倒着输出</span><br><span class="line">        return &#x27;&#x27;.join(CONV[j] for j in ans[::-1])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="434-字符串中的单词数"><a href="#434-字符串中的单词数" class="headerlink" title="434. 字符串中的单词数"></a>434. 字符串中的单词数</h2><blockquote><p>注意：python中split()函数用法</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a=&quot;     &quot;</span><br><span class="line">a.split() # 按照空格分割 分割完删除空字符串</span><br><span class="line">a.split() # 按照空格分割 但只是按照单个空格分割 分割后字符串中会包含空字符串</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def countSegments(self, s: str) -&gt; int:</span><br><span class="line">        ans =0 </span><br><span class="line">        # s=s.strip()</span><br><span class="line">        for i in range(len(s)):</span><br><span class="line">            </span><br><span class="line">            if(s[i]==&quot; &quot; and s[i-1]!=&quot; &quot; and i&gt;0) or (i==(len(s)-1) and s[i]!=&quot; &quot;):</span><br><span class="line">                ans+=1</span><br><span class="line">        return ans </span><br><span class="line">        # return len(s.split())</span><br></pre></td></tr></table></figure><h2 id="496-下一个更大元素-I"><a href="#496-下一个更大元素-I" class="headerlink" title="496. 下一个更大元素 I"></a>496. 下一个更大元素 I</h2><blockquote><p>时间复杂度较低的解法，使用 单调栈 + 哈希表</p><p>应为nums2中没有重复的元素，构造严格单调递增的栈 并将栈中的值与小于自身的值 对应关系存储到哈希表</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def nextGreaterElement(self, nums1: List[int], nums2: List[int]) -&gt; List[int]:</span><br><span class="line">        res = &#123;&#125;</span><br><span class="line">        stack = []</span><br><span class="line">        for num in reversed(nums2):</span><br><span class="line">            while stack and num &gt;= stack[-1]:</span><br><span class="line">                stack.pop()</span><br><span class="line">            res[num] = stack[-1] if stack else -1</span><br><span class="line">            stack.append(num)</span><br><span class="line">        return [res[num] for num in nums1]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="598-范围求和-II"><a href="#598-范围求和-II" class="headerlink" title="598. 范围求和 II"></a>598. 范围求和 II</h2><blockquote><p>求出区间交集即可</p><p>用不着暴力模拟 而且会超时</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int maxCount(int m, int n, vector&lt;vector&lt;int&gt;&gt;&amp; ops) &#123;</span><br><span class="line">        // 求解 对于mxn的矩阵M 操作的交集区间 即为最大值区间</span><br><span class="line">        int max_a=m,max_b=n;</span><br><span class="line">        for(vector&lt;int&gt;op : ops)</span><br><span class="line">        &#123;</span><br><span class="line">            max_a = min(op[0],max_a);</span><br><span class="line">            max_b=min(op[1],max_b);</span><br><span class="line">        &#125;</span><br><span class="line">        return max_b*max_a;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="700-二叉搜索树中的搜索"><a href="#700-二叉搜索树中的搜索" class="headerlink" title="700. 二叉搜索树中的搜索"></a>700. 二叉搜索树中的搜索</h2><blockquote><p>左子树严格小于根结点 右子树严格大于根结点</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    TreeNode* searchBST(TreeNode* root, int val) &#123;</span><br><span class="line">        //遍历二叉搜索树</span><br><span class="line">        // 左子树严格小于根结点 右子树严格大于根结点</span><br><span class="line">        if (root==nullptr)</span><br><span class="line">            return NULL;</span><br><span class="line">        if (root-&gt;val == val)</span><br><span class="line">            return root;     </span><br><span class="line">        return searchBST(val &lt; root-&gt;val ? root-&gt;left : root-&gt;right, val);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="704-二分查找"><a href="#704-二分查找" class="headerlink" title="704. 二分查找"></a>704. 二分查找</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def search(self, nums: List[int], target: int) -&gt; int:</span><br><span class="line">        low, high = 0, len(nums) - 1</span><br><span class="line">        while low &lt;= high:</span><br><span class="line">            # 确保在原数组操作</span><br><span class="line">            mid = (high - low) // 2 + low</span><br><span class="line">            num = nums[mid]</span><br><span class="line">            if num == target:</span><br><span class="line">                return mid</span><br><span class="line">            elif num &gt; target:</span><br><span class="line">                high = mid - 1</span><br><span class="line">            else:</span><br><span class="line">                low = mid + 1</span><br><span class="line">        return -1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    nums = [-1, 0, 3, 5, 9, 12]</span><br><span class="line">    target = 9</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.search(nums, target)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="1221-分割平衡字符串"><a href="#1221-分割平衡字符串" class="headerlink" title="1221. 分割平衡字符串"></a>1221. 分割平衡字符串</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def balancedStringSplit(self, s: str) -&gt; int:</span><br><span class="line">        s_list = list(s)</span><br><span class="line">        ch = 0</span><br><span class="line">        ans = 0</span><br><span class="line">        # 遍历字符串 统计两种字符出现数量之差 ch=0时 说明前缀字符串数量相同 构成平衡字符串 ans+1</span><br><span class="line">        for i in s_list:</span><br><span class="line">            if i == &#x27;R&#x27;:</span><br><span class="line">                ch += 1</span><br><span class="line">            else:</span><br><span class="line">                ch -= 1</span><br><span class="line">            if ch == 0:</span><br><span class="line">                ans += 1</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    s = &quot;RLRRLLRLRL&quot;</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.balancedStringSplit(s)</span><br><span class="line">    print(b)</span><br></pre></td></tr></table></figure><h3 id="1436-旅行终点站"><a href="#1436-旅行终点站" class="headerlink" title="1436. 旅行终点站"></a>1436. 旅行终点站</h3><blockquote><p>注意 如果用下面的办法 字典需要遍历两遍</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def destCity(self, paths: List[List[str]]) -&gt; str:</span><br><span class="line"></span><br><span class="line">        city_dict = dict()</span><br><span class="line">        for i in paths:</span><br><span class="line">            if city_dict.get(i[1]):</span><br><span class="line">                city_dict[i[1]] += 1</span><br><span class="line">            else:</span><br><span class="line">                city_dict[i[1]] = 1</span><br><span class="line">        for i in paths:</span><br><span class="line">            if city_dict.get(i[0]):</span><br><span class="line">                city_dict[i[0]] -= 1</span><br><span class="line">        # 输出值为1的城市</span><br><span class="line">        for k, v in city_dict.items():</span><br><span class="line">            if v == 1:</span><br><span class="line">                return k</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    root = [[&quot;B&quot;, &quot;C&quot;], [&quot;D&quot;, &quot;B&quot;], [&quot;C&quot;, &quot;A&quot;]]</span><br><span class="line">    targetSum = 8</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.destCity(root)</span><br><span class="line">    print(b)</span><br></pre></td></tr></table></figure><h1 id="一般"><a href="#一般" class="headerlink" title="一般"></a>一般</h1><h2 id="面试题-17-14-最小K个数"><a href="#面试题-17-14-最小K个数" class="headerlink" title="面试题 17.14. 最小K个数"></a>面试题 17.14. 最小K个数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def smallestK(self, arr: List[int], k: int) -&gt; List[int]:</span><br><span class="line">        if k &gt; 0 and k &lt; len(arr):</span><br><span class="line">            arr.sort()</span><br><span class="line">            return arr[0:k]</span><br><span class="line">        else:</span><br><span class="line">            return []</span><br></pre></td></tr></table></figure><blockquote><p>由于 C++ 语言中的堆（即优先队列）为大根堆，而 Python 语言中的堆为小根堆，因此我们要对数组中所有的数取其相反数，才能使用小根堆维护前 k 小值。、</p></blockquote><h1 id="中等"><a href="#中等" class="headerlink" title="中等"></a>中等</h1><h2 id="🌟29-两数相除"><a href="#🌟29-两数相除" class="headerlink" title="🌟29. 两数相除"></a>🌟29. 两数相除</h2><blockquote><p>有点没思路</p></blockquote><p>题解：</p><ul><li>如果我们将被除数和除数都变为正数，那么可能会导致溢出。例如当被除数为 $-2^{31}$ 时，它的相反数 $2^{31}$产生了溢出。因此，我们可以考虑将被除数和除数都变为负数，这样就不会有溢出的问题，在编码时只需要考虑 1 种情况了。</li><li>使用快速乘实现乘法运算。快速乘实际上是通过加法运算实现的。</li></ul><p>官方题解还是有点懵，找到一篇思路简单的题解：</p><ul><li>举个例子：11 除以 3 。<br>首先11比3大，结果至少是1， 然后我让3翻倍，就是6，发现11比3翻倍后还要大，那么结果就至少是2了，那我让这个6再翻倍，得12，11不比12大，吓死我了，差点让就让刚才的最小解2也翻倍得到4了。但是我知道最终结果肯定在2和4之间。也就是说2再加上某个数，这个数是多少呢？我让11减去刚才最后一次的结果6，剩下5，我们计算5是3的几倍，也就是除法，看，递归出现了。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int divide(int dividend, int divisor) &#123;</span><br><span class="line">        if(dividend == 0) return 0;</span><br><span class="line">        if(divisor == 1) return dividend;</span><br><span class="line">        if(divisor == -1)&#123;</span><br><span class="line">            if(dividend&gt;INT_MIN) return -dividend;// 只要不是最小的那个整数，都是直接返回相反数就好啦</span><br><span class="line">            return INT_MAX;// 是最小的那个，那就返回最大的整数啦</span><br><span class="line">        &#125;</span><br><span class="line">        long a = dividend;</span><br><span class="line">        long b = divisor;</span><br><span class="line">        int sign = 1; </span><br><span class="line">        if((a&gt;0&amp;&amp;b&lt;0) || (a&lt;0&amp;&amp;b&gt;0))&#123;</span><br><span class="line">            sign = -1;</span><br><span class="line">        &#125;</span><br><span class="line">        a = a&gt;0?a:-a;</span><br><span class="line">        b = b&gt;0?b:-b;</span><br><span class="line">        long res = div(a,b);</span><br><span class="line">        if(sign&gt;0)return res&gt;INT_MAX?INT_MAX:res;</span><br><span class="line">        return -res;</span><br><span class="line">    &#125;</span><br><span class="line">    int div(long a, long b)&#123;  // 似乎精髓和难点就在于下面这几句</span><br><span class="line">        if(a&lt;b) return 0;</span><br><span class="line">        long count = 1;</span><br><span class="line">        long tb = b; // 在后面的代码中不更新b</span><br><span class="line">        while((tb+tb)&lt;=a)&#123;</span><br><span class="line">            count = count + count; // 最小解翻倍</span><br><span class="line">            tb = tb+tb; // 当前测试的值也翻倍</span><br><span class="line">        &#125;</span><br><span class="line">        return count + div(a-tb,b);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def divide(self, dividend: int, divisor: int) -&gt; int:</span><br><span class="line">        # 边界情况 </span><br><span class="line">        INT_MIN = -(2&lt;&lt;30)</span><br><span class="line">        INI_MAX = (2&lt;&lt;30)-1</span><br><span class="line">        # 判断特殊情况</span><br><span class="line">        # 被除数为0</span><br><span class="line">        if dividend==0:</span><br><span class="line">            return 0</span><br><span class="line">        if divisor==-1:</span><br><span class="line">            # INT_MIN/-1 为2^31 正数越界</span><br><span class="line">            if dividend == INT_MIN:</span><br><span class="line">                return INI_MAX</span><br><span class="line">            return -dividend</span><br><span class="line">        # 方便后面找倍数关系 转为正数计算</span><br><span class="line">        # 记录符号</span><br><span class="line">        sign = -1</span><br><span class="line">        if (dividend&gt;0 and  divisor&gt;0 ) or (dividend&lt;0 and divisor&lt;0):</span><br><span class="line">            sign = 1</span><br><span class="line">        dividend = dividend if dividend&gt;0 else -dividend</span><br><span class="line">        divisor = divisor if divisor&gt;0 else -divisor</span><br><span class="line">        # 计算结果</span><br><span class="line">        # print(dividend,divisor)</span><br><span class="line">        ans = self.div(dividend,divisor)</span><br><span class="line"></span><br><span class="line">        if sign == 1:</span><br><span class="line">                return ans</span><br><span class="line">        else:</span><br><span class="line">                return -ans</span><br><span class="line"></span><br><span class="line">    def div(self,x,y):</span><br><span class="line">        # 判断 x/y可以除几轮 不能用除号 用倍数来代替</span><br><span class="line">        if x&lt;y :</span><br><span class="line">            return 0 </span><br><span class="line">        # x &gt; y x中至少包含一个y</span><br><span class="line">        times =1</span><br><span class="line">        ty= y</span><br><span class="line">        while (ty&lt;&lt;1) &lt;= x:</span><br><span class="line">            times += times</span><br><span class="line">            ty = ty&lt;&lt;1</span><br><span class="line">        return times + self.div(x-ty,y)</span><br></pre></td></tr></table></figure><h2 id="36-有效的数独"><a href="#36-有效的数独" class="headerlink" title="36. 有效的数独"></a>36. 有效的数独</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def isValidSudoku(self, board: List[List[str]]) -&gt; bool:</span><br><span class="line"></span><br><span class="line">        dict_col = &#123;&#125;</span><br><span class="line">        # 先进行行检测 确保不出现重复数字</span><br><span class="line">        row = self.signal_num(board)</span><br><span class="line">        # print(row)</span><br><span class="line">        if row:</span><br><span class="line">            # 再进行列检测 确保每一列数据不包含重复数字</span><br><span class="line">            #  矩阵转置</span><br><span class="line">            t_board = np.transpose(np.array(board))</span><br><span class="line">            col = self.signal_num(list(t_board))</span><br><span class="line">            # print(col)</span><br><span class="line">            if col:</span><br><span class="line">                # 判断3x3 区间是否有重复数字</span><br><span class="line">                # 使用numpy实现矩阵切片</span><br><span class="line">                np_board = np.transpose(np.array(board))</span><br><span class="line">                # print(np_board)</span><br><span class="line">                for j in range(3):</span><br><span class="line">                    for i in range(3):</span><br><span class="line">                        index_i = i * 3</span><br><span class="line">                        index_j = j * 3</span><br><span class="line">                        new_board = np_board[index_i:index_i + 3, index_j:index_j + 3]</span><br><span class="line">                        # 矩阵展开成一纬度</span><br><span class="line">                        d1_new_board = new_board.flatten()</span><br><span class="line">                        # print(d1_new_board)</span><br><span class="line">                        if not self.signal_num(list([d1_new_board])):</span><br><span class="line">                            return False</span><br><span class="line">            else:</span><br><span class="line">                return False</span><br><span class="line"></span><br><span class="line">        else:</span><br><span class="line">            return False</span><br><span class="line">        return True</span><br><span class="line"></span><br><span class="line">    def signal_num(self, board_self: List[List[str]]) -&gt; bool:</span><br><span class="line">        for row in board_self:</span><br><span class="line">            dict_row = &#123;&#125;</span><br><span class="line">            for i in row:</span><br><span class="line">                if i != &#x27;.&#x27; and dict_row.get(i):</span><br><span class="line">                    return False</span><br><span class="line">                else:</span><br><span class="line">                    dict_row[i] = i</span><br><span class="line">        return True</span><br></pre></td></tr></table></figure><h2 id="38-外观数列"><a href="#38-外观数列" class="headerlink" title="38. 外观数列"></a>38. 外观数列</h2><blockquote><p>可以当作双指针来做 一个记录开始位置 一个记录结束为止 相减即为字符串长度</p><p>循环次数不确定的时候要用 <strong>while</strong></p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def countAndSay(self, n: int) -&gt; str:</span><br><span class="line">        prev = &quot;1&quot;</span><br><span class="line">        # 循环n-1次 因为第一次为确定的&#x27;1&#x27;</span><br><span class="line">        # 每次循环解释 prev</span><br><span class="line">        for i in range(n - 1):</span><br><span class="line">            curr = &quot;&quot;</span><br><span class="line">            pos = 0</span><br><span class="line">            start = 0</span><br><span class="line"></span><br><span class="line">            while pos &lt; len(prev):</span><br><span class="line">                while pos &lt; len(prev) and prev[pos] == prev[start]:</span><br><span class="line">                    pos += 1</span><br><span class="line">                curr += str(pos - start) + prev[start]</span><br><span class="line">                start = pos</span><br><span class="line">            prev = curr</span><br><span class="line"></span><br><span class="line">        return prev</span><br></pre></td></tr></table></figure><h2 id="46-全排列"><a href="#46-全排列" class="headerlink" title="46. 全排列"></a>46. 全排列</h2><blockquote><p>回溯</p><p>其中要注意 python 中数组拷贝要用 new = old[:]</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">import copy</span><br><span class="line">class Solution:</span><br><span class="line">    def permute(self, nums: List[int]) -&gt; List[List[int]]:</span><br><span class="line">        # 回溯算法实现</span><br><span class="line">        # 定义一个布尔数组 标记每个节点的访问状态</span><br><span class="line">        used = [False for i in range(len(nums))]</span><br><span class="line"></span><br><span class="line">        # def</span><br><span class="line">        depth = 0 #遍历层的深度</span><br><span class="line">        res=[]</span><br><span class="line">        len_nums = len(nums) </span><br><span class="line">        path=[]</span><br><span class="line">        def dfs(depth,len_nums,path):</span><br><span class="line">            if depth == len_nums:</span><br><span class="line">                # 遍历到最后一层 添加一个排列结果</span><br><span class="line">                # 用path会出错 必须用 path[:] 它复制列表old到new</span><br><span class="line">                res.append(path[:])</span><br><span class="line">            for i in range(len_nums):</span><br><span class="line">                if  used[i]:</span><br><span class="line">                    continue</span><br><span class="line">                else:</span><br><span class="line">                    path.append(nums[i])</span><br><span class="line">                    used[i]=True</span><br><span class="line">                    dfs(depth+1,len_nums,path)</span><br><span class="line">                    path.pop()</span><br><span class="line">                    used[i]=False</span><br><span class="line">        dfs(depth,len_nums,path)</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure><h2 id="47-全排列-II"><a href="#47-全排列-II" class="headerlink" title="47. 全排列 II"></a>47. 全排列 II</h2><blockquote><p>去掉重复排列</p><p>先对数组排序 避免同一个数字多次使用</p><p>要解决重复问题，我们只要设定一个规则，保证在填第 i个数的时候重复数字只会被填入一次即可。而在本题解中，我们选择对原数组排序，保证相同的数字都相邻，然后每次填入的数一定是这个数所在重复数集合中「从左往右第一个未被填过的数字」，即如下的判断条件：</p></blockquote><p>关键代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if  used[i] or (i &gt; 0 and not used[i - 1] and nums[i] == nums[i - 1]):</span><br><span class="line">                    continue</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import copy</span><br><span class="line">class Solution:</span><br><span class="line">    def permuteUnique(self, nums: List[int]) -&gt; List[List[int]]:</span><br><span class="line"></span><br><span class="line">        # 回溯算法实现</span><br><span class="line">        # 定义一个布尔数组 标记每个节点的访问状态</span><br><span class="line">        used = [False for i in range(len(nums))]</span><br><span class="line">        # 必须要排序</span><br><span class="line">        nums.sort()</span><br><span class="line">        # def</span><br><span class="line">        depth = 0 #遍历层的深度</span><br><span class="line">        res=[]</span><br><span class="line">        len_nums = len(nums) </span><br><span class="line">        path=[]</span><br><span class="line">        def dfs(depth,len_nums,path):</span><br><span class="line">            if depth == len_nums:</span><br><span class="line">                # 遍历到最后一层 添加一个排列结果</span><br><span class="line">                # 用path会出错 必须用 path[:] 它复制列表old到new</span><br><span class="line">                res.append(path[:])</span><br><span class="line">            for i in range(len_nums):</span><br><span class="line">                if  used[i] or (i &gt; 0 and not used[i - 1] and nums[i] == nums[i - 1]):</span><br><span class="line">                # 遇到相同的数字 只有当前一个相同的数字没有被使用才可以 </span><br><span class="line">                    continue</span><br><span class="line">                else:</span><br><span class="line">                    path.append(nums[i])</span><br><span class="line">                    used[i]=True</span><br><span class="line">                    dfs(depth+1,len_nums,path)</span><br><span class="line">                    path.pop()</span><br><span class="line">                    used[i]=False</span><br><span class="line">        dfs(depth,len_nums,path)</span><br><span class="line">        return res</span><br></pre></td></tr></table></figure><h2 id="162-寻找峰值"><a href="#162-寻找峰值" class="headerlink" title="162. 寻找峰值"></a>162. 寻找峰值</h2><blockquote><p>找出最大值即满足条件</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def findPeakElement(self, nums: List[int]) -&gt; int:</span><br><span class="line">        max_value = np.max(np.array(nums))</span><br><span class="line"></span><br><span class="line">        return nums.index(int(max_value))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    nums = [1, 2, 3, 1]</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.findPeakElement(nums)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="166-分数到小数"><a href="#166-分数到小数" class="headerlink" title="166. 分数到小数"></a>166. 分数到小数</h2><blockquote><p>参考了一个非常清晰的题解</p></blockquote><ul><li>java</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">    public String fractionToDecimal(int numerator, int denominator) &#123;</span><br><span class="line">        // 转 long 计算，防止溢出</span><br><span class="line">        long a = numerator, b = denominator;</span><br><span class="line">        // 如果本身能够整除，直接返回计算结果</span><br><span class="line">        if (a % b == 0) return String.valueOf(a / b);</span><br><span class="line">        StringBuilder sb = new StringBuilder();</span><br><span class="line">        // 如果其一为负数，先追加负号</span><br><span class="line">        if (a * b &lt; 0) sb.append(&#x27;-&#x27;);</span><br><span class="line">        a = Math.abs(a); b = Math.abs(b);</span><br><span class="line">        // 计算小数点前的，部分，并将余数赋值给 a</span><br><span class="line">        sb.append(String.valueOf(a / b) + &quot;.&quot;);</span><br><span class="line">        a %= b;</span><br><span class="line">        Map&lt;Long, Integer&gt; map = new HashMap&lt;&gt;();</span><br><span class="line">        while (a != 0) &#123;</span><br><span class="line">            // 记录当前余数所在答案的位置</span><br><span class="line">            map.put(a, sb.length());</span><br><span class="line">            a *= 10;</span><br><span class="line">            sb.append(a / b);</span><br><span class="line">            a %= b;</span><br><span class="line">            // 如果当前余数之前出现过，则将 [出现位置 - 当前位置] 的部分抠出来（循环小数部分）</span><br><span class="line">            if (map.containsKey(a)) &#123;</span><br><span class="line">                int u = map.get(a);</span><br><span class="line">                return String.format(&quot;%s(%s)&quot;, sb.substring(0, u), sb.substring(u));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return sb.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>python</p><blockquote><p>python截取字符串一定要检查冒号是否完整</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def fractionToDecimal(self, numerator: int, denominator: int) -&gt; str:</span><br><span class="line">        # 判断是否可以整除</span><br><span class="line">        if numerator % denominator == 0:</span><br><span class="line">            return str(numerator // denominator)</span><br><span class="line">        ans = &#x27;&#x27;</span><br><span class="line">        # 如果不能整除 判断符号</span><br><span class="line">        if numerator * denominator &lt; 0:</span><br><span class="line">            ans += &#x27;-&#x27;</span><br><span class="line">            numerator = abs(numerator)</span><br><span class="line">            denominator = abs(denominator)</span><br><span class="line">        # 计算整数部分</span><br><span class="line">        ans += str(numerator // denominator)</span><br><span class="line">        # 计算小数部分</span><br><span class="line">        ans += &#x27;.&#x27;</span><br><span class="line">        # 出现过的小数位存储</span><br><span class="line">        nums = []</span><br><span class="line">        # 当前余数</span><br><span class="line">        numerator = numerator % denominator</span><br><span class="line">        len_ans = len(ans)</span><br><span class="line">        while numerator != 0:</span><br><span class="line">            nums.append(numerator)</span><br><span class="line">            numerator *= 10</span><br><span class="line">            # 存储数位</span><br><span class="line">            ans += str(numerator // denominator)</span><br><span class="line">            numerator %= denominator</span><br><span class="line">            # 判断当前余数是否出现过</span><br><span class="line">            if nums.__contains__(numerator):</span><br><span class="line">                loc = nums.index(numerator)</span><br><span class="line">                end = len_ans + loc</span><br><span class="line">                return ans[0:end] + &#x27;(&#x27; + ans[len_ans + loc:] + &#x27;)&#x27;</span><br><span class="line">        return ans</span><br></pre></td></tr></table></figure><h2 id="187-重复的DNA序列"><a href="#187-重复的DNA序列" class="headerlink" title="187. 重复的DNA序列"></a>187. 重复的DNA序列</h2><blockquote><p>关键字：哈希表</p><p>defaultdict的作用是在于，当字典里的key不存在但被查找时，返回的不是keyError而是一个默认值</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def findRepeatedDnaSequences(self, s: str) -&gt; List[str]:</span><br><span class="line">        ans =[]</span><br><span class="line">        substr=defaultdict(int)</span><br><span class="line">        for i in range(len(s)-10+1):</span><br><span class="line">            temp = s[i:i+10]</span><br><span class="line">            # 切片时间复杂度 O（N）</span><br><span class="line">            substr[temp]+=1</span><br><span class="line">            if substr[temp]==2:</span><br><span class="line">                ans.append(temp)</span><br><span class="line">        return ans</span><br></pre></td></tr></table></figure><h2 id="200-岛屿数量"><a href="#200-岛屿数量" class="headerlink" title="200. 岛屿数量"></a>200. 岛屿数量</h2><blockquote><p>图的DFS遍历</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">private:</span><br><span class="line">    void dfs(vector&lt;vector&lt;char&gt;&gt;&amp; grid, int r, int c) &#123;</span><br><span class="line">        // 行列范围</span><br><span class="line">        int nr = grid.size();</span><br><span class="line">        int nc = grid[0].size();</span><br><span class="line">        </span><br><span class="line">        //将已经便利过的岛屿标记为2</span><br><span class="line">        grid[r][c] = &#x27;2&#x27;;</span><br><span class="line">        //判断边界情况</span><br><span class="line">        if (r - 1 &gt;= 0 &amp;&amp; grid[r-1][c] == &#x27;1&#x27;) dfs(grid, r - 1, c);</span><br><span class="line">        if (r + 1 &lt; nr &amp;&amp; grid[r+1][c] == &#x27;1&#x27;) dfs(grid, r + 1, c);</span><br><span class="line">        if (c - 1 &gt;= 0 &amp;&amp; grid[r][c-1] == &#x27;1&#x27;) dfs(grid, r, c - 1);</span><br><span class="line">        if (c + 1 &lt; nc &amp;&amp; grid[r][c+1] == &#x27;1&#x27;) dfs(grid, r, c + 1);</span><br><span class="line">    &#125;</span><br><span class="line">public:</span><br><span class="line">    int numIslands(vector&lt;vector&lt;char&gt;&gt;&amp; grid) &#123;</span><br><span class="line">        // dfs遍历</span><br><span class="line">        int nr = grid.size();</span><br><span class="line">        if (!nr) return 0;</span><br><span class="line">        int nc = grid[0].size();</span><br><span class="line"></span><br><span class="line">        int num_islands = 0;</span><br><span class="line">        for (int r = 0; r &lt; nr; ++r) &#123;</span><br><span class="line">            for (int c = 0; c &lt; nc; ++c) &#123;</span><br><span class="line">                // dfs搜索未访问过的岛屿</span><br><span class="line">                if (grid[r][c] == &#x27;1&#x27;) &#123;</span><br><span class="line">                    ++num_islands;</span><br><span class="line">                    dfs(grid, r, c);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return num_islands;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="211-添加与搜索单词-数据结构设计"><a href="#211-添加与搜索单词-数据结构设计" class="headerlink" title="211. 添加与搜索单词 - 数据结构设计"></a>211. 添加与搜索单词 - 数据结构设计</h2><blockquote><p>字典树 神奇！</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"># 字典树</span><br><span class="line">class TreeNode:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.children = [None] * 26</span><br><span class="line">        self.isEnd = False</span><br><span class="line"></span><br><span class="line">    def insert(self, word: str) -&gt; None:</span><br><span class="line">        node = self</span><br><span class="line">        for ch in word:</span><br><span class="line">            num = ord(ch)-ord(&#x27;a&#x27;) # asscii </span><br><span class="line">            if not node.children[num]:</span><br><span class="line">                node.children[num]= TreeNode()</span><br><span class="line">            node = node.children[num]</span><br><span class="line">        node.isEnd =True</span><br><span class="line"></span><br><span class="line">class WordDictionary:</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.trieRoot = TreeNode()</span><br><span class="line"></span><br><span class="line">    def addWord(self, word: str) -&gt; None:</span><br><span class="line">        self.trieRoot.insert(word)</span><br><span class="line"></span><br><span class="line">    def search(self, word: str) -&gt; bool:</span><br><span class="line">        def dfs(index: int, node: TreeNode) -&gt; bool:</span><br><span class="line">            if index == len(word):</span><br><span class="line">                return node.isEnd #搜索到叶子结点</span><br><span class="line">            ch = word[index]</span><br><span class="line">            if ch != &#x27;.&#x27;:</span><br><span class="line">                child = node.children[ord(ch) - ord(&#x27;a&#x27;)]</span><br><span class="line">                if child is not None and dfs(index + 1, child):</span><br><span class="line">                    return True</span><br><span class="line">            else:</span><br><span class="line">                for child in node.children: # . 可以表任意一个节点 从每一个分支继续搜索</span><br><span class="line">                    if child is not None and dfs(index + 1, child):</span><br><span class="line">                        return True</span><br><span class="line">            return False</span><br><span class="line"></span><br><span class="line">        return dfs(0, self.trieRoot)</span><br><span class="line"></span><br><span class="line"># Your WordDictionary object will be instantiated and called as such:</span><br><span class="line"># obj = WordDictionary()</span><br><span class="line"># obj.addWord(word)</span><br><span class="line"># param_2 = obj.search(word)</span><br></pre></td></tr></table></figure><h2 id="223-矩形面积"><a href="#223-矩形面积" class="headerlink" title="223. 矩形面积"></a>223. 矩形面积</h2><blockquote><p>学到一招 先减后加 避免溢出</p><p>重叠部分可以求投影的交集</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def computeArea(self, ax1: int, ay1: int, ax2: int, ay2: int, bx1: int, by1: int, bx2: int, by2: int) -&gt; int:</span><br><span class="line">        # 计算重叠面积边界</span><br><span class="line">        bothx1 = max(ax1,bx1)</span><br><span class="line">        bothx2 = min(ax2,bx2)</span><br><span class="line"></span><br><span class="line">        bothy1 = max(ay1,by1)</span><br><span class="line">        bothy2 = min(ay2,by2)</span><br><span class="line">        # 计算重叠面积</span><br><span class="line">        both_area = 0</span><br><span class="line">        if bothx1&lt;bothx2 and bothy1&lt;bothy2:</span><br><span class="line">            both_area = abs(bothx2-bothx1)*abs(bothy2-bothy1)</span><br><span class="line"></span><br><span class="line">        # 先减后加 避免溢出</span><br><span class="line">        return abs(ax1-ax2)*abs(ay1-ay2) - both_area + abs(bx1-bx2)*abs(by1-by2)</span><br><span class="line">        </span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="230-二叉搜索树中第K小的元素"><a href="#230-二叉搜索树中第K小的元素" class="headerlink" title="230. 二叉搜索树中第K小的元素"></a>230. 二叉搜索树中第K小的元素</h2><blockquote><p>二叉搜索树性质：</p><p>左子树小于根节点 右子树大于根节点。</p><p>二叉搜索树的中序遍历是有序的。</p></blockquote><ul><li>pop()函数默认pop最后一个元素</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># Definition for a binary tree node.</span><br><span class="line"># class TreeNode:</span><br><span class="line">#     def __init__(self, val=0, left=None, right=None):</span><br><span class="line">#         self.val = val</span><br><span class="line">#         self.left = left</span><br><span class="line">#         self.right = right</span><br><span class="line">class Solution:</span><br><span class="line">    def kthSmallest(self, root: TreeNode, k: int) -&gt; int:</span><br><span class="line">        stack = []</span><br><span class="line">        # 左根右</span><br><span class="line">        while root or stack:</span><br><span class="line">            while root:</span><br><span class="line">                # 一直遍历到左子树叶子节点 即为最小值 </span><br><span class="line">                stack.append(root)</span><br><span class="line">                root = root.left</span><br><span class="line">            root = stack.pop()</span><br><span class="line">            k -= 1 # 出栈的次序为最小值次序</span><br><span class="line">            if k == 0:</span><br><span class="line">                return root.val</span><br><span class="line">            root = root.right</span><br><span class="line">            </span><br></pre></td></tr></table></figure><h2 id="240-搜索二维矩阵-II"><a href="#240-搜索二维矩阵-II" class="headerlink" title="240. 搜索二维矩阵 II"></a>240. 搜索二维矩阵 II</h2><blockquote><p>两种解法 从右上角搜索还是比较巧妙的！</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def searchMatrix(self, matrix: List[List[int]], target: int) -&gt; bool:</span><br><span class="line">        # # 先行搜索 找到最接近target 的值</span><br><span class="line">        # ans_row=[]</span><br><span class="line">        # for row in matrix:</span><br><span class="line">        #     for i in row:</span><br><span class="line">        #         if i == target:</span><br><span class="line">        #             return True</span><br><span class="line">        #         elif i &gt; target:</span><br><span class="line">        #             break</span><br><span class="line">        #         else:</span><br><span class="line">        #             ans_row = matrix.index(row)</span><br><span class="line">        # print(ans_row)</span><br><span class="line">        # return 0 </span><br><span class="line">        # 解法2 右上角搜索 大于target说明当前列全部大于 向左移动 小于，说明当前行全部小于 向下移动（因为在最右上角）</span><br><span class="line">        m,n=len(matrix),len(matrix[0])</span><br><span class="line">        x,y=0,n-1</span><br><span class="line">        while x&lt;m and y&gt;=0 :</span><br><span class="line">            if matrix[x][y]==target:</span><br><span class="line">                return True</span><br><span class="line">            elif matrix[x][y] &gt;target:</span><br><span class="line">                y-=1</span><br><span class="line">            elif matrix[x][y]&lt;target:</span><br><span class="line">                x+=1</span><br><span class="line">        return False</span><br></pre></td></tr></table></figure><h2 id="319-灯泡开关"><a href="#319-灯泡开关" class="headerlink" title="319. 灯泡开关"></a>319. 灯泡开关</h2><blockquote><p>脑筋急转弯 降维打击</p><p>如果我们将所有的灯泡从左到右依次编号为1,2,3…n 会发现第i次只对i的倍数进行切换状态</p><p>灯泡初始状态是灭的，偶数次切换也是灭的 奇数次切换变亮，所以求k的约数个数即可</p><p>但目的是判断奇偶性，所以只用判断k是不是完全平方数，如果是一定存在 k=x*x 即约数个数为奇数个</p><p>判断1,2,3…n中有几个完全平方数，对n开根号即可</p></blockquote><ul><li>sqrt(n + 0.5); sqrt是浮点数运算，强制类型转换为int会向下取整，因此增加0.5保证精度。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int bulbSwitch(int n) &#123;</span><br><span class="line">        return sqrt(n + 0.5);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="🌟430-扁平化多级双向链表"><a href="#🌟430-扁平化多级双向链表" class="headerlink" title="🌟430. 扁平化多级双向链表"></a>🌟430. 扁平化多级双向链表</h2><blockquote><p>参考的题解 再看看</p></blockquote><h2 id="447-回旋镖的数量"><a href="#447-回旋镖的数量" class="headerlink" title="447. 回旋镖的数量"></a>447. 回旋镖的数量</h2><blockquote><ul><li>hash_points = defaultdict(int)</li></ul><p>defaultdict，当字典里的key不存在但被查找时，返回的不是keyError而是一个工厂函数的默认值，比如list对应[ ]，str对应的是空字符串，set对应set( )，int对应0</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from collections import defaultdict</span><br><span class="line">from math import sqrt</span><br><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def numberOfBoomerangs(self, points: List[List[int]]) -&gt; int:</span><br><span class="line">        ans = 0</span><br><span class="line">        for p in points:</span><br><span class="line">            # defaultdict，当字典里的key不存在但被查找时，返回的不是keyError而是一个工厂函数的默认值，比如list对应[ ]，str对应的是空字符串，set对应set( )，int对应0</span><br><span class="line">            hash_points = defaultdict(int)</span><br><span class="line">            # 使用哈希表存储到该点距离相等的point个数</span><br><span class="line">            for temp_q in points:</span><br><span class="line">                dis = sqrt(pow((p[0] - temp_q[0]), 2) + pow((p[1] - temp_q[1]), 2))</span><br><span class="line">                hash_points[dis] += 1</span><br><span class="line">            for v in hash_points.values():</span><br><span class="line">                # 全排列</span><br><span class="line">                ans += v * (v - 1)</span><br><span class="line"></span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    points = [[0, 0], [1, 0], [2, 0]]</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.numberOfBoomerangs(points)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="437-路径总和-III"><a href="#437-路径总和-III" class="headerlink" title="437. 路径总和 III"></a>437. 路径总和 III</h2><blockquote><p>注意节点正负性 一定要遍历到最后</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># Definition for a binary tree node.</span><br><span class="line"># class TreeNode:</span><br><span class="line">#     def __init__(self, val=0, left=None, right=None):</span><br><span class="line">#         self.val = val</span><br><span class="line">#         self.left = left</span><br><span class="line">#         self.right = right</span><br><span class="line">class Solution:</span><br><span class="line">    def pathSum(self, root: TreeNode, targetSum: int) -&gt; int:</span><br><span class="line">        # 判断当前节点的路径数量</span><br><span class="line">        def get_sum(node, target):</span><br><span class="line">            # 采用递归的思路 遍历左子树和右子树</span><br><span class="line">            temp_ans=0</span><br><span class="line">            if node is None:</span><br><span class="line">                return 0</span><br><span class="line">            if node.val == target:</span><br><span class="line">                temp_ans+=1</span><br><span class="line">                # return temp_ans</span><br><span class="line">                # 不能直接return 因为节点有可能为负数</span><br><span class="line">            temp_ans+=get_sum(node.left, target - node.val)</span><br><span class="line">            temp_ans+=get_sum(node.right, target - node.val)</span><br><span class="line">            return temp_ans</span><br><span class="line">        if root is None:</span><br><span class="line">            return 0</span><br><span class="line">        # 寻找当前节点路径数量</span><br><span class="line">        ans = get_sum(root, targetSum)</span><br><span class="line">        # 寻找当前节点子树的路径数量</span><br><span class="line">        ans +=self.pathSum(root.left,targetSum)</span><br><span class="line">        ans +=self.pathSum(root.right,targetSum)</span><br><span class="line">        return ans</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="524-通过删除字母匹配到字典里最长单词"><a href="#524-通过删除字母匹配到字典里最长单词" class="headerlink" title="524. 通过删除字母匹配到字典里最长单词"></a>524. 通过删除字母匹配到字典里最长单词</h2><blockquote><p>匹配两个字符串 可以使用双指针的方法</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def findLongestWord(self, s: str, dictionary: List[str]) -&gt; str:</span><br><span class="line">        # 使用双指针实现字符串匹配</span><br><span class="line">        ans = &#x27;&#x27;</span><br><span class="line">        # 循环匹配字典中的字符串</span><br><span class="line">        for word in dictionary:</span><br><span class="line">            # 双指针</span><br><span class="line">            i, j = 0, 0</span><br><span class="line">            while i &lt; len(word) and j &lt; len(s):</span><br><span class="line">                # 在字符串s中寻找word 也就是说word中的每个字母都要在s中按顺序出现</span><br><span class="line">                if word[i] == s[j]:</span><br><span class="line">                    i += 1</span><br><span class="line">                j += 1</span><br><span class="line">            if i == len(word):</span><br><span class="line">                # 匹配成功 维护最长字串 长度相同 返回长度最长且 字典序 最小的字符串</span><br><span class="line">                if (len(word) &gt; len(ans)) or (len(word) == len(ans) and word &lt; ans):</span><br><span class="line">                    ans = word</span><br><span class="line"></span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    s = &quot;abpcplea&quot;</span><br><span class="line">    dictionary = [&quot;ale&quot;, &quot;apple&quot;, &quot;monkey&quot;, &quot;plea&quot;]</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.findLongestWord(s,dictionary)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="583-两个字符串的删除操作"><a href="#583-两个字符串的删除操作" class="headerlink" title="583. 两个字符串的删除操作"></a>583. 两个字符串的删除操作</h2><blockquote><p>值得注意的是 text[0:i-1]对应的dp数组位置为dp[i-1][j]</p><p>text 数组对应的字符下标从1开始</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def minDistance(self, word1: str, word2: str) -&gt; int:</span><br><span class="line">        m, n = len(word1), len(word2)</span><br><span class="line">        # dp[i][j] 表示word1[0:i] 和 word[0:j] 的最大公共子序列长度</span><br><span class="line">        dp = [[0] * (n + 1) for _ in range(m + 1)]</span><br><span class="line">        # print(dp)</span><br><span class="line">        for i in range(1, m + 1):</span><br><span class="line">            for j in range(1, n + 1):</span><br><span class="line">                # 当前位置字符串相同</span><br><span class="line">                if word1[i - 1] == word2[j - 1]:</span><br><span class="line">                    dp[i][j] = dp[i - 1][j - 1] + 1</span><br><span class="line">                else:</span><br><span class="line">                    # 当前位置字符串不相同 取当前位置  dp[i - 1][j] 和 dp[i][j - 1] 的最大值</span><br><span class="line">                    # 若text1[i-1] != text2[j-1]，也就是说两个字符串的最后一位不相等，那么字符串text1的[1,i]区间和字符串text2的[1,j]区间的最长公共子序列长度无法延长，因此f[i][j]就会继承f[i-1][j]与f[i][j-1]中的较大值</span><br><span class="line">                    # 值得注意的是 text[0:i-1]对应的dp数组位置为dp[i-1][j]</span><br><span class="line">                    dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])</span><br><span class="line"></span><br><span class="line">        lcs = dp[m][n]</span><br><span class="line">        return m - lcs + n - lcs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    word1 = &quot;sea&quot;</span><br><span class="line">    word2 = &quot;eata&quot;</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.minDistance(word1, word2)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="638-大礼包"><a href="#638-大礼包" class="headerlink" title="638. 大礼包"></a>638. 大礼包</h2><blockquote><p>使用了 lru_cache 参数必须可以使用hash值作为索引</p><ul><li><p>可哈希的元素：int、float、str、tuple、自定义的类的实例对象</p></li><li><p>不可哈希的元素：list、set、dict</p></li></ul></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">from functools import lru_cache</span><br><span class="line">class Solution:</span><br><span class="line">    def shoppingOffers(self, price: List[int], special: List[List[int]], needs: List[int]) -&gt; int:</span><br><span class="line">        # 价格 price</span><br><span class="line">        # 大礼包种类 special</span><br><span class="line">        # 总需求 need</span><br><span class="line"></span><br><span class="line">        # 1. 过滤掉 不优惠的大礼包组合</span><br><span class="line">        filter_sp=[]</span><br><span class="line">        for sp in special:</span><br><span class="line">            temp_sp=[]</span><br><span class="line">            for i in range(len(sp)-1):</span><br><span class="line">                temp_sp.append(sp[i]*price[i])</span><br><span class="line">            if sum(temp_sp)&gt;sp[-1]: # 比直接购买便宜</span><br><span class="line">                filter_sp.append(sp)</span><br><span class="line">        # 2.计算最优组合</span><br><span class="line">        @lru_cache(None)</span><br><span class="line">        # 缓存 加速重复计算</span><br><span class="line">        def dfs(cur_needs):</span><br><span class="line">            # 不购买任何大礼包，原价购买购物清单中的所有物品</span><br><span class="line">            min_price = sum(need * price[i] for i, need in enumerate(cur_needs))</span><br><span class="line">            for sp in filter_sp:</span><br><span class="line">                # 大礼包价格  </span><br><span class="line">                sp_price =sp[-1]</span><br><span class="line">                # 当前需求为 cur_needs 剩余需求为 next_needs</span><br><span class="line">                next_needs=[]</span><br><span class="line">                for good_index in range(len(price)):</span><br><span class="line">                    if sp[good_index]&gt;cur_needs[good_index]:</span><br><span class="line">                        # 不能购买超过需求的商品</span><br><span class="line">                        break</span><br><span class="line">                    next_needs.append(cur_needs[good_index]-sp[good_index])</span><br><span class="line">                if len(next_needs)==len(cur_needs): #大礼包可以购买 没有超出数量限制</span><br><span class="line">                    # 比较最优价格</span><br><span class="line">                    min_price=min(min_price,sp_price+dfs(tuple(next_needs)))</span><br><span class="line">            return min_price</span><br><span class="line"></span><br><span class="line">        return dfs(tuple(needs))</span><br><span class="line">        # 因为使用了 lru_cache 而list不能hash 所以必须转换为tuple</span><br></pre></td></tr></table></figure><h2 id="673-最长递增子序列的个数"><a href="#673-最长递增子序列的个数" class="headerlink" title="673. 最长递增子序列的个数"></a>673. 最长递增子序列的个数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line"></span><br><span class="line">    def findNumberOfLIS(self, nums: List[int]) -&gt; int:</span><br><span class="line"></span><br><span class="line">        # 使用动态规划 dp 数组存当前位置最长子序列长度</span><br><span class="line">        # cnt 数组存放当前位置最长子序列数量</span><br><span class="line">        # 状态转移方程 dp[i] = max(dp[j]) + 1) 且num[j]&lt;num[i]</span><br><span class="line">        max_len = 0</span><br><span class="line">        ans = 0</span><br><span class="line">        dp = [0] * len(nums)</span><br><span class="line">        cnt = [0] * len(nums)</span><br><span class="line">        # 遍历数组</span><br><span class="line">        for i, value in enumerate(nums):</span><br><span class="line">            dp[i] = 1</span><br><span class="line">            cnt[i] = 1</span><br><span class="line">            # 寻找当前位置的最长子序列</span><br><span class="line">            # 往历史最长子序列中加入nums[i]</span><br><span class="line">            # 相应的dp[i]+1 cnt[i]根据历史cnt[j]更新</span><br><span class="line"></span><br><span class="line">            for j in range(i):</span><br><span class="line">                if value &gt; nums[j]:</span><br><span class="line">                    if dp[j] + 1 &gt; dp[i]:</span><br><span class="line">                        dp[i] = dp[j] + 1</span><br><span class="line">                        cnt[i] = cnt[j]</span><br><span class="line">                    elif dp[j] + 1 == dp[i]:</span><br><span class="line">                        cnt[i] += cnt[j]</span><br><span class="line">            if dp[i] &gt; max_len:</span><br><span class="line">                # 更新数据</span><br><span class="line">                max_len = dp[i]</span><br><span class="line">                ans = cnt[i]</span><br><span class="line">            elif dp[i] == max_len:</span><br><span class="line">                # 答案为多有满足 dp[i] == max_len 的cnt[i]之和</span><br><span class="line">                ans += cnt[i]</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    board = [1, 3, 5, 4, 7]</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.findNumberOfLIS(board)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="678-有效的括号字符串"><a href="#678-有效的括号字符串" class="headerlink" title="678. 有效的括号字符串"></a>678. 有效的括号字符串</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def checkValidString(self, s: str) -&gt; bool:</span><br><span class="line">        # 堆栈模拟实现</span><br><span class="line">        left_stack = []</span><br><span class="line">        star_stack = []</span><br><span class="line">        for index, ch in enumerate(s):</span><br><span class="line">            # 遇到左括号 和 星号 分别入栈</span><br><span class="line">            # 存储下标 方便比较</span><br><span class="line">            if ch == &#x27;(&#x27;:</span><br><span class="line">                left_stack.append(index)</span><br><span class="line">            elif ch == &quot;*&quot;:</span><br><span class="line">                star_stack.append(index)</span><br><span class="line">            # 遇到右括号匹配</span><br><span class="line">            elif ch == &#x27;)&#x27;:</span><br><span class="line">                # 因为星号可以任意匹配 所以优先匹配左括号</span><br><span class="line">                if left_stack:</span><br><span class="line">                    left_stack.pop()</span><br><span class="line">                # 左括号不足的情况下使用星号匹配</span><br><span class="line">                elif star_stack:</span><br><span class="line">                    star_stack.pop()</span><br><span class="line">                # 都不能匹配则不满足有效的括号字符串</span><br><span class="line">                else:</span><br><span class="line">                    return False</span><br><span class="line"></span><br><span class="line">        # 遍历寻找右括号结束后 匹配左括号和星号</span><br><span class="line">        # 匹配时必须是右侧的星号和左侧的左括号的匹配</span><br><span class="line"></span><br><span class="line">        while left_stack:</span><br><span class="line">            # 星号消耗完了</span><br><span class="line">            if not star_stack:</span><br><span class="line">                return False</span><br><span class="line">            # 右侧星号消耗完了</span><br><span class="line">            elif left_stack[-1] &gt; star_stack[-1]:</span><br><span class="line">                return False</span><br><span class="line">            else:</span><br><span class="line">                left_stack.pop()</span><br><span class="line">                star_stack.pop()</span><br><span class="line">        return True</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    str = &quot;()()()((((()((()(()())(()))(())))((()((()())*(((())()))(()((())(((((((())()*)())((())*))))*)())()))&quot;</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.checkValidString(str)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="725-分隔链表"><a href="#725-分隔链表" class="headerlink" title="725. 分隔链表"></a>725. 分隔链表</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># Definition for singly-linked list.</span><br><span class="line"># class ListNode:</span><br><span class="line">#     def __init__(self, val=0, next=None):</span><br><span class="line">#         self.val = val</span><br><span class="line">#         self.next = next</span><br><span class="line">class Solution:</span><br><span class="line">    def splitListToParts(self, head: ListNode, k: int) -&gt; List[ListNode]:</span><br><span class="line">        print(head)</span><br><span class="line">        cur, l = head, 0</span><br><span class="line">        # 计算链表长度</span><br><span class="line">        while cur:</span><br><span class="line">            l += 1</span><br><span class="line">            cur = cur.next</span><br><span class="line">        # 均分 求余</span><br><span class="line">        each, remain = l // k, l % k</span><br><span class="line">        cur, ans, idx = head, [None] * k, 0</span><br><span class="line">        while cur:</span><br><span class="line">            ans[idx] = cur</span><br><span class="line">            # 使用last断开链表 last.next = None</span><br><span class="line">            last = None</span><br><span class="line">            # idx &lt; remain控制左侧数链表于右侧链表</span><br><span class="line">            for i in range(each + (idx &lt; remain)):</span><br><span class="line">                last = cur</span><br><span class="line">                cur = cur.next</span><br><span class="line">            idx += 1</span><br><span class="line">            last.next = None</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="1218-最长定差子序列"><a href="#1218-最长定差子序列" class="headerlink" title="1218. 最长定差子序列"></a>1218. 最长定差子序列</h2><blockquote><p>动态规划实现</p><p>从左到右遍历，计算以arr[i]为结尾的最长的等差子序列的长度。</p></blockquote><p>学到一招，vector的遍历 除了使用迭代器<code>for (vector&lt;int&gt;::iterator it=arr.begin();it!=arr.end();it++)</code>    ,还可以简写<code>for (int v: arr)</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    int longestSubsequence(vector&lt;int&gt;&amp; arr, int difference) &#123;</span><br><span class="line">            // 动态规划 </span><br><span class="line">            // unordered_map存储dp值</span><br><span class="line">            unordered_map&lt;int, int&gt; dp;</span><br><span class="line">            int ans =0;</span><br><span class="line">            for (vector&lt;int&gt;::iterator it=arr.begin();it!=arr.end();it++)</span><br><span class="line">            &#123;</span><br><span class="line">                dp[*it]=dp[*it-difference]+1;</span><br><span class="line">                // 以当前数值为结尾的等差序列长度</span><br><span class="line">                ans = max(ans,dp[*it]);</span><br><span class="line">            &#125;</span><br><span class="line">            return ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="1894-找到需要补充粉笔的学生编号"><a href="#1894-找到需要补充粉笔的学生编号" class="headerlink" title="1894. 找到需要补充粉笔的学生编号"></a>1894. 找到需要补充粉笔的学生编号</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def chalkReplacer(self, chalk: List[int], k: int) -&gt; int:</span><br><span class="line">        # 判断第几轮需要补充粉笔</span><br><span class="line">        signal_loop = sum(chalk)</span><br><span class="line">        if (k % signal_loop) == 0:</span><br><span class="line">            return 0</span><br><span class="line">        else:</span><br><span class="line">            chalk_loop = k // signal_loop</span><br><span class="line">            k -= chalk_loop * signal_loop</span><br><span class="line">            # 找出粉笔不足的下标</span><br><span class="line">            # 重整数组 计算当前位置需要累计消耗粉笔数量</span><br><span class="line">            for i in range(len(chalk)):</span><br><span class="line">                if chalk[i] &gt; k:</span><br><span class="line">                    return i</span><br><span class="line">                else:</span><br><span class="line">                    k -= chalk[i]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    chalk = [3, 4, 1, 2]</span><br><span class="line">    k = 25</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.chalkReplacer(chalk, k)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="困难"><a href="#困难" class="headerlink" title="困难"></a>困难</h1><h2 id="68-文本左右对齐"><a href="#68-文本左右对齐" class="headerlink" title="68. 文本左右对齐"></a>68. 文本左右对齐</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def fullJustify(self, words: List[str], maxWidth: int) -&gt; List[str]:</span><br><span class="line">        # 使得每行单词接近maxWidth</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        每个单词之间至少有一个空格</span><br><span class="line">        特殊情况：</span><br><span class="line">        1.单词数大于1时 左侧空格数多于右侧</span><br><span class="line">        2.当前行只有一个单词时 居左对齐 空格补充长度</span><br><span class="line">        3.最后一行 居左对齐 每个单词之间1个空格 末尾空格补充长度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        totalLineWords = []</span><br><span class="line">        signalLineWord = []</span><br><span class="line"></span><br><span class="line">        for temp_len in words:</span><br><span class="line">            if len(temp_len) + self.get_sum(signalLineWord) + len(signalLineWord) &lt;= maxWidth:</span><br><span class="line">                signalLineWord.append(temp_len)</span><br><span class="line">                # print(signalLineWord)</span><br><span class="line">            else:</span><br><span class="line">                totalLineWords.append(signalLineWord)</span><br><span class="line">                signalLineWord = [temp_len]</span><br><span class="line">        totalLineWords.append(signalLineWord)</span><br><span class="line">        ans = self.put_blank(totalLineWords, maxWidth)</span><br><span class="line">        print(ans)</span><br><span class="line">        for lens in ans:</span><br><span class="line">            print(len(lens))</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line">    # 得到单词总长度</span><br><span class="line">    def get_sum(self, word_lsits: List[str]):</span><br><span class="line">        # 统计每个单词长度</span><br><span class="line">        word_len = [len(i) for i in word_lsits]</span><br><span class="line">        return sum(word_len)</span><br><span class="line"></span><br><span class="line">    # 填充空格</span><br><span class="line">    def put_blank(self, totalLineWords: List[List[str]], maxWidth: int):</span><br><span class="line">        # print(totalLineWords[:-1])</span><br><span class="line">        ans = []</span><br><span class="line">        for line in totalLineWords[:-1]:</span><br><span class="line">            if len(line) == 1:</span><br><span class="line">                ans.append(line[0] + self.insert_blank(maxWidth - len(line[0])))</span><br><span class="line">            else:</span><br><span class="line">                # 计算平均可插入空格</span><br><span class="line">                temp_sum_word = self.get_sum(line)</span><br><span class="line">                mean_blank = int((maxWidth - temp_sum_word) / (len(line) - 1))</span><br><span class="line">                # 计算从左到右的空格数</span><br><span class="line">                mod_blank = (maxWidth - temp_sum_word) % (len(line) - 1)</span><br><span class="line">                # print(temp_sum_word)</span><br><span class="line">                # print(temp_blank, mod_blank)</span><br><span class="line">                # 填充空格</span><br><span class="line">                temp_str = &#x27;&#x27;</span><br><span class="line">                temp_word_line = line[:-1]</span><br><span class="line">                # mean</span><br><span class="line">                for word_index in range(len(line[:-1])):</span><br><span class="line">                    temp_word_line[word_index] = line[:-1][word_index] + self.insert_blank(mean_blank)</span><br><span class="line">                # mod</span><br><span class="line">                for index in range(mod_blank):</span><br><span class="line">                    temp_word_line[index] += &#x27; &#x27;</span><br><span class="line">                # str</span><br><span class="line">                for word in temp_word_line:</span><br><span class="line">                    temp_str += word</span><br><span class="line">                temp_str += line[-1]</span><br><span class="line">                ans.append(temp_str)</span><br><span class="line">        # 最后一行</span><br><span class="line">        if len(totalLineWords[-1]) == 1:</span><br><span class="line">            ans.append(totalLineWords[-1][0] + self.insert_blank(maxWidth - len(totalLineWords[-1][0])))</span><br><span class="line">        else:</span><br><span class="line">            temp_str = &#x27;&#x27;</span><br><span class="line">            for word in totalLineWords[-1][:-1]:</span><br><span class="line">                temp_str += word + &#x27; &#x27;</span><br><span class="line">            temp_str += totalLineWords[-1][-1]</span><br><span class="line">            ans.append(temp_str + self.insert_blank(maxWidth - len(temp_str)))</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line">    def insert_blank(self, num: int):</span><br><span class="line">        return &#x27; &#x27; * num</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    words = [&quot;What&quot;, &quot;must&quot;, &quot;be&quot;, &quot;acknowledgment&quot;, &quot;shall&quot;, &quot;be&quot;]</span><br><span class="line">    maxWidth = 16</span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.fullJustify(words, maxWidth)</span><br></pre></td></tr></table></figure><h2 id="🌟212-单词搜索-II"><a href="#🌟212-单词搜索-II" class="headerlink" title="🌟212. 单词搜索 II"></a>🌟212. 单词搜索 II</h2><blockquote><p>有点难 暂时不看</p></blockquote><h2 id="282-给表达式添加运算符"><a href="#282-给表达式添加运算符" class="headerlink" title="282. 给表达式添加运算符"></a>282. 给表达式添加运算符</h2><blockquote><p>官方题解比较巧妙 后缀表达式可以解决带括号的</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def addOperators(self, num: str, target: int) -&gt; List[str]:</span><br><span class="line">        num_len = len(num)</span><br><span class="line">        ans = []</span><br><span class="line"></span><br><span class="line">        # 递归函数</span><br><span class="line"></span><br><span class="line">        def backtrack(expr, loc, res, mul):</span><br><span class="line">            &quot;&quot;&quot;</span><br><span class="line">            :param expr: 当前构造的表达式</span><br><span class="line">            :param loc: 当前枚举到的字符串位置</span><br><span class="line">            :param res: 当前表达式的计算结果</span><br><span class="line">            :param mul: 最后一个连乘表达式的计算结果 因为乘法的优先级高 下一步计算时 如果为乘法 应该为res-mul+mul*new_num</span><br><span class="line">            :return: null</span><br><span class="line">            &quot;&quot;&quot;</span><br><span class="line">            if loc == num_len:</span><br><span class="line">                if target == res:</span><br><span class="line">                    ans.append(&#x27;&#x27;.join(expr))</span><br><span class="line">                return</span><br><span class="line">                # 未达到最大长度 继续递归寻找可能的字符串</span><br><span class="line">            signIndex = len(expr)  # 符号位</span><br><span class="line">            if loc &gt; 0:</span><br><span class="line">                expr.append(&#x27;&#x27;)  # 符号位占位</span><br><span class="line">            temp_num = 0  # 连续的数字</span><br><span class="line">            for j in range(loc, num_len):</span><br><span class="line">                # 去除前导0 即第一位不能是0</span><br><span class="line">                if j &gt; loc and num[loc] == &#x27;0&#x27;:</span><br><span class="line">                    break</span><br><span class="line">                temp_num = temp_num * 10 + int(num[j])</span><br><span class="line">                expr.append(num[j])</span><br><span class="line">                # 判断符号的情况</span><br><span class="line">                if loc == 0:</span><br><span class="line">                    backtrack(expr, j + 1, temp_num, temp_num)</span><br><span class="line">                else:</span><br><span class="line">                    expr[signIndex] = &#x27;+&#x27;</span><br><span class="line">                    backtrack(expr, j + 1, res + temp_num, temp_num)</span><br><span class="line">                    expr[signIndex] = &#x27;-&#x27;</span><br><span class="line">                    backtrack(expr, j + 1, res - temp_num, -temp_num)</span><br><span class="line">                    expr[signIndex] = &#x27;*&#x27;</span><br><span class="line">                    backtrack(expr, j + 1, res - mul + mul * temp_num, mul * temp_num)</span><br><span class="line">            del expr[signIndex:]  # 清除计算多余的字符串</span><br><span class="line"></span><br><span class="line">        backtrack([], 0, 0, 0)</span><br><span class="line">        return ans</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    num = &quot;123&quot;</span><br><span class="line">    target = 6</span><br><span class="line"></span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.addOperators(num, target)</span><br><span class="line">    print(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="301-删除无效的括号"><a href="#301-删除无效的括号" class="headerlink" title="301. 删除无效的括号"></a>301. 删除无效的括号</h2><blockquote><p>暂时不做</p></blockquote><h2 id="352-将数据流变为多个不相交区间"><a href="#352-将数据流变为多个不相交区间" class="headerlink" title="352. 将数据流变为多个不相交区间"></a>352. 将数据流变为多个不相交区间</h2><blockquote><p>说实话 题目给的示例没看懂</p><p>看了官方题解后发现这是一个区间问题 <a href="https://leetcode-cn.com/problems/data-stream-as-disjoint-intervals/solution/jiang-shu-ju-liu-bian-wei-duo-ge-bu-xian-hm1r/">https://leetcode-cn.com/problems/data-stream-as-disjoint-intervals/solution/jiang-shu-ju-liu-bian-wei-duo-ge-bu-xian-hm1r/</a></p><p>使用<strong>有序映射</strong>支持查询「最大的比某个元素小的键」以及「最小的比某个元素大的键」这两个操作。</p></blockquote><p>题目有点难，先学学bisect模块吧，用在二分搜索。</p><h2 id="502-IPO"><a href="#502-IPO" class="headerlink" title="502. IPO"></a>502. IPO</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">from heapq import heappush, heappop</span><br><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def findMaximizedCapital(self, k: int, w: int, profits: List[int], capital: List[int]) -&gt; int:</span><br><span class="line">        # 收益肯定比投资大 所以当 当前资本可以完成耗资最大的项目时 所获利润一定足够完成剩余项目 因此从项目中选择k个利润最大的项目完成即可</span><br><span class="line">        if w &gt;= max(capital):</span><br><span class="line">            return w + sum(nlargest(k, profits))</span><br><span class="line">        #  nlargest(k,list) nsmallest() 找出集合中最大或者最小的k个元素</span><br><span class="line">        n = len(profits)</span><br><span class="line">        # 已完成项目数</span><br><span class="line">        curr = 0</span><br><span class="line">        # 将投资成本和利润绑定</span><br><span class="line">        arr = [(capital[i], profits[i]) for i in range(n)]</span><br><span class="line">        # 按从小到大的顺序排序</span><br><span class="line">        arr.sort(key=lambda x: x[0])</span><br><span class="line">        print(arr)</span><br><span class="line">        pq = []</span><br><span class="line">        for _ in range(k):</span><br><span class="line">            while curr &lt; n and arr[curr][0] &lt;= w:</span><br><span class="line">                # 成本充足的情况下 将利润压入大根堆中</span><br><span class="line">                heappush(pq, -arr[curr][1])</span><br><span class="line">                curr += 1</span><br><span class="line">            print(pq)</span><br><span class="line">            if pq:</span><br><span class="line">                # 取相反数 相加</span><br><span class="line">                w -= heappop(pq)</span><br><span class="line">            else:</span><br><span class="line">                break</span><br><span class="line"></span><br><span class="line">        return w</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    k = 3</span><br><span class="line">    w = 0</span><br><span class="line">    profits = [1, 2, 3]  # 纯利润</span><br><span class="line">    capital = [0, 1, 2]  # 投资最小资本</span><br><span class="line">    f = Solution()</span><br><span class="line">    b = f.findMaximizedCapital(k, w, profits, capital)</span><br></pre></td></tr></table></figure><h2 id="🌟600-不含连续1的非负整数"><a href="#🌟600-不含连续1的非负整数" class="headerlink" title="🌟600. 不含连续1的非负整数"></a>🌟600. 不含连续1的非负整数</h2><blockquote><p>题解：<a href="https://leetcode-cn.com/problems/non-negative-integers-without-consecutive-ones/solution/suan-fa-xiao-ai-wo-lai-gei-ni-jie-shi-qi-4nh4/">https://leetcode-cn.com/problems/non-negative-integers-without-consecutive-ones/solution/suan-fa-xiao-ai-wo-lai-gei-ni-jie-shi-qi-4nh4/</a></p></blockquote><p><em>太难了慢慢攻克</em></p>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo配置</title>
      <link href="/2021/12/30/hexo%E9%85%8D%E7%BD%AE/"/>
      <url>/2021/12/30/hexo%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="hexo配置"><a href="#hexo配置" class="headerlink" title="hexo配置"></a>hexo配置</h1><h2 id="正确的package-json"><a href="#正确的package-json" class="headerlink" title="正确的package.json"></a>正确的package.json</h2><blockquote><p>主要解决 mathjax 公式显示bug</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;hexo-site&quot;,</span><br><span class="line">  &quot;version&quot;: &quot;0.0.0&quot;,</span><br><span class="line">  &quot;private&quot;: true,</span><br><span class="line">  &quot;scripts&quot;: &#123;</span><br><span class="line">    &quot;build&quot;: &quot;hexo generate&quot;,</span><br><span class="line">    &quot;clean&quot;: &quot;hexo clean&quot;,</span><br><span class="line">    &quot;deploy&quot;: &quot;hexo deploy&quot;,</span><br><span class="line">    &quot;server&quot;: &quot;hexo server&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hexo&quot;: &#123;</span><br><span class="line">    &quot;version&quot;: &quot;6.0.0&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dependencies&quot;: &#123;</span><br><span class="line">    &quot;hexo&quot;: &quot;^6.0.0&quot;,</span><br><span class="line">    &quot;hexo-generator-archive&quot;: &quot;^1.0.0&quot;,</span><br><span class="line">    &quot;hexo-generator-category&quot;: &quot;^1.0.0&quot;,</span><br><span class="line">    &quot;hexo-generator-index&quot;: &quot;^2.0.0&quot;,</span><br><span class="line">    &quot;hexo-generator-search&quot;: &quot;^2.4.3&quot;,</span><br><span class="line">    &quot;hexo-generator-tag&quot;: &quot;^1.0.0&quot;,</span><br><span class="line">    &quot;hexo-renderer-ejs&quot;: &quot;^2.0.0&quot;,</span><br><span class="line">    &quot;hexo-renderer-kramed&quot;: &quot;^0.1.4&quot;,</span><br><span class="line">    &quot;hexo-renderer-pug&quot;: &quot;^2.0.0&quot;,</span><br><span class="line">    &quot;hexo-renderer-stylus&quot;: &quot;^2.0.1&quot;,</span><br><span class="line">    &quot;hexo-server&quot;: &quot;^2.0.0&quot;,</span><br><span class="line">    &quot;hexo-theme-landscape&quot;: &quot;^0.0.3&quot;,</span><br><span class="line">    &quot;hexo-wordcount&quot;: &quot;^6.0.1&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="GitHub-443错误"><a href="#GitHub-443错误" class="headerlink" title="GitHub 443错误"></a>GitHub 443错误</h2><p>OpenSSL SSL_connect: Connection was reset in connection to github.com:443</p><ul><li><p>方法一</p><p>检查VPN端口号，并替换1087</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy 127.0.0.1:1087</span><br><span class="line">git config --global https.proxy 127.0.0.1:1087</span><br></pre></td></tr></table></figure><p>​    若配置过，撤销上述配置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global --unset http.proxy</span><br><span class="line">git config --global --unset https.proxy</span><br></pre></td></tr></table></figure><blockquote><p>下面是几个常用的git配置查看命令：</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy #查看git的http代理配置</span><br><span class="line">git config --global https.proxy #查看git的https代理配置</span><br><span class="line">git config --global -l #查看git的所有配置</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最优化方法</title>
      <link href="/2021/12/30/optimal_method/"/>
      <url>/2021/12/30/optimal_method/</url>
      
        <content type="html"><![CDATA[<h1 id="最优化方法"><a href="#最优化方法" class="headerlink" title="最优化方法"></a>最优化方法</h1><h2 id="极小点判定条件"><a href="#极小点判定条件" class="headerlink" title="极小点判定条件"></a>极小点判定条件</h2><p>凸函数：Hessen矩阵 半正定 （正定时为严格凸函数）</p><p>凹函数：Hessen矩阵 半负定</p><h2 id="线性规划"><a href="#线性规划" class="headerlink" title="线性规划"></a>线性规划</h2><p><strong>线性规划</strong>的目标函数<strong>等值面</strong>是<strong>平行平面</strong>。</p><h4 id="标准线性规划"><a href="#标准线性规划" class="headerlink" title="标准线性规划"></a>标准线性规划</h4><blockquote><p>主约束都是右端项非负的等式约束</p></blockquote><p>结果要不是 最优解 要不是 解无界。（<strong>不会出现 无解</strong>）</p><p>标准线性规划有容许解，则必有基本容许解。</p><p>若有最优解，则必有最优基本容许解。</p><h4 id="典范线性规划"><a href="#典范线性规划" class="headerlink" title="典范线性规划"></a>典范线性规划</h4><p>I阶段线性规划或存在最优基本容许解(W=0)，或 原问题无解(W&gt;0)。</p><p>典范线性规划 或者 解无界 或者 有最优解 <strong>不会出现无解</strong>的情况。</p><ul><li><p>第一阶段</p><p>解辅助线性规划，目的是求标准线性规划 主约束的一个 G-J方程组</p></li><li><p>第二阶段</p><p>解标准线性规划，即解原线性规划</p></li></ul><h3 id="单纯形"><a href="#单纯形" class="headerlink" title="单纯形"></a>单纯形</h3><blockquote><p>本质上是解典范线性规划的算法</p><p>根本目标是让人工变量全部退基</p><p>具有有限终止性</p></blockquote><p>自由变量    $x_1 = x_2 -x_3$</p><h4 id="最优性检验"><a href="#最优性检验" class="headerlink" title="最优性检验"></a>最优性检验</h4><p>最大判别数$\delta _l$</p><ul><li>最优解  $\delta _l \leq 0$</li><li>无界  $\delta _l \gt 0 $  $a_l \leq0$    异号</li><li>无解 <strong>第一阶段</strong> 最优值 $w&gt;0$</li></ul><blockquote><p> $\delta _l \gt 0 $  $a_l \nleq0 $    可以继续迭代，典范线性规划不会出现无解的情况。</p></blockquote><h4 id="特殊情况"><a href="#特殊情况" class="headerlink" title="特殊情况"></a>特殊情况</h4><ul><li>若所有判别数都 &lt;0 但是人工变量没有退基，任选一个非人工变量系数的<strong>非0</strong>元素作为主元，在进行一次换基运算，得到标准线性规划主约束的G-J方程组。</li><li>若基变量中有人工变量，但非人工变量变量的系数都为0，b也为0，可以直接划掉，进入第二阶段。</li><li>没有约束的变量是 自由变量，变为$x_1 = x_2 -x_3$</li></ul><h3 id="直线搜索"><a href="#直线搜索" class="headerlink" title="直线搜索"></a>直线搜索</h3><ul><li>区间收缩法（黄金分割法 用于任何单谷函数求极小值）</li><li>函数逼近法（抛物线插值法 适用于连续单谷函数）</li></ul><h3 id="最速下降法"><a href="#最速下降法" class="headerlink" title="最速下降法"></a>最速下降法</h3><blockquote><p>不具备二次终止性，线性收敛算法，无限次迭代。</p><p>如果初始点选在<strong>椭球等值面（椭圆等值线）</strong>上，<strong>迭代一次</strong>就会得到极小点，否则会无限次迭代。</p></blockquote><p>优点：直观 简单</p><p>缺点：收敛速度慢 实用性差 锯齿现象</p><p>基本思想：在点$x_k$处沿负梯度方向$p_k$进行直线搜索。</p><p>直线搜索的性质：$g_{k+1}·g_k = 0$         相邻迭代点梯度正交。</p><p>锯齿现象：最速下降法的迭代点在向极小点靠近的过程中，走的是曲折的路线，后一次搜索方向$p_{k+1}$与前一次搜索方向$p_k$垂直，称之为锯齿现象。</p><h3 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h3><p>基本思想：从$x<em>k$到$x</em>{k+1}$的迭代过程中，在点$x_k$处对$f(x)$按Taylor级数展开到第三项，解出极小点。当目标函数$f(x)$是正定二次函数的时候，牛顿法迭代一次就会得到最优解。</p><p>几何解释：在函数$f(x)$过点$x_k$的等值面方程，用一个与曲面最密切的二次曲面代替他。</p><p><strong>Taylor展开</strong></p><script type="math/tex; mode=display">f(x)=f(x_k)+g_x^T(x-x_k)+\frac{1}{2}(x-x_k)^TG_{x_k}(x-x_k)</script><h4 id="修正牛顿"><a href="#修正牛顿" class="headerlink" title="修正牛顿"></a>修正牛顿</h4><p>​        对于<strong>非正定二次函数</strong>，牛顿法一般不会有限步终止，原因：</p><p><strong>1.Hesse矩阵奇异</strong></p><script type="math/tex; mode=display">p_k = -g_k</script><p>直线搜索</p><script type="math/tex; mode=display">x_{k+1}=x_k+t_k·p_k</script><p><strong>2.Hesse矩阵可逆</strong></p><ul><li><p>牛顿方向不存在（垂直）</p><pre><code>1.    $p_k = -g_k$1.    直线搜索</code></pre></li><li><p>步长为1不合适（下降方向）</p><ol><li>直线搜索</li></ol></li><li>牛顿方向不是下降方向（上升方向）<ol><li>$p_k = G_k^{-1}·g_k$</li><li>直线搜索</li></ol></li></ul><h3 id="共轭方向法"><a href="#共轭方向法" class="headerlink" title="共轭方向法"></a>共轭方向法</h3><p>优点：<strong>克服了最速下降法的锯齿现象</strong>，从而提高了收敛速度，迭代公式简单，不必计算目标函数的二阶导数。与牛顿法相比，减少了计算量和存储量。</p><p>二次终止性：对于n元正定二次函数，从任意点出发，顺次沿着n个共轭方向作最多n次直线搜索，就可以求得目标函数的极小点。</p><p>共轭梯度法：初始共轭梯度向量$p<em>0$恰好取为初始点$x_0$的负梯度$-g_0$，而其余共轭向量$p_k$，由第$k$个迭代点$x_k$处的负梯度$-g_k$与已经得到的向量$p</em>{k-1}$的线性组合来确定，那么这个共轭方向法就称为共轭梯度法。</p><h3 id="DFP算法"><a href="#DFP算法" class="headerlink" title="DFP算法"></a>DFP算法</h3><p>性质：若初始矩阵$H_0$对称正定，则$H_k$中每一个都对称正定。</p><h3 id="步长加速法"><a href="#步长加速法" class="headerlink" title="步长加速法"></a>步长加速法</h3><p>不要求目标函数可导或可微。</p><p>基本思想：步长加速法主要由交替进行的“探测搜索”和“模式移动”组成。</p><ul><li>探测搜索：为了<strong>寻找当前迭代点的下降方向</strong></li><li>模式移动：沿着下降方向<strong>寻找新的迭代点</strong></li></ul><p>探测的出发点：<strong>参考点</strong></p><p>周围比他更好的点：<strong>基点</strong></p><p>得到的下降方向：<strong>模式</strong></p><p>从基点沿模式作直线搜索：<strong>模式移动</strong></p><p>I型探测：</p><blockquote><p> <strong>在基点周围构造一个模式</strong></p><p>失败缩小步长</p></blockquote><p>II型探测：</p><blockquote><p> <strong>判别上次的模式移动是否成功</strong></p><p>失败撤销上次模式移动，将上次的基点作为参考点，开始I型探测</p><p>失败原因：前一次模式移动过大，离开了极小点所在区域</p></blockquote><h3 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h3><p>$y=x_1t+x_2$</p><h4 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h4><script type="math/tex; mode=display">min ||Ax-b||^2</script><script type="math/tex; mode=display">min s(x_1,x_2) = \sum(x_1t+x_2-y)^2</script><p>等价于解 法方程组</p><script type="math/tex; mode=display">A^TAX=A^Tb</script><p>最优解：$x^* = (A^TA)^{-1}A^Tb$</p><p>检验</p><h2 id="约束规划问题"><a href="#约束规划问题" class="headerlink" title="约束规划问题"></a>约束规划问题</h2><h3 id="等式约束"><a href="#等式约束" class="headerlink" title="等式约束"></a>等式约束</h3><ul><li>Lagrange函数</li></ul><p>​        Lagrange乘子，使得求解等式约束问题，等价于求解无约束问题。</p><p>几何表示：</p><p>​        拉格朗日函数关于x的Hesse矩阵在$x^<em>$的<strong>约束曲面切平面的交集上正定</strong>，则$x^</em>$是等式约束问题的严格局部极小点。</p><h3 id="不等式约束"><a href="#不等式约束" class="headerlink" title="不等式约束"></a>不等式约束</h3><p>不等式约束关于容许集的任意内点都是不起作用的约束，只有容许集的边界点才能使某个或某些不等式约束变成起作用约束。</p><p>容许方向向量：</p><ul><li>对于起作用的约束</li></ul><script type="math/tex; mode=display">\nabla s_i(x)^Tp>0</script><h4 id="几何最优性条件"><a href="#几何最优性条件" class="headerlink" title="几何最优性条件"></a>几何最优性条件</h4><p>判断x* 是否为局部极小点：</p><p>​        若$x^<em>$是局部最优点，则在点$x^</em>$处的<strong>容许方向锥和下降方向锥的交集是空集</strong>。</p><script type="math/tex; mode=display">\nabla s_i(x)^Tp>0 \\\nabla f(x)^Tp<0</script><h4 id="K-T条件"><a href="#K-T条件" class="headerlink" title="K-T条件"></a>K-T条件</h4><p>几何表示：</p><p>​        若$x^<em>$是最优点，则目标函数在该点的<strong>梯度</strong>必位于由<em>*起作用约束函数的梯度张成的凸锥中</em></em>。</p><p>凸规划问题的<strong>最优性</strong>充分条件：</p><p>​        $f$是可微凸函数，$s_i$是可微凹函数，$h_i$是线性函数，如果$x^*$是K-T点，那么是全局最优点。</p><p>$u_0$不为0的充要条件：</p><p>​        在$x^*$处，起作用的约束函数，梯度全都线性无关。</p><h3 id="Z-容许方向法"><a href="#Z-容许方向法" class="headerlink" title="Z-容许方向法"></a>Z-容许方向法</h3><p>终止条件：</p><ul><li>$x^*$为K-T点的充要条件：</li></ul><script type="math/tex; mode=display">\nabla f(x)^Tp^*=0</script><p>​        <strong>并且</strong>：A’ 和 C的行向量线性无关。</p><ul><li>继续迭代，仍然是一个下降方向向量</li></ul><script type="math/tex; mode=display">\nabla f(x)^Tp^*<0</script><ul><li>换点</li></ul><script type="math/tex; mode=display">\nabla f(x)^Tp^*>0</script><p>算法：</p><ul><li>确定当前迭代点的<strong>下降容许方向</strong></li><li>通过<strong>直线搜索</strong>确定下一个迭代点  （在下降容许方向作ls 最佳步长因子有上界）</li><li>判定新的迭代点是否为问题的解</li></ul><p>判断容许方向：</p><ul><li><p>非线性约束</p><p><strong>$s(x)$为起作用的约束</strong></p></li></ul><script type="math/tex; mode=display">\nabla s(x)^Tp>0</script><ul><li>线性约束</li></ul><script type="math/tex; mode=display">A'p \geq 0</script><script type="math/tex; mode=display">Cp=0</script><h3 id="外部罚函数法"><a href="#外部罚函数法" class="headerlink" title="外部罚函数法"></a>外部罚函数法</h3><p>惩罚策略：对容许点不予惩罚，对于非容许点给予无穷大的惩罚，将约束问题转化为无约束问题。</p><p>惩罚项特点：</p><ul><li>包含有取值越来越大的正因子 $\mu$</li><li>对于容许点，惩罚项取值为0，对于非容许点，惩罚项取值为正</li></ul><h3 id="H-乘子法"><a href="#H-乘子法" class="headerlink" title="H-乘子法"></a>H-乘子法</h3><blockquote><p>H-乘子法罚因子不必趋于无穷大，而外部罚函数的罚因子要趋于无穷大，本质是为了防止Hesse矩阵条件数变得越来越坏，导致在计算中，数值稳定性变得越来越差。</p><p>拉格朗日乘子$\lambda$与罚因子$\mu$取值无关，只要求$\mu$的取值保证乘子序列收敛即可，不然会有无数个拉格朗日乘子，这是不可能的。</p></blockquote><p><strong>改进：</strong></p><ul><li>解决了外部罚函数因罚因子增大，导致的数值计算不稳定的问题。</li></ul><blockquote><p>乘子法是针对外部罚函数法的改进，外部罚函数法<strong>随着罚因子的增大</strong>，增广目标函数的Hesse矩阵条件数变得越来越坏，导致在计算中，<strong>数值稳定性变得越来越差</strong>，难以精确求解。</p></blockquote><p>​        乘子法是在<strong>约束</strong>问题的<strong>Lagrange函数</strong>中加入相应的<strong>惩罚项</strong>，使得在求解无约束问题的时候，<strong>罚因子不必趋于无穷大</strong>就能得到约束问题的最优解，保证数值计算的稳定性。</p><h4 id="终止准则"><a href="#终止准则" class="headerlink" title="终止准则"></a>终止准则</h4><p>如果无约束问题的最优解$x^<em>$是原规划问题的<strong>容许点</strong>，那么也是原问题的<em>*最优解</em></em>。</p><p><strong>等式约束</strong></p><ul><li>罚因子$\mu$的作用</li></ul><p>​    a.  乘子序列${\lambda_k}$不收敛    ${\mu} &lt;\mu^*$</p><p>​    b. 收敛的慢        ${\mu}\geq \mu^*$但不够大</p><p>​    c. $\frac{h(x<em>k)}{h(x</em>{k-1})} \geq 1$     乘子序列${\lambda_k}$发散</p><p>​    d.$\frac{h(x<em>k)}{h(x</em>{k-1})}$介于$(0,1)$ 收敛，比值越小 ，收敛越快</p><p>终止准则：$h(x)=0$</p><p><strong>不等式约束</strong></p><script type="math/tex; mode=display">min\{s(x),\frac{v^k}{2u}\}=0 \\ h(x)=0</script><p>一般形式算法中的终止条件：（平方和开根号）</p><script type="math/tex; mode=display">\varphi_k=[\sum{(min\{s(x_k),\frac{v^k}{2\mu}\})^2}+\sum{h^2_i(x_k)}]^{1/2}</script><p>若$\varphi_k &lt; \epsilon$：终止</p><p>若$\frac{\varphi<em>k}{\varphi</em>{k-1}}\geq\theta$：放大罚因子 $\mu = c*\mu$，其中 $\theta \in (0,1)$，比值太大说明收敛效果不好，要放大罚因子。</p><blockquote><p>只有等式约束时 $\frac{h(x<em>k)}{h(x</em>{k-1})}\geq\theta$放大罚因子</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 单纯形法 </tag>
            
            <tag> 牛顿法 </tag>
            
            <tag> 共轭梯度法 </tag>
            
            <tag> DFP算法 </tag>
            
            <tag> 步长加速法 </tag>
            
            <tag> Z-容许方向法 </tag>
            
            <tag> H-乘子法 </tag>
            
            <tag> 罚函数法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CLeQA 模型实现</title>
      <link href="/2021/12/06/CLeQA%20%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0/"/>
      <url>/2021/12/06/CLeQA%20%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="CLeQA-模型实现"><a href="#CLeQA-模型实现" class="headerlink" title="CLeQA 模型实现"></a>CLeQA 模型实现</h1><h2 id="环境部署"><a href="#环境部署" class="headerlink" title="环境部署"></a>环境部署</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">conda create -n cleqa python=3.7</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch</span><br><span class="line"># 或者</span><br><span class="line">pip3 install torch torchvision torchaudio</span><br><span class="line"></span><br><span class="line">pip install transformers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># wbc</span><br><span class="line">pip3 install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/cu110/torch_stable.html</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation</title>
      <link href="/2021/11/14/Knowledge%20Enhanced%20Fine-Tuning%20for%20Better%20Handling%20Unseen%20Entities%20in%20Dialogue%20Generation/"/>
      <url>/2021/11/14/Knowledge%20Enhanced%20Fine-Tuning%20for%20Better%20Handling%20Unseen%20Entities%20in%20Dialogue%20Generation/</url>
      
        <content type="html"><![CDATA[<h1 id="Knowledge-Enhanced-Fine-Tuning-for-Better-Handling-Unseen-Entities-in-Dialogue-Generation"><a href="#Knowledge-Enhanced-Fine-Tuning-for-Better-Handling-Unseen-Entities-in-Dialogue-Generation" class="headerlink" title="Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation"></a>Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation</h1><blockquote><p>EMNLP2021</p><p>论文：<a href="https://arxiv.org/abs/2109.05487">https://arxiv.org/abs/2109.05487</a></p><p>代码：<a href="https://github.com/nealcly/ke-blender">https://github.com/nealcly/ke-blender</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>预训练模型在对话生成方面取得了很大的成功，但当输入包含预训练和微调数据集中没有出现的实体（unseen entity）时，它们的性能会显著下降。为了解决这个问题，现有的方法利用外部知识库来生成适当的响应。在现实场景中，实体可能不被知识库所包含，或者受到知识检索精度的影响。为了解决这个问题，本文不再引入知识库作为输入，而是只根据输入上下文，通过预测知识库中的信息来强迫模型学习更好的语义表示。</p><p>具体来说，在知识库的帮助下，引入了两个<strong>辅助训练</strong>目标：</p><ol><li>解释masked word：在给定上下文的情况下猜测masked entity 的含义。例如“I want to submit a paper to EMNLP”，一般情况下，有人可能不知道EMLNLP这个专业名词，但是可以根据上下文猜出，这是一个“会议”或者“期刊”。</li><li>生成上位词：根据上下文预测实体的上位词。</li></ol><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211114105612.png" alt="image-20211114105612902" style="zoom: 67%;" /></p><p>从1a中可以看出，不在知识库中的实体COVID-19虽然与SARS语意接近，但模型推理给出了完全不同的生成结果。</p><p>1b中引入外部知识库，但由于COVID-19是比较新的词语，在外部知识库中无法检索得到，生成结果仍然错误。</p><p>1c中引入两个子任务辅助训练，预测Masked wordv并预测SARS的上位词得到infection。测试未知实体COVID-19时模型效果有所提升。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>Knowledge Enhanced Blender (<strong>KE-Blender</strong>）</p><h3 id="TASK"><a href="#TASK" class="headerlink" title="TASK"></a>TASK</h3><h4 id="Blender"><a href="#Blender" class="headerlink" title="Blender"></a>Blender</h4><p>训练集结构：</p><script type="math/tex; mode=display">D^S=\{U^S_i, K^S_i, R^S_i\}|^{|L|}_{i=1}</script><p>其中$U^S_i, K^S_i, R^S_i$分别表示，对话上下文、从知识库中检索到的外部知识和回应。</p><script type="math/tex; mode=display">D_P= \{U^P, R^P\}</script><p>测试集没有外部知识，因为在推理过程中很难实时获取未见过词的相关背景知识。</p><p><strong>目标：</strong></p><p>$P(R|U; θ)$    with the help of     $K^S$</p><ul><li>外部知识 K 不作为输入。</li></ul><p>对话上下文：</p><script type="math/tex; mode=display">U = {x_1, x_2, . . . , x_T}</script><p>Response:</p><script type="math/tex; mode=display">R = {y_1, y_2, . . . , y_T}</script><p>句子的隐藏层表示：</p><script type="math/tex; mode=display">h^{enc}= TRANSFORMER\_ENCODER(U)</script><p>在解码器的第t步中，$h^{enc}$和先前的输出token $y_{1:t-1}$ 作为输入，使用注意生成表示：</p><script type="math/tex; mode=display">h^{dec}_t = TRANSFORMER\_DECODER(h^{enc}, y_{1:t−1})</script><p>y_t 的概率分布：</p><script type="math/tex; mode=display">p(y_t|U, y_{1:t−1}) = softmax(W^oh^{dec}_t + b^o)</script><blockquote><p> $W^o$ and $b^o$ are trainable parameters.</p></blockquote><p>使用标准最大似然估计优化模型参数 θ</p><p>Given a <strong>training pair (U, R)</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211114144959.png" alt="image-20211114144959771" style="zoom: 33%;" /></p><h4 id="Knowledge-Grounded-Blender-KG-Blender"><a href="#Knowledge-Grounded-Blender-KG-Blender" class="headerlink" title="Knowledge Grounded Blender(KG-Blender)"></a>Knowledge Grounded Blender(KG-Blender)</h4><p>KG-Blender中将 对话上下文<strong>U</strong> 和 外部知识 <strong>K</strong> 作为输入。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211114145656.png" alt="image-20211114145656180" style="zoom:33%;" /></p><p>与Blender相比，损失函数稍有不同：</p><p>Given a <strong>training pair (U, K, R)</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211114145839.png" alt="image-20211114145839095" style="zoom:33%;" /></p><blockquote><p>当知识不可用时，很难直接使用KG-Blender，因为KG-Blender 依赖知识作为输入。</p></blockquote><h4 id="Knowledge-Enhanced-Blender-KE-Blender"><a href="#Knowledge-Enhanced-Blender-KE-Blender" class="headerlink" title="Knowledge Enhanced Blender(KE-Blender)"></a>Knowledge Enhanced Blender(KE-Blender)</h4><p><strong>辅助任务详细介绍</strong></p><h5 id="Interpret-Masked-Word："><a href="#Interpret-Masked-Word：" class="headerlink" title="Interpret Masked Word："></a>Interpret Masked Word：</h5><p>根据上下文预测单词的定义，其中定义是从知识库获得的。</p><ol><li>mask proper nouns(专有名词) or pre-defined topic word for specific dataset.</li><li>找到masked word的外部知识。</li><li>然后，要求预先训练的模型通过使用被屏蔽的话语作为输入来恢复masked word定义。</li></ol><p>具体操作可以看下方公式：</p><p><strong>signal utterance</strong></p><script type="math/tex; mode=display">u_{l−1}= \{x_1, x_2, . . . , x_T\}</script><blockquote><p>$x_j$表示单词。</p></blockquote><p><strong>$x_i$ </strong>是utterance $u_{l−1}$ 的topic word，相关定义：</p><script type="math/tex; mode=display">K_{x_i}= \{k_1, k_2, . . . , k_{|K_{x_i}|}\}</script><p>将topic word mask掉作为输入：</p><script type="math/tex; mode=display">u^{'}_{l−1}= \{x_1, . . . , x_{i−1},[MASK], x_{i+1}, . . . , x^{'}_T\}</script><p>损失函数：</p><p>Given a <strong>training pair $(u^{‘}<em>{l−1}, K</em>{x_i})$</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211114153203.png" alt="image-20211114153203931" style="zoom:33%;" /></p><h5 id="Hypernym-Generation"><a href="#Hypernym-Generation" class="headerlink" title="Hypernym Generation"></a>Hypernym Generation</h5><p>预测WordNet给出的单词的相关上位词。</p><p>$u_{l−1}$= {I submit a paper to the EMNLP}</p><p>从WordNet中替换<strong>EMNLP</strong>为 上位词 <strong>conference</strong>。</p><p>$u^{‘}_{l−1}$= {I submit a paper to the conference}</p><p>损失函数：</p><p>Given a <strong>training pair $(u<em>{l−1}, u^{‘’}</em>{l−1})$</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211114155233.png" alt="image-20211114155233067" style="zoom: 33%;" /></p><p>联合损失：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211114160209.png" alt="image-20211114160209893" style="zoom:33%;" /></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211114160558.png" alt="image-20211114160558760"></p><p>给个例子更直观的解释上面三部分。</p><p>​        这两个辅助任务强迫模型在训练期间从外部知识库学习更丰富的语义知识，根据上下文更好的猜测unseen entity的含义，生成更相关的对话。这两个训练目标都不需要进一步的人工标记，这为扩展到大规模的预训练提供了可能。</p><p>​        相对于利用命名实体或知识库来增强预训练编码器的方法，本文在给定unseen word的情况下注入知识来提高seq2seq模型的生成能力。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>Wizard of Wikipedia</li><li>Reddit Trendings</li></ul><blockquote><p>Reddit Trendings面板包含最新的热门话题，大部分都不包含在外部知识库中。</p></blockquote><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211114162707.png" alt="image-20211114162707440" style="zoom:67%;" /></p><p>PPL：困惑度</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211114163336.png" alt="image-20211114163336465" style="zoom: 33%;" /></p><p>masked word 和 上位词预测样例。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>​        为了更好地处理基于未见词的响应生成，本文提出了KE-Blender，它使模型在推理过程中无需外部知识就能生成有知识的响应。为了将知识显式地注入到模型中，提出了两个训练目标，包括解释屏蔽词和生成上位词。Wizard和Reddit趋势的结果显示，KE-Blender在外部知识可用和不可用的情况下都优于几种最先进的方法和强大的基线。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Dialogue </tag>
            
            <tag> Generation </tag>
            
            <tag> 会话 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Heterogeneous Graph Attention Network</title>
      <link href="/2021/10/26/Heterogeneous%20Graph%20Attention%20Network/"/>
      <url>/2021/10/26/Heterogeneous%20Graph%20Attention%20Network/</url>
      
        <content type="html"><![CDATA[<h1 id="Heterogeneous-Graph-Attention-Network"><a href="#Heterogeneous-Graph-Attention-Network" class="headerlink" title="Heterogeneous Graph Attention Network"></a>Heterogeneous Graph Attention Network</h1><ul><li>Heterogeneous graph Attention Network, named <strong>HAN</strong></li></ul><p>异构图注意力网络</p><p><strong>heterogeneous graph</strong> which contains different types of nodes and links</p><p><strong>homogeneous graph</strong> which includes only one type of nodes or links</p><p>heterogeneous information network (<strong>HIN</strong>)<br><strong>Meta-path</strong>, a composite relation connecting two objects, is a widely used structure to capture the semantics</p><blockquote><p>论文：</p><p>代码：</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>异构图中包含不同的节点和边，GNN做的还不够完善。由于异质图的复杂性，传统的图神经网络不能直接应用于异构图。本文提出了一种新的异构图神经网络分层注意力机制，涉及到节点级别和语义级别。节点级别的Attention主要学习节点及其临近节点间的权重，语义级别的Attention是来学习基于不同meta-path的权重。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211020103917.png" alt="image-20211020103917183" style="zoom:40%;" /></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><ul><li>Semantic-level attention</li></ul><p>语义级别的注意力旨在了解每个Metapath的重要性，并为他们分配适当的权重。同等对待meat-path是不切实际的，相同的权重会降低有用信息的效果。</p><ul><li>Node-level attention </li></ul><p>对于每个节点，节点级别注意力旨在了解基于meta-path的邻居的重要性并为它们分配不同的权重。发现节点之间的细微区别。</p><p>模型贡献：</p><ul><li>本文是首次尝试研究基于注意力机制的异构图神经网络。本文的工作使得图神经网络可以直接应用于异构图，进一步方便了基于异构图的应用。</li><li>提出了一种新的异构图注意力网络(HAN)，它包含了节点级和语义级的注意力。利用这种层次化的注意，提出的HAN可以同时考虑节点和meat-path的重要性。此外，该模型计算效率高，计算复杂度与基于元路径的节点对数目成线性关系，可应用于大规模异构图。</li><li>进行了大量的实验来评估所提出的模型的性能。通过与现有模型的比较，验证了该模型的优越性。更重要的是，通过分析层次注意机制，提出的HAN在异构图分析中具有良好的解释性。</li></ul><p><strong>模型结构：</strong><br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026130417.png" alt="image-20211026130417426" style="zoom: 67%;" /></p><h3 id="Node-level-Attention"><a href="#Node-level-Attention" class="headerlink" title="Node-level Attention"></a>Node-level Attention</h3><p>在具体任务中，一个节点在meta-path上的邻居节点有不同的重要性。Node-level attention能够学习一个节点基于meta-path的邻居节点的表示作为该节点的embedding。由于graph中包含不同类型的node，所以首先通过转换矩阵将所有节点转换到统一的特征空间。</p><script type="math/tex; mode=display">h^′= M_{ø_i}· h_i</script><p>给定一个节点对(i , j)，Node-level Attention能学习到节点j相对于节点i的权重，重要的一点是(i , j)的权重是非对称的。通过softmax计算出节点j的权重系数，得到的系数也是非对称的。</p><p>通过下面的式子聚合所有邻居节点的系数:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026131153.png" alt="image-20211026131153430" style="zoom: 33%;" /></p><p>图示聚合过程：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026131235.png" alt="image-20211026131235884" style="zoom: 33%;" /></p><p>由于异构图数据是scale free的，计算后会有很高的方差，本文通过将Node-level Attention延伸到了multihead Attention来解决这个问题。紧接着就可以得到Node i 的多条meta-path的embedding集合，即是语义层的embedding，就此Node-level Attention工作完成。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026131412.png" alt="image-20211026131412136" style="zoom:33%;" /></p><h3 id="Semantic-level-Attention"><a href="#Semantic-level-Attention" class="headerlink" title="Semantic-level Attention"></a>Semantic-level Attention</h3><p>为了学习到更综合的信息，需要根据meta-path将多种语义信息融合到一起。将Node-level Attention的结果作为输入，来学习每条语义的权重。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026131556.png" alt="image-20211026131556645" style="zoom:33%;" /></p><p>要学习每条语义的权重，首先使用一层的MLP将Semantic embedding进行非线性转换。通过Semantic-level Attention vector <strong>q</strong> 来衡量多条Semantic embedding 间的相似性。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026131710.png" alt="image-20211026131710239" style="zoom:33%;" /></p><p>经过Softmax函数，得到语义权重。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026131832.png" alt="image-20211026131832610" style="zoom:33%;" /></p><p>最后，获得语义层的embedding：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026131850.png" alt="image-20211026131850158" style="zoom:33%;" /></p><p>有了embedding之后，就可以构建loss function了，本文使用半监督的方式，通过最小化Cross-Entropy来训练。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026131949.png" alt="image-20211026131949789" style="zoom:33%;" /></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>DBLP、ACM、IMDB</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026132307.png" alt="image-20211026132307432"></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><ul><li>分类任务</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026132516.png" alt="image-20211026132516650"></p><p>由于图结构数据的方差非常高，因此重复处理10次，Table3 中为平均Macro-F1和Macro-F1。</p><ul><li>聚类任务</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211026132717.png" alt="image-20211026132717327"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文针对异构图分析中的几个基本问题，提出了一种基于注意力机制的半监督异构图神经网络。所提出的HAN能够捕获异构图背后复杂的结构和丰富的语义。该模型利用node-level注意力和semantic-level注意力分别学习node和meta path的重要性。同时，该模型统一利用了结构信息和特征信息。实验结果包括分类和聚类，证明了HAN算法的有效性。通过分析学习到的注意力权重包括节点级和语义级，证明了HAN具有良好的解释性。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Social Network </tag>
            
            <tag> HAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Knowledge Generation MRC模型复现</title>
      <link href="/2021/10/06/KnowledgeGenerationMRC%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/"/>
      <url>/2021/10/06/KnowledgeGenerationMRC%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="Knowledge-Generation-MRC模型复现"><a href="#Knowledge-Generation-MRC模型复现" class="headerlink" title="Knowledge Generation MRC模型复现"></a>Knowledge Generation MRC模型复现</h1><h2 id="扩展知识"><a href="#扩展知识" class="headerlink" title="扩展知识"></a>扩展知识</h2><ul><li>哈工大 RoBERTa-wwm-ext, Chinese <a href="https://github.com/ymcui/Chinese-BERT-wwm">https://github.com/ymcui/Chinese-BERT-wwm</a></li></ul><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><ul><li>conda</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n mq_mrc python=3.6</span><br><span class="line">source activate mq_mrc</span><br></pre></td></tr></table></figure><ul><li><p>PyTorch </p><blockquote><p>pytorch 官网 自动安装cudnn</p><p><a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch  cudatoolkit=10.1 -c pytorch</span><br><span class="line"># 官方版</span><br><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch</span><br><span class="line"># 测试：</span><br><span class="line">import torch </span><br><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure><p>​    conda 报错可以试试pip</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio</span><br></pre></td></tr></table></figure><ul><li>！不使用 pytorch-pretrained-bert</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall pytorch-pretrained-bert</span><br></pre></td></tr></table></figure><p>配置：<a href="https://www.asimok.site/2020/12/07/Bert预训练模型的使用/">https://www.asimok.site/2020/12/07/Bert预训练模型的使用/</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/data0/maqi/.conda/envs/mq_mrc/lib/python3.6/site-packages/pytorch_pretrained_bert</span><br></pre></td></tr></table></figure><ul><li>使用transformers调用预训练模型</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers</span><br></pre></td></tr></table></figure><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h3 id="数据集处理"><a href="#数据集处理" class="headerlink" title="数据集处理"></a>数据集处理</h3><p>数据集选择原始中文数据集，编码</p><p>字段只要段落和作者？？</p><h4 id="数据集结构"><a href="#数据集结构" class="headerlink" title="数据集结构"></a>数据集结构</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">- pid</span><br><span class="line">- is_classical</span><br><span class="line">- title</span><br><span class="line">- author</span><br><span class="line">- paragraphs</span><br><span class="line">- qas</span><br><span class="line">-- qid</span><br><span class="line">-- question</span><br><span class="line">-- answer</span><br><span class="line">-- pKnowledges</span><br><span class="line">-- qKnowledges</span><br></pre></td></tr></table></figure><p>最终需要的数据结构：</p><ul><li>将question独立出来</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- title</span><br><span class="line">- author</span><br><span class="line">- paragraphs</span><br><span class="line">- question</span><br><span class="line">- answer</span><br><span class="line">- pKnowledges</span><br><span class="line">- qKnowledges</span><br></pre></td></tr></table></figure><h4 id="数据集类"><a href="#数据集类" class="headerlink" title="数据集类"></a>数据集类</h4><p>在<code>__init__</code>方法中读取数据集。</p>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining</title>
      <link href="/2021/10/05/A%20Hierarchical%20Network%20for%20Abstractive%20Meeting%20Summarization%20with%20Cross-%20Domain%20Pretraining/"/>
      <url>/2021/10/05/A%20Hierarchical%20Network%20for%20Abstractive%20Meeting%20Summarization%20with%20Cross-%20Domain%20Pretraining/</url>
      
        <content type="html"><![CDATA[<h1 id="A-Hierarchical-Network-for-Abstractive-Meeting-Summarization-with-Cross-Domain-Pretraining"><a href="#A-Hierarchical-Network-for-Abstractive-Meeting-Summarization-with-Cross-Domain-Pretraining" class="headerlink" title="A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining"></a>A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining</h1><blockquote><p> <a href="https://arxiv.org/abs/2004.02016">论文：A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining</a></p><p> 代码：<a href="https://github.com/JudeLee19/HMNet-End-to-End-Abstractive-Summarization-for-Meetings">https://github.com/JudeLee19/HMNet-End-to-End-Abstractive-Summarization-for-Meetings</a></p><ul><li>非官方但比较简洁易懂的代码</li></ul></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>传统的会议总结方法依赖于复杂的multi-step pipelines，使得联合优化难以实现，并且会议记录的语义结构和风格与文章和对话有很大不同。本文提出了一个新颖的abstractive summary network，以适应会议的场景。</p><p>传统模型需要复杂的多阶段机器学习管道，如模板生成、句子聚类、多句子压缩、候选句子生成和排名。由于这些方法不是端到端的可优化的，因此很难联合改进管道中的各个部分以提高整体性能。此外，一些组件，例如模板生成，需要大量的人力参与，使解决方案无法扩展或转移。</p><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>根据输入的会议记录输出会议总结。</p><p><strong>效果展示：</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211003162004.png" alt="image-20211003162004076" style="zoom:50%;" /></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><blockquote><p> Hierarchical Meeting summarization Network (HMNet)</p></blockquote><p>本文设计了一个分层(Hierarchical)结构来适应长的会议记录，并设计了一个角色向量来描述发言者之间的差异。</p><ul><li><p>为会议中的每个角色设计一个角色向量描述不同与会者的立场差异</p></li><li><p>使用新闻数据预训练模型应对会议数据不足的情况</p></li></ul><p><strong>模型结构：</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211003215719.png" alt="image-20211003215719379"></p><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><ul><li>Role Encode 考虑 various participants</li></ul><h3 id="Hierarchical-Transformer"><a href="#Hierarchical-Transformer" class="headerlink" title="Hierarchical Transformer"></a>Hierarchical Transformer</h3><p>transformer block 由multi-head attention layer 和一个 feed-forward layer组成</p><p>由于注意机制是位置不可知的，将位置编码附加到输入向量中</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211003213825.png" alt="image-20211003213825911" style="zoom:50%;" /></p><blockquote><p>其中 $PE_{(i，j)}$代表输入序列中第i个word的位置编码的第j维。</p></blockquote><p>transformer block的输入与输出维度相同，因此可以叠加。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211003214249.png" alt="image-20211003214249510" style="zoom:50%;" /></p><h4 id="Word-level-Transformer"><a href="#Word-level-Transformer" class="headerlink" title="Word-level Transformer"></a>Word-level Transformer</h4><p>为了结合句法和语义信息，训练了两个嵌入矩阵来表示词性标记和实体标记。</p><blockquote><p>part-of-speech (POS) and entity (ENT) tags</p></blockquote><p>在序列前添加了一个特殊的标记[BOS]，以表示一个回合的开始。</p><h4 id="Turn-level-Transformer"><a href="#Turn-level-Transformer" class="headerlink" title="Turn-level Transformer"></a>Turn-level Transformer</h4><p>将Word-level Transformer的输出[EOS]与此轮role向量连接起来表示第i轮。</p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>解码器使用lower triangular mask 防止模型看到未来的token。</p><p>利用embedding矩阵的权重将解码器的输出$V_{K-1}$解码为词表上的概率分布。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211004084039.png" alt="image-20211004084039926" style="zoom:50%;" /></p><p><strong>损失函数：</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211004083836.png" alt="image-20211004083836814" style="zoom:50%;" /></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>AMI</li><li>ICSI</li></ul><p>这两个数据集分别包含来自自动语音识别(ASR)的会议记录。</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>评测结果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211004154102.png" alt="image-20211004154102213"></p><p>与之前模型性能相比，提升相当大。模型在自动指标和人工评估方面都优于以前的方法。例如，在ICSI数据集上，ROUGE-1得分从34.66%增加到46.28%。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文提出了一种用于抽象会议摘要的端到端分层神经网络HMNet。采用两级分层结构来适应长的会议记录，并用角色向量来表示每个与会者。还通过对新闻摘要数据进行预训练来缓解数据稀缺性问题。实验表明，HMNet在automatic metrics和人工评价方面都达到了最先进的性能。通过一个消融实验，表明角色向量、层次结构和预训练都有助于模型的性能。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Abstract </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP的一些评价指标</title>
      <link href="/2021/10/04/NLP%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
      <url>/2021/10/04/NLP%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</url>
      
        <content type="html"><![CDATA[<h1 id="NLP的一些评价指标"><a href="#NLP的一些评价指标" class="headerlink" title="NLP的一些评价指标"></a>NLP的一些评价指标</h1><h3 id="ROUGE"><a href="#ROUGE" class="headerlink" title="ROUGE"></a>ROUGE</h3><p>ROUGE 指标的全称是 (Recall-Oriented Understudy for Gisting Evaluation)，主要基于召回率。ROUGE 是一种常用的机器翻译和文章摘要评价指标，由 Chin-Yew Lin 提出。它通过将自动生成的摘要或翻译与一组参考摘要（通常是人工生成的）进行比较计算，得出相应的分值，以衡量自动生成的摘要或翻译与参考摘要之间的“相似度”。</p><p> 4 种 ROUGE 方法：</p><ul><li>ROUGE-N: 在 N-gram 上计算召回率。</li><li>ROUGE-L: 考虑了机器译文和参考译文之间的最长公共子序列（长度越长，得分越高，基于F值。）</li><li>ROUGE-W: 改进了ROUGE-L，用加权的方法计算最长公共子序列。</li></ul><h4 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h4><ul><li><strong>ROUGE-N：</strong></li></ul><p><img src="https://www.zhihu.com/equation?tex=ROUGE-N+%3D+%5Cfrac+++++%7B+++++++++%5Csum_%5Climits%7BS%5Cin+%5C%7BReferenceSummaries%5C%7D%7D+++++%5Csum_%5Climits%7Bgram_n%5Cin+S%7D+++++Count_%7Bmatch%7D%28gram_n%29+++++%7D+++++%7B+++++++++%5Csum_%5Climits%7BS%5Cin+%5C%7BReferenceSummaries%5C%7D%7D+++++%5Csum_%5Climits%7Bgram_n%5Cin+S%7D+++++Count%28gram_n%29+++++%7D" alt=""></p><p>其中，$n$ 表示n-gram，$Count(gram<em>n)$表示一个n-gram的出现次数，$Count</em>{match}(gram_n)$ 表示一个n-gram的共现次数。</p><ul><li><strong>ROUGE-L：</strong></li></ul><p><img src="https://www.zhihu.com/equation?tex=ROUGE-L+%3D+%5Cfrac+%7B%281%2B%5Cbeta%5E2%29+R_%7Blcs%7D+P_%7Blcs%7D%7D+%7BR_%7Blcs%7D+%2B+%5Cbeta%5E2+P_%7Blcs%7D%7D+%5C%5C+R_%7Blcs%7D+%3D+%5Cfrac+%7BLCS%28X%2C+Y%29%7D+%7Bm%7D+%5C%5C+P_%7Blcs%7D+%3D+%5Cfrac+%7BLCS%28X%2C+Y%29%7D+%7Bn%7D" alt=""></p><p>其中， $X$表示候选摘要，$Y$表示参考摘要， $LCS(X,Y)$ 表示候选摘要与参考摘要的最长公共子序列的长度，$m$表示参考摘要的长度，$n$表示候选摘要的长度。</p><h3 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h3><p>BLEU 的全称是 双语评估辅助工具(Bilingual evaluation understudy)，BLEU 的分数取值范围是 0～1，分数越接近1，说明翻译的质量越高。BLEU 主要基于精确率(Precision)。</p><h4 id="计算公式-1"><a href="#计算公式-1" class="headerlink" title="计算公式"></a>计算公式</h4><p><img src="https://www.zhihu.com/equation?tex=BLEU+%3D+BP+%5Ccdot+exp%28%5Csum_%5Climits%7Bn%3D1%7D%5EN+w_n+log%5C%2C+p_n+%29" alt=""></p><p>其中$n$表示n-gram，$w_n$ 表示n-gram的权重。</p><p>$BP$表示短句子惩罚因子（brevity penaty)，用$r$表示最短的参考翻译的长度，$c$表示候选翻译的长度。$BP$具体计算方法为：</p><script type="math/tex; mode=display">f(x) =   \begin{array}{lr}    1 & c>r\\   e^{(1-r/c)} & c \le r  \end{array}</script><p>$p_n$表示n-gram的覆盖率，具体计算方式为：</p><p><img src="https://www.zhihu.com/equation?tex=p_n+%3D+%5Cfrac+++++%7B+++++++++%5Csum_%5Climits%7BC%5Cin+%5C%7BCandidates%5C%7D%7D+++++%5Csum_%5Climits%7Bn-gram%5Cin+C%7D+++++Count_%7Bclip%7D%28n-gram%29+++++%7D+++++%7B+++++++++%5Csum_%5Climits%7BC%27%5Cin+%5C%7BCandidates%5C%7D%7D+++++%5Csum_%5Climits%7Bn-gram%5Cin+C%27%7D+++++Count%28n-gram%29+++++%7D" alt=""></p><p>$Count_{clip}$是截断计数，其计数方式为：将一个n-gram在候选翻译中出现的次数，与在各个参考翻译中出现次数的最大值进行比较，取较小的那一个。</p><h3 id="METEOR"><a href="#METEOR" class="headerlink" title="METEOR"></a>METEOR</h3><p>METEOR全称显式排序的翻译评估指标(Metric for Evaluation of Translation with Explicit Ordering)。</p><p>METEOR 是基于BLEU进行了一些改进，其目的是解决一些 BLEU 标准中固有的缺陷 。使用 WordNet 计算特定的序列匹配，同义词，词根和词缀，释义之间的匹配关系，改善了BLEU的效果，使其跟人工判别共更强的相关性。并且，是基于F值的。</p><h4 id="计算公式-2"><a href="#计算公式-2" class="headerlink" title="计算公式"></a>计算公式</h4><p><img src="https://www.zhihu.com/equation?tex=METEOR+%3D+%281-pen%29%5Ctimes+F_%7Bmeans%7D" alt=""></p><p>其中：</p><p><img src="https://www.zhihu.com/equation?tex=F_%7Bmeans%7D+%3D+%5Cfrac+%7BPR%7D+%7B%5Calpha+P+%2B+%281-%5Calpha%29R%7D%5C%5C+P+%3D+%5Cfrac+%7Bm%7D+%7Bc%7D%5C%5C+R+%3D+%5Cfrac+%7Bm%7D+%7Br%7D" alt=""></p><p>$\alpha$ 为可调控的参数，$m$ 为候选翻译中能够被匹配的一元组的数量，$c$ 为候选翻译的长度，$r$为参考摘要的长度。</p><p>$pen$ 为惩罚因子，惩罚的是候选翻译中的词序与参考翻译中的词序不同，具体计算方法为：</p><p><img src="https://www.zhihu.com/equation?tex=Pen+%3D+%5Cfrac+%7B%5C%23chunks%7D+%7Bm%7D" alt=""></p><p>$m$是候选翻译中能够被匹配的一元组的数量，$#chunks$ 指的是chunk的数量，即既在候选翻译中相邻又在参考翻译中相邻的被匹配的一元组聚集而成的单位。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> metric </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hugging Face 在线查看NLP数据集</title>
      <link href="/2021/10/03/Huggingface/"/>
      <url>/2021/10/03/Huggingface/</url>
      
        <content type="html"><![CDATA[<h1 id="Hugging-Face-在线查看NLP数据集"><a href="#Hugging-Face-在线查看NLP数据集" class="headerlink" title="Hugging Face 在线查看NLP数据集"></a>Hugging Face 在线查看NLP数据集</h1><blockquote><p> 官网：<a href="https://huggingface.co">https://huggingface.co</a></p></blockquote><p>Hugging Face在github上开源的自然语言处理，预训练模型库 Transformers， 提供了NLP领域大量state-of-art的 预训练语言模型结构的模型和调用框架。地址：<a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p><p>仓库名称的变迁过程：pytorch-pretrained-bert —&gt; pytorch-transformers —&gt; transformers</p><ul><li>在知乎发现一篇十分详尽的入门教程：<a href="https://zhuanlan.zhihu.com/p/120315111">https://zhuanlan.zhihu.com/p/120315111</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Hugging Face </tag>
            
            <tag> transformers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>进制转换</title>
      <link href="/2021/10/03/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/"/>
      <url>/2021/10/03/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="进制转换"><a href="#进制转换" class="headerlink" title="进制转换"></a>进制转换</h1><blockquote><p>昨天做leetcode的每日一题，进制转换的时候突然联想到了辗转相除法，再跟室友交流之后才弄明白辗转相除法是求最大公约数的，为了捋清楚进制转换问题，在这篇博客里用两种方法解决。</p></blockquote><p>背景：405. 数字转换为十六进制数</p><blockquote><p>给定一个整数，编写一个算法将这个数转换为十六进制数。对于负整数，我们通常使用 补码运算 方法。</p></blockquote><h2 id="连除取余法"><a href="#连除取余法" class="headerlink" title="连除取余法"></a>连除取余法</h2><blockquote><p>这个方法比较常规 一直取余数 最后将余数倒着输出就好啦</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    </span><br><span class="line">    def toHex(self, num: int) -&gt; str:</span><br><span class="line">        CONV = &quot;0123456789abcdef&quot;</span><br><span class="line">        ans =[]</span><br><span class="line">        # 32位二进制数 转成十六进制 共8位 4*8</span><br><span class="line">        for _ in range(8): </span><br><span class="line">            temp = num % 16</span><br><span class="line">            num = num//16</span><br><span class="line">            ans.append(temp)</span><br><span class="line">            if not num:</span><br><span class="line">                break</span><br><span class="line">        # 倒着输出</span><br><span class="line">        return &#x27;&#x27;.join(CONV[j] for j in ans[::-1])</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h2><blockquote><p>这个操作相当秀了。从ACM大佬那里学到一招：将/2操作变成右移一位，与1做与运算判断奇偶性是一个好习惯。</p></blockquote><p>预备知识：</p><ul><li>在编程语言中，十进制数做位运算的时候直接是当作二进制数操作的。</li><li>右移一位相当于是除2^1 ，显然，转16进制时每次要除16，即2^4 ，右移4位 每除一次得到最高位的十六进制数。</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211003085947.png" alt="image-20211003085946977"></p><blockquote><p>解释两点自己的疑惑：</p><ul><li><p>int val = (num &gt;&gt; (4 * i)) &amp; 0xf;</p><p>将二进制数四个一组 转换成十六进制 每次将待转换的四位右移到最低位。与0xf做与运算的原因在于，只取最低4位，其他位全置为0.</p></li><li><p>int i = 7; i &gt;= 0; i —</p><p>从最高位开始 依次加入字符串</p></li></ul></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    string toHex(int num) &#123;</span><br><span class="line">        if (num == 0) &#123;</span><br><span class="line">            return &quot;0&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">        string sb;</span><br><span class="line">        for (int i = 7; i &gt;= 0; i --) &#123;</span><br><span class="line">            int val = (num &gt;&gt; (4 * i)) &amp; 0xf;</span><br><span class="line">            if (sb.length() &gt; 0 || val &gt; 0) &#123;</span><br><span class="line">                char digit = val &lt; 10 ? (char) (&#x27;0&#x27; + val) : (char) (&#x27;a&#x27; + val - 10);</span><br><span class="line">                sb.push_back(digit);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return sb;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Automatically Learning Data Augmentation Policies for Dialogue Tasks</title>
      <link href="/2021/09/28/Automatically%20Learning%20Data%20Augmentation%20Policies%20for%20Dialogue%20Tasks/"/>
      <url>/2021/09/28/Automatically%20Learning%20Data%20Augmentation%20Policies%20for%20Dialogue%20Tasks/</url>
      
        <content type="html"><![CDATA[<h1 id="Automatically-Learning-Data-Augmentation-Policies-for-Dialogue-Tasks"><a href="#Automatically-Learning-Data-Augmentation-Policies-for-Dialogue-Tasks" class="headerlink" title="Automatically Learning Data Augmentation Policies for Dialogue Tasks"></a>Automatically Learning Data Augmentation Policies for Dialogue Tasks</h1><blockquote><p> <a href="https://arxiv.org/abs/1909.12868">论文：Automatically Learning Data Augmentation Policies for Dialogue Tasks</a></p><p> <a href="https://github.com/WolfNiu/AutoAugDialogue">代码：https://github.com/WolfNiu/AutoAugDialogue</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><blockquote><p>AutoAugment算法主要应用在CV领域，本文调整AutoAugment算法应用在对话任务上。</p></blockquote><p>自动数据增强（AutoAugment）通过使用目标任务上的采样策略的性能奖励训练的控制器搜索最佳扰动策略，从而减少data-level模型的偏差。</p><p>本文调整了AutoAugment，以自动发现自然语言处理（NLP）任务的effective perturbation policies(有效扰动策略)，如对话生成。</p><p>还探索了以目标任务的源输入为条件的控制器，因为某些策略可能不适用于不包含该策略所需语言特征的输入。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>从一个原子操作池开始，对对话任务的源输入进行微妙的语义保护性扰动（例如，不同的POS-标签类型的停顿词、语法错误和意译）。</p><p>接下来，允许控制器通过搜索这些原子操作的各种组合的空间来学习更复杂的增强策略。</p><p><strong>数据增强策略：</strong></p><p>下图中，第一个操作（Paraphrase, 2, 0.7）以0.7的概率对输入进行两次转述；第二个操作（Grammar Errors, 1, 0.4）以0.4的概率插入一个语法错误。因此，每个子策略最多可能有4个结果。这种修改为模型提供了一个更大的操作组合空间，使其有可能学习到更复杂和细微的增强策略。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210928204241.png" alt="image-20210928204241718" style="zoom:67%;" /></p><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>模型包含controller和target model</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210928205335.png" alt="image-20210928205335327" style="zoom:67%;" /></p><p>controller首先对一个策略进行采样，将原始数据转化为增强数据，目标模型在此基础上进行训练。训练结束后，对目标模型进行评估，以获得验证集上的性能。然后，这个性能被反馈给controller作为reward signal。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210928205353.png" alt="image-20210928205353335" style="zoom:67%;" /></p><p>input-agnostic：由一个单一的解码器组成，依次对每个操作进行采样。</p><blockquote><p> 一个操作由3个参数定义。操作类型、允许执行操作的最大次数、应用该操作的概率。</p></blockquote><p>input-aware：加入一个编码器，将训练数据作为输入，使其成为一个seq2seq模型。由于对于每个输入源，可能有一组不同的扰动最适合它，模型的输入感知控制器旨在为每个训练实例提供定制操作。</p><ul><li><p>搜索算法：REINFORCE</p><blockquote><p>对多个子策略进行抽样以形成一个策略，提供了对控制器性能不太偏颇的估计。</p></blockquote></li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>Variational Hierarchical Encoder-Decoder (VHRED)</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>表1说明所有的数据增强方法（最后3行）都比最强的基线VHRED（w/attention）有明显的改善。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20211001124428.png" alt="image-20211001124428442" style="zoom: 33%;" /></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文使AutoAugment适用于对话，并将其控制器扩展到一个有条件的模型。通过自动和人工评估表明，AutoAugment模型学会了有用的数据增强策略。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> Dialogue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SEQUENTIAL LATENT KNOWLEDGE SELECTION FOR KNOWLEDGE-GROUNDED DIALOGUE</title>
      <link href="/2021/08/27/SEQUENTIAL%20LATENT%20KNOWLEDGE%20SELECTION%20FOR%20KNOWLEDGE-GROUNDED%20DIALOGUE/"/>
      <url>/2021/08/27/SEQUENTIAL%20LATENT%20KNOWLEDGE%20SELECTION%20FOR%20KNOWLEDGE-GROUNDED%20DIALOGUE/</url>
      
        <content type="html"><![CDATA[<h1 id="SEQUENTIAL-LATENT-KNOWLEDGE-SELECTION-FOR-KNOWLEDGE-GROUNDED-DIALOGUE"><a href="#SEQUENTIAL-LATENT-KNOWLEDGE-SELECTION-FOR-KNOWLEDGE-GROUNDED-DIALOGUE" class="headerlink" title="SEQUENTIAL LATENT KNOWLEDGE SELECTION FOR KNOWLEDGE-GROUNDED DIALOGUE"></a>SEQUENTIAL LATENT KNOWLEDGE SELECTION FOR KNOWLEDGE-GROUNDED DIALOGUE</h1><blockquote><p> <a href="https://arxiv.org/abs/2002.07510">论文：https://arxiv.org/abs/2002.07510</a></p><p> <a href="https://github.com/bckim92/sequential-knowledge-transformer">代码：https://github.com/bckim92/sequential-knowledge-transformer</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>以知识为基础的对话是一项基于话语背景和外部知识产生信息性反应的任务。</p><p>提出sequential latent variable model（sequential knowledge transformer (SKT)）更好地模拟多轮知识为基础的对话中的知识选择，该模型可以跟踪知识的先验和后验分布；因此，不仅可以减少对话中知识选择的多样性造成的模糊性，还可以更好地利用响应信息来正确选择知识。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p><strong>主要贡献：</strong></p><ol><li><p>本文提出了sequential knowledge transformer (SKT)模型。该模型是第一次尝试利用顺序潜变量模型进行知识选择，随后改善以知识为基础的对话。</p></li><li><p>实验结果表明，所提出的模型不仅提高了知识选择的准确性，而且还提高了语料生成的性能。在Wizard of Wikipedia和Holl-E数据集的知识注释版本上取得了新的最先进的性能。</p></li></ol><h3 id="APPROACH"><a href="#APPROACH" class="headerlink" title="APPROACH"></a>APPROACH</h3><p><strong>模型结构：</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210825100719.png" alt="image-20210825100719031"></p><p>SKT依次对以前选择的知识进行处理，以产生反应。</p><p>模型第t轮的输入是之前的对话回合，包含<strong>apprentice</strong>的话语$x<em>1, …, x_t$, <strong>wizard</strong>的话语 $y_1, …, y</em>{t−1}$，knowledge pool $k_1, …, k_t$，输出为selected knowledge $k_s^t$ and the wizard’s response $y_t$。</p><h4 id="Sentence-Encoding"><a href="#Sentence-Encoding" class="headerlink" title="Sentence Encoding"></a>Sentence Encoding</h4><p>apprentice utterance $x^t$：</p><p>使用BERT编码为embedding $h_x^t$，每个时间步使用average pooling。</p><script type="math/tex; mode=display">H^t_x= BERT_{base}([x^t_1; ...; x^t_M]) ∈ R^{M×768}</script><script type="math/tex; mode=display">h^t_ x= avgpool(H^t_ x) ∈ R^{768}</script><p>同样，Wizard utterance $y^{t-1}$编码为$h<em>y^{t-1}$，knowledge sentences编码为${h^{t,l}</em> k} = h^{t,1}<em> k, …, h^{t,L}</em> k$。</p><p>apprentice-wizard utterance pair $h<em>{xy}^t=[h_x^t,h_y^t]$在第t轮对话使用GRU联合表示为：$d^t</em>{xy}=GRU<em>{dialog}(d^{t-1}</em>{xy},h^t_{xy})∈ R^{768}$</p><blockquote><p>1 ≤ t ≤ T：代表对话的轮次</p><p>1 ≤ m ≤ M and 1 ≤ n ≤ N ：分别表示 apprentice 和 wizard 对话中的单词</p><p>1 ≤ l ≤ L：表示knowledge sentences in the pool</p><p>T是对话长度，M和N是apprentice 和 wizard的每个话语的长度，L是知识池的大小</p></blockquote><h4 id="Sequential-Knowledge-Selection"><a href="#Sequential-Knowledge-Selection" class="headerlink" title="Sequential Knowledge Selection"></a>Sequential Knowledge Selection</h4><p>两个调整：</p><ul><li><p>将知识选择视为一个连续的决策过程，而不是一个单步决策过程</p></li><li><p>由于对话中知识选择的多样性，将其建模为潜在的变量。</p><p>因此，可以对多轮知识选择和反应生成进行联合推理，而不是逐轮进行单独推理。</p></li></ul><p>prior distribution of knowledge :$π_θ$</p><script type="math/tex; mode=display">π_θ(k^t|x≤t, y<t, k_s≤t−1 ) = softmax(q^t_{prior}[h^{t,1}_ k, ..., h^{t,L}_k]^{\top}) ∈ R^L</script><p>posterior distribution :$q_φ$</p><script type="math/tex; mode=display">q_φ(k^t|x≤t, y<t, k_s≤t−1 ) = softmax(q^t_{post}[h^{t,1}_ k, ..., h^{t,L}_k]^{\top}) ∈ R^L</script><h4 id="Decoding-with-Copy-Mechanism"><a href="#Decoding-with-Copy-Mechanism" class="headerlink" title="Decoding with Copy Mechanism"></a>Decoding with Copy Mechanism</h4><p>wizard在第$t$轮的回应由当前context $x^t$，和选择的knowledge sentence $k^t_s$生成。</p><script type="math/tex; mode=display">H^t_{xk_s}= [H^t_x; H^t_{k_s}]</script><p>Copy Mechanism使用Transformer作为解码器。</p><script type="math/tex; mode=display">h^t_ n= Decoder(H^t_ {xk_s}, y^t <n)</script><script type="math/tex; mode=display">p_{t,n}(w) = (1 − α^{copy}_{t,n}) ∗ p^{gen}_{t,n}(w) + α^{copy}_{t,n} ∗ p^{copy} _{t,n}(w)</script><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>在有无真实标签的训练中，知识选择的准确性存在很大差距。因此使用knowledge loss（即预测和真实知识句子之间的交叉熵损失）作为潜变量的辅助损失。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210826181250.png" alt="image-20210826181250713"></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>Wizard of Wikipedia (WoW)</li><li>Holl-E</li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><ul><li>Wizard of Wikipedia数据集</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210826202539.png" alt="image-20210826202539226"></p><blockquote><ul><li>本文模型在知识选择（准确率）和语篇生成（unigram F1，bigram F1）的所有指标上都优于最先进的以知识为基础的对话模型。</li><li>在没有知识标签的情况下训练的PostKS在知识选择方面显示出较低的准确率，比随机猜测略好。而在WoW Test Seen中，它达到了比E2E Transformer MemNet更好的性能，这表明利用先验和后验知识分布对知识基础的对话是有效的，</li><li>BERT提高了知识选择的准确性，但由于对话知识选择的多样性，其提高幅度并不像TextQA那样大。</li><li>E2E BERT + PostKS + Copy在基线中表现最好，这验证了顺序潜变量建模对于提高知识选择和随后的语篇生成的准确性至关重要。</li><li>和基线之间的性能差距在 Test Unseen 中更大。可以理解为，顺序潜变量可以更好地进行泛化。</li><li>在基线中加入复制机制，大幅提高了语料生成的准确性，但几乎没有改善知识选择，这也证明了顺序潜变量的有效性。</li><li>Transformer（no knowledge）在WoW Test Seen 中显示出最低的困惑，这主要是由于它可能只生成一般和简单的语料，因为没有知识基础。这种行为对困惑度是有利的，而其他基于知识的模型则有预测错误知识的风险，这对困惑度是不利的。</li></ul></blockquote><ul><li>Holl-E</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210826202712.png" alt="image-20210826202712236"></p><blockquote><ul><li><p>本文的模型在所有指标上都优于所有基线</p></li><li><p>一个值得注意的趋势是，BERT大大降低了所有模型的困惑度，这可能是由于Holl-E的数据集规模比WoW小得多，BERT可以防止过拟合。</p></li></ul></blockquote><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文研究了多轮知识为基础的对话中的知识选择问题，并首次提出了一个顺序潜变量模型SKT。模型在Wizard of Wikipedia和Holl-E数据集的知识注释版本上取得了新的最先进的性能。所提出的模型提高了知识选择的准确性，从而提高了语篇生成的性能。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Dialogue </tag>
            
            <tag> SKT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow常用操作</title>
      <link href="/2021/08/23/TensorFlow%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
      <url>/2021/08/23/TensorFlow%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="指定GPU"><a href="#指定GPU" class="headerlink" title="指定GPU"></a>指定GPU</h2><ul><li>终端指定</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 nohup python demo.py &gt;&gt; base_log.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><ul><li>程序指定</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;</span><br></pre></td></tr></table></figure><h1 id="TensorFlow常用操作"><a href="#TensorFlow常用操作" class="headerlink" title="TensorFlow常用操作"></a>TensorFlow常用操作</h1><h2 id="检测GPU是否可用"><a href="#检测GPU是否可用" class="headerlink" title="检测GPU是否可用"></a>检测GPU是否可用</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">tf.test.is_gpu_available()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用TensorFlow实现LSTM</title>
      <link href="/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0LSTM/"/>
      <url>/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0LSTM/</url>
      
        <content type="html"><![CDATA[<h1 id="使用TensorFlow实现LSTM"><a href="#使用TensorFlow实现LSTM" class="headerlink" title="使用TensorFlow实现LSTM"></a>使用TensorFlow实现LSTM</h1><h2 id="使用Cell实现"><a href="#使用Cell实现" class="headerlink" title="使用Cell实现"></a>使用Cell实现</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"># 以Cell方式实现LSTM</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># 指定GPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 128  # 批量大小</span><br><span class="line">total_words = 10000  # 词汇表大小N_vocab</span><br><span class="line">max_review_len = 80  # 句子最大长度s，大于的句子部分将截断，小于的将填充</span><br><span class="line">embedding_len = 100  # 词向量特征长度f</span><br><span class="line"># 加载IMDB数据集，此处的数据采用数字编码，一个数字代表一个单词</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(x_train[0])</span><br><span class="line"># %%</span><br><span class="line"># 数字编码表</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># 翻转编码表</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">decode_review(x_train[8])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"># 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Cell方式构建多层网络</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # [b, 64]，构建Cell初始化状态向量，重复使用</span><br><span class="line">        # 与RNN不同 LSTM有两个输出 隐藏层状态也为两个</span><br><span class="line">        self.state0 = [tf.zeros([batch_size, units]), tf.zeros([batch_size, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batch_size, units]), tf.zeros([batch_size, units])]</span><br><span class="line">        # 词向量编码 [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # 构建2个Cell</span><br><span class="line">        self.rnn_cell0 = layers.LSTMCell(units, dropout=0.5)</span><br><span class="line">        self.rnn_cell1 = layers.LSTMCell(units, dropout=0.5)</span><br><span class="line">        # 构建分类网络，用于将CELL的输出特征进行分类，2分类</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(units),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        state0 = self.state0</span><br><span class="line">        state1 = self.state1</span><br><span class="line">        out1 = None</span><br><span class="line">        for word in tf.unstack(x, axis=1):  # word: [b, 100]</span><br><span class="line">            out0, state0 = self.rnn_cell0(word, state0, training)</span><br><span class="line">            out1, state1 = self.rnn_cell1(out0, state1, training)</span><br><span class="line">        # 末层最后一个输出作为分类网络的输入: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(out1, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 64  # RNN状态向量长度f</span><br><span class="line">    epochs = 50  # 训练epochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # 装配</span><br><span class="line">    model.compile(optimizer=optimizers.RMSprop(0.001),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # 训练和验证</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # 测试</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="使用Layer实现"><a href="#使用Layer实现" class="headerlink" title="使用Layer实现"></a>使用Layer实现</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"># 以Layer方式实现LSTM</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># 指定GPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;2&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 128  # 批量大小</span><br><span class="line">total_words = 10000  # 词汇表大小N_vocab</span><br><span class="line">max_review_len = 80  # 句子最大长度s，大于的句子部分将截断，小于的将填充</span><br><span class="line">embedding_len = 100  # 词向量特征长度f</span><br><span class="line"># 加载IMDB数据集，此处的数据采用数字编码，一个数字代表一个单词</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(x_train[0])</span><br><span class="line"># %%</span><br><span class="line"># 数字编码表</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># 翻转编码表</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">decode_review(x_train[8])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"># 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Cell方式构建多层网络</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # 词向量编码 [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # 构建RNN</span><br><span class="line">        self.rnn = keras.Sequential([</span><br><span class="line">            layers.LSTM(units, dropout=0.5, return_sequences=True),</span><br><span class="line">            layers.LSTM(units, dropout=0.5)</span><br><span class="line">        ])</span><br><span class="line">        # 构建分类网络，用于将CELL的输出特征进行分类，2分类</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(32),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        x = self.rnn(x)</span><br><span class="line">        # 末层最后一个输出作为分类网络的输入: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(x, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 32  # RNN状态向量长度f</span><br><span class="line">    epochs = 50  # 训练epochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # 装配</span><br><span class="line">    model.compile(optimizer=optimizers.Adam(0.001),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # 训练和验证</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # 测试</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用TensorFlow实现RNN</title>
      <link href="/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0RNN/"/>
      <url>/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0RNN/</url>
      
        <content type="html"><![CDATA[<h1 id="使用TensorFlow实现RNN"><a href="#使用TensorFlow实现RNN" class="headerlink" title="使用TensorFlow实现RNN"></a>使用TensorFlow实现RNN</h1><h2 id="使用Cell实现"><a href="#使用Cell实现" class="headerlink" title="使用Cell实现"></a>使用Cell实现</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"># 以cell方式实现RNN</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># 指定GPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line"># 避免输出无关调试信息</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 128  # 批量大小</span><br><span class="line">total_words = 10000  # 词汇表大小N_vocab</span><br><span class="line">max_review_len = 80  # 句子最大长度s，大于的句子部分将截断，小于的将填充</span><br><span class="line">embedding_len = 100  # 词向量特征长度f</span><br><span class="line"></span><br><span class="line"># 加载IMDB数据集，此处的数据采用数字编码，一个数字代表一个单词</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(&#x27;dataset shape&#x27;)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(&#x27;dataset x_train[0]: &#x27;, x_train[0])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"># 数字编码表</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line"># 调整特殊词汇位置</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># 翻转编码表</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    # dict.get(key, default=None)</span><br><span class="line">    # default -- 如果指定键的值不存在时，返回该默认值。</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 编码--&gt;句子</span><br><span class="line">print(decode_review(x_train[8]))</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"></span><br><span class="line"># 构建数据集，打散，批量，并丢掉最后一个不够batch_size的batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Cell方式构建多层网络</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        # units [b, 64]</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # [b, 64]，构建Cell初始化状态向量，重复使用</span><br><span class="line">        self.state0 = [tf.zeros([batch_size, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batch_size, units])]</span><br><span class="line">        # 词向量编码 [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # 构建2个Cell</span><br><span class="line">        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.5)</span><br><span class="line">        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.5)</span><br><span class="line">        # 构建分类网络，用于将CELL的输出特征进行分类，2分类</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(units),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line">        # 测试阶段 training=false</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        # 初始化隐藏层状态</span><br><span class="line">        state0 = self.state0</span><br><span class="line">        state1 = self.state1</span><br><span class="line">        out1 = None</span><br><span class="line">        for word in tf.unstack(x, axis=1):  # word: [b, 100]</span><br><span class="line">            out0, state0 = self.rnn_cell0(word, state0, training)</span><br><span class="line">            # 第二层的输入为第一层的输出</span><br><span class="line">            out1, state1 = self.rnn_cell1(out0, state1, training)</span><br><span class="line">        # 末层最后一个输出作为分类网络的输入: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(out1, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 64  # RNN状态向量长度f</span><br><span class="line">    epochs = 50  # 训练epochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # 装配</span><br><span class="line">    model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-3),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # 训练和验证</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # 测试</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="使用Layer实现"><a href="#使用Layer实现" class="headerlink" title="使用Layer实现"></a>使用Layer实现</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"># 以Layer方式实现RNN</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># 指定GPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;1&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 512  # 批量大小</span><br><span class="line">total_words = 10000  # 词汇表大小N_vocab</span><br><span class="line">max_review_len = 80  # 句子最大长度s，大于的句子部分将截断，小于的将填充</span><br><span class="line">embedding_len = 100  # 词向量特征长度f</span><br><span class="line"></span><br><span class="line"># 加载IMDB数据集，此处的数据采用数字编码，一个数字代表一个单词</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(x_train[0])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"># 数字编码表</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># 翻转编码表</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">decode_review(x_train[8])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"></span><br><span class="line"># 构建数据集，打散，批量，并丢掉最后一个不够batch_size的batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Layer方式构建多层网络</span><br><span class="line">    # 该方式不需要设置RNN初始状态</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # 词向量编码 [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # 构建RNN 使用Sequential管理两层RNN</span><br><span class="line">        # return_sequences=True 使该层输出作为下一层输入</span><br><span class="line">        self.rnn = keras.Sequential([</span><br><span class="line">            layers.SimpleRNN(units, dropout=0.5, return_sequences=True),</span><br><span class="line">            layers.SimpleRNN(units, dropout=0.5)</span><br><span class="line">        ])</span><br><span class="line">        # 构建分类网络，用于将CELL的输出特征进行分类，2分类</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(32),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        # Layer方式不用手动管理隐藏层状态</span><br><span class="line">        x = self.rnn(x)</span><br><span class="line">        # 末层最后一个输出作为分类网络的输入: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(x, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 64  # RNN状态向量长度f</span><br><span class="line">    epochs = 5  # 训练epochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # 装配</span><br><span class="line">    model.compile(optimizer=optimizers.Adam(0.001),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # 训练和验证</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # 测试</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用TensorFlow实现GRU</title>
      <link href="/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0GRU/"/>
      <url>/2021/08/23/%E4%BD%BF%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0GRU/</url>
      
        <content type="html"><![CDATA[<h1 id="使用TensorFlow实现GRU"><a href="#使用TensorFlow实现GRU" class="headerlink" title="使用TensorFlow实现GRU"></a>使用TensorFlow实现GRU</h1><h2 id="使用Cell实现"><a href="#使用Cell实现" class="headerlink" title="使用Cell实现"></a>使用Cell实现</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line"># 以Cell方式实现GRU</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># 指定GPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;2&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 128  # 批量大小</span><br><span class="line">total_words = 10000  # 词汇表大小N_vocab</span><br><span class="line">max_review_len = 80  # 句子最大长度s，大于的句子部分将截断，小于的将填充</span><br><span class="line">embedding_len = 100  # 词向量特征长度f</span><br><span class="line"># 加载IMDB数据集，此处的数据采用数字编码，一个数字代表一个单词</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(x_train[0])</span><br><span class="line"># %%</span><br><span class="line"># 数字编码表</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># 翻转编码表</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">decode_review(x_train[8])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"># 构建数据集，打散，批量，并丢掉最后一个不够batch_size的batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Cell方式构建多层网络</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # [b, 64]，构建Cell初始化状态向量，重复使用</span><br><span class="line">        # GRU与RNN相同 隐藏层状态为1个 LSTM两个</span><br><span class="line">        self.state0 = [tf.zeros([batch_size, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batch_size, units])]</span><br><span class="line">        # 词向量编码 [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # 构建2个Cell</span><br><span class="line">        self.rnn_cell0 = layers.GRUCell(units, dropout=0.5)</span><br><span class="line">        self.rnn_cell1 = layers.GRUCell(units, dropout=0.5)</span><br><span class="line">        # 构建分类网络，用于将CELL的输出特征进行分类，2分类</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(units),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None, mask=None):</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        state0 = self.state0</span><br><span class="line">        state1 = self.state1</span><br><span class="line">        out1 = None</span><br><span class="line">        for word in tf.unstack(x, axis=1):  # word: [b, 100]</span><br><span class="line">            out0, state0 = self.rnn_cell0(word, state0, training)</span><br><span class="line">            out1, state1 = self.rnn_cell1(out0, state1, training)</span><br><span class="line">        # 末层最后一个输出作为分类网络的输入: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(out1, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 64  # RNN状态向量长度f</span><br><span class="line">    epochs = 50  # 训练epochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # 装配</span><br><span class="line">    model.compile(optimizer=optimizers.RMSprop(0.001),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # 训练和验证</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # 测试</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="使用Layer实现"><a href="#使用Layer实现" class="headerlink" title="使用Layer实现"></a>使用Layer实现</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"># 以Layer方式实现GRU</span><br><span class="line"># %%</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line">from tensorflow.keras import layers, losses, optimizers, Sequential</span><br><span class="line"></span><br><span class="line"># 指定GPU</span><br><span class="line">os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;3&quot;</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(22)</span><br><span class="line">np.random.seed(22)</span><br><span class="line">os.environ[&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;] = &#x27;2&#x27;</span><br><span class="line">assert tf.__version__.startswith(&#x27;2.&#x27;)</span><br><span class="line"></span><br><span class="line">batch_size = 128  # 批量大小</span><br><span class="line">total_words = 10000  # 词汇表大小N_vocab</span><br><span class="line">max_review_len = 80  # 句子最大长度s，大于的句子部分将截断，小于的将填充</span><br><span class="line">embedding_len = 100  # 词向量特征长度f</span><br><span class="line"># 加载IMDB数据集，此处的数据采用数字编码，一个数字代表一个单词</span><br><span class="line">(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)</span><br><span class="line">print(x_train.shape, len(x_train[0]), y_train.shape)</span><br><span class="line">print(x_test.shape, len(x_test[0]), y_test.shape)</span><br><span class="line"># %%</span><br><span class="line">print(x_train[0])</span><br><span class="line"># %%</span><br><span class="line"># 数字编码表</span><br><span class="line">word_index = keras.datasets.imdb.get_word_index()</span><br><span class="line"># for k,v in word_index.items():</span><br><span class="line">#     print(k,v)</span><br><span class="line"># %%</span><br><span class="line">word_index = &#123;k: (v + 3) for k, v in word_index.items()&#125;</span><br><span class="line">word_index[&quot;&lt;PAD&gt;&quot;] = 0</span><br><span class="line">word_index[&quot;&lt;START&gt;&quot;] = 1</span><br><span class="line">word_index[&quot;&lt;UNK&gt;&quot;] = 2  # unknown</span><br><span class="line">word_index[&quot;&lt;UNUSED&gt;&quot;] = 3</span><br><span class="line"># 翻转编码表</span><br><span class="line">reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def decode_review(text):</span><br><span class="line">    return &#x27; &#x27;.join([reverse_word_index.get(i, &#x27;?&#x27;) for i in text])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">decode_review(x_train[8])</span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line"># x_train:[b, 80]</span><br><span class="line"># x_test: [b, 80]</span><br><span class="line"># 截断和填充句子，使得等长，此处长句子保留句子后面的部分，短句子在前面填充</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)</span><br><span class="line"># 构建数据集，打散，批量，并丢掉最后一个不够batchsz的batch</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(1000).batch(batch_size, drop_remainder=True)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(batch_size, drop_remainder=True)</span><br><span class="line">print(&#x27;x_train shape:&#x27;, x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))</span><br><span class="line">print(&#x27;x_test shape:&#x27;, x_test.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># %%</span><br><span class="line"></span><br><span class="line">class MyRNN(keras.Model):</span><br><span class="line">    # Cell方式构建多层网络</span><br><span class="line">    def __init__(self, units):</span><br><span class="line">        super(MyRNN, self).__init__()</span><br><span class="line">        # 词向量编码 [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        self.embedding = layers.Embedding(total_words, embedding_len,</span><br><span class="line">                                          input_length=max_review_len)</span><br><span class="line">        # 构建RNN</span><br><span class="line">        self.rnn = keras.Sequential([</span><br><span class="line">            layers.GRU(units, dropout=0.5, return_sequences=True),</span><br><span class="line">            layers.GRU(units, dropout=0.5)</span><br><span class="line">        ])</span><br><span class="line">        # 构建分类网络，用于将CELL的输出特征进行分类，2分类</span><br><span class="line">        # [b, 80, 100] =&gt; [b, 64] =&gt; [b, 1]</span><br><span class="line">        self.out_layer = Sequential([</span><br><span class="line">            layers.Dense(32),</span><br><span class="line">            layers.Dropout(rate=0.5),</span><br><span class="line">            layers.ReLU(),</span><br><span class="line">            layers.Dense(1)])</span><br><span class="line"></span><br><span class="line">    def call(self, inputs, training=None,mask=None):</span><br><span class="line">        x = inputs  # [b, 80]</span><br><span class="line">        # embedding: [b, 80] =&gt; [b, 80, 100]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        # rnn cell compute,[b, 80, 100] =&gt; [b, 64]</span><br><span class="line">        x = self.rnn(x)</span><br><span class="line">        # 末层最后一个输出作为分类网络的输入: [b, 64] =&gt; [b, 1]</span><br><span class="line">        x = self.out_layer(x, training)</span><br><span class="line">        # p(y is pos|x)</span><br><span class="line">        prob = tf.sigmoid(x)</span><br><span class="line"></span><br><span class="line">        return prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    units = 32  # RNN状态向量长度f</span><br><span class="line">    epochs = 50  # 训练epochs</span><br><span class="line"></span><br><span class="line">    model = MyRNN(units)</span><br><span class="line">    # 装配</span><br><span class="line">    model.compile(optimizer=optimizers.Adam(0.001),</span><br><span class="line">                  loss=losses.BinaryCrossentropy(),</span><br><span class="line">                  metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">    # 训练和验证</span><br><span class="line">    model.fit(db_train, epochs=epochs, validation_data=db_test)</span><br><span class="line">    # 测试</span><br><span class="line">    model.evaluate(db_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
            <tag> GRU </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>智能小车开发文档</title>
      <link href="/2021/08/23/%E6%99%BA%E8%83%BD%E5%B0%8F%E8%BD%A6%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3/"/>
      <url>/2021/08/23/%E6%99%BA%E8%83%BD%E5%B0%8F%E8%BD%A6%E5%BC%80%E5%8F%91%E6%96%87%E6%A1%A3/</url>
      
        <content type="html"><![CDATA[<p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210823152407.JPG" alt="1"></p><h1 id="MQTT"><a href="#MQTT" class="headerlink" title="MQTT"></a>MQTT</h1><h2 id="主题："><a href="#主题：" class="headerlink" title="主题："></a>主题：</h2><p>小程序——-硬件：jm_y2m</p><p>硬件——-小程序：jm_m2y</p><h1 id="引脚"><a href="#引脚" class="headerlink" title="引脚"></a>引脚</h1><h2 id="uno-r3-引脚定义"><a href="#uno-r3-引脚定义" class="headerlink" title="uno r3 引脚定义"></a>uno r3 引脚定义</h2><p>  直流电机驱动板：5 6 10 11<br>  蜂鸣器 5v：8<br>  超声波传感器 5v：A0 A1<br>  LED 5v：7<br>  光线传感器 5v：A3<br>  人体红外传感器 3.3v：A2<br>  软串口：3, 4</p><h2 id="wifi-d1-引脚定义"><a href="#wifi-d1-引脚定义" class="headerlink" title="wifi d1 引脚定义"></a>wifi d1 引脚定义</h2><p>  DHT11 5v ：D7<br>  触摸按键 3.3v ：D8<br>  OLED 5v ：D15—SCL D14—SDA<br>  软串口：RX=D8,TX=D9</p><h1 id="指令"><a href="#指令" class="headerlink" title="指令"></a>指令</h1><h2 id="esp8266——-gt-uno-r3"><a href="#esp8266——-gt-uno-r3" class="headerlink" title="esp8266——-&gt;uno r3"></a>esp8266——-&gt;uno r3</h2><h3 id="串口"><a href="#串口" class="headerlink" title="串口"></a>串口</h3><p>方向：</p><blockquote><p>前：w</p><p>后：s</p><p>左：a</p><p>右：d</p><p>刹车： q</p></blockquote><p>蜂鸣器：</p><blockquote><p>设置（1声）：1</p><p>消息（3声）：3</p></blockquote><p>设置小夜灯模型：</p><blockquote><p>小夜灯开：n</p><p>小夜灯关：l</p></blockquote><p>设置避障模式：</p><blockquote><p>开启避障：o</p><p>关闭避障：p</p></blockquote><p>初始化完成提示：</p><blockquote><p>消息（3声）：3</p></blockquote><p>车速设置：</p><blockquote><p>1 2 3档</p><p>z x c</p></blockquote><h2 id="小程序———-gt-esp8266"><a href="#小程序———-gt-esp8266" class="headerlink" title="小程序———-&gt;esp8266"></a>小程序———-&gt;esp8266</h2><h3 id="消息"><a href="#消息" class="headerlink" title="消息"></a>消息</h3><ul><li>小程序发送</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;msg&quot;,</span><br><span class="line">  &quot;msg1&quot;: &quot;微信查找公众号&quot;,</span><br><span class="line">  &quot;msg2&quot;: &quot;1234567&quot;,</span><br><span class="line">  &quot;msg3&quot;: &quot;qwertydf&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;success\&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h3><p><strong>消息提醒次数</strong></p><ul><li>小程序发送</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;MSG_BEEP_TIMES&quot;,</span><br><span class="line">&quot;payload&quot;:3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>备忘录模式</strong></p><ul><li><p>小程序发送</p><blockquote><p>1开  0关</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;KEEP_MSG&quot;,</span><br><span class="line">&quot;payload&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>小夜灯开关</strong></p><ul><li><p>小程序发送</p><blockquote><p> //n 开 l 关</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;night_light&quot;,</span><br><span class="line">&quot;payload&quot;:&quot;n&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>避障模式开关</strong></p><ul><li><p>小程序发送</p><blockquote><p> //o 开 p 关</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;barrier_status&quot;,</span><br><span class="line">&quot;payload&quot;:&quot;o&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>静音模式</strong></p><ul><li>小程序发送 </li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> //1 普通 2 静音</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;MODE&quot;,</span><br><span class="line">&quot;payload&quot;:1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>重新配网</strong></p><ul><li>小程序发送</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;changewifi&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>修改城市</strong></p><ul><li>小程序发送</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;CITY&quot;,</span><br><span class="line">&quot;payload&quot;:&quot;lanzhou&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>更换APIKEY</strong></p><ul><li>小程序发送</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;APIKEY&quot;,</span><br><span class="line">&quot;payload&quot;:&quot;123dasdasd&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;setted\&quot;&#125;</span><br></pre></td></tr></table></figure><p><strong>判断8266是否在线</strong></p><ul><li>小程序发送</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;set&quot;,</span><br><span class="line">&quot;device&quot;:&quot;is_connected&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;is_connected\&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="上传数据"><a href="#上传数据" class="headerlink" title="上传数据"></a>上传数据</h3><p><strong>获取环境温湿度 获取小夜灯状态</strong></p><ul><li>小程序发送</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;update&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;temp&quot;:20,&quot;humi&quot;:30,&quot;barrier_status&quot;,&quot;o&quot;,night_light_status&quot;:&quot;n&quot;,&quot;MODE&quot;:1,&quot;KEEP_MSG&quot;:0,&quot;car_speed&quot;:&quot;&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="小车控制"><a href="#小车控制" class="headerlink" title="小车控制"></a>小车控制</h3><p><strong>前后左右</strong></p><ul><li>小程序发送</li></ul><p>前：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;front&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>后：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;back&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>左：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;left&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>右：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;right&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>停：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;stop&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;received\&quot;&#125;&quot;</span><br></pre></td></tr></table></figure><p><strong>车速</strong></p><ul><li><p>小程序发送</p><blockquote><p>一档z ：speed1</p><p>二档x ：speed2</p><p>三档c：speed3</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &quot;app&quot;,</span><br><span class="line">  &quot;type&quot;: &quot;car&quot;,</span><br><span class="line">&quot;directions&quot;:&quot;speed1&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>8266反馈</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;&#123;\&quot;source\&quot;:\&quot;device\&quot;,\&quot;status\&quot;:\&quot;received\&quot;&#125;&quot;</span><br></pre></td></tr></table></figure><image class="main" src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210815224418.JPG"  style="position: absolute; left: 0rpx; top: -218rpx; width: 750rpx; height: 1497rpx; display: flex; box-sizing: border-box"></image>]]></content>
      
      
      <categories>
          
          <category> 硬件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQTT </tag>
            
            <tag> Arduino </tag>
            
            <tag> 微信小程序 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Improving Low-resource Reading Comprehension via Cross-lingual Transposition Rethinking</title>
      <link href="/2021/08/20/Improving%20Low-resource%20Reading%20Comprehension%20via%20Cross-lingual%20Transposition%20Rethinking/"/>
      <url>/2021/08/20/Improving%20Low-resource%20Reading%20Comprehension%20via%20Cross-lingual%20Transposition%20Rethinking/</url>
      
        <content type="html"><![CDATA[<h1 id="Improving-Low-resource-Reading-Comprehension-via-Cross-lingual-Transposition-Rethinking"><a href="#Improving-Low-resource-Reading-Comprehension-via-Cross-lingual-Transposition-Rethinking" class="headerlink" title="Improving Low-resource Reading Comprehension via Cross-lingual Transposition Rethinking"></a>Improving Low-resource Reading Comprehension via Cross-lingual Transposition Rethinking</h1><blockquote><p> <a href="https://arxiv.org/abs/2107.05002">论文：https://arxiv.org/abs/2107.05002</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>解决抽取式阅读理解中低资源语言训练数据不足的问题。 通过在多语言环境中对现有的高质量提取式阅读理解数据集进行建模，提出了一个跨语言转置再思考（XLTT）模型（<strong>Cross-Lingual Transposition ReThinking</strong>）。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>提出了多语言适应性注意（multilingual adaptive attention MAA），将intra-attention，inter-attention结合起来，从每一对语言家族中学习更普遍的可归纳的语义和词法知识。为了充分利用现有的数据集，本文采用了一个新的训练框架，通过计算每个现有数据集和目标数据集之间的任务级相似度来训练模型。</p><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><ul><li>首先，对于现有的抽取式阅读理解数据集，首先利用GNMT构建了多个语系的多语言平行语料，如（英语、日语、韩语……）。 </li><li>其次，利用多语言自适应注意力，在多语言环境中学习语言学相关的语义和词汇知识，以普及到低资源语言。 </li><li>然后，计算每个训练数据集和目标数据集之间的任务级余弦相似度（使用TF-IDF计算），以使用多个训练数据集。</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210818111737.png" alt="image-20210818111737645" style="zoom:67%;" /></p><p>使用共享的多语言编码器，如Multi-BERT和XLM-R，对构建的多语言平行语料库进行编码，以获得上下文的向量表示。</p><p>主要贡献：</p><ul><li>提出了一种跨语言转置再思考（XLTT）的方法，在多语言背景下利用现有的大规模高质量ERC（抽取式机器阅读理解）数据集来解决低资源ERC的问题。</li><li>提出了多语言适应性注意力（MAA）机制，通过结合intra-attention和inter-attention的关系，可以使抽取性RC模型从每一对语言家族中捕捉到更普遍的可归纳的语义和词汇信息，有利于推广到低资源语言。本文还提出了一个新的训练框架，通过计算每个现有训练数据集和目标数据集之间的任务级相似度来训练ERC模型。</li><li>实验结果显示，本文提出的模型在2个多语言提取阅读理解基准上的表现优于6个基准，证明了多语言建模方法的有效性。</li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p><strong>MLQA</strong></p><blockquote><p>七种语言的多向平行抽取式问题回答评估基准</p></blockquote><p>TYDI QA</p><blockquote><p> 涵盖11种不同类型语言的QA数据集，有204K个QA对。</p></blockquote><p><strong>XQuAD</strong></p><blockquote><p> 通过将实例翻译成十种语言，从240个段落中获得了1190个SQuAD v1.1 QA对的数据集。</p></blockquote><p>XTREME</p><blockquote><p>大规模的多语言多任务基准，用于验证和确认多语言模型的跨语言泛化能力。</p></blockquote><h2 id="性能水平-amp-结论"><a href="#性能水平-amp-结论" class="headerlink" title="性能水平&amp;结论"></a>性能水平&amp;结论</h2><p>MLQA数据集测试结果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210818195927.png" alt="QQ20210818-195753"></p><p>XQuAD数据集测试结果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210818195842.png" alt="QQ20210818-195811"></p><p>与之前的最佳模型相比，XLTT模型在MLQA测试集上取得了平均5.1的F1成绩和4.5的EM成绩，在XQuAD测试集上获得了平均2.7的F1成绩和3.6的EM成绩。两种多语言ERC的实验结果证明了本文提出的多语言ERC方法对对低资源语言的有效性。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> Low-resource </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MS MARCO NLG任务调研</title>
      <link href="/2021/08/13/MS-MARCO-NLG%E4%BB%BB%E5%8A%A1%E8%B0%83%E7%A0%94/"/>
      <url>/2021/08/13/MS-MARCO-NLG%E4%BB%BB%E5%8A%A1%E8%B0%83%E7%A0%94/</url>
      
        <content type="html"><![CDATA[<h1 id="MS-MARCO-NLG任务调研"><a href="#MS-MARCO-NLG任务调研" class="headerlink" title="MS MARCO NLG任务调研"></a>MS MARCO NLG任务调研</h1><blockquote><p>NLG——自然语言生成</p><p><a href="https://microsoft.github.io/msmarco/">MS MARCO:https://microsoft.github.io/msmarco/</a></p><p>Natural Language Generation Task:RETIRED(03/01/2018-10/30/2020)</p></blockquote><h2 id="参考论文"><a href="#参考论文" class="headerlink" title="参考论文"></a>参考论文</h2><div class="table-container"><table><thead><tr><th>Rank</th><th>Model</th><th>Paper</th><th>Code</th><th>Submissio Date</th><th>Rouge-L</th><th>Bleu-1</th></tr></thead><tbody><tr><td>2</td><td><strong>PALM</strong> Alibaba Damo NLP</td><td><a href="https://arxiv.org/abs/2004.07159">PALM: Pre-training an Autoencoding&amp;Autoregressive Language Model for Context-conditioned Generation</a></td><td><a href="https://github.com/alibaba/AliceMind/tree/main/PALM">https://github.com/alibaba/AliceMind/tree/main/PALM</a></td><td>December 16th,2019</td><td>0.498</td><td>0.499</td></tr><tr><td>4</td><td><strong>Masque NLGEN Style</strong> NTT Media Intelligence Laboratories</td><td><a href="https://arxiv.org/abs/1901.02262">Multi-style Generative Reading Comprehension</a></td><td></td><td>January 3rd, 2019</td><td>0.496</td><td>0.501</td></tr><tr><td>15</td><td><strong>VNET</strong> Baidu NLP</td><td><a href="https://arxiv.org/abs/1805.02220">Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification</a></td><td></td><td>November 8th, 2018</td><td>0.484</td><td>0.468</td></tr><tr><td>40</td><td><strong>ConZNet</strong> Samsung Research</td><td><a href="https://aclanthology.org/D18-1054/">Cut to the Chase: A Context Zoom-in Network for Reading Comprehension</a></td><td></td><td>July 16th, 2018</td><td>0.421</td><td>0.386</td></tr><tr><td>90</td><td><strong>BiDaF Baseline(Implemented By MSMARCO Team)</strong> Allen Institute for AI &amp; University of Washington</td><td><a href="https://arxiv.org/abs/1611.01603">Bidirectional Attention Flow for Machine Comprehension</a></td><td><a href="https://github.com/allenai/bi-att-flow">https://github.com/allenai/bi-att-flow</a></td><td>April 23th, 2018</td><td>0.169</td><td>0.093</td></tr></tbody></table></div><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><div class="table-container"><table><thead><tr><th>Dataset</th><th>Segment</th><th>Query Source</th><th>Answer</th><th>Queries</th><th>Document</th></tr></thead><tbody><tr><td>SQuAD</td><td>No</td><td>Crowd-sourced</td><td>Span</td><td>100k</td><td>536</td></tr><tr><td>CNN/Daily Mail</td><td>No</td><td>close</td><td>Fill in entity</td><td>1.4M</td><td>93K CNN, 220K DM</td></tr><tr><td>MS MARCO v2</td><td>Yes</td><td>User logs</td><td>Human generated</td><td>1M</td><td>8.8M passages, 3.2M docs</td></tr><tr><td>NarrativeQA</td><td>No</td><td>Crowd-sourced</td><td>Human generated</td><td>47k</td><td>1572 stories</td></tr><tr><td>DuReader</td><td>No</td><td>Crowd-sourced</td><td>Human generated</td><td>200K</td><td>1M</td></tr></tbody></table></div><h2 id="常用模型"><a href="#常用模型" class="headerlink" title="常用模型"></a>常用模型</h2><div class="table-container"><table><thead><tr><th>Model</th><th>介绍</th><th>论文</th></tr></thead><tbody><tr><td><strong>PALM</strong></td><td>Pre-training an Autoencoding&amp;Autoregressive Language Model</td><td><a href="https://arxiv.org/abs/2004.07159">PALM: Pre-training an Autoencoding&amp;Autoregressive Language Model for Context-conditioned Generation</a></td></tr><tr><td><strong>ConZNet</strong></td><td>context zoom-in network</td><td><a href="https://aclanthology.org/D18-1054/">Cut to the Chase: A Context Zoom-in Network for Reading Comprehension</a></td></tr><tr><td><strong>V-NET</strong></td><td>an end-to-end frame- work to tackle the multi-passage MRC task</td><td><a href="https://arxiv.org/abs/1805.02220">Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification</a></td></tr><tr><td>S-Net</td><td>an extraction-then-synthesis framework</td><td><a href="https://arxiv.org/abs/1706.04815">S-Net: From Answer Extraction to Answer Generation for Machine Reading Comprehension</a></td></tr><tr><td>Selector NLGEN</td><td></td><td></td></tr><tr><td>BERT+Multi-Pointer</td><td></td><td></td></tr><tr><td>CompLM</td><td></td><td></td></tr><tr><td><strong>Masque</strong></td><td>based on multi-source abstractive summarization and learns multi-style answers together</td><td><a href="https://arxiv.org/abs/1901.02262">Multi-style Generative Reading Comprehension</a></td></tr><tr><td><strong>BiDAF</strong></td><td>Bi-Directional Attention Flow</td><td><a href="https://arxiv.org/abs/1611.01603">Bidirectional Attention Flow for Machine Comprehension</a></td></tr><tr><td>MRU</td><td>Multi-Range Reasoning Units</td><td><a href="https://arxiv.org/abs/1803.09074">Multi-range Reasoning for Machine Comprehension</a></td></tr></tbody></table></div><h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><p>NLG常用metrics：</p><ul><li><strong>BLEU</strong></li><li><strong>ROUGE</strong></li><li><strong>METEOR</strong></li><li>lNIST/CIDEr</li><li>STM</li><li>TER</li><li>TERp</li></ul><h3 id="ROUGE"><a href="#ROUGE" class="headerlink" title="ROUGE"></a>ROUGE</h3><p>ROUGE 指标的全称是 (Recall-Oriented Understudy for Gisting Evaluation)，主要基于召回率。ROUGE 是一种常用的机器翻译和文章摘要评价指标，由 Chin-Yew Lin 提出。</p><p> 4 种 ROUGE 方法：</p><ul><li>ROUGE-N: 在 N-gram 上计算召回率。</li><li>ROUGE-L: 考虑了机器译文和参考译文之间的最长公共子序列（长度越长，得分越高，基于F值。）</li><li>ROUGE-W: 改进了ROUGE-L，用加权的方法计算最长公共子序列。</li></ul><h4 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h4><ul><li><strong>ROUGE-N：</strong></li></ul><p><img src="https://www.zhihu.com/equation?tex=ROUGE-N+%3D+%5Cfrac+++++%7B+++++++++%5Csum_%5Climits%7BS%5Cin+%5C%7BReferenceSummaries%5C%7D%7D+++++%5Csum_%5Climits%7Bgram_n%5Cin+S%7D+++++Count_%7Bmatch%7D%28gram_n%29+++++%7D+++++%7B+++++++++%5Csum_%5Climits%7BS%5Cin+%5C%7BReferenceSummaries%5C%7D%7D+++++%5Csum_%5Climits%7Bgram_n%5Cin+S%7D+++++Count%28gram_n%29+++++%7D" alt=""></p><p>其中，$n$ 表示n-gram，$Count(gram<em>n)$表示一个n-gram的出现次数，$Count</em>{match}(gram_n)$ 表示一个n-gram的共现次数。</p><ul><li><strong>ROUGE-L：</strong></li></ul><p><img src="https://www.zhihu.com/equation?tex=ROUGE-L+%3D+%5Cfrac+%7B%281%2B%5Cbeta%5E2%29+R_%7Blcs%7D+P_%7Blcs%7D%7D+%7BR_%7Blcs%7D+%2B+%5Cbeta%5E2+P_%7Blcs%7D%7D+%5C%5C+R_%7Blcs%7D+%3D+%5Cfrac+%7BLCS%28X%2C+Y%29%7D+%7Bm%7D+%5C%5C+P_%7Blcs%7D+%3D+%5Cfrac+%7BLCS%28X%2C+Y%29%7D+%7Bn%7D" alt=""></p><p>其中， $X$表示候选摘要，$Y$表示参考摘要， $LCS(X,Y)$ 表示候选摘要与参考摘要的最长公共子序列的长度，$m$​表示参考摘要的长度，$n$​表示候选摘要的长度。</p><h3 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h3><p>BLEU 的全称是 双语评估辅助工具(Bilingual evaluation understudy)，BLEU 的分数取值范围是 0～1，分数越接近1，说明翻译的质量越高。BLEU 主要基于精确率(Precision)。</p><h4 id="计算公式-1"><a href="#计算公式-1" class="headerlink" title="计算公式"></a>计算公式</h4><p><img src="https://www.zhihu.com/equation?tex=BLEU+%3D+BP+%5Ccdot+exp%28%5Csum_%5Climits%7Bn%3D1%7D%5EN+w_n+log%5C%2C+p_n+%29" alt=""></p><p>其中$n$表示n-gram，$w_n$​ 表示n-gram的权重。</p><p>$BP$表示短句子惩罚因子（brevity penaty)，用$r$表示最短的参考翻译的长度，$c$表示候选翻译的长度。$BP$具体计算方法为：</p><script type="math/tex; mode=display">f(x) =   \begin{array}{lr}    1 & c>r\\   e^{(1-r/c)} & c \le r  \end{array}</script><p>$p_n$表示n-gram的覆盖率，具体计算方式为：</p><p><img src="https://www.zhihu.com/equation?tex=p_n+%3D+%5Cfrac+++++%7B+++++++++%5Csum_%5Climits%7BC%5Cin+%5C%7BCandidates%5C%7D%7D+++++%5Csum_%5Climits%7Bn-gram%5Cin+C%7D+++++Count_%7Bclip%7D%28n-gram%29+++++%7D+++++%7B+++++++++%5Csum_%5Climits%7BC%27%5Cin+%5C%7BCandidates%5C%7D%7D+++++%5Csum_%5Climits%7Bn-gram%5Cin+C%27%7D+++++Count%28n-gram%29+++++%7D" alt=""></p><p>$Count_{clip}$是截断计数，其计数方式为：将一个n-gram在候选翻译中出现的次数，与在各个参考翻译中出现次数的最大值进行比较，取较小的那一个。</p><h3 id="METEOR"><a href="#METEOR" class="headerlink" title="METEOR"></a>METEOR</h3><p>METEOR全称显式排序的翻译评估指标(Metric for Evaluation of Translation with Explicit Ordering)。</p><p>METEOR 是基于BLEU进行了一些改进，其目的是解决一些 BLEU 标准中固有的缺陷 。使用 WordNet 计算特定的序列匹配，同义词，词根和词缀，释义之间的匹配关系，改善了BLEU的效果，使其跟人工判别共更强的相关性。并且，是基于F值的。</p><h4 id="计算公式-2"><a href="#计算公式-2" class="headerlink" title="计算公式"></a>计算公式</h4><p><img src="https://www.zhihu.com/equation?tex=METEOR+%3D+%281-pen%29%5Ctimes+F_%7Bmeans%7D" alt=""></p><p>其中：</p><p><img src="https://www.zhihu.com/equation?tex=F_%7Bmeans%7D+%3D+%5Cfrac+%7BPR%7D+%7B%5Calpha+P+%2B+%281-%5Calpha%29R%7D%5C%5C+P+%3D+%5Cfrac+%7Bm%7D+%7Bc%7D%5C%5C+R+%3D+%5Cfrac+%7Bm%7D+%7Br%7D" alt=""></p><p>$\alpha$ 为可调控的参数，$m$ 为候选翻译中能够被匹配的一元组的数量，$c$ 为候选翻译的长度，$r$为参考摘要的长度。</p><p>$pen$ 为惩罚因子，惩罚的是候选翻译中的词序与参考翻译中的词序不同，具体计算方法为：</p><p><img src="https://www.zhihu.com/equation?tex=Pen+%3D+%5Cfrac+%7B%5C%23chunks%7D+%7Bm%7D" alt=""></p><p>$m$​是候选翻译中能够被匹配的一元组的数量，$#chunks$​​​ 指的是chunk的数量，即既在候选翻译中相邻又在参考翻译中相邻的被匹配的一元组聚集而成的单位。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MARCO </tag>
            
            <tag> NLG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>简版-翻译、摘要、会话、文本生成任务顶会论文</title>
      <link href="/2021/08/13/%E7%AE%80%E7%89%88-%E7%BF%BB%E8%AF%91%E3%80%81%E6%91%98%E8%A6%81%E3%80%81%E4%BC%9A%E8%AF%9D%E3%80%81%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/"/>
      <url>/2021/08/13/%E7%AE%80%E7%89%88-%E7%BF%BB%E8%AF%91%E3%80%81%E6%91%98%E8%A6%81%E3%80%81%E4%BC%9A%E8%AF%9D%E3%80%81%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h1 id="简版-翻译、摘要、会话、文本生成任务顶会论文"><a href="#简版-翻译、摘要、会话、文本生成任务顶会论文" class="headerlink" title="简版-翻译、摘要、会话、文本生成任务顶会论文"></a>简版-翻译、摘要、会话、文本生成任务顶会论文</h1><h2 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h2><h3 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1811.00357&#39;]">Latent Variable Model for Multi-modal Translation</a></td><td></td><td><a href="https://github.com/iacercalixto/variational_mmt">https://github.com/iacercalixto/variational_mmt</a></td><td><a href="https://arxiv.org/pdf/1811.00357">https://arxiv.org/pdf/1811.00357</a></td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.05414&#39;]">Rewriter-Evaluator Architecture for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.05414">https://arxiv.org/pdf/2012.05414</a></td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.08226&#39;]">Consistency Regularization for Cross-Lingual Fine-Tuning</a></td><td></td><td><a href="https://github.com/bozheng-hit/xTune">https://github.com/bozheng-hit/xTune</a></td><td><a href="https://arxiv.org/pdf/2106.08226">https://arxiv.org/pdf/2106.08226</a></td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06381&#39;]">Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment</a></td><td></td><td><a href="https://github.com/CZWin32768/XLM-Align">https://github.com/CZWin32768/XLM-Align</a></td><td><a href="https://arxiv.org/pdf/2106.06381">https://arxiv.org/pdf/2106.06381</a></td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15127&#39;]">Improving Zero-Shot Translation by Disentangling Positional Information</a></td><td></td><td><a href="https://github.com/nlp-dke/NMTGMinor/tree/master/recipes/zero-shot">https://github.com/nlp-dke/NMTGMinor/tree/master/recipes/zero-shot</a></td><td><a href="https://arxiv.org/pdf/2012.15127">https://arxiv.org/pdf/2012.15127</a></td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15715&#39;]">Beyond Offline Mapping: Learning Cross-lingual Word Embeddings through Context Anchoring</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15715">https://arxiv.org/pdf/2012.15715</a></td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15421&#39;]">Verb Knowledge Injection for Multilingual Event Processing</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15421">https://arxiv.org/pdf/2012.15421</a></td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06937&#39;]">Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning</a></td><td></td><td><a href="https://github.com/INK-USC/XCSR">https://github.com/INK-USC/XCSR</a></td><td><a href="https://arxiv.org/pdf/2106.06937">https://arxiv.org/pdf/2106.06937</a></td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00148&#39;]">Bilingual Lexicon Induction via Unsupervised Bitext Construction and Word Alignment</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2101.00148">https://arxiv.org/pdf/2101.00148</a></td></tr><tr><td>10</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11867&#39;]">Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation</a></td><td></td><td><a href="https://github.com/bzhangGo/zero">https://github.com/bzhangGo/zero</a></td><td><a href="https://arxiv.org/pdf/2004.11867">https://arxiv.org/pdf/2004.11867</a></td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13169&#39;]">Simultaneous Translation Policies: From Fixed to Adaptive</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.13169">https://arxiv.org/pdf/2004.13169</a></td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14021&#39;]">Multiscale Collaborative Deep Models for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/pemywei/MSC-NMT">https://github.com/pemywei/MSC-NMT</a></td><td><a href="https://arxiv.org/pdf/2004.14021">https://arxiv.org/pdf/2004.14021</a></td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14788&#39;]">Character-Level Translation with Self-attention</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14788">https://arxiv.org/pdf/2004.14788</a></td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00850&#39;]">ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/lifu-tu/ENGINE">https://github.com/lifu-tu/ENGINE</a></td><td><a href="https://arxiv.org/pdf/2005.00850">https://arxiv.org/pdf/2005.00850</a></td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00308&#39;]">Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.00308">https://arxiv.org/pdf/2005.00308</a></td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.06606&#39;]">Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/xlhex/dpe">https://github.com/xlhex/dpe</a></td><td><a href="https://arxiv.org/pdf/2005.06606">https://arxiv.org/pdf/2005.06606</a></td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.02014&#39;]">Norm-Based Curriculum Learning for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/NLP2CT/norm-nmt">https://github.com/NLP2CT/norm-nmt</a></td><td><a href="https://arxiv.org/pdf/2006.02014">https://arxiv.org/pdf/2006.02014</a></td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2007.02671&#39;]">Bilingual Dictionary Based Neural Machine Translation without Using Parallel Sentences</a></td><td></td><td><a href="https://github.com/mttravel/Dictionary-based-MT">https://github.com/mttravel/Dictionary-based-MT</a></td><td><a href="https://arxiv.org/pdf/2007.02671">https://arxiv.org/pdf/2007.02671</a></td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11867&#39;]">Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation</a></td><td></td><td><a href="https://github.com/bzhangGo/zero">https://github.com/bzhangGo/zero</a></td><td><a href="https://arxiv.org/pdf/2004.11867">https://arxiv.org/pdf/2004.11867</a></td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00850&#39;]">ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/lifu-tu/ENGINE">https://github.com/lifu-tu/ENGINE</a></td><td><a href="https://arxiv.org/pdf/2005.00850">https://arxiv.org/pdf/2005.00850</a></td></tr><tr><td>21</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.01313&#39;]">An Effective Approach to Unsupervised Machine Translation</a></td><td></td><td><a href="https://github.com/artetxem/monoses">https://github.com/artetxem/monoses</a></td><td><a href="https://arxiv.org/pdf/1902.01313">https://arxiv.org/pdf/1902.01313</a></td></tr><tr><td>22</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.05979&#39;]">When a Good Translation is Wrong in Context: Context-Aware Machine Translation Improves on Deixis, Ellipsis, and Lexical Cohesion</a></td><td></td><td><a href="https://github.com/lena-voita/good-translation-wrong-in-context">https://github.com/lena-voita/good-translation-wrong-in-context</a></td><td><a href="https://arxiv.org/pdf/1905.05979">https://arxiv.org/pdf/1905.05979</a></td></tr><tr><td>23</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.02780&#39;]">Syntactically Supervised Transformers for Faster Neural Machine Translation</a></td><td></td><td><a href="https://github.com/dojoteef/synst">https://github.com/dojoteef/synst</a></td><td><a href="https://arxiv.org/pdf/1906.02780">https://arxiv.org/pdf/1906.02780</a></td></tr><tr><td>24</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/2106.08680&#39;, &#39;https://arxiv.org/abs/1906.00591&#39;]">Evaluating Gender Bias in Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.08680">https://arxiv.org/pdf/2106.08680</a></td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01787&#39;]">Learning Deep Transformer Models for Machine Translation</a></td><td></td><td><a href="https://github.com/wangqiangneu/dlcl">https://github.com/wangqiangneu/dlcl</a></td><td><a href="https://arxiv.org/pdf/1906.01787">https://arxiv.org/pdf/1906.01787</a></td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00376&#39;]">Domain Adaptation of Neural Machine Translation by Lexicon Induction</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.00376">https://arxiv.org/pdf/1906.00376</a></td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.09444&#39;]">Retrieving Sequential Information for Non-Autoregressive Neural Machine Translation</a></td><td></td><td><a href="https://github.com/ictnlp/RSI-NAT">https://github.com/ictnlp/RSI-NAT</a></td><td><a href="https://arxiv.org/pdf/1906.09444">https://arxiv.org/pdf/1906.09444</a></td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1810.06729&#39;]">Robust Neural Machine Translation with Joint Textual and Phonetic Embedding</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1810.06729">https://arxiv.org/pdf/1810.06729</a></td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.13872&#39;]">Simple and Effective Paraphrastic Similarity from Parallel Translations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.13872">https://arxiv.org/pdf/1909.13872</a></td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.04980&#39;]">Unsupervised Question Answering by Cloze Translation</a></td><td></td><td><a href="https://github.com/facebookresearch/UnsupervisedQA">https://github.com/facebookresearch/UnsupervisedQA</a></td><td><a href="https://arxiv.org/pdf/1906.04980">https://arxiv.org/pdf/1906.04980</a></td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.10761&#39;]">Bilingual Lexicon Induction through Unsupervised Machine Translation</a></td><td></td><td><a href="https://github.com/artetxem/monoses">https://github.com/artetxem/monoses</a></td><td><a href="https://arxiv.org/pdf/1907.10761">https://arxiv.org/pdf/1907.10761</a></td></tr><tr><td>32</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.10523&#39;]">Soft Contextual Data Augmentation for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/teslacool/SCA">https://github.com/teslacool/SCA</a></td><td><a href="https://arxiv.org/pdf/1905.10523">https://arxiv.org/pdf/1905.10523</a></td></tr><tr><td>33</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03785&#39;]">Generalized Data Augmentation for Low-Resource Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.03785">https://arxiv.org/pdf/1906.03785</a></td></tr></tbody></table></div><h3 id="EMNLP"><a href="#EMNLP" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.10485&#39;]">Fully Quantized Transformer for Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1910.10485">https://arxiv.org/pdf/1910.10485</a></td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.10260&#39;]">Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.10260">https://arxiv.org/pdf/2002.10260</a></td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14109&#39;]">Adversarial Subword Regularization for Robust Neural Machine Translation</a></td><td></td><td><a href="https://github.com/dmis-lab/AdvSR">https://github.com/dmis-lab/AdvSR</a></td><td><a href="https://arxiv.org/pdf/2004.14109">https://arxiv.org/pdf/2004.14109</a></td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02353&#39;]">Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages</a></td><td></td><td><a href="https://github.com/masakhane-io/masakhane-mt">https://github.com/masakhane-io/masakhane-mt</a></td><td><a href="https://arxiv.org/pdf/2010.02353">https://arxiv.org/pdf/2010.02353</a></td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.14824&#39;]">On Romanization for Model Transfer Between Scripts in Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.14824">https://arxiv.org/pdf/2009.14824</a></td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13781&#39;]">Graph-to-Tree Neural Networks for Learning Structured Input-Output Translation with Applications to Semantic Parsing and Math Word Problem</a></td><td></td><td><a href="https://github.com/IBM/Graph2Tree">https://github.com/IBM/Graph2Tree</a></td><td><a href="https://arxiv.org/pdf/2004.13781">https://arxiv.org/pdf/2004.13781</a></td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04924&#39;]">On Long-Tailed Phenomena in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/vyraun/long-tailed">https://github.com/vyraun/long-tailed</a></td><td><a href="https://arxiv.org/pdf/2010.04924">https://arxiv.org/pdf/2010.04924</a></td></tr><tr><td>8</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.02955&#39;]">A Multilingual View of Unsupervised Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.02955">https://arxiv.org/pdf/2002.02955</a></td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.00180&#39;]">Explicit Cross-lingual Pre-training for Unsupervised Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.00180">https://arxiv.org/pdf/1909.00180</a></td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.00157&#39;]">Improving Back-Translation with Uncertainty-based Confidence Estimation</a></td><td></td><td><a href="https://github.com/THUNLP-MT/UCE4BT">https://github.com/THUNLP-MT/UCE4BT</a></td><td><a href="https://arxiv.org/pdf/1909.00157">https://arxiv.org/pdf/1909.00157</a></td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1912.07239&#39;]">Iterative Dual Domain Adaptation for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1912.07239">https://arxiv.org/pdf/1912.07239</a></td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01383&#39;]">Context-Aware Monolingual Repair for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/lena-voita/good-translation-wrong-in-context">https://github.com/lena-voita/good-translation-wrong-in-context</a></td><td><a href="https://arxiv.org/pdf/1909.01383">https://arxiv.org/pdf/1909.01383</a></td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.09646&#39;]">Dynamic Past and Future for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/zhengzx-nlp/dynamic-nmt">https://github.com/zhengzx-nlp/dynamic-nmt</a></td><td><a href="https://arxiv.org/pdf/1904.09646">https://arxiv.org/pdf/1904.09646</a></td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01559&#39;]">Simpler and Faster Learning of Adaptive Policies for Simultaneous Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.01559">https://arxiv.org/pdf/1909.01559</a></td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.10430&#39;]">Unsupervised Domain Adaptation for Neural Machine Translation with Domain-Aware Feature Embeddings</a></td><td></td><td><a href="https://github.com/zdou0830/DAFE">https://github.com/zdou0830/DAFE</a></td><td><a href="https://arxiv.org/pdf/1908.10430">https://arxiv.org/pdf/1908.10430</a></td></tr><tr><td>16</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1911.00835&#39;]">Controlling Text Complexity in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/sweta20/ComplexityControlledMT">https://github.com/sweta20/ComplexityControlledMT</a></td><td><a href="https://arxiv.org/pdf/1911.00835">https://arxiv.org/pdf/1911.00835</a></td></tr><tr><td>17</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.05731&#39;]">Simple and Effective Noisy Channel Modeling for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></td><td><a href="https://arxiv.org/pdf/1908.05731">https://arxiv.org/pdf/1908.05731</a></td></tr><tr><td>18</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.06708&#39;]">Hint-Based Training for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/zhuohan123/hint-nart">https://github.com/zhuohan123/hint-nart</a></td><td><a href="https://arxiv.org/pdf/1909.06708">https://arxiv.org/pdf/1909.06708</a></td></tr></tbody></table></div><h3 id="NAACL"><a href="#NAACL" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.04507&#39;]">Self-Training for Unsupervised Neural Machine Translation in Unbalanced Training Data Scenarios</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.04507">https://arxiv.org/pdf/2004.04507</a></td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2009.11201&#39;]">Harnessing Multilinguality in Unsupervised Machine Translation for Rare Languages</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.11201">https://arxiv.org/pdf/2009.11201</a></td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.06799&#39;]">Towards Continual Learning for Multilingual Machine Translation via Vocabulary Substitution</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2103.06799">https://arxiv.org/pdf/2103.06799</a></td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2003.09586&#39;]">Probing Word Translations in the Transformer and Trading Decoder for Encoder Layers</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2003.09586">https://arxiv.org/pdf/2003.09586</a></td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.06490&#39;, &#39;https://arxiv.org/abs/1911.00234&#39;]">Sequence Tagging and Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1911.00234">https://arxiv.org/pdf/1911.00234</a></td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2008.09396&#39;]">Neural Machine Translation without Embeddings</a></td><td></td><td><a href="https://github.com/UriSha/EmbeddinglessNMT">https://github.com/UriSha/EmbeddinglessNMT</a></td><td><a href="https://arxiv.org/pdf/2008.09396">https://arxiv.org/pdf/2008.09396</a></td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.07316&#39;]">From Masked Language Modeling to Translation: Non-English Auxiliary Tasks Improve Zero-shot Spoken Language Understanding</a></td><td></td><td><a href="https://bitbucket.org/robvanderg/xsid">https://bitbucket.org/robvanderg/xsid</a></td><td><a href="https://arxiv.org/pdf/2105.07316">https://arxiv.org/pdf/2105.07316</a></td></tr><tr><td>8</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.10531&#39;]">Improving the Lexical Ability of Pretrained Language Models for Unsupervised Neural Machine Translation</a></td><td></td><td><a href="https://github.com/alexandra-chron/lexical_xlm_relm">https://github.com/alexandra-chron/lexical_xlm_relm</a></td><td><a href="https://arxiv.org/pdf/2103.10531">https://arxiv.org/pdf/2103.10531</a></td></tr><tr><td>9</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12868&#39;]">Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/yongchanghao/multi-task-nat">https://github.com/yongchanghao/multi-task-nat</a></td><td><a href="https://arxiv.org/pdf/2010.12868">https://arxiv.org/pdf/2010.12868</a></td></tr><tr><td>10</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05146&#39;]">Assessing Reference-Free Peer Evaluation for Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.05146">https://arxiv.org/pdf/2104.05146</a></td></tr><tr><td>11</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2009.09654&#39;]">Generative Imagination Elevates Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.09654">https://arxiv.org/pdf/2009.09654</a></td></tr><tr><td>12</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12827&#39;]">Context-aware Decoder for Neural Machine Translation using a Target-side Document-Level Language Model</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12827">https://arxiv.org/pdf/2010.12827</a></td></tr><tr><td>13</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05964&#39;]">Restoring and Mining the Records of the Joseon Dynasty via Neural Language Modeling and Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.05964">https://arxiv.org/pdf/2104.05964</a></td></tr><tr><td>14</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.06683&#39;]">The Curious Case of Hallucinations in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/vyraun/hallucinations">https://github.com/vyraun/hallucinations</a></td><td><a href="https://arxiv.org/pdf/2104.06683">https://arxiv.org/pdf/2104.06683</a></td></tr><tr><td>15</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.08942&#39;]">Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/samuki/reinforce-joey">https://github.com/samuki/reinforce-joey</a></td><td><a href="https://arxiv.org/pdf/2106.08942">https://arxiv.org/pdf/2106.08942</a></td></tr><tr><td>16</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.03137&#39;]">Cross-lingual Supervision Improves Unsupervised Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.03137">https://arxiv.org/pdf/2004.03137</a></td></tr><tr><td>17</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.02461&#39;]">ReWE: Regressing Word Embeddings for Regularization of Neural Machine Translation Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.02461">https://arxiv.org/pdf/1904.02461</a></td></tr><tr><td>18</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09514&#39;]">Lost in Machine Translation: A Method to Reduce Meaning Loss</a></td><td></td><td><a href="https://github.com/reubenharry/pragmatic-translation">https://github.com/reubenharry/pragmatic-translation</a></td><td><a href="https://arxiv.org/pdf/1902.09514">https://arxiv.org/pdf/1902.09514</a></td></tr><tr><td>19</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.02878&#39;]">Syntax-Enhanced Neural Machine Translation with Syntax-Aware Word Representations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1905.02878">https://arxiv.org/pdf/1905.02878</a></td></tr><tr><td>20</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09508&#39;, &#39;https://arxiv.org/abs/1902.01509&#39;]">Improving Robustness of Machine Translation with Synthetic Noise</a></td><td></td><td><a href="https://github.com/MysteryVaibhav/robust_mtnt">https://github.com/MysteryVaibhav/robust_mtnt</a></td><td><a href="https://arxiv.org/pdf/1902.09508">https://arxiv.org/pdf/1902.09508</a></td></tr><tr><td>21</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.04079&#39;]">Differentiable Sampling with Flexible Reference Word Order for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/Izecson/saml-nmt">https://github.com/Izecson/saml-nmt</a></td><td><a href="https://arxiv.org/pdf/1904.04079">https://arxiv.org/pdf/1904.04079</a></td></tr><tr><td>22</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00556&#39;]">Fluent Translations from Disfluent Speech in End-to-End Speech Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.00556">https://arxiv.org/pdf/1906.00556</a></td></tr><tr><td>23</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.08788&#39;]">Selective Attention for Context-aware Neural Machine Translation</a></td><td></td><td><a href="https://github.com/sameenmaruf/selective-attn">https://github.com/sameenmaruf/selective-attn</a></td><td><a href="https://arxiv.org/pdf/1903.08788">https://arxiv.org/pdf/1903.08788</a></td></tr></tbody></table></div><h3 id="COLING"><a href="#COLING" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00890&#39;]">Emergent Communication Pretraining for Few-Shot Machine Translation</a></td><td></td><td><a href="https://github.com/cambridgeltl/ECNMT">https://github.com/cambridgeltl/ECNMT</a></td><td><a href="https://arxiv.org/pdf/2011.00890">https://arxiv.org/pdf/2011.00890</a></td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00678&#39;]">Investigating Catastrophic Forgetting During Continual Training for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00678">https://arxiv.org/pdf/2011.00678</a></td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.01482&#39;]">Layer-wise Multi-view Learning for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.01482">https://arxiv.org/pdf/2011.01482</a></td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.03732&#39;]">Leveraging Discourse Rewards for Document-Level Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.03732">https://arxiv.org/pdf/2010.03732</a></td></tr><tr><td>5</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.02266&#39;]">Optimized Transformer for Low-resource Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.02266">https://arxiv.org/pdf/2011.02266</a></td></tr><tr><td>6</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12549&#39;]">Robust Unsupervised Neural Machine Translation with Adversarial Denoising Training</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.12549">https://arxiv.org/pdf/2002.12549</a></td></tr><tr><td>7</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.11018&#39;]">Token Drop mechanism for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/zhajiahe/Token_Drop">https://github.com/zhajiahe/Token_Drop</a></td><td><a href="https://arxiv.org/pdf/2010.11018">https://arxiv.org/pdf/2010.11018</a></td></tr><tr><td>8</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.03469&#39;]">Understanding Pure Character-Based Neural Machine Translation: The Case of Translating Finnish into English</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.03469">https://arxiv.org/pdf/2011.03469</a></td></tr></tbody></table></div><h2 id="会话-对话系统"><a href="#会话-对话系统" class="headerlink" title="会话/对话系统"></a>会话/对话系统</h2><h3 id="ACL-1"><a href="#ACL-1" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.12458&#39;]">TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.12458">https://arxiv.org/pdf/2012.12458</a></td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00162&#39;]">HERALD: An Annotation Efficient Method to Detect User Disengagement in Social Conversations</a></td><td></td><td><a href="https://github.com/Weixin-Liang/HERALD">https://github.com/Weixin-Liang/HERALD</a></td><td><a href="https://arxiv.org/pdf/2106.00162">https://arxiv.org/pdf/2106.00162</a></td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.13073&#39;]">Maria: A Visual Experience Powered Conversational Agent</a></td><td></td><td><a href="https://github.com/jokieleung/Maria">https://github.com/jokieleung/Maria</a></td><td><a href="https://arxiv.org/pdf/2105.13073">https://arxiv.org/pdf/2105.13073</a></td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.14756&#39;]">Dialogue Response Selection with Hierarchical Curriculum Learning</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.14756">https://arxiv.org/pdf/2012.14756</a></td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.14556&#39;]">Diversifying Dialog Generation via Adaptive Label Smoothing</a></td><td></td><td><a href="https://github.com/lemon234071/AdaLabel">https://github.com/lemon234071/AdaLabel</a></td><td><a href="https://arxiv.org/pdf/2105.14556">https://arxiv.org/pdf/2105.14556</a></td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06169&#39;]">BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data</a></td><td></td><td><a href="https://github.com/songhaoyu/BoB">https://github.com/songhaoyu/BoB</a></td><td><a href="https://arxiv.org/pdf/2106.06169">https://arxiv.org/pdf/2106.06169</a></td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.13391&#39;]">I like fish, especially dolphins: Addressing Contradictions in Dialogue Modeling</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.13391">https://arxiv.org/pdf/2012.13391</a></td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2011.09553&#39;]">A Sequence-to-Sequence Approach to Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/sweetalyssum/Seq2Seq-DU">https://github.com/sweetalyssum/Seq2Seq-DU</a></td><td><a href="https://arxiv.org/pdf/2011.09553">https://arxiv.org/pdf/2011.09553</a></td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.03410&#39;]">Generating Relevant and Coherent Dialogue Responses using Self-Separated Conditional Variational AutoEncoders</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.03410">https://arxiv.org/pdf/2106.03410</a></td></tr><tr><td>10</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00123&#39;]">Intent Classification and Slot Filling for Privacy Policies</a></td><td></td><td><a href="https://github.com/wasiahmad/PolicyIE">https://github.com/wasiahmad/PolicyIE</a></td><td><a href="https://arxiv.org/pdf/2101.00123">https://arxiv.org/pdf/2101.00123</a></td></tr><tr><td>11</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.12578&#39;]">Dual Slot Selector via Local Reliability Verification for Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/guojinyu88/DSSDST">https://github.com/guojinyu88/DSSDST</a></td><td><a href="https://arxiv.org/pdf/2107.12578">https://arxiv.org/pdf/2107.12578</a></td></tr><tr><td>12</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.15171&#39;]">Learning from Perturbations: Diverse and Informative Dialogue Generation with Inverse Adversarial Training</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.15171">https://arxiv.org/pdf/2105.15171</a></td></tr><tr><td>13</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.11164&#39;]">Modeling Bilingual Conversational Characteristics for Neural Chat Translation</a></td><td></td><td><a href="https://github.com/XL2248/CPCC">https://github.com/XL2248/CPCC</a></td><td><a href="https://arxiv.org/pdf/2107.11164">https://arxiv.org/pdf/2107.11164</a></td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11019&#39;]">Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/LooperXX/DF-Net">https://github.com/LooperXX/DF-Net</a></td><td><a href="https://arxiv.org/pdf/2004.11019">https://arxiv.org/pdf/2004.11019</a></td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11054&#39;]">Learning Dialog Policies from Weak Demonstrations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.11054">https://arxiv.org/pdf/2004.11054</a></td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.08866&#39;]">Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained Conversational Representations</a></td><td></td><td><a href="https://github.com/PolyAI-LDN/task-specific-datasets">https://github.com/PolyAI-LDN/task-specific-datasets</a></td><td><a href="https://arxiv.org/pdf/2005.08866">https://arxiv.org/pdf/2005.08866</a></td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.04346&#39;]">Diversifying Dialogue Generation with Non-Conversational Text</a></td><td></td><td><a href="https://github.com/chin-gyou/Div-Non-Conv">https://github.com/chin-gyou/Div-Non-Conv</a></td><td><a href="https://arxiv.org/pdf/2005.04346">https://arxiv.org/pdf/2005.04346</a></td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.09544&#39;]">Grounding Conversations with Improvised Dialogues</a></td><td></td><td><a href="https://github.com/wise-east/spolin">https://github.com/wise-east/spolin</a></td><td><a href="https://arxiv.org/pdf/2004.09544">https://arxiv.org/pdf/2004.09544</a></td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04908&#39;]">Designing Precise and Robust Dialogue Response Evaluators</a></td><td></td><td><a href="https://github.com/ZHAOTING/dialog-processing">https://github.com/ZHAOTING/dialog-processing</a></td><td><a href="https://arxiv.org/pdf/2004.04908">https://arxiv.org/pdf/2004.04908</a></td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.07931&#39;]">PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research">https://github.com/PaddlePaddle/Research</a></td><td><a href="https://arxiv.org/pdf/1910.07931">https://arxiv.org/pdf/1910.07931</a></td></tr><tr><td>21</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00891&#39;]">Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/stanford-oval/zero-shot-multiwoz-acl2020">https://github.com/stanford-oval/zero-shot-multiwoz-acl2020</a></td><td><a href="https://arxiv.org/pdf/2005.00891">https://arxiv.org/pdf/2005.00891</a></td></tr><tr><td>22</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.03809&#39;]">Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward Decomposition</a></td><td></td><td><a href="https://github.com/truthless11/MADPL">https://github.com/truthless11/MADPL</a></td><td><a href="https://arxiv.org/pdf/2004.03809">https://arxiv.org/pdf/2004.03809</a></td></tr><tr><td>23</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.03954&#39;]">Towards Conversational Recommendation over Multi-Type Dialogs</a></td><td></td><td><a href="https://github.com/PaddlePaddle/models">https://github.com/PaddlePaddle/models</a></td><td><a href="https://arxiv.org/pdf/2005.03954">https://arxiv.org/pdf/2005.03954</a></td></tr><tr><td>24</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04100&#39;]">KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation</a></td><td></td><td><a href="https://github.com/thu-coai/KdConv">https://github.com/thu-coai/KdConv</a></td><td><a href="https://arxiv.org/pdf/2004.04100">https://arxiv.org/pdf/2004.04100</a></td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.08854&#39;]">Incremental Transformer with Deliberation Decoder for Document Grounded Conversations</a></td><td></td><td><a href="https://github.com/lizekang/ITDD">https://github.com/lizekang/ITDD</a></td><td><a href="https://arxiv.org/pdf/1907.08854">https://arxiv.org/pdf/1907.08854</a></td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.05373&#39;]">E3: Entailment-driven Extracting and Editing for Conversational Machine Reading</a></td><td></td><td><a href="https://github.com/vzhong/e3">https://github.com/vzhong/e3</a></td><td><a href="https://arxiv.org/pdf/1906.05373">https://arxiv.org/pdf/1906.05373</a></td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.07004&#39;]">Improving Multi-turn Dialogue Modelling with Utterance ReWriter</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.07004">https://arxiv.org/pdf/1906.07004</a></td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.12866&#39;]">Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</a></td><td></td><td><a href="https://github.com/wenhuchen/HDSA-Dialog">https://github.com/wenhuchen/HDSA-Dialog</a></td><td><a href="https://arxiv.org/pdf/1905.12866">https://arxiv.org/pdf/1905.12866</a></td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.00326&#39;]">Observing Dialogue in Therapy: Categorizing and Forecasting Behavioral Codes</a></td><td></td><td><a href="https://github.com/utahnlp/therapist-observer">https://github.com/utahnlp/therapist-observer</a></td><td><a href="https://arxiv.org/pdf/1907.00326">https://arxiv.org/pdf/1907.00326</a></td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.01166&#39;]">Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems</a></td><td></td><td><a href="https://github.com/henryhungle/MTN">https://github.com/henryhungle/MTN</a></td><td><a href="https://arxiv.org/pdf/1907.01166">https://arxiv.org/pdf/1907.01166</a></td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.06725&#39;]">Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good</a></td><td></td><td><a href="https://gitlab.com/ucdavisnlp/persuasionforgood">https://gitlab.com/ucdavisnlp/persuasionforgood</a></td><td><a href="https://arxiv.org/pdf/1906.06725">https://arxiv.org/pdf/1906.06725</a></td></tr></tbody></table></div><h3 id="EMNLP-1"><a href="#EMNLP-1" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.09378&#39;]">Difference-aware Knowledge Selection for Knowledge-grounded Conversation Generation</a></td><td></td><td><a href="https://github.com/chujiezheng/DiffKS">https://github.com/chujiezheng/DiffKS</a></td><td><a href="https://arxiv.org/pdf/2009.09378">https://arxiv.org/pdf/2009.09378</a></td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12328&#39;]">Few-shot Natural Language Generation for Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/pengbaolin/SC-GPT">https://github.com/pengbaolin/SC-GPT</a></td><td><a href="https://arxiv.org/pdf/2002.12328">https://arxiv.org/pdf/2002.12328</a></td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.13656&#39;]">Learning Knowledge Bases with Parameters for Task-Oriented Dialogue Systems</a></td><td></td><td><a href="https://github.com/HLTCHKUST/ke-dialogue">https://github.com/HLTCHKUST/ke-dialogue</a></td><td><a href="https://arxiv.org/pdf/2009.13656">https://arxiv.org/pdf/2009.13656</a></td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04344&#39;]">Plug-and-Play Conversational Models</a></td><td></td><td><a href="https://github.com/andreamad8/PPCM">https://github.com/andreamad8/PPCM</a></td><td><a href="https://arxiv.org/pdf/2010.04344">https://arxiv.org/pdf/2010.04344</a></td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02795&#39;]">COSMIC: COmmonSense knowledge for eMotion Identification in Conversations</a></td><td></td><td><a href="https://github.com/declare-lab/conv-emotion">https://github.com/declare-lab/conv-emotion</a></td><td><a href="https://arxiv.org/pdf/2010.02795">https://arxiv.org/pdf/2010.02795</a></td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.03755&#39;]">Generalizable and Explainable Dialogue Generation via Explicit Action Learning</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.03755">https://arxiv.org/pdf/2010.03755</a></td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02260&#39;]">Effects of Naturalistic Variation in Goal-Oriented Dialog</a></td><td></td><td><a href="https://github.com/IBM/naturalistic-variation-goal-oriented-dialog-datasets">https://github.com/IBM/naturalistic-variation-goal-oriented-dialog-datasets</a></td><td><a href="https://arxiv.org/pdf/2010.02260">https://arxiv.org/pdf/2010.02260</a></td></tr><tr><td>8</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11540&#39;]">DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation</a></td><td></td><td><a href="https://github.com/SenticNet/conv-emotion">https://github.com/SenticNet/conv-emotion</a></td><td><a href="https://arxiv.org/pdf/1908.11540">https://arxiv.org/pdf/1908.11540</a></td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11546&#39;]">Modeling Multi-Action Policy for Task-Oriented Dialogues</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1908.11546">https://arxiv.org/pdf/1908.11546</a></td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.12868&#39;]">Automatically Learning Data Augmentation Policies for Dialogue Tasks</a></td><td></td><td><a href="https://github.com/WolfNiu/AutoAugDialogue">https://github.com/WolfNiu/AutoAugDialogue</a></td><td><a href="https://arxiv.org/pdf/1909.12868">https://arxiv.org/pdf/1909.12868</a></td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.03317&#39;]">Dependency Parsing for Spoken Dialog Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.03317">https://arxiv.org/pdf/1909.03317</a></td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.05391&#39;]">Towards Knowledge-Based Recommender Dialog System</a></td><td></td><td><a href="https://github.com/THUDM/KBRD">https://github.com/THUDM/KBRD</a></td><td><a href="https://arxiv.org/pdf/1908.05391">https://arxiv.org/pdf/1908.05391</a></td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.00610&#39;]">DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic Knowledge Graphs</a></td><td></td><td><a href="https://github.com/Pascalson/DyKGChat">https://github.com/Pascalson/DyKGChat</a></td><td><a href="https://arxiv.org/pdf/1910.00610">https://arxiv.org/pdf/1910.00610</a></td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01388&#39;]">How to Build User Simulators to Train RL-based Dialog Systems</a></td><td></td><td><a href="https://github.com/wyshi/user-simulator">https://github.com/wyshi/user-simulator</a></td><td><a href="https://arxiv.org/pdf/1909.01388">https://arxiv.org/pdf/1909.01388</a></td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09368&#39;]">Dual Attention Networks for Visual Reference Resolution in Visual Dialog</a></td><td></td><td><a href="https://github.com/gicheonkang/DAN-VisDial">https://github.com/gicheonkang/DAN-VisDial</a></td><td><a href="https://arxiv.org/pdf/1902.09368">https://arxiv.org/pdf/1902.09368</a></td></tr><tr><td>16</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11487&#39;]">Dialog Intent Induction with Deep Multi-View Clustering</a></td><td></td><td><a href="https://github.com/asappresearch/dialog-intent-induction">https://github.com/asappresearch/dialog-intent-induction</a></td><td><a href="https://arxiv.org/pdf/1908.11487">https://arxiv.org/pdf/1908.11487</a></td></tr><tr><td>17</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.05069&#39;]">Multi-Task Learning for Conversational Question Answering over a Large-Scale Knowledge Base</a></td><td></td><td><a href="https://github.com/taoshen58/MaSP">https://github.com/taoshen58/MaSP</a></td><td><a href="https://arxiv.org/pdf/1910.05069">https://arxiv.org/pdf/1910.05069</a></td></tr></tbody></table></div><h3 id="NAACL-1"><a href="#NAACL-1" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.04898&#39;]">Open-Domain Question Answering Goes Conversational via Question Rewriting</a></td><td></td><td><a href="https://github.com/apple/ml-qrecc">https://github.com/apple/ml-qrecc</a></td><td><a href="https://arxiv.org/pdf/2010.04898">https://arxiv.org/pdf/2010.04898</a></td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.00783&#39;]">Action-Based Conversations Dataset: A Corpus for Building More In-Depth Task- Oriented Dialogue Systems</a></td><td></td><td><a href="https://github.com/asappresearch/abcd">https://github.com/asappresearch/abcd</a></td><td><a href="https://arxiv.org/pdf/2104.00783">https://arxiv.org/pdf/2104.00783</a></td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.11230&#39;]">Self-Supervised Contrastive Learning for Efficient User Satisfaction Prediction in Conversational Agents</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.11230">https://arxiv.org/pdf/2010.11230</a></td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.07831&#39;]">Human-like informative conversations: Better acknowledgements using conditional mutual information</a></td><td></td><td><a href="https://github.com/AshwinParanjape/human-like-informative-conversations">https://github.com/AshwinParanjape/human-like-informative-conversations</a></td><td><a href="https://arxiv.org/pdf/2104.07831">https://arxiv.org/pdf/2104.07831</a></td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2102.02191&#39;]">DiSCoL: Toward Engaging Dialogue Systems through Conversational Line Guided Response Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2102.02191">https://arxiv.org/pdf/2102.02191</a></td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12757&#39;]">Adding Chit-Chat to Enhance Task-Oriented Dialogues</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12757">https://arxiv.org/pdf/2010.12757</a></td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.10663&#39;]">Fast and Scalable Dialogue State Tracking with Explicit Modular Decomposition</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.10663">https://arxiv.org/pdf/2004.10663</a></td></tr><tr><td>8</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1810.13327&#39;]">Cross-lingual Transfer Learning for Multilingual Task Oriented Dialog</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1810.13327">https://arxiv.org/pdf/1810.13327</a></td></tr><tr><td>9</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.03371&#39;]">Evaluating Coherence in Dialogue Systems using Entailment</a></td><td></td><td><a href="https://github.com/nouhadziri/DialogEntailment">https://github.com/nouhadziri/DialogEntailment</a></td><td><a href="https://arxiv.org/pdf/1904.03371">https://arxiv.org/pdf/1904.03371</a></td></tr></tbody></table></div><h3 id="COLING-1"><a href="#COLING-1" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2012.04080&#39;]">A Taxonomy of Empathetic Response Intents in Human Social Conversations</a></td><td></td><td><a href="https://github.com/anuradha1992/EmpatheticIntents">https://github.com/anuradha1992/EmpatheticIntents</a></td><td><a href="https://arxiv.org/pdf/2012.04080">https://arxiv.org/pdf/2012.04080</a></td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2105.10606&#39;]">CEREC: A Corpus for Entity Resolution in Email Conversations</a></td><td></td><td><a href="https://github.com/paragdakle/emailcoref">https://github.com/paragdakle/emailcoref</a></td><td><a href="https://arxiv.org/pdf/2105.10606">https://arxiv.org/pdf/2105.10606</a></td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.00671&#39;]">Conversational Machine Comprehension: a Literature Review</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2006.00671">https://arxiv.org/pdf/2006.00671</a></td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00615&#39;]">Improving Conversational Question Answering Systems after Deployment using Feedback-Weighted Learning</a></td><td></td><td><a href="https://github.com/jjacampos/FeedbackWeightedLearning">https://github.com/jjacampos/FeedbackWeightedLearning</a></td><td><a href="https://arxiv.org/pdf/2011.00615">https://arxiv.org/pdf/2011.00615</a></td></tr><tr><td>5</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04125&#39;]">Towards Topic-Guided Conversational Recommender System</a></td><td></td><td><a href="https://github.com/RUCAIBox/TG-ReDial">https://github.com/RUCAIBox/TG-ReDial</a></td><td><a href="https://arxiv.org/pdf/2010.04125">https://arxiv.org/pdf/2010.04125</a></td></tr><tr><td>6</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00483&#39;]">Deconstruct to Reconstruct a Configurable Evaluation Metric for Open-Domain Dialogue Systems</a></td><td></td><td><a href="https://github.com/vitouphy/usl_dialogue_metric">https://github.com/vitouphy/usl_dialogue_metric</a></td><td><a href="https://arxiv.org/pdf/2011.00483">https://arxiv.org/pdf/2011.00483</a></td></tr><tr><td>7</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00564&#39;]">Recent Neural Methods on Slot Filling and Intent Classification for Task-Oriented Dialogue Systems: A Survey</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00564">https://arxiv.org/pdf/2011.00564</a></td></tr></tbody></table></div><h2 id="文本生成"><a href="#文本生成" class="headerlink" title="文本生成"></a>文本生成</h2><h3 id="ACL-2"><a href="#ACL-2" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.03432&#39;]">Generalising Multilingual Concept-to-Text NLG with Language Agnostic Delexicalisation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.03432">https://arxiv.org/pdf/2105.03432</a></td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00190&#39;]">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2101.00190">https://arxiv.org/pdf/2101.00190</a></td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00288&#39;]">Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models</a></td><td></td><td><a href="https://github.com/tongshuangwu/polyjuice">https://github.com/tongshuangwu/polyjuice</a></td><td><a href="https://arxiv.org/pdf/2101.00288">https://arxiv.org/pdf/2101.00288</a></td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15786&#39;]">Conditional Generation of Temporally-ordered Event Sequences</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15786">https://arxiv.org/pdf/2012.15786</a></td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06471&#39;]">Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.06471">https://arxiv.org/pdf/2106.06471</a></td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.15053&#39;]">Factorising Meaning and Form for Intent-Preserving Paraphrasing</a></td><td></td><td><a href="https://github.com/tomhosking/separator">https://github.com/tomhosking/separator</a></td><td><a href="https://arxiv.org/pdf/2105.15053">https://arxiv.org/pdf/2105.15053</a></td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00210&#39;]">Improving Formality Style Transfer with Context-Aware Rule Injection</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.00210">https://arxiv.org/pdf/2106.00210</a></td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.01875&#39;]">DeepRapper: Neural Rap Generation with Rhyme and Rhythm Modeling</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2107.01875">https://arxiv.org/pdf/2107.01875</a></td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15329&#39;]">Generating Landmark Navigation Instructions from Maps as a Graph-to-Text Problem</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15329">https://arxiv.org/pdf/2012.15329</a></td></tr><tr><td>10</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.11134&#39;]">One2Set: Generating Diverse Keyphrases as a Set</a></td><td></td><td><a href="https://github.com/jiacheng-ye/kg_one2set">https://github.com/jiacheng-ye/kg_one2set</a></td><td><a href="https://arxiv.org/pdf/2105.11134">https://arxiv.org/pdf/2105.11134</a></td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03829&#39;]">Distilling Knowledge Learned in BERT for Text Generation</a></td><td></td><td><a href="https://github.com/ChenRocks/Distill-BERT-Textgen">https://github.com/ChenRocks/Distill-BERT-Textgen</a></td><td><a href="https://arxiv.org/pdf/1911.03829">https://arxiv.org/pdf/1911.03829</a></td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.08022&#39;]">Rigid Formats Controlled Text Generation</a></td><td></td><td><a href="https://github.com/lipiji/SongNet">https://github.com/lipiji/SongNet</a></td><td><a href="https://arxiv.org/pdf/2004.08022">https://arxiv.org/pdf/2004.08022</a></td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.12704&#39;]">Semantic Graphs for Generating Deep Questions</a></td><td></td><td><a href="https://github.com/WING-NUS/SG-Deep-Question-Generation">https://github.com/WING-NUS/SG-Deep-Question-Generation</a></td><td><a href="https://arxiv.org/pdf/2004.12704">https://arxiv.org/pdf/2004.12704</a></td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14257&#39;]">Politeness Transfer: A Tag and Generate Approach</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14257">https://arxiv.org/pdf/2004.14257</a></td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.09123&#39;]">GPT-too: A language-model-first approach for AMR-to-text generation</a></td><td></td><td><a href="https://github.com/IBM/GPT-too-AMR2text">https://github.com/IBM/GPT-too-AMR2text</a></td><td><a href="https://arxiv.org/pdf/2005.09123">https://arxiv.org/pdf/2005.09123</a></td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.04560&#39;]">Posterior Control of Blackbox Generation</a></td><td></td><td><a href="https://github.com/XiangLi1999/PosteriorControl-NLG">https://github.com/XiangLi1999/PosteriorControl-NLG</a></td><td><a href="https://arxiv.org/pdf/2005.04560">https://arxiv.org/pdf/2005.04560</a></td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.07522&#39;]">Parallel Data Augmentation for Formality Style Transfer</a></td><td></td><td><a href="https://github.com/lancopku/Augmented_Data_for_FST">https://github.com/lancopku/Augmented_Data_for_FST</a></td><td><a href="https://arxiv.org/pdf/2005.07522">https://arxiv.org/pdf/2005.07522</a></td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.01096&#39;]">Neural Data-to-Text Generation via Jointly Learning the Segmentation and Correspondence</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.01096">https://arxiv.org/pdf/2005.01096</a></td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.13461&#39;]">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1910.13461">https://arxiv.org/pdf/1910.13461</a></td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03882&#39;]">Pre-train and Plug-in: Flexible Conditional Text Generation with Variational Auto- Encoders</a></td><td></td><td><a href="https://github.com/WHUIR/PPVAE">https://github.com/WHUIR/PPVAE</a></td><td><a href="https://arxiv.org/pdf/1911.03882">https://arxiv.org/pdf/1911.03882</a></td></tr><tr><td>21</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1909.10158&#39;]">Two Birds, One Stone: A Simple, Unified Model for Text Generation from Structured and Unstructured Data</a></td><td></td><td><a href="https://github.com/h-shahidi/2birds-gen">https://github.com/h-shahidi/2birds-gen</a></td><td><a href="https://arxiv.org/pdf/1909.10158">https://arxiv.org/pdf/1909.10158</a></td></tr><tr><td>22</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.02247&#39;]">Unsupervised Opinion Summarization as Copycat-Review Generation</a></td><td></td><td><a href="https://github.com/ixlan/CopyCat-abstractive-opinion-summarizer">https://github.com/ixlan/CopyCat-abstractive-opinion-summarizer</a></td><td><a href="https://arxiv.org/pdf/1911.02247">https://arxiv.org/pdf/1911.02247</a></td></tr><tr><td>23</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.08101&#39;]">Evidence-Aware Inferential Text Generation with Vector Quantised Variational AutoEncoder</a></td><td></td><td><a href="https://github.com/microsoft/EA-VQ-VAE">https://github.com/microsoft/EA-VQ-VAE</a></td><td><a href="https://arxiv.org/pdf/2006.08101">https://arxiv.org/pdf/2006.08101</a></td></tr><tr><td>24</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04696&#39;]">BLEURT: Learning Robust Metrics for Text Generation</a></td><td></td><td><a href="https://github.com/google-research/bleurt">https://github.com/google-research/bleurt</a></td><td><a href="https://arxiv.org/pdf/2004.04696">https://arxiv.org/pdf/2004.04696</a></td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01834&#39;]">Automatic Generation of High Quality CCGbanks for Parser Domain Adaptation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.01834">https://arxiv.org/pdf/1906.01834</a></td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.07870&#39;]">PaperRobot: Incremental Draft Generation of Scientific Ideas</a></td><td></td><td><a href="https://github.com/EagleW/PaperRobot">https://github.com/EagleW/PaperRobot</a></td><td><a href="https://arxiv.org/pdf/1905.07870">https://arxiv.org/pdf/1905.07870</a></td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03221&#39;]">Data-to-text Generation with Entity Modeling</a></td><td></td><td><a href="https://github.com/ratishsp/data2text-entity-py">https://github.com/ratishsp/data2text-entity-py</a></td><td><a href="https://arxiv.org/pdf/1906.03221">https://arxiv.org/pdf/1906.03221</a></td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.03067&#39;]">Key Fact as Pivot: A Two-Stage Model for Low Resource Table-to-Text Generation</a></td><td></td><td><a href="https://github.com/lancopku/Pivot">https://github.com/lancopku/Pivot</a></td><td><a href="https://arxiv.org/pdf/1908.03067">https://arxiv.org/pdf/1908.03067</a></td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.12667&#39;]">Reinforced Dynamic Reasoning for Conversational Question Generation</a></td><td></td><td><a href="https://github.com/ZJULearning/ReDR">https://github.com/ZJULearning/ReDR</a></td><td><a href="https://arxiv.org/pdf/1907.12667">https://arxiv.org/pdf/1907.12667</a></td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.04106&#39;]">Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</a></td><td></td><td><a href="https://github.com/kenchan0226/keyphrase-generation-rl">https://github.com/kenchan0226/keyphrase-generation-rl</a></td><td><a href="https://arxiv.org/pdf/1906.04106">https://arxiv.org/pdf/1906.04106</a></td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03889&#39;]">Topic-Aware Neural Keyphrase Generation for Social Media Language</a></td><td></td><td><a href="https://github.com/yuewang-cuhk/TAKG">https://github.com/yuewang-cuhk/TAKG</a></td><td><a href="https://arxiv.org/pdf/1906.03889">https://arxiv.org/pdf/1906.03889</a></td></tr><tr><td>32</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03717&#39;]">Argument Generation with Retrieval, Planning, and Realization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.03717">https://arxiv.org/pdf/1906.03717</a></td></tr><tr><td>33</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.12866&#39;]">Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</a></td><td></td><td><a href="https://github.com/wenhuchen/HDSA-Dialog">https://github.com/wenhuchen/HDSA-Dialog</a></td><td><a href="https://arxiv.org/pdf/1905.12866">https://arxiv.org/pdf/1905.12866</a></td></tr><tr><td>34</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01231&#39;]">Coherent Comments Generation for Chinese Articles with a Graph-to-Sequence Model</a></td><td></td><td><a href="https://github.com/lancopku/Graph-to-seq-comment-generation">https://github.com/lancopku/Graph-to-seq-comment-generation</a></td><td><a href="https://arxiv.org/pdf/1906.01231">https://arxiv.org/pdf/1906.01231</a></td></tr><tr><td>35</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.02525&#39;]">Cross-Lingual Training for Automatic Question Generation</a></td><td></td><td><a href="https://github.com/vishwajeet93/clqg">https://github.com/vishwajeet93/clqg</a></td><td><a href="https://arxiv.org/pdf/1906.02525">https://arxiv.org/pdf/1906.02525</a></td></tr><tr><td>36</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.00756&#39;]">Graph Neural Networks with Generated Parameters for Relation Extraction</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.00756">https://arxiv.org/pdf/1902.00756</a></td></tr><tr><td>37</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.09699&#39;]">Learning to Select, Track, and Generate for Data-to-Text</a></td><td></td><td><a href="https://github.com/aistairc/rotowire-modified">https://github.com/aistairc/rotowire-modified</a></td><td><a href="https://arxiv.org/pdf/1907.09699">https://arxiv.org/pdf/1907.09699</a></td></tr><tr><td>38</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.08540&#39;]">Predicting Human Activities from User-Generated Content</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1907.08540">https://arxiv.org/pdf/1907.08540</a></td></tr></tbody></table></div><h3 id="EMNLP-2"><a href="#EMNLP-2" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12328&#39;]">Few-shot Natural Language Generation for Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/pengbaolin/SC-GPT">https://github.com/pengbaolin/SC-GPT</a></td><td><a href="https://arxiv.org/pdf/2002.12328">https://arxiv.org/pdf/2002.12328</a></td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03587&#39;]">How Decoding Strategies Affect the Verifiability of Generated Text</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1911.03587">https://arxiv.org/pdf/1911.03587</a></td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14983&#39;]">Control, Generate, Augment: A Scalable Framework for Multi-Attribute Text Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14983">https://arxiv.org/pdf/2004.14983</a></td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.07576&#39;]">Pretrained Language Models for Dialogue Generation with Multiple Input Sources</a></td><td></td><td><a href="https://github.com/caoyu-noob/Multi-GPT2">https://github.com/caoyu-noob/Multi-GPT2</a></td><td><a href="https://arxiv.org/pdf/2010.07576">https://arxiv.org/pdf/2010.07576</a></td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14579&#39;]">Logic2Text: High-Fidelity Natural Language Generation from Logical Forms</a></td><td></td><td><a href="https://github.com/czyssrs/Logic2Text">https://github.com/czyssrs/Logic2Text</a></td><td><a href="https://arxiv.org/pdf/2004.14579">https://arxiv.org/pdf/2004.14579</a></td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.10056&#39;]">Composed Variational Natural Language Generation for Few-shot Intents</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.10056">https://arxiv.org/pdf/2009.10056</a></td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.00910&#39;]">Continual Learning for Natural Language Generation in Task-oriented Dialog Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.00910">https://arxiv.org/pdf/2010.00910</a></td></tr><tr><td>8</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04246&#39;]">Dual Inference for Improving Language Understanding and Generation</a></td><td></td><td><a href="https://github.com/MiuLab/DuaLUG">https://github.com/MiuLab/DuaLUG</a></td><td><a href="https://arxiv.org/pdf/2010.04246">https://arxiv.org/pdf/2010.04246</a></td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.09022&#39;]">Neural data-to-text generation: A comparison between pipeline and end- to-end architectures</a></td><td></td><td><a href="https://github.com/ThiagoCF05/webnlg">https://github.com/ThiagoCF05/webnlg</a></td><td><a href="https://arxiv.org/pdf/1908.09022">https://arxiv.org/pdf/1908.09022</a></td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.02622&#39;]">MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.02622">https://arxiv.org/pdf/1909.02622</a></td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.04453&#39;]">Select and Attend: Towards Controllable Content Selection in Text Generation</a></td><td></td><td><a href="https://github.com/chin-gyou/controllable-selection">https://github.com/chin-gyou/controllable-selection</a></td><td><a href="https://arxiv.org/pdf/1909.04453">https://arxiv.org/pdf/1909.04453</a></td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.10245&#39;]">Knowledge Aware Conversation Generation with Explainable Reasoning over Augmented Graphs</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research/tree/master/NLP/EMNLP2019-AKGCM">https://github.com/PaddlePaddle/Research/tree/master/NLP/EMNLP2019-AKGCM</a></td><td><a href="https://arxiv.org/pdf/1903.10245">https://arxiv.org/pdf/1903.10245</a></td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11658&#39;]">Autoregressive Text Generation Beyond Feedback Loops</a></td><td></td><td><a href="https://github.com/schmiflo/crf-generation">https://github.com/schmiflo/crf-generation</a></td><td><a href="https://arxiv.org/pdf/1908.11658">https://arxiv.org/pdf/1908.11658</a></td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.07195&#39;]">ARAML: A Stable Adversarial Training Framework for Text Generation</a></td><td></td><td><a href="https://github.com/kepei1106/ARAML">https://github.com/kepei1106/ARAML</a></td><td><a href="https://arxiv.org/pdf/1908.07195">https://arxiv.org/pdf/1908.07195</a></td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1901.00398&#39;]">Judge the Judges: A Large-Scale Evaluation Study of Neural Language Models for Online Review Generation</a></td><td></td><td><a href="https://github.com/Crista23/JudgeTheJudges">https://github.com/Crista23/JudgeTheJudges</a></td><td><a href="https://arxiv.org/pdf/1901.00398">https://arxiv.org/pdf/1901.00398</a></td></tr></tbody></table></div><h3 id="NAACL-2"><a href="#NAACL-2" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2005.00054&#39;]">APo-VAE: Text Generation in Hyperbolic Space</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.00054">https://arxiv.org/pdf/2005.00054</a></td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05218&#39;]">FUDGE: Controlled Text Generation With Future Discriminators</a></td><td></td><td><a href="https://github.com/yangkevin2/naacl-2021-fudge-controlled-generation">https://github.com/yangkevin2/naacl-2021-fudge-controlled-generation</a></td><td><a href="https://arxiv.org/pdf/2104.05218">https://arxiv.org/pdf/2104.05218</a></td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12884&#39;]">NeuroLogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12884">https://arxiv.org/pdf/2010.12884</a></td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05801&#39;]">Plot-guided Adversarial Example Construction for Evaluating Open-domain Story Generation</a></td><td></td><td><a href="https://github.com/PlusLabNLP/Plot-guided-Coherence-Evaluation">https://github.com/PlusLabNLP/Plot-guided-Coherence-Evaluation</a></td><td><a href="https://arxiv.org/pdf/2104.05801">https://arxiv.org/pdf/2104.05801</a></td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2006.15720&#39;]">Progressive Generation of Long Text with Pretrained Language Models</a></td><td></td><td><a href="https://github.com/tanyuqian/progressive-generation">https://github.com/tanyuqian/progressive-generation</a></td><td><a href="https://arxiv.org/pdf/2006.15720">https://arxiv.org/pdf/2006.15720</a></td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.02484&#39;]">OodGAN: Generative Adversarial Network for Out-of-Domain Data Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.02484">https://arxiv.org/pdf/2104.02484</a></td></tr><tr><td>7</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.11205&#39;]">Jointly Optimizing Diversity and Relevance in Neural Response Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.11205">https://arxiv.org/pdf/1902.11205</a></td></tr><tr><td>8</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.11564&#39;]">Neural Text Generation from Rich Semantic Representations</a></td><td></td><td><a href="https://github.com/shlurbee/dmrs-text-generation-naacl2019">https://github.com/shlurbee/dmrs-text-generation-naacl2019</a></td><td><a href="https://arxiv.org/pdf/1904.11564">https://arxiv.org/pdf/1904.11564</a></td></tr><tr><td>9</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.02342&#39;]">Text Generation from Knowledge Graphs with Graph Transformers</a></td><td></td><td><a href="https://github.com/rikdz/GraphWriter">https://github.com/rikdz/GraphWriter</a></td><td><a href="https://arxiv.org/pdf/1904.02342">https://arxiv.org/pdf/1904.02342</a></td></tr><tr><td>10</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.04428&#39;]">Text Generation with Exemplar-based Adaptive Decoding</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.04428">https://arxiv.org/pdf/1904.04428</a></td></tr><tr><td>11</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1809.01694&#39;]">Accelerated Reinforcement Learning for Sentence Generation by Vocabulary Prediction</a></td><td></td><td><a href="https://github.com/hassyGo/NLG-RL">https://github.com/hassyGo/NLG-RL</a></td><td><a href="https://arxiv.org/pdf/1809.01694">https://arxiv.org/pdf/1809.01694</a></td></tr><tr><td>12</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.09722&#39;]">Pre-trained language model representations for language generation</a></td><td></td><td><a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></td><td><a href="https://arxiv.org/pdf/1903.09722">https://arxiv.org/pdf/1903.09722</a></td></tr><tr><td>13</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.01301&#39;]">Pragmatically Informative Text Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.01301">https://arxiv.org/pdf/1904.01301</a></td></tr><tr><td>14</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1806.08462&#39;]">Stochastic Wasserstein Autoencoder for Probabilistic Sentence Generation</a></td><td></td><td><a href="https://github.com/HareeshBahuleyan/probabilistic_nlg">https://github.com/HareeshBahuleyan/probabilistic_nlg</a></td><td><a href="https://arxiv.org/pdf/1806.08462">https://arxiv.org/pdf/1806.08462</a></td></tr></tbody></table></div><h3 id="COLING-2"><a href="#COLING-2" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.04000&#39;, &#39;https://arxiv.org/abs/1911.03587&#39;, &#39;https://arxiv.org/abs/1704.06851&#39;]">Affective Text Generation</a></td><td></td><td><a href="https://github.com/ishikasingh/Affective-text-gen">https://github.com/ishikasingh/Affective-text-gen</a></td><td><a href="https://arxiv.org/pdf/2011.04000">https://arxiv.org/pdf/2011.04000</a></td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.13588&#39;]">Curious Case of Language Generation Evaluation Metrics: A Cautionary Tale</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.13588">https://arxiv.org/pdf/2010.13588</a></td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2012.04332&#39;]">Facts2Story: Controlling Text Generation by Key Facts</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.04332">https://arxiv.org/pdf/2012.04332</a></td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00592&#39;]">Vec2Sent: Probing Sentence Embeddings with Natural Language Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00592">https://arxiv.org/pdf/2011.00592</a></td></tr></tbody></table></div><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><h3 id="ACL-3"><a href="#ACL-3" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.13648&#39;]">Cross-Lingual Abstractive Summarization with Limited Parallel Resources</a></td><td></td><td><a href="https://github.com/WoodenWhite/MCLAS">https://github.com/WoodenWhite/MCLAS</a></td><td><a href="https://arxiv.org/pdf/2105.13648">https://arxiv.org/pdf/2105.13648</a></td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.04623&#39;]">Improving Factual Consistency of Abstractive Summarization via Question Answering</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.04623">https://arxiv.org/pdf/2105.04623</a></td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.03801&#39;]">Long-Span Summarization via Local Attention and Content Selection</a></td><td></td><td><a href="https://github.com/potsawee/longsum0">https://github.com/potsawee/longsum0</a></td><td><a href="https://arxiv.org/pdf/2105.03801">https://arxiv.org/pdf/2105.03801</a></td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.15135&#39;]">TWAG: A Topic-Guided Wikipedia Abstract Generator</a></td><td></td><td><a href="https://github.com/THU-KEG/TWAG">https://github.com/THU-KEG/TWAG</a></td><td><a href="https://arxiv.org/pdf/2106.15135">https://arxiv.org/pdf/2106.15135</a></td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.12544&#39;]">Language Model as an Annotator: Exploring DialoGPT for Dialogue Summarization</a></td><td></td><td><a href="https://github.com/xcfcode/PLM_annotator">https://github.com/xcfcode/PLM_annotator</a></td><td><a href="https://arxiv.org/pdf/2105.12544">https://arxiv.org/pdf/2105.12544</a></td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.12041&#39;]">BASS: Boosting Abstractive Summarization with Unified Semantic Graph</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.12041">https://arxiv.org/pdf/2105.12041</a></td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.11921&#39;]">Focus Attention: Promoting Faithfulness and Diversity in Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.11921">https://arxiv.org/pdf/2105.11921</a></td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.14774&#39;]">Generating Query Focused Summaries from Query-Free Resources</a></td><td></td><td><a href="https://github.com/yumoxu/marge">https://github.com/yumoxu/marge</a></td><td><a href="https://arxiv.org/pdf/2012.14774">https://arxiv.org/pdf/2012.14774</a></td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00829&#39;]">ConvoSumm: Conversation Summarization Benchmark and Improved Abstractive Summarization with Argument Mining</a></td><td></td><td><a href="https://github.com/Yale-LILY/ConvoSumm">https://github.com/Yale-LILY/ConvoSumm</a></td><td><a href="https://arxiv.org/pdf/2106.00829">https://arxiv.org/pdf/2106.00829</a></td></tr><tr><td>10</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00661&#39;]">On Faithfulness and Factuality in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/google-research-datasets/xsum_hallucination_annotations">https://github.com/google-research-datasets/xsum_hallucination_annotations</a></td><td><a href="https://arxiv.org/pdf/2005.00661">https://arxiv.org/pdf/2005.00661</a></td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.03754&#39;]">FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/esdurmus/summary-faithfulness">https://github.com/esdurmus/summary-faithfulness</a></td><td><a href="https://arxiv.org/pdf/2005.03754">https://arxiv.org/pdf/2005.03754</a></td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00661&#39;]">On Faithfulness and Factuality in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/google-research-datasets/xsum_hallucination_annotations">https://github.com/google-research-datasets/xsum_hallucination_annotations</a></td><td><a href="https://arxiv.org/pdf/2005.00661">https://arxiv.org/pdf/2005.00661</a></td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.01159&#39;]">Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward</a></td><td></td><td><a href="https://github.com/luyang-huang96/GraphAugmentedSum">https://github.com/luyang-huang96/GraphAugmentedSum</a></td><td><a href="https://arxiv.org/pdf/2005.01159">https://arxiv.org/pdf/2005.01159</a></td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2105.05361&#39;]">The Summary Loop: Learning to Write Abstractive Summaries Without Examples</a></td><td></td><td><a href="https://github.com/cannylab/summary_loop">https://github.com/cannylab/summary_loop</a></td><td><a href="https://arxiv.org/pdf/2105.05361">https://arxiv.org/pdf/2105.05361</a></td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.10043&#39;]">Leveraging Graph to Improve Abstractive Multi-Document Summarization</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research">https://github.com/PaddlePaddle/Research</a></td><td><a href="https://arxiv.org/pdf/2005.10043">https://arxiv.org/pdf/2005.10043</a></td></tr><tr><td>16</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00077&#39;]">Scoring Sentence Singletons and Pairs for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/ucfnlp/summarization-sing-pair-mix">https://github.com/ucfnlp/summarization-sing-pair-mix</a></td><td><a href="https://arxiv.org/pdf/1906.00077">https://arxiv.org/pdf/1906.00077</a></td></tr></tbody></table></div><h3 id="EMNLP-3"><a href="#EMNLP-3" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.02016&#39;]">A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining</a></td><td></td><td><a href="https://github.com/microsoft/HMNet">https://github.com/microsoft/HMNet</a></td><td><a href="https://arxiv.org/pdf/2004.02016">https://arxiv.org/pdf/2004.02016</a></td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13983&#39;]">Conditional Neural Generation using Sub-Aspect Functions for Extractive News Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.13983">https://arxiv.org/pdf/2004.13983</a></td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.08242&#39;]">Unsupervised Extractive Summarization by Pre-training Hierarchical Transformers</a></td><td></td><td><a href="https://github.com/xssstory/STAS">https://github.com/xssstory/STAS</a></td><td><a href="https://arxiv.org/pdf/2010.08242">https://arxiv.org/pdf/2010.08242</a></td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.01786&#39;]">Corpora Evaluation and System Bias detection in Multi Document Summarization</a></td><td></td><td><a href="https://github.com/LCS2-IIITD/summarization_bias">https://github.com/LCS2-IIITD/summarization_bias</a></td><td><a href="https://arxiv.org/pdf/2010.01786">https://arxiv.org/pdf/2010.01786</a></td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.05139&#39;]">An Empirical Study of Cross-Dataset Evaluation for Neural Summarization Systems</a></td><td></td><td><a href="https://github.com/zide05/CDEvalSumm">https://github.com/zide05/CDEvalSumm</a></td><td><a href="https://arxiv.org/pdf/2010.05139">https://arxiv.org/pdf/2010.05139</a></td></tr><tr><td>6</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.13114&#39;]">Contrastive Attention Mechanism for Abstractive Sentence Summarization</a></td><td></td><td><a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td><a href="https://arxiv.org/pdf/1910.13114">https://arxiv.org/pdf/1910.13114</a></td></tr><tr><td>7</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.08486&#39;]">Concept Pointer Network for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/wprojectsn/codes">https://github.com/wprojectsn/codes</a></td><td><a href="https://arxiv.org/pdf/1910.08486">https://arxiv.org/pdf/1910.08486</a></td></tr><tr><td>8</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.13114&#39;]">Contrastive Attention Mechanism for Abstractive Sentence Summarization</a></td><td></td><td><a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td><a href="https://arxiv.org/pdf/1910.13114">https://arxiv.org/pdf/1910.13114</a></td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.00863&#39;]">Neural Extractive Text Summarization with Syntactic Compression</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.00863">https://arxiv.org/pdf/1902.00863</a></td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.08345&#39;]">Text Summarization with Pretrained Encoders</a></td><td></td><td><a href="https://github.com/nlpyang/PreSumm">https://github.com/nlpyang/PreSumm</a></td><td><a href="https://arxiv.org/pdf/1908.08345">https://arxiv.org/pdf/1908.08345</a></td></tr></tbody></table></div><h3 id="NAACL-3"><a href="#NAACL-3" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.08014&#39;]">GSum: A General Framework for Guided Neural Abstractive Summarization</a></td><td></td><td><a href="https://github.com/neulab/guided_summarization">https://github.com/neulab/guided_summarization</a></td><td><a href="https://arxiv.org/pdf/2010.08014">https://arxiv.org/pdf/2010.08014</a></td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12836&#39;]">Improving Zero and Few-Shot Abstractive Summarization with Intermediate Fine- tuning and Data Augmentation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12836">https://arxiv.org/pdf/2010.12836</a></td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.08400&#39;]">Structure-Aware Abstractive Conversation Summarization via Discourse and Action Graphs</a></td><td></td><td><a href="https://github.com/GT-SALT/Structure-Aware-BART">https://github.com/GT-SALT/Structure-Aware-BART</a></td><td><a href="https://arxiv.org/pdf/2104.08400">https://arxiv.org/pdf/2104.08400</a></td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.11332&#39;]">AdaptSum: Towards Low-Resource Domain Adaptation for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/TysonYu/AdaptSum">https://github.com/TysonYu/AdaptSum</a></td><td><a href="https://arxiv.org/pdf/2103.11332">https://arxiv.org/pdf/2103.11332</a></td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.01726&#39;]">A New Approach to Overgenerating and Scoring Abstractive Summaries</a></td><td></td><td><a href="https://github.com/ucfnlp/varying-length-summ">https://github.com/ucfnlp/varying-length-summ</a></td><td><a href="https://arxiv.org/pdf/2104.01726">https://arxiv.org/pdf/2104.01726</a></td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.09061&#39;]">Improving Faithfulness in Abstractive Summarization with Contrast Candidate Generation and Selection</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.09061">https://arxiv.org/pdf/2104.09061</a></td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.01317&#39;]">Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/jiangycTarheel/TPT-Summ">https://github.com/jiangycTarheel/TPT-Summ</a></td><td><a href="https://arxiv.org/pdf/2106.01317">https://arxiv.org/pdf/2106.01317</a></td></tr><tr><td>8</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.02205&#39;]">Attention Head Masking for Inference Time Content Selection in Abstractive Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.02205">https://arxiv.org/pdf/2104.02205</a></td></tr><tr><td>9</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.13346&#39;]">Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics</a></td><td></td><td><a href="https://github.com/artidoro/frank">https://github.com/artidoro/frank</a></td><td><a href="https://arxiv.org/pdf/2104.13346">https://arxiv.org/pdf/2104.13346</a></td></tr></tbody></table></div><h3 id="COLING-3"><a href="#COLING-3" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00692&#39;]">How Domain Terminology Affects Meeting Summarization Performance</a></td><td></td><td><a href="https://github.com/ucfnlp/meeting-domain-terminology">https://github.com/ucfnlp/meeting-domain-terminology</a></td><td><a href="https://arxiv.org/pdf/2011.00692">https://arxiv.org/pdf/2011.00692</a></td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.09739&#39;]">Fact-level Extractive Summarization with Hierarchical Graph Mask on BERT</a></td><td></td><td><a href="https://github.com/Ruifeng-paper/FactExsum-coling2020">https://github.com/Ruifeng-paper/FactExsum-coling2020</a></td><td><a href="https://arxiv.org/pdf/2011.09739">https://arxiv.org/pdf/2011.09739</a></td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.01421&#39;]">WSL-DS: Weakly Supervised Learning with Distant Supervision for Query Focused Multi-Document Abstractive Summarization</a></td><td></td><td><a href="https://github.com/tahmedge/WSL-DS-COLING-2020">https://github.com/tahmedge/WSL-DS-COLING-2020</a></td><td><a href="https://arxiv.org/pdf/2011.01421">https://arxiv.org/pdf/2011.01421</a></td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> arxiv </tag>
            
            <tag> ACL </tag>
            
            <tag> NAACL </tag>
            
            <tag> EMNLP </tag>
            
            <tag> COLING </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>完整版-翻译、摘要、会话、文本生成任务顶会论文</title>
      <link href="/2021/08/13/%E5%AE%8C%E6%95%B4%E7%89%88-%E7%BF%BB%E8%AF%91%E3%80%81%E6%91%98%E8%A6%81%E3%80%81%E4%BC%9A%E8%AF%9D%E3%80%81%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/"/>
      <url>/2021/08/13/%E5%AE%8C%E6%95%B4%E7%89%88-%E7%BF%BB%E8%AF%91%E3%80%81%E6%91%98%E8%A6%81%E3%80%81%E4%BC%9A%E8%AF%9D%E3%80%81%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h1 id="完整版-翻译、摘要、会话、文本生成任务顶会论文"><a href="#完整版-翻译、摘要、会话、文本生成任务顶会论文" class="headerlink" title="完整版-翻译、摘要、会话、文本生成任务顶会论文"></a>完整版-翻译、摘要、会话、文本生成任务顶会论文</h1><h2 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h2><h3 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1811.00357&#39;]">Latent Variable Model for Multi-modal Translation</a></td><td></td><td><a href="https://github.com/iacercalixto/variational_mmt">https://github.com/iacercalixto/variational_mmt</a></td><td><a href="https://arxiv.org/pdf/1811.00357">https://arxiv.org/pdf/1811.00357</a></td><td>In this work, we propose to model the interaction between visual and textual features for multi-modal neural machine translation (MMT) through a latent variable model. This latent variable can be seen as a multi-modal stochastic embedding of an image and its description in a foreign language. It is used in a target-language decoder and also to predict image features. Importantly, our model formulation utilises visual and textual inputs during training but does not require that images be available at test time. We show that our latent variable MMT formulation improves considerably over strong baselines, including a multi-task learning approach (Elliott and Kádár, 2017) and a conditional variational auto-encoder approach (Toyama et al., 2016). Finally, we show improvements due to (i) predicting image features in addition to only conditioning on them, (ii) imposing a constraint on the minimum amount of information encoded in the latent variable, and (iii) by training on additional target-language image descriptions (i.e. synthetic data).</td><td>在这项工作中，我们建议通过潜在变量模型为多模态神经机器翻译 (MMT) 的视觉和文本特征之间的交互建模。这个潜在变量可以看作是图像的多模态随机嵌入及其在外语中的描述。它用于目标语言解码器，也用于预测图像特征。重要的是，我们的模型公式在训练期间利用视觉和文本输入，但不需要在测试时提供图像。我们表明，我们的潜在变量 MMT 公式在强基线上有相当大的改进，包括多任务学习方法（Elliott 和 Kádár，2017 年）和条件变分自动编码器方法（Toyama 等人，2016 年）。最后，我们展示了由于（i）预测图像特征以及仅对它们进行调节，（ii）对潜在变量中编码的最小信息量施加约束，以及（iii）通过额外目标语言训练的改进图像描述（即合成数据）。</td><td>Iacer Calixto   Miguel Rios   Wilker Aziz</td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.05414&#39;]">Rewriter-Evaluator Architecture for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.05414">https://arxiv.org/pdf/2012.05414</a></td><td>Encoder-decoder has been widely used in neural machine translation (NMT). A few methods have been proposed to improve it with multiple passes of decoding. However, their full potential is limited by a lack of appropriate termination policies. To address this issue, we present a novel architecture, Rewriter-Evaluator. It consists of a rewriter and an evaluator. Translating a source sentence involves multiple passes. At every pass, the rewriter produces a new translation to improve the past translation and the evaluator estimates the translation quality to decide whether to terminate the rewriting process. We also propose prioritized gradient descent (PGD) that facilitates training the rewriter and the evaluator jointly. Though incurring multiple passes of decoding, Rewriter-Evaluator with the proposed PGD method can be trained with a similar time to that of training encoder-decoder models. We apply the proposed architecture to improve the general NMT models (e.g., Transformer). We conduct extensive experiments on two translation tasks, Chinese-English and English-German, and show that the proposed architecture notably improves the performances of NMT models and significantly outperforms previous baselines.</td><td>编码器-解码器已广泛应用于神经机器翻译（NMT）。已经提出了一些方法来通过多次解码来改进它。然而，由于缺乏适当的终止政策，它们的全部潜力受到限制。为了解决这个问题，我们提出了一种新颖的架构，Rewriter-Evaluator。它由重写器和评估器组成。翻译源句子涉及多次传递。在每次通过时，重写者都会生成一个新的翻译来改进过去的翻译，而评估者则评估翻译质量以决定是否终止重写过程。我们还提出了优先梯度下降 (PGD)，它有助于联合训练重写器和评估器。尽管会导致多次解码，但可以使用与训练编码器-解码器模型相似的时间来训练使用所提出的 PGD 方法的 Rewriter-Evaluator。我们应用所提出的架构来改进一般的 NMT 模型（例如，Transformer）。我们对汉语-英语和英语-德语这两个翻译任务进行了大量实验，结果表明所提出的架构显着提高了 NMT 模型的性能，并显着优于以前的基线。</td><td>Yangming Li   Kaisheng Yao</td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.08226&#39;]">Consistency Regularization for Cross-Lingual Fine-Tuning</a></td><td></td><td><a href="https://github.com/bozheng-hit/xTune">https://github.com/bozheng-hit/xTune</a></td><td><a href="https://arxiv.org/pdf/2106.08226">https://arxiv.org/pdf/2106.08226</a></td><td>Fine-tuning pre-trained cross-lingual language models can transfer task-specific supervision from one language to the others. In this work, we propose to improve cross-lingual fine-tuning with consistency regularization. Specifically, we use example consistency regularization to penalize the prediction sensitivity to four types of data augmentations, i.e., subword sampling, Gaussian noise, code-switch substitution, and machine translation. In addition, we employ model consistency to regularize the models trained with two augmented versions of the same training set. Experimental results on the XTREME benchmark show that our method significantly improves cross-lingual fine-tuning across various tasks, including text classification, question answering, and sequence labeling.</td><td></td><td>Bo Zheng   Li Dong   Shaohan Huang   Wenhui Wang   Zewen Chi   Saksham Singhal   Wanxiang Che   Ting Liu   Xia Song   Furu Wei</td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06381&#39;]">Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment</a></td><td></td><td><a href="https://github.com/CZWin32768/XLM-Align">https://github.com/CZWin32768/XLM-Align</a></td><td><a href="https://arxiv.org/pdf/2106.06381">https://arxiv.org/pdf/2106.06381</a></td><td>The cross-lingual language models are typically pretrained with masked language modeling on multilingual text or parallel sentences. In this paper, we introduce denoising word alignment as a new cross-lingual pre-training task. Specifically, the model first self-labels word alignments for parallel sentences. Then we randomly mask tokens in a bitext pair. Given a masked token, the model uses a pointer network to predict the aligned token in the other language. We alternately perform the above two steps in an expectation-maximization manner. Experimental results show that our method improves cross-lingual transferability on various datasets, especially on the token-level tasks, such as question answering, and structured prediction. Moreover, the model can serve as a pretrained word aligner, which achieves reasonably low error rates on the alignment benchmarks. The code and pretrained parameters are available at <a href="https://github.com/CZWin32768/XLM-Align">https://github.com/CZWin32768/XLM-Align</a>.</td><td>跨语言语言模型通常使用多语言文本或平行句子的掩码语言模型进行预训练。在本文中，我们将去噪词对齐作为一种新的跨语言预训练任务引入。具体来说，该模型首先自我标记平行句子的词对齐。然后我们随机屏蔽一个 bittext 对中的令牌。给定一个掩码标记，该模型使用指针网络来预测其他语言中对齐的标记。我们以期望最大化的方式交替执行上述两个步骤。实验结果表明，我们的方法提高了各种数据集的跨语言迁移能力，尤其是在令牌级任务上，例如问答和结构化预测。此外，该模型可以作为预训练的词对齐器，在对齐基准上实现相当低的错误率。代码和预训练参数可从 <a href="https://github.com/CZWin32768/XLM-Align">https://github.com/CZWin32768/XLM-Align</a> 获得。</td><td>Zewen Chi   Li Dong   Bo Zheng   Shaohan Huang   Xian-Ling Mao   Heyan Huang   Furu Wei</td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15127&#39;]">Improving Zero-Shot Translation by Disentangling Positional Information</a></td><td></td><td><a href="https://github.com/nlp-dke/NMTGMinor/tree/master/recipes/zero-shot">https://github.com/nlp-dke/NMTGMinor/tree/master/recipes/zero-shot</a></td><td><a href="https://arxiv.org/pdf/2012.15127">https://arxiv.org/pdf/2012.15127</a></td><td>Multilingual neural machine translation has shown the capability of directly translating between language pairs unseen in training, i.e. zero-shot translation. Despite being conceptually attractive, it often suffers from low output quality. The difficulty of generalizing to new translation directions suggests the model representations are highly specific to those language pairs seen in training. We demonstrate that a main factor causing the language-specific representations is the positional correspondence to input tokens. We show that this can be easily alleviated by removing residual connections in an encoder layer. With this modification, we gain up to 18.5 BLEU points on zero-shot translation while retaining quality on supervised directions. The improvements are particularly prominent between related languages, where our proposed model outperforms pivot-based translation. Moreover, our approach allows easy integration of new languages, which substantially expands translation coverage. By thorough inspections of the hidden layer outputs, we show that our approach indeed leads to more language-independent representations.</td><td>多语言神经机器翻译已经显示出在训练中看不到的语言对之间直接翻译的能力，即零样本翻译。尽管在概念上很有吸引力，但它经常受到输出质量低的影响。推广到新的翻译方向的困难表明模型表示对于训练中看到的那些语言对是高度特定的。我们证明了导致语言特定表示的一个主要因素是与输入标记的位置对应。我们表明，通过删除编码器层中的残差连接可以轻松缓解这种情况。通过这种修改，我们在零样本平移上获得了高达 18.5 BLEU 点，同时在监督方向上保持了质量。相关语言之间的改进尤为突出，我们提出的模型优于基于枢轴的翻译。此外，我们的方法允许轻松集成新语言，从而大大扩展了翻译范围。通过对隐藏层输出的彻底检查，我们表明我们的方法确实导致了更多与语言无关的表示。</td><td>Danni Liu   Jan Niehues   James Cross   Francisco Guzmán   Xian Li</td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15715&#39;]">Beyond Offline Mapping: Learning Cross-lingual Word Embeddings through Context Anchoring</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15715">https://arxiv.org/pdf/2012.15715</a></td><td>Recent research on cross-lingual word embeddings has been dominated by unsupervised mapping approaches that align monolingual embeddings. Such methods critically rely on those embeddings having a similar structure, but it was recently shown that the separate training in different languages causes departures from this assumption. In this paper, we propose an alternative approach that does not have this limitation, while requiring a weak seed dictionary (e.g., a list of identical words) as the only form of supervision. Rather than aligning two fixed embedding spaces, our method works by fixing the target language embeddings, and learning a new set of embeddings for the source language that are aligned with them. To that end, we use an extension of skip-gram that leverages translated context words as anchor points, and incorporates self-learning and iterative restarts to reduce the dependency on the initial dictionary. Our approach outperforms conventional mapping methods on bilingual lexicon induction, and obtains competitive results in the downstream XNLI task.</td><td>最近关于跨语言词嵌入的研究主要由对齐单语嵌入的无监督映射方法主导。这些方法严重依赖于那些具有相似结构的嵌入，但最近表明，不同语言的单独训练会导致偏离这一假设。在本文中，我们提出了一种没有这种限制的替代方法，同时需要一个弱种子字典（例如，相同单词的列表）作为唯一的监督形式。我们的方法不是对齐两个固定的嵌入空间，而是通过修复目标语言嵌入，并为源语言学习一组与它们对齐的新嵌入来工作。为此，我们使用了skip-gram 的扩展，它利用翻译的上下文词作为锚点，并结合自学习和迭代重启来减少对初始字典的依赖。我们的方法在双语词典归纳方面优于传统的映射方法，并在下游 XNLI 任务中获得了有竞争力的结果。</td><td>Aitor Ormazabal   Mikel Artetxe   Aitor Soroa   Gorka Labaka   Eneko Agirre</td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15421&#39;]">Verb Knowledge Injection for Multilingual Event Processing</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15421">https://arxiv.org/pdf/2012.15421</a></td><td>In parallel to their overwhelming success across NLP tasks, language ability of deep Transformer networks, pretrained via language modeling (LM) objectives has undergone extensive scrutiny. While probing revealed that these models encode a range of syntactic and semantic properties of a language, they are still prone to fall back on superficial cues and simple heuristics to solve downstream tasks, rather than leverage deeper linguistic knowledge. In this paper, we target one such area of their deficiency, verbal reasoning. We investigate whether injecting explicit information on verbs’ semantic-syntactic behaviour improves the performance of LM-pretrained Transformers in event extraction tasks — downstream tasks for which accurate verb processing is paramount. Concretely, we impart the verb knowledge from curated lexical resources into dedicated adapter modules (dubbed verb adapters), allowing it to complement, in downstream tasks, the language knowledge obtained during LM-pretraining. We first demonstrate that injecting verb knowledge leads to performance gains in English event extraction. We then explore the utility of verb adapters for event extraction in other languages: we investigate (1) zero-shot language transfer with multilingual Transformers as well as (2) transfer via (noisy automatic) translation of English verb-based lexical constraints. Our results show that the benefits of verb knowledge injection indeed extend to other languages, even when verb adapters are trained on noisily translated constraints.</td><td>在 NLP 任务中取得压倒性成功的同时，通过语言建模 (LM) 目标预训练的深度 Transformer 网络的语言能力也受到了广泛的审查。虽然探索表明这些模型编码了语言的一系列句法和语义属性，但它们仍然倾向于依靠表面线索和简单的启发式方法来解决下游任务，而不是利用更深层次的语言知识。在本文中，我们针对他们的不足之处之一，即语言推理。我们调查了注入关于动词语义句法行为的显式信息是否可以提高 LM 预训练 Transformer 在事件提取任务中的性能 - 准确的动词处理至关重要的下游任务。具体来说，我们将精选词汇资源中的动词知识传授给专用的适配器模块（称为动词适配器），使其在下游任务中补充 LM 预训练期间获得的语言知识。我们首先证明注入动词知识可以提高英语事件提取的性能。然后，我们探索了动词适配器在其他语言中用于事件提取的效用：我们研究了 (1) 使用多语言 Transformer 的零样本语言迁移以及 (2) 通过（嘈杂的自动）翻译基于英语动词的词汇约束的迁移。我们的结果表明，动词知识注入的好处确实扩展到其他语言，即使动词适配器在嘈杂的翻译约束上进行训练。</td><td>Olga Majewska   Ivan Vulić   Goran Glavaš   Edoardo M. Ponti   Anna Korhonen</td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06937&#39;]">Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning</a></td><td></td><td><a href="https://github.com/INK-USC/XCSR">https://github.com/INK-USC/XCSR</a></td><td><a href="https://arxiv.org/pdf/2106.06937">https://arxiv.org/pdf/2106.06937</a></td><td>Commonsense reasoning research has so far been limited to English. We aim to evaluate and improve popular multilingual language models (ML-LMs) to help advance commonsense reasoning (CSR) beyond English. We collect the Mickey Corpus, consisting of 561k sentences in 11 different languages, which can be used for analyzing and improving ML-LMs. We propose Mickey Probe, a language-agnostic probing task for fairly evaluating the common sense of popular ML-LMs across different languages. In addition, we also create two new datasets, X-CSQA and X-CODAH, by translating their English versions to 15 other languages, so that we can evaluate popular ML-LMs for cross-lingual commonsense reasoning. To improve the performance beyond English, we propose a simple yet effective method — multilingual contrastive pre-training (MCP). It significantly enhances sentence representations, yielding a large performance gain on both benchmarks.</td><td></td><td>Bill Yuchen Lin   Seyeon Lee   Xiaoyang Qiao   Xiang Ren</td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00148&#39;]">Bilingual Lexicon Induction via Unsupervised Bitext Construction and Word Alignment</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2101.00148">https://arxiv.org/pdf/2101.00148</a></td><td>Bilingual lexicons map words in one language to their translations in another, and are typically induced by learning linear projections to align monolingual word embedding spaces. In this paper, we show it is possible to produce much higher quality lexicons with methods that combine (1) unsupervised bitext mining and (2) unsupervised word alignment. Directly applying a pipeline that uses recent algorithms for both subproblems significantly improves induced lexicon quality and further gains are possible by learning to filter the resulting lexical entries, with both unsupervised and semi-supervised schemes. Our final model outperforms the state of the art on the BUCC 2020 shared task by 14 $F_1$ points averaged over 12 language pairs, while also providing a more interpretable approach that allows for rich reasoning of word meaning in context. Further analysis of our output and the standard reference lexicons suggests they are of comparable quality, and new benchmarks may be needed to measure further progress on this task.</td><td>双语词典将一种语言中的单词映射到另一种语言中的翻译，并且通常通过学习线性投影来对齐单语单词嵌入空间来诱导。在本文中，我们展示了使用结合 (1) 无监督双文本挖掘和 (2) 无监督词对齐的方法可以生成更高质量的词典。直接应用对两个子问题使用最新算法的管道可以显着提高诱导词典的质量，并且通过学习过滤生成的词条，可以使用无监督和半监督方案进一步提高。我们的最终模型在 BUCC 2020 共享任务上的表现优于现有技术，在 12 个语言对上平均提高了 14 $F_1$ 点，同时还提供了一种更具可解释性的方法，允许在上下文中对词义进行丰富的推理。对我们的输出和标准参考词典的进一步分析表明它们的质量相当，可能需要新的基准来衡量这项任务的进一步进展。</td><td>Haoyue Shi   Luke Zettlemoyer   Sida I. Wang</td></tr><tr><td>10</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11867&#39;]">Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation</a></td><td></td><td><a href="https://github.com/bzhangGo/zero">https://github.com/bzhangGo/zero</a></td><td><a href="https://arxiv.org/pdf/2004.11867">https://arxiv.org/pdf/2004.11867</a></td><td>Massively multilingual models for neural machine translation (NMT) are theoretically attractive, but often underperform bilingual models and deliver poor zero-shot translations. In this paper, we explore ways to improve them. We argue that multilingual NMT requires stronger modeling capacity to support language pairs with varying typological characteristics, and overcome this bottleneck via language-specific components and deepening NMT architectures. We identify the off-target translation issue (i.e. translating into a wrong target language) as the major source of the inferior zero-shot performance, and propose random online backtranslation to enforce the translation of unseen training language pairs. Experiments on OPUS-100 (a novel multilingual dataset with 100 languages) show that our approach substantially narrows the performance gap with bilingual models in both one-to-many and many-to-many settings, and improves zero-shot performance by ~10 BLEU, approaching conventional pivot-based methods.</td><td>用于神经机器翻译 (NMT) 的大规模多语言模型在理论上很有吸引力，但通常表现不如双语模型并且提供糟糕的零样本翻译。在本文中，我们探索了改进它们的方法。我们认为多语言 NMT 需要更强的建模能力来支持具有不同类型特征的语言对，并通过特定于语言的组件和深化 NMT 架构来克服这一瓶颈。我们将脱靶翻译问题（即翻译成错误的目标语言）确定为较差的零样本性能的主要来源，并提出随机在线反向翻译来强制翻译看不见的训练语言对。在 OPUS-100（一个包含 100 种语言的新型多语言数据集）上的实验表明，我们的方法大大缩小了在一对多和多对多设置中与双语模型的性能差距，并将零样本性能提高了约 10 BLEU，接近传统的基于枢轴的方法。</td><td>Biao Zhang   Philip Williams   Ivan Titov   Rico Sennrich</td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13169&#39;]">Simultaneous Translation Policies: From Fixed to Adaptive</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.13169">https://arxiv.org/pdf/2004.13169</a></td><td>Adaptive policies are better than fixed policies for simultaneous translation, since they can flexibly balance the tradeoff between translation quality and latency based on the current context information. But previous methods on obtaining adaptive policies either rely on complicated training process, or underperform simple fixed policies. We design an algorithm to achieve adaptive policies via a simple heuristic composition of a set of fixed policies. Experiments on Chinese -&gt; English and German -&gt; English show that our adaptive policies can outperform fixed ones by up to 4 BLEU points for the same latency, and more surprisingly, it even surpasses the BLEU score of full-sentence translation in the greedy mode (and very close to beam mode), but with much lower latency.</td><td>对于同步翻译，自适应策略优于固定策略，因为它们可以根据当前上下文信息灵活地平衡翻译质量和延迟之间的权衡。但是以前获取自适应策略的方法要么依赖于复杂的训练过程，要么表现不佳。我们设计了一种算法，通过一组固定策略的简单启发式组合来实现自适应策略。中文 -&gt; 英文和德文 -&gt; 英文的实验表明，在相同的延迟下，我们的自适应策略可以比固定策略高出多达 4 个 BLEU 点，更令人惊讶的是，它甚至超过了贪婪模式下完整句子翻译的 BLEU 分数（并且非常接近光束模式），但延迟要低得多。</td><td>Baigong Zheng   Kaibo Liu   Renjie Zheng   Mingbo Ma   Hairong Liu   Liang Huang</td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14021&#39;]">Multiscale Collaborative Deep Models for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/pemywei/MSC-NMT">https://github.com/pemywei/MSC-NMT</a></td><td><a href="https://arxiv.org/pdf/2004.14021">https://arxiv.org/pdf/2004.14021</a></td><td>Recent evidence reveals that Neural Machine Translation (NMT) models with deeper neural networks can be more effective but are difficult to train. In this paper, we present a MultiScale Collaborative (MSC) framework to ease the training of NMT models that are substantially deeper than those used previously. We explicitly boost the gradient back-propagation from top to bottom levels by introducing a block-scale collaboration mechanism into deep NMT models. Then, instead of forcing the whole encoder stack directly learns a desired representation, we let each encoder block learns a fine-grained representation and enhance it by encoding spatial dependencies using a context-scale collaboration. We provide empirical evidence showing that the MSC nets are easy to optimize and can obtain improvements of translation quality from considerably increased depth. On IWSLT translation tasks with three translation directions, our extremely deep models (with 72-layer encoders) surpass strong baselines by +2.2~+3.1 BLEU points. In addition, our deep MSC achieves a BLEU score of 30.56 on WMT14 English-German task that significantly outperforms state-of-the-art deep NMT models.</td><td>最近的证据表明，具有更深神经网络的神经机器翻译 (NMT) 模型可能更有效，但难以训练。在本文中，我们提出了一个多尺度协作 (MSC) 框架，以简化 NMT 模型的训练，这些模型比以前使用的模型要深得多。我们通过在深度 NMT 模型中引入块级协作机制，显式地提升了从上到下的梯度反向传播。然后，我们不是强制整个编码器堆栈直接学习所需的表示，而是让每个编码器块学习细粒度的表示，并通过使用上下文尺度协作对空间依赖性进行编码来增强它。我们提供的经验证据表明，MSC 网络易于优化，并且可以从显着增加的深度中获得翻译质量的改进。在具有三个翻译方向的 IWSLT 翻译任务上，我们极深的模型（具有 72 层编码器）超过强基线 +2.2~+3.1 BLEU 点。此外，我们的深度 MSC 在 WMT14 英德任务上获得了 30.56 的 BLEU 分数，明显优于最先进的深度 NMT 模型。</td><td>Xiangpeng Wei   Heng Yu   Yue Hu   Yue Zhang   Rongxiang Weng   Weihua Luo</td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14788&#39;]">Character-Level Translation with Self-attention</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14788">https://arxiv.org/pdf/2004.14788</a></td><td>We explore the suitability of self-attention models for character-level neural machine translation. We test the standard transformer model, as well as a novel variant in which the encoder block combines information from nearby characters using convolutions. We perform extensive experiments on WMT and UN datasets, testing both bilingual and multilingual translation to English using up to three input languages (French, Spanish, and Chinese). Our transformer variant consistently outperforms the standard transformer at the character-level and converges faster while learning more robust character-level alignments.</td><td>我们探索了自注意力模型对字符级神经机器翻译的适用性。我们测试了标准转换器模型，以及一种新的变体，其中编码器块使用卷积结合来自附近字符的信息。我们对 WMT 和 UN 数据集进行了大量实验，使用最多三种输入语言（法语、西班牙语和中文）测试双语和多语种翻译成英语。我们的转换器变体在字符级别始终优于标准转换器，并且在学习更强大的字符级别对齐的同时收敛速度更快。</td><td>Yingqiang Gao   Nikola I. Nikolov   Yuhuang Hu   Richard H. R. Hahnloser</td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00850&#39;]">ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/lifu-tu/ENGINE">https://github.com/lifu-tu/ENGINE</a></td><td><a href="https://arxiv.org/pdf/2005.00850">https://arxiv.org/pdf/2005.00850</a></td><td>We propose to train a non-autoregressive machine translation model to minimize the energy defined by a pretrained autoregressive model. In particular, we view our non-autoregressive translation system as an inference network (Tu and Gimpel, 2018) trained to minimize the autoregressive teacher energy. This contrasts with the popular approach of training a non-autoregressive model on a distilled corpus consisting of the beam-searched outputs of such a teacher model. Our approach, which we call ENGINE (ENerGy-based Inference NEtworks), achieves state-of-the-art non-autoregressive results on the IWSLT 2014 DE-EN and WMT 2016 RO-EN datasets, approaching the performance of autoregressive models.</td><td>我们建议训练一个非自回归机器翻译模型，以最小化由预训练自回归模型定义的能量。特别是，我们将我们的非自回归翻译系统视为一个推理网络（Tu 和 Gimpel，2018），经过训练以最小化自回归教师能量。这与在由这种教师模型的波束搜索输出组成的蒸馏语料库上训练非自回归模型的流行方法形成对比。我们称为 ENGINE（基于能源的推理网络）的方法在 IWSLT 2014 DE-EN 和 WMT 2016 RO-EN 数据集上实现了最先进的非自回归结果，接近自回归模型的性能。</td><td>Lifu Tu   Richard Yuanzhe Pang   Sam Wiseman   Kevin Gimpel</td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00308&#39;]">Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.00308">https://arxiv.org/pdf/2005.00308</a></td><td>Machine translation (MT) has benefited from using synthetic training data originating from translating monolingual corpora, a technique known as backtranslation. Combining backtranslated data from different sources has led to better results than when using such data in isolation. In this work we analyse the impact that data translated with rule-based, phrase-based statistical and neural MT systems has on new MT systems. We use a real-world low-resource use-case (Basque-to-Spanish in the clinical domain) as well as a high-resource language pair (German-to-English) to test different scenarios with backtranslation and employ data selection to optimise the synthetic corpora. We exploit different data selection strategies in order to reduce the amount of data used, while at the same time maintaining high-quality MT systems. We further tune the data selection method by taking into account the quality of the MT systems used for backtranslation and lexical diversity of the resulting corpora. Our experiments show that incorporating backtranslated data from different sources can be beneficial, and that availing of data selection can yield improved performance.</td><td>机器翻译 (MT) 受益于使用源自翻译单语语料库的合成训练数据，这种技术称为反向翻译。与单独使用这些数据相比，将来自不同来源的反向翻译数据结合起来会产生更好的结果。在这项工作中，我们分析了使用基于规则、基于短语的统计和神经 MT 系统翻译的数据对新 MT 系统的影响。我们使用现实世界的低资源用例（临床领域的巴斯克语到西班牙语）以及高资源语言对（德语到英语）来测试不同的反向翻译场景，并采用数据选择来优化合成语料库。我们利用不同的数据选择策略来减少使用的数据量，同时保持高质量的 MT 系统。我们通过考虑用于反向翻译的 MT 系统的质量和结果语料库的词汇多样性来进一步调整数据选择方法。我们的实验表明，合并来自不同来源的反向翻译数据可能是有益的，并且利用数据选择可以提高性能。</td><td>Xabier Soto   Dimitar Shterionov   Alberto Poncelas   Andy Way</td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.06606&#39;]">Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/xlhex/dpe">https://github.com/xlhex/dpe</a></td><td><a href="https://arxiv.org/pdf/2005.06606">https://arxiv.org/pdf/2005.06606</a></td><td>This paper introduces Dynamic Programming Encoding (DPE), a new segmentation algorithm for tokenizing sentences into subword units. We view the subword segmentation of output sentences as a latent variable that should be marginalized out for learning and inference. A mixed character-subword transformer is proposed, which enables exact log marginal likelihood estimation and exact MAP inference to find target segmentations with maximum posterior probability. DPE uses a lightweight mixed character-subword transformer as a means of pre-processing parallel data to segment output sentences using dynamic programming. Empirical results on machine translation suggest that DPE is effective for segmenting output sentences and can be combined with BPE dropout for stochastic segmentation of source sentences. DPE achieves an average improvement of 0.9 BLEU over BPE (Sennrich et al., 2016) and an average improvement of 0.55 BLEU over BPE dropout (Provilkov et al., 2019) on several WMT datasets including English &lt;=&gt; (German, Romanian, Estonian, Finnish, Hungarian).</td><td>本文介绍了动态编程编码 (DPE)，这是一种将句子标记为子词单元的新分词算法。我们将输出句子的子词分割视为一个潜在变量，应该被边缘化以进行学习和推理。提出了一种混合字符-子字转换器，它能够进行精确的对数边际似然估计和精确的 MAP 推理，以找到具有最大后验概率的目标分段。 DPE 使用轻量级混合字符-子字转换器作为预处理并行数据的一种手段，以使用动态编程对输出句子进行分段。机器翻译的实证结果表明，DPE 对分割输出句子是有效的，并且可以与 BPE dropout 结合用于源句子的随机分割。 DPE 在包括英语 &lt;=&gt;（德语、罗马尼亚语、爱沙尼亚语、芬兰语、匈牙利语）。</td><td>Xuanli He   Gholamreza Haffari   Mohammad Norouzi</td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.02014&#39;]">Norm-Based Curriculum Learning for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/NLP2CT/norm-nmt">https://github.com/NLP2CT/norm-nmt</a></td><td><a href="https://arxiv.org/pdf/2006.02014">https://arxiv.org/pdf/2006.02014</a></td><td>A neural machine translation (NMT) system is expensive to train, especially with high-resource settings. As the NMT architectures become deeper and wider, this issue gets worse and worse. In this paper, we aim to improve the efficiency of training an NMT by introducing a novel norm-based curriculum learning method. We use the norm (aka length or module) of a word embedding as a measure of 1) the difficulty of the sentence, 2) the competence of the model, and 3) the weight of the sentence. The norm-based sentence difficulty takes the advantages of both linguistically motivated and model-based sentence difficulties. It is easy to determine and contains learning-dependent features. The norm-based model competence makes NMT learn the curriculum in a fully automated way, while the norm-based sentence weight further enhances the learning of the vector representation of the NMT. Experimental results for the WMT’14 English-German and WMT’17 Chinese-English translation tasks demonstrate that the proposed method outperforms strong baselines in terms of BLEU score (+1.17/+1.56) and training speedup (2.22x/3.33x).</td><td></td><td>Xuebo Liu   Houtim Lai   Derek F. Wong   Lidia S. Chao</td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2007.02671&#39;]">Bilingual Dictionary Based Neural Machine Translation without Using Parallel Sentences</a></td><td></td><td><a href="https://github.com/mttravel/Dictionary-based-MT">https://github.com/mttravel/Dictionary-based-MT</a></td><td><a href="https://arxiv.org/pdf/2007.02671">https://arxiv.org/pdf/2007.02671</a></td><td>In this paper, we propose a new task of machine translation (MT), which is based on no parallel sentences but can refer to a ground-truth bilingual dictionary. Motivated by the ability of a monolingual speaker learning to translate via looking up the bilingual dictionary, we propose the task to see how much potential an MT system can attain using the bilingual dictionary and large scale monolingual corpora, while is independent on parallel sentences. We propose anchored training (AT) to tackle the task. AT uses the bilingual dictionary to establish anchoring points for closing the gap between source language and target language. Experiments on various language pairs show that our approaches are significantly better than various baselines, including dictionary-based word-by-word translation, dictionary-supervised cross-lingual word embedding transformation, and unsupervised MT. On distant language pairs that are hard for unsupervised MT to perform well, AT performs remarkably better, achieving performances comparable to supervised SMT trained on more than 4M parallel sentences.</td><td>在本文中，我们提出了机器翻译 (MT) 的一项新任务，该任务不基于平行句，但可以参考真值双语词典。受单语说话者通过查找双语词典学习翻译的能力的启发，我们提出了一项任务，即在独立于平行句子的情况下，使用双语词典和大规模单语语料库查看 MT 系统可以实现多少潜力。我们建议锚定训练（AT）来解决这个任务。 AT 使用双语词典建立定位点，以缩小源语言和目标语言之间的差距。在各种语言对上的实验表明，我们的方法明显优于各种基线，包括基于字典的逐字翻译、字典监督的跨语言词嵌入转换和无监督的机器翻译。在无监督 MT 难以表现良好的远距离语言对上，AT 表现得非常好，达到了与在超过 4M 并行句子上训练的有监督 SMT 相当的性能。</td><td>Xiangyu Duan   Baijun Ji   Hao Jia   Min Tan   Min Zhang   Boxing Chen   Weihua Luo   Yue Zhang</td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11867&#39;]">Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation</a></td><td></td><td><a href="https://github.com/bzhangGo/zero">https://github.com/bzhangGo/zero</a></td><td><a href="https://arxiv.org/pdf/2004.11867">https://arxiv.org/pdf/2004.11867</a></td><td>Massively multilingual models for neural machine translation (NMT) are theoretically attractive, but often underperform bilingual models and deliver poor zero-shot translations. In this paper, we explore ways to improve them. We argue that multilingual NMT requires stronger modeling capacity to support language pairs with varying typological characteristics, and overcome this bottleneck via language-specific components and deepening NMT architectures. We identify the off-target translation issue (i.e. translating into a wrong target language) as the major source of the inferior zero-shot performance, and propose random online backtranslation to enforce the translation of unseen training language pairs. Experiments on OPUS-100 (a novel multilingual dataset with 100 languages) show that our approach substantially narrows the performance gap with bilingual models in both one-to-many and many-to-many settings, and improves zero-shot performance by ~10 BLEU, approaching conventional pivot-based methods.</td><td>用于神经机器翻译 (NMT) 的大规模多语言模型在理论上很有吸引力，但通常表现不如双语模型并且提供糟糕的零样本翻译。在本文中，我们探索了改进它们的方法。我们认为多语言 NMT 需要更强的建模能力来支持具有不同类型特征的语言对，并通过特定于语言的组件和深化 NMT 架构来克服这一瓶颈。我们将脱靶翻译问题（即翻译成错误的目标语言）确定为较差的零样本性能的主要来源，并提出随机在线反向翻译来强制翻译看不见的训练语言对。在 OPUS-100（一个包含 100 种语言的新型多语言数据集）上的实验表明，我们的方法大大缩小了在一对多和多对多设置中与双语模型的性能差距，并将零样本性能提高了约 10 BLEU，接近传统的基于枢轴的方法。</td><td>Biao Zhang   Philip Williams   Ivan Titov   Rico Sennrich</td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00850&#39;]">ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/lifu-tu/ENGINE">https://github.com/lifu-tu/ENGINE</a></td><td><a href="https://arxiv.org/pdf/2005.00850">https://arxiv.org/pdf/2005.00850</a></td><td>We propose to train a non-autoregressive machine translation model to minimize the energy defined by a pretrained autoregressive model. In particular, we view our non-autoregressive translation system as an inference network (Tu and Gimpel, 2018) trained to minimize the autoregressive teacher energy. This contrasts with the popular approach of training a non-autoregressive model on a distilled corpus consisting of the beam-searched outputs of such a teacher model. Our approach, which we call ENGINE (ENerGy-based Inference NEtworks), achieves state-of-the-art non-autoregressive results on the IWSLT 2014 DE-EN and WMT 2016 RO-EN datasets, approaching the performance of autoregressive models.</td><td>我们建议训练一个非自回归机器翻译模型，以最小化由预训练自回归模型定义的能量。特别是，我们将我们的非自回归翻译系统视为一个推理网络（Tu 和 Gimpel，2018），经过训练以最小化自回归教师能量。这与在由这种教师模型的波束搜索输出组成的蒸馏语料库上训练非自回归模型的流行方法形成对比。我们称为 ENGINE（基于能源的推理网络）的方法在 IWSLT 2014 DE-EN 和 WMT 2016 RO-EN 数据集上实现了最先进的非自回归结果，接近自回归模型的性能。</td><td>Lifu Tu   Richard Yuanzhe Pang   Sam Wiseman   Kevin Gimpel</td></tr><tr><td>21</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.01313&#39;]">An Effective Approach to Unsupervised Machine Translation</a></td><td></td><td><a href="https://github.com/artetxem/monoses">https://github.com/artetxem/monoses</a></td><td><a href="https://arxiv.org/pdf/1902.01313">https://arxiv.org/pdf/1902.01313</a></td><td>While machine translation has traditionally relied on large amounts of parallel corpora, a recent research line has managed to train both Neural Machine Translation (NMT) and Statistical Machine Translation (SMT) systems using monolingual corpora only. In this paper, we identify and address several deficiencies of existing unsupervised SMT approaches by exploiting subword information, developing a theoretically well founded unsupervised tuning method, and incorporating a joint refinement procedure. Moreover, we use our improved SMT system to initialize a dual NMT model, which is further fine-tuned through on-the-fly back-translation. Together, we obtain large improvements over the previous state-of-the-art in unsupervised machine translation. For instance, we get 22.5 BLEU points in English-to-German WMT 2014, 5.5 points more than the previous best unsupervised system, and 0.5 points more than the (supervised) shared task winner back in 2014.</td><td>虽然机器翻译传统上依赖于大量的平行语料库，但最近的一项研究成功地仅使用单语语料库来训练神经机器翻译 (NMT) 和统计机器翻译 (SMT) 系统。在本文中，我们通过利用子字信息、开发理论上有充分根据的无监督调整方法并结合联合细化程序来识别和解决现有无监督 SMT 方法的几个缺陷。此外，我们使用改进的 SMT 系统来初始化双 NMT 模型，该模型通过动态反向翻译进一步微调。总之，我们在无监督机器翻译方面比以前的最新技术取得了很大的改进。例如，我们在 English-to-German WMT 2014 中获得 22.5 BLEU 分，比之前最好的无监督系统多 5.5 分，比 2014 年的（监督）共享任务获胜者多 0.5 分。</td><td>Mikel Artetxe   Gorka Labaka   Eneko Agirre</td></tr><tr><td>22</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.05979&#39;]">When a Good Translation is Wrong in Context: Context-Aware Machine Translation Improves on Deixis, Ellipsis, and Lexical Cohesion</a></td><td></td><td><a href="https://github.com/lena-voita/good-translation-wrong-in-context">https://github.com/lena-voita/good-translation-wrong-in-context</a></td><td><a href="https://arxiv.org/pdf/1905.05979">https://arxiv.org/pdf/1905.05979</a></td><td>Though machine translation errors caused by the lack of context beyond one sentence have long been acknowledged, the development of context-aware NMT systems is hampered by several problems. Firstly, standard metrics are not sensitive to improvements in consistency in document-level translations. Secondly, previous work on context-aware NMT assumed that the sentence-aligned parallel data consisted of complete documents while in most practical scenarios such document-level data constitutes only a fraction of the available parallel data. To address the first issue, we perform a human study on an English-Russian subtitles dataset and identify deixis, ellipsis and lexical cohesion as three main sources of inconsistency. We then create test sets targeting these phenomena. To address the second shortcoming, we consider a set-up in which a much larger amount of sentence-level data is available compared to that aligned at the document level. We introduce a model that is suitable for this scenario and demonstrate major gains over a context-agnostic baseline on our new benchmarks without sacrificing performance as measured with BLEU.</td><td>尽管由于缺乏一个句子之外的上下文而导致机器翻译错误早已得到承认，但上下文感知 NMT 系统的发展受到几个问题的阻碍。首先，标准指标对文档级翻译一致性的改进不敏感。其次，之前关于上下文感知 NMT 的工作假设句子对齐的并行数据由完整的文档组成，而在大多数实际场景中，此类文档级数据仅构成可用并行数据的一小部分。为了解决第一个问题，我们对英俄字幕数据集进行了人类研究，并将指示符、省略号和词汇衔接确定为不一致的三个主要来源。然后我们创建针对这些现象的测试集。为了解决第二个缺点，我们考虑了一种设置，其中与在文档级别对齐的数据相比，可用的句子级别数据要多得多。我们引入了一个适用于这种情况的模型，并在不牺牲使用 BLEU 测量的性能的情况下，在我们的新基准测试中展示了相对于上下文无关基线的主要收益。</td><td>Elena Voita   Rico Sennrich   Ivan Titov</td></tr><tr><td>23</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.02780&#39;]">Syntactically Supervised Transformers for Faster Neural Machine Translation</a></td><td></td><td><a href="https://github.com/dojoteef/synst">https://github.com/dojoteef/synst</a></td><td><a href="https://arxiv.org/pdf/1906.02780">https://arxiv.org/pdf/1906.02780</a></td><td>Standard decoders for neural machine translation autoregressively generate a single target token per time step, which slows inference especially for long outputs. While architectural advances such as the Transformer fully parallelize the decoder computations at training time, inference still proceeds sequentially. Recent developments in non- and semi- autoregressive decoding produce multiple tokens per time step independently of the others, which improves inference speed but deteriorates translation quality. In this work, we propose the syntactically supervised Transformer (SynST), which first autoregressively predicts a chunked parse tree before generating all of the target tokens in one shot conditioned on the predicted parse. A series of controlled experiments demonstrates that SynST decodes sentences ~ 5x faster than the baseline autoregressive Transformer while achieving higher BLEU scores than most competing methods on En-De and En-Fr datasets.</td><td>用于神经机器翻译的标准解码器在每个时间步长自动回归生成单个目标标记，这会减慢推理速度，尤其是对于长输出。虽然诸如 Transformer 之类的架构进步在训练时完全并行化了解码器计算，但推理仍然按顺序进行。非自回归解码和半自回归解码的最新发展在每个时间步长生成多个标记，独立于其他标记，这提高了推理速度，但降低了翻译质量。在这项工作中，我们提出了句法监督的 Transformer (SynST)，它首先自回归预测一个分块的解析树，然后在一次以预测解析为条件的镜头中生成所有目标标记。一系列受控实验表明，SynST 解码句子的速度比基线自回归 Transformer 快 5 倍，同时在 En-De 和 En-Fr 数据集上获得比大多数竞争方法更高的 BLEU 分数。</td><td>Nader Akoury   Kalpesh Krishna   Mohit Iyyer</td></tr><tr><td>24</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/2106.08680&#39;, &#39;https://arxiv.org/abs/1906.00591&#39;]">Evaluating Gender Bias in Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.08680">https://arxiv.org/pdf/2106.08680</a></td><td>With language models being deployed increasingly in the real world, it is essential to address the issue of the fairness of their outputs. The word embedding representations of these language models often implicitly draw unwanted associations that form a social bias within the model. The nature of gendered languages like Hindi, poses an additional problem to the quantification and mitigation of bias, owing to the change in the form of the words in the sentence, based on the gender of the subject. Additionally, there is sparse work done in the realm of measuring and debiasing systems for Indic languages. In our work, we attempt to evaluate and quantify the gender bias within a Hindi-English machine translation system. We implement a modified version of the existing TGBI metric based on the grammatical considerations for Hindi. We also compare and contrast the resulting bias measurements across multiple metrics for pre-trained embeddings and the ones learned by our machine translation model.</td><td>随着语言模型在现实世界中越来越多地部署，解决其输出的公平性问题至关重要。这些语言模型的词嵌入表示通常会隐含地绘制不需要的关联，从而在模型内形成社会偏见。由于基于主题的性别，句子中单词的形式发生了变化，像印地语这样的性别化语言的性质给偏见的量化和缓解带来了额外的问题。此外，在印度语言的测量和去偏差系统领域完成的工作很少。在我们的工作中，我们尝试评估和量化印地语-英语机器翻译系统中的性别偏见。我们基于印地语的语法考虑实施了现有 TGBI 指标的修改版本。我们还比较和对比了预训练嵌入和我们的机器翻译模型学习的嵌入的多个指标的偏差测量结果。</td><td>Gauri Gupta   Krithika Ramesh   Sanjay Singh   Gabriel Stanovsky   Noah A. Smith   Luke Zettlemoyer</td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01787&#39;]">Learning Deep Transformer Models for Machine Translation</a></td><td></td><td><a href="https://github.com/wangqiangneu/dlcl">https://github.com/wangqiangneu/dlcl</a></td><td><a href="https://arxiv.org/pdf/1906.01787">https://arxiv.org/pdf/1906.01787</a></td><td>Transformer is the state-of-the-art model in recent machine translation evaluations. Two strands of research are promising to improve models of this kind: the first uses wide networks (a.k.a. Transformer-Big) and has been the de facto standard for the development of the Transformer system, and the other uses deeper language representation but faces the difficulty arising from learning deep networks. Here, we continue the line of research on the latter. We claim that a truly deep Transformer model can surpass the Transformer-Big counterpart by 1) proper use of layer normalization and 2) a novel way of passing the combination of previous layers to the next. On WMT’16 English- German, NIST OpenMT’12 Chinese-English and larger WMT’18 Chinese-English tasks, our deep system (30/25-layer encoder) outperforms the shallow Transformer-Big/Base baseline (6-layer encoder) by 0.4-2.4 BLEU points. As another bonus, the deep model is 1.6X smaller in size and 3X faster in training than Transformer-Big.</td><td>Transformer 是最近机器翻译评估中最先进的模型。有两方面的研究有望改进此类模型：一是使用宽网络（又名 Transformer-Big）并且已经成为 Transformer 系统开发的事实上的标准，另一方面使用更深层次的语言表示但面临困难源于学习深度网络。在这里，我们继续对后者进行研究。我们声称，一个真正的深度 Transformer 模型可以通过 1) 正确使用层归一化和 2) 一种将前一层的组合传递到下一层的新方法来超越 Transformer-Big 对应物。在 WMT’16 English-German、NIST OpenMT’12 Chinese-English 和更大的 WMT’18 Chinese-English 任务中，我们的深层系统（30/25 层编码器）优于浅层 Transformer-Big/Base 基线（6 层编码器） ) 0.4-2.4 BLEU 点。作为另一个好处，深度模型的大小比 Transformer-Big 小 1.6 倍，训练速度快 3 倍。</td><td>Qiang Wang   Bei Li   Tong Xiao   Jingbo Zhu   Changliang Li   Derek F. Wong   Lidia S. Chao</td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00376&#39;]">Domain Adaptation of Neural Machine Translation by Lexicon Induction</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.00376">https://arxiv.org/pdf/1906.00376</a></td><td>It has been previously noted that neural machine translation (NMT) is very sensitive to domain shift. In this paper, we argue that this is a dual effect of the highly lexicalized nature of NMT, resulting in failure for sentences with large numbers of unknown words, and lack of supervision for domain-specific words. To remedy this problem, we propose an unsupervised adaptation method which fine-tunes a pre-trained out-of-domain NMT model using a pseudo-in-domain corpus. Specifically, we perform lexicon induction to extract an in-domain lexicon, and construct a pseudo-parallel in-domain corpus by performing word-for-word back-translation of monolingual in-domain target sentences. In five domains over twenty pairwise adaptation settings and two model architectures, our method achieves consistent improvements without using any in-domain parallel sentences, improving up to 14 BLEU over unadapted models, and up to 2 BLEU over strong back-translation baselines.</td><td>之前已经注意到神经机器翻译 (NMT) 对域转移非常敏感。在本文中，我们认为这是 NMT 高度词汇化性质的双重影响，导致具有大量未知单词的句子失败，以及缺乏对特定领域单词的监督。为了解决这个问题，我们提出了一种无监督的自适应方法，该方法使用伪域内语料库对预训练的域外 NMT 模型进行微调。具体来说，我们进行词典归纳以提取域内词典，并通过对单语域内目标句子进行逐字反向翻译来构建伪平行域内语料库。在超过 20 个成对适应设置和两个模型架构的五个域中，我们的方法在不使用任何域内并行语句的情况下实现了一致的改进，在未适应模型上提高了 14 个 BLEU，在强反向翻译基线上提高了 2 个 BLEU。</td><td>Junjie Hu   Mengzhou Xia   Graham Neubig   Jaime Carbonell</td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.09444&#39;]">Retrieving Sequential Information for Non-Autoregressive Neural Machine Translation</a></td><td></td><td><a href="https://github.com/ictnlp/RSI-NAT">https://github.com/ictnlp/RSI-NAT</a></td><td><a href="https://arxiv.org/pdf/1906.09444">https://arxiv.org/pdf/1906.09444</a></td><td>Non-Autoregressive Transformer (NAT) aims to accelerate the Transformer model through discarding the autoregressive mechanism and generating target words independently, which fails to exploit the target sequential information. Over-translation and under-translation errors often occur for the above reason, especially in the long sentence translation scenario. In this paper, we propose two approaches to retrieve the target sequential information for NAT to enhance its translation ability while preserving the fast-decoding property. Firstly, we propose a sequence-level training method based on a novel reinforcement algorithm for NAT (Reinforce-NAT) to reduce the variance and stabilize the training procedure. Secondly, we propose an innovative Transformer decoder named FS-decoder to fuse the target sequential information into the top layer of the decoder. Experimental results on three translation tasks show that the Reinforce-NAT surpasses the baseline NAT system by a significant margin on BLEU without decelerating the decoding speed and the FS-decoder achieves comparable translation performance to the autoregressive Transformer with considerable speedup.</td><td>Non-Autoregressive Transformer (NAT) 旨在通过丢弃自回归机制并独立生成目标词来加速 Transformer 模型，这无法利用目标序列信息。由于上述原因，经常会出现过度翻译和翻译不足的错误，尤其是在长句翻译场景中。在本文中，我们提出了两种方法来检索 NAT 的目标序列信息，以增强其翻译能力，同时保留快速解码特性。首先，我们提出了一种基于新的 NAT 强化算法（Reinforce-NAT）的序列级训练方法，以减少方差并稳定训练过程。其次，我们提出了一种名为 FS-decoder 的创新 Transformer 解码器，将目标序列信息融合到解码器的顶层。在三个翻译任务上的实验结果表明，在不降低解码速度的情况下，Reinforce-NAT 在 BLEU 上大大超过了基线 NAT 系统，并且 FS-decoder 以相当大的速度实现了与自回归 Transformer 相当的翻译性能。</td><td>Chenze Shao   Yang Feng   Jinchao Zhang   Fandong Meng   Xilin Chen   Jie Zhou</td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1810.06729&#39;]">Robust Neural Machine Translation with Joint Textual and Phonetic Embedding</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1810.06729">https://arxiv.org/pdf/1810.06729</a></td><td>Neural machine translation (NMT) is notoriously sensitive to noises, but noises are almost inevitable in practice. One special kind of noise is the homophone noise, where words are replaced by other words with similar pronunciations. We propose to improve the robustness of NMT to homophone noises by 1) jointly embedding both textual and phonetic information of source sentences, and 2) augmenting the training dataset with homophone noises. Interestingly, to achieve better translation quality and more robustness, we found that most (though not all) weights should be put on the phonetic rather than textual information. Experiments show that our method not only significantly improves the robustness of NMT to homophone noises, but also surprisingly improves the translation quality on some clean test sets.</td><td>众所周知，神经机器翻译 (NMT) 对噪音非常敏感，但在实践中噪音几乎是不可避免的。一种特殊的噪音是同音噪音，其中单词被其他具有相似发音的单词替换。我们建议通过 1) 联合嵌入源句子的文本和语音信息，以及 2) 用同音噪声增强训练数据集来提高 NMT 对同音噪声的鲁棒性。有趣的是，为了获得更好的翻译质量和更强的鲁棒性，我们发现大多数（尽管不是全部）权重应该放在语音信息而不是文本信息上。实验表明，我们的方法不仅显着提高了 NMT 对同音字噪声的鲁棒性，而且还令人惊讶地提高了一些干净测试集的翻译质量。</td><td>Hairong Liu   Mingbo Ma   Liang Huang   Hao Xiong   Zhongjun He</td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.13872&#39;]">Simple and Effective Paraphrastic Similarity from Parallel Translations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.13872">https://arxiv.org/pdf/1909.13872</a></td><td>We present a model and methodology for learning paraphrastic sentence embeddings directly from bitext, removing the time-consuming intermediate step of creating paraphrase corpora. Further, we show that the resulting model can be applied to cross-lingual tasks where it both outperforms and is orders of magnitude faster than more complex state-of-the-art baselines.</td><td></td><td>John Wieting   Kevin Gimpel   Graham Neubig   Taylor Berg-Kirkpatrick</td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.04980&#39;]">Unsupervised Question Answering by Cloze Translation</a></td><td></td><td><a href="https://github.com/facebookresearch/UnsupervisedQA">https://github.com/facebookresearch/UnsupervisedQA</a></td><td><a href="https://arxiv.org/pdf/1906.04980">https://arxiv.org/pdf/1906.04980</a></td><td>Obtaining training data for Question Answering (QA) is time-consuming and resource-intensive, and existing QA datasets are only available for limited domains and languages. In this work, we explore to what extent high quality training data is actually required for Extractive QA, and investigate the possibility of unsupervised Extractive QA. We approach this problem by first learning to generate context, question and answer triples in an unsupervised manner, which we then use to synthesize Extractive QA training data automatically. To generate such triples, we first sample random context paragraphs from a large corpus of documents and then random noun phrases or named entity mentions from these paragraphs as answers. Next we convert answers in context to “fill-in-the-blank” cloze questions and finally translate them into natural questions. We propose and compare various unsupervised ways to perform cloze-to-natural question translation, including training an unsupervised NMT model using non-aligned corpora of natural questions and cloze questions as well as a rule-based approach. We find that modern QA models can learn to answer human questions surprisingly well using only synthetic training data. We demonstrate that, without using the SQuAD training data at all, our approach achieves 56.4 F1 on SQuAD v1 (64.5 F1 when the answer is a Named entity mention), outperforming early supervised models.</td><td>获取问答 (QA) 的训练数据既耗时又耗费资源，现有的 QA 数据集仅适用于有限的领域和语言。在这项工作中，我们探索了 Extractive QA 在多大程度上需要高质量的训练数据，并研究了无监督 Extractive QA 的可能性。我们通过首先学习以无监督的方式生成上下文、问题和答案三元组来解决这个问题，然后我们将其用于自动合成提取 QA 训练数据。为了生成这样的三元组，我们首先从大型文档语料库中随机抽取上下文段落，然后从这些段落中随机抽取名词短语或命名实体作为答案。接下来，我们将上下文中的答案转换为“填空”完形填空题，最后将它们转换为自然问题。我们提出并比较了执行完形填空到自然问题翻译的各种无监督方法，包括使用自然问题和完形填空问题的非对齐语料库以及基于规则的方法训练无监督 NMT 模型。我们发现现代 QA 模型可以学习仅使用合成训练数据就出人意料地很好地回答人类问题。我们证明，在完全不使用 SQuAD 训练数据的情况下，我们的方法在 SQuAD v1 上达到了 56.4 F1（当答案是命名实体提及时为 64.5 F1），优于早期的监督模型。</td><td>Patrick Lewis   Ludovic Denoyer   Sebastian Riedel</td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.10761&#39;]">Bilingual Lexicon Induction through Unsupervised Machine Translation</a></td><td></td><td><a href="https://github.com/artetxem/monoses">https://github.com/artetxem/monoses</a></td><td><a href="https://arxiv.org/pdf/1907.10761">https://arxiv.org/pdf/1907.10761</a></td><td>A recent research line has obtained strong results on bilingual lexicon induction by aligning independently trained word embeddings in two languages and using the resulting cross-lingual embeddings to induce word translation pairs through nearest neighbor or related retrieval methods. In this paper, we propose an alternative approach to this problem that builds on the recent work on unsupervised machine translation. This way, instead of directly inducing a bilingual lexicon from cross-lingual embeddings, we use them to build a phrase-table, combine it with a language model, and use the resulting machine translation system to generate a synthetic parallel corpus, from which we extract the bilingual lexicon using statistical word alignment techniques. As such, our method can work with any word embedding and cross-lingual mapping technique, and it does not require any additional resource besides the monolingual corpus used to train the embeddings. When evaluated on the exact same cross-lingual embeddings, our proposed method obtains an average improvement of 6 accuracy points over nearest neighbor and 4 points over CSLS retrieval, establishing a new state-of-the-art in the standard MUSE dataset.</td><td>最近的一条研究线通过对齐两种语言中独立训练的词嵌入并使用产生的跨语言嵌入通过最近邻或相关检索方法来诱导词翻译对，在双语词典归纳方面取得了很好的成果。在本文中，我们提出了一种替代方法来解决这个问题，该方法建立在最近关于无监督机器翻译的工作基础上。这样，我们不是直接从跨语言嵌入中归纳出双语词典，而是使用它们来构建短语表，将其与语言模型结合，并使用生成的机器翻译系统生成合成平行语料库，从中我们使用统计词对齐技术提取双语词典。因此，我们的方法可以与任何词嵌入和跨语言映射技术一起使用，除了用于训练嵌入的单语语料库之外，它不需要任何额外的资源。当对完全相同的跨语言嵌入进行评估时，我们提出的方法比最近邻平均提高了 6 个精度点，比 CSLS 检索平均提高了 4 个点，在标准 MUSE 数据集中建立了新的最新技术。</td><td>Mikel Artetxe   Gorka Labaka   Eneko Agirre</td></tr><tr><td>32</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.10523&#39;]">Soft Contextual Data Augmentation for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/teslacool/SCA">https://github.com/teslacool/SCA</a></td><td><a href="https://arxiv.org/pdf/1905.10523">https://arxiv.org/pdf/1905.10523</a></td><td>While data augmentation is an important trick to boost the accuracy of deep learning methods in computer vision tasks, its study in natural language tasks is still very limited. In this paper, we present a novel data augmentation method for neural machine translation. Different from previous augmentation methods that randomly drop, swap or replace words with other words in a sentence, we softly augment a randomly chosen word in a sentence by its contextual mixture of multiple related words. More accurately, we replace the one-hot representation of a word by a distribution (provided by a language model) over the vocabulary, i.e., replacing the embedding of this word by a weighted combination of multiple semantically similar words. Since the weights of those words depend on the contextual information of the word to be replaced, the newly generated sentences capture much richer information than previous augmentation methods. Experimental results on both small scale and large scale machine translation datasets demonstrate the superiority of our method over strong baselines.</td><td>虽然数据增强是在计算机视觉任务中提高深度学习方法准确性的重要技巧，但它在自然语言任务中的研究仍然非常有限。在本文中，我们提出了一种新的神经机器翻译数据增强方法。与之前随机删除、交换或替换句子中的其他单词的增强方法不同，我们通过多个相关单词的上下文混合来轻柔地增强句子中随机选择的单词。更准确地说，我们用词汇表上的分布（由语言模型提供）替换一个词的 one-hot 表示，即用多个语义相似词的加权组合替换这个词的嵌入。由于这些词的权重取决于要替换的词的上下文信息，因此新生成的句子比以前的增强方法捕获了更丰富的信息。在小规模和大规模机器翻译数据集上的实验结果证明了我们的方法在强基线上的优越性。</td><td>Jinhua Zhu   Fei Gao   Lijun Wu   Yingce Xia   Tao Qin   Wengang Zhou   Xueqi Cheng   Tie-Yan Liu</td></tr><tr><td>33</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03785&#39;]">Generalized Data Augmentation for Low-Resource Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.03785">https://arxiv.org/pdf/1906.03785</a></td><td>Translation to or from low-resource languages LRLs poses challenges for machine translation in terms of both adequacy and fluency. Data augmentation utilizing large amounts of monolingual data is regarded as an effective way to alleviate these problems. In this paper, we propose a general framework for data augmentation in low-resource machine translation that not only uses target-side monolingual data, but also pivots through a related high-resource language HRL. Specifically, we experiment with a two-step pivoting method to convert high-resource data to the LRL, making use of available resources to better approximate the true data distribution of the LRL. First, we inject LRL words into HRL sentences through an induced bilingual dictionary. Second, we further edit these modified sentences using a modified unsupervised machine translation framework. Extensive experiments on four low-resource datasets show that under extreme low-resource settings, our data augmentation techniques improve translation quality by up to~1.5 to~8 BLEU points compared to supervised back-translation baselines</td><td>与低资源语言 LRL 之间的翻译在充分性和流畅性方面对机器翻译提出了挑战。利用大量单语数据的数据增强被认为是缓解这些问题的有效方法。在本文中，我们提出了一种用于低资源机器翻译中数据增强的通用框架，该框架不仅使用目标端单语数据，而且还通过相关的高资源语言 HRL 进行支点。具体来说，我们尝试使用两步旋转方法将高资源数据转换为 LRL，利用可用资源更好地近似 LRL 的真实数据分布。首先，我们通过诱导双语词典将 LRL 词注入 HRL 句子中。其次，我们使用修改后的无监督机器翻译框架进一步编辑这些修改后的句子。对四个低资源数据集的大量实验表明，在极端低资源设置下，与有监督的反向翻译基线相比，我们的数据增强技术将翻译质量提高了 1.5 到 8 个 BLEU 点</td><td>Mengzhou Xia   Xiang Kong   Antonios Anastasopoulos   Graham Neubig</td></tr></tbody></table></div><h3 id="EMNLP"><a href="#EMNLP" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.10485&#39;]">Fully Quantized Transformer for Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1910.10485">https://arxiv.org/pdf/1910.10485</a></td><td>State-of-the-art neural machine translation methods employ massive amounts of parameters. Drastically reducing computational costs of such methods without affecting performance has been up to this point unsuccessful. To this end, we propose FullyQT: an all-inclusive quantization strategy for the Transformer. To the best of our knowledge, we are the first to show that it is possible to avoid any loss in translation quality with a fully quantized Transformer. Indeed, compared to full-precision, our 8-bit models score greater or equal BLEU on most tasks. Comparing ourselves to all previously proposed methods, we achieve state-of-the-art quantization results.</td><td>最先进的神经机器翻译方法使用大量参数。在不影响性能的情况下大幅降低此类方法的计算成本到目前为止还没有成功。为此，我们提出了 FullQT：Transformer 的全包量化策略。据我们所知，我们是第一个证明使用完全量化的 Transformer 可以避免翻译质量下降的人。事实上，与全精度相比，我们的 8 位模型在大多数任务上的得分更高或等于 BLEU。与之前提出的所有方法相比，我们实现了最先进的量化结果。</td><td>Gabriele Prato   Ella Charlaix   Mehdi Rezagholizadeh</td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.10260&#39;]">Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.10260">https://arxiv.org/pdf/2002.10260</a></td><td>Transformer-based models have brought a radical change to neural machine translation. A key feature of the Transformer architecture is the so-called multi-head attention mechanism, which allows the model to focus simultaneously on different parts of the input. However, recent works have shown that most attention heads learn simple, and often redundant, positional patterns. In this paper, we propose to replace all but one attention head of each encoder layer with simple fixed — non-learnable — attentive patterns that are solely based on position and do not require any external knowledge. Our experiments with different data sizes and multiple language pairs show that fixing the attention heads on the encoder side of the Transformer at training time does not impact the translation quality and even increases BLEU scores by up to 3 points in low-resource scenarios.</td><td>基于 Transformer 的模型给神经机器翻译带来了根本性的变化。 Transformer 架构的一个关键特性是所谓的多头注意力机制，它允许模型同时关注输入的不同部分。然而，最近的工作表明，大多数注意力头学习简单的、通常是冗余的位置模式。在本文中，我们建议用简单的固定的——不可学习的——注意力模式替换每个编码器层的除一个注意力头之外的所有注意力模式，这些模式完全基于位置并且不需要任何外部知识。我们对不同数据大小和多语言对的实验表明，在训练时将注意力头固定在 Transformer 的编码器端不会影响翻译质量，甚至在低资源场景中将 BLEU 分数提高多达 3 分。</td><td>Alessandro Raganato   Yves Scherrer   Jörg Tiedemann</td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14109&#39;]">Adversarial Subword Regularization for Robust Neural Machine Translation</a></td><td></td><td><a href="https://github.com/dmis-lab/AdvSR">https://github.com/dmis-lab/AdvSR</a></td><td><a href="https://arxiv.org/pdf/2004.14109">https://arxiv.org/pdf/2004.14109</a></td><td>Exposing diverse subword segmentations to neural machine translation (NMT) models often improves the robustness of machine translation as NMT models can experience various subword candidates. However, the diversification of subword segmentations mostly relies on the pre-trained subword language models from which erroneous segmentations of unseen words are less likely to be sampled. In this paper, we present adversarial subword regularization (ADVSR) to study whether gradient signals during training can be a substitute criterion for exposing diverse subword segmentations. We experimentally show that our model-based adversarial samples effectively encourage NMT models to be less sensitive to segmentation errors and improve the performance of NMT models in low-resource and out-domain datasets.</td><td>将不同的子词分割暴露给神经机器翻译 (NMT) 模型通常会提高机器翻译的鲁棒性，因为 NMT 模型可以体验各种子词候选。然而，子词切分的多样化主要依赖于预训练的子词语言模型，从这些模型中不太可能对不可见词的错误切分进行采样。在本文中，我们提出了对抗性子词正则化（ADVSR）来研究训练期间的梯度信号是否可以作为暴露不同子词分割的替代标准。我们通过实验表明，我们基于模型的对抗样本有效地鼓励 NMT 模型对分割错误不那么敏感，并提高了 NMT 模型在低资源和域外数据集中的性能。</td><td>Jungsoo Park   Mujeen Sung   Jinhyuk Lee   Jaewoo Kang</td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02353&#39;]">Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages</a></td><td></td><td><a href="https://github.com/masakhane-io/masakhane-mt">https://github.com/masakhane-io/masakhane-mt</a></td><td><a href="https://arxiv.org/pdf/2010.02353">https://arxiv.org/pdf/2010.02353</a></td><td>Research in NLP lacks geographic diversity, and the question of how NLP can be scaled to low-resourced languages has not yet been adequately solved. “Low-resourced”-ness is a complex problem going beyond data availability and reflects systemic problems in society. In this paper, we focus on the task of Machine Translation (MT), that plays a crucial role for information accessibility and communication worldwide. Despite immense improvements in MT over the past decade, MT is centered around a few high-resourced languages. As MT researchers cannot solve the problem of low-resourcedness alone, we propose participatory research as a means to involve all necessary agents required in the MT development process. We demonstrate the feasibility and scalability of participatory research with a case study on MT for African languages. Its implementation leads to a collection of novel translation datasets, MT benchmarks for over 30 languages, with human evaluations for a third of them, and enables participants without formal training to make a unique scientific contribution. Benchmarks, models, data, code, and evaluation results are released under <a href="https://github.com/masakhane-io/masakhane-mt">https://github.com/masakhane-io/masakhane-mt</a>.</td><td></td><td>Wilhelmina Nekoto   Vukosi Marivate   Tshinondiwa Matsila   Timi Fasubaa   Tajudeen Kolawole   Taiwo Fagbohungbe   Solomon Oluwole Akinola   Shamsuddeen Hassan Muhammad   Salomon Kabongo   Salomey Osei   Sackey Freshia   Rubungo Andre Niyongabo   Ricky Macharm   Perez Ogayo   Orevaoghene Ahia   Musie Meressa   Mofe Adeyemi   Masabata Mokgesi-Selinga   Lawrence Okegbemi   Laura Jane Martinus   Kolawole Tajudeen   Kevin Degila   Kelechi Ogueji   Kathleen Siminyu   Julia Kreutzer</td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.14824&#39;]">On Romanization for Model Transfer Between Scripts in Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.14824">https://arxiv.org/pdf/2009.14824</a></td><td>Transfer learning is a popular strategy to improve the quality of low-resource machine translation. For an optimal transfer of the embedding layer, the child and parent model should share a substantial part of the vocabulary. This is not the case when transferring to languages with a different script. We explore the benefit of romanization in this scenario. Our results show that romanization entails information loss and is thus not always superior to simpler vocabulary transfer methods, but can improve the transfer between related languages with different scripts. We compare two romanization tools and find that they exhibit different degrees of information loss, which affects translation quality. Finally, we extend romanization to the target side, showing that this can be a successful strategy when coupled with a simple deromanization model.</td><td>迁移学习是提高低资源机器翻译质量的流行策略。为了优化嵌入层的转移，子模型和父模型应该共享词汇表的大部分。转换为具有不同脚本的语言时，情况并非如此。我们探讨了在这种情况下罗马化的好处。我们的结果表明，罗马化会导致信息丢失，因此并不总是优于更简单的词汇转移方法，但可以改善具有不同脚本的相关语言之间的转移。我们比较了两种罗马化工具，发现它们表现出不同程度的信息丢失，这会影响翻译质量。最后，我们将罗马化扩展到目标端，表明当与简单的去罗马化模型相结合时，这可能是一个成功的策略。</td><td>Chantal Amrhein   Rico Sennrich</td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13781&#39;]">Graph-to-Tree Neural Networks for Learning Structured Input-Output Translation with Applications to Semantic Parsing and Math Word Problem</a></td><td></td><td><a href="https://github.com/IBM/Graph2Tree">https://github.com/IBM/Graph2Tree</a></td><td><a href="https://arxiv.org/pdf/2004.13781">https://arxiv.org/pdf/2004.13781</a></td><td>The celebrated Seq2Seq technique and its numerous variants achieve excellent performance on many tasks such as neural machine translation, semantic parsing, and math word problem solving. However, these models either only consider input objects as sequences while ignoring the important structural information for encoding, or they simply treat output objects as sequence outputs instead of structural objects for decoding. In this paper, we present a novel Graph-to-Tree Neural Networks, namely Graph2Tree consisting of a graph encoder and a hierarchical tree decoder, that encodes an augmented graph-structured input and decodes a tree-structured output. In particular, we investigated our model for solving two problems, neural semantic parsing and math word problem. Our extensive experiments demonstrate that our Graph2Tree model outperforms or matches the performance of other state-of-the-art models on these tasks.</td><td>著名的 Seq2Seq 技术及其众多变体在神经机器翻译、语义解析和数学单词问题解决等许多任务上都取得了出色的表现。然而，这些模型要么只将输入对象视为序列而忽略编码的重要结构信息，要么将输出对象简单地视为序列输出而不是结构对象进行解码。在本文中，我们提出了一种新颖的图到树神经网络，即由图编码器和分层树解码器组成的 Graph2Tree，它对增强的图结构输入进行编码并解码树结构输出。特别是，我们研究了解决两个问题的模型，神经语义解析和数学单词问题。我们广泛的实验表明，我们的 Graph2Tree 模型在这些任务上的表现优于或匹配其他最先进模型的性能。</td><td>Shucheng Li   Lingfei Wu   Shiwei Feng   Fangli Xu   Fengyuan Xu   Sheng Zhong</td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04924&#39;]">On Long-Tailed Phenomena in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/vyraun/long-tailed">https://github.com/vyraun/long-tailed</a></td><td><a href="https://arxiv.org/pdf/2010.04924">https://arxiv.org/pdf/2010.04924</a></td><td>State-of-the-art Neural Machine Translation (NMT) models struggle with generating low-frequency tokens, tackling which remains a major challenge. The analysis of long-tailed phenomena in the context of structured prediction tasks is further hindered by the added complexities of search during inference. In this work, we quantitatively characterize such long-tailed phenomena at two levels of abstraction, namely, token classification and sequence generation. We propose a new loss function, the Anti-Focal loss, to better adapt model training to the structural dependencies of conditional text generation by incorporating the inductive biases of beam search in the training process. We show the efficacy of the proposed technique on a number of Machine Translation (MT) datasets, demonstrating that it leads to significant gains over cross-entropy across different language pairs, especially on the generation of low-frequency words. We have released the code to reproduce our results.</td><td>最先进的神经机器翻译 (NMT) 模型难以生成低频标记，这仍然是一个主要挑战。在结构化预测任务的上下文中对长尾现象的分析进一步受到推理期间搜索复杂性的阻碍。在这项工作中，我们在两个抽象层次上定量描述了这种长尾现象，即标记分类和序列生成。我们提出了一种新的损失函数，即 Anti-Focal 损失，通过在训练过程中结合波束搜索的归纳偏差，更好地使模型训练适应条件文本生成的结构依赖性。我们展示了所提出的技术在许多机器翻译 (MT) 数据集上的有效性，证明它在跨不同语言对的交叉熵上带来了显着的收益，尤其是在低频词的生成方面。我们已经发布了代码来重现我们的结果。</td><td>Vikas Raunak   Siddharth Dalmia   Vivek Gupta   Florian Metze</td></tr><tr><td>8</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.02955&#39;]">A Multilingual View of Unsupervised Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.02955">https://arxiv.org/pdf/2002.02955</a></td><td>We present a probabilistic framework for multilingual neural machine translation that encompasses supervised and unsupervised setups, focusing on unsupervised translation. In addition to studying the vanilla case where there is only monolingual data available, we propose a novel setup where one language in the (source, target) pair is not associated with any parallel data, but there may exist auxiliary parallel data that contains the other. This auxiliary data can naturally be utilized in our probabilistic framework via a novel cross-translation loss term. Empirically, we show that our approach results in higher BLEU scores over state-of-the-art unsupervised models on the WMT’14 English-French, WMT’16 English-German, and WMT’16 English-Romanian datasets in most directions. In particular, we obtain a +1.65 BLEU advantage over the best-performing unsupervised model in the Romanian-English direction.</td><td>我们提出了一个用于多语言神经机器翻译的概率框架，其中包括有监督和无监督设置，重点是无监督翻译。除了研究只有单语数据可用的普通情况外，我们还提出了一种新颖的设置，其中（源、目标）对中的一种语言与任何并行数据无关，但可能存在包含另一种语言的辅助并行数据.通过新的交叉翻译损失项，这些辅助数据可以自然地用于我们的概率框架中。根据经验，我们表明，我们的方法在 WMT’14 English-French、WMT’16 English-German 和 WMT’16 English-Romanian 数据集的大多数方向上比最先进的无监督模型获得更高的 BLEU 分数。特别是，我们在罗马尼亚语-英语方向上获得了优于性能最佳的无监督模型的 +1.65 BLEU 优势。</td><td>Xavier Garcia   Pierre Foret   Thibault Sellam   Ankur P. Parikh</td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.00180&#39;]">Explicit Cross-lingual Pre-training for Unsupervised Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.00180">https://arxiv.org/pdf/1909.00180</a></td><td>Pre-training has proven to be effective in unsupervised machine translation due to its ability to model deep context information in cross-lingual scenarios. However, the cross-lingual information obtained from shared BPE spaces is inexplicit and limited. In this paper, we propose a novel cross-lingual pre-training method for unsupervised machine translation by incorporating explicit cross-lingual training signals. Specifically, we first calculate cross-lingual n-gram embeddings and infer an n-gram translation table from them. With those n-gram translation pairs, we propose a new pre-training model called Cross-lingual Masked Language Model (CMLM), which randomly chooses source n-grams in the input text stream and predicts their translation candidates at each time step. Experiments show that our method can incorporate beneficial cross-lingual information into pre-trained models. Taking pre-trained CMLM models as the encoder and decoder, we significantly improve the performance of unsupervised machine translation.</td><td>预训练已被证明在无监督机器翻译中是有效的，因为它能够在跨语言场景中对深层上下文信息进行建模。然而，从共享 BPE 空间获得的跨语言信息是不明确和有限的。在本文中，我们通过结合明确的跨语言训练信号，提出了一种新的跨语言预训练方法，用于无监督机器翻译。具体来说，我们首先计算跨语言 n-gram 嵌入并从中推断出 n-gram 翻译表。利用这些 n-gram 翻译对，我们提出了一种称为跨语言掩码语言模型 (CMLM) 的新预训练模型，该模型在输入文本流中随机选择源 n-gram 并在每个时间步预测它们的翻译候选。实验表明，我们的方法可以将有益的跨语言信息整合到预先训练的模型中。以预训练的 CMLM 模型作为编码器和解码器，我们显着提高了无监督机器翻译的性能。</td><td>Shuo Ren   Yu Wu   Shujie Liu   Ming Zhou   Shuai Ma</td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.00157&#39;]">Improving Back-Translation with Uncertainty-based Confidence Estimation</a></td><td></td><td><a href="https://github.com/THUNLP-MT/UCE4BT">https://github.com/THUNLP-MT/UCE4BT</a></td><td><a href="https://arxiv.org/pdf/1909.00157">https://arxiv.org/pdf/1909.00157</a></td><td>While back-translation is simple and effective in exploiting abundant monolingual corpora to improve low-resource neural machine translation (NMT), the synthetic bilingual corpora generated by NMT models trained on limited authentic bilingual data are inevitably noisy. In this work, we propose to quantify the confidence of NMT model predictions based on model uncertainty. With word- and sentence-level confidence measures based on uncertainty, it is possible for back-translation to better cope with noise in synthetic bilingual corpora. Experiments on Chinese-English and English-German translation tasks show that uncertainty-based confidence estimation significantly improves the performance of back-translation.</td><td>虽然反向翻译在利用丰富的单语语料库来改进低资源神经机器翻译 (NMT) 方面简单而有效，但由在有限真实双语数据上训练的 NMT 模型生成的合成双语语料库不可避免地存在噪声。在这项工作中，我们建议基于模型不确定性量化 NMT 模型预测的置信度。通过基于不确定性的单词和句子级别的置信度度量，回译可以更好地应对合成双语语料库中的噪声。汉英和英德翻译任务的实验表明，基于不确定性的置信度估计显着提高了回译的性能。</td><td>Shuo Wang   Yang Liu   Chao Wang   Huanbo Luan   Maosong Sun</td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1912.07239&#39;]">Iterative Dual Domain Adaptation for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1912.07239">https://arxiv.org/pdf/1912.07239</a></td><td>Previous studies on the domain adaptation for neural machine translation (NMT) mainly focus on the one-pass transferring out-of-domain translation knowledge to in-domain NMT model. In this paper, we argue that such a strategy fails to fully extract the domain-shared translation knowledge, and repeatedly utilizing corpora of different domains can lead to better distillation of domain-shared translation knowledge. To this end, we propose an iterative dual domain adaptation framework for NMT. Specifically, we first pre-train in-domain and out-of-domain NMT models using their own training corpora respectively, and then iteratively perform bidirectional translation knowledge transfer (from in-domain to out-of-domain and then vice versa) based on knowledge distillation until the in-domain NMT model convergences. Furthermore, we extend the proposed framework to the scenario of multiple out-of-domain training corpora, where the above-mentioned transfer is performed sequentially between the in-domain and each out-of-domain NMT models in the ascending order of their domain similarities. Empirical results on Chinese-English and English-German translation tasks demonstrate the effectiveness of our framework.</td><td>先前关于神经机器翻译（NMT）领域适应的研究主要集中在将域外翻译知识一次性转移到域内 NMT 模型上。在本文中，我们认为这种策略无法完全提取领域共享翻译知识，重复利用不同领域的语料库可以更好地提炼领域共享翻译知识。为此，我们为 NMT 提出了一个迭代双域适应框架。具体来说，我们首先分别使用自己的训练语料对域内和域外 NMT 模型进行预训练，然后迭代执行双向翻译知识转移（从域内到域外，反之亦然）。知识蒸馏，直到域内 NMT 模型收敛。此外，我们将所提出的框架扩展到多个域外训练语料库的场景，其中上述转移是在域内和域外 NMT 模型之间按照域的升序顺序执行的相似之处。汉英和英德翻译任务的实证结果证明了我们框架的有效性。</td><td>Jiali Zeng   Yang Liu   Jinsong Su   Yubin Ge   Yaojie Lu   Yongjing Yin   Jiebo Luo</td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01383&#39;]">Context-Aware Monolingual Repair for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/lena-voita/good-translation-wrong-in-context">https://github.com/lena-voita/good-translation-wrong-in-context</a></td><td><a href="https://arxiv.org/pdf/1909.01383">https://arxiv.org/pdf/1909.01383</a></td><td>Modern sentence-level NMT systems often produce plausible translations of isolated sentences. However, when put in context, these translations may end up being inconsistent with each other. We propose a monolingual DocRepair model to correct inconsistencies between sentence-level translations. DocRepair performs automatic post-editing on a sequence of sentence-level translations, refining translations of sentences in context of each other. For training, the DocRepair model requires only monolingual document-level data in the target language. It is trained as a monolingual sequence-to-sequence model that maps inconsistent groups of sentences into consistent ones. The consistent groups come from the original training data; the inconsistent groups are obtained by sampling round-trip translations for each isolated sentence. We show that this approach successfully imitates inconsistencies we aim to fix: using contrastive evaluation, we show large improvements in the translation of several contextual phenomena in an English-Russian translation task, as well as improvements in the BLEU score. We also conduct a human evaluation and show a strong preference of the annotators to corrected translations over the baseline ones. Moreover, we analyze which discourse phenomena are hard to capture using monolingual data only.</td><td>现代句子级 NMT 系统通常会对孤立的句子产生合理的翻译。然而，当放在上下文中时，这些翻译最终可能会彼此不一致。我们提出了一种单语 DocRepair 模型来纠正句子级翻译之间的不一致。 DocRepair 对一系列句子级翻译执行自动后期编辑，在彼此的上下文中完善句子的翻译。对于训练，DocRepair 模型只需要目标语言的单语文档级数据。它被训练为单语序列到序列模型，将不一致的句子组映射到一致的句子组。一致组来自原始训练数据；不一致的组是通过对每个孤立句子的往返翻译进行采样来获得的。我们表明这种方法成功地模仿了我们旨在解决的不一致问题：使用对比评估，我们在英俄翻译任务中的几种上下文现象的翻译方面取得了很大的改进，以及 BLEU 分数的改进。我们还进行了人工评估，并显示出注释者对更正翻译的强烈偏好，而不是基线翻译。此外，我们分析了仅使用单语数据难以捕捉哪些话语现象。</td><td>Elena Voita   Rico Sennrich   Ivan Titov</td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.09646&#39;]">Dynamic Past and Future for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/zhengzx-nlp/dynamic-nmt">https://github.com/zhengzx-nlp/dynamic-nmt</a></td><td><a href="https://arxiv.org/pdf/1904.09646">https://arxiv.org/pdf/1904.09646</a></td><td>Previous studies have shown that neural machine translation (NMT) models can benefit from explicitly modeling translated (Past) and untranslated (Future) to groups of translated and untranslated contents through parts-to-wholes assignment. The assignment is learned through a novel variant of routing-by-agreement mechanism (Sabour et al., 2017), namely {\em Guided Dynamic Routing}, where the translating status at each decoding step {\em guides} the routing process to assign each source word to its associated group (i.e., translated or untranslated content) represented by a capsule, enabling translation to be made from holistic context. Experiments show that our approach achieves substantial improvements over both RNMT and Transformer by producing more adequate translations. Extensive analysis demonstrates that our method is highly interpretable, which is able to recognize the translated and untranslated contents as expected.</td><td>先前的研究表明，神经机器翻译 (NMT) 模型可以受益于通过部分到整体分配将已翻译（过去）和未翻译（未来）显式建模为已翻译和未翻译内容的组。该分配是通过协议路由机制的一种新变体（Sabour 等人，2017 年）学习的，即 {\em 引导动态路由}，其中每个解码步骤的翻译状态{\em 引导}路由过程到将每个源词分配给由胶囊表示的相关组（即翻译或未翻译的内容），从而能够从整体上下文进行翻译。实验表明，我们的方法通过产生更充分的翻译，在 RNMT 和 Transformer 上取得了实质性的改进。广泛的分析表明，我们的方法具有高度的可解释性，能够按预期识别翻译和未翻译的内容。</td><td>Zaixiang Zheng   Shujian Huang   Zhaopeng Tu   Xin-Yu Dai   Jiajun Chen</td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01559&#39;]">Simpler and Faster Learning of Adaptive Policies for Simultaneous Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.01559">https://arxiv.org/pdf/1909.01559</a></td><td>Simultaneous translation is widely useful but remains challenging. Previous work falls into two main categories: (a) fixed-latency policies such as Ma et al. (2019) and (b) adaptive policies such as Gu et al. (2017). The former are simple and effective, but have to aggressively predict future content due to diverging source-target word order; the latter do not anticipate, but suffer from unstable and inefficient training. To combine the merits of both approaches, we propose a simple supervised-learning framework to learn an adaptive policy from oracle READ/WRITE sequences generated from parallel text. At each step, such an oracle sequence chooses to WRITE the next target word if the available source sentence context provides enough information to do so, otherwise READ the next source word. Experiments on German&lt;-&gt;English show that our method, without retraining the underlying NMT model, can learn flexible policies with better BLEU scores and similar latencies compared to previous work.</td><td>同声传译具有广泛的用途，但仍然具有挑战性。以前的工作分为两大类：（a）固定延迟策略，如 Ma 等人。 (2019) 和 (b) 适应性政策，如 Gu 等人。 (2017)。前者简单有效，但由于源目标词序不同，必须积极预测未来的内容；后者没有预期，而是遭受不稳定和低效的训练。为了结合这两种方法的优点，我们提出了一个简单的监督学习框架，从并行文本生成的 oracle READ/WRITE 序列中学习自适应策略。在每一步，如果可用的源句子上下文提供了足够的信息，这样的预言机序列选择写入下一个目标词，否则读取下一个源词。在德语&lt;-&gt;英语上的实验表明，与之前的工作相比，我们的方法无需重新训练底层 NMT 模型，就可以学习具有更好 BLEU 分数和类似延迟的灵活策略。</td><td>Baigong Zheng   Renjie Zheng   Mingbo Ma   Liang Huang</td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.10430&#39;]">Unsupervised Domain Adaptation for Neural Machine Translation with Domain-Aware Feature Embeddings</a></td><td></td><td><a href="https://github.com/zdou0830/DAFE">https://github.com/zdou0830/DAFE</a></td><td><a href="https://arxiv.org/pdf/1908.10430">https://arxiv.org/pdf/1908.10430</a></td><td>The recent success of neural machine translation models relies on the availability of high quality, in-domain data. Domain adaptation is required when domain-specific data is scarce or nonexistent. Previous unsupervised domain adaptation strategies include training the model with in-domain copied monolingual or back-translated data. However, these methods use generic representations for text regardless of domain shift, which makes it infeasible for translation models to control outputs conditional on a specific domain. In this work, we propose an approach that adapts models with domain-aware feature embeddings, which are learned via an auxiliary language modeling task. Our approach allows the model to assign domain-specific representations to words and output sentences in the desired domain. Our empirical results demonstrate the effectiveness of the proposed strategy, achieving consistent improvements in multiple experimental settings. In addition, we show that combining our method with back translation can further improve the performance of the model.</td><td>最近神经机器翻译模型的成功依赖于高质量域内数据的可用性。当特定于域的数据稀缺或不存在时，需要域自适应。以前的无监督域适应策略包括使用域内复制的单语或反向翻译数据训练模型。然而，这些方法使用文本的通用表示而不考虑域转移，这使得翻译模型无法控制以特定域为条件的输出。在这项工作中，我们提出了一种方法，该方法可以通过辅助语言建模任务学习具有领域感知特征嵌入的模型。我们的方法允许模型将特定于域的表示分配给所需域中的单词和输出句子。我们的实证结果证明了所提出策略的有效性，在多个实验环境中实现了一致的改进。此外，我们表明将我们的方法与反向翻译相结合可以进一步提高模型的性能。</td><td>Zi-Yi Dou   Junjie Hu   Antonios Anastasopoulos   Graham Neubig</td></tr><tr><td>16</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1911.00835&#39;]">Controlling Text Complexity in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/sweta20/ComplexityControlledMT">https://github.com/sweta20/ComplexityControlledMT</a></td><td><a href="https://arxiv.org/pdf/1911.00835">https://arxiv.org/pdf/1911.00835</a></td><td>This work introduces a machine translation task where the output is aimed at audiences of different levels of target language proficiency. We collect a high quality dataset of news articles available in English and Spanish, written for diverse grade levels and propose a method to align segments across comparable bilingual articles. The resulting dataset makes it possible to train multi-task sequence-to-sequence models that translate Spanish into English targeted at an easier reading grade level than the original Spanish. We show that these multi-task models outperform pipeline approaches that translate and simplify text independently.</td><td>这项工作引入了机器翻译任务，其中输出针对不同目标语言水平的受众。我们收集了一个高质量的英语和西班牙语新闻文章数据集，为不同年级编写，并提出了一种方法来对齐可比双语文章中的片段。由此产生的数据集可以训练多任务序列到序列模型，将西班牙语翻译成英语，目标是比原始西班牙语更容易阅读。我们表明，这些多任务模型优于独立翻译和简化文本的管道方法。</td><td>Sweta Agrawal   Marine Carpuat</td></tr><tr><td>17</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.05731&#39;]">Simple and Effective Noisy Channel Modeling for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></td><td><a href="https://arxiv.org/pdf/1908.05731">https://arxiv.org/pdf/1908.05731</a></td><td>Previous work on neural noisy channel modeling relied on latent variable models that incrementally process the source and target sentence. This makes decoding decisions based on partial source prefixes even though the full source is available. We pursue an alternative approach based on standard sequence to sequence models which utilize the entire source. These models perform remarkably well as channel models, even though they have neither been trained on, nor designed to factor over incomplete target sentences. Experiments with neural language models trained on billions of words show that noisy channel models can outperform a direct model by up to 3.2 BLEU on WMT’17 German-English translation. We evaluate on four language-pairs and our channel models consistently outperform strong alternatives such right-to-left reranking models and ensembles of direct models.</td><td>先前关于神经噪声通道建模的工作依赖于增量处理源语句和目标语句的潜在变量模型。即使完整源可用，这也会基于部分源前缀做出解码决策。我们寻求一种基于标准序列到序列模型的替代方法，该模型利用整个源。这些模型作为通道模型的表现非常好，即使它们既没有接受过训练，也没有被设计为考虑不完整的目标句子。在数十亿单词上训练的神经语言模型的实验表明，在 WMT’17 德英翻译中，噪声通道模型的性能比直接模型高 3.2 BLEU。我们对四个语言对进行评估，我们的通道模型始终优于强大的替代方案，例如从右到左的重新排序模型和直接模型的集合。</td><td>Kyra Yee   Nathan Ng   Yann N. Dauphin   Michael Auli</td></tr><tr><td>18</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.06708&#39;]">Hint-Based Training for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/zhuohan123/hint-nart">https://github.com/zhuohan123/hint-nart</a></td><td><a href="https://arxiv.org/pdf/1909.06708">https://arxiv.org/pdf/1909.06708</a></td><td>Due to the unparallelizable nature of the autoregressive factorization, AutoRegressive Translation (ART) models have to generate tokens sequentially during decoding and thus suffer from high inference latency. Non-AutoRegressive Translation (NART) models were proposed to reduce the inference time, but could only achieve inferior translation accuracy. In this paper, we proposed a novel approach to leveraging the hints from hidden states and word alignments to help the training of NART models. The results achieve significant improvement over previous NART models for the WMT14 En-De and De-En datasets and are even comparable to a strong LSTM-based ART baseline but one order of magnitude faster in inference.</td><td>由于自回归分解的无与伦比的性质，自回归翻译 (ART) 模型必须在解码期间按顺序生成令牌，因此会遭受高推理延迟。提出了非自回归翻译 (NART) 模型以减少推理时间，但只能实现较差的翻译准确度。在本文中，我们提出了一种利用隐藏状态和词对齐的提示来帮助训练 NART 模型的新方法。与 WMT14 En-De 和 De-En 数据集的先前 NART 模型相比，结果实现了显着改进，甚至可与基于 LSTM 的强大 ART 基线相媲美，但推理速度快了一个数量级。</td><td>Zhuohan Li   Zi Lin   Di He   Fei Tian   Tao Qin   Liwei Wang   Tie-Yan Liu</td></tr></tbody></table></div><h3 id="NAACL"><a href="#NAACL" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.04507&#39;]">Self-Training for Unsupervised Neural Machine Translation in Unbalanced Training Data Scenarios</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.04507">https://arxiv.org/pdf/2004.04507</a></td><td>Unsupervised neural machine translation (UNMT) that relies solely on massive monolingual corpora has achieved remarkable results in several translation tasks. However, in real-world scenarios, massive monolingual corpora do not exist for some extremely low-resource languages such as Estonian, and UNMT systems usually perform poorly when there is not adequate training corpus for one language. In this paper, we first define and analyze the unbalanced training data scenario for UNMT. Based on this scenario, we propose UNMT self-training mechanisms to train a robust UNMT system and improve its performance in this case. Experimental results on several language pairs show that the proposed methods substantially outperform conventional UNMT systems.</td><td>仅依赖海量单语语料库的无监督神经机器翻译 (UNMT) 在多项翻译任务中取得了显著成果。然而，在现实世界的场景中，对于一些资源极少的语言（例如爱沙尼亚语），不存在大量的单语语料库，并且当一种语言没有足够的训练语料库时，UNMT 系统通常表现不佳。在本文中，我们首先定义和分析了 UNMT 的不平衡训练数据场景。基于这种情况，我们提出了 UNMT 自训练机制来训练一个强大的 UNMT 系统并在这种情况下提高其性能。在几个语言对上的实验结果表明，所提出的方法大大优于传统的 UNMT 系统。</td><td>Haipeng Sun   Rui Wang   Kehai Chen   Masao Utiyama   Eiichiro Sumita   Tiejun Zhao</td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2009.11201&#39;]">Harnessing Multilinguality in Unsupervised Machine Translation for Rare Languages</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.11201">https://arxiv.org/pdf/2009.11201</a></td><td>Unsupervised translation has reached impressive performance on resource-rich language pairs such as English-French and English-German. However, early studies have shown that in more realistic settings involving low-resource, rare languages, unsupervised translation performs poorly, achieving less than 3.0 BLEU. In this work, we show that multilinguality is critical to making unsupervised systems practical for low-resource settings. In particular, we present a single model for 5 low-resource languages (Gujarati, Kazakh, Nepali, Sinhala, and Turkish) to and from English directions, which leverages monolingual and auxiliary parallel data from other high-resource language pairs via a three-stage training scheme. We outperform all current state-of-the-art unsupervised baselines for these languages, achieving gains of up to 14.4 BLEU. Additionally, we outperform a large collection of supervised WMT submissions for various language pairs as well as match the performance of the current state-of-the-art supervised model for Nepali-English. We conduct a series of ablation studies to establish the robustness of our model under different degrees of data quality, as well as to analyze the factors which led to the superior performance of the proposed approach over traditional unsupervised models.</td><td>无监督翻译在英语-法语和英语-德语等资源丰富的语言对上取得了令人瞩目的表现。然而，早期研究表明，在涉及资源匮乏、稀有语言的更现实环境中，无监督翻译表现不佳，达到 3.0 BLEU 以下。在这项工作中，我们表明多语言对于使无监督系统适用于低资源环境至关重要。特别是，我们为 5 种低资源语言（古吉拉特语、哈萨克语、尼泊尔语、僧伽罗语和土耳其语）与英语方向之间提供了一个单一模型，该模型利用来自其他高资源语言对的单语和辅助并行数据，通过三个-阶段训练计划。我们优于这些语言的所有当前最先进的无监督基线，实现了高达 14.4 BLEU 的增益。此外，我们在各种语言对的监督 WMT 提交中表现出色，并且与当前最先进的尼泊尔语-英语监督模型的性能相匹配。我们进行了一系列消融研究，以建立我们模型在不同数据质量程度下的稳健性，并分析导致所提出方法优于传统无监督模型的因素。</td><td>Xavier Garcia   Aditya Siddhant   Orhan Firat   Ankur P. Parikh</td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.06799&#39;]">Towards Continual Learning for Multilingual Machine Translation via Vocabulary Substitution</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2103.06799">https://arxiv.org/pdf/2103.06799</a></td><td>We propose a straightforward vocabulary adaptation scheme to extend the language capacity of multilingual machine translation models, paving the way towards efficient continual learning for multilingual machine translation. Our approach is suitable for large-scale datasets, applies to distant languages with unseen scripts, incurs only minor degradation on the translation performance for the original language pairs and provides competitive performance even in the case where we only possess monolingual data for the new languages.</td><td>我们提出了一种简单的词汇适应方案来扩展多语言机器翻译模型的语言能力，为多语言机器翻译的高效持续学习铺平道路。我们的方法适用于大规模数据集，适用于具有看不见的脚本的远程语言，对原始语言对的翻译性能仅造成轻微的下降，并且即使在我们仅拥有新语言的单语数据的情况下也能提供有竞争力的性能。</td><td>Xavier Garcia   Noah Constant   Ankur P. Parikh   Orhan Firat</td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2003.09586&#39;]">Probing Word Translations in the Transformer and Trading Decoder for Encoder Layers</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2003.09586">https://arxiv.org/pdf/2003.09586</a></td><td>Due to its effectiveness and performance, the Transformer translation model has attracted wide attention, most recently in terms of probing-based approaches. Previous work focuses on using or probing source linguistic features in the encoder. To date, the way word translation evolves in Transformer layers has not yet been investigated. Naively, one might assume that encoder layers capture source information while decoder layers translate. In this work, we show that this is not quite the case: translation already happens progressively in encoder layers and even in the input embeddings. More surprisingly, we find that some of the lower decoder layers do not actually do that much decoding. We show all of this in terms of a probing approach where we project representations of the layer analyzed to the final trained and frozen classifier level of the Transformer decoder to measure word translation accuracy. Our findings motivate and explain a Transformer configuration change: if translation already happens in the encoder layers, perhaps we can increase the number of encoder layers, while decreasing the number of decoder layers, boosting decoding speed, without loss in translation quality? Our experiments show that this is indeed the case: we can increase speed by up to a factor 2.3 with small gains in translation quality, while an 18-4 deep encoder configuration boosts translation quality by +1.42 BLEU (En-De) at a speed-up of 1.4.</td><td>由于其有效性和性能，Transformer 翻译模型引起了广泛关注，最近在基于探测的方法方面。以前的工作侧重于在编码器中使用或探测源语言特征。迄今为止，尚未研究单词翻译在 Transformer 层中的演变方式。天真地，人们可能会假设编码器层在解码器层转换时捕获源信息。在这项工作中，我们表明情况并非如此：翻译已经在编码器层甚至输入嵌入中逐步发生。更令人惊讶的是，我们发现一些较低的解码器层实际上并没有做那么多解码。我们以探测方法展示了所有这些，其中我们将分析的层的表示投影到 Transformer 解码器的最终训练和冻结分类器级别，以测量单词翻译的准确性。我们的发现激发并解释了 Transformer 配置的变化：如果翻译已经发生在编码器层，也许我们可以增加编码器层的数量，同时减少解码器层的数量，提高解码速度，而不损失翻译质量？我们的实验表明情况确实如此：我们可以将速度提高 2.3 倍，而翻译质量的提高很小，而 18-4 深度编码器配置以 +1.42 BLEU (En-De) 的速度将翻译质量提高- 1.4。</td><td>Hongfei Xu   Josef van Genabith   Qiuhui Liu   Deyi Xiong</td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.06490&#39;, &#39;https://arxiv.org/abs/1911.00234&#39;]">Sequence Tagging and Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1911.00234">https://arxiv.org/pdf/1911.00234</a></td><td>While deep learning is a powerful tool for natural language processing (NLP) problems, successful solutions to these problems rely heavily on large amounts of annotated samples. However, manually annotating data is expensive and time-consuming. Active Learning (AL) strategies reduce the need for huge volumes of labeled data by iteratively selecting a small number of examples for manual annotation based on their estimated utility in training the given model. In this paper, we argue that since AL strategies choose examples independently, they may potentially select similar examples, all of which may not contribute significantly to the learning process. Our proposed approach, Active$\mathbf{^2}$ Learning (A$\mathbf{^2}$L), actively adapts to the deep learning model being trained to eliminate further such redundant examples chosen by an AL strategy. We show that A$\mathbf{^2}$L is widely applicable by using it in conjunction with several different AL strategies and NLP tasks. We empirically demonstrate that the proposed approach is further able to reduce the data requirements of state-of-the-art AL strategies by an absolute percentage reduction of $\approx\mathbf{3-25\%}$ on multiple NLP tasks while achieving the same performance with no additional computation overhead.</td><td>虽然深度学习是解决自然语言处理 (NLP) 问题的强大工具，但这些问题的成功解决方案在很大程度上依赖于大量带注释的样本。但是，手动注释数据既昂贵又耗时。主动学习 (AL) 策略通过迭代选择少量示例进行手动注释，基于它们在训练给定模型中的估计效用，减少了对大量标记数据的需求。在本文中，我们认为由于 AL 策略独立选择示例，它们可能会选择相似的示例，所有这些示例可能对学习过程没有显着贡献。我们提出的方法 Active$\mathbf{^2}$ Learning (A$\mathbf{^2}$L) 主动适应正在训练的深度学习模型，以进一步消除 AL 策略选择的此类冗余示例。我们通过将 A$\mathbf{^2}$L 与几种不同的 AL 策略和 NLP 任务结合使用，表明它具有广泛的适用性。我们凭经验证明，所提出的方法能够通过在多个 NLP 任务上减少 $\approx\mathbf{3-25\%}$ 的绝对百分比来进一步降低最先进的 AL 策略的数据需求，同时实现相同的性能，没有额外的计算开销。</td><td>Rishi Hazra   Parag Dutta   Shubham Gupta   Mohammed Abdul Qaathir   Ambedkar Dukkipati   Rishi Hazra   Parag Dutta   Shubham Gupta   Mohammed Abdul Qaathir   Ambedkar Dukkipati</td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2008.09396&#39;]">Neural Machine Translation without Embeddings</a></td><td></td><td><a href="https://github.com/UriSha/EmbeddinglessNMT">https://github.com/UriSha/EmbeddinglessNMT</a></td><td><a href="https://arxiv.org/pdf/2008.09396">https://arxiv.org/pdf/2008.09396</a></td><td>Many NLP models operate over sequences of subword tokens produced by hand-crafted tokenization rules and heuristic subword induction algorithms. A simple universal alternative is to represent every computerized text as a sequence of bytes via UTF-8, obviating the need for an embedding layer since there are fewer token types (256) than dimensions. Surprisingly, replacing the ubiquitous embedding layer with one-hot representations of each byte does not hurt performance; experiments on byte-to-byte machine translation from English to 10 different languages show a consistent improvement in BLEU, rivaling character-level and even standard subword-level models. A deeper investigation reveals that the combination of embeddingless models with decoder-input dropout amounts to token dropout, which benefits byte-to-byte models in particular.</td><td></td><td>Uri Shaham   Omer Levy</td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.07316&#39;]">From Masked Language Modeling to Translation: Non-English Auxiliary Tasks Improve Zero-shot Spoken Language Understanding</a></td><td></td><td><a href="https://bitbucket.org/robvanderg/xsid">https://bitbucket.org/robvanderg/xsid</a></td><td><a href="https://arxiv.org/pdf/2105.07316">https://arxiv.org/pdf/2105.07316</a></td><td>The lack of publicly available evaluation data for low-resource languages limits progress in Spoken Language Understanding (SLU). As key tasks like intent classification and slot filling require abundant training data, it is desirable to reuse existing data in high-resource languages to develop models for low-resource scenarios. We introduce xSID, a new benchmark for cross-lingual Slot and Intent Detection in 13 languages from 6 language families, including a very low-resource dialect. To tackle the challenge, we propose a joint learning approach, with English SLU training data and non-English auxiliary tasks from raw text, syntax and translation for transfer. We study two setups which differ by type and language coverage of the pre-trained embeddings. Our results show that jointly learning the main tasks with masked language modeling is effective for slots, while machine translation transfer works best for intent classification.</td><td>缺乏对低资源语言的公开评估数据限制了口语理解 (SLU) 的进展。由于意图分类和槽填充等关键任务需要大量的训练数据，因此需要重用高资源语言的现有数据来开发低资源场景的模型。我们引入了 xSID，这是一种跨语言槽和意图检测的新基准，用于 6 个语言家族的 13 种语言，包括资源非常少的方言。为了应对这一挑战，我们提出了一种联合学习方法，使用英语 SLU 训练数据和来自原始文本、语法和翻译的非英语辅助任务进行迁移。我们研究了两种不同的设置，它们因预训练嵌入的类型和语言覆盖范围而异。我们的结果表明，使用掩码语言建模联合学习主要任务对槽有效，而机器翻译迁移最适合意图分类。</td><td>Rob van der Goot   Ibrahim Sharaf   Aizhan Imankulova   Ahmet Üstün   Marija Stepanović   Alan Ramponi   Siti Oryza Khairunnisa   Mamoru Komachi   Barbara Plank</td></tr><tr><td>8</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.10531&#39;]">Improving the Lexical Ability of Pretrained Language Models for Unsupervised Neural Machine Translation</a></td><td></td><td><a href="https://github.com/alexandra-chron/lexical_xlm_relm">https://github.com/alexandra-chron/lexical_xlm_relm</a></td><td><a href="https://arxiv.org/pdf/2103.10531">https://arxiv.org/pdf/2103.10531</a></td><td>Successful methods for unsupervised neural machine translation (UNMT) employ crosslingual pretraining via self-supervision, often in the form of a masked language modeling or a sequence generation task, which requires the model to align the lexical- and high-level representations of the two languages. While cross-lingual pretraining works for similar languages with abundant corpora, it performs poorly in low-resource and distant languages. Previous research has shown that this is because the representations are not sufficiently aligned. In this paper, we enhance the bilingual masked language model pretraining with lexical-level information by using type-level cross-lingual subword embeddings. Empirical results demonstrate improved performance both on UNMT (up to 4.5 BLEU) and bilingual lexicon induction using our method compared to a UNMT baseline.</td><td>无监督神经机器翻译 (UNMT) 的成功方法通过自我监督采用跨语言预训练，通常采用掩码语言建模或序列生成任务的形式，这需要模型对齐两者的词汇和高级表示语言。虽然跨语言预训练适用于具有丰富语料库的相似语言，但它在资源匮乏和距离较远的语言中表现不佳。先前的研究表明，这是因为表示没有充分对齐。在本文中，我们通过使用类型级别的跨语言子词嵌入来增强具有词汇级别信息的双语掩码语言模型预训练。实证结果表明，与 UNMT 基线相比，使用我们的方法在 UNMT（高达 4.5 BLEU）和双语词典归纳方面的性能都有所提高。</td><td>Alexandra Chronopoulou   Dario Stojanovski   Alexander Fraser</td></tr><tr><td>9</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12868&#39;]">Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine Translation</a></td><td></td><td><a href="https://github.com/yongchanghao/multi-task-nat">https://github.com/yongchanghao/multi-task-nat</a></td><td><a href="https://arxiv.org/pdf/2010.12868">https://arxiv.org/pdf/2010.12868</a></td><td>Non-Autoregressive machine Translation (NAT) models have demonstrated significant inference speedup but suffer from inferior translation accuracy. The common practice to tackle the problem is transferring the Autoregressive machine Translation (AT) knowledge to NAT models, e.g., with knowledge distillation. In this work, we hypothesize and empirically verify that AT and NAT encoders capture different linguistic properties of source sentences. Therefore, we propose to adopt Multi-Task learning to transfer the AT knowledge to NAT models through encoder sharing. Specifically, we take the AT model as an auxiliary task to enhance NAT model performance. Experimental results on WMT14 English-German and WMT16 English-Romanian datasets show that the proposed Multi-Task NAT achieves significant improvements over the baseline NAT models. Furthermore, the performance on large-scale WMT19 and WMT20 English-German datasets confirm the consistency of our proposed method. In addition, experimental results demonstrate that our Multi-Task NAT is complementary to knowledge distillation, the standard knowledge transfer method for NAT.</td><td>非自回归机器翻译 (NAT) 模型已经证明了显着的推理加速，但翻译准确性较差。解决该问题的常见做法是将自回归机器翻译 (AT) 知识转移到 NAT 模型，例如，通过知识蒸馏。在这项工作中，我们假设并凭经验验证 AT 和 NAT 编码器捕获源句子的不同语言属性。因此，我们建议采用多任务学习，通过编码器共享将 AT 知识转移到 NAT 模型。具体来说，我们将 AT 模型作为辅助任务来增强 NAT 模型的性能。 WMT14 English-German 和 WMT16 English-Romanian 数据集的实验结果表明，所提出的多任务 NAT 比基线 NAT 模型取得了显着的改进。此外，大规模 WMT19 和 WMT20 英德数据集的性能证实了我们提出的方法的一致性。此外，实验结果表明，我们的多任务 NAT 是知识蒸馏的补充，这是 NAT 的标准知识转移方法。</td><td>Yongchang Hao   Shilin He   Wenxiang Jiao   Zhaopeng Tu   Michael Lyu   Xing Wang</td></tr><tr><td>10</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05146&#39;]">Assessing Reference-Free Peer Evaluation for Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.05146">https://arxiv.org/pdf/2104.05146</a></td><td>Reference-free evaluation has the potential to make machine translation evaluation substantially more scalable, allowing us to pivot easily to new languages or domains. It has been recently shown that the probabilities given by a large, multilingual model can achieve state of the art results when used as a reference-free metric. We experiment with various modifications to this model and demonstrate that by scaling it up we can match the performance of BLEU. We analyze various potential weaknesses of the approach and find that it is surprisingly robust and likely to offer reasonable performance across a broad spectrum of domains and different system qualities.</td><td></td><td>Sweta Agrawal   George Foster   Markus Freitag   Colin Cherry</td></tr><tr><td>11</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2009.09654&#39;]">Generative Imagination Elevates Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.09654">https://arxiv.org/pdf/2009.09654</a></td><td>There are common semantics shared across text and images. Given a sentence in a source language, whether depicting the visual scene helps translation into a target language? Existing multimodal neural machine translation methods (MNMT) require triplets of bilingual sentence - image for training and tuples of source sentence - image for inference. In this paper, we propose ImagiT, a novel machine translation method via visual imagination. ImagiT first learns to generate visual representation from the source sentence, and then utilizes both source sentence and the “imagined representation” to produce a target translation. Unlike previous methods, it only needs the source sentence at the inference time. Experiments demonstrate that ImagiT benefits from visual imagination and significantly outperforms the text-only neural machine translation baselines. Further analysis reveals that the imagination process in ImagiT helps fill in missing information when performing the degradation strategy.</td><td>文本和图像之间共享通用语义。给定一个源语言的句子，描绘视觉场景是否有助于翻译成目标语言？现有的多模态神经机器翻译方法 (MNMT) 需要双语句子的三元组 - 用于训练的图像和用于推理的源句元组 - 图像。在本文中，我们提出了 ImagiT，一种通过视觉想象的新型机器翻译方法。 ImagiT 首先学习从源句生成视觉表示，然后利用源句和“想象的表示”来生成目标翻译。与以前的方法不同，它只需要推理时的源语句。实验表明，ImagiT 受益于视觉想象力，并显着优于纯文本神经机器翻译基线。进一步的分析表明，在执行退化策略时，ImagiT 中的想象过程有助于填补缺失的信息。</td><td>Quanyu Long   Mingxuan Wang   Lei Li</td></tr><tr><td>12</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12827&#39;]">Context-aware Decoder for Neural Machine Translation using a Target-side Document-Level Language Model</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12827">https://arxiv.org/pdf/2010.12827</a></td><td>Although many context-aware neural machine translation models have been proposed to incorporate contexts in translation, most of those models are trained end-to-end on parallel documents aligned in sentence-level. Because only a few domains (and language pairs) have such document-level parallel data, we cannot perform accurate context-aware translation in most domains. We therefore present a simple method to turn a sentence-level translation model into a context-aware model by incorporating a document-level language model into the decoder. Our context-aware decoder is built upon only a sentence-level parallel corpora and monolingual corpora; thus no document-level parallel data is needed. In a theoretical viewpoint, the core part of this work is the novel representation of contextual information using point-wise mutual information between context and the current sentence. We show the effectiveness of our approach in three language pairs, English to French, English to Russian, and Japanese to English, by evaluation in \textsc{bleu} and contrastive tests for context-aware translation.</td><td>尽管已经提出了许多上下文感知神经机器翻译模型来将上下文结合到翻译中，但这些模型中的大多数都是在句子级别对齐的并行文档上进行端到端训练的。因为只有少数域（和语言对）有这样的文档级并行数据，我们无法在大多数域中执行准确的上下文感知翻译。因此，我们提出了一种简单的方法，通过将文档级语言模型合并到解码器中，将句子级翻译模型转变为上下文感知模型。我们的上下文感知解码器仅建立在句子级平行语料库和单语语料库上；因此不需要文档级并行数据。从理论的角度来看，这项工作的核心部分是使用上下文和当前句子之间的逐点互信息对上下文信息进行新颖的表示。我们通过 \textsc{bleu} 中的评估和上下文感知翻译的对比测试，展示了我们的方法在英语到法语、英语到俄语和日语到英语这三种语言对中的有效性。</td><td>Amane Sugiyama   Naoki Yoshinaga</td></tr><tr><td>13</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05964&#39;]">Restoring and Mining the Records of the Joseon Dynasty via Neural Language Modeling and Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.05964">https://arxiv.org/pdf/2104.05964</a></td><td>Understanding voluminous historical records provides clues on the past in various aspects, such as social and political issues and even natural science facts. However, it is generally difficult to fully utilize the historical records, since most of the documents are not written in a modern language and part of the contents are damaged over time. As a result, restoring the damaged or unrecognizable parts as well as translating the records into modern languages are crucial tasks. In response, we present a multi-task learning approach to restore and translate historical documents based on a self-attention mechanism, specifically utilizing two Korean historical records, ones of the most voluminous historical records in the world. Experimental results show that our approach significantly improves the accuracy of the translation task than baselines without multi-task learning. In addition, we present an in-depth exploratory analysis on our translated results via topic modeling, uncovering several significant historical events.</td><td>了解大量的历史记录可以从各个方面提供有关过去的线索，例如社会和政治问题，甚至自然科学事实。然而，要充分利用历史记录，一般来说是困难的，因为大多数文件不是用现代语言写成的，部分内容随着时间的推移而损坏。因此，修复损坏或无法识别的部分以及将记录翻译成现代语言是至关重要的任务。作为回应，我们提出了一种基于自注意力机制的多任务学习方法来恢复和翻译历史文献，特别是利用了两个韩国历史记录，这是世界上最丰富的历史记录。实验结果表明，与没有多任务学习的基线相比，我们的方法显着提高了翻译任务的准确性。此外，我们通过主题建模对我们的翻译结果进行了深入的探索性分析，揭示了几个重要的历史事件。</td><td>Kyeongpil Kang   Kyohoon Jin   Soyoung Yang   Sujin Jang   Jaegul Choo   Youngbin Kim</td></tr><tr><td>14</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.06683&#39;]">The Curious Case of Hallucinations in Neural Machine Translation</a></td><td></td><td><a href="https://github.com/vyraun/hallucinations">https://github.com/vyraun/hallucinations</a></td><td><a href="https://arxiv.org/pdf/2104.06683">https://arxiv.org/pdf/2104.06683</a></td><td>In this work, we study hallucinations in Neural Machine Translation (NMT), which lie at an extreme end on the spectrum of NMT pathologies. Firstly, we connect the phenomenon of hallucinations under source perturbation to the Long-Tail theory of Feldman (2020), and present an empirically validated hypothesis that explains hallucinations under source perturbation. Secondly, we consider hallucinations under corpus-level noise (without any source perturbation) and demonstrate that two prominent types of natural hallucinations (detached and oscillatory outputs) could be generated and explained through specific corpus-level noise patterns. Finally, we elucidate the phenomenon of hallucination amplification in popular data-generation processes such as Backtranslation and sequence-level Knowledge Distillation.</td><td>在这项工作中，我们研究了神经机器翻译 (NMT) 中的幻觉，它处于 NMT 病理范围的极端。首先，我们将源扰动下的幻觉现象与 Feldman (2020) 的长尾理论联系起来，并提出了一个经过实证验证的假设来解释源扰动下的幻觉。其次，我们考虑了语料库级别噪声（没有任何源扰动）下的幻觉，并证明可以通过特定的语料库级别噪声模式生成和解释两种主要类型的自然幻觉（分离输出和振荡输出）。最后，我们阐明了流行的数据生成过程（例如反向翻译和序列级知识蒸馏）中的幻觉放大现象。</td><td>Vikas Raunak   Arul Menezes   Marcin Junczys-Dowmunt</td></tr><tr><td>15</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.08942&#39;]">Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/samuki/reinforce-joey">https://github.com/samuki/reinforce-joey</a></td><td><a href="https://arxiv.org/pdf/2106.08942">https://arxiv.org/pdf/2106.08942</a></td><td>Policy gradient algorithms have found wide adoption in NLP, but have recently become subject to criticism, doubting their suitability for NMT. Choshen et al. (2020) identify multiple weaknesses and suspect that their success is determined by the shape of output distributions rather than the reward. In this paper, we revisit these claims and study them under a wider range of configurations. Our experiments on in-domain and cross-domain adaptation reveal the importance of exploration and reward scaling, and provide empirical counter-evidence to these claims.</td><td>策略梯度算法在 NLP 中被广泛采用，但最近受到批评，怀疑它们是否适用于 NMT。 Choshen 等人。 (2020) 确定了多个弱点，并怀疑它们的成功取决于输出分布的形状而不是奖励。在本文中，我们重新审视这些主张并在更广泛的配置下研究它们。我们对域内和跨域适应的实验揭示了探索和奖励缩放的重要性，并为这些主张提供了实证反证。</td><td>Samuel Kiegeland   Julia Kreutzer</td></tr><tr><td>16</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.03137&#39;]">Cross-lingual Supervision Improves Unsupervised Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.03137">https://arxiv.org/pdf/2004.03137</a></td><td>Neural machine translation~(NMT) is ineffective for zero-resource languages. Recent works exploring the possibility of unsupervised neural machine translation (UNMT) with only monolingual data can achieve promising results. However, there are still big gaps between UNMT and NMT with parallel supervision. In this work, we introduce a multilingual unsupervised NMT (\method) framework to leverage weakly supervised signals from high-resource language pairs to zero-resource translation directions. More specifically, for unsupervised language pairs \texttt{En-De}, we can make full use of the information from parallel dataset \texttt{En-Fr} to jointly train the unsupervised translation directions all in one model. \method is based on multilingual models which require no changes to the standard unsupervised NMT. Empirical results demonstrate that \method significantly improves the translation quality by more than 3 BLEU score on six benchmark unsupervised translation directions.</td><td>神经机器翻译~（NMT）对零资源语言无效。最近探索仅使用单语数据进行无监督神经机器翻译 (UNMT) 的可能性的工作可以获得有希望的结果。然而，并行监督的UNMT和NMT之间仍然存在很大差距。在这项工作中，我们引入了一种多语言无监督 NMT（\method）框架，以利用来自高资源语言对的弱监督信号到零资源翻译方向。更具体地说，对于无监督语言对 \texttt{En-De}，我们可以充分利用来自并行数据集 \texttt{En-Fr} 的信息，在一个模型中联合训练无监督翻译方向。 \method 基于多语言模型，无需更改标准的无监督 NMT。实证结果表明，\method 在六个基准无监督翻译方向上显着提高了超过 3 BLEU 分数的翻译质量。</td><td>Mingxuan Wang   Hongxiao Bai   Hai Zhao   Lei Li</td></tr><tr><td>17</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.02461&#39;]">ReWE: Regressing Word Embeddings for Regularization of Neural Machine Translation Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.02461">https://arxiv.org/pdf/1904.02461</a></td><td>Regularization of neural machine translation is still a significant problem, especially in low-resource settings. To mollify this problem, we propose regressing word embeddings (ReWE) as a new regularization technique in a system that is jointly trained to predict the next word in the translation (categorical value) and its word embedding (continuous value). Such a joint training allows the proposed system to learn the distributional properties represented by the word embeddings, empirically improving the generalization to unseen sentences. Experiments over three translation datasets have showed a consistent improvement over a strong baseline, ranging between 0.91 and 2.54 BLEU points, and also a marked improvement over a state-of-the-art system.</td><td>神经机器翻译的正则化仍然是一个重大问题，尤其是在资源匮乏的环境中。为了解决这个问题，我们提出回归词嵌入 (ReWE) 作为一种新的正则化技术，该系统经过联合训练以预测翻译中的下一个词（分类值）及其词嵌入（连续值）。这种联合训练允许所提出的系统学习由词嵌入表示的分布特性，从经验上改进对看不见的句子的泛化。在三个翻译数据集上的实验表明，在强大的基线上有持续的改进，范围在 0.91 到 2.54 BLEU 点之间，并且比最先进的系统也有显着的改进。</td><td>Inigo Jauregi Unanue   Ehsan Zare Borzeshi   Nazanin Esmaili   Massimo Piccardi</td></tr><tr><td>18</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09514&#39;]">Lost in Machine Translation: A Method to Reduce Meaning Loss</a></td><td></td><td><a href="https://github.com/reubenharry/pragmatic-translation">https://github.com/reubenharry/pragmatic-translation</a></td><td><a href="https://arxiv.org/pdf/1902.09514">https://arxiv.org/pdf/1902.09514</a></td><td>A desideratum of high-quality translation systems is that they preserve meaning, in the sense that two sentences with different meanings should not translate to one and the same sentence in another language. However, state-of-the-art systems often fail in this regard, particularly in cases where the source and target languages partition the “meaning space” in different ways. For instance, “I cut my finger.” and “I cut my finger off.” describe different states of the world but are translated to French (by both Fairseq and Google Translate) as “Je me suis coupe le doigt.”, which is ambiguous as to whether the finger is detached. More generally, translation systems are typically many-to-one (non-injective) functions from source to target language, which in many cases results in important distinctions in meaning being lost in translation. Building on Bayesian models of informative utterance production, we present a method to define a less ambiguous translation system in terms of an underlying pre-trained neural sequence-to-sequence model. This method increases injectivity, resulting in greater preservation of meaning as measured by improvement in cycle-consistency, without impeding translation quality (measured by BLEU score).</td><td>高质量翻译系统的一个必要条件是它们能够保留意义，也就是说，两个意义不同的句子不应翻译成另一种语言的同一个句子。然而，最先进的系统在这方面经常失败，特别是在源语言和目标语言以不同方式划分“意义空间”的情况下。例如，“我割破了手指”。和“我切掉了我的手指。”描述世界的不同状态，但被翻译成法语（由 Fairseq 和谷歌翻译）为“Je me suis coupe le doigt.”，对于手指是否分离是模棱两可的。更一般地说，翻译系统通常是从源语言到目标语言的多对一（非内射）功能，这在许多情况下导致翻译中丢失意义的重要区别。基于信息性话语产生的贝叶斯模型，我们提出了一种方法，根据底层的预训练神经序列到序列模型定义一个不那么模糊的翻译系统。这种方法增加了注入性，从而在不影响翻译质量（由 BLEU 分数衡量）的情况下，通过改进循环一致性来衡量更好地保留意义。</td><td>Reuben Cohn-Gordon   Noah Goodman</td></tr><tr><td>19</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.02878&#39;]">Syntax-Enhanced Neural Machine Translation with Syntax-Aware Word Representations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1905.02878">https://arxiv.org/pdf/1905.02878</a></td><td>Syntax has been demonstrated highly effective in neural machine translation (NMT). Previous NMT models integrate syntax by representing 1-best tree outputs from a well-trained parsing system, e.g., the representative Tree-RNN and Tree-Linearization methods, which may suffer from error propagation. In this work, we propose a novel method to integrate source-side syntax implicitly for NMT. The basic idea is to use the intermediate hidden representations of a well-trained end-to-end dependency parser, which are referred to as syntax-aware word representations (SAWRs). Then, we simply concatenate such SAWRs with ordinary word embeddings to enhance basic NMT models. The method can be straightforwardly integrated into the widely-used sequence-to-sequence (Seq2Seq) NMT models. We start with a representative RNN-based Seq2Seq baseline system, and test the effectiveness of our proposed method on two benchmark datasets of the Chinese-English and English-Vietnamese translation tasks, respectively. Experimental results show that the proposed approach is able to bring significant BLEU score improvements on the two datasets compared with the baseline, 1.74 points for Chinese-English translation and 0.80 point for English-Vietnamese translation, respectively. In addition, the approach also outperforms the explicit Tree-RNN and Tree-Linearization methods.</td><td>语法已被证明在神经机器翻译 (NMT) 中非常有效。以前的 NMT 模型通过表示来自训练有素的解析系统的 1-best 树输出来集成语法，例如代表性的 Tree-RNN 和 Tree-Linearization 方法，它们可能会受到错误传播的影响。在这项工作中，我们提出了一种为 NMT 隐式集成源端语法的新方法。基本思想是使用训练有素的端到端依赖解析器的中间隐藏表示，称为语法感知词表示 (SAWR)。然后，我们简单地将这些 SAWR 与普通的词嵌入连接起来，以增强基本的 NMT 模型。该方法可以直接集成到广泛使用的序列到序列 (Seq2Seq) NMT 模型中。我们从一个代表性的基于 RNN 的 Seq2Seq 基线系统开始，并分别在汉英和英越翻译任务的两个基准数据集上测试我们提出的方法的有效性。实验结果表明，与基线相比，所提出的方法能够在两个数据集上带来显着的 BLEU 分数改进，汉英翻译分别为 1.74 分和英越翻译 0.80 分。此外，该方法还优于显式 Tree-RNN 和 Tree-Linearization 方法。</td><td>Meishan Zhang   Zhenghua Li   Guohong Fu   Min Zhang</td></tr><tr><td>20</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09508&#39;, &#39;https://arxiv.org/abs/1902.01509&#39;]">Improving Robustness of Machine Translation with Synthetic Noise</a></td><td></td><td><a href="https://github.com/MysteryVaibhav/robust_mtnt">https://github.com/MysteryVaibhav/robust_mtnt</a></td><td><a href="https://arxiv.org/pdf/1902.09508">https://arxiv.org/pdf/1902.09508</a></td><td>Modern Machine Translation (MT) systems perform consistently well on clean, in-domain text. However most human generated text, particularly in the realm of social media, is full of typos, slang, dialect, idiolect and other noise which can have a disastrous impact on the accuracy of output translation. In this paper we leverage the Machine Translation of Noisy Text (MTNT) dataset to enhance the robustness of MT systems by emulating naturally occurring noise in otherwise clean data. Synthesizing noise in this manner we are ultimately able to make a vanilla MT system resilient to naturally occurring noise and partially mitigate loss in accuracy resulting therefrom.</td><td>现代机器翻译 (MT) 系统在干净的域内文本上始终表现良好。然而，大多数人工生成的文本，特别是在社交媒体领域，充满了拼写错误、俚语、方言、方言和其他噪音，这些噪音会对输出翻译的准确性产生灾难性的影响。在本文中，我们利用嘈杂文本机器翻译 (MTNT) 数据集通过在其他干净的数据中模拟自然发生的噪声来增强 MT 系统的鲁棒性。以这种方式合成噪声，我们最终能够使普通 MT 系统对自然发生的噪声具有弹性，并部分减轻由此导致的精度损失。</td><td>Vaibhav Vaibhav   Sumeet Singh   Craig Stewart   Graham Neubig   Vladimir Karpukhin   Omer Levy   Jacob Eisenstein   Marjan Ghazvininejad</td></tr><tr><td>21</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.04079&#39;]">Differentiable Sampling with Flexible Reference Word Order for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/Izecson/saml-nmt">https://github.com/Izecson/saml-nmt</a></td><td><a href="https://arxiv.org/pdf/1904.04079">https://arxiv.org/pdf/1904.04079</a></td><td>Despite some empirical success at correcting exposure bias in machine translation, scheduled sampling algorithms suffer from a major drawback: they incorrectly assume that words in the reference translations and in sampled sequences are aligned at each time step. Our new differentiable sampling algorithm addresses this issue by optimizing the probability that the reference can be aligned with the sampled output, based on a soft alignment predicted by the model itself. As a result, the output distribution at each time step is evaluated with respect to the whole predicted sequence. Experiments on IWSLT translation tasks show that our approach improves BLEU compared to maximum likelihood and scheduled sampling baselines. In addition, our approach is simpler to train with no need for sampling schedule and yields models that achieve larger improvements with smaller beam sizes.</td><td></td><td>Weijia Xu   Xing Niu   Marine Carpuat</td></tr><tr><td>22</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00556&#39;]">Fluent Translations from Disfluent Speech in End-to-End Speech Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.00556">https://arxiv.org/pdf/1906.00556</a></td><td>Spoken language translation applications for speech suffer due to conversational speech phenomena, particularly the presence of disfluencies. With the rise of end-to-end speech translation models, processing steps such as disfluency removal that were previously an intermediate step between speech recognition and machine translation need to be incorporated into model architectures. We use a sequence-to-sequence model to translate from noisy, disfluent speech to fluent text with disfluencies removed using the recently collected `copy-edited’ references for the Fisher Spanish-English dataset. We are able to directly generate fluent translations and introduce considerations about how to evaluate success on this task. This work provides a baseline for a new task, the translation of conversational speech with joint removal of disfluencies.</td><td>由于会话语音现象，特别是不流畅的存在，语音的口语翻译应用程序受到影响。随着端到端语音翻译模型的兴起，之前作为语音识别和机器翻译之间的中间步骤的不流畅去除等处理步骤需要纳入模型架构中。我们使用序列到序列模型将嘈杂、不流利的语音转换为流利的文本，并使用最近收集的 Fisher 西班牙语-英语数据集的“复制编辑”参考删除了不流利之处。我们能够直接生成流畅的翻译，并引入有关如何评估此任务成功的注意事项。这项工作为一项新任务提供了基线，即翻译会话语音并联合消除不流畅。</td><td>Elizabeth Salesky   Matthias Sperber   Alex Waibel</td></tr><tr><td>23</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.08788&#39;]">Selective Attention for Context-aware Neural Machine Translation</a></td><td></td><td><a href="https://github.com/sameenmaruf/selective-attn">https://github.com/sameenmaruf/selective-attn</a></td><td><a href="https://arxiv.org/pdf/1903.08788">https://arxiv.org/pdf/1903.08788</a></td><td>Despite the progress made in sentence-level NMT, current systems still fall short at achieving fluent, good quality translation for a full document. Recent works in context-aware NMT consider only a few previous sentences as context and may not scale to entire documents. To this end, we propose a novel and scalable top-down approach to hierarchical attention for context-aware NMT which uses sparse attention to selectively focus on relevant sentences in the document context and then attends to key words in those sentences. We also propose single-level attention approaches based on sentence or word-level information in the context. The document-level context representation, produced from these attention modules, is integrated into the encoder or decoder of the Transformer model depending on whether we use monolingual or bilingual context. Our experiments and evaluation on English-German datasets in different document MT settings show that our selective attention approach not only significantly outperforms context-agnostic baselines but also surpasses context-aware baselines in most cases.</td><td>尽管在句子级 NMT 方面取得了进展，但当前的系统仍然无法实现对完整文档的流畅、高质量的翻译。最近在上下文感知 NMT 中的工作只考虑前面的几个句子作为上下文，可能无法扩展到整个文档。为此，我们提出了一种新颖且可扩展的自上而下的上下文感知 NMT 分层注意力方法，该方法使用稀疏注意力来选择性地关注文档上下文中的相关句子，然后关注这些句子中的关键词。我们还提出了基于上下文中句子或单词级信息的单级注意力方法。由这些注意力模块产生的文档级上下文表示被集成到 Transformer 模型的编码器或解码器中，具体取决于我们使用的是单语还是双语上下文。我们在不同文档 MT 设置中对英德数据集的实验和评估表明，我们的选择性注意方法不仅显着优于上下文无关基线，而且在大多数情况下也超过了上下文感知基线。</td><td>Sameen Maruf   André F. T. Martins   Gholamreza Haffari</td></tr></tbody></table></div><h3 id="COLING"><a href="#COLING" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00890&#39;]">Emergent Communication Pretraining for Few-Shot Machine Translation</a></td><td></td><td><a href="https://github.com/cambridgeltl/ECNMT">https://github.com/cambridgeltl/ECNMT</a></td><td><a href="https://arxiv.org/pdf/2011.00890">https://arxiv.org/pdf/2011.00890</a></td><td>While state-of-the-art models that rely upon massively multilingual pretrained encoders achieve sample efficiency in downstream applications, they still require abundant amounts of unlabelled text. Nevertheless, most of the world’s languages lack such resources. Hence, we investigate a more radical form of unsupervised knowledge transfer in the absence of linguistic data. In particular, for the first time we pretrain neural networks via emergent communication from referential games. Our key assumption is that grounding communication on images—-as a crude approximation of real-world environments—-inductively biases the model towards learning natural languages. On the one hand, we show that this substantially benefits machine translation in few-shot settings. On the other hand, this also provides an extrinsic evaluation protocol to probe the properties of emergent languages ex vitro. Intuitively, the closer they are to natural languages, the higher the gains from pretraining on them should be. For instance, in this work we measure the influence of communication success and maximum sequence length on downstream performances. Finally, we introduce a customised adapter layer and annealing strategies for the regulariser of maximum-a-posteriori inference during fine-tuning. These turn out to be crucial to facilitate knowledge transfer and prevent catastrophic forgetting. Compared to a recurrent baseline, our method yields gains of $59.0\%<script type="math/tex">\sim</script>147.6\%$ in BLEU score with only $500$ NMT training instances and $65.1\%<script type="math/tex">\sim</script>196.7\%$ with $1,000$ NMT training instances across four language pairs. These proof-of-concept results reveal the potential of emergent communication pretraining for both natural language processing tasks in resource-poor settings and extrinsic evaluation of artificial languages.</td><td></td><td>Yaoyiran Li   Edoardo M. Ponti   Ivan Vulić   Anna Korhonen</td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00678&#39;]">Investigating Catastrophic Forgetting During Continual Training for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00678">https://arxiv.org/pdf/2011.00678</a></td><td>Neural machine translation (NMT) models usually suffer from catastrophic forgetting during continual training where the models tend to gradually forget previously learned knowledge and swing to fit the newly added data which may have a different distribution, e.g. a different domain. Although many methods have been proposed to solve this problem, we cannot get to know what causes this phenomenon yet. Under the background of domain adaptation, we investigate the cause of catastrophic forgetting from the perspectives of modules and parameters (neurons). The investigation on the modules of the NMT model shows that some modules have tight relation with the general-domain knowledge while some other modules are more essential in the domain adaptation. And the investigation on the parameters shows that some parameters are important for both the general-domain and in-domain translation and the great change of them during continual training brings about the performance decline in general-domain. We conduct experiments across different language pairs and domains to ensure the validity and reliability of our findings.</td><td>神经机器翻译 (NMT) 模型在持续训练期间通常会遭受灾难性遗忘，其中模型往往会逐渐忘记先前学到的知识并摆动以适应可能具有不同分布的新添加数据，例如不同的域。虽然已经提出了很多方法来解决这个问题，但我们还不能知道是什么导致了这种现象。在领域适应的背景下，我们从模块和参数（神经元）的角度研究了灾难性遗忘的原因。对 NMT 模型模块的调查表明，一些模块与通用领域知识关系密切，而另一些模块在领域适应中更为重要。对参数的调查表明，一些参数对通用域和域内翻译都很重要，并且在持续训练过程中它们的巨大变化导致通用域的性能下降。我们在不同的语言对和领域进行实验，以确保我们发现的有效性和可靠性。</td><td>Shuhao Gu   Yang Feng</td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.01482&#39;]">Layer-wise Multi-view Learning for Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.01482">https://arxiv.org/pdf/2011.01482</a></td><td>Traditional neural machine translation is limited to the topmost encoder layer’s context representation and cannot directly perceive the lower encoder layers. Existing solutions usually rely on the adjustment of network architecture, making the calculation more complicated or introducing additional structural restrictions. In this work, we propose layer-wise multi-view learning to solve this problem, circumventing the necessity to change the model structure. We regard each encoder layer’s off-the-shelf output, a by-product in layer-by-layer encoding, as the redundant view for the input sentence. In this way, in addition to the topmost encoder layer (referred to as the primary view), we also incorporate an intermediate encoder layer as the auxiliary view. We feed the two views to a partially shared decoder to maintain independent prediction. Consistency regularization based on KL divergence is used to encourage the two views to learn from each other. Extensive experimental results on five translation tasks show that our approach yields stable improvements over multiple strong baselines. As another bonus, our method is agnostic to network architectures and can maintain the same inference speed as the original model.</td><td>传统的神经机器翻译仅限于最顶层编码器层的上下文表示，无法直接感知较低的编码器层。现有的解决方案通常依赖于网络架构的调整，使计算更加复杂或引入额外的结构限制。在这项工作中，我们提出了分层多视图学习来解决这个问题，避免了改变模型结构的必要性。我们将每个编码器层的现成输出（逐层编码的副产品）视为输入句子的冗余视图。这样，除了最顶层的编码器层（称为主视图），我们还合并了一个中间编码器层作为辅助视图。我们将两个视图提供给部分共享的解码器以保持独立预测。基于KL散度的一致性正则化用于鼓励两种观点相互学习。五项翻译任务的大量实验结果表明，我们的方法在多个强基线上产生了稳定的改进。作为另一个好处，我们的方法与网络架构无关，并且可以保持与原始模型相同的推理速度。</td><td>Qiang Wang   Changliang Li   Yue Zhang   Tong Xiao   Jingbo Zhu</td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.03732&#39;]">Leveraging Discourse Rewards for Document-Level Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.03732">https://arxiv.org/pdf/2010.03732</a></td><td>Document-level machine translation focuses on the translation of entire documents from a source to a target language. It is widely regarded as a challenging task since the translation of the individual sentences in the document needs to retain aspects of the discourse at document level. However, document-level translation models are usually not trained to explicitly ensure discourse quality. Therefore, in this paper we propose a training approach that explicitly optimizes two established discourse metrics, lexical cohesion (LC) and coherence (COH), by using a reinforcement learning objective. Experiments over four different language pairs and three translation domains have shown that our training approach has been able to achieve more cohesive and coherent document translations than other competitive approaches, yet without compromising the faithfulness to the reference translation. In the case of the Zh-En language pair, our method has achieved an improvement of 2.46 percentage points (pp) in LC and 1.17 pp in COH over the runner-up, while at the same time improving 0.63 pp in BLEU score and 0.47 pp in F_BERT.</td><td>文档级机器翻译侧重于将整个文档从源语言翻译成目标语言。它被广泛认为是一项具有挑战性的任务，因为文档中单个句子的翻译需要在文档级别保留话语的各个方面。然而，文档级翻译模型通常没有经过训练以明确确保话语质量。因此，在本文中，我们提出了一种训练方法，该方法通过使用强化学习目标明确优化两个已建立的话语指标，词汇衔接 (LC) 和连贯 (COH)。对四种不同语言对和三个翻译领域的实验表明，我们的训练方法比其他竞争方法能够实现更具凝聚力和连贯性的文档翻译，同时又不影响对参考翻译的忠实度。在 Zh-En 语言对的情况下，我们的方法在 LC 和 COH 方面比亚军提高了 2.46 个百分点（pp），同时在 BLEU 得分上提高了 0.63 个百分点（pp）和 0.47 F_BERT 中的 pp。</td><td>Inigo Jauregi Unanue   Nazanin Esmaili   Gholamreza Haffari   Massimo Piccardi</td></tr><tr><td>5</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.02266&#39;]">Optimized Transformer for Low-resource Neural Machine Translation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.02266">https://arxiv.org/pdf/2011.02266</a></td><td>Language pairs with limited amounts of parallel data, also known as low-resource languages, remain a challenge for neural machine translation. While the Transformer model has achieved significant improvements for many language pairs and has become the de facto mainstream architecture, its capability under low-resource conditions has not been fully investigated yet. Our experiments on different subsets of the IWSLT14 training data show that the effectiveness of Transformer under low-resource conditions is highly dependent on the hyper-parameter settings. Our experiments show that using an optimized Transformer for low-resource conditions improves the translation quality up to 7.3 BLEU points compared to using the Transformer default settings.</td><td>并行数据量有限的语言对，也称为低资源语言，仍然是神经机器翻译的挑战。虽然 Transformer 模型在许多语言对上都取得了显着的改进，已经成为事实上的主流架构，但其在低资源条件下的能力尚未得到充分研究。我们对 IWSLT14 训练数据的不同子集进行的实验表明，Transformer 在低资源条件下的有效性高度依赖于超参数设置。我们的实验表明，与使用 Transformer 默认设置相比，在低资源条件下使用优化的 Transformer 可将翻译质量提高多达 7.3 BLEU 点。</td><td>Ali Araabi   Christof Monz</td></tr><tr><td>6</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12549&#39;]">Robust Unsupervised Neural Machine Translation with Adversarial Denoising Training</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2002.12549">https://arxiv.org/pdf/2002.12549</a></td><td>Unsupervised neural machine translation (UNMT) has recently attracted great interest in the machine translation community. The main advantage of the UNMT lies in its easy collection of required large training text sentences while with only a slightly worse performance than supervised neural machine translation which requires expensive annotated translation pairs on some translation tasks. In most studies, the UMNT is trained with clean data without considering its robustness to the noisy data. However, in real-world scenarios, there usually exists noise in the collected input sentences which degrades the performance of the translation system since the UNMT is sensitive to the small perturbations of the input sentences. In this paper, we first time explicitly take the noisy data into consideration to improve the robustness of the UNMT based systems. First of all, we clearly defined two types of noises in training sentences, i.e., word noise and word order noise, and empirically investigate its effect in the UNMT, then we propose adversarial training methods with denoising process in the UNMT. Experimental results on several language pairs show that our proposed methods substantially improved the robustness of the conventional UNMT systems in noisy scenarios.</td><td>无监督神经机器翻译（UNMT）最近引起了机器翻译社区的极大兴趣。 UNMT 的主要优势在于它可以轻松收集所需的大型训练文本句子，而其性能仅比监督神经机器翻译稍差，后者在某些翻译任务上需要昂贵的注释翻译对。在大多数研究中，UMNT 是用干净的数据训练的，而没有考虑它对噪声数据的鲁棒性。然而，在实际场景中，由于 UNMT 对输入句子的小扰动很敏感，因此收集的输入句子中通常存在噪声，这会降低翻译系统的性能。在本文中，我们第一次明确地将噪声数据考虑在内，以提高基于 UNMT 的系统的鲁棒性。首先，我们明确定义了训练句子中的两类噪声，即词噪声和词序噪声，并实证研究了其在 UNMT 中的影响，然后我们在 UNMT 中提出了具有去噪过程的对抗性训练方法。几个语言对的实验结果表明，我们提出的方法大大提高了传统 UNMT 系统在嘈杂场景中的鲁棒性。</td><td>Haipeng Sun   Rui Wang   Kehai Chen   Xugang Lu   Masao Utiyama   Eiichiro Sumita   Tiejun Zhao</td></tr><tr><td>7</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.11018&#39;]">Token Drop mechanism for Neural Machine Translation</a></td><td></td><td><a href="https://github.com/zhajiahe/Token_Drop">https://github.com/zhajiahe/Token_Drop</a></td><td><a href="https://arxiv.org/pdf/2010.11018">https://arxiv.org/pdf/2010.11018</a></td><td>Neural machine translation with millions of parameters is vulnerable to unfamiliar inputs. We propose Token Drop to improve generalization and avoid overfitting for the NMT model. Similar to word dropout, whereas we replace dropped token with a special token instead of setting zero to words. We further introduce two self-supervised objectives: Replaced Token Detection and Dropped Token Prediction. Our method aims to force model generating target translation with less information, in this way the model can learn textual representation better. Experiments on Chinese-English and English-Romanian benchmark demonstrate the effectiveness of our approach and our model achieves significant improvements over a strong Transformer baseline.</td><td>具有数百万个参数的神经机器翻译容易受到陌生输入的影响。我们提出 Token Drop 来提高泛化能力并避免对 NMT 模型的过度拟合。类似于单词丢失，而我们用特殊标记替换掉的标记，而不是将单词设置为零。我们进一步介绍了两个自我监督的目标：替换令牌检测和丢弃令牌预测。我们的方法旨在用更少的信息强制模型生成目标翻译，这样模型可以更好地学习文本表示。中文-英文和英文-罗马尼亚语基准的实验证明了我们方法的有效性，我们的模型在强大的 Transformer 基线上取得了显着的改进。</td><td>Huaao Zhang   Shigui Qiu   Xiangyu Duan   Min Zhang</td></tr><tr><td>8</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.03469&#39;]">Understanding Pure Character-Based Neural Machine Translation: The Case of Translating Finnish into English</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.03469">https://arxiv.org/pdf/2011.03469</a></td><td>Recent work has shown that deeper character-based neural machine translation (NMT) models can outperform subword-based models. However, it is still unclear what makes deeper character-based models successful. In this paper, we conduct an investigation into pure character-based models in the case of translating Finnish into English, including exploring the ability to learn word senses and morphological inflections and the attention mechanism. We demonstrate that word-level information is distributed over the entire character sequence rather than over a single character, and characters at different positions play different roles in learning linguistic knowledge. In addition, character-based models need more layers to encode word senses which explains why only deeper models outperform subword-based models. The attention distribution pattern shows that separators attract a lot of attention and we explore a sparse word-level attention to enforce character hidden states to capture the full word-level information. Experimental results show that the word-level attention with a single head results in 1.2 BLEU points drop.</td><td>最近的工作表明，更深层次的基于字符的神经机器翻译 (NMT) 模型可以胜过基于子词的模型。然而，目前尚不清楚是什么让更深层次的基于字符的模型成功。在本文中，我们在将芬兰语翻译成英语的情况下对纯基于字符的模型进行了调查，包括探索学习词义和形态变化的能力以及注意机制。我们证明了词级信息分布在整个字符序列而不是单个字符上，并且不同位置的字符在学习语言知识中扮演着不同的角色。此外，基于字符的模型需要更多层来编码词义，这解释了为什么只有更深的模型才能胜过基于子词的模型。注意力分布模式表明分隔符吸引了很多注意力，我们探索了一种稀疏的词级注意力来强制字符隐藏状态来捕获完整的词级信息。实验结果表明，单个头部的词级注意力导致 1.2 BLEU 点下降。</td><td>Gongbo Tang   Rico Sennrich   Joakim Nivre</td></tr></tbody></table></div><h2 id="会话-对话系统"><a href="#会话-对话系统" class="headerlink" title="会话/对话系统"></a>会话/对话系统</h2><h3 id="ACL-1"><a href="#ACL-1" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.12458&#39;]">TicketTalk: Toward human-level performance with end-to-end, transaction-based dialog systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.12458">https://arxiv.org/pdf/2012.12458</a></td><td>We present a data-driven, end-to-end approach to transaction-based dialog systems that performs at near-human levels in terms of verbal response quality and factual grounding accuracy. We show that two essential components of the system produce these results: a sufficiently large and diverse, in-domain labeled dataset, and a neural network-based, pre-trained model that generates both verbal responses and API call predictions. In terms of data, we introduce TicketTalk, a movie ticketing dialog dataset with 23,789 annotated conversations. The movie ticketing conversations range from completely open-ended and unrestricted to more structured, both in terms of their knowledge base, discourse features, and number of turns. In qualitative human evaluations, model-generated responses trained on just 10,000 TicketTalk dialogs were rated to “make sense” 86.5 percent of the time, almost the same as human responses in the same contexts. Our simple, API-focused annotation schema results in a much easier labeling task making it faster and more cost effective. It is also the key component for being able to predict API calls accurately. We handle factual grounding by incorporating API calls in the training data, allowing our model to learn which actions to take and when. Trained on the same 10,000-dialog set, the model’s API call predictions were rated to be correct 93.9 percent of the time in our evaluations, surpassing the ratings for the corresponding human labels. We show how API prediction and response generation scores improve as the dataset size incrementally increases from 5000 to 21,000 dialogs. Our analysis also clearly illustrates the benefits of pre-training. We are publicly releasing the TicketTalk dataset with this paper to facilitate future work on transaction-based dialogs.</td><td>我们为基于事务的对话系统提供了一种数据驱动的端到端方法，该方法在口头响应质量和事实基础准确性方面的表现接近人类水平。我们展示了系统的两个基本组成部分会产生这些结果：一个足够大且多样化的域内标记数据集，以及一个基于神经网络的预训练模型，该模型生成口头响应和 API 调用预测。在数据方面，我们引入了 TicketTalk，这是一个电影票务对话数据集，包含 23,789 个带注释的对话。电影票务对话的范围从完全开放和不受限制到更加结构化，无论是在知识基础、话语特征还是回合数方面。在定性的人类评估中，仅在 10,000 个 TicketTalk 对话上训练的模型生成的响应被评为“有意义”的时间为 86.5%，几乎与相同上下文中的人类响应相同。我们以 API 为中心的简单注释模式使标记任务变得更加简单，从而使其更快、更具成本效益。它也是能够准确预测 API 调用的关键组件。我们通过在训练数据中加入 API 调用来处理事实基础，让我们的模型了解要采取哪些行动以及何时采取行动。在相同的 10,000 个对话集上进行训练，模型的 API 调用预测在我们的评估中被评为 93.9% 的正确率，超过了相应人工标签的评分。我们展示了 API 预测和响应生成分数如何随着数据集大小从 5000 个对话逐渐增加到 21,000 个而提高。我们的分析还清楚地说明了预训练的好处。我们将随本文公开发布 TicketTalk 数据集，以促进基于事务的对话的未来工作。</td><td>Bill Byrne   Karthik Krishnamoorthi   Saravanan Ganesh   Mihir Sanjay Kale</td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00162&#39;]">HERALD: An Annotation Efficient Method to Detect User Disengagement in Social Conversations</a></td><td></td><td><a href="https://github.com/Weixin-Liang/HERALD">https://github.com/Weixin-Liang/HERALD</a></td><td><a href="https://arxiv.org/pdf/2106.00162">https://arxiv.org/pdf/2106.00162</a></td><td>Open-domain dialog systems have a user-centric goal: to provide humans with an engaging conversation experience. User engagement is one of the most important metrics for evaluating open-domain dialog systems, and could also be used as real-time feedback to benefit dialog policy learning. Existing work on detecting user disengagement typically requires hand-labeling many dialog samples. We propose HERALD, an efficient annotation framework that reframes the training data annotation process as a denoising problem. Specifically, instead of manually labeling training samples, we first use a set of labeling heuristics to label training samples automatically. We then denoise the weakly labeled data using the Shapley algorithm. Finally, we use the denoised data to train a user engagement detector. Our experiments show that HERALD improves annotation efficiency significantly and achieves 86% user disengagement detection accuracy in two dialog corpora.</td><td>开放域对话系统有一个以用户为中心的目标：为人类提供引人入胜的对话体验。用户参与度是评估开放域对话系统的最重要指标之一，也可以用作实时反馈以促进对话策略学习。检测用户脱离的现有工作通常需要手动标记许多对话样本。我们提出了 HERALD，这是一种高效的注释框架，可将训练数据注释过程重新构建为去噪问题。具体来说，我们首先使用一组标记启发式方法来自动标记训练样本，而不是手动标记训练样本。然后我们使用 Shapley 算法对弱标记数据进行去噪。最后，我们使用去噪数据来训练用户参与检测器。我们的实验表明，HERALD 显着提高了注释效率，并在两个对话语料库中实现了 86% 的用户脱离检测准确率。</td><td>Weixin Liang   Kai-Hui Liang   Zhou Yu</td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.13073&#39;]">Maria: A Visual Experience Powered Conversational Agent</a></td><td></td><td><a href="https://github.com/jokieleung/Maria">https://github.com/jokieleung/Maria</a></td><td><a href="https://arxiv.org/pdf/2105.13073">https://arxiv.org/pdf/2105.13073</a></td><td>Arguably, the visual perception of conversational agents to the physical world is a key way for them to exhibit the human-like intelligence. Image-grounded conversation is thus proposed to address this challenge. Existing works focus on exploring the multimodal dialog models that ground the conversation on a given image. In this paper, we take a step further to study image-grounded conversation under a fully open-ended setting where no paired dialog and image are assumed available. Specifically, we present Maria, a neural conversation agent powered by the visual world experiences which are retrieved from a large-scale image index. Maria consists of three flexible components, i.e., text-to-image retriever, visual concept detector and visual-knowledge-grounded response generator. The retriever aims to retrieve a correlated image to the dialog from an image index, while the visual concept detector extracts rich visual knowledge from the image. Then, the response generator is grounded on the extracted visual knowledge and dialog context to generate the target response. Extensive experiments demonstrate Maria outperforms previous state-of-the-art methods on automatic metrics and human evaluation, and can generate informative responses that have some visual commonsense of the physical world.</td><td>可以说，会话代理对物理世界的视觉感知是他们展示类人智能的关键方式。因此，提出了基于图像的对话来应对这一挑战。现有的工作侧重于探索基于给定图像进行对话的多模态对话模型。在本文中，我们进一步研究在完全开放的设置下基于图像的对话，假设没有配对的对话和图像可用。具体来说，我们展示了 Maria，一种神经对话代理，由从大规模图像索引中检索的视觉世界体验提供支持。 Maria 由三个灵活的组件组成，即文本到图像检索器、视觉概念检测器和基于视觉知识的响应生成器。检索器旨在从图像索引中检索与对话相关的图像，而视觉概念检测器从图像中提取丰富的视觉知识。然后，响应生成器基于提取的视觉知识和对话上下文来生成目标响应。大量实验表明，Maria 在自动度量和人工评估方面优于以前最先进的方法，并且可以生成具有物理世界一些视觉常识的信息响应。</td><td>Zujie Liang   Huang Hu   Can Xu   Chongyang Tao   Xiubo Geng   Yining Chen   Fan Liang   Daxin Jiang</td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.14756&#39;]">Dialogue Response Selection with Hierarchical Curriculum Learning</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.14756">https://arxiv.org/pdf/2012.14756</a></td><td>We study the learning of a matching model for dialogue response selection. Motivated by the recent finding that models trained with random negative samples are not ideal in real-world scenarios, we propose a hierarchical curriculum learning framework that trains the matching model in an “easy-to-difficult” scheme. Our learning framework consists of two complementary curricula: (1) corpus-level curriculum (CC); and (2) instance-level curriculum (IC). In CC, the model gradually increases its ability in finding the matching clues between the dialogue context and a response candidate. As for IC, it progressively strengthens the model’s ability in identifying the mismatching information between the dialogue context and a response candidate. Empirical studies on three benchmark datasets with three state-of-the-art matching models demonstrate that the proposed learning framework significantly improves the model performance across various evaluation metrics.</td><td></td><td>Yixuan Su   Deng Cai   Qingyu Zhou   Zibo Lin   Simon Baker   Yunbo Cao   Shuming Shi   Nigel Collier   Yan Wang</td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.14556&#39;]">Diversifying Dialog Generation via Adaptive Label Smoothing</a></td><td></td><td><a href="https://github.com/lemon234071/AdaLabel">https://github.com/lemon234071/AdaLabel</a></td><td><a href="https://arxiv.org/pdf/2105.14556">https://arxiv.org/pdf/2105.14556</a></td><td>Neural dialogue generation models trained with the one-hot target distribution suffer from the over-confidence issue, which leads to poor generation diversity as widely reported in the literature. Although existing approaches such as label smoothing can alleviate this issue, they fail to adapt to diverse dialog contexts. In this paper, we propose an Adaptive Label Smoothing (AdaLabel) approach that can adaptively estimate a target label distribution at each time step for different contexts. The maximum probability in the predicted distribution is used to modify the soft target distribution produced by a novel light-weight bi-directional decoder module. The resulting target distribution is aware of both previous and future contexts and is adjusted to avoid over-training the dialogue model. Our model can be trained in an end-to-end manner. Extensive experiments on two benchmark datasets show that our approach outperforms various competitive baselines in producing diverse responses.</td><td>使用 one-hot 目标分布训练的神经对话生成模型存在过度自信的问题，这导致了文献中广泛报道的生成多样性较差。尽管标签平滑等现有方法可以缓解这个问题，但它们无法适应不同的对话上下文。在本文中，我们提出了一种自适应标签平滑 (AdaLabel) 方法，该方法可以针对不同的上下文在每个时间步自适应地估计目标标签分布。预测分布中的最大概率用于修改由新型轻量级双向解码器模块产生的软目标分布。由此产生的目标分布了解之前和未来的上下文，并进行调整以避免过度训练对话模型。我们的模型可以以端到端的方式进行训练。对两个基准数据集的大量实验表明，我们的方法在产生不同响应方面优于各种竞争基线。</td><td>Yida Wang   Yinhe Zheng   Yong Jiang   Minlie Huang</td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06169&#39;]">BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data</a></td><td></td><td><a href="https://github.com/songhaoyu/BoB">https://github.com/songhaoyu/BoB</a></td><td><a href="https://arxiv.org/pdf/2106.06169">https://arxiv.org/pdf/2106.06169</a></td><td>Maintaining consistent personas is essential for dialogue agents. Although tremendous advancements have been brought, the limited-scale of annotated persona-dense data are still barriers towards training robust and consistent persona-based dialogue models. In this work, we show how the challenges can be addressed by disentangling persona-based dialogue generation into two sub-tasks with a novel BERT-over-BERT (BoB) model. Specifically, the model consists of a BERT-based encoder and two BERT-based decoders, where one decoder is for response generation, and another is for consistency understanding. In particular, to learn the ability of consistency understanding from large-scale non-dialogue inference data, we train the second decoder in an unlikelihood manner. Under different limited data settings, both automatic and human evaluations demonstrate that the proposed model outperforms strong baselines in response quality and persona consistency.</td><td>保持一致的角色对于对话代理至关重要。尽管已经带来了巨大的进步，但带注释的角色密集数据的规模有限仍然是训练强大且一致的基于角色的对话模型的障碍。在这项工作中，我们展示了如何通过使用新颖的 BERT-over-BERT (BoB) 模型将基于角色的对话生成分解为两个子任务来解决挑战。具体来说，该模型由一个基于 BERT 的编码器和两个基于 BERT 的解码器组成，其中一个解码器用于响应生成，另一个用于一致性理解。特别是，为了从大规模非对话推理数据中学习一致性理解能力，我们以不太可能的方式训练第二个解码器。在不同的有限数据设置下，自动和人工评估都表明，所提出的模型在响应质量和角色一致性方面优于强大的基线。</td><td>Haoyu Song   Yan Wang   Kaiyan Zhang   Wei-Nan Zhang   Ting Liu</td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.13391&#39;]">I like fish, especially dolphins: Addressing Contradictions in Dialogue Modeling</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.13391">https://arxiv.org/pdf/2012.13391</a></td><td>To quantify how well natural language understanding models can capture consistency in a general conversation, we introduce the DialoguE COntradiction DEtection task (DECODE) and a new conversational dataset containing both human-human and human-bot contradictory dialogues. We then compare a structured utterance-based approach of using pre-trained Transformer models for contradiction detection with the typical unstructured approach. Results reveal that: (i) our newly collected dataset is notably more effective at providing supervision for the dialogue contradiction detection task than existing NLI data including those aimed to cover the dialogue domain; (ii) the structured utterance-based approach is more robust and transferable on both analysis and out-of-distribution dialogues than its unstructured counterpart. We also show that our best contradiction detection model correlates well with human judgments and further provide evidence for its usage in both automatically evaluating and improving the consistency of state-of-the-art generative chatbots.</td><td>为了量化自然语言理解模型在一般对话中捕捉一致性的能力，我们引入了对话矛盾检测任务 (DECODE) 和一个包含人与人和人与机器人矛盾对话的新对话数据集。然后，我们将使用预训练的 Transformer 模型进行矛盾检测的基于结构化话语的方法与典型的非结构化方法进行比较。结果表明：（i）我们新收集的数据集在为对话矛盾检测任务提供监督方面比现有的 NLI 数据（包括旨在覆盖对话域的数据）更有效； (ii) 基于结构化话语的方法在分析和分布外对话上都比其非结构化方法更健壮和可转移。我们还表明，我们最好的矛盾检测模型与人类判断密切相关，并进一步为其在自动评估和提高最先进生成聊天机器人的一致性方面的使用提供了证据。</td><td>Yixin Nie   Mary Williamson   Mohit Bansal   Douwe Kiela   Jason Weston</td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2011.09553&#39;]">A Sequence-to-Sequence Approach to Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/sweetalyssum/Seq2Seq-DU">https://github.com/sweetalyssum/Seq2Seq-DU</a></td><td><a href="https://arxiv.org/pdf/2011.09553">https://arxiv.org/pdf/2011.09553</a></td><td>This paper is concerned with dialogue state tracking (DST) in a task-oriented dialogue system. Building a DST module that is highly effective is still a challenging issue, although significant progresses have been made recently. This paper proposes a new approach to dialogue state tracking, referred to as Seq2Seq-DU, which formalizes DST as a sequence-to-sequence problem. Seq2Seq-DU employs two BERT-based encoders to respectively encode the utterances in the dialogue and the descriptions of schemas, an attender to calculate attentions between the utterance embeddings and the schema embeddings, and a decoder to generate pointers to represent the current state of dialogue. Seq2Seq-DU has the following advantages. It can jointly model intents, slots, and slot values; it can leverage the rich representations of utterances and schemas based on BERT; it can effectively deal with categorical and non-categorical slots, and unseen schemas. In addition, Seq2Seq-DU can also be used in the NLU (natural language understanding) module of a dialogue system. Experimental results on benchmark datasets in different settings (SGD, MultiWOZ2.2, MultiWOZ2.1, WOZ2.0, DSTC2, M2M, SNIPS, and ATIS) show that Seq2Seq-DU outperforms the existing methods.</td><td>本文关注的是面向任务的对话系统中的对话状态跟踪（DST）。尽管最近取得了重大进展，但构建高效的 DST 模块仍然是一个具有挑战性的问题。本文提出了一种新的对话状态跟踪方法，称为 Seq2Seq-DU，它将 DST 形式化为序列到序列问题。 Seq2Seq-DU 使用两个基于 BERT 的编码器分别对对话中的话语和模式描述进行编码，一个参与器计算话语嵌入和模式嵌入之间的注意力，以及一个解码器来生成表示当前对话状态的指针. Seq2Seq-DU 具有以下优点。它可以联合建模意图、槽位和槽位值；它可以利用基于 BERT 的丰富的话语和模式表示；它可以有效地处理分类和非分类槽以及看不见的模式。此外，Seq2Seq-DU 还可以用于对话系统的 NLU（自然语言理解）模块。在不同设置（SGD、MultiWOZ2.2、MultiWOZ2.1、WOZ2.0、DSTC2、M2M、SNIPS 和 ATIS）的基准数据集上的实验结果表明，Seq2Seq-DU 优于现有方法。</td><td>Yue Feng   Yang Wang   Hang Li</td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.03410&#39;]">Generating Relevant and Coherent Dialogue Responses using Self-Separated Conditional Variational AutoEncoders</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.03410">https://arxiv.org/pdf/2106.03410</a></td><td>Conditional Variational AutoEncoder (CVAE) effectively increases the diversity and informativeness of responses in open-ended dialogue generation tasks through enriching the context vector with sampled latent variables. However, due to the inherent one-to-many and many-to-one phenomena in human dialogues, the sampled latent variables may not correctly reflect the contexts’ semantics, leading to irrelevant and incoherent generated responses. To resolve this problem, we propose Self-separated Conditional Variational AutoEncoder (abbreviated as SepaCVAE) that introduces group information to regularize the latent variables, which enhances CVAE by improving the responses’ relevance and coherence while maintaining their diversity and informativeness. SepaCVAE actively divides the input data into groups, and then widens the absolute difference between data pairs from distinct groups, while narrowing the relative distance between data pairs in the same group. Empirical results from automatic evaluation and detailed analysis demonstrate that SepaCVAE can significantly boost responses in well-established open-domain dialogue datasets.</td><td>条件变分自动编码器 (CVAE) 通过用采样的潜在变量丰富上下文向量，有效地增加了开放式对话生成任务中响应的多样性和信息量。然而，由于人类对话中固有的一对多和多对一现象，采样的潜在变量可能无法正确反映上下文的语义，导致生成的响应不相关和不连贯。为了解决这个问题，我们提出了自分离条件变分自动编码器（SepaCVAE），它引入了组信息来规范潜在变量，通过提高响应的相关性和连贯性来增强 CVAE，同时保持它们的多样性和信息量。 SepaCVAE 主动将输入数据分组，然后扩大来自不同组的数据对之间的绝对差异，同时缩小同一组中数据对之间的相对距离。自动评估和详细分析的实证结果表明，SepaCVAE 可以显着提高在完善的开放域对话数据集中的响应。</td><td>Bin Sun   Shaoxiong Feng   Yiwei Li   Jiamou Liu   Kan Li</td></tr><tr><td>10</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00123&#39;]">Intent Classification and Slot Filling for Privacy Policies</a></td><td></td><td><a href="https://github.com/wasiahmad/PolicyIE">https://github.com/wasiahmad/PolicyIE</a></td><td><a href="https://arxiv.org/pdf/2101.00123">https://arxiv.org/pdf/2101.00123</a></td><td>Understanding privacy policies is crucial for users as it empowers them to learn about the information that matters to them. Sentences written in a privacy policy document explain privacy practices, and the constituent text spans convey further specific information about that practice. We refer to predicting the privacy practice explained in a sentence as intent classification and identifying the text spans sharing specific information as slot filling. In this work, we propose PolicyIE, an English corpus consisting of 5,250 intent and 11,788 slot annotations spanning 31 privacy policies of websites and mobile applications. PolicyIE corpus is a challenging real-world benchmark with limited labeled examples reflecting the cost of collecting large-scale annotations from domain experts. We present two alternative neural approaches as baselines, (1) intent classification and slot filling as a joint sequence tagging and (2) modeling them as a sequence-to-sequence (Seq2Seq) learning task. The experiment results show that both approaches perform comparably in intent classification, while the Seq2Seq method outperforms the sequence tagging approach in slot filling by a large margin. We perform a detailed error analysis to reveal the challenges of the proposed corpus.</td><td>了解隐私政策对用户至关重要，因为它使他们能够了解对他们而言重要的信息。写在隐私政策文件中的句子解释了隐私实践，构成文本的跨度传达了有关该实践的进一步具体信息。我们将预测在句子中解释的隐私实践称为意图分类，并将共享特定信息的文本跨度称为插槽填充。在这项工作中，我们提出了 PolicyIE，这是一个英语语料库，由 5,250 个意图和 11,788 个槽注释组成，涵盖 31 个网站和移动应用程序的隐私政策。 PolicyIE 语料库是一个具有挑战性的现实世界基准，其有限的标记示例反映了从领域专家那里收集大规模注释的成本。我们提出了两种替代神经方法作为基线，(1) 意图分类和槽填充作为联合序列标记，(2) 将它们建模为序列到序列 (Seq2Seq) 学习任务。实验结果表明，两种方法在意图分类方面的表现相当，而 Seq2Seq 方法在槽填充方面优于序列标记方法。我们进行了详细的错误分析，以揭示所提出的语料库的挑战。</td><td>Wasi Uddin Ahmad   Jianfeng Chi   Tu Le   Thomas Norton   Yuan Tian   Kai-Wei Chang</td></tr><tr><td>11</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.12578&#39;]">Dual Slot Selector via Local Reliability Verification for Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/guojinyu88/DSSDST">https://github.com/guojinyu88/DSSDST</a></td><td><a href="https://arxiv.org/pdf/2107.12578">https://arxiv.org/pdf/2107.12578</a></td><td>The goal of dialogue state tracking (DST) is to predict the current dialogue state given all previous dialogue contexts. Existing approaches generally predict the dialogue state at every turn from scratch. However, the overwhelming majority of the slots in each turn should simply inherit the slot values from the previous turn. Therefore, the mechanism of treating slots equally in each turn not only is inefficient but also may lead to additional errors because of the redundant slot value generation. To address this problem, we devise the two-stage DSS-DST which consists of the Dual Slot Selector based on the current turn dialogue, and the Slot Value Generator based on the dialogue history. The Dual Slot Selector determines each slot whether to update slot value or to inherit the slot value from the previous turn from two aspects: (1) if there is a strong relationship between it and the current turn dialogue utterances; (2) if a slot value with high reliability can be obtained for it through the current turn dialogue. The slots selected to be updated are permitted to enter the Slot Value Generator to update values by a hybrid method, while the other slots directly inherit the values from the previous turn. Empirical results show that our method achieves 56.93%, 60.73%, and 58.04% joint accuracy on MultiWOZ 2.0, MultiWOZ 2.1, and MultiWOZ 2.2 datasets respectively and achieves a new state-of-the-art performance with significant improvements.</td><td>对话状态跟踪（DST）的目标是在给定所有先前对话上下文的情况下预测当前对话状态。现有方法通常从头开始预测每一轮的对话状态。然而，每一回合中的绝大多数槽位应该简单地继承上一回合的槽位值。因此，在每一轮中平等对待槽的机制不仅效率低下，而且可能由于冗余槽值的生成而导致额外的错误。为了解决这个问题，我们设计了两阶段 DSS-DST，它由基于当前回合对话的双槽选择器和基于对话历史的槽值生成器组成。 Dual Slot Selector从两个方面决定每个槽是更新槽值还是继承上一回合的槽值：（1）是否与当前回合对话话语有很强的关系； (2) 是否可以通过当前回合对话为其获得高可靠性的槽值。选择更新的槽位被允许进入槽位值生成器以混合方式更新值，而其他槽位直接继承上一回合的值。实证结果表明，我们的方法在 MultiWOZ 2.0、MultiWOZ 2.1 和 MultiWOZ 2.2 数据集上分别实现了 56.93%、60.73% 和 58.04% 的联合精度，并实现了新的最先进的性能，并具有显着的改进。</td><td>Jinyu Guo   Kai Shuang   Jijie Li   Zihan Wang</td></tr><tr><td>12</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.15171&#39;]">Learning from Perturbations: Diverse and Informative Dialogue Generation with Inverse Adversarial Training</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.15171">https://arxiv.org/pdf/2105.15171</a></td><td>In this paper, we propose Inverse Adversarial Training (IAT) algorithm for training neural dialogue systems to avoid generic responses and model dialogue history better. In contrast to standard adversarial training algorithms, IAT encourages the model to be sensitive to the perturbation in the dialogue history and therefore learning from perturbations. By giving higher rewards for responses whose output probability reduces more significantly when dialogue history is perturbed, the model is encouraged to generate more diverse and consistent responses. By penalizing the model when generating the same response given perturbed dialogue history, the model is forced to better capture dialogue history and generate more informative responses. Experimental results on two benchmark datasets show that our approach can better model dialogue history and generate more diverse and consistent responses. In addition, we point out a problem of the widely used maximum mutual information (MMI) based methods for improving the diversity of dialogue response generation models and demonstrate it empirically.</td><td>在本文中，我们提出了用于训练神经对话系统的反向对抗训练 (IAT) 算法，以更好地避免通用响应和模型对话历史。与标准的对抗训练算法相比，IAT 鼓励模型对对话历史中的扰动敏感，从而从扰动中学习。通过对对话历史受到扰动时输出概率降低更显着的响应给予更高的奖励，鼓励模型生成更多样化和一致的响应。通过在给定扰动的对话历史时生成相同响应时惩罚模型，该模型被迫更好地捕获对话历史并生成更多信息响应。在两个基准数据集上的实验结果表明，我们的方法可以更好地对对话历史进行建模，并生成更多样化和一致的响应。此外，我们指出了广泛使用的基于最大互信息（MMI）的方法用于提高对话响应生成模型的多样性的问题，并进行了实证证明。</td><td>Wangchunshu Zhou   Qifei Li   Chenle Li</td></tr><tr><td>13</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.11164&#39;]">Modeling Bilingual Conversational Characteristics for Neural Chat Translation</a></td><td></td><td><a href="https://github.com/XL2248/CPCC">https://github.com/XL2248/CPCC</a></td><td><a href="https://arxiv.org/pdf/2107.11164">https://arxiv.org/pdf/2107.11164</a></td><td>Neural chat translation aims to translate bilingual conversational text, which has a broad application in international exchanges and cooperation. Despite the impressive performance of sentence-level and context-aware Neural Machine Translation (NMT), there still remain challenges to translate bilingual conversational text due to its inherent characteristics such as role preference, dialogue coherence, and translation consistency. In this paper, we aim to promote the translation quality of conversational text by modeling the above properties. Specifically, we design three latent variational modules to learn the distributions of bilingual conversational characteristics. Through sampling from these learned distributions, the latent variables, tailored for role preference, dialogue coherence, and translation consistency, are incorporated into the NMT model for better translation. We evaluate our approach on the benchmark dataset BConTrasT (English-German) and a self-collected bilingual dialogue corpus, named BMELD (English-Chinese). Extensive experiments show that our approach notably boosts the performance over strong baselines by a large margin and significantly surpasses some state-of-the-art context-aware NMT models in terms of BLEU and TER. Additionally, we make the BMELD dataset publicly available for the research community.</td><td>神经聊天翻译旨在翻译双语会话文本，在国际交流与合作中有着广泛的应用。尽管句子级和上下文感知神经机器翻译 (NMT) 的表现令人印象深刻，但由于其固有的特性，例如角色偏好、对话连贯性和翻译一致性，翻译双语会话文本仍然存在挑战。在本文中，我们旨在通过对上述属性进行建模来提高会话文本的翻译质量。具体来说，我们设计了三个潜在的变分模块来学习双语会话特征的分布。通过从这些学习到的分布中采样，为角色偏好、对话连贯性和翻译一致性量身定制的潜在变量被纳入 NMT 模型中，以实现更好的翻译。我们在基准数据集 BConTrasT（英德）和自收集的双语对话语料库 BMELD（英汉）上评估我们的方法。大量实验表明，我们的方法显着提高了强基线的性能，并且在 BLEU 和 TER 方面显着超越了一些最先进的上下文感知 NMT 模型。此外，我们还向研究社区公开 BMELD 数据集。</td><td>Yunlong Liang   Fandong Meng   Yufeng Chen   Jinan Xu   Jie Zhou</td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11019&#39;]">Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/LooperXX/DF-Net">https://github.com/LooperXX/DF-Net</a></td><td><a href="https://arxiv.org/pdf/2004.11019">https://arxiv.org/pdf/2004.11019</a></td><td>Recent studies have shown remarkable success in end-to-end task-oriented dialog system. However, most neural models rely on large training data, which are only available for a certain number of task domains, such as navigation and scheduling.</td><td></td><td></td></tr><tr><td>This makes it difficult to scalable for a new domain with limited labeled data. However, there has been relatively little research on how to effectively use data from all domains to improve the performance of each domain and also unseen domains. To this end, we investigate methods that can make explicit use of domain knowledge and introduce a shared-private network to learn shared and specific knowledge. In addition, we propose a novel Dynamic Fusion Network (DF-Net) which automatically exploit the relevance between the target domain and each domain. Results show that our model outperforms existing methods on multi-domain dialogue, giving the state-of-the-art in the literature. Besides, with little training data, we show its transferability by outperforming prior best model by 13.9\% on average.</td><td>最近的研究表明，端到端的面向任务的对话系统取得了显着的成功。然而，大多数神经模型依赖于大量的训练数据，这些数据仅适用于一定数量的任务域，例如导航和调度。</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>这使得难以针对具有有限标记数据的新域进行扩展。然而，关于如何有效地使用来自所有领域的数据来提高每个领域和不可见领域的性能的研究相对较少。为此，我们研究了可以明确使用领域知识并引入共享私有网络来学习共享和特定知识的方法。此外，我们提出了一种新颖的动态融合网络（DF-Net），它可以自动利用目标域和每个域之间的相关性。结果表明，我们的模型在多领域对话方面优于现有方法，提供了文献中的最新技术。此外，在训练数据很少的情况下，我们通过比先前的最佳模型平均高出 13.9% 来展示其可迁移性。</td><td>Libo Qin   Xiao Xu   Wanxiang Che   Yue Zhang   Ting Liu</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.11054&#39;]">Learning Dialog Policies from Weak Demonstrations</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.11054">https://arxiv.org/pdf/2004.11054</a></td><td>Deep reinforcement learning is a promising approach to training a dialog manager, but current methods struggle with the large state and action spaces of multi-domain dialog systems. Building upon Deep Q-learning from Demonstrations (DQfD), an algorithm that scores highly in difficult Atari games, we leverage dialog data to guide the agent to successfully respond to a user’s requests. We make progressively fewer assumptions about the data needed, using labeled, reduced-labeled, and even unlabeled data to train expert demonstrators. We introduce Reinforced Fine-tune Learning, an extension to DQfD, enabling us to overcome the domain gap between the datasets and the environment. Experiments in a challenging multi-domain dialog system framework validate our approaches, and get high success rates even when trained on out-of-domain data.</td><td>深度强化学习是训练对话管理器的一种很有前途的方法，但当前的方法难以应对多域对话系统的大型状态和动作空间。基于演示中的深度 Q 学习 (DQfD)，一种在困难的 Atari 游戏中得分很高的算法，我们利用对话数据来指导代理成功响应用户的请求。我们逐渐减少对所需数据的假设，使用标记、减少标记甚至未标记的数据来训练专家演示者。我们引入了强化微调学习，这是 DQfD 的扩展，使我们能够克服数据集和环境之间的领域差距。在具有挑战性的多域对话系统框架中进行的实验验证了我们的方法，即使在域外数据上进行训练时也能获得很高的成功率。</td><td>Gabriel Gordon-Hall   Philip John Gorinski   Shay B. Cohen</td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.08866&#39;]">Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained Conversational Representations</a></td><td></td><td><a href="https://github.com/PolyAI-LDN/task-specific-datasets">https://github.com/PolyAI-LDN/task-specific-datasets</a></td><td><a href="https://arxiv.org/pdf/2005.08866">https://arxiv.org/pdf/2005.08866</a></td><td>We introduce Span-ConveRT, a light-weight model for dialog slot-filling which frames the task as a turn-based span extraction task. This formulation allows for a simple integration of conversational knowledge coded in large pretrained conversational models such as ConveRT (Henderson et al., 2019). We show that leveraging such knowledge in Span-ConveRT is especially useful for few-shot learning scenarios: we report consistent gains over 1) a span extractor that trains representations from scratch in the target domain, and 2) a BERT-based span extractor. In order to inspire more work on span extraction for the slot-filling task, we also release RESTAURANTS-8K, a new challenging data set of 8,198 utterances, compiled from actual conversations in the restaurant booking domain.</td><td>我们引入了 Span-ConveRT，这是一种用于对话槽填充的轻量级模型，它将任务框架为基于回合的跨度提取任务。这种公式允许简单地集成在大型预训练会话模型（如 ConveRT）中编码的会话知识（Henderson 等，2019）。我们表明，在 Span-ConveRT 中利用这些知识对于少样本学习场景特别有用：我们报告了一致的收益：1）一个跨度提取器，在目标域中从头开始训练表示，2）一个基于 BERT 的跨度提取器。为了激发更多关于槽位填充任务的跨度提取工作，我们还发布了 RESTAURANTS-8K，这是一个新的具有挑战性的数据集，包含 8,198 条话语，由餐厅预订领域的实际对话编译而成。</td><td>Sam Coope   Tyler Farghly   Daniela Gerz   Ivan Vulić   Matthew Henderson</td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.04346&#39;]">Diversifying Dialogue Generation with Non-Conversational Text</a></td><td></td><td><a href="https://github.com/chin-gyou/Div-Non-Conv">https://github.com/chin-gyou/Div-Non-Conv</a></td><td><a href="https://arxiv.org/pdf/2005.04346">https://arxiv.org/pdf/2005.04346</a></td><td>Neural network-based sequence-to-sequence (seq2seq) models strongly suffer from the low-diversity problem when it comes to open-domain dialogue generation. As bland and generic utterances usually dominate the frequency distribution in our daily chitchat, avoiding them to generate more interesting responses requires complex data filtering, sampling techniques or modifying the training objective. In this paper, we propose a new perspective to diversify dialogue generation by leveraging non-conversational text. Compared with bilateral conversations, non-conversational text are easier to obtain, more diverse and cover a much broader range of topics. We collect a large-scale non-conversational corpus from multi sources including forum comments, idioms and book snippets. We further present a training paradigm to effectively incorporate these text via iterative back translation. The resulting model is tested on two conversational datasets and is shown to produce significantly more diverse responses without sacrificing the relevance with context.</td><td>当涉及到开放域对话生成时，基于神经网络的序列到序列 (seq2seq) 模型严重受到低多样性问题的影响。由于平淡和通用的话语通常在我们的日常聊天中占据频率分布的主导地位，因此避免它们产生更有趣的响应需要复杂的数据过滤、采样技术或修改训练目标。在本文中，我们提出了一个新的视角，通过利用非对话文本来使对话生成多样化。与双边对话相比，非对话文本更容易获取、更多样化并且涵盖的主题范围更广。我们从包括论坛评论、习语和书籍片段在内的多个来源收集了一个大规模的非会话语料库。我们进一步提出了一种训练范式，以通过迭代回译有效地合并这些文本。生成的模型在两个会话数据集上进行了测试，结果表明可以在不牺牲与上下文的相关性的情况下产生更加多样化的响应。</td><td>Hui Su   Xiaoyu Shen   Sanqiang Zhao   Xiao Zhou   Pengwei Hu   Randy Zhong   Cheng Niu   Jie Zhou</td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.09544&#39;]">Grounding Conversations with Improvised Dialogues</a></td><td></td><td><a href="https://github.com/wise-east/spolin">https://github.com/wise-east/spolin</a></td><td><a href="https://arxiv.org/pdf/2004.09544">https://arxiv.org/pdf/2004.09544</a></td><td>Effective dialogue involves grounding, the process of establishing mutual knowledge that is essential for communication between people. Modern dialogue systems are not explicitly trained to build common ground, and therefore overlook this important aspect of communication. Improvisational theater (improv) intrinsically contains a high proportion of dialogue focused on building common ground, and makes use of the yes-and principle, a strong grounding speech act, to establish coherence and an actionable objective reality. We collect a corpus of more than 26,000 yes-and turns, transcribing them from improv dialogues and extracting them from larger, but more sparsely populated movie script dialogue corpora, via a bootstrapped classifier. We fine-tune chit-chat dialogue systems with our corpus to encourage more grounded, relevant conversation and confirm these findings with human evaluations.</td><td>有效的对话涉及基础，即建立相互了解的过程，这对于人与人之间的交流至关重要。现代对话系统没有经过明确训练来建立共同点，因此忽略了沟通的这一重要方面。即兴戏剧 (improv) 本质上包含着大量侧重于建立共同点的对话，并利用是和原则，一种强大的基础言语行为，建立连贯性和可操作的客观现实。我们收集了超过 26,000 个是和转的语料库，从即兴对话中转录它们，并通过自举分类器从更大但人口更稀少的电影剧本对话语料库中提取它们。我们使用我们的语料库微调闲聊对话系统，以鼓励更扎实、相关的对话，并通过人工评估确认这些发现。</td><td>Hyundong Cho   Jonathan May</td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04908&#39;]">Designing Precise and Robust Dialogue Response Evaluators</a></td><td></td><td><a href="https://github.com/ZHAOTING/dialog-processing">https://github.com/ZHAOTING/dialog-processing</a></td><td><a href="https://arxiv.org/pdf/2004.04908">https://arxiv.org/pdf/2004.04908</a></td><td>Automatic dialogue response evaluator has been proposed as an alternative to automated metrics and human evaluation. However, existing automatic evaluators achieve only moderate correlation with human judgement and they are not robust. In this work, we propose to build a reference-free evaluator and exploit the power of semi-supervised training and pretrained (masked) language models. Experimental results demonstrate that the proposed evaluator achieves a strong correlation (&gt; 0.6) with human judgement and generalizes robustly to diverse responses and corpora. We open-source the code and data in <a href="https://github.com/ZHAOTING/dialog-processing">https://github.com/ZHAOTING/dialog-processing</a>.</td><td>自动对话响应评估器已被提议作为自动度量和人工评估的替代方案。然而，现有的自动评估器与人类判断仅实现中等程度的相关性，并且它们并不稳健。在这项工作中，我们建议构建一个无参考评估器，并利用半监督训练和预训练（屏蔽）语言模型的力量。实验结果表明，所提出的评估器与人类判断具有很强的相关性（&gt; 0.6），并且可以稳健地推广到不同的响应和语料库。我们在 <a href="https://github.com/ZHAOTING/dialog-processing">https://github.com/ZHAOTING/dialog-processing</a> 中开源了代码和数据。</td><td>Tianyu Zhao   Divesh Lala   Tatsuya Kawahara</td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.07931&#39;]">PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research">https://github.com/PaddlePaddle/Research</a></td><td><a href="https://arxiv.org/pdf/1910.07931">https://arxiv.org/pdf/1910.07931</a></td><td>Pre-training models have been proved effective for a wide range of natural language processing tasks. Inspired by this, we propose a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering. In this framework, we adopt flexible attention mechanisms to fully leverage the bi-directional context and the uni-directional characteristic of language generation. We also introduce discrete latent variables to tackle the inherent one-to-many mapping problem in response generation. Two reciprocal tasks of response generation and latent act recognition are designed and carried out simultaneously within a shared network. Comprehensive experiments on three publicly available datasets verify the effectiveness and superiority of the proposed framework.</td><td>预训练模型已被证明对广泛的自然语言处理任务有效。受此启发，我们提出了一种新颖的对话生成预训练框架，以支持各种对话，包括闲聊、基于知识的对话和对话问答。在这个框架中，我们采用灵活的注意力机制来充分利用双向上下文和语言生成的单向特性。我们还引入了离散潜在变量来解决响应生成中固有的一对多映射问题。响应生成和潜在行为识别这两个互惠任务是在共享网络中同时设计和执行的。对三个公开可用数据集的综合实验验证了所提出框架的有效性和优越性。</td><td>Siqi Bao   Huang He   Fan Wang   Hua Wu   Haifeng Wang</td></tr><tr><td>21</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00891&#39;]">Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking</a></td><td></td><td><a href="https://github.com/stanford-oval/zero-shot-multiwoz-acl2020">https://github.com/stanford-oval/zero-shot-multiwoz-acl2020</a></td><td><a href="https://arxiv.org/pdf/2005.00891">https://arxiv.org/pdf/2005.00891</a></td><td>Zero-shot transfer learning for multi-domain dialogue state tracking can allow us to handle new domains without incurring the high cost of data acquisition. This paper proposes new zero-short transfer learning technique for dialogue state tracking where the in-domain training data are all synthesized from an abstract dialogue model and the ontology of the domain. We show that data augmentation through synthesized data can improve the accuracy of zero-shot learning for both the TRADE model and the BERT-based SUMBT model on the MultiWOZ 2.1 dataset. We show training with only synthesized in-domain data on the SUMBT model can reach about 2/3 of the accuracy obtained with the full training dataset. We improve the zero-shot learning state of the art on average across domains by 21%.</td><td>用于多域对话状态跟踪的零样本迁移学习可以让我们处理新域，而不会产生高昂的数据采集成本。本文提出了新的用于对话状态跟踪的零短转移学习技术，其中域内训练数据全部由抽象对话模型和域本体合成。我们表明，通过合成数据进行数据增强可以提高 MultiWOZ 2.1 数据集上的 TRADE 模型和基于 BERT 的 SUMBT 模型的零样本学习的准确性。我们表明，仅在 SUMBT 模型上使用合成的域内数据进行训练可以达到使用完整训练数据集获得的准确度的 2/3 左右。我们将跨领域的零样本学习技术平均提高了 21%。</td><td>Giovanni Campagna   Agata Foryciarz   Mehrad Moradshahi   Monica S. Lam</td></tr><tr><td>22</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.03809&#39;]">Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward Decomposition</a></td><td></td><td><a href="https://github.com/truthless11/MADPL">https://github.com/truthless11/MADPL</a></td><td><a href="https://arxiv.org/pdf/2004.03809">https://arxiv.org/pdf/2004.03809</a></td><td>Many studies have applied reinforcement learning to train a dialog policy and show great promise these years. One common approach is to employ a user simulator to obtain a large number of simulated user experiences for reinforcement learning algorithms. However, modeling a realistic user simulator is challenging. A rule-based simulator requires heavy domain expertise for complex tasks, and a data-driven simulator requires considerable data and it is even unclear how to evaluate a simulator. To avoid explicitly building a user simulator beforehand, we propose Multi-Agent Dialog Policy Learning, which regards both the system and the user as the dialog agents. Two agents interact with each other and are jointly learned simultaneously. The method uses the actor-critic framework to facilitate pretraining and improve scalability. We also propose Hybrid Value Network for the role-aware reward decomposition to integrate role-specific domain knowledge of each agent in the task-oriented dialog. Results show that our method can successfully build a system policy and a user policy simultaneously, and two agents can achieve a high task success rate through conversational interaction.</td><td>许多研究已经应用强化学习来训练对话策略，并且这些年来显示出巨大的希望。一种常见的方法是使用用户模拟器为强化学习算法获取大量模拟用户体验。然而，对真实的用户模拟器建模是具有挑战性的。基于规则的模拟器需要大量的领域专业知识来处理复杂的任务，而数据驱动的模拟器需要大量数据，甚至不清楚如何评估模拟器。为了避免事先明确构建用户模拟器，我们提出了多代理对话策略学习，它将系统和用户都视为对话代理。两个代理相互交互并同时共同学习。该方法使用 actor-critic 框架来促进预训练并提高可扩展性。我们还提出了用于角色感知奖励分解的混合价值网络，以在面向任务的对话中集成每个代理的特定于角色的领域知识。结果表明，我们的方法可以成功地同时构建系统策略和用户策略，并且两个代理可以通过对话交互实现较高的任务成功率。</td><td>Ryuichi Takanobu   Runze Liang   Minlie Huang</td></tr><tr><td>23</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.03954&#39;]">Towards Conversational Recommendation over Multi-Type Dialogs</a></td><td></td><td><a href="https://github.com/PaddlePaddle/models">https://github.com/PaddlePaddle/models</a></td><td><a href="https://arxiv.org/pdf/2005.03954">https://arxiv.org/pdf/2005.03954</a></td><td>We propose a new task of conversational recommendation over multi-type dialogs, where the bots can proactively and naturally lead a conversation from a non-recommendation dialog (e.g., QA) to a recommendation dialog, taking into account user’s interests and feedback. To facilitate the study of this task, we create a human-to-human Chinese dialog dataset \emph{DuRecDial} (about 10k dialogs, 156k utterances), which contains multiple sequential dialogs for every pair of a recommendation seeker (user) and a recommender (bot). In each dialog, the recommender proactively leads a multi-type dialog to approach recommendation targets and then makes multiple recommendations with rich interaction behavior. This dataset allows us to systematically investigate different parts of the overall problem, e.g., how to naturally lead a dialog, how to interact with users for recommendation. Finally we establish baseline results on DuRecDial for future studies. Dataset and codes are publicly available at <a href="https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2020-DuRecDial">https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2020-DuRecDial</a>.</td><td>我们提出了多类型对话的对话推荐新任务，其中机器人可以主动且自然地将对话从非推荐对话（例如 QA）引导到推荐对话，同时考虑到用户的兴趣和反馈。为了促进这项任务的研究，我们创建了一个人对人的中文对话数据集 \emph{DuRecDial}（大约 10k 个对话，156k 个话语），其中包含每对推荐搜索者（用户）和一个推荐人（机器人）。在每个对话中，推荐者主动引导多类型对话接近推荐目标，然后做出具有丰富交互行为的多重推荐。该数据集允许我们系统地调查整个问题的不同部分，例如，如何自然地引导对话，如何与用户交互以进行推荐。最后，我们在 DuRecDial 上建立基线结果以供未来研究。数据集和代码可在 <a href="https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2020-DuRecDial">https://github.com/PaddlePaddle/models/tree/develop/PaddleNLP/Research/ACL2020-DuRecDial</a> 公开获得。</td><td>Zeming Liu   Haifeng Wang   Zheng-Yu Niu   Hua Wu   Wanxiang Che   Ting Liu</td></tr><tr><td>24</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04100&#39;]">KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation</a></td><td></td><td><a href="https://github.com/thu-coai/KdConv">https://github.com/thu-coai/KdConv</a></td><td><a href="https://arxiv.org/pdf/2004.04100">https://arxiv.org/pdf/2004.04100</a></td><td>The research of knowledge-driven conversational systems is largely limited due to the lack of dialog data which consist of multi-turn conversations on multiple topics and with knowledge annotations. In this paper, we propose a Chinese multi-domain knowledge-driven conversation dataset, KdConv, which grounds the topics in multi-turn conversations to knowledge graphs. Our corpus contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. These conversations contain in-depth discussions on related topics and natural transition between multiple topics. To facilitate the following research on this corpus, we provide several benchmark models. Comparative results show that the models can be enhanced by introducing background knowledge, yet there is still a large space for leveraging knowledge to model multi-turn conversations for further research. Results also show that there are obvious performance differences between different domains, indicating that it is worth to further explore transfer learning and domain adaptation. The corpus and benchmark models are publicly available.</td><td>由于缺乏由多个主题的多轮对话和知识注释组成的对话数据，知识驱动的对话系统的研究在很大程度上受到限制。在本文中，我们提出了一个中文多领域知识驱动对话数据集 KdConv，它将多轮对话中的主题基于知识图谱。我们的语料库包含来自三个领域（电影、音乐和旅行）的 4.5K 对话和 86K 话语，平均轮数为 19.0。这些对话包含对相关主题的深入讨论以及多个主题之间的自然过渡。为了便于对该语料库的后续研究，我们提供了几个基准模型。对比结果表明，可以通过引入背景知识来增强模型，但利用知识对多轮对话进行建模以供进一步研究仍有很大的空间。结果还表明，不同领域之间存在明显的性能差异，表明值得进一步探索迁移学习和领域适应。语料库和基准模型是公开的。</td><td>Hao Zhou   Chujie Zheng   Kaili Huang   Minlie Huang   Xiaoyan Zhu</td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.08854&#39;]">Incremental Transformer with Deliberation Decoder for Document Grounded Conversations</a></td><td></td><td><a href="https://github.com/lizekang/ITDD">https://github.com/lizekang/ITDD</a></td><td><a href="https://arxiv.org/pdf/1907.08854">https://arxiv.org/pdf/1907.08854</a></td><td>Document Grounded Conversations is a task to generate dialogue responses when chatting about the content of a given document. Obviously, document knowledge plays a critical role in Document Grounded Conversations, while existing dialogue models do not exploit this kind of knowledge effectively enough. In this paper, we propose a novel Transformer-based architecture for multi-turn document grounded conversations. In particular, we devise an Incremental Transformer to encode multi-turn utterances along with knowledge in related documents. Motivated by the human cognitive process, we design a two-pass decoder (Deliberation Decoder) to improve context coherence and knowledge correctness. Our empirical study on a real-world Document Grounded Dataset proves that responses generated by our model significantly outperform competitive baselines on both context coherence and knowledge relevance.</td><td>Document Grounded Conversations 是一项在讨论给定文档的内容时生成对话响应的任务。显然，文档知识在基于文档的对话中起着至关重要的作用，而现有的对话模型并没有足够有效地利用这种知识。在本文中，我们提出了一种新颖的基于 Transformer 的架构，用于多轮文档基础对话。特别是，我们设计了一个增量转换器来编码多轮话语以及相关文档中的知识。受人类认知过程的启发，我们设计了一个两遍解码器（Deliberation Decoder）来提高上下文的一致性和知识的正确性。我们对真实世界文档接地数据集的实证研究证明，我们的模型生成的响应在上下文一致性和知识相关性方面都显着优于竞争基准。</td><td>Zekang Li   Cheng Niu   Fandong Meng   Yang Feng   Qian Li   Jie Zhou</td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.05373&#39;]">E3: Entailment-driven Extracting and Editing for Conversational Machine Reading</a></td><td></td><td><a href="https://github.com/vzhong/e3">https://github.com/vzhong/e3</a></td><td><a href="https://arxiv.org/pdf/1906.05373">https://arxiv.org/pdf/1906.05373</a></td><td>Conversational machine reading systems help users answer high-level questions (e.g. determine if they qualify for particular government benefits) when they do not know the exact rules by which the determination is made(e.g. whether they need certain income levels or veteran status). The key challenge is that these rules are only provided in the form of a procedural text (e.g. guidelines from government website) which the system must read to figure out what to ask the user. We present a new conversational machine reading model that jointly extracts a set of decision rules from the procedural text while reasoning about which are entailed by the conversational history and which still need to be edited to create questions for the user. On the recently introduced ShARC conversational machine reading dataset, our Entailment-driven Extract and Edit network (E3) achieves a new state-of-the-art, outperforming existing systems as well as a new BERT-based baseline. In addition, by explicitly highlighting which information still needs to be gathered, E3 provides a more explainable alternative to prior work. We release source code for our models and experiments at <a href="https://github.com/vzhong/e3">https://github.com/vzhong/e3</a>.</td><td>当用户不知道做出决定的确切规则（例如，他们是否需要某些收入水平或退伍军人身份）时，对话式机器阅读系统可帮助用户回答高级问题（例如，确定他们是否有资格获得特定的政府福利）。关键的挑战在于，这些规则仅以程序文本的形式提供（例如政府网站上的指南），系统必须阅读这些文本才能弄清楚要问用户什么。我们提出了一种新的对话机器阅读模型，该模型从程序文本中联合提取一组决策规则，同时推理对话历史所包含的哪些规则以及哪些仍需要编辑以为用户创建问题。在最近推出的 ShARC 对话式机器阅读数据集上，我们的 Entailment-driven 提取和编辑网络 (E3) 实现了新的最先进的技术，优于现有系统以及新的基于 BERT 的基线。此外，通过明确突出显示哪些信息仍需要收集，E3 为之前的工作提供了一个更易于解释的替代方案。我们在 <a href="https://github.com/vzhong/e3">https://github.com/vzhong/e3</a> 上发布了我们的模型和实验的源代码。</td><td>Victor Zhong   Luke Zettlemoyer</td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.07004&#39;]">Improving Multi-turn Dialogue Modelling with Utterance ReWriter</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.07004">https://arxiv.org/pdf/1906.07004</a></td><td>Recent research has made impressive progress in single-turn dialogue modelling. In the multi-turn setting, however, current models are still far from satisfactory. One major challenge is the frequently occurred coreference and information omission in our daily conversation, making it hard for machines to understand the real intention. In this paper, we propose rewriting the human utterance as a pre-process to help multi-turn dialgoue modelling. Each utterance is first rewritten to recover all coreferred and omitted information. The next processing steps are then performed based on the rewritten utterance. To properly train the utterance rewriter, we collect a new dataset with human annotations and introduce a Transformer-based utterance rewriting architecture using the pointer network. We show the proposed architecture achieves remarkably good performance on the utterance rewriting task. The trained utterance rewriter can be easily integrated into online chatbots and brings general improvement over different domains.</td><td></td><td>Hui Su   Xiaoyu Shen   Rongzhi Zhang   Fei Sun   Pengwei Hu   Cheng Niu   Jie Zhou</td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.12866&#39;]">Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</a></td><td></td><td><a href="https://github.com/wenhuchen/HDSA-Dialog">https://github.com/wenhuchen/HDSA-Dialog</a></td><td><a href="https://arxiv.org/pdf/1905.12866">https://arxiv.org/pdf/1905.12866</a></td><td>Semantically controlled neural response generation on limited-domain has achieved great performance. However, moving towards multi-domain large-scale scenarios are shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the graph. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the large-scale Multi-Domain-WOZ dataset, our model can yield a significant improvement over the baselines on various automatic and human evaluation metrics.</td><td>在有限域上语义控制的神经响应生成已经取得了很好的性能。然而，由于语义输入的可能组合随着域的数量呈指数增长，因此转向多域大规模场景是很困难的。为了缓解这种可扩展性问题，我们利用对话行为的结构来构建多层分层图，其中每个行为在图上表示为从根到叶的路线。然后，我们将这种先验图结构作为归纳偏置来构建分层解缠结的自注意力网络，在其中我们解开注意力头以模拟对话行为图上的指定节点。通过在每一层激活不同的（解开的）头，可以组合地对许多对话行为语义进行建模以控制神经响应的生成。在大规模多域 WOZ 数据集上，我们的模型可以在各种自动和人工评估指标的基线上产生显着改进。</td><td>Wenhu Chen   Jianshu Chen   Pengda Qin   Xifeng Yan   William Yang Wang</td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.00326&#39;]">Observing Dialogue in Therapy: Categorizing and Forecasting Behavioral Codes</a></td><td></td><td><a href="https://github.com/utahnlp/therapist-observer">https://github.com/utahnlp/therapist-observer</a></td><td><a href="https://arxiv.org/pdf/1907.00326">https://arxiv.org/pdf/1907.00326</a></td><td>Automatically analyzing dialogue can help understand and guide behavior in domains such as counseling, where interactions are largely mediated by conversation. In this paper, we study modeling behavioral codes used to asses a psychotherapy treatment style called Motivational Interviewing (MI), which is effective for addressing substance abuse and related problems. Specifically, we address the problem of providing real-time guidance to therapists with a dialogue observer that (1) categorizes therapist and client MI behavioral codes and, (2) forecasts codes for upcoming utterances to help guide the conversation and potentially alert the therapist. For both tasks, we define neural network models that build upon recent successes in dialogue modeling. Our experiments demonstrate that our models can outperform several baselines for both tasks. We also report the results of a careful analysis that reveals the impact of the various network design tradeoffs for modeling therapy dialogue.</td><td>自动分析对话可以帮助理解和指导咨询等领域的行为，在这些领域，互动主要通过对话进行。在本文中，我们研究了用于评估称为动机访谈 (MI) 的心理治疗治疗方式的行为代码建模，该方式可有效解决药物滥用和相关问题。具体来说，我们解决了通过对话观察员向治疗师提供实时指导的问题，该对话观察员 (1) 对治疗师和客户 MI 行为代码进行分类，以及 (2) 预测即将出现的话语的代码，以帮助指导对话并可能提醒治疗师。对于这两个任务，我们定义了建立在对话建模最近成功基础上的神经网络模型。我们的实验表明，我们的模型在这两个任务上都可以胜过几个基线。我们还报告了仔细分析的结果，揭示了各种网络设计权衡对建模治疗对话的影响。</td><td>Jie Cao   Michael Tanana   Zac E. Imel   Eric Poitras   David C. Atkins   Vivek Srikumar</td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.01166&#39;]">Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems</a></td><td></td><td><a href="https://github.com/henryhungle/MTN">https://github.com/henryhungle/MTN</a></td><td><a href="https://arxiv.org/pdf/1907.01166">https://arxiv.org/pdf/1907.01166</a></td><td>Developing Video-Grounded Dialogue Systems (VGDS), where a dialogue is conducted based on visual and audio aspects of a given video, is significantly more challenging than traditional image or text-grounded dialogue systems because (1) feature space of videos span across multiple picture frames, making it difficult to obtain semantic information; and (2) a dialogue agent must perceive and process information from different modalities (audio, video, caption, etc.) to obtain a comprehensive understanding. Most existing work is based on RNNs and sequence-to-sequence architectures, which are not very effective for capturing complex long-term dependencies (like in videos). To overcome this, we propose Multimodal Transformer Networks (MTN) to encode videos and incorporate information from different modalities. We also propose query-aware attention through an auto-encoder to extract query-aware features from non-text modalities. We develop a training procedure to simulate token-level decoding to improve the quality of generated responses during inference. We get state of the art performance on Dialogue System Technology Challenge 7 (DSTC7). Our model also generalizes to another multimodal visual-grounded dialogue task, and obtains promising performance. We implemented our models using PyTorch and the code is released at <a href="https://github.com/henryhungle/MTN">https://github.com/henryhungle/MTN</a>.</td><td>开发基于视频的对话系统 (VGDS)，其中基于给定视频的视觉和音频方面进行对话，比传统的图像或文本对话系统更具挑战性，因为 (1) 视频的特征空间跨越多个图片框，语义信息获取困难； (2) 对话代理必须感知和处理来自不同形式（音频、视频、字幕等）的信息，以获得全面的理解。大多数现有工作基于 RNN 和序列到序列架构，这对于捕获复杂的长期依赖关系（如视频）不是很有效。为了克服这个问题，我们提出了多模态变压器网络 (MTN) 来编码视频并合并来自不同模态的信息。我们还通过自动编码器提出了查询感知注意力，以从非文本模式中提取查询感知特征。我们开发了一个训练程序来模拟令牌级解码，以提高推理过程中生成响应的质量。我们在对话系统技术挑战 7 (DSTC7) 上获得了最先进的性能。我们的模型还推广到另一个多模态基于视觉的对话任务，并获得了有希望的性能。我们使用 PyTorch 实现了我们的模型，代码发布在 <a href="https://github.com/henryhungle/MTN。">https://github.com/henryhungle/MTN。</a></td><td>Hung Le   Doyen Sahoo   Nancy F. Chen   Steven C. H. Hoi</td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.06725&#39;]">Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good</a></td><td></td><td><a href="https://gitlab.com/ucdavisnlp/persuasionforgood">https://gitlab.com/ucdavisnlp/persuasionforgood</a></td><td><a href="https://arxiv.org/pdf/1906.06725">https://arxiv.org/pdf/1906.06725</a></td><td>Developing intelligent persuasive conversational agents to change people’s opinions and actions for social good is the frontier in advancing the ethical development of automated dialogue systems. To do so, the first step is to understand the intricate organization of strategic disclosures and appeals employed in human persuasion conversations. We designed an online persuasion task where one participant was asked to persuade the other to donate to a specific charity. We collected a large dataset with 1,017 dialogues and annotated emerging persuasion strategies from a subset. Based on the annotation, we built a baseline classifier with context information and sentence-level features to predict the 10 persuasion strategies used in the corpus. Furthermore, to develop an understanding of personalized persuasion processes, we analyzed the relationships between individuals’ demographic and psychological backgrounds including personality, morality, value systems, and their willingness for donation. Then, we analyzed which types of persuasion strategies led to a greater amount of donation depending on the individuals’ personal backgrounds. This work lays the ground for developing a personalized persuasive dialogue system.</td><td>开发智能的有说服力的对话代理来改变人们的意见和行为以促进社会利益是推进自动对话系统伦理发展的前沿。为此，第一步是了解人类说服对话中采用的战略披露和呼吁的复杂组织。我们设计了一项在线说服任务，要求一名参与者说服另一名参与者向特定慈善机构捐款。我们收集了一个包含 1,017 个对话的大型数据集，并从一个子集中注释了新兴的说服策略。基于注释，我们构建了一个具有上下文信息和句子级特征的基线分类器，以预测语料库中使用的 10 种说服策略。此外，为了了解个性化说服过程，我们分析了个人的人口统计学和心理背景之间的关系，包括个性、道德、价值体系和他们的捐赠意愿。然后，我们根据个人的个人背景分析了哪些类型的说服策略会导致更多的捐赠。这项工作为开发个性化的说服性对话系统奠定了基础。</td><td>Xuewei Wang   Weiyan Shi   Richard Kim   Yoojung Oh   Sijia Yang   Jingwen Zhang   Zhou Yu</td></tr></tbody></table></div><h3 id="EMNLP-1"><a href="#EMNLP-1" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.09378&#39;]">Difference-aware Knowledge Selection for Knowledge-grounded Conversation Generation</a></td><td></td><td><a href="https://github.com/chujiezheng/DiffKS">https://github.com/chujiezheng/DiffKS</a></td><td><a href="https://arxiv.org/pdf/2009.09378">https://arxiv.org/pdf/2009.09378</a></td><td>In a multi-turn knowledge-grounded dialog, the difference between the knowledge selected at different turns usually provides potential clues to knowledge selection, which has been largely neglected in previous research. In this paper, we propose a difference-aware knowledge selection method. It first computes the difference between the candidate knowledge sentences provided at the current turn and those chosen in the previous turns. Then, the differential information is fused with or disentangled from the contextual information to facilitate final knowledge selection. Automatic, human observational, and interactive evaluation shows that our method is able to select knowledge more accurately and generate more informative responses, significantly outperforming the state-of-the-art baselines. The codes are available at <a href="https://github.com/chujiezheng/DiffKS">https://github.com/chujiezheng/DiffKS</a>.</td><td>在多轮基于知识的对话中，不同轮选择的知识之间的差异通常为知识选择提供了潜在的线索，而这在以前的研究中被很大程度上忽略了。在本文中，我们提出了一种差异感知知识选择方法。它首先计算当前回合提供的候选知识句子与前一回合选择的候选知识句子之间的差异。然后，差异信息与上下文信息融合或分离，以促进最终的知识选择。自动、人工观察和交互式评估表明，我们的方法能够更准确地选择知识并生成更多信息响应，显着优于最先进的基线。代码可在 <a href="https://github.com/chujiezeng/DiffKS">https://github.com/chujiezeng/DiffKS</a> 获得。</td><td>Chujie Zheng   Yunbo Cao   Daxin Jiang   Minlie Huang</td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12328&#39;]">Few-shot Natural Language Generation for Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/pengbaolin/SC-GPT">https://github.com/pengbaolin/SC-GPT</a></td><td><a href="https://arxiv.org/pdf/2002.12328">https://arxiv.org/pdf/2002.12328</a></td><td>As a crucial component in task-oriented dialog systems, the Natural Language Generation (NLG) module converts a dialog act represented in a semantic form into a response in natural language. The success of traditional template-based or statistical models typically relies on heavily annotated data, which is infeasible for new domains. Therefore, it is pivotal for an NLG system to generalize well with limited labelled data in real applications. To this end, we present FewShotWoz, the first NLG benchmark to simulate the few-shot learning setting in task-oriented dialog systems. Further, we develop the SC-GPT model. It is pre-trained on a large set of annotated NLG corpus to acquire the controllable generation ability, and fine-tuned with only a few domain-specific labels to adapt to new domains. Experiments on FewShotWoz and the large Multi-Domain-WOZ datasets show that the proposed SC-GPT significantly outperforms existing methods, measured by various automatic metrics and human evaluations.</td><td>作为面向任务的对话系统中的重要组成部分，自然语言生成 (NLG) 模块将以语义形式表示的对话行为转换为自然语言的响应。传统的基于模板或统计模型的成功通常依赖于大量注释的数据，这对于新领域是不可行的。因此，NLG 系统在实际应用中利用有限的标记数据很好地泛化是至关重要的。为此，我们提出了FewShotWoz，这是第一个在面向任务的对话系统中模拟小样本学习设置的NLG 基准测试。此外，我们开发了 SC-GPT 模型。它在大量带注释的 NLG 语料库上进行预训练以获得可控生成能力，并仅使用少数特定领域的标签进行微调以适应新领域。在FewShotWoz 和大型Multi-Domain-WOZ 数据集上的实验表明，所提出的SC-GPT 显着优于现有方法，通过各种自动指标和人工评估来衡量。</td><td>Baolin Peng   Chenguang Zhu   Chunyuan Li   Xiujun Li   Jinchao Li   Michael Zeng   Jianfeng Gao</td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.13656&#39;]">Learning Knowledge Bases with Parameters for Task-Oriented Dialogue Systems</a></td><td></td><td><a href="https://github.com/HLTCHKUST/ke-dialogue">https://github.com/HLTCHKUST/ke-dialogue</a></td><td><a href="https://arxiv.org/pdf/2009.13656">https://arxiv.org/pdf/2009.13656</a></td><td>Task-oriented dialogue systems are either modularized with separate dialogue state tracking (DST) and management steps or end-to-end trainable. In either case, the knowledge base (KB) plays an essential role in fulfilling user requests. Modularized systems rely on DST to interact with the KB, which is expensive in terms of annotation and inference time. End-to-end systems use the KB directly as input, but they cannot scale when the KB is larger than a few hundred entries. In this paper, we propose a method to embed the KB, of any size, directly into the model parameters. The resulting model does not require any DST or template responses, nor the KB as input, and it can dynamically update its KB via fine-tuning. We evaluate our solution in five task-oriented dialogue datasets with small, medium, and large KB size. Our experiments show that end-to-end models can effectively embed knowledge bases in their parameters and achieve competitive performance in all evaluated datasets.</td><td>面向任务的对话系统要么采用单独的对话状态跟踪 (DST) 和管理步骤进行模块化，要么采用端到端可训练。无论哪种情况，知识库 (KB) 在满足用户请求方面都起着至关重要的作用。模块化系统依赖 DST 与 KB 交互，这在注释和推理时间方面很昂贵。端到端系统直接使用 KB 作为输入，但当 KB 大于几百个条目时，它们无法扩展。在本文中，我们提出了一种将任意大小的知识库直接嵌入模型参数的方法。生成的模型不需要任何 DST 或模板响应，也不需要 KB 作为输入，并且可以通过微调动态更新其 KB。我们在具有小、中和大 KB 大小的五个面向任务的对话数据集中评估我们的解决方案。我们的实验表明，端到端模型可以有效地将知识库嵌入其参数中，并在所有评估数据集中实现具有竞争力的性能。</td><td>Andrea Madotto   Samuel Cahyawijaya   Genta Indra Winata   Yan Xu   Zihan Liu   Zhaojiang Lin   Pascale Fung</td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04344&#39;]">Plug-and-Play Conversational Models</a></td><td></td><td><a href="https://github.com/andreamad8/PPCM">https://github.com/andreamad8/PPCM</a></td><td><a href="https://arxiv.org/pdf/2010.04344">https://arxiv.org/pdf/2010.04344</a></td><td>There has been considerable progress made towards conversational models that generate coherent and fluent responses; however, this often involves training large language models on large dialogue datasets, such as Reddit. These large conversational models provide little control over the generated responses, and this control is further limited in the absence of annotated conversational datasets for attribute specific generation that can be used for fine-tuning the model. In this paper, we first propose and evaluate plug-and-play methods for controllable response generation, which does not require dialogue specific datasets and does not rely on fine-tuning a large model. While effective, the decoding procedure induces considerable computational overhead, rendering the conversational model unsuitable for interactive usage. To overcome this, we introduce an approach that does not require further computation at decoding time, while also does not require any fine-tuning of a large language model. We demonstrate, through extensive automatic and human evaluation, a high degree of control over the generated conversational responses with regard to multiple desired attributes, while being fluent.</td><td>在产生连贯和流畅反应的对话模型方面取得了相当大的进展；然而，这通常涉及在大型对话数据集（例如 Reddit）上训练大型语言模型。这些大型对话模型对生成的响应几乎没有控制，并且这种控制在缺少可用于微调模型的特定属性生成的带注释对话数据集的情况下进一步受到限制。在本文中，我们首先提出并评估了用于可控响应生成的即插即用方法，该方法不需要对话特定的数据集，也不依赖于对大型模型进行微调。虽然有效，但解码过程会引起相当大的计算开销，使会话模型不适合交互式使用。为了克服这个问题，我们引入了一种在解码时不需要进一步计算的方法，同时也不需要对大型语言模型进行任何微调。我们通过广泛的自动和人工评估展示了对生成的关于多个所需属性的对话响应的高度控制，同时流畅。</td><td>Andrea Madotto   Etsuko Ishii   Zhaojiang Lin   Sumanth Dathathri   Pascale Fung</td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02795&#39;]">COSMIC: COmmonSense knowledge for eMotion Identification in Conversations</a></td><td></td><td><a href="https://github.com/declare-lab/conv-emotion">https://github.com/declare-lab/conv-emotion</a></td><td><a href="https://arxiv.org/pdf/2010.02795">https://arxiv.org/pdf/2010.02795</a></td><td>In this paper, we address the task of utterance level emotion recognition in conversations using commonsense knowledge. We propose COSMIC, a new framework that incorporates different elements of commonsense such as mental states, events, and causal relations, and build upon them to learn interactions between interlocutors participating in a conversation. Current state-of-the-art methods often encounter difficulties in context propagation, emotion shift detection, and differentiating between related emotion classes. By learning distinct commonsense representations, COSMIC addresses these challenges and achieves new state-of-the-art results for emotion recognition on four different benchmark conversational datasets. Our code is available at <a href="https://github.com/declare-lab/conv-emotion">https://github.com/declare-lab/conv-emotion</a>.</td><td>在本文中，我们使用常识知识解决对话中话语级情感识别的任务。我们提出了 COSMIC，这是一个新框架，它结合了不同的常识元素，例如心理状态、事件和因果关系，并以此为基础来学习参与对话的对话者之间的互动。当前最先进的方法在上下文传播、情感转移检测和相关情感类别之间的区分方面经常遇到困难。通过学习不同的常识表示，COSMIC 解决了这些挑战，并在四个不同的基准会话数据集上实现了情感识别的最新结果。我们的代码可在 <a href="https://github.com/declare-lab/conv-emotion">https://github.com/declare-lab/conv-emotion</a> 获得。</td><td>Deepanway Ghosal   Navonil Majumder   Alexander Gelbukh   Rada Mihalcea   Soujanya Poria</td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.03755&#39;]">Generalizable and Explainable Dialogue Generation via Explicit Action Learning</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.03755">https://arxiv.org/pdf/2010.03755</a></td><td>Response generation for task-oriented dialogues implicitly optimizes two objectives at the same time: task completion and language quality. Conditioned response generation serves as an effective approach to separately and better optimize these two objectives. Such an approach relies on system action annotations which are expensive to obtain. To alleviate the need of action annotations, latent action learning is introduced to map each utterance to a latent representation. However, this approach is prone to over-dependence on the training data, and the generalization capability is thus restricted. To address this issue, we propose to learn natural language actions that represent utterances as a span of words. This explicit action representation promotes generalization via the compositional structure of language. It also enables an explainable generation process. Our proposed unsupervised approach learns a memory component to summarize system utterances into a short span of words. To further promote a compact action representation, we propose an auxiliary task that restores state annotations as the summarized dialogue context using the memory component. Our proposed approach outperforms latent action baselines on MultiWOZ, a benchmark multi-domain dataset.</td><td>面向任务的对话的响应生成同时隐式优化了两个目标：任务完成和语言质量。条件反应生成是分别和更好地优化这两个目标的有效方法。这种方法依赖于获取昂贵的系统动作注释。为了减轻对动作注释的需要，引入了潜在动作学习以将每个话语映射到潜在表示。然而，这种方法容易过度依赖训练数据，从而限制了泛化能力。为了解决这个问题，我们建议学习将话语表示为单词跨度的自然语言动作。这种显式的动作表示通过语言的组合结构促进了泛化。它还支持可解释的生成过程。我们提出的无监督方法学习了一个记忆组件，将系统的话语概括为一个短的单词跨度。为了进一步促进紧凑的动作表示，我们提出了一个辅助任务，该任务使用记忆组件将状态注释恢复为汇总的对话上下文。我们提出的方法优于基准多域数据集 MultiWOZ 上的潜在动作基线。</td><td>Xinting Huang   Jianzhong Qi   Yu Sun   Rui Zhang</td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.02260&#39;]">Effects of Naturalistic Variation in Goal-Oriented Dialog</a></td><td></td><td><a href="https://github.com/IBM/naturalistic-variation-goal-oriented-dialog-datasets">https://github.com/IBM/naturalistic-variation-goal-oriented-dialog-datasets</a></td><td><a href="https://arxiv.org/pdf/2010.02260">https://arxiv.org/pdf/2010.02260</a></td><td>Existing benchmarks used to evaluate the performance of end-to-end neural dialog systems lack a key component: natural variation present in human conversations. Most datasets are constructed through crowdsourcing, where the crowd workers follow a fixed template of instructions while enacting the role of a user/agent. This results in straight-forward, somewhat routine, and mostly trouble-free conversations, as crowd workers do not think to represent the full range of actions that occur naturally with real users. In this work, we investigate the impact of naturalistic variation on two goal-oriented datasets: bAbI dialog task and Stanford Multi-Domain Dataset (SMD). We also propose new and more effective testbeds for both datasets, by introducing naturalistic variation by the user. We observe that there is a significant drop in performance (more than 60% in Ent. F1 on SMD and 85% in per-dialog accuracy on bAbI task) of recent state-of-the-art end-to-end neural methods such as BossNet and GLMP on both datasets.</td><td>用于评估端到端神经对话系统性能的现有基准缺乏一个关键组成部分：人类对话中存在的自然变化。大多数数据集是通过众包构建的，众包工作人员在扮演用户/代理角色的同时遵循固定的指令模板。这导致了直接的、有点常规的、并且大部分是无故障的对话，因为人群工作人员并不认为代表真实用户自然发生的全部动作。在这项工作中，我们研究了自然变化对两个面向目标的数据集的影响：bAbI 对话任务和斯坦福多域数据集 (SMD)。我们还通过引入用户的自然变化，为这两个数据集提出了新的、更有效的测试平台。我们观察到，最近最先进的端到端神经方法的性能显着下降（SMD 上的 Ent.F1 超过 60%，bAbI 任务的每个对话准确度下降了 85%），例如作为两个数据集上的 BossNet 和 GLMP。</td><td>Jatin Ganhotra   Robert Moore   Sachindra Joshi   Kahini Wadhawan</td></tr><tr><td>8</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11540&#39;]">DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation</a></td><td></td><td><a href="https://github.com/SenticNet/conv-emotion">https://github.com/SenticNet/conv-emotion</a></td><td><a href="https://arxiv.org/pdf/1908.11540">https://arxiv.org/pdf/1908.11540</a></td><td>Emotion recognition in conversation (ERC) has received much attention, lately, from researchers due to its potential widespread applications in diverse areas, such as health-care, education, and human resources. In this paper, we present Dialogue Graph Convolutional Network (DialogueGCN), a graph neural network based approach to ERC. We leverage self and inter-speaker dependency of the interlocutors to model conversational context for emotion recognition. Through the graph network, DialogueGCN addresses context propagation issues present in the current RNN-based methods. We empirically show that this method alleviates such issues, while outperforming the current state of the art on a number of benchmark emotion classification datasets.</td><td></td><td>Deepanway Ghosal   Navonil Majumder   Soujanya Poria   Niyati Chhaya   Alexander Gelbukh</td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11546&#39;]">Modeling Multi-Action Policy for Task-Oriented Dialogues</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1908.11546">https://arxiv.org/pdf/1908.11546</a></td><td>Dialogue management (DM) plays a key role in the quality of the interaction with the user in a task-oriented dialogue system. In most existing approaches, the agent predicts only one DM policy action per turn. This significantly limits the expressive power of the conversational agent and introduces unwanted turns of interactions that may challenge users’ patience. Longer conversations also lead to more errors and the system needs to be more robust to handle them. In this paper, we compare the performance of several models on the task of predicting multiple acts for each turn. A novel policy model is proposed based on a recurrent cell called gated Continue-Act-Slots (gCAS) that overcomes the limitations of the existing models. Experimental results show that gCAS outperforms other approaches. The code is available at <a href="https://leishu02.github.io/">https://leishu02.github.io/</a></td><td>在面向任务的对话系统中，对话管理 (DM) 在与用户交互的质量中起着关键作用。在大多数现有方法中，代理每回合仅预测一个 DM 策略操作。这显着限制了对话代理的表达能力，并引入了可能挑战用户耐心的不必要的交互转变。更长的对话也会导致更多的错误，系统需要更强大来处理它们。在本文中，我们比较了几种模型在预测每个回合的多个动作的任务上的性能。基于称为门控Continue-Act-Slots（gCAS）的循环单元提出了一种新颖的策略模型，该模型克服了现有模型的局限性。实验结果表明，gCAS 优于其他方法。代码可在 <a href="https://leishu02.github.io/">https://leishu02.github.io/</a> 获得</td><td>Lei Shu   Hu Xu   Bing Liu   Piero Molino</td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.12868&#39;]">Automatically Learning Data Augmentation Policies for Dialogue Tasks</a></td><td></td><td><a href="https://github.com/WolfNiu/AutoAugDialogue">https://github.com/WolfNiu/AutoAugDialogue</a></td><td><a href="https://arxiv.org/pdf/1909.12868">https://arxiv.org/pdf/1909.12868</a></td><td>Automatic data augmentation (AutoAugment) (Cubuk et al., 2019) searches for optimal perturbation policies via a controller trained using performance rewards of a sampled policy on the target task, hence reducing data-level model bias. While being a powerful algorithm, their work has focused on computer vision tasks, where it is comparatively easy to apply imperceptible perturbations without changing an image’s semantic meaning. In our work, we adapt AutoAugment to automatically discover effective perturbation policies for natural language processing (NLP) tasks such as dialogue generation. We start with a pool of atomic operations that apply subtle semantic-preserving perturbations to the source inputs of a dialogue task (e.g., different POS-tag types of stopword dropout, grammatical errors, and paraphrasing). Next, we allow the controller to learn more complex augmentation policies by searching over the space of the various combinations of these atomic operations. Moreover, we also explore conditioning the controller on the source inputs of the target task, since certain strategies may not apply to inputs that do not contain that strategy’s required linguistic features. Empirically, we demonstrate that both our input-agnostic and input-aware controllers discover useful data augmentation policies, and achieve significant improvements over the previous state-of-the-art, including trained on manually-designed policies.</td><td>自动数据增强 (AutoAugment) (Cubuk et al., 2019) 通过使用目标任务采样策略的性能奖励训练的控制器搜索最佳扰动策略，从而减少数据级模型偏差。虽然是一种强大的算法，但他们的工作主要集中在计算机视觉任务上，在不改变图像语义的情况下应用不易察觉的扰动相对容易。在我们的工作中，我们采用 AutoAugment 自动发现自然语言处理 (NLP) 任务（如对话生成）的有效扰动策略。我们从一组原子操作开始，这些操作将微妙的语义保留扰动应用于对话任务的源输入（例如，不同的 POS 标签类型的停用词丢失、语法错误和释义）。接下来，我们允许控制器通过搜索这些原子操作的各种组合的空间来学习更复杂的增强策略。此外，我们还探索在目标任务的源输入上调节控制器，因为某些策略可能不适用于不包含该策略所需语言特征的输入。从经验上讲，我们证明了我们的输入不可知和输入感知控制器都发现了有用的数据增强策略，并且比以前的最先进技术取得了显着的改进，包括对手动设计的策略进行训练。</td><td>Tong Niu   Mohit Bansal</td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.03317&#39;]">Dependency Parsing for Spoken Dialog Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.03317">https://arxiv.org/pdf/1909.03317</a></td><td>Dependency parsing of conversational input can play an important role in language understanding for dialog systems by identifying the relationships between entities extracted from user utterances. Additionally, effective dependency parsing can elucidate differences in language structure and usage for discourse analysis of human-human versus human-machine dialogs. However, models trained on datasets based on news articles and web data do not perform well on spoken human-machine dialog, and currently available annotation schemes do not adapt well to dialog data. Therefore, we propose the Spoken Conversation Universal Dependencies (SCUD) annotation scheme that extends the Universal Dependencies (UD) (Nivre et al., 2016) guidelines to spoken human-machine dialogs. We also provide ConvBank, a conversation dataset between humans and an open-domain conversational dialog system with SCUD annotation. Finally, to demonstrate the utility of the dataset, we train a dependency parser on the ConvBank dataset. We demonstrate that by pre-training a dependency parser on a set of larger public datasets and fine-tuning on ConvBank data, we achieved the best result, 85.05% unlabeled and 77.82% labeled attachment accuracy.</td><td></td><td>Sam Davidson   Dian Yu   Zhou Yu</td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.05391&#39;]">Towards Knowledge-Based Recommender Dialog System</a></td><td></td><td><a href="https://github.com/THUDM/KBRD">https://github.com/THUDM/KBRD</a></td><td><a href="https://arxiv.org/pdf/1908.05391">https://arxiv.org/pdf/1908.05391</a></td><td>In this paper, we propose a novel end-to-end framework called KBRD, which stands for Knowledge-Based Recommender Dialog System. It integrates the recommender system and the dialog generation system. The dialog system can enhance the performance of the recommendation system by introducing knowledge-grounded information about users’ preferences, and the recommender system can improve that of the dialog generation system by providing recommendation-aware vocabulary bias. Experimental results demonstrate that our proposed model has significant advantages over the baselines in both the evaluation of dialog generation and recommendation. A series of analyses show that the two systems can bring mutual benefits to each other, and the introduced knowledge contributes to both their performances.</td><td>在本文中，我们提出了一种名为 KBRD 的新型端到端框架，它代表基于知识的推荐对话系统。它集成了推荐系统和对话生成系统。对话系统可以通过引入关于用户偏好的基于知识的信息来提高推荐系统的性能，推荐系统可以通过提供推荐感知词汇偏差来改进对话生成系统的性能。实验结果表明，我们提出的模型在对话生成和推荐的评估方面均优于基线。一系列分析表明，这两个系统可以互惠互利，所引入的知识对两者的性能都有贡献。</td><td>Qibin Chen   Junyang Lin   Yichang Zhang   Ming Ding   Yukuo Cen   Hongxia Yang   Jie Tang</td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.00610&#39;]">DyKgChat: Benchmarking Dialogue Generation Grounding on Dynamic Knowledge Graphs</a></td><td></td><td><a href="https://github.com/Pascalson/DyKGChat">https://github.com/Pascalson/DyKGChat</a></td><td><a href="https://arxiv.org/pdf/1910.00610">https://arxiv.org/pdf/1910.00610</a></td><td>Data-driven, knowledge-grounded neural conversation models are capable of generating more informative responses. However, these models have not yet demonstrated that they can zero-shot adapt to updated, unseen knowledge graphs. This paper proposes a new task about how to apply dynamic knowledge graphs in neural conversation model and presents a novel TV series conversation corpus (DyKgChat) for the task. Our new task and corpus aids in understanding the influence of dynamic knowledge graphs on responses generation. Also, we propose a preliminary model that selects an output from two networks at each time step: a sequence-to-sequence model (Seq2Seq) and a multi-hop reasoning model, in order to support dynamic knowledge graphs. To benchmark this new task and evaluate the capability of adaptation, we introduce several evaluation metrics and the experiments show that our proposed approach outperforms previous knowledge-grounded conversation models. The proposed corpus and model can motivate the future research directions.</td><td>数据驱动、以知识为基础的神经对话模型能够生成更多信息响应。然而，这些模型尚未证明它们可以零样本适应更新的、看不见的知识图。本文提出了有关如何在神经会话模型和任务提出了一种新的电视连续剧谈话文集（DyKgChat）应用动态知识图新任务。我们的新任务和语料库有助于理解动态知识图对响应生成的影响。此外，我们提出了一个初步的模型，其选择从两个网络的输出在每个时间步骤：一个序列到序列模型（Seq2Seq）和多跳推理模型中，为了支持动态知识的曲线图。为了对这项新任务进行基准测试并评估适应能力，我们引入了几个评估指标，实验表明我们提出的方法优于以前的基于知识的对话模型。所提出的语料库和模型可以激励未来的研究方向。</td><td>Yi-Lin Tuan   Yun-Nung Chen   Hung-yi Lee</td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.01388&#39;]">How to Build User Simulators to Train RL-based Dialog Systems</a></td><td></td><td><a href="https://github.com/wyshi/user-simulator">https://github.com/wyshi/user-simulator</a></td><td><a href="https://arxiv.org/pdf/1909.01388">https://arxiv.org/pdf/1909.01388</a></td><td>User simulators are essential for training reinforcement learning (RL) based dialog models. The performance of the simulator directly impacts the RL policy. However, building a good user simulator that models real user behaviors is challenging. We propose a method of standardizing user simulator building that can be used by the community to compare dialog system quality using the same set of user simulators fairly. We present implementations of six user simulators trained with different dialog planning and generation methods. We then calculate a set of automatic metrics to evaluate the quality of these simulators both directly and indirectly. We also ask human users to assess the simulators directly and indirectly by rating the simulated dialogs and interacting with the trained systems. This paper presents a comprehensive evaluation framework for user simulator study and provides a better understanding of the pros and cons of different user simulators, as well as their impacts on the trained systems.</td><td>用户模拟器对于训练基于强化学习 (RL) 的对话模型至关重要。模拟器的性能直接影响 RL 策略。然而，构建一个好的用户模拟器来模拟真实的用户行为是具有挑战性的。我们提出了一种标准化用户模拟器构建的方法，社区可以使用该方法来公平地比较使用同一组用户模拟器的对话系统质量。我们展示了使用不同对话规划和生成方法训练的六个用户模拟器的实现。然后我们计算一组自动指标来直接和间接评估这些模拟器的质量。我们还要求人类用户通过对模拟对话进行评级并与训练有素的系统交互来直接或间接评估模拟器。本文提出了一个用于用户模拟器研究的综合评估框架，并更好地了解不同用户模拟器的优缺点，以及它们对训练系统的影响。</td><td>Weiyan Shi   Kun Qian   Xuewei Wang   Zhou Yu</td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.09368&#39;]">Dual Attention Networks for Visual Reference Resolution in Visual Dialog</a></td><td></td><td><a href="https://github.com/gicheonkang/DAN-VisDial">https://github.com/gicheonkang/DAN-VisDial</a></td><td><a href="https://arxiv.org/pdf/1902.09368">https://arxiv.org/pdf/1902.09368</a></td><td>Visual dialog (VisDial) is a task which requires an AI agent to answer a series of questions grounded in an image. Unlike in visual question answering (VQA), the series of questions should be able to capture a temporal context from a dialog history and exploit visually-grounded information. A problem called visual reference resolution involves these challenges, requiring the agent to resolve ambiguous references in a given question and find the references in a given image. In this paper, we propose Dual Attention Networks (DAN) for visual reference resolution. DAN consists of two kinds of attention networks, REFER and FIND. Specifically, REFER module learns latent relationships between a given question and a dialog history by employing a self-attention mechanism. FIND module takes image features and reference-aware representations (i.e., the output of REFER module) as input, and performs visual grounding via bottom-up attention mechanism. We qualitatively and quantitatively evaluate our model on VisDial v1.0 and v0.9 datasets, showing that DAN outperforms the previous state-of-the-art model by a significant margin.</td><td>视觉对话 (VisDial) 是一项需要 AI 代理回答基于图像的一系列问题的任务。与视觉问答 (VQA) 不同，这一系列问题应该能够从对话历史中捕获时间上下文并利用基于视觉的信息。称为视觉参考解析的问题涉及这些挑战，需要代理解决给定问题中的模糊参考并在给定图像中找到参考。在本文中，我们提出了用于视觉参考分辨率的双注意力网络（DAN）。 DAN 由两种注意力网络组成，REFER 和 FIND。具体来说，REFER 模块通过采用自注意力机制来学习给定问题和对话历史之间的潜在关系。 FIND 模块以图像特征和参考感知表示（即 REFER 模块的输出）作为输入，并通过自下而上的注意力机制执行视觉接地。我们在 VisDial v1.0 和 v0.9 数据集上定性和定量地评估了我们的模型，表明 DAN 的性能明显优于之前的最先进模型。</td><td>Gi-Cheon Kang   Jaeseo Lim   Byoung-Tak Zhang</td></tr><tr><td>16</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11487&#39;]">Dialog Intent Induction with Deep Multi-View Clustering</a></td><td></td><td><a href="https://github.com/asappresearch/dialog-intent-induction">https://github.com/asappresearch/dialog-intent-induction</a></td><td><a href="https://arxiv.org/pdf/1908.11487">https://arxiv.org/pdf/1908.11487</a></td><td>We introduce the dialog intent induction task and present a novel deep multi-view clustering approach to tackle the problem. Dialog intent induction aims at discovering user intents from user query utterances in human-human conversations such as dialogs between customer support agents and customers. Motivated by the intuition that a dialog intent is not only expressed in the user query utterance but also captured in the rest of the dialog, we split a conversation into two independent views and exploit multi-view clustering techniques for inducing the dialog intent. In particular, we propose alternating-view k-means (AV-KMEANS) for joint multi-view representation learning and clustering analysis. The key innovation is that the instance-view representations are updated iteratively by predicting the cluster assignment obtained from the alternative view, so that the multi-view representations of the instances lead to similar cluster assignments. Experiments on two public datasets show that AV-KMEANS can induce better dialog intent clusters than state-of-the-art unsupervised representation learning methods and standard multi-view clustering approaches.</td><td>我们介绍了对话意图归纳任务，并提出了一种新颖的深度多视图聚类方法来解决该问题。对话意图归纳旨在从人与人对话（例如客户支持代理和客户之间的对话）中的用户查询话语中发现用户意图。受对话意图不仅在用户查询话语中表达而且还在对话的其余部分中表达的直觉的启发，我们将对话分成两个独立的视图，并利用多视图聚类技术来诱导对话意图。特别是，我们提出了交替视图 k-means (AV-KMEANS) 用于联合多视图表示学习和聚类分析。关键创新是通过预测从替代视图获得的集群分配来迭代更新实例视图表示，以便实例的多视图表示导致相似的集群分配。在两个公共数据集上的实验表明，与最先进的无监督表示学习方法和标准多视图聚类方法相比，AV-KMEANS 可以诱导更好的对话意图聚类。</td><td>Hugh Perkins   Yi Yang</td></tr><tr><td>17</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.05069&#39;]">Multi-Task Learning for Conversational Question Answering over a Large-Scale Knowledge Base</a></td><td></td><td><a href="https://github.com/taoshen58/MaSP">https://github.com/taoshen58/MaSP</a></td><td><a href="https://arxiv.org/pdf/1910.05069">https://arxiv.org/pdf/1910.05069</a></td><td>We consider the problem of conversational question answering over a large-scale knowledge base. To handle huge entity vocabulary of a large-scale knowledge base, recent neural semantic parsing based approaches usually decompose the task into several subtasks and then solve them sequentially, which leads to following issues: 1) errors in earlier subtasks will be propagated and negatively affect downstream ones; and 2) each subtask cannot naturally share supervision signals with others. To tackle these issues, we propose an innovative multi-task learning framework where a pointer-equipped semantic parsing model is designed to resolve coreference in conversations, and naturally empower joint learning with a novel type-aware entity detection model. The proposed framework thus enables shared supervisions and alleviates the effect of error propagation. Experiments on a large-scale conversational question answering dataset containing 1.6M question answering pairs over 12.8M entities show that the proposed framework improves overall F1 score from 67% to 79% compared with previous state-of-the-art work.</td><td>我们考虑在大规模知识库上进行对话式问答的问题。为了处理大规模知识库的庞大实体词汇表，最近的基于神经语义解析的方法通常将任务分解为几个子任务，然后依次解决它们，这导致以下问题：1）早期子任务中的错误将被传播并产生负面影响下游的； 2）每个子任务不能自然地与其他人共享监督信号。为了解决这些问题，我们提出了一种创新的多任务学习框架，其中设计了一个配备指针的语义解析模型来解决对话中的共指问题，并自然地通过一种新颖的类型感知实体检测模型来授权联合学习。因此，所提出的框架能够实现共享监督并减轻错误传播的影响。在包含超过 1280 万个实体的 160 万个问答对的大规模会话问答数据集上的实验表明，与之前的最先进工作相比，所提出的框架将整体 F1 分数从 67% 提高到 79%。</td><td>Tao Shen   Xiubo Geng   Tao Qin   Daya Guo   Duyu Tang   Nan Duan   Guodong Long   Daxin Jiang</td></tr></tbody></table></div><h3 id="NAACL-1"><a href="#NAACL-1" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.04898&#39;]">Open-Domain Question Answering Goes Conversational via Question Rewriting</a></td><td></td><td><a href="https://github.com/apple/ml-qrecc">https://github.com/apple/ml-qrecc</a></td><td><a href="https://arxiv.org/pdf/2010.04898">https://arxiv.org/pdf/2010.04898</a></td><td>We introduce a new dataset for Question Rewriting in Conversational Context (QReCC), which contains 14K conversations with 80K question-answer pairs. The task in QReCC is to find answers to conversational questions within a collection of 10M web pages (split into 54M passages). Answers to questions in the same conversation may be distributed across several web pages. QReCC provides annotations that allow us to train and evaluate individual subtasks of question rewriting, passage retrieval and reading comprehension required for the end-to-end conversational question answering (QA) task. We report the effectiveness of a strong baseline approach that combines the state-of-the-art model for question rewriting, and competitive models for open-domain QA. Our results set the first baseline for the QReCC dataset with F1 of 19.10, compared to the human upper bound of 75.45, indicating the difficulty of the setup and a large room for improvement.</td><td></td><td>Raviteja Anantha   Svitlana Vakulenko   Zhucheng Tu   Shayne Longpre   Stephen Pulman   Srinivas Chappidi</td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.00783&#39;]">Action-Based Conversations Dataset: A Corpus for Building More In-Depth Task- Oriented Dialogue Systems</a></td><td></td><td><a href="https://github.com/asappresearch/abcd">https://github.com/asappresearch/abcd</a></td><td><a href="https://arxiv.org/pdf/2104.00783">https://arxiv.org/pdf/2104.00783</a></td><td>Existing goal-oriented dialogue datasets focus mainly on identifying slots and values. However, customer support interactions in reality often involve agents following multi-step procedures derived from explicitly-defined company policies as well. To study customer service dialogue systems in more realistic settings, we introduce the Action-Based Conversations Dataset (ABCD), a fully-labeled dataset with over 10K human-to-human dialogues containing 55 distinct user intents requiring unique sequences of actions constrained by policies to achieve task success. We propose two additional dialog tasks, Action State Tracking and Cascading Dialogue Success, and establish a series of baselines involving large-scale, pre-trained language models on this dataset. Empirical results demonstrate that while more sophisticated networks outperform simpler models, a considerable gap (50.8% absolute accuracy) still exists to reach human-level performance on ABCD.</td><td>现有的面向目标的对话数据集主要侧重于识别槽和值。然而，现实中的客户支持交互通常也涉及代理遵循源自明确定义的公司政策的多步骤程序。为了在更现实的环境中研究客户服务对话系统，我们引入了基于动作的对话数据集 (ABCD)，这是一个完全标记的数据集，其中包含超过 10K 人与人之间的对话，其中包含 55 个不同的用户意图，需要受策略约束的独特动作序列以实现任务成功。我们提出了两个额外的对话任务，Action State Tracking 和 Cascading Dialogue Success，并在这个数据集上建立了一系列涉及大规模、预训练语言模型的基线。实证结果表明，虽然更复杂的网络优于更简单的模型，但在 ABCD 上达到人类水平的表现仍然存在相当大的差距（50.8% 的绝对准确率）。</td><td>Derek Chen   Howard Chen   Yi Yang   Alex Lin   Zhou Yu</td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.11230&#39;]">Self-Supervised Contrastive Learning for Efficient User Satisfaction Prediction in Conversational Agents</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.11230">https://arxiv.org/pdf/2010.11230</a></td><td>Turn-level user satisfaction is one of the most important performance metrics for conversational agents. It can be used to monitor the agent’s performance and provide insights about defective user experiences. Moreover, a powerful satisfaction model can be used as an objective function that a conversational agent continuously optimizes for. While end-to-end deep learning has shown promising results, having access to a large number of reliable annotated samples required by these methods remains challenging. In a large-scale conversational system, there is a growing number of newly developed skills, making the traditional data collection, annotation, and modeling process impractical due to the required annotation costs as well as the turnaround times. In this paper, we suggest a self-supervised contrastive learning approach that leverages the pool of unlabeled data to learn user-agent interactions. We show that the pre-trained models using the self-supervised objective are transferable to the user satisfaction prediction. In addition, we propose a novel few-shot transfer learning approach that ensures better transferability for very small sample sizes. The suggested few-shot method does not require any inner loop optimization process and is scalable to very large datasets and complex models. Based on our experiments using real-world data from a large-scale commercial system, the suggested approach is able to significantly reduce the required number of annotations, while improving the generalization on unseen out-of-domain skills.</td><td>回合级用户满意度是会话代理最重要的性能指标之一。它可用于监控代理的性能并提供有关有缺陷的用户体验的见解。此外，强大的满意度模型可以用作对话代理不断优化的目标函数。虽然端到端深度学习已显示出有希望的结果，但访问这些方法所需的大量可靠的带注释的样本仍然具有挑战性。在大型对话系统中，新开发的技能越来越多，由于所需的注释成本和周转时间，使得传统的数据收集、注释和建模过程变得不切实际。在本文中，我们提出了一种自监督对比学习方法，该方法利用未标记数据池来学习用户-代理交互。我们表明使用自监督目标的预训练模型可转移到用户满意度预测。此外，我们提出了一种新颖的少样本迁移学习方法，可确保对非常小的样本量具有更好的迁移能力。建议的小样本方法不需要任何内循环优化过程，并且可扩展到非常大的数据集和复杂模型。基于我们使用来自大规模商业系统的真实世界数据的实验，所建议的方法能够显着减少所需的注释数量，同时提高对看不见的域外技能的泛化。</td><td>Mohammad Kachuee   Hao Yuan   Young-Bum Kim   Sungjin Lee</td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.07831&#39;]">Human-like informative conversations: Better acknowledgements using conditional mutual information</a></td><td></td><td><a href="https://github.com/AshwinParanjape/human-like-informative-conversations">https://github.com/AshwinParanjape/human-like-informative-conversations</a></td><td><a href="https://arxiv.org/pdf/2104.07831">https://arxiv.org/pdf/2104.07831</a></td><td>This work aims to build a dialogue agent that can weave new factual content into conversations as naturally as humans. We draw insights from linguistic principles of conversational analysis and annotate human-human conversations from the Switchboard Dialog Act Corpus to examine humans strategies for acknowledgement, transition, detail selection and presentation. When current chatbots (explicitly provided with new factual content) introduce facts into a conversation, their generated responses do not acknowledge the prior turns. This is because models trained with two contexts - new factual content and conversational history - generate responses that are non-specific w.r.t. one of the contexts, typically the conversational history. We show that specificity w.r.t. conversational history is better captured by Pointwise Conditional Mutual Information ($\text{pcmi}_h$) than by the established use of Pointwise Mutual Information ($\text{pmi}$). Our proposed method, Fused-PCMI, trades off $\text{pmi}$ for $\text{pcmi}_h$ and is preferred by humans for overall quality over the Max-PMI baseline 60% of the time. Human evaluators also judge responses with higher $\text{pcmi}_h$ better at acknowledgement 74% of the time. The results demonstrate that systems mimicking human conversational traits (in this case acknowledgement) improve overall quality and more broadly illustrate the utility of linguistic principles in improving dialogue agents.</td><td>这项工作旨在构建一个对话代理，可以像人类一样自然地将新的事实内容编织到对话中。我们从对话分析的语言原则中汲取见解，并从 Switchboard Dialog Act Corpus 中注释人与人的对话，以检查人类在确认、转换、细节选择和呈现方面的策略。当当前的聊天机器人（明确提供新的事实内容）将事实引入对话时，它们生成的响应不会确认先前的转变。这是因为在两个上下文（新的事实内容和对话历史）中训练的模型会生成非特定 w.r.t. 的响应。上下文之一，通常是对话历史。我们展示了这种特异性 w.r.t. Pointwise Conditional Mutual Information ($\text{pcmi}_h$) 比使用 Pointwise Mutual Information ($\text{pmi}$) 更好地捕获会话历史。我们提出的方法，Fused-PCMI，用 $\text{pmi}$ 换取 $\text{pcmi}_h$，并且在 60% 的时间里，人们更喜欢在 Max-PMI 基线上的整体质量。人类评估者在 74% 的时间里也能更好地判断具有较高 $\text{pcmi}_h$ 的响应。结果表明，模仿人类对话特征（在这种情况下是确认）的系统提高了整体质量，并更广泛地说明了语言原则在改进对话代理方面的效用。</td><td>Ashwin Paranjape   Christopher D. Manning</td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2102.02191&#39;]">DiSCoL: Toward Engaging Dialogue Systems through Conversational Line Guided Response Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2102.02191">https://arxiv.org/pdf/2102.02191</a></td><td>Having engaging and informative conversations with users is the utmost goal for open-domain conversational systems. Recent advances in transformer-based language models and their applications to dialogue systems have succeeded to generate fluent and human-like responses. However, they still lack control over the generation process towards producing contentful responses and achieving engaging conversations. To achieve this goal, we present \textbf{DiSCoL} (\textbf{Di}alogue \textbf{S}ystems through \textbf{Co}versational \textbf{L}ine guided response generation). DiSCoL is an open-domain dialogue system that leverages conversational lines (briefly \textbf{convlines}) as controllable and informative content-planning elements to guide the generation model produce engaging and informative responses. Two primary modules in DiSCoL’s pipeline are conditional generators trained for 1) predicting relevant and informative convlines for dialogue contexts and 2) generating high-quality responses conditioned on the predicted convlines. Users can also change the returned convlines to \textit{control} the direction of the conversations towards topics that are more interesting for them. Through automatic and human evaluations, we demonstrate the efficiency of the convlines in producing engaging conversations.</td><td>与用户进行引人入胜且信息丰富的对话是开放域对话系统的最大目标。基于转换器的语言模型及其在对话系统中的应用的最新进展已经成功地产生了流畅和类似人类的响应。然而，他们仍然缺乏对生成内容的响应和实现引人入胜的对话的生成过程的控制。为了实现这一目标，我们提出了 \textbf{DiSCoL}（\textbf{Di}alogue \textbf{S}ystems through \textbf{Co}versational \textbf{L}ine 引导响应生成）。 DiSCoL 是一个开放域对话系统，它利用对话线（简称 \textbf{convlines}）作为可控和信息丰富的内容规划元素来指导生成模型产生引人入胜和信息丰富的响应。 DiSCoL 管道中的两个主要模块是条件生成器，用于 1) 预测对话上下文的相关和信息丰富的 convlines 和 2) 生成以预测的 convlines 为条件的高质量响应。用户还可以将返回的 convlines 更改为 \textit{control} 将对话的方向转向对他们更感兴趣的主题。通过自动和人工评估，我们展示了 convlines 在产生引人入胜的对话方面的效率。</td><td>Sarik Ghazarian   Zixi Liu   Tuhin Chakrabarty   Xuezhe Ma   Aram Galstyan   Nanyun Peng</td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12757&#39;]">Adding Chit-Chat to Enhance Task-Oriented Dialogues</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12757">https://arxiv.org/pdf/2010.12757</a></td><td>Existing dialogue corpora and models are typically designed under two disjoint motives: while task-oriented systems focus on achieving functional goals (e.g., booking hotels), open-domain chatbots aim at making socially engaging conversations. In this work, we propose to integrate both types of systems by Adding Chit-Chat to ENhance Task-ORiented dialogues (ACCENTOR), with the goal of making virtual assistant conversations more engaging and interactive. Specifically, we propose a Human &lt;-&gt; AI collaborative data collection approach for generating diverse chit-chat responses to augment task-oriented dialogues with minimal annotation effort. We then present our new chit-chat-based annotations to 23.8K dialogues from two popular task-oriented datasets (Schema-Guided Dialogue and MultiWOZ 2.1) and demonstrate their advantage over the originals via human evaluation. Lastly, we propose three new models for adding chit-chat to task-oriented dialogues, explicitly trained to predict user goals and to generate contextually relevant chit-chat responses. Automatic and human evaluations show that, compared with the state-of-the-art task-oriented baseline, our models can code-switch between task and chit-chat to be more engaging, interesting, knowledgeable, and humanlike, while maintaining competitive task performance.</td><td>现有的对话语料库和模型通常是在两个不相交的动机下设计的：面向任务的系统专注于实现功能目标（例如，预订酒店），而开放域聊天机器人旨在进行社交互动。在这项工作中，我们建议通过将 Chit-Chat 添加到增强面向任务的对话 (ACCENTOR) 来集成两种类型的系统，目的是使虚拟助手对话更具吸引力和互动性。具体来说，我们提出了一种 Human &lt;-&gt; AI 协作数据收集方法，用于生成各种闲聊响应，以最少的注释工作来增强面向任务的对话。然后，我们向来自两个流行的面向任务的数据集（Schema-Guided Dialogue 和 MultiWOZ 2.1）的 23.8K 对话展示了我们新的基于闲聊的注释，并通过人工评估证明了它们相对于原始数据的优势。最后，我们提出了三个新模型，用于将闲聊添加到面向任务的对话中，经过明确训练以预测用户目标并生成上下文相关的闲聊响应。自动和人工评估表明，与最先进的面向任务的基线相比，我们的模型可以在任务和闲聊之间进行代码切换，使其更具吸引力、有趣、知识渊博和人性化，同时保持竞争性任务表现。</td><td>Kai Sun   Seungwhan Moon   Paul Crook   Stephen Roller   Becka Silvert   Bing Liu   Zhiguang Wang   Honglei Liu   Eunjoon Cho   Claire Cardie</td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2004.10663&#39;]">Fast and Scalable Dialogue State Tracking with Explicit Modular Decomposition</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.10663">https://arxiv.org/pdf/2004.10663</a></td><td>We present a fast and scalable architecture called Explicit Modular Decomposition (EMD), in which we incorporate both classification-based and extraction-based methods and design four modules (for classification and sequence labelling) to jointly extract dialogue states. Experimental results based on the MultiWoz 2.0 dataset validates the superiority of our proposed model in terms of both complexity and scalability when compared to the state-of-the-art methods, especially in the scenario of multi-domain dialogues entangled with many turns of utterances.</td><td>我们提出了一种称为显式模块化分解 (EMD) 的快速且可扩展的架构，其中我们结合了基于分类和基于提取的方法，并设计了四个模块（用于分类和序列标记）来联合提取对话状态。与最先进的方法相比，基于 MultiWoz 2.0 数据集的实验结果验证了我们提出的模型在复杂性和可扩展性方面的优越性，尤其是在多域对话与多轮话语纠缠的情况下.</td><td>Dingmin Wang   Chenghua Lin   Li Zhong   Kam-Fai Wong</td></tr><tr><td>8</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1810.13327&#39;]">Cross-lingual Transfer Learning for Multilingual Task Oriented Dialog</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1810.13327">https://arxiv.org/pdf/1810.13327</a></td><td>One of the first steps in the utterance interpretation pipeline of many task-oriented conversational AI systems is to identify user intents and the corresponding slots. Since data collection for machine learning models for this task is time-consuming, it is desirable to make use of existing data in a high-resource language to train models in low-resource languages. However, development of such models has largely been hindered by the lack of multilingual training data. In this paper, we present a new data set of 57k annotated utterances in English (43k), Spanish (8.6k) and Thai (5k) across the domains weather, alarm, and reminder. We use this data set to evaluate three different cross-lingual transfer methods: (1) translating the training data, (2) using cross-lingual pre-trained embeddings, and (3) a novel method of using a multilingual machine translation encoder as contextual word representations. We find that given several hundred training examples in the the target language, the latter two methods outperform translating the training data. Further, in very low-resource settings, multilingual contextual word representations give better results than using cross-lingual static embeddings. We also compare the cross-lingual methods to using monolingual resources in the form of contextual ELMo representations and find that given just small amounts of target language data, this method outperforms all cross-lingual methods, which highlights the need for more sophisticated cross-lingual methods.</td><td></td><td>Sebastian Schuster   Sonal Gupta   Rushin Shah   Mike Lewis</td></tr><tr><td>9</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.03371&#39;]">Evaluating Coherence in Dialogue Systems using Entailment</a></td><td></td><td><a href="https://github.com/nouhadziri/DialogEntailment">https://github.com/nouhadziri/DialogEntailment</a></td><td><a href="https://arxiv.org/pdf/1904.03371">https://arxiv.org/pdf/1904.03371</a></td><td>Evaluating open-domain dialogue systems is difficult due to the diversity of possible correct answers. Automatic metrics such as BLEU correlate weakly with human annotations, resulting in a significant bias across different models and datasets. Some researchers resort to human judgment experimentation for assessing response quality, which is expensive, time consuming, and not scalable. Moreover, judges tend to evaluate a small number of dialogues, meaning that minor differences in evaluation configuration may lead to dissimilar results. In this paper, we present interpretable metrics for evaluating topic coherence by making use of distributed sentence representations. Furthermore, we introduce calculable approximations of human judgment based on conversational coherence by adopting state-of-the-art entailment techniques. Results show that our metrics can be used as a surrogate for human judgment, making it easy to evaluate dialogue systems on large-scale datasets and allowing an unbiased estimate for the quality of the responses.</td><td>由于可能正确答案的多样性，评估开放域对话系统很困难。 BLEU 等自动指标与人工注释的相关性较弱，导致不同模型和数据集之间存在显着偏差。一些研究人员采用人工判断实验来评估响应质量，这是昂贵、耗时且不可扩展的。此外，评委倾向于评价少量对话，这意味着评价配置的微小差异可能导致不同的结果。在本文中，我们通过使用分布式句子表示，提出了用于评估主题连贯性的可解释指标。此外，我们通过采用最先进的蕴含技术，基于对话连贯性引入了人类判断的可计算近似值。结果表明，我们的指标可以用作人类判断的替代品，从而可以轻松评估大规模数据集上的对话系统，并允许对响应质量进行无偏估计。</td><td>Nouha Dziri   Ehsan Kamalloo   Kory W. Mathewson   Osmar Zaiane</td></tr></tbody></table></div><h3 id="COLING-1"><a href="#COLING-1" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2012.04080&#39;]">A Taxonomy of Empathetic Response Intents in Human Social Conversations</a></td><td></td><td><a href="https://github.com/anuradha1992/EmpatheticIntents">https://github.com/anuradha1992/EmpatheticIntents</a></td><td><a href="https://arxiv.org/pdf/2012.04080">https://arxiv.org/pdf/2012.04080</a></td><td>Open-domain conversational agents or chatbots are becoming increasingly popular in the natural language processing community. One of the challenges is enabling them to converse in an empathetic manner. Current neural response generation methods rely solely on end-to-end learning from large scale conversation data to generate dialogues. This approach can produce socially unacceptable responses due to the lack of large-scale quality data used to train the neural models. However, recent work has shown the promise of combining dialogue act/intent modelling and neural response generation. This hybrid method improves the response quality of chatbots and makes them more controllable and interpretable. A key element in dialog intent modelling is the development of a taxonomy. Inspired by this idea, we have manually labeled 500 response intents using a subset of a sizeable empathetic dialogue dataset (25K dialogues). Our goal is to produce a large-scale taxonomy for empathetic response intents. Furthermore, using lexical and machine learning methods, we automatically analysed both speaker and listener utterances of the entire dataset with identified response intents and 32 emotion categories. Finally, we use information visualization methods to summarize emotional dialogue exchange patterns and their temporal progression. These results reveal novel and important empathy patterns in human-human open-domain conversations and can serve as heuristics for hybrid approaches.</td><td>开放域对话代理或聊天机器人在自然语言处理社区中变得越来越流行。挑战之一是使他们能够以善解人意的方式交谈。当前的神经响应生成方法仅依赖于从大规模对话数据中进行端到端学习来生成对话。由于缺乏用于训练神经模型的大规模质量数据，这种方法可能会产生社会上无法接受的反应。然而，最近的工作显示了将对话行为/意图建模和神经反应生成相结合的前景。这种混合方法提高了聊天机器人的响应质量，并使它们更加可控和可解释。对话意图建模的一个关键要素是分类法的开发。受这个想法的启发，我们使用一个相当大的移情对话数据集（25K 对话）的子集手动标记了 500 个响应意图。我们的目标是为移情反应意图生成大规模分类法。此外，使用词汇和机器学习方法，我们自动分析了整个数据集的说话者和听者的话语，并确定了响应意图和 32 种情感类别。最后，我们使用信息可视化方法来总结情感对话交流模式及其时间进展。这些结果揭示了人与人开放域对话中新颖而重要的移情模式，可以作为混合方法的启发式方法。</td><td>Anuradha Welivita   Pearl Pu</td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2105.10606&#39;]">CEREC: A Corpus for Entity Resolution in Email Conversations</a></td><td></td><td><a href="https://github.com/paragdakle/emailcoref">https://github.com/paragdakle/emailcoref</a></td><td><a href="https://arxiv.org/pdf/2105.10606">https://arxiv.org/pdf/2105.10606</a></td><td>We present the first large scale corpus for entity resolution in email conversations (CEREC). The corpus consists of 6001 email threads from the Enron Email Corpus containing 36,448 email messages and 60,383 entity coreference chains. The annotation is carried out as a two-step process with minimal manual effort. Experiments are carried out for evaluating different features and performance of four baselines on the created corpus. For the task of mention identification and coreference resolution, a best performance of 59.2 F1 is reported, highlighting the room for improvement. An in-depth qualitative and quantitative error analysis is presented to understand the limitations of the baselines considered.</td><td>我们展示了第一个用于电子邮件对话中实体解析的大规模语料库 (CEREC)。该语料库由来自安然电子邮件语料库的 6001 个电子邮件线程组成，其中包含 36,448 封电子邮件和 60,383 个实体共指链。注释作为两步过程执行，手动操作最少。进行实验以评估四个基线在创建的语料库上的不同特征和性能。对于提及识别和共指解析的任务，报告了 59.2 F1 的最佳性能，突出了改进的空间。提供了深入的定性和定量误差分析，以了解所考虑基线的局限性。</td><td>Parag Pravin Dakle   Dan I. Moldovan</td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.00671&#39;]">Conversational Machine Comprehension: a Literature Review</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2006.00671">https://arxiv.org/pdf/2006.00671</a></td><td>Conversational Machine Comprehension (CMC), a research track in conversational AI, expects the machine to understand an open-domain natural language text and thereafter engage in a multi-turn conversation to answer questions related to the text. While most of the research in Machine Reading Comprehension (MRC) revolves around single-turn question answering (QA), multi-turn CMC has recently gained prominence, thanks to the advancement in natural language understanding via neural language models such as BERT and the introduction of large-scale conversational datasets such as CoQA and QuAC. The rise in interest has, however, led to a flurry of concurrent publications, each with a different yet structurally similar modeling approach and an inconsistent view of the surrounding literature. With the volume of model submissions to conversational datasets increasing every year, there exists a need to consolidate the scattered knowledge in this domain to streamline future research. This literature review attempts at providing a holistic overview of CMC with an emphasis on the common trends across recently published models, specifically in their approach to tackling conversational history. The review synthesizes a generic framework for CMC models while highlighting the differences in recent approaches and intends to serve as a compendium of CMC for future researchers.</td><td>Conversational Machine Comprehension (CMC) 是会话 AI 的一个研究方向，它希望机器能够理解开放领域的自然语言文本，然后进行多轮对话以回答与文本相关的问题。虽然机器阅读理解 (MRC) 的大部分研究都围绕单轮问答 (QA) 展开，但由于通过 BERT 等神经语言模型和介绍大规模会话数据集，如 CoQA 和 QuAC。然而，兴趣的增加导致了大量并发出版物，每一种都有不同但结构相似的建模方法和对周围文献的不一致看法。随着会话数据集的模型提交量逐年增加，需要整合该领域的零散知识以简化未来的研究。这篇文献综述试图提供 CMC 的整体概述，重点是最近发布的模型的共同趋势，特别是它们处理对话历史的方法。该评论综合了 CMC 模型的通用框架，同时突出了最近方法的差异，并打算作为未来研究人员的 CMC 纲要。</td><td>Somil Gupta   Bhanu Pratap Singh Rawat   Hong Yu</td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00615&#39;]">Improving Conversational Question Answering Systems after Deployment using Feedback-Weighted Learning</a></td><td></td><td><a href="https://github.com/jjacampos/FeedbackWeightedLearning">https://github.com/jjacampos/FeedbackWeightedLearning</a></td><td><a href="https://arxiv.org/pdf/2011.00615">https://arxiv.org/pdf/2011.00615</a></td><td>The interaction of conversational systems with users poses an exciting opportunity for improving them after deployment, but little evidence has been provided of its feasibility. In most applications, users are not able to provide the correct answer to the system, but they are able to provide binary (correct, incorrect) feedback. In this paper we propose feedback-weighted learning based on importance sampling to improve upon an initial supervised system using binary user feedback. We perform simulated experiments on document classification (for development) and Conversational Question Answering datasets like QuAC and DoQA, where binary user feedback is derived from gold annotations. The results show that our method is able to improve over the initial supervised system, getting close to a fully-supervised system that has access to the same labeled examples in in-domain experiments (QuAC), and even matching in out-of-domain experiments (DoQA). Our work opens the prospect to exploit interactions with real users and improve conversational systems after deployment.</td><td>对话系统与用户的交互为部署后改进它们提供了一个令人兴奋的机会，但几乎没有提供其可行性的证据。在大多数应用中，用户无法向系统提供正确答案，但他们能够提供二元（正确、不正确）反馈。在本文中，我们提出了基于重要性采样的反馈加权学习，以改进使用二元用户反馈的初始监督系统。我们对文档分类（用于开发）和对话式问答数据集（如 QuAC 和 DoQA）进行模拟实验，其中二进制用户反馈来自黄金注释。结果表明，我们的方法能够改进初始监督系统，接近完全监督系统，该系统可以在域内实验 (QuAC) 中访问相同的标记示例，甚至可以在域外进行匹配实验（DoQA）。我们的工作开辟了利用与真实用户的交互并在部署后改进对话系统的前景。</td><td>Jon Ander Campos   Kyunghyun Cho   Arantxa Otegi   Aitor Soroa   Gorka Azkune   Eneko Agirre</td></tr><tr><td>5</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04125&#39;]">Towards Topic-Guided Conversational Recommender System</a></td><td></td><td><a href="https://github.com/RUCAIBox/TG-ReDial">https://github.com/RUCAIBox/TG-ReDial</a></td><td><a href="https://arxiv.org/pdf/2010.04125">https://arxiv.org/pdf/2010.04125</a></td><td>Conversational recommender systems (CRS) aim to recommend high-quality items to users through interactive conversations. To develop an effective CRS, the support of high-quality datasets is essential. Existing CRS datasets mainly focus on immediate requests from users, while lack proactive guidance to the recommendation scenario. In this paper, we contribute a new CRS dataset named \textbf{TG-ReDial} (\textbf{Re}commendation through \textbf{T}opic-\textbf{G}uided \textbf{Dial}og). Our dataset has two major features. First, it incorporates topic threads to enforce natural semantic transitions towards the recommendation scenario. Second, it is created in a semi-automatic way, hence human annotation is more reasonable and controllable. Based on TG-ReDial, we present the task of topic-guided conversational recommendation, and propose an effective approach to this task. Extensive experiments have demonstrated the effectiveness of our approach on three sub-tasks, namely topic prediction, item recommendation and response generation. TG-ReDial is available at <a href="https://github.com/RUCAIBox/TG-ReDial">https://github.com/RUCAIBox/TG-ReDial</a>.</td><td>会话推荐系统（CRS）旨在通过交互式会话向用户推荐高质量的项目。要开发有效的 CRS，高质量数据集的支持必不可少。现有的 CRS 数据集主要关注用户的即时请求，而缺乏对推荐场景的主动指导。在本文中，我们贡献了一个名为 \textbf{TG-ReDial} 的新 CRS 数据集（\textbf{Re}commendation through \textbf{T}opic-\textbf{G}uided \textbf{Dial}og）。我们的数据集有两个主要特征。首先，它结合了主题线程来强制向推荐场景进行自然语义转换。其次，采用半自动方式创建，人工标注更加合理可控。基于TG-ReDial，我们提出了主题引导的对话推荐任务，并提出了一种有效的方法来完成这项任务。大量实验证明了我们的方法在三个子任务上的有效性，即主题预测、项目推荐和响应生成。 TG-ReDial 可在 <a href="https://github.com/RUCAIBox/TG-ReDial">https://github.com/RUCAIBox/TG-ReDial</a> 获得。</td><td>Kun Zhou   Yuanhang Zhou   Wayne Xin Zhao   Xiaoke Wang   Ji-Rong Wen</td></tr><tr><td>6</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00483&#39;]">Deconstruct to Reconstruct a Configurable Evaluation Metric for Open-Domain Dialogue Systems</a></td><td></td><td><a href="https://github.com/vitouphy/usl_dialogue_metric">https://github.com/vitouphy/usl_dialogue_metric</a></td><td><a href="https://arxiv.org/pdf/2011.00483">https://arxiv.org/pdf/2011.00483</a></td><td>Many automatic evaluation metrics have been proposed to score the overall quality of a response in open-domain dialogue. Generally, the overall quality is comprised of various aspects, such as relevancy, specificity, and empathy, and the importance of each aspect differs according to the task. For instance, specificity is mandatory in a food-ordering dialogue task, whereas fluency is preferred in a language-teaching dialogue system. However, existing metrics are not designed to cope with such flexibility. For example, BLEU score fundamentally relies only on word overlapping, whereas BERTScore relies on semantic similarity between reference and candidate response. Thus, they are not guaranteed to capture the required aspects, i.e., specificity. To design a metric that is flexible to a task, we first propose making these qualities manageable by grouping them into three groups: understandability, sensibleness, and likability, where likability is a combination of qualities that are essential for a task. We also propose a simple method to composite metrics of each aspect to obtain a single metric called USL-H, which stands for Understandability, Sensibleness, and Likability in Hierarchy. We demonstrated that USL-H score achieves good correlations with human judgment and maintains its configurability towards different aspects and metrics.</td><td>已经提出了许多自动评估指标来对开放域对话中响应的整体质量进行评分。一般来说，整体素质由相关性、特异性、同理心等多个方面组成，每个方面的重要性因任务而异。例如，在订餐对话任务中，特定性是强制性的，而在语言教学对话系统中，流畅性是首选。然而，现有的指标并不是为了应对这种灵活性而设计的。例如，BLEU 分数从根本上只依赖于单词重叠，而 BERTScore 依赖于参考和候选响应之间的语义相似性。因此，它们不能保证捕获所需的方面，即特异性。为了设计一个对任务灵活的度量，我们首先建议通过将这些品质分为三组来使这些品质易于管理：可理解性、合理性和可爱性，其中可爱性是任务必不可少的品质的组合。我们还提出了一种简单的方法来组合每个方面的指标，以获得一个称为 USL-H 的单一指标，它代表层次结构中的可理解性、敏感性和可爱性。我们证明 USL-H 分数与人类判断具有良好的相关性，并保持其对不同方面和指标的可配置性。</td><td>Vitou Phy   Yang Zhao   Akiko Aizawa</td></tr><tr><td>7</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00564&#39;]">Recent Neural Methods on Slot Filling and Intent Classification for Task-Oriented Dialogue Systems: A Survey</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00564">https://arxiv.org/pdf/2011.00564</a></td><td>In recent years, fostered by deep learning technologies and by the high demand for conversational AI, various approaches have been proposed that address the capacity to elicit and understand user’s needs in task-oriented dialogue systems. We focus on two core tasks, slot filling (SF) and intent classification (IC), and survey how neural-based models have rapidly evolved to address natural language understanding in dialogue systems. We introduce three neural architectures: independent model, which model SF and IC separately, joint models, which exploit the mutual benefit of the two tasks simultaneously, and transfer learning models, that scale the model to new domains. We discuss the current state of the research in SF and IC and highlight challenges that still require attention.</td><td>近年来，在深度学习技术和对对话式 AI 的高需求的推动下，已经提出了各种方法来解决在面向任务的对话系统中引发和理解用户需求的能力。我们专注于两个核心任务，槽填充 (SF) 和意图分类 (IC)，并调查基于神经的模型如何快速发展以解决对话系统中的自然语言理解问题。我们引入了三种神经架构：独立模型，分别对 SF 和 IC 进行建模，联合模型，同时利用两个任务的互利，以及迁移学习模型，将模型扩展到新领域。我们讨论了 SF 和 IC 的研究现状，并强调了仍然需要关注的挑战。</td><td>Samuel Louvan   Bernardo Magnini</td></tr></tbody></table></div><h2 id="文本生成"><a href="#文本生成" class="headerlink" title="文本生成"></a>文本生成</h2><h3 id="ACL-2"><a href="#ACL-2" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.03432&#39;]">Generalising Multilingual Concept-to-Text NLG with Language Agnostic Delexicalisation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.03432">https://arxiv.org/pdf/2105.03432</a></td><td>Concept-to-text Natural Language Generation is the task of expressing an input meaning representation in natural language. Previous approaches in this task have been able to generalise to rare or unseen instances by relying on a delexicalisation of the input. However, this often requires that the input appears verbatim in the output text. This poses challenges in multilingual settings, where the task expands to generate the output text in multiple languages given the same input. In this paper, we explore the application of multilingual models in concept-to-text and propose Language Agnostic Delexicalisation, a novel delexicalisation method that uses multilingual pretrained embeddings, and employs a character-level post-editing model to inflect words in their correct form during relexicalisation. Our experiments across five datasets and five languages show that multilingual models outperform monolingual models in concept-to-text and that our framework outperforms previous approaches, especially for low resource languages.</td><td>概念到文本的自然语言生成是用自然语言表达输入意义表示的任务。此任务中的先前方法已经能够通过依赖于输入的去词法化来推广到罕见或看不见的实例。但是，这通常要求输入在输出文本中逐字显示。这给多语言设置带来了挑战，在这种情况下，任务扩展为在给定相同输入的情况下以多种语言生成输出文本。在本文中，我们探索了多语言模型在概念到文本中的应用，并提出了 Language Agnostic Delexicalisation，这是一种新的 delexicalisation 方法，它使用多语言预训练嵌入，并采用字符级后编辑模型以正确的形式对单词进行变形在词法化过程中。我们对五个数据集和五种语言的实验表明，多语言模型在概念到文本方面优于单语模型，并且我们的框架优于以前的方法，尤其是对于低资源语言。</td><td>Giulio Zhou   Gerasimos Lampouras</td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00190&#39;]">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2101.00190">https://arxiv.org/pdf/2101.00190</a></td><td>Fine-tuning is the de facto way to leverage large pretrained language models to perform downstream tasks. However, it modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen, but optimizes a small continuous task-specific vector (called the prefix). Prefix-tuning draws inspiration from prompting, allowing subsequent tokens to attend to this prefix as if it were “virtual tokens”. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We find that by learning only 0.1\% of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics unseen during training.</td><td>微调是利用大型预训练语言模型执行下游任务的事实上的方法。然而，它修改了所有语言模型参数，因此需要为每个任务存储一个完整的副本。在本文中，我们提出了前缀调整，这是自然语言生成任务微调的轻量级替代方案，它保持语言模型参数冻结，但优化了一个小的连续任务特定向量（称为前缀）。前缀调整从提示中汲取灵感，允许后续标记关注这个前缀，就好像它是“虚拟标记”一样。我们将前缀调整应用于 GPT-2 以生成表格到文本，并应用于 BART 以进行汇总。我们发现，通过仅学习 0.1% 的参数，前缀调整在全数据设置中获得了可比的性能，在低数据设置中优于微调，并且可以更好地外推到在训练期间未见过的主题的示例。</td><td>Xiang Lisa Li   Percy Liang</td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2101.00288&#39;]">Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models</a></td><td></td><td><a href="https://github.com/tongshuangwu/polyjuice">https://github.com/tongshuangwu/polyjuice</a></td><td><a href="https://arxiv.org/pdf/2101.00288">https://arxiv.org/pdf/2101.00288</a></td><td>While counterfactual examples are useful for analysis and training of NLP models, current generation methods either rely on manual labor to create very few counterfactuals, or only instantiate limited types of perturbations such as paraphrases or word substitutions. We present Polyjuice, a general-purpose counterfactual generator that allows for control over perturbation types and locations, trained by finetuning GPT-2 on multiple datasets of paired sentences. We show that Polyjuice produces diverse sets of realistic counterfactuals, which in turn are useful in various distinct applications: improving training and evaluation on three different tasks (with around 70% less annotation effort than manual generation), augmenting state-of-the-art explanation techniques, and supporting systematic counterfactual error analysis by revealing behaviors easily missed by human experts.</td><td>虽然反事实示例对于 NLP 模型的分析和训练很有用，但当前的生成方法要么依靠手工劳动来创建很少的反事实，要么仅实例化有限类型的扰动，例如释义或单词替换。我们展示了 Polyjuice，一种通用的反事实生成器，允许控制扰动类型和位置，通过在多个成对句子数据集上微调 GPT-2 进行训练。我们展示了 Polyjuice 产生了多种真实的反事实，这些反事实反过来又可用于各种不同的应用：改进对三个不同任务的训练和评估（比手动生成减少大约 70% 的注释工作），增强最先进的技术解释技术，并通过揭示人类专家容易遗漏的行为来支持系统的反事实错误分析。</td><td>Tongshuang Wu   Marco Tulio Ribeiro   Jeffrey Heer   Daniel S. Weld</td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15786&#39;]">Conditional Generation of Temporally-ordered Event Sequences</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15786">https://arxiv.org/pdf/2012.15786</a></td><td>Models of narrative schema knowledge have proven useful for a range of event-related tasks, but they typically do not capture the temporal relationships between events. We propose a single model that addresses both temporal ordering, sorting given events into the order they occurred, and event infilling, predicting new events which fit into an existing temporally-ordered sequence. We use a BART-based conditional generation model that can capture both temporality and common event co-occurrence, meaning it can be flexibly applied to different tasks in this space. Our model is trained as a denoising autoencoder: we take temporally-ordered event sequences, shuffle them, delete some events, and then attempt to recover the original event sequence. This task teaches the model to make inferences given incomplete knowledge about the events in an underlying scenario. On the temporal ordering task, we show that our model is able to unscramble event sequences from existing datasets without access to explicitly labeled temporal training data, outperforming both a BERT-based pairwise model and a BERT-based pointer network. On event infilling, human evaluation shows that our model is able to generate events that fit better temporally into the input events when compared to GPT-2 story completion models.</td><td></td><td>Shih-Ting Lin   Nathanael Chambers   Greg Durrett</td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.06471&#39;]">Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.06471">https://arxiv.org/pdf/2106.06471</a></td><td>Medical report generation is one of the most challenging tasks in medical image analysis. Although existing approaches have achieved promising results, they either require a predefined template database in order to retrieve sentences or ignore the hierarchical nature of medical report generation. To address these issues, we propose MedWriter that incorporates a novel hierarchical retrieval mechanism to automatically extract both report and sentence-level templates for clinically accurate report generation. MedWriter first employs the Visual-Language Retrieval~(VLR) module to retrieve the most relevant reports for the given images. To guarantee the logical coherence between sentences, the Language-Language Retrieval~(LLR) module is introduced to retrieve relevant sentences based on the previous generated description. At last, a language decoder fuses image features and features from retrieved reports and sentences to generate meaningful medical reports. We verified the effectiveness of our model by automatic evaluation and human evaluation on two datasets, i.e., Open-I and MIMIC-CXR.</td><td>医学报告生成是医学图像分析中最具挑战性的任务之一。尽管现有方法已经取得了可喜的成果，但它们要么需要一个预定义的模板数据库来检索句子，要么忽略医疗报告生成的层次性。为了解决这些问题，我们提出了 MedWriter，它结合了一种新颖的分层检索机制，可以自动提取报告和句子级模板，以生成临床准确的报告。 MedWriter 首先使用 Visual-Language Retrieval~(VLR) 模块来检索给定图像的最相关报告。为了保证句子之间的逻辑连贯性，引入了Language-Language Retrieval~(LLR)模块，根据之前生成的描述检索相关句子。最后，语言解码器将图像特征与检索到的报告和句子的特征融合，以生成有意义的医学报告。我们通过对两个数据集（即 Open-I 和 MIMIC-CXR）的自动评估和人工评估来验证我们模型的有效性。</td><td>Xingyi Yang   Muchao Ye   Quanzeng You   Fenglong Ma</td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.15053&#39;]">Factorising Meaning and Form for Intent-Preserving Paraphrasing</a></td><td></td><td><a href="https://github.com/tomhosking/separator">https://github.com/tomhosking/separator</a></td><td><a href="https://arxiv.org/pdf/2105.15053">https://arxiv.org/pdf/2105.15053</a></td><td>We propose a method for generating paraphrases of English questions that retain the original intent but use a different surface form. Our model combines a careful choice of training objective with a principled information bottleneck, to induce a latent encoding space that disentangles meaning and form. We train an encoder-decoder model to reconstruct a question from a paraphrase with the same meaning and an exemplar with the same surface form, leading to separated encoding spaces. We use a Vector-Quantized Variational Autoencoder to represent the surface form as a set of discrete latent variables, allowing us to use a classifier to select a different surface form at test time. Crucially, our method does not require access to an external source of target exemplars. Extensive experiments and a human evaluation show that we are able to generate paraphrases with a better tradeoff between semantic preservation and syntactic novelty compared to previous methods.</td><td>我们提出了一种生成保留原始意图但使用不同表面形式的英语问题释义的方法。我们的模型将精心选择的训练目标与原则性的信息瓶颈相结合，以诱导潜在的编码空间，将意义和形式分开。我们训练一个编码器-解码器模型，以从具有相同含义的释义和具有相同表面形式的示例中重建问题，从而导致分离的编码空间。我们使用矢量量化变分自编码器将表面形式表示为一组离散的潜在变量，允许我们在测试时使用分类器选择不同的表面形式。至关重要的是，我们的方法不需要访问目标示例的外部源。广泛的实验和人工评估表明，与以前的方法相比，我们能够生成在语义保留和句法新颖性之间具有更好权衡的释义。</td><td>Tom Hosking   Mirella Lapata</td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00210&#39;]">Improving Formality Style Transfer with Context-Aware Rule Injection</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2106.00210">https://arxiv.org/pdf/2106.00210</a></td><td>Models pre-trained on large-scale regular text corpora often do not work well for user-generated data where the language styles differ significantly from the mainstream text. Here we present Context-Aware Rule Injection (CARI), an innovative method for formality style transfer (FST). CARI injects multiple rules into an end-to-end BERT-based encoder and decoder model. It learns to select optimal rules based on context. The intrinsic evaluation showed that CARI achieved the new highest performance on the FST benchmark dataset. Our extrinsic evaluation showed that CARI can greatly improve the regular pre-trained models’ performance on several tweet sentiment analysis tasks.</td><td>在大规模常规文本语料库上预训练的模型通常不适用于语言风格与主流文本显着不同的用户生成数据。在这里，我们提出了上下文感知规则注入 (CARI)，这是一种形式风格转移 (FST) 的创新方法。 CARI 将多个规则注入基于端到端 BERT 的编码器和解码器模型。它学习根据上下文选择最佳规则。内在评估表明，CARI 在 FST 基准数据集上取得了新的最高性能。我们的外部评估表明，CARI 可以极大地提高常规预训练模型在多项推文情感分析任务上的性能。</td><td>Zonghai Yao   Hong Yu</td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2107.01875&#39;]">DeepRapper: Neural Rap Generation with Rhyme and Rhythm Modeling</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2107.01875">https://arxiv.org/pdf/2107.01875</a></td><td>Rap generation, which aims to produce lyrics and corresponding singing beats, needs to model both rhymes and rhythms. Previous works for rap generation focused on rhyming lyrics but ignored rhythmic beats, which are important for rap performance. In this paper, we develop DeepRapper, a Transformer-based rap generation system that can model both rhymes and rhythms. Since there is no available rap dataset with rhythmic beats, we develop a data mining pipeline to collect a large-scale rap dataset, which includes a large number of rap songs with aligned lyrics and rhythmic beats. Second, we design a Transformer-based autoregressive language model which carefully models rhymes and rhythms. Specifically, we generate lyrics in the reverse order with rhyme representation and constraint for rhyme enhancement and insert a beat symbol into lyrics for rhythm/beat modeling. To our knowledge, DeepRapper is the first system to generate rap with both rhymes and rhythms. Both objective and subjective evaluations demonstrate that DeepRapper generates creative and high-quality raps with rhymes and rhythms. Code will be released on GitHub.</td><td>Rap 生成旨在生成歌词和相应的歌唱节拍，需要对韵律和节奏进行建模。以前的说唱创作专注于押韵歌词，但忽略了对说唱表演很重要的节奏节拍。在本文中，我们开发了 DeepRapper，这是一种基于 Transformer 的说唱生成系统，可以对韵律和节奏进行建模。由于没有可用的有节奏节拍的说唱数据集，我们开发了一个数据挖掘管道来收集大规模的说唱数据集，其中包括大量具有对齐歌词和节奏节拍的说唱歌曲。其次，我们设计了一个基于 Transformer 的自回归语言模型，它仔细地对韵律和节奏进行建模。具体来说，我们以相反的顺序生成带有韵律表示和韵律增强约束的歌词，并在歌词中插入节拍符号以进行节奏/节拍建模。据我们所知，DeepRapper 是第一个同时生成韵律和节奏的说唱系统。客观和主观的评价都表明，DeepRapper 能够创作出具有韵律和节奏感的创造性和高质量的说唱。代码将在 GitHub 上发布。</td><td>Lanqing Xue   Kaitao Song   Duocai Wu   Xu Tan   Nevin L. Zhang   Tao Qin   Wei-Qiang Zhang   Tie-Yan Liu</td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.15329&#39;]">Generating Landmark Navigation Instructions from Maps as a Graph-to-Text Problem</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.15329">https://arxiv.org/pdf/2012.15329</a></td><td>Car-focused navigation services are based on turns and distances of named streets, whereas navigation instructions naturally used by humans are centered around physical objects called landmarks. We present a neural model that takes OpenStreetMap representations as input and learns to generate navigation instructions that contain visible and salient landmarks from human natural language instructions. Routes on the map are encoded in a location- and rotation-invariant graph representation that is decoded into natural language instructions. Our work is based on a novel dataset of 7,672 crowd-sourced instances that have been verified by human navigation in Street View. Our evaluation shows that the navigation instructions generated by our system have similar properties as human-generated instructions, and lead to successful human navigation in Street View.</td><td>以汽车为中心的导航服务基于命名街道的转弯和距离，而人类自然使用的导航指令则以称为地标的物理对象为中心。我们提出了一个神经模型，该模型将 OpenStreetMap 表示作为输入，并学习生成包含来自人类自然语言指令的可见和显着地标的导航指令。地图上的路线以位置和旋转不变的图形表示进行编码，该图形表示被解码为自然语言指令。我们的工作基于一个包含 7,672 个众包实例的新数据集，这些实例已通过街景中的人工导航进行验证。我们的评估表明，我们系统生成的导航指令与人工生成的指令具有相似的特性，并导致街景中的人工导航成功。</td><td>Raphael Schumann   Stefan Riezler</td></tr><tr><td>10</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.11134&#39;]">One2Set: Generating Diverse Keyphrases as a Set</a></td><td></td><td><a href="https://github.com/jiacheng-ye/kg_one2set">https://github.com/jiacheng-ye/kg_one2set</a></td><td><a href="https://arxiv.org/pdf/2105.11134">https://arxiv.org/pdf/2105.11134</a></td><td>Recently, the sequence-to-sequence models have made remarkable progress on the task of keyphrase generation (KG) by concatenating multiple keyphrases in a predefined order as a target sequence during training. However, the keyphrases are inherently an unordered set rather than an ordered sequence. Imposing a predefined order will introduce wrong bias during training, which can highly penalize shifts in the order between keyphrases. In this work, we propose a new training paradigm One2Set without predefining an order to concatenate the keyphrases. To fit this paradigm, we propose a novel model that utilizes a fixed set of learned control codes as conditions to generate a set of keyphrases in parallel. To solve the problem that there is no correspondence between each prediction and target during training, we propose a $K$-step target assignment mechanism via bipartite matching, which greatly increases the diversity and reduces the duplication ratio of generated keyphrases. The experimental results on multiple benchmarks demonstrate that our approach significantly outperforms the state-of-the-art methods.</td><td>最近，序列到序列模型通过在训练期间以预定义的顺序连接多个关键短语作为目标序列，在关键短语生成 (KG) 任务上取得了显着进展。然而，关键短语本质上是一个无序的集合，而不是一个有序的序列。强加预定义的顺序会在训练期间引入错误的偏差，这会严重影响关键短语之间的顺序变化。在这项工作中，我们提出了一种新的训练范式 One2Set，而无需预先定义连接关键短语的顺序。为了适应这种范式，我们提出了一种新模型，该模型利用一组固定的学习控制代码作为条件来并行生成一组关键短语。为了解决训练过程中每个预测和目标之间没有对应关系的问题，我们提出了一种通过二部匹配的$K$-step目标分配机制，大大增加了多样性并减少了生成的关键短语的重复率。多个基准的实验结果表明，我们的方法明显优于最先进的方法。</td><td>Jiacheng Ye   Tao Gui   Yichao Luo   Yige Xu   Qi Zhang</td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03829&#39;]">Distilling Knowledge Learned in BERT for Text Generation</a></td><td></td><td><a href="https://github.com/ChenRocks/Distill-BERT-Textgen">https://github.com/ChenRocks/Distill-BERT-Textgen</a></td><td><a href="https://arxiv.org/pdf/1911.03829">https://arxiv.org/pdf/1911.03829</a></td><td>Large-scale pre-trained language model such as BERT has achieved great success in language understanding tasks. However, it remains an open question how to utilize BERT for language generation. In this paper, we present a novel approach, Conditional Masked Language Modeling (C-MLM), to enable the finetuning of BERT on target generation tasks. The finetuned BERT (teacher) is exploited as extra supervision to improve conventional Seq2Seq models (student) for better text generation performance. By leveraging BERT’s idiosyncratic bidirectional nature, distilling knowledge learned in BERT can encourage auto-regressive Seq2Seq models to plan ahead, imposing global sequence-level supervision for coherent text generation. Experiments show that the proposed approach significantly outperforms strong Transformer baselines on multiple language generation tasks such as machine translation and text summarization. Our proposed model also achieves new state of the art on IWSLT German-English and English-Vietnamese MT datasets. Code is available at <a href="https://github.com/ChenRocks/Distill-BERT-Textgen">https://github.com/ChenRocks/Distill-BERT-Textgen</a>.</td><td>BERT 等大规模预训练语言模型在语言理解任务中取得了巨大成功。然而，如何利用 BERT 进行语言生成仍然是一个悬而未决的问题。在本文中，我们提出了一种新方法，即条件掩码语言建模 (C-MLM)，以实现 BERT 在目标生成任务上的微调。微调的 BERT（教师）被用作额外的监督来改进传统的 Seq2Seq 模型（学生）以获得更好的文本生成性能。通过利用 BERT 的特殊双向性质，提炼在 BERT 中学到的知识可以鼓励自回归 Seq2Seq 模型提前计划，为连贯文本生成施加全局序列级监督。实验表明，所提出的方法在机器翻译和文本摘要等多语言生成任务上明显优于强 Transformer 基线。我们提出的模型还在 IWSLT 德语-英语和英语-越南语 MT 数据集上达到了最新的技术水平。代码可在 <a href="https://github.com/ChenRocks/Distill-BERT-Textgen">https://github.com/ChenRocks/Distill-BERT-Textgen</a> 获得。</td><td>Yen-Chun Chen   Zhe Gan   Yu Cheng   Jingzhou Liu   Jingjing Liu</td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.08022&#39;]">Rigid Formats Controlled Text Generation</a></td><td></td><td><a href="https://github.com/lipiji/SongNet">https://github.com/lipiji/SongNet</a></td><td><a href="https://arxiv.org/pdf/2004.08022">https://arxiv.org/pdf/2004.08022</a></td><td>Neural text generation has made tremendous progress in various tasks. One common characteristic of most of the tasks is that the texts are not restricted to some rigid formats when generating. However, we may confront some special text paradigms such as Lyrics (assume the music score is given), Sonnet, SongCi (classical Chinese poetry of the Song dynasty), etc. The typical characteristics of these texts are in three folds: (1) They must comply fully with the rigid predefined formats. (2) They must obey some rhyming schemes. (3) Although they are restricted to some formats, the sentence integrity must be guaranteed. To the best of our knowledge, text generation based on the predefined rigid formats has not been well investigated. Therefore, we propose a simple and elegant framework named SongNet to tackle this problem. The backbone of the framework is a Transformer-based auto-regressive language model. Sets of symbols are tailor-designed to improve the modeling performance especially on format, rhyme, and sentence integrity. We improve the attention mechanism to impel the model to capture some future information on the format. A pre-training and fine-tuning framework is designed to further improve the generation quality. Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates significantly better results in terms of both automatic metrics and the human evaluation.</td><td>神经文本生成在各种任务中取得了巨大的进步。大多数任务的一个共同特征是文本在生成时不受某些严格格式的限制。但是，我们可能会遇到一些特殊的文本范式，例如歌词（假设给定乐谱）、十四行诗、宋词（宋代中国古典诗歌）等。这些文本的典型特征有三方面：（1）它们必须完全符合严格的预定义格式。 (2) 他们必须遵守一些押韵方案。 (3) 虽然限于某些格式，但必须保证句子的完整性。据我们所知，基于预定义的刚性格式的文本生成尚未得到很好的研究。因此，我们提出了一个简单而优雅的框架 SongNet 来解决这个问题。该框架的主干是一个基于 Transformer 的自回归语言模型。符号集是量身定制的，以提高建模性能，尤其是在格式、韵律和句子完整性方面。我们改进了注意力机制以促使模型捕获有关格式的一些未来信息。预训练和微调框架旨在进一步提高生成质量。在两个收集的语料库上进行的大量实验表明，我们提出的框架在自动度量和人工评估方面都产生了明显更好的结果。</td><td>Piji Li   Haisong Zhang   Xiaojiang Liu   Shuming Shi</td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.12704&#39;]">Semantic Graphs for Generating Deep Questions</a></td><td></td><td><a href="https://github.com/WING-NUS/SG-Deep-Question-Generation">https://github.com/WING-NUS/SG-Deep-Question-Generation</a></td><td><a href="https://arxiv.org/pdf/2004.12704">https://arxiv.org/pdf/2004.12704</a></td><td>This paper proposes the problem of Deep Question Generation (DQG), which aims to generate complex questions that require reasoning over multiple pieces of information of the input passage. In order to capture the global structure of the document and facilitate reasoning, we propose a novel framework which first constructs a semantic-level graph for the input document and then encodes the semantic graph by introducing an attention-based GGNN (Att-GGNN). Afterwards, we fuse the document-level and graph-level representations to perform joint training of content selection and question decoding. On the HotpotQA deep-question centric dataset, our model greatly improves performance over questions requiring reasoning over multiple facts, leading to state-of-the-art performance. The code is publicly available at <a href="https://github.com/WING-NUS/SG-Deep-Question-Generation">https://github.com/WING-NUS/SG-Deep-Question-Generation</a>.</td><td>本文提出了深度问题生成 (DQG) 问题，旨在生成需要对输入段落的多条信息进行推理的复杂问题。为了捕获文档的全局结构并促进推理，我们提出了一种新颖的框架，该框架首先为输入文档构建语义级图，然后通过引入基于注意力的 GGNN（Att-GGNN）对语义图进行编码。之后，我们融合文档级和图形级表示来执行内容选择和问题解码的联合训练。在 HotpotQA 以深度问题为中心的数据集上，我们的模型大大提高了需要对多个事实进行推理的问题的性能，从而达到最先进的性能。该代码可在 <a href="https://github.com/WING-NUS/SG-Deep-Question-Generation">https://github.com/WING-NUS/SG-Deep-Question-Generation</a> 上公开获得。</td><td>Liangming Pan   Yuxi Xie   Yansong Feng   Tat-Seng Chua   Min-Yen Kan</td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14257&#39;]">Politeness Transfer: A Tag and Generate Approach</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14257">https://arxiv.org/pdf/2004.14257</a></td><td>This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the meaning. We also provide a dataset of more than 1.39 instances automatically labeled for politeness to encourage benchmark evaluations on this new task. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For politeness as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for grammaticality, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at <a href="https://github.com/tag-and-generate">https://github.com/tag-and-generate</a>.</td><td>本文介绍了一种礼貌转移的新任务，即在保留意义的同时将非礼貌句子转换为礼貌句子。我们还提供了一个包含超过 1.39 个自动标记礼貌的实例的数据集，以鼓励对这项新任务进行基准评估。我们设计了一个标签并生成了识别风格属性的管道，随后在保留大部分源内容的同时以目标风格生成了一个句子。对于礼貌以及其他五个转移任务，我们的模型在内容保存的自动度量方面优于最先进的方法，在样式转移准确性方面具有可比或更好的性能。此外，我们的模型在语法方面超越了现有的人类评估方法，这意味着在所有六种风格迁移任务中的保留和迁移准确性。数据和代码位于 <a href="https://github.com/tag-and-generate。">https://github.com/tag-and-generate。</a></td><td>Aman Madaan   Amrith Setlur   Tanmay Parekh   Barnabas Poczos   Graham Neubig   Yiming Yang   Ruslan Salakhutdinov   Alan W Black   Shrimai Prabhumoye</td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.09123&#39;]">GPT-too: A language-model-first approach for AMR-to-text generation</a></td><td></td><td><a href="https://github.com/IBM/GPT-too-AMR2text">https://github.com/IBM/GPT-too-AMR2text</a></td><td><a href="https://arxiv.org/pdf/2005.09123">https://arxiv.org/pdf/2005.09123</a></td><td>Meaning Representations (AMRs) are broad-coverage sentence-level semantic graphs. Existing approaches to generating text from AMR have focused on training sequence-to-sequence or graph-to-sequence models on AMR annotated data only. In this paper, we propose an alternative approach that combines a strong pre-trained language model with cycle consistency-based re-scoring. Despite the simplicity of the approach, our experimental results show these models outperform all previous techniques on the English LDC2017T10dataset, including the recent use of transformer architectures. In addition to the standard evaluation metrics, we provide human evaluation experiments that further substantiate the strength of our approach.</td><td>含义表示（AMR）是广泛覆盖的句子级语义图。现有的从 AMR 生成文本的方法侧重于仅在 AMR 注释数据上训练序列到序列或图到序列模型。在本文中，我们提出了一种替代方法，将强大的预训练语言模型与基于循环一致性的重新评分相结合。尽管该方法很简单，但我们的实验结果表明，这些模型在英国 LDC2017T10 数据集上的表现优于之前的所有技术，包括最近使用的变压器架构。除了标准的评估指标外，我们还提供了人工评估实验，进一步证实了我们方法的优势。</td><td>Manuel Mager   Ramon Fernandez Astudillo   Tahira Naseem   Md Arafat Sultan   Young-Suk Lee   Radu Florian   Salim Roukos</td></tr><tr><td>16</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.04560&#39;]">Posterior Control of Blackbox Generation</a></td><td></td><td><a href="https://github.com/XiangLi1999/PosteriorControl-NLG">https://github.com/XiangLi1999/PosteriorControl-NLG</a></td><td><a href="https://arxiv.org/pdf/2005.04560">https://arxiv.org/pdf/2005.04560</a></td><td>Text generation often requires high-precision output that obeys task-specific rules. This fine-grained control is difficult to enforce with off-the-shelf deep learning models. In this work, we consider augmenting neural generation models with discrete control states learned through a structured latent-variable approach. Under this formulation, task-specific knowledge can be encoded through a range of rich, posterior constraints that are effectively trained into the model. This approach allows users to ground internal model decisions based on prior knowledge, without sacrificing the representational power of neural generative models. Experiments consider applications of this approach for text generation. We find that this method improves over standard benchmarks, while also providing fine-grained control.</td><td>文本生成通常需要遵守特定任务规则的高精度输出。这种细粒度的控制很难用现成的深度学习模型来实施。在这项工作中，我们考虑使用通过结构化潜在变量方法学习的离散控制状态来增强神经生成模型。在这个公式下，特定任务的知识可以通过一系列丰富的后验约束进行编码，这些约束被有效地训练到模型中。这种方法允许用户基于先验知识进行内部模型决策，而不会牺牲神经生成模型的表示能力。实验考虑了这种方法在文本生成中的应用。我们发现这种方法比标准基准有所改进，同时还提供了细粒度的控制。</td><td>Xiang Lisa Li   Alexander M. Rush</td></tr><tr><td>17</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.07522&#39;]">Parallel Data Augmentation for Formality Style Transfer</a></td><td></td><td><a href="https://github.com/lancopku/Augmented_Data_for_FST">https://github.com/lancopku/Augmented_Data_for_FST</a></td><td><a href="https://arxiv.org/pdf/2005.07522">https://arxiv.org/pdf/2005.07522</a></td><td>The main barrier to progress in the task of Formality Style Transfer is the inadequacy of training data. In this paper, we study how to augment parallel data and propose novel and simple data augmentation methods for this task to obtain useful sentence pairs with easily accessible models and systems. Experiments demonstrate that our augmented parallel data largely helps improve formality style transfer when it is used to pre-train the model, leading to the state-of-the-art results in the GYAFC benchmark dataset.</td><td>形式风格迁移任务进展的主要障碍是训练数据的不足。在本文中，我们研究如何增强并行数据并为此任务提出新颖且简单的数据增强方法，以获得具有易于访问的模型和系统的有用句子对。实验表明，我们的增强并行数据在用于预训练模型时在很大程度上有助于改进形式风格转移，从而在 GYAFC 基准数据集中获得最先进的结果。</td><td>Yi Zhang   Tao Ge   Xu Sun</td></tr><tr><td>18</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.01096&#39;]">Neural Data-to-Text Generation via Jointly Learning the Segmentation and Correspondence</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.01096">https://arxiv.org/pdf/2005.01096</a></td><td>The neural attention model has achieved great success in data-to-text generation tasks. Though usually excelling at producing fluent text, it suffers from the problem of information missing, repetition and “hallucination”. Due to the black-box nature of the neural attention architecture, avoiding these problems in a systematic way is non-trivial. To address this concern, we propose to explicitly segment target text into fragment units and align them with their data correspondences. The segmentation and correspondence are jointly learned as latent variables without any human annotations. We further impose a soft statistical constraint to regularize the segmental granularity. The resulting architecture maintains the same expressive power as neural attention models, while being able to generate fully interpretable outputs with several times less computational cost. On both E2E and WebNLG benchmarks, we show the proposed model consistently outperforms its neural attention counterparts.</td><td></td><td>Xiaoyu Shen   Ernie Chang   Hui Su   Jie Zhou   Dietrich Klakow</td></tr><tr><td>19</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1910.13461&#39;]">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1910.13461">https://arxiv.org/pdf/1910.13461</a></td><td>We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and many other more recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of the original sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa with comparable training resources on GLUE and SQuAD, achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 6 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also report ablation experiments that replicate other pretraining schemes within the BART framework, to better measure which factors most influence end-task performance.</td><td>我们提出了 BART，一种用于预训练序列到序列模型的去噪自动编码器。 BART 通过 (1) 使用任意噪声函数破坏文本和 (2) 学习模型来重建原始文本进行训练。它使用标准的基于 Transformer 的神经机器翻译架构，尽管它很简单，但可以看作是对 BERT（由于双向编码器）、GPT（带有从左到右的解码器）和许多其他最近的预训练方案的泛化.我们评估了许多噪声方法，通过随机打乱原始句子的顺序和使用新颖的填充方案来找到最佳性能，其中文本的跨度被替换为单个掩码标记。 BART 在针对文本生成进行微调时特别有效，但也适用于理解任务。它将 RoBERTa 的性能与 GLUE 和 SQuAD 上的可比训练资源相匹配，在一系列抽象对话、问答和总结任务上取得了最新的最新成果，增益高达 6 ROUGE。 BART 还为机器翻译提供了比反向翻译系统增加 1.1 BLEU 的能力，并且只进行了目标语言预训练。我们还报告了在 BART 框架内复制其他预训练方案的消融实验，以更好地衡量哪些因素对最终任务性能影响最大。</td><td>Mike Lewis   Yinhan Liu   Naman Goyal   Marjan Ghazvininejad   Abdelrahman Mohamed   Omer Levy   Ves Stoyanov   Luke Zettlemoyer</td></tr><tr><td>20</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03882&#39;]">Pre-train and Plug-in: Flexible Conditional Text Generation with Variational Auto- Encoders</a></td><td></td><td><a href="https://github.com/WHUIR/PPVAE">https://github.com/WHUIR/PPVAE</a></td><td><a href="https://arxiv.org/pdf/1911.03882">https://arxiv.org/pdf/1911.03882</a></td><td>Conditional Text Generation has drawn much attention as a topic of Natural Language Generation (NLG) which provides the possibility for humans to control the properties of generated contents. Current conditional generation models cannot handle emerging conditions due to their joint end-to-end learning fashion. When a new condition added, these techniques require full retraining. In this paper, we present a new framework named Pre-train and Plug-in Variational Auto-Encoder (PPVAE) towards flexible conditional text generation. PPVAE decouples the text generation module from the condition representation module to allow “one-to-many” conditional generation. When a fresh condition emerges, only a lightweight network needs to be trained and works as a plug-in for PPVAE, which is efficient and desirable for real-world applications. Extensive experiments demonstrate the superiority of PPVAE against the existing alternatives with better conditionality and diversity but less training effort.</td><td>条件文本生成作为自然语言生成 (NLG) 的一个主题备受关注，它为人类提供了控制生成内容属性的可能性。由于它们的联合端到端学习方式，当前的条件生成模型无法处理新出现的条件。当添加新条件时，这些技术需要完全重新训练。在本文中，我们提出了一个名为 Pre-train and Plug-in Variational Auto-Encoder (PPVAE) 的新框架，用于灵活的条件文本生成。 PPVAE 将文本生成模块与条件表示模块分离，以允许“一对多”条件生成。当新的条件出现时，只需要训练一个轻量级网络，并作为 PPVAE 的插件工作，这对于现实世界的应用是有效的和可取的。大量实验证明了 PPVAE 相对于现有替代方案的优越性，具有更好的条件和多样性，但训练工作量更少。</td><td>Yu Duan   Canwen Xu   Jiaxin Pei   Jialong Han   Chenliang Li</td></tr><tr><td>21</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1909.10158&#39;]">Two Birds, One Stone: A Simple, Unified Model for Text Generation from Structured and Unstructured Data</a></td><td></td><td><a href="https://github.com/h-shahidi/2birds-gen">https://github.com/h-shahidi/2birds-gen</a></td><td><a href="https://arxiv.org/pdf/1909.10158">https://arxiv.org/pdf/1909.10158</a></td><td>A number of researchers have recently questioned the necessity of increasingly complex neural network (NN) architectures. In particular, several recent papers have shown that simpler, properly tuned models are at least competitive across several NLP tasks. In this work, we show that this is also the case for text generation from structured and unstructured data. We consider neural table-to-text generation and neural question generation (NQG) tasks for text generation from structured and unstructured data, respectively. Table-to-text generation aims to generate a description based on a given table, and NQG is the task of generating a question from a given passage where the generated question can be answered by a certain sub-span of the passage using NN models. Experimental results demonstrate that a basic attention-based seq2seq model trained with the exponential moving average technique achieves the state of the art in both tasks. Code is available at <a href="https://github.com/h-shahidi/2birds-gen">https://github.com/h-shahidi/2birds-gen</a>.</td><td>许多研究人员最近质疑日益复杂的神经网络 (NN) 架构的必要性。特别是，最近的几篇论文表明，更简单、经过适当调整的模型至少在多个 NLP 任务中具有竞争力。在这项工作中，我们表明这也是从结构化和非结构化数据生成文本的情况。我们分别考虑从结构化和非结构化数据生成文本的神经表格到文本生成和神经问题生成 (NQG) 任务。表到文本生成旨在基于给定的表生成描述，而 NQG 是从给定的段落中生成问题的任务，其中生成的问题可以使用 NN 模型通过段落的某个子跨度来回答。实验结果表明，使用指数移动平均技术训练的基于注意力的基本 seq2seq 模型在这两个任务中都达到了最先进的水平。代码可在 <a href="https://github.com/h-shahidi/2birds-gen">https://github.com/h-shahidi/2birds-gen</a> 获得。</td><td>Hamidreza Shahidi   Ming Li   Jimmy Lin</td></tr><tr><td>22</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.02247&#39;]">Unsupervised Opinion Summarization as Copycat-Review Generation</a></td><td></td><td><a href="https://github.com/ixlan/CopyCat-abstractive-opinion-summarizer">https://github.com/ixlan/CopyCat-abstractive-opinion-summarizer</a></td><td><a href="https://arxiv.org/pdf/1911.02247">https://arxiv.org/pdf/1911.02247</a></td><td>Opinion summarization is the task of automatically creating summaries that reflect subjective information expressed in multiple documents, such as product reviews. While the majority of previous work has focused on the extractive setting, i.e., selecting fragments from input reviews to produce a summary, we let the model generate novel sentences and hence produce abstractive summaries. Recent progress in summarization has seen the development of supervised models which rely on large quantities of document-summary pairs. Since such training data is expensive to acquire, we instead consider the unsupervised setting, in other words, we do not use any summaries in training. We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the “amount of novelty” going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, when generating summaries, we force the novelty to be minimal, and produce a text reflecting consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder model. Both individual reviews and the products they correspond to are associated with stochastic latent codes, and the review generator (“decoder”) has direct access to the text of input reviews through the pointer-generator mechanism. Experiments on Amazon and Yelp datasets, show that setting at test time the review’s latent code to its mean, allows the model to produce fluent and coherent summaries reflecting common opinions.</td><td>意见摘要是自动创建反映在多个文档中表达的主观信息（例如产品评论）的摘要的任务。虽然以前的大部分工作都集中在提取设置上，即从输入评论中选择片段以生成摘要，但我们让模型生成新颖的句子，从而生成抽象摘要。摘要的最新进展见证了依赖大量文档摘要对的监督模型的发展。由于获取此类训练数据的成本很高，因此我们转而考虑无监督设置，换句话说，我们在训练中不使用任何摘要。我们为评论集合定义了一个生成模型，该模型利用了一种直觉，即在给定一组产品的其他评论生成新评论时，我们应该能够控制进入新评论的“新颖性”，或者等效地，改变它偏离输入的程度。在测试时，在生成摘要时，我们将新颖性降至最低，并生成反映共识意见的文本。我们通过定义分层变分自编码器模型来捕捉这种直觉。个人评论和它们对应的产品都与随机潜在代码相关联，评论生成器（“解码器”）可以通过指针生成器机制直接访问输入评论的文本。在 Amazon 和 Yelp 数据集上的实验表明，在测试时将评论的潜在代码设置为其平均值，允许模型生成反映共同意见的流畅和连贯的摘要。</td><td>Arthur Bražinskas   Mirella Lapata   Ivan Titov</td></tr><tr><td>23</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2006.08101&#39;]">Evidence-Aware Inferential Text Generation with Vector Quantised Variational AutoEncoder</a></td><td></td><td><a href="https://github.com/microsoft/EA-VQ-VAE">https://github.com/microsoft/EA-VQ-VAE</a></td><td><a href="https://arxiv.org/pdf/2006.08101">https://arxiv.org/pdf/2006.08101</a></td><td>Generating inferential texts about an event in different perspectives requires reasoning over different contexts that the event occurs. Existing works usually ignore the context that is not explicitly provided, resulting in a context-independent semantic representation that struggles to support the generation. To address this, we propose an approach that automatically finds evidence for an event from a large text corpus, and leverages the evidence to guide the generation of inferential texts. Our approach works in an encoder-decoder manner and is equipped with a Vector Quantised-Variational Autoencoder, where the encoder outputs representations from a distribution over discrete variables. Such discrete representations enable automatically selecting relevant evidence, which not only facilitates evidence-aware generation, but also provides a natural way to uncover rationales behind the generation. Our approach provides state-of-the-art performance on both Event2Mind and ATOMIC datasets. More importantly, we find that with discrete representations, our model selectively uses evidence to generate different inferential texts.</td><td>从不同角度生成关于事件的推理文本需要对事件发生的不同上下文进行推理。现有作品通常会忽略未明确提供的上下文，从而导致难以支持生成的上下文无关语义表示。为了解决这个问题，我们提出了一种从大型文本语料库中自动寻找事件证据的方法，并利用这些证据来指导推理文本的生成。我们的方法以编码器-解码器的方式工作，并配备了矢量量化变分自动编码器，其中编码器输出离散变量分布的表示。这种离散表示能够自动选择相关证据，这不仅有利于证据意识的生成，而且还提供了一种自然的方式来揭示生成背后的基本原理。我们的方法在 Event2Mind 和 ATOMIC 数据集上都提供了最先进的性能。更重要的是，我们发现对于离散表示，我们的模型有选择地使用证据来生成不同的推理文本。</td><td>Daya Guo   Duyu Tang   Nan Duan   Jian Yin   Daxin Jiang   Ming Zhou</td></tr><tr><td>24</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.04696&#39;]">BLEURT: Learning Robust Metrics for Text Generation</a></td><td></td><td><a href="https://github.com/google-research/bleurt">https://github.com/google-research/bleurt</a></td><td><a href="https://arxiv.org/pdf/2004.04696">https://arxiv.org/pdf/2004.04696</a></td><td>Text generation has made significant advances in the last few years. Yet, evaluation metrics have lagged behind, as the most popular choices (e.g., BLEU and ROUGE) may correlate poorly with human judgments. We propose BLEURT, a learned evaluation metric based on BERT that can model human judgments with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize. BLEURT provides state-of-the-art results on the last three years of the WMT Metrics shared task and the WebNLG Competition dataset. In contrast to a vanilla BERT-based approach, it yields superior results even when the training data is scarce and out-of-distribution.</td><td>文本生成在过去几年中取得了重大进展。然而，评估指标已经落后，因为最流行的选择（例如，BLEU 和 ROUGE）可能与人类判断的相关性很差。我们提出了 BLEURT，这是一种基于 BERT 的学习评估指标，可以用几千个可能有偏见的训练示例对人类判断进行建模。我们方法的一个关键方面是一种新颖的预训练方案，它使用数百万个合成示例来帮助模型泛化。 BLEURT 提供了过去三年 WMT 指标共享任务和 WebNLG 竞赛数据集的最新结果。与基于 BERT 的普通方法相比，即使训练数据稀缺且分布不均时，它也能产生出色的结果。</td><td>Thibault Sellam   Dipanjan Das   Ankur P. Parikh</td></tr><tr><td>25</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01834&#39;]">Automatic Generation of High Quality CCGbanks for Parser Domain Adaptation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.01834">https://arxiv.org/pdf/1906.01834</a></td><td>We propose a new domain adaptation method for Combinatory Categorial Grammar (CCG) parsing, based on the idea of automatic generation of CCG corpora exploiting cheaper resources of dependency trees. Our solution is conceptually simple, and not relying on a specific parser architecture, making it applicable to the current best-performing parsers. We conduct extensive parsing experiments with detailed discussion; on top of existing benchmark datasets on (1) biomedical texts and (2) question sentences, we create experimental datasets of (3) speech conversation and (4) math problems. When applied to the proposed method, an off-the-shelf CCG parser shows significant performance gains, improving from 90.7% to 96.6% on speech conversation, and from 88.5% to 96.8% on math problems.</td><td>我们提出了一种用于组合分类语法（CCG）解析的新域适应方法，基于利用依赖树的更便宜资源自动生成 CCG 语料库的思想。我们的解决方案在概念上很简单，不依赖于特定的解析器架构，使其适用于当前性能最佳的解析器。我们进行了广泛的解析实验并进行了详细的讨论；在 (1) 生物医学文本和 (2) 问题句子的现有基准数据集之上，我们创建了 (3) 语音对话和 (4) 数学问题的实验数据集。当应用于所提出的方法时，现成的 CCG 解析器显示出显着的性能提升，语音对话从 90.7% 提高到 96.6%，数学问题从 88.5% 提高到 96.8%。</td><td>Masashi Yoshikawa   Hiroshi Noji   Koji Mineshima   Daisuke Bekki</td></tr><tr><td>26</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.07870&#39;]">PaperRobot: Incremental Draft Generation of Scientific Ideas</a></td><td></td><td><a href="https://github.com/EagleW/PaperRobot">https://github.com/EagleW/PaperRobot</a></td><td><a href="https://arxiv.org/pdf/1905.07870">https://arxiv.org/pdf/1905.07870</a></td><td>We present a PaperRobot who performs as an automatic research assistant by (1) conducting deep understanding of a large collection of human-written papers in a target domain and constructing comprehensive background knowledge graphs (KGs); (2) creating new ideas by predicting links from the background KGs, by combining graph attention and contextual text attention; (3) incrementally writing some key elements of a new paper based on memory-attention networks: from the input title along with predicted related entities to generate a paper abstract, from the abstract to generate conclusion and future work, and finally from future work to generate a title for a follow-on paper. Turing Tests, where a biomedical domain expert is asked to compare a system output and a human-authored string, show PaperRobot generated abstracts, conclusion and future work sections, and new titles are chosen over human-written ones up to 30%, 24% and 12% of the time, respectively.</td><td>我们展示了一个 PaperRobot，它通过（1）对目标领域的大量人工论文进行深入理解并构建全面的背景知识图（KG）； (2) 通过结合图注意力和上下文文本注意力从背景知识图谱中预测链接来创造新的想法； (3) 增量编写基于记忆注意力网络的新论文的一些关键元素：从输入标题和预测的相关实体生成论文摘要，从摘要生成结论和未来工作，最后从未来工作到为后续论文生成标题。图灵测试，要求生物医学领域专家比较系统输出和人工编写的字符串，显示 PaperRobot 生成的摘要、结论和未来工作部分，并且选择新标题而不是人工编写的标题高达 30% 和 24%和 12% 的时间，分别。</td><td>Qingyun Wang   Lifu Huang   Zhiying Jiang   Kevin Knight   Heng Ji   Mohit Bansal   Yi Luan</td></tr><tr><td>27</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03221&#39;]">Data-to-text Generation with Entity Modeling</a></td><td></td><td><a href="https://github.com/ratishsp/data2text-entity-py">https://github.com/ratishsp/data2text-entity-py</a></td><td><a href="https://arxiv.org/pdf/1906.03221">https://arxiv.org/pdf/1906.03221</a></td><td>Recent approaches to data-to-text generation have shown great promise thanks to the use of large-scale datasets and the application of neural network architectures which are trained end-to-end. These models rely on representation learning to select content appropriately, structure it coherently, and verbalize it grammatically, treating entities as nothing more than vocabulary tokens. In this work we propose an entity-centric neural architecture for data-to-text generation. Our model creates entity-specific representations which are dynamically updated. Text is generated conditioned on the data input and entity memory representations using hierarchical attention at each time step. We present experiments on the RotoWire benchmark and a (five times larger) new dataset on the baseball domain which we create. Our results show that the proposed model outperforms competitive baselines in automatic and human evaluation.</td><td>由于大规模数据集的使用和端到端训练的神经网络架构的应用，最近的数据到文本生成方法显示出了巨大的希望。这些模型依靠表示学习来适当地选择内容、连贯地构建内容并按语法表达，将实体视为词汇标记。在这项工作中，我们提出了一种以实体为中心的神经架构，用于数据到文本的生成。我们的模型创建了动态更新的特定于实体的表示。文本是根据数据输入和实体内存表示在每个时间步使用分层注意力生成的。我们展示了 RotoWire 基准测试和我们创建的棒球域上的（大五倍）新数据集。我们的结果表明，所提出的模型在自动和人工评估中优于竞争基线。</td><td>Ratish Puduppully   Li Dong   Mirella Lapata</td></tr><tr><td>28</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.03067&#39;]">Key Fact as Pivot: A Two-Stage Model for Low Resource Table-to-Text Generation</a></td><td></td><td><a href="https://github.com/lancopku/Pivot">https://github.com/lancopku/Pivot</a></td><td><a href="https://arxiv.org/pdf/1908.03067">https://arxiv.org/pdf/1908.03067</a></td><td>Table-to-text generation aims to translate the structured data into the unstructured text. Most existing methods adopt the encoder-decoder framework to learn the transformation, which requires large-scale training samples. However, the lack of large parallel data is a major practical problem for many domains. In this work, we consider the scenario of low resource table-to-text generation, where only limited parallel data is available. We propose a novel model to separate the generation into two stages: key fact prediction and surface realization. It first predicts the key facts from the tables, and then generates the text with the key facts. The training of key fact prediction needs much fewer annotated data, while surface realization can be trained with pseudo parallel corpus. We evaluate our model on a biography generation dataset. Our model can achieve $27.34$ BLEU score with only $1,000$ parallel data, while the baseline model only obtain the performance of $9.71$ BLEU score.</td><td>表到文本生成旨在将结构化数据转换为非结构化文本。大多数现有方法采用编码器-解码器框架来学习转换，这需要大规模的训练样本。然而，缺乏大型并行数据是许多领域的主要实际问题。在这项工作中，我们考虑了低资源表到文本生成的场景，其中只有有限的并行数据可用。我们提出了一种新颖的模型，将生成分为两个阶段：关键事实预测和表面实现。它首先从表格中预测关键事实，然后用关键事实生成文本。关键事实预测的训练需要更少的标注数据，而表面实现可以用伪平行语料库训练。我们在传记生成数据集上评估我们的模型。我们的模型只需 1,000 美元的并行数据即可获得 27.34 美元的 BLEU 分数，而基准模型仅获得 9.71 美元的 BLEU 分数。</td><td>Shuming Ma   Pengcheng Yang   Tianyu Liu   Peng Li   Jie Zhou   Xu Sun</td></tr><tr><td>29</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.12667&#39;]">Reinforced Dynamic Reasoning for Conversational Question Generation</a></td><td></td><td><a href="https://github.com/ZJULearning/ReDR">https://github.com/ZJULearning/ReDR</a></td><td><a href="https://arxiv.org/pdf/1907.12667">https://arxiv.org/pdf/1907.12667</a></td><td>This paper investigates a new task named Conversational Question Generation (CQG) which is to generate a question based on a passage and a conversation history (i.e., previous turns of question-answer pairs). CQG is a crucial task for developing intelligent agents that can drive question-answering style conversations or test user understanding of a given passage. Towards that end, we propose a new approach named Reinforced Dynamic Reasoning (ReDR) network, which is based on the general encoder-decoder framework but incorporates a reasoning procedure in a dynamic manner to better understand what has been asked and what to ask next about the passage. To encourage producing meaningful questions, we leverage a popular question answering (QA) model to provide feedback and fine-tune the question generator using a reinforcement learning mechanism. Empirical results on the recently released CoQA dataset demonstrate the effectiveness of our method in comparison with various baselines and model variants. Moreover, to show the applicability of our method, we also apply it to create multi-turn question-answering conversations for passages in SQuAD.</td><td></td><td>Boyuan Pan   Hao Li   Ziyu Yao   Deng Cai   Huan Sun</td></tr><tr><td>30</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.04106&#39;]">Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards</a></td><td></td><td><a href="https://github.com/kenchan0226/keyphrase-generation-rl">https://github.com/kenchan0226/keyphrase-generation-rl</a></td><td><a href="https://arxiv.org/pdf/1906.04106">https://arxiv.org/pdf/1906.04106</a></td><td>Generating keyphrases that summarize the main points of a document is a fundamental task in natural language processing. Although existing generative models are capable of predicting multiple keyphrases for an input document as well as determining the number of keyphrases to generate, they still suffer from the problem of generating too few keyphrases. To address this problem, we propose a reinforcement learning (RL) approach for keyphrase generation, with an adaptive reward function that encourages a model to generate both sufficient and accurate keyphrases. Furthermore, we introduce a new evaluation method that incorporates name variations of the ground-truth keyphrases using the Wikipedia knowledge base. Thus, our evaluation method can more robustly evaluate the quality of predicted keyphrases. Extensive experiments on five real-world datasets of different scales demonstrate that our RL approach consistently and significantly improves the performance of the state-of-the-art generative models with both conventional and new evaluation methods.</td><td>生成总结文档要点的关键短语是自然语言处理中的一项基本任务。尽管现有的生成模型能够预测输入文档的多个关键短语以及确定要生成的关键短语的数量，但它们仍然存在生成的关键短语太少的问题。为了解决这个问题，我们提出了一种用于生成关键短语的强化学习 (RL) 方法，该方法具有自适应奖励功能，可以鼓励模型生成足够且准确的关键短语。此外，我们引入了一种新的评估方法，该方法使用维基百科知识库结合了真实关键词的名称变体。因此，我们的评估方法可以更稳健地评估预测的关键短语的质量。对五个不同规模的真实世界数据集进行的大量实验表明，我们的 RL 方法通过传统和新的评估方法一致且显着地提高了最先进的生成模型的性能。</td><td>Hou Pong Chan   Wang Chen   Lu Wang   Irwin King</td></tr><tr><td>31</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03889&#39;]">Topic-Aware Neural Keyphrase Generation for Social Media Language</a></td><td></td><td><a href="https://github.com/yuewang-cuhk/TAKG">https://github.com/yuewang-cuhk/TAKG</a></td><td><a href="https://arxiv.org/pdf/1906.03889">https://arxiv.org/pdf/1906.03889</a></td><td>A huge volume of user-generated content is daily produced on social media. To facilitate automatic language understanding, we study keyphrase prediction, distilling salient information from massive posts. While most existing methods extract words from source posts to form keyphrases, we propose a sequence-to-sequence (seq2seq) based neural keyphrase generation framework, enabling absent keyphrases to be created. Moreover, our model, being topic-aware, allows joint modeling of corpus-level latent topic representations, which helps alleviate the data sparsity that widely exhibited in social media language. Experiments on three datasets collected from English and Chinese social media platforms show that our model significantly outperforms both extraction and generation models that do not exploit latent topics. Further discussions show that our model learns meaningful topics, which interprets its superiority in social media keyphrase generation.</td><td></td><td>Yue Wang   Jing Li   Hou Pong Chan   Irwin King   Michael R. Lyu   Shuming Shi</td></tr><tr><td>32</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.03717&#39;]">Argument Generation with Retrieval, Planning, and Realization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1906.03717">https://arxiv.org/pdf/1906.03717</a></td><td>Automatic argument generation is an appealing but challenging task. In this paper, we study the specific problem of counter-argument generation, and present a novel framework, CANDELA. It consists of a powerful retrieval system and a novel two-step generation model, where a text planning decoder first decides on the main talking points and a proper language style for each sentence, then a content realization decoder reflects the decisions and constructs an informative paragraph-level argument. Furthermore, our generation model is empowered by a retrieval system indexed with 12 million articles collected from Wikipedia and popular English news media, which provides access to high-quality content with diversity. Automatic evaluation on a large-scale dataset collected from Reddit shows that our model yields significantly higher BLEU, ROUGE, and METEOR scores than the state-of-the-art and non-trivial comparisons. Human evaluation further indicates that our system arguments are more appropriate for refutation and richer in content.</td><td>自动参数生成是一项有吸引力但具有挑战性的任务。在本文中，我们研究了反论点生成的具体问题，并提出了一个新颖的框架 CANDELA。它由一个强大的检索系统和一个新颖的两步生成模型组成，其中文本规划解码器首先决定每个句子的主要谈话点和适当的语言风格，然后内容实现解码器反映决定并构建信息段落- 级别的论点。此外，我们的生成模型由一个检索系统提供支持，该检索系统索引了从维基百科和流行英语新闻媒体收集的 1200 万篇文章，可提供对高质量内容的访问。对从 Reddit 收集的大规模数据集的自动评估表明，我们的模型产生的 BLEU、ROUGE 和 METEOR 分数明显高于最先进的和非平凡的比较。人工评估进一步表明，我们的系统论点更适合反驳，内容更丰富。</td><td>Xinyu Hua   Zhe Hu   Lu Wang</td></tr><tr><td>33</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1905.12866&#39;]">Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</a></td><td></td><td><a href="https://github.com/wenhuchen/HDSA-Dialog">https://github.com/wenhuchen/HDSA-Dialog</a></td><td><a href="https://arxiv.org/pdf/1905.12866">https://arxiv.org/pdf/1905.12866</a></td><td>Semantically controlled neural response generation on limited-domain has achieved great performance. However, moving towards multi-domain large-scale scenarios are shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the graph. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the large-scale Multi-Domain-WOZ dataset, our model can yield a significant improvement over the baselines on various automatic and human evaluation metrics.</td><td>在有限域上语义控制的神经响应生成已经取得了很好的性能。然而，由于语义输入的可能组合随着域的数量呈指数增长，因此转向多域大规模场景是很困难的。为了缓解这种可扩展性问题，我们利用对话行为的结构来构建多层分层图，其中每个行为在图上表示为从根到叶的路线。然后，我们将这种先验图结构作为归纳偏置来构建分层解缠结的自注意力网络，在其中我们解开注意力头以模拟对话行为图上的指定节点。通过在每一层激活不同的（解开的）头，可以组合地对许多对话行为语义进行建模以控制神经响应的生成。在大规模多域 WOZ 数据集上，我们的模型可以在各种自动和人工评估指标的基线上产生显着改进。</td><td>Wenhu Chen   Jianshu Chen   Pengda Qin   Xifeng Yan   William Yang Wang</td></tr><tr><td>34</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.01231&#39;]">Coherent Comments Generation for Chinese Articles with a Graph-to-Sequence Model</a></td><td></td><td><a href="https://github.com/lancopku/Graph-to-seq-comment-generation">https://github.com/lancopku/Graph-to-seq-comment-generation</a></td><td><a href="https://arxiv.org/pdf/1906.01231">https://arxiv.org/pdf/1906.01231</a></td><td>Automatic article commenting is helpful in encouraging user engagement and interaction on online news platforms. However, the news documents are usually too long for traditional encoder-decoder based models, which often results in general and irrelevant comments. In this paper, we propose to generate comments with a graph-to-sequence model that models the input news as a topic interaction graph. By organizing the article into graph structure, our model can better understand the internal structure of the article and the connection between topics, which makes it better able to understand the story. We collect and release a large scale news-comment corpus from a popular Chinese online news platform Tencent Kuaibao. Extensive experiment results show that our model can generate much more coherent and informative comments compared with several strong baseline models.</td><td>自动文章评论有助于鼓励用户在在线新闻平台上参与和互动。然而，对于传统的基于编码器-解码器的模型来说，新闻文档通常太长，这通常会导致一般和不相关的评论。在本文中，我们建议使用图到序列模型生成评论，该模型将输入新闻建模为主题交互图。通过将文章组织成图结构，我们的模型可以更好地理解文章的内部结构和主题之间的联系，从而更好地理解故事。我们从中国流行的在线新闻平台腾讯快报收集并发布了一个大规模的新闻评论语料库。广泛的实验结果表明，与几个强大的基线模型相比，我们的模型可以生成更加连贯和信息丰富的评论。</td><td>Wei Li   Jingjing Xu   Yancheng He   Shengli Yan   Yunfang Wu   Xu sun</td></tr><tr><td>35</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.02525&#39;]">Cross-Lingual Training for Automatic Question Generation</a></td><td></td><td><a href="https://github.com/vishwajeet93/clqg">https://github.com/vishwajeet93/clqg</a></td><td><a href="https://arxiv.org/pdf/1906.02525">https://arxiv.org/pdf/1906.02525</a></td><td>Automatic question generation (QG) is a challenging problem in natural language understanding. QG systems are typically built assuming access to a large number of training instances where each instance is a question and its corresponding answer. For a new language, such training instances are hard to obtain making the QG problem even more challenging. Using this as our motivation, we study the reuse of an available large QG dataset in a secondary language (e.g. English) to learn a QG model for a primary language (e.g. Hindi) of interest. For the primary language, we assume access to a large amount of monolingual text but only a small QG dataset. We propose a cross-lingual QG model which uses the following training regime: (i) Unsupervised pretraining of language models in both primary and secondary languages and (ii) joint supervised training for QG in both languages. We demonstrate the efficacy of our proposed approach using two different primary languages, Hindi and Chinese. We also create and release a new question answering dataset for Hindi consisting of 6555 sentences.</td><td>自动问题生成（QG）是自然语言理解中的一个具有挑战性的问题。 QG 系统通常假设访问大量训练实例而构建，其中每个实例都是一个问题及其相应的答案。对于一种新语言，很难获得这样的训练实例，这使得 QG 问题更具挑战性。以此为动机，我们研究了在第二语言（例如英语）中重用可用的大型 QG 数据集来学习感兴趣的主要语言（例如印地语）的 QG 模型。对于主要语言，我们假设可以访问大量单语文本，但只能访问一个小的 QG 数据集。我们提出了一种跨语言 QG 模型，它使用以下训练机制：（i）主要和次要语言的语言模型的无监督预训练和（ii）两种语言的 QG 联合监督训练。我们使用两种不同的主要语言印地语和中文证明了我们提出的方法的有效性。我们还为印地语创建并发布了一个新的问答数据集，由 6555 个句子组成。</td><td>Vishwajeet Kumar   Nitish Joshi   Arijit Mukherjee   Ganesh Ramakrishnan   Preethi Jyothi</td></tr><tr><td>36</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.00756&#39;]">Graph Neural Networks with Generated Parameters for Relation Extraction</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.00756">https://arxiv.org/pdf/1902.00756</a></td><td>Recently, progress has been made towards improving relational reasoning in machine learning field. Among existing models, graph neural networks (GNNs) is one of the most effective approaches for multi-hop relational reasoning. In fact, multi-hop relational reasoning is indispensable in many natural language processing tasks such as relation extraction. In this paper, we propose to generate the parameters of graph neural networks (GP-GNNs) according to natural language sentences, which enables GNNs to process relational reasoning on unstructured text inputs. We verify GP-GNNs in relation extraction from text. Experimental results on a human-annotated dataset and two distantly supervised datasets show that our model achieves significant improvements compared to baselines. We also perform a qualitative analysis to demonstrate that our model could discover more accurate relations by multi-hop relational reasoning.</td><td>最近，在改进机器学习领域的关系推理方面取得了进展。在现有模型中，图神经网络 (GNN) 是多跳关系推理最有效的方法之一。事实上，在关系抽取等很多自然语言处理任务中，多跳关系推理是必不可少的。在本文中，我们建议根据自然语言句子生成图神经网络 (GP-GNN) 的参数，这使 GNN 能够处理非结构化文本输入的关系推理。我们在从文本中提取关系中验证了 GP-GNN。在人工注释数据集和两个远程监督数据集上的实验结果表明，与基线相比，我们的模型取得了显着的改进。我们还进行了定性分析，以证明我们的模型可以通过多跳关系推理发现更准确的关系。</td><td>Hao Zhu   Yankai Lin   Zhiyuan Liu   Jie Fu   Tat-seng Chua   Maosong Sun</td></tr><tr><td>37</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.09699&#39;]">Learning to Select, Track, and Generate for Data-to-Text</a></td><td></td><td><a href="https://github.com/aistairc/rotowire-modified">https://github.com/aistairc/rotowire-modified</a></td><td><a href="https://arxiv.org/pdf/1907.09699">https://arxiv.org/pdf/1907.09699</a></td><td>We propose a data-to-text generation model with two modules, one for tracking and the other for text generation. Our tracking module selects and keeps track of salient information and memorizes which record has been mentioned. Our generation module generates a summary conditioned on the state of tracking module. Our model is considered to simulate the human-like writing process that gradually selects the information by determining the intermediate variables while writing the summary. In addition, we also explore the effectiveness of the writer information for generation. Experimental results show that our model outperforms existing models in all evaluation metrics even without writer information. Incorporating writer information further improves the performance, contributing to content planning and surface realization.</td><td>我们提出了一种具有两个模块的数据到文本生成模型，一个用于跟踪，另一个用于文本生成。我们的跟踪模块选择并跟踪显着信息并记住提到的记录。我们的生成模块根据跟踪模块的状态生成摘要。我们的模型被认为是模拟类人的写作过程，通过在撰写摘要时确定中间变量来逐步选择信息。此外，我们还探索了作者信息对生成的有效性。实验结果表明，即使没有作者信息，我们的模型在所有评估指标上都优于现有模型。结合作者信息进一步提高了性能，有助于内容规划和表面实现。</td><td>Hayate Iso   Yui Uehara   Tatsuya Ishigaki   Hiroshi Noji   Eiji Aramaki   Ichiro Kobayashi   Yusuke Miyao   Naoaki Okazaki   Hiroya Takamura</td></tr><tr><td>38</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1907.08540&#39;]">Predicting Human Activities from User-Generated Content</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1907.08540">https://arxiv.org/pdf/1907.08540</a></td><td>The activities we do are linked to our interests, personality, political preferences, and decisions we make about the future. In this paper, we explore the task of predicting human activities from user-generated content. We collect a dataset containing instances of social media users writing about a range of everyday activities. We then use a state-of-the-art sentence embedding framework tailored to recognize the semantics of human activities and perform an automatic clustering of these activities. We train a neural network model to make predictions about which clusters contain activities that were performed by a given user based on the text of their previous posts and self-description. Additionally, we explore the degree to which incorporating inferred user traits into our model helps with this prediction task.</td><td>我们所做的活动与我们的兴趣、个性、政治偏好以及我们对未来所做的决定有关。在本文中，我们探索了从用户生成的内容中预测人类活动的任务。我们收集了一个数据集，其中包含社交媒体用户撰写的一系列日常活动的实例。然后我们使用最先进的句子嵌入框架来识别人类活动的语义并执行这些活动的自动聚类。我们训练一个神经网络模型，以根据给定用户之前帖子的文本和自我描述来预测哪些集群包含由给定用户执行的活动。此外，我们探索了将推断的用户特征合并到我们的模型中有助于此预测任务的程度。</td><td>Steven R. Wilson   Rada Mihalcea</td></tr></tbody></table></div><h3 id="EMNLP-2"><a href="#EMNLP-2" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2002.12328&#39;]">Few-shot Natural Language Generation for Task-Oriented Dialog</a></td><td></td><td><a href="https://github.com/pengbaolin/SC-GPT">https://github.com/pengbaolin/SC-GPT</a></td><td><a href="https://arxiv.org/pdf/2002.12328">https://arxiv.org/pdf/2002.12328</a></td><td>As a crucial component in task-oriented dialog systems, the Natural Language Generation (NLG) module converts a dialog act represented in a semantic form into a response in natural language. The success of traditional template-based or statistical models typically relies on heavily annotated data, which is infeasible for new domains. Therefore, it is pivotal for an NLG system to generalize well with limited labelled data in real applications. To this end, we present FewShotWoz, the first NLG benchmark to simulate the few-shot learning setting in task-oriented dialog systems. Further, we develop the SC-GPT model. It is pre-trained on a large set of annotated NLG corpus to acquire the controllable generation ability, and fine-tuned with only a few domain-specific labels to adapt to new domains. Experiments on FewShotWoz and the large Multi-Domain-WOZ datasets show that the proposed SC-GPT significantly outperforms existing methods, measured by various automatic metrics and human evaluations.</td><td>作为面向任务的对话系统中的重要组成部分，自然语言生成 (NLG) 模块将以语义形式表示的对话行为转换为自然语言的响应。传统的基于模板或统计模型的成功通常依赖于大量注释的数据，这对于新领域是不可行的。因此，NLG 系统在实际应用中利用有限的标记数据很好地泛化是至关重要的。为此，我们提出了FewShotWoz，这是第一个在面向任务的对话系统中模拟小样本学习设置的NLG 基准测试。此外，我们开发了 SC-GPT 模型。它在大量带注释的 NLG 语料库上进行预训练以获得可控生成能力，并仅使用少数特定领域的标签进行微调以适应新领域。在FewShotWoz 和大型Multi-Domain-WOZ 数据集上的实验表明，所提出的SC-GPT 显着优于现有方法，通过各种自动指标和人工评估来衡量。</td><td>Baolin Peng   Chenguang Zhu   Chunyuan Li   Xiujun Li   Jinchao Li   Michael Zeng   Jianfeng Gao</td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/1911.03587&#39;]">How Decoding Strategies Affect the Verifiability of Generated Text</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1911.03587">https://arxiv.org/pdf/1911.03587</a></td><td>Recent progress in pre-trained language models led to systems that are able to generate text of an increasingly high quality. While several works have investigated the fluency and grammatical correctness of such models, it is still unclear to which extent the generated text is consistent with factual world knowledge. Here, we go beyond fluency and also investigate the verifiability of text generated by state-of-the-art pre-trained language models. A generated sentence is verifiable if it can be corroborated or disproved by Wikipedia, and we find that the verifiability of generated text strongly depends on the decoding strategy. In particular, we discover a tradeoff between factuality (i.e., the ability of generating Wikipedia corroborated text) and repetitiveness. While decoding strategies such as top-k and nucleus sampling lead to less repetitive generations, they also produce less verifiable text. Based on these finding, we introduce a simple and effective decoding strategy which, in comparison to previously used decoding strategies, produces less repetitive and more verifiable text.</td><td>预训练语言模型的最新进展导致系统能够生成质量越来越高的文本。虽然有几项工作调查了此类模型的流畅性和语法正确性，但仍不清楚生成的文本在多大程度上与事实世界知识一致。在这里，我们超越了流畅性，还研究了由最先进的预训练语言模型生成的文本的可验证性。如果生成的句子可以被维基百科证实或反驳，那么它就是可验证的，我们发现生成文本的可验证性在很大程度上取决于解码策略。特别是，我们发现了事实性（即生成维基百科确证文本的能力）和重复性之间的权衡。虽然诸如 top-k 和核采样之类的解码策略会减少重复生成，但它们也会产生较少的可验证文本。基于这些发现，我们引入了一种简单有效的解码策略，与以前使用的解码策略相比，该策略产生的文本重复性更低且可验证性更高。</td><td>Luca Massarelli   Fabio Petroni   Aleksandra Piktus   Myle Ott   Tim Rocktäschel   Vassilis Plachouras   Fabrizio Silvestri   Sebastian Riedel</td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14983&#39;]">Control, Generate, Augment: A Scalable Framework for Multi-Attribute Text Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.14983">https://arxiv.org/pdf/2004.14983</a></td><td>We introduce CGA, a conditional VAE architecture, to control, generate, and augment text. CGA is able to generate natural English sentences controlling multiple semantic and syntactic attributes by combining adversarial learning with a context-aware loss and a cyclical word dropout routine. We demonstrate the value of the individual model components in an ablation study. The scalability of our approach is ensured through a single discriminator, independently of the number of attributes. We show high quality, diversity and attribute control in the generated sentences through a series of automatic and human assessments. As the main application of our work, we test the potential of this new NLG model in a data augmentation scenario. In a downstream NLP task, the sentences generated by our CGA model show significant improvements over a strong baseline, and a classification performance often comparable to adding same amount of additional real data.</td><td>我们引入了 CGA，一种有条件的 VAE 架构，来控制、生成和增加文本。 CGA 能够通过将对抗性学习与上下文感知损失和循环词丢失例程相结合，生成控制多个语义和句法属性的自然英语句子。我们在消融研究中展示了各个模型组件的价值。我们的方法的可扩展性是通过单个鉴别器来确保的，与属性的数量无关。我们通过一系列自动和人工评估在生成的句子中展示了高质量、多样性和属性控制。作为我们工作的主要应用，我们在数据增强场景中测试了这种新的 NLG 模型的潜力。在下游 NLP 任务中，我们的 CGA 模型生成的句子在强大的基线上显示出显着的改进，并且分类性能通常与添加相同数量的额外真实数据相当。</td><td>Giuseppe Russo   Nora Hollenstein   Claudiu Musat   Ce Zhang</td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.07576&#39;]">Pretrained Language Models for Dialogue Generation with Multiple Input Sources</a></td><td></td><td><a href="https://github.com/caoyu-noob/Multi-GPT2">https://github.com/caoyu-noob/Multi-GPT2</a></td><td><a href="https://arxiv.org/pdf/2010.07576">https://arxiv.org/pdf/2010.07576</a></td><td>Large-scale pretrained language models have achieved outstanding performance on natural language understanding tasks. However, it is still under investigating how to apply them to dialogue generation tasks, especially those with responses conditioned on multiple sources. Previous work simply concatenates all input sources or averages information from different input sources. In this work, we study dialogue models with multiple input sources adapted from the pretrained language model GPT2. We explore various methods to fuse multiple separate attention information corresponding to different sources. Our experimental results show that proper fusion methods deliver higher relevance with dialogue history than simple fusion baselines.</td><td>大规模预训练语言模型在自然语言理解任务上取得了出色的表现。然而，它仍在研究如何将它们应用于对话生成任务，尤其是那些以多个来源为条件的响应。以前的工作只是连接所有输入源或平均来自不同输入源的信息。在这项工作中，我们研究了从预训练语言模型 GPT2 改编而来的具有多个输入源的对话模型。我们探索了各种方法来融合对应于不同来源的多个单独的注意力信息。我们的实验结果表明，与简单的融合基线相比，适当的融合方法与对话历史的相关性更高。</td><td>Yu Cao   Wei Bi   Meng Fang   Dacheng Tao</td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.14579&#39;]">Logic2Text: High-Fidelity Natural Language Generation from Logical Forms</a></td><td></td><td><a href="https://github.com/czyssrs/Logic2Text">https://github.com/czyssrs/Logic2Text</a></td><td><a href="https://arxiv.org/pdf/2004.14579">https://arxiv.org/pdf/2004.14579</a></td><td>Previous works on Natural Language Generation (NLG) from structured data have primarily focused on surface-level descriptions of record sequences. However, for complex structured data, e.g., multi-row tables, it is often desirable for an NLG system to describe interesting facts from logical inferences across records. If only provided with the table, it is hard for existing models to produce controllable and high-fidelity logical generations. In this work, we formulate logical level NLG as generation from logical forms in order to obtain controllable, high-fidelity, and faithful generations. We present a new large-scale dataset, \textsc{Logic2Text}, with 10,753 descriptions involving common logic types paired with the underlying logical forms. The logical forms show diversified graph structure of free schema, which poses great challenges on the model’s ability to understand the semantics. We experiment on (1) Fully-supervised training with the full datasets, and (2) Few-shot setting, provided with hundreds of paired examples; We compare several popular generation models and analyze their performances. We hope our dataset can encourage research towards building an advanced NLG system capable of natural, faithful, and human-like generation. The dataset and code are available at <a href="https://github.com/czyssrs/Logic2Text">https://github.com/czyssrs/Logic2Text</a>.</td><td>以前从结构化数据中生成自然语言 (NLG) 的工作主要集中在记录序列的表面级描述上。然而，对于复杂的结构化数据，例如多行表，NLG 系统通常希望通过跨记录的逻辑推理来描述有趣的事实。如果只提供表格，现有模型很难产生可控且高保真的逻辑代。在这项工作中，我们将逻辑层次 NLG 制定为逻辑形式的代，以获得可控、高保真和忠实的代。我们提出了一个新的大规模数据集 \textsc{Logic2Text}，其中包含 10,753 个描述，涉及与底层逻辑形式配对的常见逻辑类型。逻辑形式表现出自由模式的多样化图结构，这对模型的语义理解能力提出了很大的挑战。我们对 (1) 使用完整数据集进行全监督训练，以及 (2) 小样本设置进行实验，提供数百个配对示例；我们比较了几种流行的生成模型并分析了它们的性能。我们希望我们的数据集能够鼓励研究建立一个能够自然、忠实和类人生成的先进 NLG 系统。数据集和代码可从 <a href="https://github.com/czyssrs/Logic2Text">https://github.com/czyssrs/Logic2Text</a> 获得。</td><td>Zhiyu Chen   Wenhu Chen   Hanwen Zha   Xiyou Zhou   Yunkai Zhang   Sairam Sundaresan   William Yang Wang</td></tr><tr><td>6</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2009.10056&#39;]">Composed Variational Natural Language Generation for Few-shot Intents</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2009.10056">https://arxiv.org/pdf/2009.10056</a></td><td>In this paper, we focus on generating training examples for few-shot intents in the realistic imbalanced scenario. To build connections between existing many-shot intents and few-shot intents, we consider an intent as a combination of a domain and an action, and propose a composed variational natural language generator (CLANG), a transformer-based conditional variational autoencoder. CLANG utilizes two latent variables to represent the utterances corresponding to two different independent parts (domain and action) in the intent, and the latent variables are composed together to generate natural examples. Additionally, to improve the generator learning, we adopt the contrastive regularization loss that contrasts the in-class with the out-of-class utterance generation given the intent. To evaluate the quality of the generated utterances, experiments are conducted on the generalized few-shot intent detection task. Empirical results show that our proposed model achieves state-of-the-art performances on two real-world intent detection datasets.</td><td>在本文中，我们专注于为现实不平衡场景中的小样本意图生成训练示例。为了在现有的多样本意图和少样本意图之间建立联系，我们将意图视为域和动作的组合，并提出了一种组合变分自然语言生成器 (CLANG)，一种基于转换器的条件变分自动编码器。 CLANG 利用两个潜在变量来表示意图中两个不同独立部分（领域和动作）对应的话语，并将潜在变量组合在一起以生成自然示例。此外，为了改进生成器学习，我们采用了对比正则化损失，将给定意图的课堂内话语生成与课堂外话语生成进行对比。为了评估生成的话语的质量，对广义的小样本意图检测任务进行了实验。实证结果表明，我们提出的模型在两个真实世界的意图检测数据集上实现了最先进的性能。</td><td>Congying Xia   Caiming Xiong   Philip Yu   Richard Socher</td></tr><tr><td>7</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.00910&#39;]">Continual Learning for Natural Language Generation in Task-oriented Dialog Systems</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.00910">https://arxiv.org/pdf/2010.00910</a></td><td>Natural language generation (NLG) is an essential component of task-oriented dialog systems. Despite the recent success of neural approaches for NLG, they are typically developed in an offline manner for particular domains. To better fit real-life applications where new data come in a stream, we study NLG in a “continual learning” setting to expand its knowledge to new domains or functionalities incrementally. The major challenge towards this goal is catastrophic forgetting, meaning that a continually trained model tends to forget the knowledge it has learned before. To this end, we propose a method called ARPER (Adaptively Regularized Prioritized Exemplar Replay) by replaying prioritized historical exemplars, together with an adaptive regularization technique based on ElasticWeight Consolidation. Extensive experiments to continually learn new domains and intents are conducted on MultiWoZ-2.0 to benchmark ARPER with a wide range of techniques. Empirical results demonstrate that ARPER significantly outperforms other methods by effectively mitigating the detrimental catastrophic forgetting issue.</td><td>自然语言生成 (NLG) 是面向任务的对话系统的重要组成部分。尽管最近 NLG 的神经方法取得了成功，但它们通常是针对特定领域以离线方式开发的。为了更好地适应新数据流入的现实生活应用程序，我们在“持续学习”设置中研究 NLG，以逐步将其知识扩展到新的领域或功能。实现这一目标的主要挑战是灾难性遗忘，这意味着不断训练的模型往往会忘记它之前学到的知识。为此，我们提出了一种称为 ARPER（Adaptively Regularized Prioritized Exemplar Replay）的方法，通过重放优先的历史样本，以及基于 ElasticWeight Consolidation 的自适应正则化技术。在 MultiWoZ-2.0 上进行了大量实验以不断学习新的领域和意图，以使用各种技术对 ARPER 进行基准测试。实证结果表明，ARPER 通过有效减轻有害的灾难性遗忘问题显着优于其他方法。</td><td>Fei Mi   Liangwei Chen   Mengjie Zhao   Minlie Huang   Boi Faltings</td></tr><tr><td>8</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.04246&#39;]">Dual Inference for Improving Language Understanding and Generation</a></td><td></td><td><a href="https://github.com/MiuLab/DuaLUG">https://github.com/MiuLab/DuaLUG</a></td><td><a href="https://arxiv.org/pdf/2010.04246">https://arxiv.org/pdf/2010.04246</a></td><td>Natural language understanding (NLU) and Natural language generation (NLG) tasks hold a strong dual relationship, where NLU aims at predicting semantic labels based on natural language utterances and NLG does the opposite. The prior work mainly focused on exploiting the duality in model training in order to obtain the models with better performance. However, regarding the fast-growing scale of models in the current NLP area, sometimes we may have difficulty retraining whole NLU and NLG models. To better address the issue, this paper proposes to leverage the duality in the inference stage without the need of retraining. The experiments on three benchmark datasets demonstrate the effectiveness of the proposed method in both NLU and NLG, providing the great potential of practical usage.</td><td>自然语言理解 (NLU) 和自然语言生成 (NLG) 任务具有很强的双重关系，其中 NLU 旨在根据自然语言表达预测语义标签，而 NLG 则相反。先前的工作主要集中在利用模型训练中的二元性以获得性能更好的模型。然而，对于当前 NLP 领域快速增长的模型规模，有时我们可能难以重新训练整个 NLU 和 NLG 模型。为了更好地解决这个问题，本文建议在推理阶段利用二元性，而无需重新训练。在三个基准数据集上的实验证明了该方法在 NLU 和 NLG 中的有效性，提供了巨大的实际使用潜力。</td><td>Shang-Yu Su   Yung-Sung Chuang   Yun-Nung Chen</td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.09022&#39;]">Neural data-to-text generation: A comparison between pipeline and end- to-end architectures</a></td><td></td><td><a href="https://github.com/ThiagoCF05/webnlg">https://github.com/ThiagoCF05/webnlg</a></td><td><a href="https://arxiv.org/pdf/1908.09022">https://arxiv.org/pdf/1908.09022</a></td><td>Traditionally, most data-to-text applications have been designed using a modular pipeline architecture, in which non-linguistic input data is converted into natural language through several intermediate transformations. In contrast, recent neural models for data-to-text generation have been proposed as end-to-end approaches, where the non-linguistic input is rendered in natural language with much less explicit intermediate representations in-between. This study introduces a systematic comparison between neural pipeline and end-to-end data-to-text approaches for the generation of text from RDF triples. Both architectures were implemented making use of state-of-the art deep learning methods as the encoder-decoder Gated-Recurrent Units (GRU) and Transformer. Automatic and human evaluations together with a qualitative analysis suggest that having explicit intermediate steps in the generation process results in better texts than the ones generated by end-to-end approaches. Moreover, the pipeline models generalize better to unseen inputs. Data and code are publicly available.</td><td>传统上，大多数数据到文本应用程序都是使用模块化管道架构设计的，其中非语言输入数据通过几个中间转换转换为自然语言。相比之下，最近用于数据到文本生成的神经模型已被提出作为端到端方法，其中非语言输入以自然语言呈现，中间的中间表示要少得多。本研究介绍了神经管道和端到端数据到文本方法之间的系统比较，用于从 RDF 三元组生成文本。这两种架构都是利用最先进的深度学习方法作为编码器-解码器门控循环单元 (GRU) 和转换器来实现的。自动和人工评估以及定性分析表明，在生成过程中具有明确的中间步骤会产生比端到端方法生成的文本更好的文本。此外，管道模型可以更好地泛化到看不见的输入。数据和代码是公开的。</td><td>Thiago Castro Ferreira   Chris van der Lee   Emiel van Miltenburg   Emiel Krahmer</td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.02622&#39;]">MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1909.02622">https://arxiv.org/pdf/1909.02622</a></td><td>A robust evaluation metric has a profound impact on the development of text generation systems. A desirable metric compares system output against references based on their semantics rather than surface forms. In this paper we investigate strategies to encode system and reference texts to devise a metric that shows a high correlation with human judgment of text quality. We validate our new metric, namely MoverScore, on a number of text generation tasks including summarization, machine translation, image captioning, and data-to-text generation, where the outputs are produced by a variety of neural and non-neural systems. Our findings suggest that metrics combining contextualized representations with a distance measure perform the best. Such metrics also demonstrate strong generalization capability across tasks. For ease-of-use we make our metrics available as web service.</td><td>一个强大的评估指标对文本生成系统的发展有着深远的影响。理想的度量根据语义而不是表面形式将系统输出与引用进行比较。在本文中，我们研究了对系统和参考文本进行编码的策略，以设计出与人类对文本质量的判断高度相关的度量。我们在许多文本生成任务上验证了我们的新指标，即 MoverScore，包括摘要、机器翻译、图像字幕和数据到文本生成，其中输出由各种神经和非神经系统生成。我们的研究结果表明，将上下文表示与距离度量相结合的指标表现最佳。这些指标还展示了跨任务的强大泛化能力。为了便于使用，我们将我们的指标作为 Web 服务提供。</td><td>Wei Zhao   Maxime Peyrard   Fei Liu   Yang Gao   Christian M. Meyer   Steffen Eger</td></tr><tr><td>11</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1909.04453&#39;]">Select and Attend: Towards Controllable Content Selection in Text Generation</a></td><td></td><td><a href="https://github.com/chin-gyou/controllable-selection">https://github.com/chin-gyou/controllable-selection</a></td><td><a href="https://arxiv.org/pdf/1909.04453">https://arxiv.org/pdf/1909.04453</a></td><td>Many text generation tasks naturally contain two steps: content selection and surface realization. Current neural encoder-decoder models conflate both steps into a black-box architecture. As a result, the content to be described in the text cannot be explicitly controlled. This paper tackles this problem by decoupling content selection from the decoder. The decoupled content selection is human interpretable, whose value can be manually manipulated to control the content of generated text. The model can be trained end-to-end without human annotations by maximizing a lower bound of the marginal likelihood. We further propose an effective way to trade-off between performance and controllability with a single adjustable hyperparameter. In both data-to-text and headline generation tasks, our model achieves promising results, paving the way for controllable content selection in text generation.</td><td>许多文本生成任务自然包含两个步骤：内容选择和表面实现。当前的神经编码器-解码器模型将这两个步骤合并为一个黑盒架构。因此，无法明确控制文本中要描述的内容。本文通过将内容选择与解码器解耦来解决这个问题。解耦的内容选择是人类可解释的，其值可以手动操作以控制生成文本的内容。通过最大化边际似然的下限，可以在没有人工注释的情况下端到端地训练模型。我们进一步提出了一种有效的方法，可以通过单个可调超参数在性能和可控性之间进行权衡。在数据到文本和标题生成任务中，我们的模型取得了可喜的结果，为文本生成中的可控内容选择铺平了道路。</td><td>Xiaoyu Shen   Jun Suzuki   Kentaro Inui   Hui Su   Dietrich Klakow   Satoshi Sekine</td></tr><tr><td>12</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.10245&#39;]">Knowledge Aware Conversation Generation with Explainable Reasoning over Augmented Graphs</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research/tree/master/NLP/EMNLP2019-AKGCM">https://github.com/PaddlePaddle/Research/tree/master/NLP/EMNLP2019-AKGCM</a></td><td><a href="https://arxiv.org/pdf/1903.10245">https://arxiv.org/pdf/1903.10245</a></td><td>Two types of knowledge, triples from knowledge graphs and texts from documents, have been studied for knowledge aware open-domain conversation generation, in which graph paths can narrow down vertex candidates for knowledge selection decision, and texts can provide rich information for response generation. Fusion of a knowledge graph and texts might yield mutually reinforcing advantages, but there is less study on that. To address this challenge, we propose a knowledge aware chatting machine with three components, an augmented knowledge graph with both triples and texts, knowledge selector, and knowledge aware response generator. For knowledge selection on the graph, we formulate it as a problem of multi-hop graph reasoning to effectively capture conversation flow, which is more explainable and flexible in comparison with previous work. To fully leverage long text information that differentiates our graph from others, we improve a state of the art reasoning algorithm with machine reading comprehension technology. We demonstrate the effectiveness of our system on two datasets in comparison with state-of-the-art models.</td><td>已经研究了两种类型的知识，知识图谱中的三元组和文档中的文本，用于知识感知开放域对话生成，其中图路径可以缩小知识选择决策的顶点候选，文本可以为响应生成提供丰富的信息。知识图谱和文本的融合可能会产生相辅相成的优势，但对此的研究较少。为了应对这一挑战，我们提出了一种具有三个组件的知识感知聊天机，一个具有三元组和文本的增强知识图，知识选择器和知识感知响应生成器。对于图上的知识选择，我们将其表述为多跳图推理问题，以有效捕获对话流，与以前的工作相比，它更具可解释性和灵活性。为了充分利用将我们的图与其他图区分开来的长文本信息，我们使用机器阅读理解技术改进了最先进的推理算法。与最先进的模型相比，我们证明了我们的系统在两个数据集上的有效性。</td><td>Zhibin Liu   Zheng-Yu Niu   Hua Wu   Haifeng Wang</td></tr><tr><td>13</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.11658&#39;]">Autoregressive Text Generation Beyond Feedback Loops</a></td><td></td><td><a href="https://github.com/schmiflo/crf-generation">https://github.com/schmiflo/crf-generation</a></td><td><a href="https://arxiv.org/pdf/1908.11658">https://arxiv.org/pdf/1908.11658</a></td><td>Autoregressive state transitions, where predictions are conditioned on past predictions, are the predominant choice for both deterministic and stochastic sequential models. However, autoregressive feedback exposes the evolution of the hidden state trajectory to potential biases from well-known train-test discrepancies. In this paper, we combine a latent state space model with a CRF observation model. We argue that such autoregressive observation models form an interesting middle ground that expresses local correlations on the word level but keeps the state evolution non-autoregressive. On unconditional sentence generation we show performance improvements compared to RNN and GAN baselines while avoiding some prototypical failure modes of autoregressive models.</td><td>自回归状态转换，其中预测以过去的预测为条件，是确定性和随机序列模型的主要选择。然而，自回归反馈将隐藏状态轨迹的演变暴露于众所周知的训练测试差异的潜在偏差。在本文中，我们将潜在状态空间模型与 CRF 观察模型相结合。我们认为，这种自回归观察模型形成了一个有趣的中间立场，它在单词级别上表达了局部相关性，但保持状态演化非自回归。在无条件句子生成方面，我们展示了与 RNN 和 GAN 基线相比的性能改进，同时避免了自回归模型的一些原型故障模式。</td><td>Florian Schmidt   Stephan Mandt   Thomas Hofmann</td></tr><tr><td>14</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.07195&#39;]">ARAML: A Stable Adversarial Training Framework for Text Generation</a></td><td></td><td><a href="https://github.com/kepei1106/ARAML">https://github.com/kepei1106/ARAML</a></td><td><a href="https://arxiv.org/pdf/1908.07195">https://arxiv.org/pdf/1908.07195</a></td><td>Most of the existing generative adversarial networks (GAN) for text generation suffer from the instability of reinforcement learning training algorithms such as policy gradient, leading to unstable performance. To tackle this problem, we propose a novel framework called Adversarial Reward Augmented Maximum Likelihood (ARAML). During adversarial training, the discriminator assigns rewards to samples which are acquired from a stationary distribution near the data rather than the generator’s distribution. The generator is optimized with maximum likelihood estimation augmented by the discriminator’s rewards instead of policy gradient. Experiments show that our model can outperform state-of-the-art text GANs with a more stable training process.</td><td>大多数现有的用于文本生成的生成对抗网络（GAN）都受到强化学习训练算法（如策略梯度）的不稳定性的影响，导致性能不稳定。为了解决这个问题，我们提出了一种称为对抗性奖励增强最大似然（ARAML）的新框架。在对抗性训练期间，鉴别器将奖励分配给从数据附近的平稳分布而不是生成器的分布中获得的样本。生成器通过最大似然估计进行优化，由鉴别器的奖励而不是策略梯度来增强。实验表明，我们的模型可以通过更稳定的训练过程超越最先进的文本 GAN。</td><td>Pei Ke   Fei Huang   Minlie Huang   Xiaoyan Zhu</td></tr><tr><td>15</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1901.00398&#39;]">Judge the Judges: A Large-Scale Evaluation Study of Neural Language Models for Online Review Generation</a></td><td></td><td><a href="https://github.com/Crista23/JudgeTheJudges">https://github.com/Crista23/JudgeTheJudges</a></td><td><a href="https://arxiv.org/pdf/1901.00398">https://arxiv.org/pdf/1901.00398</a></td><td>We conduct a large-scale, systematic study to evaluate the existing evaluation methods for natural language generation in the context of generating online product reviews. We compare human-based evaluators with a variety of automated evaluation procedures, including discriminative evaluators that measure how well machine-generated text can be distinguished from human-written text, as well as word overlap metrics that assess how similar the generated text compares to human-written references. We determine to what extent these different evaluators agree on the ranking of a dozen of state-of-the-art generators for online product reviews. We find that human evaluators do not correlate well with discriminative evaluators, leaving a bigger question of whether adversarial accuracy is the correct objective for natural language generation. In general, distinguishing machine-generated text is challenging even for human evaluators, and human decisions correlate better with lexical overlaps. We find lexical diversity an intriguing metric that is indicative of the assessments of different evaluators. A post-experiment survey of participants provides insights into how to evaluate and improve the quality of natural language generation systems.</td><td>我们进行了大规模、系统的研究，以在生成在线产品评论的背景下评估现有的自然语言生成评估方法。我们将基于人类的评估器与各种自动评估程序进行比较，包括衡量机器生成的文本与人类编写的文本的区分程度的判别评估器，以及评估生成的文本与人类的相似程度的单词重叠指标- 书面参考。我们确定这些不同的评估者在多大程度上同意在线产品评论的十几个最先进的生成器的排名。我们发现人类评估者与判别性评估者的相关性不佳，这留下了一个更大的问题，即对抗性准确性是否是自然语言生成的正确目标。一般来说，即使对于人类评估者来说，区分机器生成的文本也是一项挑战，而人类决策与词汇重叠的相关性更好。我们发现词汇多样性是一个有趣的指标，它表明不同评估者的评估。对参与者的实验后调查提供了有关如何评估和提高自然语言生成系统质量的见解。</td><td>Cristina Garbacea   Samuel Carton   Shiyan Yan   Qiaozhu Mei</td></tr></tbody></table></div><h3 id="NAACL-2"><a href="#NAACL-2" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2005.00054&#39;]">APo-VAE: Text Generation in Hyperbolic Space</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2005.00054">https://arxiv.org/pdf/2005.00054</a></td><td>Natural language often exhibits inherent hierarchical structure ingrained with complex syntax and semantics. However, most state-of-the-art deep generative models learn embeddings only in Euclidean vector space, without accounting for this structural property of language. In this paper, we investigate text generation in a hyperbolic latent space to learn continuous hierarchical representations. An Adversarial Poincare Variational Autoencoder (APo-VAE) is presented, where both the prior and variational posterior of latent variables are defined over a Poincare ball via wrapped normal distributions. By adopting the primal-dual formulation of KL divergence, an adversarial learning procedure is introduced to empower robust model training. Extensive experiments in language modeling and dialog-response generation tasks demonstrate the winning effectiveness of the proposed APo-VAE model over VAEs in Euclidean latent space, thanks to its superb capabilities in capturing latent language hierarchies in hyperbolic space.</td><td>自然语言通常表现出根深蒂固的复杂语法和语义的固有层次结构。然而，大多数最先进的深度生成模型仅在欧几里得向量空间中学习嵌入，而没有考虑语言的这种结构特性。在本文中，我们研究了双曲潜在空间中的文本生成，以学习连续的分层表示。提出了对抗性庞加莱变分自动编码器 (APo-VAE)，其中潜在变量的先验和变分后验都通过包裹正态分布在庞加莱球上定义。通过采用 KL 散度的原始对偶公式，引入了对抗性学习程序以增强稳健的模型训练。语言建模和对话响应生成任务中的大量实验证明了所提出的 APo-VAE 模型在欧几里德潜在空间中的 VAE 上的获胜有效性，这要归功于其在双曲线空间中捕获潜在语言层次结构的卓越能力。</td><td>Shuyang Dai   Zhe Gan   Yu Cheng   Chenyang Tao   Lawrence Carin   Jingjing Liu</td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05218&#39;]">FUDGE: Controlled Text Generation With Future Discriminators</a></td><td></td><td><a href="https://github.com/yangkevin2/naacl-2021-fudge-controlled-generation">https://github.com/yangkevin2/naacl-2021-fudge-controlled-generation</a></td><td><a href="https://arxiv.org/pdf/2104.05218">https://arxiv.org/pdf/2104.05218</a></td><td>We propose Future Discriminators for Generation (FUDGE), a flexible and modular method for controlled text generation. Given a pre-existing model G for generating text from a distribution of interest, FUDGE enables conditioning on a desired attribute a (for example, formality) while requiring access only to G’s output logits. FUDGE learns an attribute predictor operating on a partial sequence, and uses this predictor’s outputs to adjust G’s original probabilities. We show that FUDGE models terms corresponding to a Bayesian decomposition of the conditional distribution of G given attribute a. Moreover, FUDGE can easily compose predictors for multiple desired attributes. We evaluate FUDGE on three tasks — couplet completion in poetry, topic control in language generation, and formality change in machine translation — and observe gains in all three tasks.</td><td>我们提出了未来生成判别器（FUDGE），这是一种用于受控文本生成的灵活且模块化的方法。给定一个用于从感兴趣的分布生成文本的预先存在的模型 G，FUDGE 可以对所需的属性 a（例如形式）进行调节，同时只需要访问 G 的输出 logits。 FUDGE 学习对部分序列进行操作的属性预测器，并使用该预测器的输出来调整 G 的原始概率。我们展示了 FUDGE 模型项对应于给定属性 a 的 G 的条件分布的贝叶斯分解。此外，FUDGE 可以轻松地为多个所需属性组合预测器。我们在三项任务上评估 FUDGE——诗歌中的对联完成、语言生成中的主题控制和机器翻译中的形式变化——并观察所有三项任务的收益。</td><td>Kevin Yang   Dan Klein</td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12884&#39;]">NeuroLogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12884">https://arxiv.org/pdf/2010.12884</a></td><td>Conditional text generation often requires lexical constraints, i.e., which words should or shouldn’t be included in the output text. While the dominant recipe for conditional text generation has been large-scale pretrained language models that are finetuned on the task-specific training data, such models do not learn to follow the underlying constraints reliably, even when supervised with large amounts of task-specific examples.</td><td></td><td></td></tr><tr><td>We propose NeuroLogic Decoding, a simple yet effective algorithm that enables neural language models — supervised or not — to generate fluent text while satisfying complex lexical constraints. Our approach is powerful yet efficient. It handles any set of lexical constraints that is expressible under predicate logic, while its asymptotic runtime is equivalent to conventional beam search.</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Empirical results on four benchmarks show that NeuroLogic Decoding outperforms previous approaches, including algorithms that handle a subset of our constraints. Moreover, we find that unsupervised models with NeuroLogic Decoding often outperform supervised models with conventional decoding, even when the latter is based on considerably larger networks. Our results suggest the limit of large-scale neural networks for fine-grained controllable generation and the promise of inference-time algorithms.</td><td>条件文本生成通常需要词法约束，即哪些词应该或不应该包含在输出文本中。虽然条件文本生成的主要方法是在特定任务的训练数据上进行微调的大规模预训练语言模型，但这些模型并不能可靠地学习遵循潜在的约束，即使在有大量特定任务示例的监督下.</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>我们提出了 NeuroLogic Decoding，这是一种简单而有效的算法，它使神经语言模型（无论是否受监督）都能生成流畅的文本，同时满足复杂的词汇约束。我们的方法强大而高效。它处理在谓词逻辑下可表达的任何词法约束集，而其渐近运行时等效于传统的波束搜索。</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>四个基准的实证结果表明，神经逻辑解码优于以前的方法，包括处理我们的约束子集的算法。此外，我们发现使用 NeuroLogic Decoding 的无监督模型通常优于使用传统解码的监督模型，即使后者基于相当大的网络。我们的结果表明，大规模神经网络对细粒度可控生成的限制和推理时间算法的前景。</td><td>Ximing Lu   Peter West   Rowan Zellers   Ronan Le Bras   Chandra Bhagavatula   Yejin Choi</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.05801&#39;]">Plot-guided Adversarial Example Construction for Evaluating Open-domain Story Generation</a></td><td></td><td><a href="https://github.com/PlusLabNLP/Plot-guided-Coherence-Evaluation">https://github.com/PlusLabNLP/Plot-guided-Coherence-Evaluation</a></td><td><a href="https://arxiv.org/pdf/2104.05801">https://arxiv.org/pdf/2104.05801</a></td><td>With the recent advances of open-domain story generation, the lack of reliable automatic evaluation metrics becomes an increasingly imperative issue that hinders the fast development of story generation. According to conducted researches in this regard, learnable evaluation metrics have promised more accurate assessments by having higher correlations with human judgments. A critical bottleneck of obtaining a reliable learnable evaluation metric is the lack of high-quality training data for classifiers to efficiently distinguish plausible and implausible machine-generated stories. Previous works relied on \textit{heuristically manipulated} plausible examples to mimic possible system drawbacks such as repetition, contradiction, or irrelevant content in the text level, which can be \textit{unnatural} and \textit{oversimplify} the characteristics of implausible machine-generated stories. We propose to tackle these issues by generating a more comprehensive set of implausible stories using {\em plots}, which are structured representations of controllable factors used to generate stories. Since these plots are compact and structured, it is easier to manipulate them to generate text with targeted undesirable properties, while at the same time maintain the grammatical correctness and naturalness of the generated sentences. To improve the quality of generated implausible stories, we further apply the adversarial filtering procedure presented by \citet{zellers2018swag} to select a more nuanced set of implausible texts. Experiments show that the evaluation metrics trained on our generated data result in more reliable automatic assessments that correlate remarkably better with human judgments compared to the baselines.</td><td>随着开放域故事生成的最新进展，缺乏可靠的自动评估指标成为阻碍故事生成快速发展的日益紧迫的问题。根据在这方面进行的研究，可学习的评估指标通过与人类判断具有更高的相关性，有望实现更准确的评估。获得可靠的可学习评估指标的一个关键瓶颈是缺乏用于分类器的高质量训练数据，以有效区分机器生成的可信和不可信的故事。以前的工作依靠\textit{启发式操作}似是而非的例子来模仿可能的系统缺陷，例如文本级别的重复、矛盾或不相关的内容，这些可能是\textit{unnatural}和\textit{oversimplify}难以置信的机器的特征-生成的故事。我们建议通过使用 {\em plots} 生成一组更全面的难以置信的故事来解决这些问题，这些故事是用于生成故事的可控因素的结构化表示。由于这些情节紧凑且结构化，因此更容易操纵它们以生成具有针对性的不良属性的文本，同时保持生成的句子的语法正确性和自然性。为了提高生成的难以置信的故事的质量，我们进一步应用了\citet{zellers2018swag} 提出的对抗性过滤程序来选择一组更细微的难以置信的文本。实验表明，在我们生成的数据上训练的评估指标会产生更可靠的自动评估，与基线相比，与人类判断的相关性明显更好。</td><td>Sarik Ghazarian   Zixi Liu   Akash SM   Ralph Weischedel   Aram Galstyan   Nanyun Peng</td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2006.15720&#39;]">Progressive Generation of Long Text with Pretrained Language Models</a></td><td></td><td><a href="https://github.com/tanyuqian/progressive-generation">https://github.com/tanyuqian/progressive-generation</a></td><td><a href="https://arxiv.org/pdf/2006.15720">https://arxiv.org/pdf/2006.15720</a></td><td>Large-scale language models (LMs) pretrained on massive corpora of text, such as GPT-2, are powerful open-domain text generators. However, as our systematic examination reveals, it is still challenging for such models to generate coherent long passages of text (e.g., 1000 tokens), especially when the models are fine-tuned to the target domain on a small corpus. Previous planning-then-generation methods also fall short of producing such long text in various domains. To overcome the limitations, we propose a simple but effective method of generating text in a progressive manner, inspired by generating images from low to high resolution. Our method first produces domain-specific content keywords and then progressively refines them into complete passages in multiple stages. The simple design allows our approach to take advantage of pretrained LMs at each stage and effectively adapt to any target domain given only a small set of examples. We conduct a comprehensive empirical study with a broad set of evaluation metrics, and show that our approach significantly improves upon the fine-tuned large LMs and various planning-then-generation methods in terms of quality and sample efficiency. Human evaluation also validates that our model generations are more coherent.</td><td>在大量文本语料库（例如 GPT-2）上预训练的大规模语言模型 (LM) 是强大的开放域文本生成器。然而，正如我们的系统检查所揭示的那样，这些模型生成连贯的长文本段落（例如 1000 个标记）仍然具有挑战性，尤其是当模型在小型语料库上针对目标域进行微调时。以前的规划然后生成方法也无法在各个领域生成如此长的文本。为了克服这些限制，我们提出了一种以渐进方式生成文本的简单而有效的方法，其灵感来自于生成从低分辨率到高分辨率的图像。我们的方法首先生成特定领域的内容关键字，然后在多个阶段逐步将它们细化为完整的段落。简单的设计使我们的方法能够在每个阶段利用预训练的 LM，并有效地适应任何仅给定一小部分示例的目标域。我们使用广泛的评估指标进行了全面的实证研究，并表明我们的方法在质量和样本效率方面显着改进了微调的大型 LM 和各种规划然后生成方法。人工评估还验证了我们的模型生成更加连贯。</td><td>Bowen Tan   Zichao Yang   Maruan AI-Shedivat   Eric P. Xing   Zhiting Hu</td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.02484&#39;]">OodGAN: Generative Adversarial Network for Out-of-Domain Data Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.02484">https://arxiv.org/pdf/2104.02484</a></td><td>Detecting an Out-of-Domain (OOD) utterance is crucial for a robust dialog system. Most dialog systems are trained on a pool of annotated OOD data to achieve this goal. However, collecting the annotated OOD data for a given domain is an expensive process. To mitigate this issue, previous works have proposed generative adversarial networks (GAN) based models to generate OOD data for a given domain automatically. However, these proposed models do not work directly with the text. They work with the text’s latent space instead, enforcing these models to include components responsible for encoding text into latent space and decoding it back, such as auto-encoder. These components increase the model complexity, making it difficult to train. We propose OodGAN, a sequential generative adversarial network (SeqGAN) based model for OOD data generation. Our proposed model works directly on the text and hence eliminates the need to include an auto-encoder. OOD data generated using OodGAN model outperforms state-of-the-art in OOD detection metrics for ROSTD (67% relative improvement in FPR 0.95) and OSQ datasets (28% relative improvement in FPR 0.95) (Zheng et al., 2020).</td><td>检测域外 (OOD) 话语对于强大的对话系统至关重要。大多数对话系统都在带注释的 OOD 数据池上进行训练以实现这一目标。但是，为给定域收集带注释的 OOD 数据是一个昂贵的过程。为了缓解这个问题，以前的工作提出了基于生成对抗网络 (GAN) 的模型来自动生成给定域的 OOD 数据。然而，这些提议的模型并不直接与文本一起工作。相反，它们使用文本的潜在空间，强制这些模型包含负责将文本编码到潜在空间并将其解码回来的组件，例如自动编码器。这些组件增加了模型的复杂性，使其难以训练。我们提出了 OodGAN，这是一种基于序列生成对抗网络 (SeqGAN) 的模型，用于生成 OOD 数据。我们提出的模型直接作用于文本，因此不需要包含自动编码器。使用 OodGAN 模型生成的 OOD 数据在 ROSTD（FPR 0.95 的相对改进 67%）和 OSQ 数据集（FPR 0.95 的相对改进 28%）（Zheng 等人，2020）的 OOD 检测指标方面优于最新技术。</td><td>Petr Marek   Vishal Ishwar Naik   Vincent Auvray   Anuj Goyal</td></tr><tr><td>7</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.11205&#39;]">Jointly Optimizing Diversity and Relevance in Neural Response Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.11205">https://arxiv.org/pdf/1902.11205</a></td><td>Although recent neural conversation models have shown great potential, they often generate bland and generic responses. While various approaches have been explored to diversify the output of the conversation model, the improvement often comes at the cost of decreased relevance. In this paper, we propose a SpaceFusion model to jointly optimize diversity and relevance that essentially fuses the latent space of a sequence-to-sequence model and that of an autoencoder model by leveraging novel regularization terms. As a result, our approach induces a latent space in which the distance and direction from the predicted response vector roughly match the relevance and diversity, respectively. This property also lends itself well to an intuitive visualization of the latent space. Both automatic and human evaluation results demonstrate that the proposed approach brings significant improvement compared to strong baselines in both diversity and relevance.</td><td>尽管最近的神经对话模型显示出巨大的潜力，但它们通常会产生平淡而一般的反应。虽然已经探索了各种方法来使对话模型的输出多样化，但改进通常以降低相关性为代价。在本文中，我们提出了一种 SpaceFusion 模型来联合优化多样性和相关性，该模型通过利用新的正则化项基本上融合了序列到序列模型的潜在空间和自动编码器模型的潜在空间。结果，我们的方法引入了一个潜在空间，其中与预测响应向量的距离和方向分别大致匹配相关性和多样性。此属性也非常适合潜在空间的直观可视化。自动和人工评估结果都表明，与多样性和相关性的强大基线相比，所提出的方法带来了显着的改进。</td><td>Xiang Gao   Sungjin Lee   Yizhe Zhang   Chris Brockett   Michel Galley   Jianfeng Gao   Bill Dolan</td></tr><tr><td>8</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.11564&#39;]">Neural Text Generation from Rich Semantic Representations</a></td><td></td><td><a href="https://github.com/shlurbee/dmrs-text-generation-naacl2019">https://github.com/shlurbee/dmrs-text-generation-naacl2019</a></td><td><a href="https://arxiv.org/pdf/1904.11564">https://arxiv.org/pdf/1904.11564</a></td><td>We propose neural models to generate high-quality text from structured representations based on Minimal Recursion Semantics (MRS). MRS is a rich semantic representation that encodes more precise semantic detail than other representations such as Abstract Meaning Representation (AMR). We show that a sequence-to-sequence model that maps a linearization of Dependency MRS, a graph-based representation of MRS, to English text can achieve a BLEU score of 66.11 when trained on gold data. The performance can be improved further using a high-precision, broad coverage grammar-based parser to generate a large silver training corpus, achieving a final BLEU score of 77.17 on the full test set, and 83.37 on the subset of test data most closely matching the silver data domain. Our results suggest that MRS-based representations are a good choice for applications that need both structured semantics and the ability to produce natural language text as output.</td><td>我们提出神经模型，从基于最小递归语义 (MRS) 的结构化表示生成高质量文本。 MRS 是一种丰富的语义表示，与抽象含义表示 (AMR) 等其他表示相比，它编码了更精确的语义细节。我们表明，当对黄金数据进行训练时，将依赖关系 MRS（一种基于图形的 MRS 表示）的线性化映射到英文文本的序列到序列模型可以达到 66.11 的 BLEU 分数。使用高精度、覆盖面广的基于语法的解析器生成大型银色训练语料库，可以进一步提高性能，在完整测试集上获得 77.17 的最终 BLEU 分数，在最匹配的测试数据子集上获得 83.37 分银色数据域。我们的结果表明，对于既需要结构化语义又需要生成自然语言文本作为输出的应用程序，基于 MRS 的表示是一个不错的选择。</td><td>Valerie Hajdik   Jan Buys   Michael W. Goodman   Emily M. Bender</td></tr><tr><td>9</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.02342&#39;]">Text Generation from Knowledge Graphs with Graph Transformers</a></td><td></td><td><a href="https://github.com/rikdz/GraphWriter">https://github.com/rikdz/GraphWriter</a></td><td><a href="https://arxiv.org/pdf/1904.02342">https://arxiv.org/pdf/1904.02342</a></td><td>Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system, and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a significant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long-distance dependencies, and structural variety. We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints. Incorporated into an encoder-decoder setup, we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.</td><td>生成表达跨越多个句子的复杂想法的文本需要对其内容进行结构化表示（文档计划），但这些表示手动生成的成本高得令人望而却步。在这项工作中，我们解决了从信息提取系统的输出，尤其是知识图谱中生成连贯的多句文本的问题。图形知识表示在计算中无处不在，但由于其非层次性、长距离依赖的崩溃和结构多样性，对文本生成技术构成了重大挑战。我们引入了一种新颖的图转换编码器，它可以利用此类知识图的关系结构，而无需施加线性化或分层约束。结合到编码器 - 解码器设置中，我们提供了一个端到端的可训练系统，用于我们应用于科学文本领域的图到文本生成。自动和人工评估表明，我们的技术产生了更多信息文本，与竞争性编码器 - 解码器方法相比，这些文本表现出更好的文档结构。</td><td>Rik Koncel-Kedziorski   Dhanush Bekal   Yi Luan   Mirella Lapata   Hannaneh Hajishirzi</td></tr><tr><td>10</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.04428&#39;]">Text Generation with Exemplar-based Adaptive Decoding</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.04428">https://arxiv.org/pdf/1904.04428</a></td><td>We propose a novel conditioned text generation model. It draws inspiration from traditional template-based text generation techniques, where the source provides the content (i.e., what to say), and the template influences how to say it. Building on the successful encoder-decoder paradigm, it first encodes the content representation from the given input text; to produce the output, it retrieves exemplar text from the training data as “soft templates,” which are then used to construct an exemplar-specific decoder. We evaluate the proposed model on abstractive text summarization and data-to-text generation. Empirical results show that this model achieves strong performance and outperforms comparable baselines.</td><td>我们提出了一种新颖的条件文本生成模型。它从传统的基于模板的文本生成技术中汲取灵感，其中源提供内容（即说什么），而模板影响如何说。基于成功的编码器-解码器范例，它首先对给定输入文本的内容表示进行编码；为了产生输出，它从训练数据中检索示例文本作为“软模板”，然后用于构建特定于示例的解码器。我们在抽象文本摘要和数据到文本生成方面评估了所提出的模型。实证结果表明，该模型实现了强大的性能并优于可比较的基线。</td><td>Hao Peng   Ankur P. Parikh   Manaal Faruqui   Bhuwan Dhingra   Dipanjan Das</td></tr><tr><td>11</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1809.01694&#39;]">Accelerated Reinforcement Learning for Sentence Generation by Vocabulary Prediction</a></td><td></td><td><a href="https://github.com/hassyGo/NLG-RL">https://github.com/hassyGo/NLG-RL</a></td><td><a href="https://arxiv.org/pdf/1809.01694">https://arxiv.org/pdf/1809.01694</a></td><td>A major obstacle in reinforcement learning-based sentence generation is the large action space whose size is equal to the vocabulary size of the target-side language. To improve the efficiency of reinforcement learning, we present a novel approach for reducing the action space based on dynamic vocabulary prediction. Our method first predicts a fixed-size small vocabulary for each input to generate its target sentence. The input-specific vocabularies are then used at supervised and reinforcement learning steps, and also at test time. In our experiments on six machine translation and two image captioning datasets, our method achieves faster reinforcement learning ($\sim$2.7x faster) with less GPU memory ($\sim$2.3x less) than the full-vocabulary counterpart. The reinforcement learning with our method consistently leads to significant improvement of BLEU scores, and the scores are equal to or better than those of baselines using the full vocabularies, with faster decoding time ($\sim$3x faster) on CPUs.</td><td>基于强化学习的句子生成的一个主要障碍是大的动作空间，其大小等于目标方语言的词汇量。为了提高强化学习的效率，我们提出了一种基于动态词汇预测来减少动作空间的新方法。我们的方法首先为每个输入预测一个固定大小的小词汇表以生成其目标句子。然后在监督和强化学习步骤以及测试时使用特定于输入的词汇表。在我们对六个机器翻译和两个图像字幕数据集的实验中，我们的方法实现了更快的强化学习（$\sim$2.7x 快），而 GPU 内存更少（$\sim$2.3x）比全词汇对应物少。使用我们的方法进行的强化学习始终导致 BLEU 分数的显着提高，并且分数等于或优于使用完整词汇表的基线的分数，并且在 CPU 上具有更快的解码时间（$\sim$3x 快）。</td><td>Kazuma Hashimoto   Yoshimasa Tsuruoka</td></tr><tr><td>12</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1903.09722&#39;]">Pre-trained language model representations for language generation</a></td><td></td><td><a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></td><td><a href="https://arxiv.org/pdf/1903.09722">https://arxiv.org/pdf/1903.09722</a></td><td>Pre-trained language model representations have been successful in a wide range of language understanding tasks. In this paper, we examine different strategies to integrate pre-trained representations into sequence to sequence models and apply it to neural machine translation and abstractive summarization. We find that pre-trained representations are most effective when added to the encoder network which slows inference by only 14%. Our experiments in machine translation show gains of up to 5.3 BLEU in a simulated resource-poor setup. While returns diminish with more labeled data, we still observe improvements when millions of sentence-pairs are available. Finally, on abstractive summarization we achieve a new state of the art on the full text version of CNN/DailyMail.</td><td>预训练的语言模型表示已在广泛的语言理解任务中取得成功。在本文中，我们研究了将预训练表示集成到序列到序列模型中的不同策略，并将其应用于神经机器翻译和抽象摘要。我们发现，将预训练的表示添加到编码器网络时最有效，仅将推理速度降低 14%。我们的机器翻译实验表明，在模拟资源匮乏的设置中，增益高达 5.3 BLEU。虽然回报随着更多标记数据而减少，但当有数百万个句子对可用时，我们仍然观察到改进。最后，在抽象摘要方面，我们在 CNN/DailyMail 的全文版本上实现了最新的技术水平。</td><td>Sergey Edunov   Alexei Baevski   Michael Auli</td></tr><tr><td>13</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1904.01301&#39;]">Pragmatically Informative Text Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1904.01301">https://arxiv.org/pdf/1904.01301</a></td><td>We improve the informativeness of models for conditional text generation using techniques from computational pragmatics. These techniques formulate language production as a game between speakers and listeners, in which a speaker should generate output text that a listener can use to correctly identify the original input that the text describes. While such approaches are widely used in cognitive science and grounded language learning, they have received less attention for more standard language generation tasks. We consider two pragmatic modeling methods for text generation: one where pragmatics is imposed by information preservation, and another where pragmatics is imposed by explicit modeling of distractors. We find that these methods improve the performance of strong existing systems for abstractive summarization and generation from structured meaning representations.</td><td>我们使用计算语用学的技术提高了条件文本生成模型的信息量。这些技术将语言生成表述为说话者和听者之间的游戏，其中说话者应该生成输出文本，听者可以使用该输出文本来正确识别文本描述的原始输入。虽然这些方法广泛用于认知科学和基础语言学习，但它们在更标准的语言生成任务中受到的关注较少。我们考虑了两种用于文本生成的语用建模方法：一种是通过信息保存来施加语用，另一种是通过干扰项的显式建模来施加语用。我们发现这些方法提高了强大的现有系统的性能，用于从结构化含义表示中进行抽象摘要和生成。</td><td>Sheng Shen   Daniel Fried   Jacob Andreas   Dan Klein</td></tr><tr><td>14</td><td>NAACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1806.08462&#39;]">Stochastic Wasserstein Autoencoder for Probabilistic Sentence Generation</a></td><td></td><td><a href="https://github.com/HareeshBahuleyan/probabilistic_nlg">https://github.com/HareeshBahuleyan/probabilistic_nlg</a></td><td><a href="https://arxiv.org/pdf/1806.08462">https://arxiv.org/pdf/1806.08462</a></td><td>The variational autoencoder (VAE) imposes a probabilistic distribution (typically Gaussian) on the latent space and penalizes the Kullback—Leibler (KL) divergence between the posterior and prior. In NLP, VAEs are extremely difficult to train due to the problem of KL collapsing to zero. One has to implement various heuristics such as KL weight annealing and word dropout in a carefully engineered manner to successfully train a VAE for text. In this paper, we propose to use the Wasserstein autoencoder (WAE) for probabilistic sentence generation, where the encoder could be either stochastic or deterministic. We show theoretically and empirically that, in the original WAE, the stochastically encoded Gaussian distribution tends to become a Dirac-delta function, and we propose a variant of WAE that encourages the stochasticity of the encoder. Experimental results show that the latent space learned by WAE exhibits properties of continuity and smoothness as in VAEs, while simultaneously achieving much higher BLEU scores for sentence reconstruction.</td><td></td><td>Hareesh Bahuleyan   Lili Mou   Hao Zhou   Olga Vechtomova</td></tr></tbody></table></div><h3 id="COLING-2"><a href="#COLING-2" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.04000&#39;, &#39;https://arxiv.org/abs/1911.03587&#39;, &#39;https://arxiv.org/abs/1704.06851&#39;]">Affective Text Generation</a></td><td></td><td><a href="https://github.com/ishikasingh/Affective-text-gen">https://github.com/ishikasingh/Affective-text-gen</a></td><td><a href="https://arxiv.org/pdf/2011.04000">https://arxiv.org/pdf/2011.04000</a></td><td>Human use language not just to convey information but also to express their inner feelings and mental states. In this work, we adapt the state-of-the-art language generation models to generate affective (emotional) text. We posit a model capable of generating affect-driven and topic-focused sentences without losing grammatical correctness as the affect intensity increases. We propose to incorporate emotion as prior for the probabilistic state-of-the-art text generation model such as GPT-2. The model gives a user the flexibility to control the category and intensity of emotion as well as the topic of the generated text. Previous attempts at modelling fine-grained emotions fall out on grammatical correctness at extreme intensities, but our model is resilient to this and delivers robust results at all intensities. We conduct automated evaluations and human studies to test the performance of our model and provide a detailed comparison of the results with other models. In all evaluations, our model outperforms existing affective text generation models.</td><td>人类使用语言不仅是为了传达信息，也是为了表达内心的感受和心理状态。在这项工作中，我们采用最先进的语言生成模型来生成情感（情感）文本。我们假设一个模型能够生成情感驱动和以主题为中心的句子，而不会随着情感强度的增加而失去语法正确性。我们建议将情感作为先验的概率状态最先进的文本生成模型，例如 GPT-2。该模型使用户可以灵活地控制情绪的类别和强度以及生成文本的主题。之前对细粒度情绪建模的尝试在极端强度下的语法正确性失败，但我们的模型对此具有弹性，并在所有强度下都能提供稳健的结果。我们进行自动评估和人体研究来测试我们模型的性能，并提供与其他模型的结果的详细比较。在所有评估中，我们的模型优于现有的情感文本生成模型。</td><td>Ishika Singh   Ahsan Barkati   Tushar Goswamy   Ashutosh Modi   Luca Massarelli   Fabio Petroni   Aleksandra Piktus   Myle Ott   Tim Rocktäschel   Vassilis Plachouras   Fabrizio Silvestri   Sebastian Riedel   Sayan Ghosh   Mathieu Chollet   Eugene Laksana   Louis-Philippe Morency   Stefan Scherer</td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.13588&#39;]">Curious Case of Language Generation Evaluation Metrics: A Cautionary Tale</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.13588">https://arxiv.org/pdf/2010.13588</a></td><td>Automatic evaluation of language generation systems is a well-studied problem in Natural Language Processing. While novel metrics are proposed every year, a few popular metrics remain as the de facto metrics to evaluate tasks such as image captioning and machine translation, despite their known limitations. This is partly due to ease of use, and partly because researchers expect to see them and know how to interpret them. In this paper, we urge the community for more careful consideration of how they automatically evaluate their models by demonstrating important failure cases on multiple datasets, language pairs and tasks. Our experiments show that metrics (i) usually prefer system outputs to human-authored texts, (ii) can be insensitive to correct translations of rare words, (iii) can yield surprisingly high scores when given a single sentence as system output for the entire test set.</td><td>语言生成系统的自动评估是自然语言处理中一个经过充分研究的问题。虽然每年都会提出新的指标，但一些流行的指标仍然是评估图像字幕和机器翻译等任务的实际指标，尽管它们有已知的局限性。这部分是由于易于使用，部分是因为研究人员希望看到它们并知道如何解释它们。在本文中，我们敦促社区更仔细地考虑他们如何通过在多个数据集、语言对和任务上展示重要的失败案例来自动评估他们的模型。我们的实验表明，指标 (i) 通常更喜欢系统输出而不是人工编写的文本，(ii) 可能对稀有单词的正确翻译不敏感，(iii) 当将单个句子作为整个系统的输出时，可以产生令人惊讶的高分测试集。</td><td>Ozan Caglayan   Pranava Madhyastha   Lucia Specia</td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2012.04332&#39;]">Facts2Story: Controlling Text Generation by Key Facts</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2012.04332">https://arxiv.org/pdf/2012.04332</a></td><td>Recent advancements in self-attention neural network architectures have raised the bar for open-ended text generation. Yet, while current methods are capable of producing a coherent text which is several hundred words long, attaining control over the content that is being generated — as well as evaluating it — are still open questions. We propose a controlled generation task which is based on expanding a sequence of facts, expressed in natural language, into a longer narrative. We introduce human-based evaluation metrics for this task, as well as a method for deriving a large training dataset. We evaluate three methods on this task, based on fine-tuning pre-trained models. We show that while auto-regressive, unidirectional Language Models such as GPT2 produce better fluency, they struggle to adhere to the requested facts. We propose a plan-and-cloze model (using fine-tuned XLNet) which produces competitive fluency while adhering to the requested content.</td><td>自注意力神经网络架构的最新进展提高了开放式文本生成的门槛。然而，虽然当前的方法能够生成几百字长的连贯文本，但对正在生成的内容进行控制——以及对其进行评估——仍然是悬而未决的问题。我们提出了一个受控生成任务，该任务基于将用自然语言表达的一系列事实扩展为更长的叙述。我们为此任务引入了基于人类的评估指标，以及一种用于导出大型训练数据集的方法。我们基于微调预训练模型评估了针对此任务的三种方法。我们表明，虽然 GPT2 等自回归、单向语言模型产生更好的流畅性，但它们难以坚持要求的事实。我们提出了一个计划和完形填空模型（使用微调的 XLNet），该模型在坚持要求的内容的同时产生有竞争力的流畅度。</td><td>Eyal Orbach   Yoav Goldberg</td></tr><tr><td>4</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00592&#39;]">Vec2Sent: Probing Sentence Embeddings with Natural Language Generation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2011.00592">https://arxiv.org/pdf/2011.00592</a></td><td>We introspect black-box sentence embeddings by conditionally generating from them with the objective to retrieve the underlying discrete sentence. We perceive of this as a new unsupervised probing task and show that it correlates well with downstream task performance. We also illustrate how the language generated from different encoders differs. We apply our approach to generate sentence analogies from sentence embeddings.</td><td>我们通过有条件地生成黑盒句子嵌入来内省黑盒句子嵌入，目的是检索潜在的离散句子。我们认为这是一项新的无监督探测任务，并表明它与下游任务性能相关性很好。我们还说明了从不同编码器生成的语言有何不同。我们应用我们的方法从句子嵌入生成句子类比。</td><td>Martin Kerscher   Steffen Eger</td></tr></tbody></table></div><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><h3 id="ACL-3"><a href="#ACL-3" class="headerlink" title="ACL"></a>ACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.13648&#39;]">Cross-Lingual Abstractive Summarization with Limited Parallel Resources</a></td><td></td><td><a href="https://github.com/WoodenWhite/MCLAS">https://github.com/WoodenWhite/MCLAS</a></td><td><a href="https://arxiv.org/pdf/2105.13648">https://arxiv.org/pdf/2105.13648</a></td><td>Parallel cross-lingual summarization data is scarce, requiring models to better use the limited available cross-lingual resources. Existing methods to do so often adopt sequence-to-sequence networks with multi-task frameworks. Such approaches apply multiple decoders, each of which is utilized for a specific task. However, these independent decoders share no parameters, hence fail to capture the relationships between the discrete phrases of summaries in different languages, breaking the connections in order to transfer the knowledge of the high-resource languages to low-resource languages. To bridge these connections, we propose a novel Multi-Task framework for Cross-Lingual Abstractive Summarization (MCLAS) in a low-resource setting. Employing one unified decoder to generate the sequential concatenation of monolingual and cross-lingual summaries, MCLAS makes the monolingual summarization task a prerequisite of the cross-lingual summarization (CLS) task. In this way, the shared decoder learns interactions involving alignments and summary patterns across languages, which encourages attaining knowledge transfer. Experiments on two CLS datasets demonstrate that our model significantly outperforms three baseline models in both low-resource and full-dataset scenarios. Moreover, in-depth analysis on the generated summaries and attention heads verifies that interactions are learned well using MCLAS, which benefits the CLS task under limited parallel resources.</td><td>并行的跨语言摘要数据稀缺，需要模型更好地利用有限的可用跨语言资源。现有的方法通常采用具有多任务框架的序列到序列网络。此类方法应用多个解码器，每个解码器用于特定任务。然而，这些独立的解码器没有共享参数，因此无法捕捉不同语言摘要的离散短语之间的关系，从而打破了联系，以将高资源语言的知识转移到低资源语言。为了弥合这些联系，我们提出了一种新的多任务框架，用于在低资源环境中进行跨语言抽象摘要（MCLAS）。 MCLAS 采用一个统一的解码器来生成单语和跨语言摘要的顺序连接，使单语摘要任务成为跨语言摘要 (CLS) 任务的先决条件。通过这种方式，共享解码器学习涉及跨语言对齐和摘要模式的交互，从而鼓励实现知识转移。在两个 CLS 数据集上的实验表明，我们的模型在低资源和全数据集场景中都明显优于三个基线模型。此外，对生成的摘要和注意力头的深入分析验证了使用 MCLAS 可以很好地学习交互，这有利于有限并行资源下的 CLS 任务。</td><td>Yu Bai   Yang Gao   Heyan Huang</td></tr><tr><td>2</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.04623&#39;]">Improving Factual Consistency of Abstractive Summarization via Question Answering</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.04623">https://arxiv.org/pdf/2105.04623</a></td><td>A commonly observed problem with the state-of-the art abstractive summarization models is that the generated summaries can be factually inconsistent with the input documents. The fact that automatic summarization may produce plausible-sounding yet inaccurate summaries is a major concern that limits its wide application. In this paper we present an approach to address factual consistency in summarization. We first propose an efficient automatic evaluation metric to measure factual consistency; next, we propose a novel learning algorithm that maximizes the proposed metric during model training. Through extensive experiments, we confirm that our method is effective in improving factual consistency and even overall quality of the summaries, as judged by both automatic metrics and human evaluation.</td><td>最先进的抽象摘要模型的一个常见问题是生成的摘要可能与输入文档实际上不一致。自动摘要可能会产生看似合理但不准确的摘要，这一事实是限制其广泛应用的主要问题。在本文中，我们提出了一种解决摘要中事实一致性的方法。我们首先提出了一种有效的自动评估指标来衡量事实一致性；接下来，我们提出了一种新颖的学习算法，可以在模型训练期间最大化提出的度量。通过广泛的实验，我们确认我们的方法在提高事实一致性甚至摘要的整体质量方面是有效的，这通过自动指标和人工评估来判断。</td><td>Feng Nan   Cicero Nogueira dos Santos   Henghui Zhu   Patrick Ng   Kathleen McKeown   Ramesh Nallapati   Dejiao Zhang   Zhiguo Wang   Andrew O. Arnold   Bing Xiang</td></tr><tr><td>3</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.03801&#39;]">Long-Span Summarization via Local Attention and Content Selection</a></td><td></td><td><a href="https://github.com/potsawee/longsum0">https://github.com/potsawee/longsum0</a></td><td><a href="https://arxiv.org/pdf/2105.03801">https://arxiv.org/pdf/2105.03801</a></td><td>Transformer-based models have achieved state-of-the-art results in a wide range of natural language processing (NLP) tasks including document summarization. Typically these systems are trained by fine-tuning a large pre-trained model to the target task. One issue with these transformer-based models is that they do not scale well in terms of memory and compute requirements as the input length grows. Thus, for long document summarization, it can be challenging to train or fine-tune these models. In this work, we exploit large pre-trained transformer-based models and address long-span dependencies in abstractive summarization using two methods: local self-attention; and explicit content selection. These approaches are compared on a range of network configurations. Experiments are carried out on standard long-span summarization tasks, including Spotify Podcast, arXiv, and PubMed datasets. We demonstrate that by combining these methods, we can achieve state-of-the-art results on all three tasks in the ROUGE scores. Moreover, without a large-scale GPU card, our approach can achieve comparable or better results than existing approaches.</td><td>基于 Transformer 的模型在包括文档摘要在内的各种自然语言处理 (NLP) 任务中取得了最先进的结果。通常，这些系统是通过针对目标任务对大型预训练模型进行微调来训练的。这些基于转换器的模型的一个问题是，随着输入长度的增加，它们在内存和计算要求方面不能很好地扩展。因此，对于长文档摘要，训练或微调这些模型可能具有挑战性。在这项工作中，我们利用大型预训练的基于 Transformer 的模型，并使用两种方法解决抽象摘要中的长跨度依赖性：局部自注意力；和明确的内容选择。这些方法在一系列网络配置上进行了比较。实验是在标准的大跨度摘要任务上进行的，包括 Spotify Podcast、arXiv 和 PubMed 数据集。我们证明，通过结合这些方法，我们可以在 ROUGE 分数中的所有三个任务上获得最先进的结果。此外，在没有大规模 GPU 卡的情况下，我们的方法可以获得与现有方法相当或更好的结果。</td><td>Potsawee Manakul   Mark J. F. Gales</td></tr><tr><td>4</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.15135&#39;]">TWAG: A Topic-Guided Wikipedia Abstract Generator</a></td><td></td><td><a href="https://github.com/THU-KEG/TWAG">https://github.com/THU-KEG/TWAG</a></td><td><a href="https://arxiv.org/pdf/2106.15135">https://arxiv.org/pdf/2106.15135</a></td><td>Wikipedia abstract generation aims to distill a Wikipedia abstract from web sources and has met significant success by adopting multi-document summarization techniques. However, previous works generally view the abstract as plain text, ignoring the fact that it is a description of a certain entity and can be decomposed into different topics. In this paper, we propose a two-stage model TWAG that guides the abstract generation with topical information. First, we detect the topic of each input paragraph with a classifier trained on existing Wikipedia articles to divide input documents into different topics. Then, we predict the topic distribution of each abstract sentence, and decode the sentence from topic-aware representations with a Pointer-Generator network. We evaluate our model on the WikiCatSum dataset, and the results show that \modelnames outperforms various existing baselines and is capable of generating comprehensive abstracts. Our code and dataset can be accessed at \url{<a href="https://github.com/THU-KEG/TWAG}">https://github.com/THU-KEG/TWAG}</a></td><td>维基百科摘要生成旨在从网络资源中提取维基百科摘要，并通过采用多文档摘要技术取得了重大成功。然而，以前的工作一般将摘要视为纯文本，忽略了它是对某个实体的描述，可以分解为不同主题的事实。在本文中，我们提出了一个两阶段模型 TWAG，它用主题信息指导抽象生成。首先，我们使用在现有维基百科文章上训练的分类器检测每个输入段落的主题，以将输入文档划分为不同的主题。然后，我们预测每个抽象句子的主题分布，并使用指针生成器网络从主题感知表示中解码句子。我们在 WikiCatSum 数据集上评估我们的模型，结果表明 \modelnames 优于各种现有的基线，并且能够生成全面的摘要。我们的代码和数据集可以在 \url{<a href="https://github.com/THU-KEG/TWAG}">https://github.com/THU-KEG/TWAG}</a> 访问</td><td>Fangwei Zhu   Shangqing Tu   Jiaxin Shi   Juanzi Li   Lei Hou   Tong Cui</td></tr><tr><td>5</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.12544&#39;]">Language Model as an Annotator: Exploring DialoGPT for Dialogue Summarization</a></td><td></td><td><a href="https://github.com/xcfcode/PLM_annotator">https://github.com/xcfcode/PLM_annotator</a></td><td><a href="https://arxiv.org/pdf/2105.12544">https://arxiv.org/pdf/2105.12544</a></td><td>Current dialogue summarization systems usually encode the text with a number of general semantic features (e.g., keywords and topics) to gain more powerful dialogue modeling capabilities. However, these features are obtained via open-domain toolkits that are dialog-agnostic or heavily relied on human annotations. In this paper, we show how DialoGPT, a pre-trained model for conversational response generation, can be developed as an unsupervised dialogue annotator, which takes advantage of dialogue background knowledge encoded in DialoGPT. We apply DialoGPT to label three types of features on two dialogue summarization datasets, SAMSum and AMI, and employ pre-trained and non pre-trained models as our summarizes. Experimental results show that our proposed method can obtain remarkable improvements on both datasets and achieves new state-of-the-art performance on the SAMSum dataset.</td><td></td><td>Xiachong Feng   Xiaocheng Feng   Libo Qin   Bing Qin   Ting Liu</td></tr><tr><td>6</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.12041&#39;]">BASS: Boosting Abstractive Summarization with Unified Semantic Graph</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.12041">https://arxiv.org/pdf/2105.12041</a></td><td>Abstractive summarization for long-document or multi-document remains challenging for the Seq2Seq architecture, as Seq2Seq is not good at analyzing long-distance relations in text. In this paper, we present BASS, a novel framework for Boosting Abstractive Summarization based on a unified Semantic graph, which aggregates co-referent phrases distributing across a long range of context and conveys rich relations between phrases. Further, a graph-based encoder-decoder model is proposed to improve both the document representation and summary generation process by leveraging the graph structure. Specifically, several graph augmentation methods are designed to encode both the explicit and implicit relations in the text while the graph-propagation attention mechanism is developed in the decoder to select salient content into the summary. Empirical results show that the proposed architecture brings substantial improvements for both long-document and multi-document summarization tasks.</td><td>长文档或多文档的抽象摘要对于 Seq2Seq 架构仍然具有挑战性，因为 Seq2Seq 不擅长分析文本中的长距离关系。在本文中，我们提出了 BASS，这是一种基于统一语义图的增强抽象摘要的新框架，该框架聚合了分布在广泛上下文中的共同指涉短语，并传达了短语之间的丰富关系。此外，提出了一种基于图的编码器-解码器模型，以通过利用图结构来改进文档表示和摘要生成过程。具体来说，设计了几种图增强方法来对文本中的显式和隐式关系进行编码，同时在解码器中开发图传播注意机制以将显着内容选择到摘要中。实证结果表明，所提出的架构为长文档和多文档摘要任务带来了实质性的改进。</td><td>Wenhao Wu   Wei Li   Xinyan Xiao   Jiachen Liu   Ziqiang Cao   Sujian Li   Hua Wu   Haifeng Wang</td></tr><tr><td>7</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2105.11921&#39;]">Focus Attention: Promoting Faithfulness and Diversity in Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2105.11921">https://arxiv.org/pdf/2105.11921</a></td><td>Professional summaries are written with document-level information, such as the theme of the document, in mind. This is in contrast with most seq2seq decoders which simultaneously learn to focus on salient content, while deciding what to generate, at each decoding step. With the motivation to narrow this gap, we introduce Focus Attention Mechanism, a simple yet effective method to encourage decoders to proactively generate tokens that are similar or topical to the input document. Further, we propose a Focus Sampling method to enable generation of diverse summaries, an area currently understudied in summarization. When evaluated on the BBC extreme summarization task, two state-of-the-art models augmented with Focus Attention generate summaries that are closer to the target and more faithful to their input documents, outperforming their vanilla counterparts on \rouge and multiple faithfulness measures. We also empirically demonstrate that Focus Sampling is more effective in generating diverse and faithful summaries than top-$k$ or nucleus sampling-based decoding methods.</td><td>专业摘要是用文档级别的信息编写的，例如文档的主题。这与大多数 seq2seq 解码器形成对比，后者在每个解码步骤中同时学习关注显着内容，同时决定生成什么。为了缩小这一差距，我们引入了焦点注意力机制，这是一种简单而有效的方法，可以鼓励解码器主动生成与输入文档相似或主题的标记。此外，我们提出了一种焦点抽样方法，以生成多样化的摘要，这是目前在摘要中研究不足的领域。当在 BBC 极端摘要任务上进行评估时，两个最先进的模型增强了 Focus Attention 生成的摘要更接近目标，更忠实于他们的输入文档，在 \rouge 和多重忠实度度量上优于普通模型。我们还凭经验证明，焦点采样在生成多样化和忠实的摘要方面比基于 top-$k$ 或核采样的解码方法更有效。</td><td>Rahul Aralikatte   Shashi Narayan   Joshua Maynez   Sascha Rothe   Ryan McDonald</td></tr><tr><td>8</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2012.14774&#39;]">Generating Query Focused Summaries from Query-Free Resources</a></td><td></td><td><a href="https://github.com/yumoxu/marge">https://github.com/yumoxu/marge</a></td><td><a href="https://arxiv.org/pdf/2012.14774">https://arxiv.org/pdf/2012.14774</a></td><td>The availability of large-scale datasets has driven the development of neural models that create generic summaries from single or multiple documents. In this work we consider query focused summarization (QFS), a task for which training data in the form of queries, documents, and summaries is not readily available. We propose to decompose QFS into (1) query modeling (i.e., finding supportive evidence within a set of documents for a query) and (2) conditional language modeling (i.e., summary generation). We introduce MaRGE, a Masked ROUGE Regression framework for evidence estimation and ranking which relies on a unified representation for summaries and queries, so that summaries in generic data can be converted into proxy queries for learning a query model. Experiments across QFS benchmarks and query types show that our model achieves state-of-the-art performance despite learning from weak supervision.</td><td>大规模数据集的可用性推动了神经模型的发展，该模型从单个或多个文档创建通用摘要。在这项工作中，我们考虑以查询为中心的摘要 (QFS)，这是一项不容易获得查询、文档和摘要形式的训练数据的任务。我们建议将 QFS 分解为 (1) 查询建模（即在一组文档中为查询找到支持证据）和（2）条件语言建模（即摘要生成）。我们引入了 MaRGE，这是一种用于证据估计和排序的 Masked ROUGE 回归框架，它依赖于摘要和查询的统一表示，因此可以将通用数据中的摘要转换为代理查询以学习查询模型。跨 QFS 基准测试和查询类型的实验表明，尽管从弱监督中学习，我们的模型仍实现了最先进的性能。</td><td>Yumo Xu   Mirella Lapata</td></tr><tr><td>9</td><td>ACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.00829&#39;]">ConvoSumm: Conversation Summarization Benchmark and Improved Abstractive Summarization with Argument Mining</a></td><td></td><td><a href="https://github.com/Yale-LILY/ConvoSumm">https://github.com/Yale-LILY/ConvoSumm</a></td><td><a href="https://arxiv.org/pdf/2106.00829">https://arxiv.org/pdf/2106.00829</a></td><td>While online conversations can cover a vast amount of information in many different formats, abstractive text summarization has primarily focused on modeling solely news articles. This research gap is due, in part, to the lack of standardized datasets for summarizing online discussions. To address this gap, we design annotation protocols motivated by an issues—viewpoints—assertions framework to crowdsource four new datasets on diverse online conversation forms of news comments, discussion forums, community question answering forums, and email threads. We benchmark state-of-the-art models on our datasets and analyze characteristics associated with the data. To create a comprehensive benchmark, we also evaluate these models on widely-used conversation summarization datasets to establish strong baselines in this domain. Furthermore, we incorporate argument mining through graph construction to directly model the issues, viewpoints, and assertions present in a conversation and filter noisy input, showing comparable or improved results according to automatic and human evaluations.</td><td>虽然在线对话可以涵盖多种不同格式的大量信息，但抽象文本摘要主要侧重于对新闻文章进行建模。这种研究差距部分是由于缺乏用于总结在线讨论的标准化数据集。为了解决这一差距，我们设计了由问题-观点-断言框架驱动的注释协议，以众包新闻评论、讨论论坛、社区问答论坛和电子邮件线程等各种在线对话形式的四个新数据集。我们在我们的数据集上对最先进的模型进行基准测试并分析与数据相关的特征。为了创建一个全面的基准，我们还在广泛使用的对话摘要数据集上评估这些模型，以在该领域建立强大的基线。此外，我们通过图构建结合参数挖掘，直接对对话中存在的问题、观点和断言进行建模，并过滤嘈杂的输入，根据自动和人工评估显示可比较或改进的结果。</td><td>Alexander R. Fabbri   Faiaz Rahman   Imad Rizvi   Borui Wang   Haoran Li   Yashar Mehdad   Dragomir Radev</td></tr><tr><td>10</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00661&#39;]">On Faithfulness and Factuality in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/google-research-datasets/xsum_hallucination_annotations">https://github.com/google-research-datasets/xsum_hallucination_annotations</a></td><td><a href="https://arxiv.org/pdf/2005.00661">https://arxiv.org/pdf/2005.00661</a></td><td>It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as language modeling and story generation. In this paper we have analyzed limitations of these models for abstractive document summarization and found that these models are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with faithfulness than standard metrics, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria.</td><td>众所周知，神经文本生成模型中的标准似然训练和近似解码目标会导致对语言建模和故事生成等开放式任务的响应较少。在本文中，我们分析了这些模型在抽象文档摘要方面的局限性，发现这些模型很容易出现对输入文档不忠实的幻觉内容。我们对几个神经抽象摘要系统进行了大规模的人工评估，以更好地了解它们产生的幻觉类型。我们的人工注释者在所有模型生成的摘要中发现了大量幻觉内容。然而，我们的分析确实表明，预训练模型不仅在原始指标（即 ROUGE）方面是更好的总结器，而且在生成人类评估的忠实和事实摘要方面也是如此。此外，我们表明，与标准度量相比，文本蕴涵度量与忠诚度的相关性更好，这可能会引领自动评估度量以及训练和解码标准的发展。</td><td>Joshua Maynez   Shashi Narayan   Bernd Bohnet   Ryan McDonald</td></tr><tr><td>11</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.03754&#39;]">FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/esdurmus/summary-faithfulness">https://github.com/esdurmus/summary-faithfulness</a></td><td><a href="https://arxiv.org/pdf/2005.03754">https://arxiv.org/pdf/2005.03754</a></td><td>Neural abstractive summarization models are prone to generate content inconsistent with the source document, i.e. unfaithful. Existing automatic metrics do not capture such mistakes effectively. We tackle the problem of evaluating faithfulness of a generated summary given its source document. We first collected human annotations of faithfulness for outputs from numerous models on two datasets. We find that current models exhibit a trade-off between abstractiveness and faithfulness: outputs with less word overlap with the source document are more likely to be unfaithful. Next, we propose an automatic question answering (QA) based metric for faithfulness, FEQA, which leverages recent advances in reading comprehension. Given question-answer pairs generated from the summary, a QA model extracts answers from the document; non-matched answers indicate unfaithful information in the summary. Among metrics based on word overlap, embedding similarity, and learned language understanding models, our QA-based metric has significantly higher correlation with human faithfulness scores, especially on highly abstractive summaries.</td><td>神经抽象摘要模型容易生成与源文档不一致的内容，即不忠实的。现有的自动指标不能有效地捕捉此类错误。我们解决了在给定源文件的情况下评估生成摘要的忠实度的问题。我们首先从两个数据集上的众多模型中收集了人类忠实度的人工注释。我们发现当前的模型表现出抽象性和忠实性之间的权衡：与源文档的单词重叠较少的输出更有可能是不忠实的。接下来，我们提出了一种基于自动问答 (QA) 的忠诚度指标，FEQA，它利用了阅读理解方面的最新进展。给定从摘要生成的问答对，QA 模型从文档中提取答案；不匹配的答案表示摘要中的信息不真实。在基于单词重叠、嵌入相似性和学习语言理解模型的指标中，我们基于 QA 的指标与人类忠诚度得分的相关性显着更高，尤其是在高度抽象的摘要上。</td><td>Esin Durmus   He He   Mona Diab</td></tr><tr><td>12</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.00661&#39;]">On Faithfulness and Factuality in Abstractive Summarization</a></td><td></td><td><a href="https://github.com/google-research-datasets/xsum_hallucination_annotations">https://github.com/google-research-datasets/xsum_hallucination_annotations</a></td><td><a href="https://arxiv.org/pdf/2005.00661">https://arxiv.org/pdf/2005.00661</a></td><td>It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as language modeling and story generation. In this paper we have analyzed limitations of these models for abstractive document summarization and found that these models are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with faithfulness than standard metrics, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria.</td><td>众所周知，神经文本生成模型中的标准似然训练和近似解码目标会导致对语言建模和故事生成等开放式任务的响应较少。在本文中，我们分析了这些模型在抽象文档摘要方面的局限性，发现这些模型很容易出现对输入文档不忠实的幻觉内容。我们对几个神经抽象摘要系统进行了大规模的人工评估，以更好地了解它们产生的幻觉类型。我们的人工注释者在所有模型生成的摘要中发现了大量幻觉内容。然而，我们的分析确实表明，预训练模型不仅在原始指标（即 ROUGE）方面是更好的总结器，而且在生成人类评估的忠实和事实摘要方面也是如此。此外，我们表明，与标准度量相比，文本蕴涵度量与忠诚度的相关性更好，这可能会引领自动评估度量以及训练和解码标准的发展。</td><td>Joshua Maynez   Shashi Narayan   Bernd Bohnet   Ryan McDonald</td></tr><tr><td>13</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.01159&#39;]">Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward</a></td><td></td><td><a href="https://github.com/luyang-huang96/GraphAugmentedSum">https://github.com/luyang-huang96/GraphAugmentedSum</a></td><td><a href="https://arxiv.org/pdf/2005.01159">https://arxiv.org/pdf/2005.01159</a></td><td>Sequence-to-sequence models for abstractive summarization have been studied extensively, yet the generated summaries commonly suffer from fabricated content, and are often found to be near-extractive. We argue that, to address these issues, the summarizer should acquire semantic interpretation over input, e.g., via structured representation, to allow the generation of more informative summaries. In this paper, we present ASGARD, a novel framework for Abstractive Summarization with Graph-Augmentation and semantic-driven RewarD. We propose the use of dual encoders—-a sequential document encoder and a graph-structured encoder—-to maintain the global context and local characteristics of entities, complementing each other. We further design a reward based on a multiple choice cloze test to drive the model to better capture entity interactions. Results show that our models produce significantly higher ROUGE scores than a variant without knowledge graph as input on both New York Times and CNN/Daily Mail datasets. We also obtain better or comparable performance compared to systems that are fine-tuned from large pretrained language models. Human judges further rate our model outputs as more informative and containing fewer unfaithful errors.</td><td>用于抽象摘要的序列到序列模型已被广泛研究，但生成的摘要通常受到捏造的内容的影响，并且经常被发现接近于提取。我们认为，为了解决这些问题，摘要器应该获得对输入的语义解释，例如，通过结构化表示，以允许生成更多信息摘要。在本文中，我们提出了 ASGARD，这是一种具有图增强和语义驱动的 RewarD 的抽象摘要框架。我们建议使用双编码器——顺序文档编码器和图结构编码器——来维护实体的全局上下文和局部特征，相互补充。我们进一步设计了基于多项选择完形填空测试的奖励，以驱动模型更好地捕获实体交互。结果表明，我们的模型在纽约时报和 CNN/每日邮报数据集上产生的 ROUGE 分数明显高于没有知识图作为输入的变体。与从大型预训练语言模型微调的系统相比，我们还获得了更好或相当的性能。人类法官进一步评价我们的模型输出信息更多，包含更少的不忠实错误。</td><td>Luyang Huang   Lingfei Wu   Lu Wang</td></tr><tr><td>14</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2105.05361&#39;]">The Summary Loop: Learning to Write Abstractive Summaries Without Examples</a></td><td></td><td><a href="https://github.com/cannylab/summary_loop">https://github.com/cannylab/summary_loop</a></td><td><a href="https://arxiv.org/pdf/2105.05361">https://arxiv.org/pdf/2105.05361</a></td><td>This work presents a new approach to unsupervised abstractive summarization based on maximizing a combination of coverage and fluency for a given length constraint. It introduces a novel method that encourages the inclusion of key terms from the original document into the summary: key terms are masked out of the original document and must be filled in by a coverage model using the current generated summary. A novel unsupervised training procedure leverages this coverage model along with a fluency model to generate and score summaries. When tested on popular news summarization datasets, the method outperforms previous unsupervised methods by more than 2 R-1 points, and approaches results of competitive supervised methods. Our model attains higher levels of abstraction with copied passages roughly two times shorter than prior work, and learns to compress and merge sentences without supervision.</td><td>这项工作提出了一种新的无监督抽象摘要方法，该方法基于在给定长度约束下最大化覆盖率和流畅度的组合。它引入了一种新方法，鼓励将原始文档中的关键术语包含在摘要中：关键术语从原始文档中被屏蔽，并且必须由使用当前生成的摘要的覆盖模型填充。一种新颖的无监督训练程序利用此覆盖模型和流畅性模型来生成和评分摘要。在流行的新闻摘要数据集上进行测试时，该方法比以前的无监督方法高出 2 个 R-1 点以上，并且接近竞争性监督方法的结果。我们的模型通过复制的段落比以前的工作短大约两倍，获得了更高的抽象水平，并学会了在没有监督的情况下压缩和合并句子。</td><td>Philippe Laban   Andrew Hsi   John Canny   Marti A. Hearst</td></tr><tr><td>15</td><td>ACL2020</td><td><a href="[&#39;https://arxiv.org/abs/2005.10043&#39;]">Leveraging Graph to Improve Abstractive Multi-Document Summarization</a></td><td></td><td><a href="https://github.com/PaddlePaddle/Research">https://github.com/PaddlePaddle/Research</a></td><td><a href="https://arxiv.org/pdf/2005.10043">https://arxiv.org/pdf/2005.10043</a></td><td>Graphs that capture relations between textual units have great benefits for detecting salient information from multiple documents and generating overall coherent summaries. In this paper, we develop a neural abstractive multi-document summarization (MDS) model which can leverage well-known graph representations of documents such as similarity graph and discourse graph, to more effectively process multiple input documents and produce abstractive summaries. Our model utilizes graphs to encode documents in order to capture cross-document relations, which is crucial to summarizing long documents. Our model can also take advantage of graphs to guide the summary generation process, which is beneficial for generating coherent and concise summaries. Furthermore, pre-trained language models can be easily combined with our model, which further improve the summarization performance significantly. Empirical results on the WikiSum and MultiNews dataset show that the proposed architecture brings substantial improvements over several strong baselines.</td><td>捕获文本单元之间关系的图对于从多个文档中检测显着信息和生成整体连贯的摘要有很大的好处。在本文中，我们开发了一种神经抽象多文档摘要 (MDS) 模型，该模型可以利用众所周知的文档图表示（例如相似图和话语图）来更有效地处理多个输入文档并生成抽象摘要。我们的模型利用图对文档进行编码以捕获跨文档关系，这对于总结长文档至关重要。我们的模型还可以利用图来指导摘要生成过程，这有利于生成连贯简洁的摘要。此外，预训练的语言模型可以很容易地与我们的模型结合，这进一步显着提高了摘要性能。 WikiSum 和 MultiNews 数据集上的实证结果表明，所提出的架构比几个强大的基线带来了实质性的改进。</td><td>Wei Li   Xinyan Xiao   Jiachen Liu   Hua Wu   Haifeng Wang   Junping Du</td></tr><tr><td>16</td><td>ACL2019</td><td><a href="[&#39;https://arxiv.org/abs/1906.00077&#39;]">Scoring Sentence Singletons and Pairs for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/ucfnlp/summarization-sing-pair-mix">https://github.com/ucfnlp/summarization-sing-pair-mix</a></td><td><a href="https://arxiv.org/pdf/1906.00077">https://arxiv.org/pdf/1906.00077</a></td><td>When writing a summary, humans tend to choose content from one or two sentences and merge them into a single summary sentence. However, the mechanisms behind the selection of one or multiple source sentences remain poorly understood. Sentence fusion assumes multi-sentence input; yet sentence selection methods only work with single sentences and not combinations of them. There is thus a crucial gap between sentence selection and fusion to support summarizing by both compressing single sentences and fusing pairs. This paper attempts to bridge the gap by ranking sentence singletons and pairs together in a unified space. Our proposed framework attempts to model human methodology by selecting either a single sentence or a pair of sentences, then compressing or fusing the sentence(s) to produce a summary sentence. We conduct extensive experiments on both single- and multi-document summarization datasets and report findings on sentence selection and abstraction.</td><td>在撰写摘要时，人们倾向于从一两个句子中选择内容并将它们合并为一个摘要句子。然而，选择一个或多个源句子背后的机制仍然知之甚少。句子融合假设多句输入；然而，句子选择方法仅适用于单个句子，而不适用于它们的组合。因此，在句子选择和融合之间存在一个关键的差距，以支持通过压缩单个句子和融合对来进行总结。本文试图通过在统一空间中对句子单例和句子对进行排序来弥合这一差距。我们提出的框架试图通过选择单个句子或一对句子来模拟人类方法，然后压缩或融合句子以生成摘要句子。我们对单文档和多文档摘要数据集进行了广泛的实验，并报告了关于句子选择和抽象的发现。</td><td>Logan Lebanoff   Kaiqiang Song   Franck Dernoncourt   Doo Soon Kim   Seokhwan Kim   Walter Chang   Fei Liu</td></tr></tbody></table></div><h3 id="EMNLP-3"><a href="#EMNLP-3" class="headerlink" title="EMNLP"></a>EMNLP</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.02016&#39;]">A Hierarchical Network for Abstractive Meeting Summarization with Cross- Domain Pretraining</a></td><td></td><td><a href="https://github.com/microsoft/HMNet">https://github.com/microsoft/HMNet</a></td><td><a href="https://arxiv.org/pdf/2004.02016">https://arxiv.org/pdf/2004.02016</a></td><td>With the abundance of automatic meeting transcripts, meeting summarization is of great interest to both participants and other parties. Traditional methods of summarizing meetings depend on complex multi-step pipelines that make joint optimization intractable. Meanwhile, there are a handful of deep neural models for text summarization and dialogue systems. However, the semantic structure and styles of meeting transcripts are quite different from articles and conversations. In this paper, we propose a novel abstractive summary network that adapts to the meeting scenario. We design a hierarchical structure to accommodate long meeting transcripts and a role vector to depict the difference among speakers. Furthermore, due to the inadequacy of meeting summary data, we pretrain the model on large-scale news summary data. Empirical results show that our model outperforms previous approaches in both automatic metrics and human evaluation. For example, on ICSI dataset, the ROUGE-1 score increases from 34.66% to 46.28%.</td><td>由于有大量的自动会议记录，会议摘要对参与者和其他各方都非常感兴趣。总结会议的传统方法依赖于复杂的多步骤管道，这使得联合优化变得难以处理。同时，还有一些用于文本摘要和对话系统的深度神经模型。然而，会议记录的语义结构和风格与文章和对话有很大不同。在本文中，我们提出了一种适用于会议场景的新型抽象摘要网络。我们设计了一个层次结构来容纳长会议记录和一个角色向量来描述演讲者之间的差异。此外，由于会议摘要数据不足，我们在大规模新闻摘要数据上预训练模型。实证结果表明，我们的模型在自动度量和人工评估方面都优于以前的方法。例如，在 ICSI 数据集上，ROUGE-1 分数从 34.66% 增加到 46.28%。</td><td>Chenguang Zhu   Ruochen Xu   Michael Zeng   Xuedong Huang</td></tr><tr><td>2</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2004.13983&#39;]">Conditional Neural Generation using Sub-Aspect Functions for Extractive News Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2004.13983">https://arxiv.org/pdf/2004.13983</a></td><td>Much progress has been made in text summarization, fueled by neural architectures using large-scale training corpora. However, in the news domain, neural models easily overfit by leveraging position-related features due to the prevalence of the inverted pyramid writing style. In addition, there is an unmet need to generate a variety of summaries for different users. In this paper, we propose a neural framework that can flexibly control summary generation by introducing a set of sub-aspect functions (i.e. importance, diversity, position). These sub-aspect functions are regulated by a set of control codes to decide which sub-aspect to focus on during summary generation. We demonstrate that extracted summaries with minimal position bias is comparable with those generated by standard models that take advantage of position preference. We also show that news summaries generated with a focus on diversity can be more preferred by human raters. These results suggest that a more flexible neural summarization framework providing more control options could be desirable in tailoring to different user preferences, which is useful since it is often impractical to articulate such preferences for different applications a priori.</td><td>在使用大规模训练语料库的神经架构的推动下，文本摘要取得了很大进展。然而，在新闻领域，由于倒金字塔写作风格的盛行，神经模型很容易通过利用与位置相关的特征来过度拟合。此外，还存在为不同用户生成各种摘要的需求未得到满足。在本文中，我们提出了一个神经框架，可以通过引入一组子方面函数（即重要性、多样性、位置）来灵活控制摘要生成。这些子方面功能由一组控制代码调节，以决定在摘要生成期间关注哪个子方面。我们证明了具有最小位置偏差的提取摘要与利用位置偏好的标准模型生成的摘要具有可比性。我们还表明，人工评估者可能更喜欢以多样性为重点生成的新闻摘要。这些结果表明，在针对不同的用户偏好进行定制时，可能需要提供更多控制选项的更灵活的神经摘要框架，这很有用，因为先验地阐明不同应用程序的此类偏好通常是不切实际的。</td><td>Zhengyuan Liu   Ke Shi   Nancy F. Chen</td></tr><tr><td>3</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.08242&#39;]">Unsupervised Extractive Summarization by Pre-training Hierarchical Transformers</a></td><td></td><td><a href="https://github.com/xssstory/STAS">https://github.com/xssstory/STAS</a></td><td><a href="https://arxiv.org/pdf/2010.08242">https://arxiv.org/pdf/2010.08242</a></td><td>Unsupervised extractive document summarization aims to select important sentences from a document without using labeled summaries during training. Existing methods are mostly graph-based with sentences as nodes and edge weights measured by sentence similarities. In this work, we find that transformer attentions can be used to rank sentences for unsupervised extractive summarization. Specifically, we first pre-train a hierarchical transformer model using unlabeled documents only. Then we propose a method to rank sentences using sentence-level self-attentions and pre-training objectives. Experiments on CNN/DailyMail and New York Times datasets show our model achieves state-of-the-art performance on unsupervised summarization. We also find in experiments that our model is less dependent on sentence positions. When using a linear combination of our model and a recent unsupervised model explicitly modeling sentence positions, we obtain even better results.</td><td>无监督提取文档摘要旨在在训练期间不使用标记摘要从文档中选择重要句子。现有的方法大多是基于图的，以句子为节点，边权重由句子相似度衡量。在这项工作中，我们发现 Transformer attention 可用于对无监督提取摘要的句子进行排名。具体来说，我们首先仅使用未标记的文档预训练分层转换器模型。然后我们提出了一种使用句子级自我注意和预训练目标对句子进行排序的方法。在 CNN/DailyMail 和纽约时报数据集上的实验表明，我们的模型在无监督摘要方面达到了最先进的性能。我们还在实验中发现我们的模型对句子位置的依赖性较小。当使用我们的模型和最近的无监督模型的线性组合显式建模句子位置时，我们获得了更好的结果。</td><td>Shusheng Xu   Xingxing Zhang   Yi Wu   Furu Wei   Ming Zhou</td></tr><tr><td>4</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.01786&#39;]">Corpora Evaluation and System Bias detection in Multi Document Summarization</a></td><td></td><td><a href="https://github.com/LCS2-IIITD/summarization_bias">https://github.com/LCS2-IIITD/summarization_bias</a></td><td><a href="https://arxiv.org/pdf/2010.01786">https://arxiv.org/pdf/2010.01786</a></td><td>Multi-document summarization (MDS) is the task of reflecting key points from any set of documents into a concise text paragraph. In the past, it has been used to aggregate news, tweets, product reviews, etc. from various sources. Owing to no standard definition of the task, we encounter a plethora of datasets with varying levels of overlap and conflict between participating documents. There is also no standard regarding what constitutes summary information in MDS. Adding to the challenge is the fact that new systems report results on a set of chosen datasets, which might not correlate with their performance on the other datasets. In this paper, we study this heterogeneous task with the help of a few widely used MDS corpora and a suite of state-of-the-art models. We make an attempt to quantify the quality of summarization corpus and prescribe a list of points to consider while proposing a new MDS corpus. Next, we analyze the reason behind the absence of an MDS system which achieves superior performance across all corpora. We then observe the extent to which system metrics are influenced, and bias is propagated due to corpus properties. The scripts to reproduce the experiments in this work are available at <a href="https://github.com/LCS2-IIITD/summarization_bias.git">https://github.com/LCS2-IIITD/summarization_bias.git</a>.</td><td></td><td>Alvin Dey   Tanya Chowdhury   Yash Kumar Atri   Tanmoy Chakraborty</td></tr><tr><td>5</td><td>EMNLP2020</td><td><a href="[&#39;https://arxiv.org/abs/2010.05139&#39;]">An Empirical Study of Cross-Dataset Evaluation for Neural Summarization Systems</a></td><td></td><td><a href="https://github.com/zide05/CDEvalSumm">https://github.com/zide05/CDEvalSumm</a></td><td><a href="https://arxiv.org/pdf/2010.05139">https://arxiv.org/pdf/2010.05139</a></td><td>Neural network-based models augmented with unsupervised pre-trained knowledge have achieved impressive performance on text summarization. However, most existing evaluation methods are limited to an in-domain setting, where summarizers are trained and evaluated on the same dataset. We argue that this approach can narrow our understanding of the generalization ability for different summarization systems. In this paper, we perform an in-depth analysis of characteristics of different datasets and investigate the performance of different summarization models under a cross-dataset setting, in which a summarizer trained on one corpus will be evaluated on a range of out-of-domain corpora. A comprehensive study of 11 representative summarization systems on 5 datasets from different domains reveals the effect of model architectures and generation ways (i.e. abstractive and extractive) on model generalization ability. Further, experimental results shed light on the limitations of existing summarizers. Brief introduction and supplementary code can be found in <a href="https://github.com/zide05/CDEvalSumm">https://github.com/zide05/CDEvalSumm</a>.</td><td></td><td>Yiran Chen   Pengfei Liu   Ming Zhong   Zi-Yi Dou   Danqing Wang   Xipeng Qiu   Xuanjing Huang</td></tr><tr><td>6</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.13114&#39;]">Contrastive Attention Mechanism for Abstractive Sentence Summarization</a></td><td></td><td><a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td><a href="https://arxiv.org/pdf/1910.13114">https://arxiv.org/pdf/1910.13114</a></td><td>We propose a contrastive attention mechanism to extend the sequence-to-sequence framework for abstractive sentence summarization task, which aims to generate a brief summary of a given source sentence. The proposed contrastive attention mechanism accommodates two categories of attention: one is the conventional attention that attends to relevant parts of the source sentence, the other is the opponent attention that attends to irrelevant or less relevant parts of the source sentence. Both attentions are trained in an opposite way so that the contribution from the conventional attention is encouraged and the contribution from the opponent attention is discouraged through a novel softmax and softmin functionality. Experiments on benchmark datasets show that, the proposed contrastive attention mechanism is more focused on the relevant parts for the summary than the conventional attention mechanism, and greatly advances the state-of-the-art performance on the abstractive sentence summarization task. We release the code at <a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td>我们提出了一种对比注意机制来扩展抽象句子摘要任务的序列到序列框架，旨在生成给定源句子的简短摘要。所提出的对比注意力机制包含两类注意力：一种是关注源句相关部分的常规注意力，另一种是关注源句中不相关或不太相关部分的对手注意力。两种注意力都以相反的方式进行训练，从而通过新颖的 softmax 和 softmin 功能鼓励传统注意力的贡献，并阻止对手注意力的贡献。在基准数据集上的实验表明，所提出的对比注意机制比传统的注意机制更关注摘要的相关部分，并且大大提高了抽象句子摘要任务的最新性能。我们在 <a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a> 发布代码</td><td>Xiangyu Duan   Hoongfei Yu   Mingming Yin   Min Zhang   Weihua Luo   Yue Zhang</td></tr><tr><td>7</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.08486&#39;]">Concept Pointer Network for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/wprojectsn/codes">https://github.com/wprojectsn/codes</a></td><td><a href="https://arxiv.org/pdf/1910.08486">https://arxiv.org/pdf/1910.08486</a></td><td>A quality abstractive summary should not only copy salient source texts as summaries but should also tend to generate new conceptual words to express concrete details. Inspired by the popular pointer generator sequence-to-sequence model, this paper presents a concept pointer network for improving these aspects of abstractive summarization. The network leverages knowledge-based, context-aware conceptualizations to derive an extended set of candidate concepts. The model then points to the most appropriate choice using both the concept set and original source text. This joint approach generates abstractive summaries with higher-level semantic concepts. The training model is also optimized in a way that adapts to different data, which is based on a novel method of distantly-supervised learning guided by reference summaries and testing set. Overall, the proposed approach provides statistically significant improvements over several state-of-the-art models on both the DUC-2004 and Gigaword datasets. A human evaluation of the model’s abstractive abilities also supports the quality of the summaries produced within this framework.</td><td>高质量的抽象摘要不仅应该复制突出的源文本作为摘要，还应该倾向于生成新的概念词来表达具体细节。受流行的指针生成器序列到序列模型的启发，本文提出了一个概念指针网络，用于改进抽象摘要的这些方面。该网络利用基于知识的、上下文感知的概念化来推导出一组扩展的候选概念。然后，模型使用概念集和原始源文本指出最合适的选择。这种联合方法生成具有更高级别语义概念的抽象摘要。训练模型也以适应不同数据的方式进行了优化，这是基于一种以参考摘要和测试集为指导的远程监督学习的新方法。总体而言，与 DUC-2004 和 Gigaword 数据集上的几个最先进模型相比，所提出的方法在统计上有显着改进。对模型抽象能力的人工评估也支持在该框架内生成的摘要的质量。</td><td>Wang Wenbo   Gao Yang   Huang Heyan   Zhou Yuxiang</td></tr><tr><td>8</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1910.13114&#39;]">Contrastive Attention Mechanism for Abstractive Sentence Summarization</a></td><td></td><td><a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td><a href="https://arxiv.org/pdf/1910.13114">https://arxiv.org/pdf/1910.13114</a></td><td>We propose a contrastive attention mechanism to extend the sequence-to-sequence framework for abstractive sentence summarization task, which aims to generate a brief summary of a given source sentence. The proposed contrastive attention mechanism accommodates two categories of attention: one is the conventional attention that attends to relevant parts of the source sentence, the other is the opponent attention that attends to irrelevant or less relevant parts of the source sentence. Both attentions are trained in an opposite way so that the contribution from the conventional attention is encouraged and the contribution from the opponent attention is discouraged through a novel softmax and softmin functionality. Experiments on benchmark datasets show that, the proposed contrastive attention mechanism is more focused on the relevant parts for the summary than the conventional attention mechanism, and greatly advances the state-of-the-art performance on the abstractive sentence summarization task. We release the code at <a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a></td><td>我们提出了一种对比注意机制来扩展抽象句子摘要任务的序列到序列框架，旨在生成给定源句子的简短摘要。所提出的对比注意力机制包含两类注意力：一种是关注源句相关部分的常规注意力，另一种是关注源句中不相关或不太相关部分的对手注意力。两种注意力都以相反的方式进行训练，从而通过新颖的 softmax 和 softmin 功能鼓励传统注意力的贡献，并阻止对手注意力的贡献。在基准数据集上的实验表明，所提出的对比注意机制比传统的注意机制更关注摘要的相关部分，并且大大提高了抽象句子摘要任务的最新性能。我们在 <a href="https://github.com/travel-go/Abstractive-Text-Summarization">https://github.com/travel-go/Abstractive-Text-Summarization</a> 发布代码</td><td>Xiangyu Duan   Hoongfei Yu   Mingming Yin   Min Zhang   Weihua Luo   Yue Zhang</td></tr><tr><td>9</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1902.00863&#39;]">Neural Extractive Text Summarization with Syntactic Compression</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/1902.00863">https://arxiv.org/pdf/1902.00863</a></td><td>Recent neural network approaches to summarization are largely either selection-based extraction or generation-based abstraction. In this work, we present a neural model for single-document summarization based on joint extraction and syntactic compression. Our model chooses sentences from the document, identifies possible compressions based on constituency parses, and scores those compressions with a neural model to produce the final summary. For learning, we construct oracle extractive-compressive summaries, then learn both of our components jointly with this supervision. Experimental results on the CNN/Daily Mail and New York Times datasets show that our model achieves strong performance (comparable to state-of-the-art systems) as evaluated by ROUGE. Moreover, our approach outperforms an off-the-shelf compression module, and human and manual evaluation shows that our model’s output generally remains grammatical.</td><td>最近的神经网络总结方法主要是基于选择的提取或基于生成的抽象。在这项工作中，我们提出了一种基于联合提取和句法压缩的单文档摘要神经模型。我们的模型从文档中选择句子，根据选区解析识别可能的压缩，并使用神经模型对这些压缩进行评分以生成最终摘要。对于学习，我们构建 oracle 提取压缩摘要，然后在此监督下共同学习我们的两个组件。在 CNN/Daily Mail 和纽约时报数据集上的实验结果表明，我们的模型获得了 ROUGE 评估的强大性能（可与最先进的系统相媲美）。此外，我们的方法优于现成的压缩模块，人工和人工评估表明我们模型的输出通常保持语法。</td><td>Jiacheng Xu   Greg Durrett</td></tr><tr><td>10</td><td>EMNLP2019</td><td><a href="[&#39;https://arxiv.org/abs/1908.08345&#39;]">Text Summarization with Pretrained Encoders</a></td><td></td><td><a href="https://github.com/nlpyang/PreSumm">https://github.com/nlpyang/PreSumm</a></td><td><a href="https://arxiv.org/pdf/1908.08345">https://arxiv.org/pdf/1908.08345</a></td><td>Bidirectional Encoder Representations from Transformers (BERT) represents the latest incarnation of pretrained language models which have recently advanced a wide range of natural language processing tasks. In this paper, we showcase how BERT can be usefully applied in text summarization and propose a general framework for both extractive and abstractive models. We introduce a novel document-level encoder based on BERT which is able to express the semantics of a document and obtain representations for its sentences. Our extractive model is built on top of this encoder by stacking several inter-sentence Transformer layers. For abstractive summarization, we propose a new fine-tuning schedule which adopts different optimizers for the encoder and the decoder as a means of alleviating the mismatch between the two (the former is pretrained while the latter is not). We also demonstrate that a two-staged fine-tuning approach can further boost the quality of the generated summaries. Experiments on three datasets show that our model achieves state-of-the-art results across the board in both extractive and abstractive settings. Our code is available at <a href="https://github.com/nlpyang/PreSumm">https://github.com/nlpyang/PreSumm</a></td><td>Transformers 的双向编码器表示 (BERT) 代表了预训练语言模型的最新化身，这些模型最近推进了广泛的自然语言处理任务。在本文中，我们展示了 BERT 如何有效地应用于文本摘要，并为提取和抽象模型提出了一个通用框架。我们引入了一种基于 BERT 的新型文档级编码器，它能够表达文档的语义并获得其句子的表示。我们的提取模型建立在这个编码器之上，通过堆叠几个句间 Transformer 层。对于抽象摘要，我们提出了一种新的微调计划，它对编码器和解码器采用不同的优化器作为减轻两者之间不匹配的手段（前者是预训练的，而后者不是）。我们还证明了两阶段微调方法可以进一步提高生成摘要的质量。在三个数据集上的实验表明，我们的模型在提取和抽象设置中都取得了全面的最新结果。我们的代码可在 <a href="https://github.com/nlpyang/PreSumm">https://github.com/nlpyang/PreSumm</a> 获得</td><td>Yang Liu   Mirella Lapata</td></tr></tbody></table></div><h3 id="NAACL-3"><a href="#NAACL-3" class="headerlink" title="NAACL"></a>NAACL</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.08014&#39;]">GSum: A General Framework for Guided Neural Abstractive Summarization</a></td><td></td><td><a href="https://github.com/neulab/guided_summarization">https://github.com/neulab/guided_summarization</a></td><td><a href="https://arxiv.org/pdf/2010.08014">https://arxiv.org/pdf/2010.08014</a></td><td>Neural abstractive summarization models are flexible and can produce coherent summaries, but they are sometimes unfaithful and can be difficult to control. While previous studies attempt to provide different types of guidance to control the output and increase faithfulness, it is not clear how these strategies compare and contrast to each other. In this paper, we propose a general and extensible guided summarization framework (GSum) that can effectively take different kinds of external guidance as input, and we perform experiments across several different varieties. Experiments demonstrate that this model is effective, achieving state-of-the-art performance according to ROUGE on 4 popular summarization datasets when using highlighted sentences as guidance. In addition, we show that our guided model can generate more faithful summaries and demonstrate how different types of guidance generate qualitatively different summaries, lending a degree of controllability to the learned models.</td><td>神经抽象摘要模型很灵活，可以产生连贯的摘要，但它们有时不可靠并且难以控制。虽然以前的研究试图提供不同类型的指导来控制输出和增加忠诚度，但尚不清楚这些策略如何相互比较和对比。在本文中，我们提出了一个通用且可扩展的引导式总结框架（GSum），它可以有效地将不同种类的外部引导作为输入，并在几个不同的品种上进行实验。实验表明，该模型是有效的，在使用突出显示的句子作为指导时，根据 ROUGE 在 4 个流行的摘要数据集上实现了最先进的性能。此外，我们展示了我们的引导模型可以生成更忠实的摘要，并展示不同类型的引导如何生成质量不同的摘要，从而为学习模型提供一定程度的可控性。</td><td>Zi-Yi Dou   Pengfei Liu   Hiroaki Hayashi   Zhengbao Jiang   Graham Neubig</td></tr><tr><td>2</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2010.12836&#39;]">Improving Zero and Few-Shot Abstractive Summarization with Intermediate Fine- tuning and Data Augmentation</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2010.12836">https://arxiv.org/pdf/2010.12836</a></td><td>Models pretrained with self-supervised objectives on large text corpora achieve state-of-the-art performance on English text summarization tasks. However, these models are typically fine-tuned on hundreds of thousands of data points, an infeasible requirement when applying summarization to new, niche domains. In this work, we introduce a novel and generalizable method, called WikiTransfer, for fine-tuning pretrained models for summarization in an unsupervised, dataset-specific manner. WikiTransfer fine-tunes pretrained models on pseudo-summaries, produced from generic Wikipedia data, which contain characteristics of the target dataset, such as the length and level of abstraction of the desired summaries. WikiTransfer models achieve state-of-the-art, zero-shot abstractive summarization performance on the CNN-DailyMail dataset and demonstrate the effectiveness of our approach on three additional diverse datasets. These models are more robust to noisy data and also achieve better or comparable few-shot performance using 10 and 100 training examples when compared to few-shot transfer from other summarization datasets. To further boost performance, we employ data augmentation via round-trip translation as well as introduce a regularization term for improved few-shot transfer. To understand the role of dataset aspects in transfer performance and the quality of the resulting output summaries, we further study the effect of the components of our unsupervised fine-tuning data and analyze few-shot performance using both automatic and human evaluation.</td><td>在大型文本语料库上使用自监督目标进行预训练的模型在英语文本摘要任务上取得了最先进的性能。然而，这些模型通常会在数十万个数据点上进行微调，这在将汇总应用于新的利基领域时是不可行的。在这项工作中，我们引入了一种新颖且可推广的方法，称为 WikiTransfer，用于微调预训练模型，以无监督的、特定于数据集的方式进行汇总。 WikiTransfer 微调伪摘要上的预训练模型，这些模型由通用维基百科数据生成，其中包含目标数据集的特征，例如所需摘要的长度和抽象级别。 WikiTransfer 模型在 CNN-DailyMail 数据集上实现了最先进的零样本抽象摘要性能，并证明了我们的方法在另外三个不同数据集上的有效性。与来自其他摘要数据集的小样本传输相比，这些模型对嘈杂的数据更加稳健，并且使用 10 和 100 个训练示例也能实现更好或可比的小样本性能。为了进一步提高性能，我们通过往返翻译使用数据增强，并引入了一个正则化项来改进小样本传输。为了了解数据集方面在传输性能和结果输出摘要质量中的作用，我们进一步研究了无监督微调数据组件的影响，并使用自动和人工评估分析了小样本性能。</td><td>Alexander R. Fabbri   Simeng Han   Haoyuan Li   Haoran Li   Marjan Ghazvininejad   Shafiq Joty   Dragomir Radev   Yashar Mehdad</td></tr><tr><td>3</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.08400&#39;]">Structure-Aware Abstractive Conversation Summarization via Discourse and Action Graphs</a></td><td></td><td><a href="https://github.com/GT-SALT/Structure-Aware-BART">https://github.com/GT-SALT/Structure-Aware-BART</a></td><td><a href="https://arxiv.org/pdf/2104.08400">https://arxiv.org/pdf/2104.08400</a></td><td>Abstractive conversation summarization has received much attention recently. However, these generated summaries often suffer from insufficient, redundant, or incorrect content, largely due to the unstructured and complex characteristics of human-human interactions. To this end, we propose to explicitly model the rich structures in conversations for more precise and accurate conversation summarization, by first incorporating discourse relations between utterances and action triples (“who-doing-what”) in utterances through structured graphs to better encode conversations, and then designing a multi-granularity decoder to generate summaries by combining all levels of information. Experiments show that our proposed models outperform state-of-the-art methods and generalize well in other domains in terms of both automatic evaluations and human judgments. We have publicly released our code at <a href="https://github.com/GT-SALT/Structure-Aware-BART">https://github.com/GT-SALT/Structure-Aware-BART</a>.</td><td></td><td>Jiaao Chen   Diyi Yang</td></tr><tr><td>4</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2103.11332&#39;]">AdaptSum: Towards Low-Resource Domain Adaptation for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/TysonYu/AdaptSum">https://github.com/TysonYu/AdaptSum</a></td><td><a href="https://arxiv.org/pdf/2103.11332">https://arxiv.org/pdf/2103.11332</a></td><td>State-of-the-art abstractive summarization models generally rely on extensive labeled data, which lowers their generalization ability on domains where such data are not available. In this paper, we present a study of domain adaptation for the abstractive summarization task across six diverse target domains in a low-resource setting. Specifically, we investigate the second phase of pre-training on large-scale generative models under three different settings: 1) source domain pre-training; 2) domain-adaptive pre-training; and 3) task-adaptive pre-training. Experiments show that the effectiveness of pre-training is correlated with the similarity between the pre-training data and the target domain task. Moreover, we find that continuing pre-training could lead to the pre-trained model’s catastrophic forgetting, and a learning method with less forgetting can alleviate this issue. Furthermore, results illustrate that a huge gap still exists between the low-resource and high-resource settings, which highlights the need for more advanced domain adaptation methods for the abstractive summarization task.</td><td>最先进的抽象摘要模型通常依赖于广泛的标记数据，这降低了它们在这些数据不可用的域上的泛化能力。在本文中，我们提出了在低资源环境中跨六个不同目标域的抽象摘要任务的域适应研究。具体来说，我们研究了在三种不同设置下对大规模生成模型进行预训练的第二阶段：1）源域预训练； 2）领域自适应预训练； 3) 任务自适应预训练。实验表明，预训练的有效性与预训练数据与目标域任务之间的相似性相关。此外，我们发现继续预训练可能导致预训练模型的灾难性遗忘，而减少遗忘的学习方法可以缓解这个问题。此外，结果表明低资源和高资源设置之间仍然存在巨大差距，这突出了抽象摘要任务需要更高级的域适应方法。</td><td>Tiezheng Yu   Zihan Liu   Pascale Fung</td></tr><tr><td>5</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.01726&#39;]">A New Approach to Overgenerating and Scoring Abstractive Summaries</a></td><td></td><td><a href="https://github.com/ucfnlp/varying-length-summ">https://github.com/ucfnlp/varying-length-summ</a></td><td><a href="https://arxiv.org/pdf/2104.01726">https://arxiv.org/pdf/2104.01726</a></td><td>We propose a new approach to generate multiple variants of the target summary with diverse content and varying lengths, then score and select admissible ones according to users’ needs. Abstractive summarizers trained on single reference summaries may struggle to produce outputs that achieve multiple desirable properties, i.e., capturing the most important information, being faithful to the original, grammatical and fluent. In this paper, we propose a two-staged strategy to generate a diverse set of candidate summaries from the source text in stage one, then score and select admissible ones in stage two. Importantly, our generator gives a precise control over the length of the summary, which is especially well-suited when space is limited. Our selectors are designed to predict the optimal summary length and put special emphasis on faithfulness to the original text. Both stages can be effectively trained, optimized and evaluated. Our experiments on benchmark summarization datasets suggest that this paradigm can achieve state-of-the-art performance.</td><td>我们提出了一种新方法来生成具有不同内容和不同长度的目标摘要的多个变体，然后根据用户的需求评分并选择可接受的变体。在单一参考摘要上训练的抽象摘要者可能难以产生实现多种理想属性的输出，即捕获最重要的信息、忠实于原文、语法和流利。在本文中，我们提出了一个两阶段的策略，在第一阶段从源文本生成一组不同的候选摘要，然后在第二阶段评分并选择可接受的摘要。重要的是，我们的生成器可以精确控制摘要的长度，这尤其适用于空间有限的情况。我们的选择器旨在预测最佳摘要长度，并特别强调对原文的忠实度。这两个阶段都可以有效地训练、优化和评估。我们在基准摘要数据集上的实验表明，这种范式可以实现最先进的性能。</td><td>Kaiqiang Song   Bingqing Wang   Zhe Feng   Fei Liu</td></tr><tr><td>6</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.09061&#39;]">Improving Faithfulness in Abstractive Summarization with Contrast Candidate Generation and Selection</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.09061">https://arxiv.org/pdf/2104.09061</a></td><td>Despite significant progress in neural abstractive summarization, recent studies have shown that the current models are prone to generating summaries that are unfaithful to the original context. To address the issue, we study contrast candidate generation and selection as a model-agnostic post-processing technique to correct the extrinsic hallucinations (i.e. information not present in the source text) in unfaithful summaries. We learn a discriminative correction model by generating alternative candidate summaries where named entities and quantities in the generated summary are replaced with ones with compatible semantic types from the source document. This model is then used to select the best candidate as the final output summary. Our experiments and analysis across a number of neural summarization systems show that our proposed method is effective in identifying and correcting extrinsic hallucinations. We analyze the typical hallucination phenomenon by different types of neural summarization systems, in hope to provide insights for future work on the direction.</td><td>尽管在神经抽象摘要方面取得了重大进展，但最近的研究表明，当前的模型容易生成与原始上下文不相符的摘要。为了解决这个问题，我们研究了对比候选生成和选择作为一种与模型无关的后处理技术，以纠正不可靠摘要中的外在幻觉（即源文本中不存在的信息）。我们通过生成替代候选摘要来学习判别校正模型，其中生成的摘要中的命名实体和数量被替换为源文档中具有兼容语义类型的实体和数量。然后使用该模型选择最佳候选者作为最终输出摘要。我们对许多神经摘要系统的实验和分析表明，我们提出的方法在识别和纠正外在幻觉方面是有效的。我们通过不同类型的神经摘要系统分析了典型的幻觉现象，希望为未来的方向工作提供见解。</td><td>Sihao Chen   Fan Zhang   Kazoo Sone   Dan Roth</td></tr><tr><td>7</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2106.01317&#39;]">Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization</a></td><td></td><td><a href="https://github.com/jiangycTarheel/TPT-Summ">https://github.com/jiangycTarheel/TPT-Summ</a></td><td><a href="https://arxiv.org/pdf/2106.01317">https://arxiv.org/pdf/2106.01317</a></td><td>Abstractive summarization, the task of generating a concise summary of input documents, requires: (1) reasoning over the source document to determine the salient pieces of information scattered across the long document, and (2) composing a cohesive text by reconstructing these salient facts into a shorter summary that faithfully reflects the complex relations connecting these facts. In this paper, we adapt TP-TRANSFORMER (Schlag et al., 2019), an architecture that enriches the original Transformer (Vaswani et al., 2017) with the explicitly compositional Tensor Product Representation (TPR), for the task of abstractive summarization. The key feature of our model is a structural bias that we introduce by encoding two separate representations for each token to represent the syntactic structure (with role vectors) and semantic content (with filler vectors) separately. The model then binds the role and filler vectors into the TPR as the layer output. We argue that the structured intermediate representations enable the model to take better control of the contents (salient facts) and structures (the syntax that connects the facts) when generating the summary. Empirically, we show that our TP-TRANSFORMER outperforms the Transformer and the original TP-TRANSFORMER significantly on several abstractive summarization datasets based on both automatic and human evaluations. On several syntactic and semantic probing tasks, we demonstrate the emergent structural information in the role vectors and improved syntactic interpretability in the TPR layer outputs. Code and models are available at <a href="https://github.com/jiangycTarheel/TPT-Summ">https://github.com/jiangycTarheel/TPT-Summ</a>.</td><td>抽象摘要，即生成输入文档的简明摘要的任务，需要：(1) 对源文档进行推理以确定散布在长文档中的显着信息，以及 (2) 通过重构这些显着事实来组成一个有凝聚力的文本成一个简短的总结，忠实地反映了连接这些事实的复杂关系。在本文中，我们采用了 TP-TRANSFORMER (Schlag et al., 2019)，一种用显式组合张量积表示 (TPR) 丰富原始 Transformer (Vaswani et al., 2017) 的架构，用于抽象总结的任务.我们模型的关键特征是结构偏差，我们通过为每个标记编码两个单独的表示来分别表示句法结构（使用角色向量）和语义内容（使用填充向量）来引入结构偏差。然后模型将角色和填充向量绑定到 TPR 作为层输出。我们认为，结构化的中间表示使模型能够在生成摘要时更好地控制内容（显着事实）和结构（连接事实的语法）。根据经验，我们表明我们的 TP-TRANSFORMER 在基于自动和人工评估的几个抽象摘要数据集上显着优于 Transformer 和原始 TP-TRANSFORMER。在几个句法和语义探测任务中，我们展示了角色向量中的紧急结构信息和 TPR 层输出中改进的句法可解释性。代码和模型可在 <a href="https://github.com/jiangycTarheel/TPT-Summ">https://github.com/jiangycTarheel/TPT-Summ</a> 获得。</td><td>Yichen Jiang   Asli Celikyilmaz   Paul Smolensky   Paul Soulos   Sudha Rao   Hamid Palangi   Roland Fernandez   Caitlin Smith   Mohit Bansal   Jianfeng Gao</td></tr><tr><td>8</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.02205&#39;]">Attention Head Masking for Inference Time Content Selection in Abstractive Summarization</a></td><td></td><td></td><td><a href="https://arxiv.org/pdf/2104.02205">https://arxiv.org/pdf/2104.02205</a></td><td>How can we effectively inform content selection in Transformer-based abstractive summarization models? In this work, we present a simple-yet-effective attention head masking technique, which is applied on encoder-decoder attentions to pinpoint salient content at inference time. Using attention head masking, we are able to reveal the relation between encoder-decoder attentions and content selection behaviors of summarization models. We then demonstrate its effectiveness on three document summarization datasets based on both in-domain and cross-domain settings. Importantly, our models outperform prior state-of-the-art models on CNN/Daily Mail and New York Times datasets. Moreover, our inference-time masking technique is also data-efficient, requiring only 20% of the training samples to outperform BART fine-tuned on the full CNN/DailyMail dataset.</td><td>我们如何在基于 Transformer 的抽象摘要模型中有效地告知内容选择？在这项工作中，我们提出了一种简单而有效的注意力头掩蔽技术，该技术应用于编码器-解码器注意力以在推理时精确定位显着内容。使用注意力头屏蔽，我们能够揭示编码器-解码器注意力与摘要模型的内容选择行为之间的关系。然后，我们在基于域内和跨域设置的三个文档摘要数据集上证明了它的有效性。重要的是，我们的模型在 CNN/《每日邮报》和《纽约时报》数据集上的表现优于先前最先进的模型。此外，我们的推理时间屏蔽技术也是数据高效的，只需要 20% 的训练样本就可以胜过在完整的 CNN/DailyMail 数据集上微调的 BART。</td><td>Shuyang Cao   Lu Wang</td></tr><tr><td>9</td><td>NAACL2021</td><td><a href="[&#39;https://arxiv.org/abs/2104.13346&#39;]">Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics</a></td><td></td><td><a href="https://github.com/artidoro/frank">https://github.com/artidoro/frank</a></td><td><a href="https://arxiv.org/pdf/2104.13346">https://arxiv.org/pdf/2104.13346</a></td><td>Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights into the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets. Through these annotations, we identify the proportion of different categories of factual errors in various summarization models and benchmark factuality metrics, showing their correlation with human judgment as well as their specific strengths and weaknesses.</td><td>现代摘要模型生成高度流畅但通常实际上不可靠的输出。这引发了大量试图衡量自动生成的摘要的真实性的指标。由于缺乏共同的基准，这些指标无法进行比较。此外，所有这些方法都将事实性视为一个二元概念，无法更深入地了解不同系统造成的各种不一致。为了解决这些限制，我们设计了一种事实错误的类型学，并使用它从 CNN/DM 和 XSum 数据集的最先进的摘要系统中收集生成的摘要的人工注释。通过这些注释，我们确定了各种摘要模型和基准事实性指标中不同类别的事实错误的比例，显示了它们与人类判断的相关性以及它们的具体优势和劣势。</td><td>Artidoro Pagnoni   Vidhisha Balachandran   Yulia Tsvetkov</td></tr></tbody></table></div><h3 id="COLING-3"><a href="#COLING-3" class="headerlink" title="COLING"></a>COLING</h3><div class="table-container"><table><thead><tr><th>序号</th><th>会议/期刊</th><th>论文</th><th>主要技术</th><th>代码</th><th>论文下载地址</th><th>摘要</th><th>摘要翻译</th><th>作者</th></tr></thead><tbody><tr><td>1</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.00692&#39;]">How Domain Terminology Affects Meeting Summarization Performance</a></td><td></td><td><a href="https://github.com/ucfnlp/meeting-domain-terminology">https://github.com/ucfnlp/meeting-domain-terminology</a></td><td><a href="https://arxiv.org/pdf/2011.00692">https://arxiv.org/pdf/2011.00692</a></td><td>Meetings are essential to modern organizations. Numerous meetings are held and recorded daily, more than can ever be comprehended. A meeting summarization system that identifies salient utterances from the transcripts to automatically generate meeting minutes can help. It empowers users to rapidly search and sift through large meeting collections. To date, the impact of domain terminology on the performance of meeting summarization remains understudied, despite that meetings are rich with domain knowledge. In this paper, we create gold-standard annotations for domain terminology on a sizable meeting corpus; they are known as jargon terms. We then analyze the performance of a meeting summarization system with and without jargon terms. Our findings reveal that domain terminology can have a substantial impact on summarization performance. We publicly release all domain terminology to advance research in meeting summarization.</td><td></td><td>Jia Jin Koay   Alexander Roustai   Xiaojin Dai   Dillon Burns   Alec Kerrigan   Fei Liu</td></tr><tr><td>2</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.09739&#39;]">Fact-level Extractive Summarization with Hierarchical Graph Mask on BERT</a></td><td></td><td><a href="https://github.com/Ruifeng-paper/FactExsum-coling2020">https://github.com/Ruifeng-paper/FactExsum-coling2020</a></td><td><a href="https://arxiv.org/pdf/2011.09739">https://arxiv.org/pdf/2011.09739</a></td><td>Most current extractive summarization models generate summaries by selecting salient sentences. However, one of the problems with sentence-level extractive summarization is that there exists a gap between the human-written gold summary and the oracle sentence labels. In this paper, we propose to extract fact-level semantic units for better extractive summarization. We also introduce a hierarchical structure, which incorporates the multi-level of granularities of the textual information into the model. In addition, we incorporate our model with BERT using a hierarchical graph mask. This allows us to combine BERT’s ability in natural language understanding and the structural information without increasing the scale of the model. Experiments on the CNN/DaliyMail dataset show that our model achieves state-of-the-art results.</td><td>大多数当前的提取摘要模型通过选择显着句子来生成摘要。然而，句子级提取摘要的问题之一是人工编写的黄金摘要与oracle句子标签之间存在差距。在本文中，我们建议提取事实级别的语义单元以更好地提取摘要。我们还引入了一种层次结构，它将文本信息的多级粒度合并到模型中。此外，我们使用分层图掩码将我们的模型与 BERT 结合起来。这使我们能够在不增加模型规模的情况下，将 BERT 在自然语言理解方面的能力与结构信息结合起来。在 CNN/DaliyMail 数据集上的实验表明，我们的模型达到了最先进的结果。</td><td>Ruifeng Yuan   Zili Wang   Wenjie Li</td></tr><tr><td>3</td><td>COLING2020</td><td><a href="[&#39;https://arxiv.org/abs/2011.01421&#39;]">WSL-DS: Weakly Supervised Learning with Distant Supervision for Query Focused Multi-Document Abstractive Summarization</a></td><td></td><td><a href="https://github.com/tahmedge/WSL-DS-COLING-2020">https://github.com/tahmedge/WSL-DS-COLING-2020</a></td><td><a href="https://arxiv.org/pdf/2011.01421">https://arxiv.org/pdf/2011.01421</a></td><td>In the Query Focused Multi-Document Summarization (QF-MDS) task, a set of documents and a query are given where the goal is to generate a summary from these documents based on the given query. However, one major challenge for this task is the lack of availability of labeled training datasets. To overcome this issue, in this paper, we propose a novel weakly supervised learning approach via utilizing distant supervision. In particular, we use datasets similar to the target dataset as the training data where we leverage pre-trained sentence similarity models to generate the weak reference summary of each individual document in a document set from the multi-document gold reference summaries. Then, we iteratively train our summarization model on each single-document to alleviate the computational complexity issue that occurs while training neural summarization models in multiple documents (i.e., long sequences) at once. Experimental results in Document Understanding Conferences (DUC) datasets show that our proposed approach sets a new state-of-the-art result in terms of various evaluation metrics.</td><td>在 Query Focused Multi-Document Summarization (QF-MDS) 任务中，给出了一组文档和一个查询，其目标是根据给定的查询从这些文档中生成摘要。然而，这项任务的一个主要挑战是缺乏标记的训练数据集。为了克服这个问题，在本文中，我们提出了一种利用远程监督的新型弱监督学习方法。特别是，我们使用与目标数据集相似的数据集作为训练数据，我们利用预训练的句子相似性模型从多文档黄金参考摘要中生成文档集中每个单独文档的弱参考摘要。然后，我们在每个单文档上迭代训练我们的摘要模型，以减轻在一次在多个文档（即长序列）中训练神经摘要模型时出现的计算复杂性问题。文档理解会议 (DUC) 数据集中的实验结果表明，我们提出的方法在各种评估指标方面取得了新的最新成果。</td><td>Md Tahmid Rahman Laskar   Enamul Hoque   Jimmy Xiangji Huang</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> arxiv </tag>
            
            <tag> ACL </tag>
            
            <tag> NAACL </tag>
            
            <tag> EMNLP </tag>
            
            <tag> COLING </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown不常用数学符号语法</title>
      <link href="/2021/08/10/Markdown%E4%B8%8D%E5%B8%B8%E7%94%A8%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7%E8%AF%AD%E6%B3%95/"/>
      <url>/2021/08/10/Markdown%E4%B8%8D%E5%B8%B8%E7%94%A8%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7%E8%AF%AD%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="Markdown不常用数学符号语法"><a href="#Markdown不常用数学符号语法" class="headerlink" title="Markdown不常用数学符号语法"></a>Markdown不常用数学符号语法</h1><blockquote><p>参考资料：</p><ul><li><p><a href="https://blog.csdn.net/LB_yifeng/article/details/83302697">https://blog.csdn.net/LB_yifeng/article/details/83302697</a></p></li><li><p><a href="https://blog.csdn.net/qq_18150255/article/details/88040858?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-0.pc_relevant_baidujshouduan&amp;spm=1001.2101.3001.4242">https://blog.csdn.net/qq_18150255/article/details/88040858?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-0.pc_relevant_baidujshouduan&amp;spm=1001.2101.3001.4242</a></p></li></ul></blockquote><h2 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h2><div class="table-container"><table><thead><tr><th style="text-align:center">符号</th><th style="text-align:center">语法</th><th style="text-align:center">符号</th><th style="text-align:center">语法</th><th style="text-align:center">符号</th><th style="text-align:center">语法</th></tr></thead><tbody><tr><td style="text-align:center">±</td><td style="text-align:center">\pm</td><td style="text-align:center">⋅</td><td style="text-align:center">\cdot</td><td style="text-align:center">≈</td><td style="text-align:center">\approx</td></tr><tr><td style="text-align:center">∓</td><td style="text-align:center">\mp</td><td style="text-align:center">≠</td><td style="text-align:center">\nep</td><td style="text-align:center">$\ldots$</td><td style="text-align:center">\ldots</td></tr><tr><td style="text-align:center">$\bigotimes$</td><td style="text-align:center">\bigotimes</td><td style="text-align:center">$\bigoplus$</td><td style="text-align:center">\bigoplus​</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$\prod$</td><td style="text-align:center">\prod</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr></tbody></table></div><h2 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h2><div class="table-container"><table><thead><tr><th style="text-align:center">符号</th><th>语法</th><th>符号</th><th>语法</th><th>符号</th><th>语法</th></tr></thead><tbody><tr><td style="text-align:center">α</td><td>\alphaα</td><td>β</td><td>\beta</td><td>γ</td><td>\gammaγ</td></tr><tr><td style="text-align:center">ρ</td><td>\rhoρ</td><td>λ</td><td>\lambda</td><td>μ</td><td>\mu</td></tr><tr><td style="text-align:center">ξ</td><td>\xi</td><td>ω</td><td>\omega</td><td>ϵ</td><td>\epsilon</td></tr><tr><td style="text-align:center">φ</td><td>\varphi</td><td>δ</td><td>\delta</td><td></td></tr></tbody></table></div><h2 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h2><div class="table-container"><table><thead><tr><th style="text-align:center">符号</th><th style="text-align:center">语法</th><th style="text-align:center">符号</th><th style="text-align:center">语法</th><th style="text-align:center">符号</th><th style="text-align:center">语法</th></tr></thead><tbody><tr><td style="text-align:center">$\hat{a}$</td><td style="text-align:center">\hat{a}</td><td style="text-align:center">$\vec{a}$</td><td style="text-align:center">\vec{a}</td><td style="text-align:center">$\overrightarrow{AB}$</td><td style="text-align:center">\overrightarrow{AB}</td></tr></tbody></table></div><h2 id="箭头符号"><a href="#箭头符号" class="headerlink" title="箭头符号"></a>箭头符号</h2><div class="table-container"><table><thead><tr><th style="text-align:center">符号</th><th style="text-align:center">语法</th><th style="text-align:center">符号</th><th style="text-align:center">语法</th><th style="text-align:center">符号</th><th style="text-align:center">语法</th></tr></thead><tbody><tr><td style="text-align:center">$\rightarrow$</td><td style="text-align:center">\rightarrow</td><td style="text-align:center">$\Leftarrow$</td><td style="text-align:center">\Leftarrow</td><td style="text-align:center">$\Longrightarrow$</td><td style="text-align:center">\Longrightarrow</td></tr></tbody></table></div><h2 id="积分"><a href="#积分" class="headerlink" title="积分"></a>积分</h2><div class="table-container"><table><thead><tr><th style="text-align:center">符号</th><th style="text-align:center">语法</th><th style="text-align:center">符号</th><th style="text-align:center">语法</th><th style="text-align:center">符号</th><th style="text-align:center">语法</th></tr></thead><tbody><tr><td style="text-align:center">$\partial$</td><td style="text-align:center">\partial</td><td style="text-align:center">$\iint$</td><td style="text-align:center">\iint</td><td style="text-align:center">$\int$</td><td style="text-align:center">\int</td></tr></tbody></table></div><h2 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h2><div class="table-container"><table><thead><tr><th style="text-align:center">符号</th><th style="text-align:center">语法</th></tr></thead><tbody><tr><td style="text-align:center">$\sum_{k=1}^{n}f(k)$</td><td style="text-align:center">\sum_{k=1}^{n}f(k)</td></tr><tr><td style="text-align:center">$\prod_{k=1}^{n}f(k)$</td><td style="text-align:center">\prod_{k=1}^{n}f(k)</td></tr><tr><td style="text-align:center">$\lim_{n\to\infty}k^{-1}=0$</td><td style="text-align:center">\lim_{n\to\infty}k^{-1}=0</td></tr><tr><td style="text-align:center">$\int_{a}^{b}f(x)dx$</td><td style="text-align:center">\int_{a}^{b}f(x)dx</td></tr><tr><td style="text-align:center">${n\choose m}$</td><td style="text-align:center">{n\choose m}</td></tr><tr><td style="text-align:center">$f(x) = \left{ \begin{array}{lr} x^2 &amp; : x &lt; 0\  x^3 &amp; : x \ge 0  \end{array}\right.$</td><td style="text-align:center">f(x) =   \begin{array}{lr}    x^2 &amp; : x &lt; 0\    x^3 &amp; : x \ge 0  \end{array}</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> Latex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>arxiv论文整理工具</title>
      <link href="/2021/08/10/arxiv%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86%E5%B7%A5%E5%85%B7/"/>
      <url>/2021/08/10/arxiv%E8%AE%BA%E6%96%87%E6%95%B4%E7%90%86%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<h1 id="arxiv论文整理工具"><a href="#arxiv论文整理工具" class="headerlink" title="arxiv论文整理工具"></a>arxiv论文整理工具</h1><p>可以自动从arxiv获取各大顶会论文 </p><ul><li>自动下载论文 </li><li>摘要提取 </li><li>摘要翻译 </li><li>代码获取</li><li>整理导出pdf</li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><blockquote><p>必须修改变量 file_name = ‘papers.txt’</p><p>papers.txt为需要整理的论文名</p></blockquote><ul><li><p>papers.txt标准格式</p><blockquote><p>第一列为论文分类 第二列为论文名 其余可空</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">| --------- | ------------------------------------------------------------ | -------- | ---- | -------- |</span><br><span class="line">|           |                                                              |          |      |          |</span><br><span class="line">|           |                                                              |          |      |          |</span><br><span class="line">| ACL2020   | Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation |          |      |          |</span><br><span class="line">| ACL2020   | Simultaneous Translation Policies: From Fixed to Adaptive    |          |      |          |</span><br><span class="line">| ACL2020   | Multiscale Collaborative Deep Models for Neural Machine Translation |          |      |          |</span><br><span class="line">| ACL2020   | Character-Level Translation with Self-attention              |          |      |          |</span><br><span class="line">| ACL2020   | Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation |          |      |          |</span><br><span class="line">| ACL2020   | ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation |          |      |          |</span><br><span class="line">| ACL2020   | Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation |          |      |          |</span><br><span class="line">| ACL2020   | Variational Neural Machine Translation with Normalizing Flows |          |      |          |</span><br></pre></td></tr></table></figure><ul><li>具体实现</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br></pre></td><td class="code"><pre><span class="line">import html</span><br><span class="line">import json</span><br><span class="line">import os</span><br><span class="line">import random</span><br><span class="line">import re</span><br><span class="line">import time</span><br><span class="line">import urllib.request</span><br><span class="line">from urllib import parse</span><br><span class="line"></span><br><span class="line">import chardet</span><br><span class="line">import requests</span><br><span class="line">from lxml import etree</span><br><span class="line">from tqdm import tqdm</span><br><span class="line"></span><br><span class="line"># title = &#x27;Diversifying Dialogue Generation with Non-Conversational Text&#x27;</span><br><span class="line">file_name = &#x27;source_paper/COLING_摘要.txt&#x27;</span><br><span class="line">output_file_name = &#x27;COLING_摘要&#x27;</span><br><span class="line">download_path = &#x27;downloads/&#x27;</span><br><span class="line">GOOGLE_TRANSLATE_URL = &#x27;http://translate.google.cn/m?q=%s&amp;tl=%s&amp;sl=%s&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 读取论文目录文件</span><br><span class="line">def get_paper_name(file_name_fun):</span><br><span class="line">    paper_name_fun = []</span><br><span class="line">    # 论文 会议/期刊</span><br><span class="line">    paper_class_fun = []</span><br><span class="line">    with open(file_name_fun, &#x27;r&#x27;) as f:</span><br><span class="line">        file_info = f.readlines()</span><br><span class="line">    for i in file_info:</span><br><span class="line">        temp_read = str(i.split(&#x27;|&#x27;)[2]).replace(&#x27; &#x27;, &#x27;&#x27;)</span><br><span class="line">        # print(temp_read)</span><br><span class="line">        if not (temp_read.__contains__(&#x27;---&#x27;) or temp_read.__eq__(&#x27;&#x27;)):</span><br><span class="line">            paper_name_fun.append(i.split(&#x27;|&#x27;)[2].strip())</span><br><span class="line">            paper_class_fun.append(i.split(&#x27;|&#x27;)[1].strip())</span><br><span class="line">    print(&#x27;读取到 &#x27; + str(len(paper_name_fun)) + &#x27; 篇论文&#x27;)</span><br><span class="line">    return paper_name_fun, paper_class_fun</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 根据论文名从arxiv获取论文下载链接</span><br><span class="line"># 获取作者信息</span><br><span class="line"># 获取摘要</span><br><span class="line"># 翻译摘要</span><br><span class="line">def get_paper_urls_authors_abstract(title_fun):</span><br><span class="line">    url = &#x27;https://arxiv.org/search/?query=&#x27; + title_fun.replace(&#x27; &#x27;,</span><br><span class="line">                                                                 &#x27;+&#x27;) + &#x27;&amp;searchtype=title&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&#x27;</span><br><span class="line">    try:</span><br><span class="line">        # time.sleep(1)</span><br><span class="line">        html_fun = urllib.request.urlopen(url).read().decode(&#x27;utf-8&#x27;)</span><br><span class="line">        # time.sleep(1)</span><br><span class="line"></span><br><span class="line">        dom = etree.HTML(html_fun, etree.HTMLParser(encoding=&#x27;utf-8&#x27;))</span><br><span class="line">        # title = dom.xpath(&#x27;//*[@id=&quot;main-container&quot;]/div[2]/ol/li/p[1]/span/text()&#x27;)  # 论文名</span><br><span class="line">        paper_url_fun = dom.xpath(&#x27;//*[@id=&quot;main-container&quot;]/div[2]/ol/li/div/p/a/@href&#x27;)</span><br><span class="line">        # 判断论文是否可检索</span><br><span class="line">        if len(paper_url_fun) != 0:</span><br><span class="line">            download_url_fun = dom.xpath(&#x27;//*[@id=&quot;main-container&quot;]/div[2]/ol/li/div/p/span/a[1]/@href&#x27;)</span><br><span class="line">            author_fun_temp = dom.xpath(&#x27;//*[@id=&quot;main-container&quot;]/div[2]/ol/li/p[2]/a/text()&#x27;)</span><br><span class="line">            author_fun = &#x27;&#x27;</span><br><span class="line">            for i in author_fun_temp:</span><br><span class="line">                author_fun = author_fun + &quot;   &quot; + i</span><br><span class="line">            author_fun = author_fun.strip()</span><br><span class="line">            abstract_fun_temp = dom.xpath(&#x27;//*[@id=&quot;main-container&quot;]/div[2]/ol/li/p[3]/span[3]/text()&#x27;)</span><br><span class="line">            abstract_fun = str(abstract_fun_temp[0]).strip()</span><br><span class="line">            abstract_translate_fun = translate(abstract_fun, &quot;en&quot;, &quot;zh-CN&quot;)</span><br><span class="line">            return title_fun, paper_url_fun, download_url_fun, author_fun, abstract_fun, abstract_translate_fun</span><br><span class="line">        else:</span><br><span class="line">            print(&#x27;\n论文不可检索！！！&#x27;)</span><br><span class="line">            return &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;</span><br><span class="line">    except:</span><br><span class="line">        return &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;, &#x27;&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 下载论文</span><br><span class="line">def download_paper(download_path_fun, download_url_fun, title_fun):</span><br><span class="line">    temp_download_url = tqdm(download_url_fun)</span><br><span class="line">    # if not os.path.exists(download_path_fun + file_name.split(&#x27;.&#x27;)[0]):</span><br><span class="line">    #     os.makedirs(download_path_fun + file_name.split(&#x27;.&#x27;)[0])</span><br><span class="line">    # download_path_fun = download_path_fun + file_name.split(&#x27;.&#x27;)[0] + &#x27;/&#x27;</span><br><span class="line">    for url in temp_download_url:</span><br><span class="line">        if not str(url).__eq__(&#x27;&#x27;):</span><br><span class="line">            temp_download_url.set_description(&quot;\n正在下载： %s&quot; % url[0])</span><br><span class="line">            r = requests.get(url[0])</span><br><span class="line">            while r.status_code == 403:</span><br><span class="line">                time.sleep(500 + random.uniform(0, 500))</span><br><span class="line">                r = requests.get(url[0])</span><br><span class="line">            with open(download_path_fun + str(title_fun[download_url_fun.index(url)]) + &#x27;.pdf&#x27;, &quot;wb&quot;) as f:</span><br><span class="line">                f.write(r.content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取官方github代码</span><br><span class="line">def get_github_code(paper_url_fun):</span><br><span class="line">    temp_paper_url_fun = tqdm(paper_url_fun)</span><br><span class="line">    for url in temp_paper_url_fun:</span><br><span class="line">        if not str(url).__eq__(&#x27;&#x27;):</span><br><span class="line">            temp_paper_url_fun.set_description(&quot;\n正在获取代码： %s&quot; % url[0])</span><br><span class="line">            url = &#x27;https://arxiv.paperswithcode.com/api/v0/repos-and-datasets/&#x27; + url[0].split(&#x27;/&#x27;)[-1]</span><br><span class="line">            rq = requests.get(url)</span><br><span class="line">            rq.encoding = chardet.detect(rq.content)[&#x27;encoding&#x27;]</span><br><span class="line">            try:</span><br><span class="line">                code = json.loads(rq.text)[&#x27;code&#x27;][&#x27;official&#x27;][&#x27;url&#x27;]</span><br><span class="line">            except:</span><br><span class="line">                code = &#x27;&#x27;</span><br><span class="line">            github_code.append(code)</span><br><span class="line">        else:</span><br><span class="line">            github_code.append(&#x27;&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 翻译摘要</span><br><span class="line">def translate(text, text_language=&quot;auto&quot;, to_language=&quot;auto&quot;):</span><br><span class="line">    text = parse.quote(text)</span><br><span class="line">    url = GOOGLE_TRANSLATE_URL % (text, to_language, text_language)</span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    data = response.text</span><br><span class="line">    expr = r&#x27;(?s)class=&quot;(?:t0|result-container)&quot;&gt;(.*?)&lt;&#x27;</span><br><span class="line">    result = re.findall(expr, data)</span><br><span class="line">    if len(result) == 0:</span><br><span class="line">        return &quot;&quot;</span><br><span class="line"></span><br><span class="line">    return html.unescape(result[0])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 导出md文件</span><br><span class="line">def save_md(out_file_fun, title_fun, paper_class_fun, paper_url_fun, download_url_fun, github_code_fun):</span><br><span class="line">    exclude_paper = 0</span><br><span class="line">    with open(out_file_fun, &#x27;w+&#x27;) as f:</span><br><span class="line">        f.writelines(&#x27;| 序号 | 会议/期刊 | 论文 | 主要技术 | 代码 | 论文下载地址 | 摘要 | 摘要翻译 | 作者 |\n&#x27;)</span><br><span class="line">        f.writelines(&#x27;| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n&#x27;)</span><br><span class="line">        for i in range(len(title_fun)):</span><br><span class="line">            if not str(title_fun[i]).__eq__(&#x27;&#x27;):</span><br><span class="line">                if str(download_url_fun[i]).__eq__(&#x27;&#x27;):</span><br><span class="line">                    download_url_fun[i] = [&#x27;&#x27;]</span><br><span class="line">                md_str = &#x27;| &#x27; + str(i + 1 - exclude_paper) + &#x27; | &#x27; + str(paper_class_fun[i]) + &#x27; | [&#x27; + str(</span><br><span class="line">                    title_fun[i]) + &#x27;](&#x27; + str(</span><br><span class="line">                    paper_url_fun[i]) + &#x27;) |      | &#x27; + str(</span><br><span class="line">                    github_code_fun[i]) + &#x27; | &#x27; + str(download_url_fun[i][0]) + &#x27; | &#x27; + str(abstract[i]) + &#x27; | &#x27; + str(</span><br><span class="line">                    abstract_translate[i]) + &#x27; | &#x27; + str(author[i]) + &#x27; |\n&#x27;</span><br><span class="line">                f.writelines(md_str)</span><br><span class="line">            else:</span><br><span class="line">                exclude_paper += 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_md_simple(out_file_fun, title_fun, paper_class_fun, paper_url_fun, download_url_fun, github_code_fun):</span><br><span class="line">    exclude_paper = 0</span><br><span class="line">    with open(out_file_fun, &#x27;w+&#x27;) as f:</span><br><span class="line">        f.writelines(&#x27;| 序号 | 会议/期刊 | 论文 | 主要技术 | 代码 | 论文下载地址 |\n&#x27;)</span><br><span class="line">        f.writelines(&#x27;| --- | --- | --- | --- | --- | --- |\n&#x27;)</span><br><span class="line">        for i in range(len(title_fun)):</span><br><span class="line">            if not str(title_fun[i]).__eq__(&#x27;&#x27;):</span><br><span class="line">                if str(download_url_fun[i]).__eq__(&#x27;&#x27;):</span><br><span class="line">                    download_url_fun[i] = [&#x27;&#x27;]</span><br><span class="line">                md_str = &#x27;| &#x27; + str(i + 1 - exclude_paper) + &#x27; | &#x27; + str(paper_class_fun[i]) + &#x27; | [&#x27; + str(</span><br><span class="line">                    title_fun[i]) + &#x27;](&#x27; + str(</span><br><span class="line">                    paper_url_fun[i]) + &#x27;) |      | &#x27; + str(</span><br><span class="line">                    github_code_fun[i]) + &#x27; | &#x27; + str(download_url_fun[i][0]) + &#x27; |\n&#x27;</span><br><span class="line">                f.writelines(md_str)</span><br><span class="line">            else:</span><br><span class="line">                exclude_paper += 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    # main</span><br><span class="line">    out_file_dir = &#x27;data/&#x27; + output_file_name + &#x27;/&#x27;</span><br><span class="line">    out_file = out_file_dir + output_file_name + &#x27;.md&#x27;</span><br><span class="line">    out_file_simple = out_file_dir + output_file_name + &#x27;_simple.md&#x27;</span><br><span class="line">    download_path = download_path + output_file_name + &#x27;/&#x27;</span><br><span class="line">    # 创建输出文件夹</span><br><span class="line">    if not os.path.exists(out_file_dir):</span><br><span class="line">        os.makedirs(out_file_dir)</span><br><span class="line">    if not os.path.exists(download_path):</span><br><span class="line">        os.makedirs(download_path)</span><br><span class="line">    title = []</span><br><span class="line">    paper_url = []</span><br><span class="line">    download_url = []</span><br><span class="line">    github_code = []</span><br><span class="line">    author = []</span><br><span class="line">    abstract = []</span><br><span class="line">    abstract_translate = []</span><br><span class="line">    print(&#x27;\n读取论文目录文件&#x27;)</span><br><span class="line"></span><br><span class="line">    temp_file_name, paper_class = get_paper_name(file_name)</span><br><span class="line">    temp_file_name = tqdm(temp_file_name)</span><br><span class="line">    print(&#x27;\n根据论文名从arxiv获取论文链接 作者信息 摘要 摘要翻译&#x27;)</span><br><span class="line">    for title_name in temp_file_name:</span><br><span class="line">        temp_file_name.set_description(&quot;\n正在获取： %s&quot; % title_name)</span><br><span class="line">        time.sleep(1)</span><br><span class="line">        paper_urls = get_paper_urls_authors_abstract(title_name)</span><br><span class="line">        title.append(paper_urls[0])</span><br><span class="line">        paper_url.append(paper_urls[1])</span><br><span class="line">        download_url.append(paper_urls[2])</span><br><span class="line">        author.append(paper_urls[3])</span><br><span class="line">        abstract.append(paper_urls[4])</span><br><span class="line">        abstract_translate.append(paper_urls[5])</span><br><span class="line">    # 下载论文</span><br><span class="line">    print(&#x27;\n下载论文&#x27;)</span><br><span class="line">    download_paper(download_path, download_url, title)</span><br><span class="line">    print(&#x27;\n获取github代码&#x27;)</span><br><span class="line">    get_github_code(paper_url)</span><br><span class="line">    # 保存md</span><br><span class="line">    print(&#x27;\n导出md文件&#x27;)</span><br><span class="line">    # 更新文件保存地址</span><br><span class="line"></span><br><span class="line">    save_md(out_file, title, paper_class, paper_url, download_url, github_code)</span><br><span class="line">    print(out_file)</span><br><span class="line">    # 不保存 摘要 摘要翻译 作者信息</span><br><span class="line">    save_md_simple(out_file_simple, title, paper_class, paper_url, download_url, github_code)</span><br><span class="line">    print(out_file_simple)</span><br><span class="line"></span><br><span class="line">    print(&#x27;\n进程结束!&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> arxiv </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cheap and Good Simple and Effective Data Augmentation for Low Resource Machine Reading</title>
      <link href="/2021/08/06/Cheap%20and%20Good%20Simple%20and%20Effective%20Data%20Augmentation%20for%20Low%20Resource%20Machine%20Reading/"/>
      <url>/2021/08/06/Cheap%20and%20Good%20Simple%20and%20Effective%20Data%20Augmentation%20for%20Low%20Resource%20Machine%20Reading/</url>
      
        <content type="html"><![CDATA[<h1 id="Cheap-and-Good-Simple-and-Effective-Data-Augmentation-for-Low-Resource-Machine-Reading"><a href="#Cheap-and-Good-Simple-and-Effective-Data-Augmentation-for-Low-Resource-Machine-Reading" class="headerlink" title="Cheap and Good Simple and Effective Data Augmentation for Low Resource Machine Reading"></a>Cheap and Good Simple and Effective Data Augmentation for Low Resource Machine Reading</h1><blockquote><p> <a href="https://arxiv.org/abs/2106.04134">论文：https://arxiv.org/abs/2106.04134</a></p><p> <a href="https://github.com/vanh17/techqa">代码：https://github.com/vanh17/techqa</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>为低资源机器阅读理解提出了一个简单而有效的数据增强策略。首先在包含正确答案的近似上下文的增强数据上对MRC系统的答案提取组件进行预训练，然后再对准确答案的跨度进行训练。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>不是直接在训练期间提供的答案跨度上训练神经网络，而是先对其进行预训练，以确定答案出现的大致范围。然后，以两种不同的方式使用这个预训练的神经模型。首先，在训练之前，用这个模型的权重来初始化答案提取模型，而不是从头开始。第二，在推理时，将预训练的模型作为一个额外的文档检索组件来使用：只关注那些包含被确定为可能包含答案的文档。</p><p><strong>主要贡献：</strong></p><ul><li>为MRC QA引入了一种简单而有效的数据增强方法。通过人为地移动训练分区中答案跨度的边界来产生额外的训练数据，并在这些数据上预训练一个模型，以确定答案可能出现的大致范围。</li><li>使用两种不同的策略来利用预训练模型，首先，将其知识转移到答案提取模型中，用其学到的权重进行初始化；其次，在推理时，使用预训练模型根据文档包含答案上下文的可能性进行排序，并在得分最高的文档中提取答案。</li><li>将近似的RC知识用于文档检索和答案提取，可以大大改善在低资源RC任务上的性能。</li></ul><p><strong>模型结构：</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210804222659.png" alt="image-20210804222659187"></p><h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><blockquote><p>预训练 the BERT-MRC model    </p></blockquote><ul><li>首先用概率对答案进行抽样，抽取出需要用来数据增强的片段。</li><li>对于选中的答案片段，通过将正确的答案跨度向左或向右移动d个字符来产生n个额外的模糊答案跨度。每个生成的答案跨度都成为一个新的positive training data point。</li><li>用增加的训练数据构建新的训练数据artificial data，训练模型以抽取答案近似范围。</li></ul><h3 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h3><p>继续在原始答案跨度（没有增强的数据集）上进一步训练的BERT-MRC模型来转移这种近似答案边界的知识。由此产生训练的模型是用于完整任务中答案跨度预测的最终模型。</p><h3 id="Document-Retrieval"><a href="#Document-Retrieval" class="headerlink" title="Document Retrieval"></a>Document Retrieval</h3><p>采用在增强的数据上训练的模型来top-k score答案跨度，并只保留与这些答案跨度相关的文档。提供一个更小但更相关的候选文档集，可以大大改善AE的性能。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><blockquote><p>TechQA 一个复杂的、低资源的MRC任务。</p><p>PolicyQA 一个实用但规模适中的QA数据集，也包含长的答案跨度。</p></blockquote><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210805213308.png" alt="image-20210805213308533"></p><ul><li>数据增强有助于TechQA的文档检索任务。</li><li>与基线模型(OBB)相比，”数据增强 “模型，”数据增强+迁移学习 “模型的DRA分数大幅提高。</li><li>为了进一步分析数据增强对文档检索的影响，把 “数据增强 “模型检索到的文档作为输入到BERT Large的OBL基线中。证明由数据增强模型检索的候选文档可以提高外部独立模型的文档检索性能。</li></ul><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul><li>答案检索阶段：数据增强策略能够捕捉到答案出现的更大范围。</li><li>答案提取阶段：额外的训练数据，帮助提取模型缩小其搜索空间。</li></ul><p>实验证明，通过提供更大的答案范围和额外的训练数据（即生成人工训练数据点），可以改善文档检索和答案提取的性能。特别是，大大改善了基于BERT的检索器和答案提取器在TechQA上的表现。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> DAMa </tag>
            
            <tag> Low-Resource </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tensorflow模型保存与加载</title>
      <link href="/2021/08/05/Tensorflow%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD/"/>
      <url>/2021/08/05/Tensorflow%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<h1 id="Tensorflow模型保存与加载"><a href="#Tensorflow模型保存与加载" class="headerlink" title="Tensorflow模型保存与加载"></a>Tensorflow模型保存与加载</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>]=<span class="string">&#x27;2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    x is a simple image, not a batch</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x,y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">batchsz = <span class="number">128</span></span><br><span class="line">(x, y), (x_val, y_val) = datasets.mnist.load_data()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;datasets:&#x27;</span>, x.shape, y.shape, x.<span class="built_in">min</span>(), x.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">db = tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line">db = db.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">60000</span>).batch(batchsz)</span><br><span class="line">ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">ds_val = ds_val.<span class="built_in">map</span>(preprocess).batch(batchsz) </span><br><span class="line"></span><br><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(db))</span><br><span class="line"><span class="built_in">print</span>(sample[<span class="number">0</span>].shape, sample[<span class="number">1</span>].shape)</span><br></pre></td></tr></table></figure><pre><code>datasets: (60000, 28, 28) (60000,) 0 255(128, 784) (128, 10)</code></pre><h2 id="1-保存权值"><a href="#1-保存权值" class="headerlink" title="1.保存权值"></a>1.保存权值</h2><p>模型创建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================dense (Dense)                multiple                  200960    _________________________________________________________________dense_1 (Dense)              multiple                  32896     _________________________________________________________________dense_2 (Dense)              multiple                  8256      _________________________________________________________________dense_3 (Dense)              multiple                  2080      _________________________________________________________________dense_4 (Dense)              multiple                  330       =================================================================Total params: 244,522Trainable params: 244,522Non-trainable params: 0_________________________________________________________________</code></pre><p>模型训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">network.fit(db, epochs=<span class="number">3</span>, validation_data=ds_val, validation_freq=<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>Epoch 1/3469/469 [==============================] - 10s 22ms/step - loss: 0.2594 - accuracy: 0.9232Epoch 2/3469/469 [==============================] - 12s 25ms/step - loss: 0.1406 - accuracy: 0.9619 - val_loss: 0.1288 - val_accuracy: 0.9629Epoch 3/3469/469 [==============================] - 9s 20ms/step - loss: 0.1076 - accuracy: 0.970379/79 [==============================] - 3s 39ms/step - loss: 0.1237 - accuracy: 0.9689[0.12368294241494805, 0.9689]</code></pre><p>保存权值 删除之前创建的网络</p><blockquote><p>network.save_weights</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">network.save_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;saved weights.&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> network</span><br></pre></td></tr></table></figure><pre><code>saved weights.</code></pre><p>创建与之前结构相同的网络 并加载保存的权值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>加载权值 评估网络效果</p><blockquote><p>network.load_weights</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">network.load_weights(<span class="string">&#x27;weights.ckpt&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;loaded weights!&#x27;</span>)</span><br><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>loaded weights!79/79 [==============================] - 3s 40ms/step - loss: 0.1237 - accuracy: 0.9689[0.12368294241494805, 0.9689]</code></pre><h2 id="2-保存模型"><a href="#2-保存模型" class="headerlink" title="2.保存模型"></a>2.保存模型</h2><blockquote><p>保存模型的所有信息 效率较低 重新加载前无需创建与之前结构相同的网络</p></blockquote><p>模型创建&amp;训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">network.fit(db, epochs=<span class="number">2</span>, validation_data=ds_val, validation_freq=<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential_2&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================dense_10 (Dense)             multiple                  200960    _________________________________________________________________dense_11 (Dense)             multiple                  32896     _________________________________________________________________dense_12 (Dense)             multiple                  8256      _________________________________________________________________dense_13 (Dense)             multiple                  2080      _________________________________________________________________dense_14 (Dense)             multiple                  330       =================================================================Total params: 244,522Trainable params: 244,522Non-trainable params: 0_________________________________________________________________Epoch 1/2469/469 [==============================] - 11s 23ms/step - loss: 0.2920 - accuracy: 0.9103Epoch 2/2469/469 [==============================] - 13s 28ms/step - loss: 0.1434 - accuracy: 0.9591 - val_loss: 0.1399 - val_accuracy: 0.963679/79 [==============================] - 4s 46ms/step - loss: 0.1399 - accuracy: 0.9636[0.1399224520914398, 0.9636]</code></pre><p>保存模型所有信息</p><blockquote><p>network.save</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">network.save(<span class="string">&#x27;model.h5&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;saved total model.&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> network</span><br></pre></td></tr></table></figure><pre><code>saved total model.</code></pre><p>加载模型 评估效果</p><blockquote><p>tf.keras.models.load_model</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;loaded model from file.&#x27;</span>)</span><br><span class="line">network = tf.keras.models.load_model(<span class="string">&#x27;model.h5&#x27;</span>)</span><br><span class="line">                                     </span><br><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>loaded model from file.WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.79/79 [==============================] - 3s 35ms/step - loss: 0.1399 - accuracy: 0.9636[0.1399224520914398, 0.9636]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow.keras.layers keras.Model 自定义层应用</title>
      <link href="/2021/08/05/tensorflow.keras.layers%20keras.Model%20%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82%E5%BA%94%E7%94%A8/"/>
      <url>/2021/08/05/tensorflow.keras.layers%20keras.Model%20%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="tensorflow-keras-layers-keras-Model-自定义层应用"><a href="#tensorflow-keras-layers-keras-Model-自定义层应用" class="headerlink" title="tensorflow.keras.layers keras.Model 自定义层应用"></a>tensorflow.keras.layers keras.Model 自定义层应用</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span>    tensorflow <span class="keyword">import</span> keras</span><br></pre></td></tr></table></figure><p>数据预处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    x is a simple image, not a batch</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x,y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">自定义Layer</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDense</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inp_dim, outp_dim</span>):</span></span><br><span class="line"><span class="built_in">super</span>(MyDense, self).__init__()</span><br><span class="line"></span><br><span class="line">self.kernel = self.add_weight(<span class="string">&#x27;w&#x27;</span>, [inp_dim, outp_dim])</span><br><span class="line">self.bias = self.add_weight(<span class="string">&#x27;b&#x27;</span>, [outp_dim])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">out = inputs @ self.kernel + self.bias</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> out </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>自定义Model</p><blockquote><p>继承keras.Model可使用complie fit 等方法</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line"><span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line">        <span class="comment"># 自定义5层网络</span></span><br><span class="line">self.fc1 = MyDense(<span class="number">28</span>*<span class="number">28</span>, <span class="number">256</span>)</span><br><span class="line">self.fc2 = MyDense(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">self.fc3 = MyDense(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">self.fc4 = MyDense(<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">self.fc5 = MyDense(<span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># 定义网络传播过程</span></span><br><span class="line">x = self.fc1(inputs)</span><br><span class="line">x = tf.nn.relu(x)</span><br><span class="line">x = self.fc2(x)</span><br><span class="line">x = tf.nn.relu(x)</span><br><span class="line">x = self.fc3(x)</span><br><span class="line">x = tf.nn.relu(x)</span><br><span class="line">x = self.fc4(x)</span><br><span class="line">x = tf.nn.relu(x)</span><br><span class="line">x = self.fc5(x) </span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">batchsz = <span class="number">128</span></span><br><span class="line">(x, y), (x_val, y_val) = datasets.mnist.load_data()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;datasets:&#x27;</span>, x.shape, y.shape, x.<span class="built_in">min</span>(), x.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">db = tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line">db = db.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">60000</span>).batch(batchsz)</span><br><span class="line">ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">ds_val = ds_val.<span class="built_in">map</span>(preprocess).batch(batchsz) </span><br><span class="line"></span><br><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(db))</span><br><span class="line"><span class="built_in">print</span>(sample[<span class="number">0</span>].shape, sample[<span class="number">1</span>].shape)</span><br></pre></td></tr></table></figure><pre><code>datasets: (60000, 28, 28) (60000,) 0 255(128, 784) (128, 10)</code></pre><p>创建模型</p><blockquote><p>summary()必须在fit 或 build之后使用</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">network = MyModel()</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line"><span class="comment"># summary()必须在fit 或 build之后使用</span></span><br><span class="line">network.summary()</span><br><span class="line"></span><br><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">network.fit(db, epochs=<span class="number">5</span>, validation_data=ds_val,</span><br><span class="line">              validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;my_model_8&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================my_dense_40 (MyDense)        multiple                  200960    _________________________________________________________________my_dense_41 (MyDense)        multiple                  32896     _________________________________________________________________my_dense_42 (MyDense)        multiple                  8256      _________________________________________________________________my_dense_43 (MyDense)        multiple                  2080      _________________________________________________________________my_dense_44 (MyDense)        multiple                  330       =================================================================Total params: 244,522Trainable params: 244,522Non-trainable params: 0_________________________________________________________________Epoch 1/5469/469 [==============================] - 10s 22ms/step - loss: 0.3078 - accuracy: 0.9076Epoch 2/5469/469 [==============================] - 13s 28ms/step - loss: 0.1409 - accuracy: 0.9600 - val_loss: 0.1318 - val_accuracy: 0.9641Epoch 3/5469/469 [==============================] - 13s 27ms/step - loss: 0.1125 - accuracy: 0.9680Epoch 4/5469/469 [==============================] - 16s 35ms/step - loss: 0.0984 - accuracy: 0.9724 - val_loss: 0.1196 - val_accuracy: 0.9673Epoch 5/5469/469 [==============================] - 15s 32ms/step - loss: 0.0875 - accuracy: 0.976079/79 [==============================] - 3s 33ms/step - loss: 0.1224 - accuracy: 0.9704[0.12237951139141393, 0.9704]</code></pre><p>模型预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(ds_val))</span><br><span class="line">x = sample[<span class="number">0</span>]</span><br><span class="line">y = sample[<span class="number">1</span>] <span class="comment"># one-hot</span></span><br><span class="line">pred = network.predict(x) <span class="comment"># [b, 10]</span></span><br><span class="line"><span class="comment"># convert back to number </span></span><br><span class="line">y = tf.argmax(y, axis=<span class="number">1</span>)</span><br><span class="line">pred = tf.argmax(pred, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pred)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)tf.Tensor([7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow.keras.Model compile fit evaluate应用</title>
      <link href="/2021/08/04/tensorflow.keras%20compile%20fit%20evaluate%E5%BA%94%E7%94%A8/"/>
      <url>/2021/08/04/tensorflow.keras%20compile%20fit%20evaluate%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="tensorflow-keras-Model-compile-fit-evaluate应用"><a href="#tensorflow-keras-Model-compile-fit-evaluate应用" class="headerlink" title="tensorflow.keras.Model compile fit evaluate应用"></a>tensorflow.keras.Model compile fit evaluate应用</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br></pre></td></tr></table></figure><p>数据预处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    x is a simple image, not a batch</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x,y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">batchsz = <span class="number">128</span></span><br><span class="line">(x, y), (x_val, y_val) = datasets.mnist.load_data()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;datasets:&#x27;</span>, x.shape, y.shape, x.<span class="built_in">min</span>(), x.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">db = tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line"><span class="comment"># 使用preprocess函数处理数据集</span></span><br><span class="line">db = db.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">60000</span>).batch(batchsz)</span><br><span class="line"></span><br><span class="line">ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">ds_val = ds_val.<span class="built_in">map</span>(preprocess).batch(batchsz) </span><br><span class="line"></span><br><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(db))</span><br><span class="line"><span class="built_in">print</span>(sample[<span class="number">0</span>].shape, sample[<span class="number">1</span>].shape)</span><br></pre></td></tr></table></figure><pre><code>datasets: (60000, 28, 28) (60000,) 0 255(128, 784) (128, 10)</code></pre><p>模型构建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary()</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential_2&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================dense_10 (Dense)             multiple                  200960    _________________________________________________________________dense_11 (Dense)             multiple                  32896     _________________________________________________________________dense_12 (Dense)             multiple                  8256      _________________________________________________________________dense_13 (Dense)             multiple                  2080      _________________________________________________________________dense_14 (Dense)             multiple                  330       =================================================================Total params: 244,522Trainable params: 244,522Non-trainable params: 0_________________________________________________________________</code></pre><p>使用compile设置模型的优化器，损失函数，metrics</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">network.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>] <span class="comment"># accuracy用来计算准确度</span></span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用fit配置模型的训练数据集，训练轮次，验证数据集，验证频次</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.fit(db, epochs=<span class="number">5</span>, validation_data=ds_val, validation_freq=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><pre><code>Epoch 1/5469/469 [==============================] - 11s 24ms/step - loss: 0.2834 - accuracy: 0.9153Epoch 2/5469/469 [==============================] - 12s 27ms/step - loss: 0.1356 - accuracy: 0.9628 - val_loss: 0.1399 - val_accuracy: 0.9614Epoch 3/5469/469 [==============================] - 9s 19ms/step - loss: 0.1134 - accuracy: 0.9696Epoch 4/5469/469 [==============================] - 12s 26ms/step - loss: 0.1001 - accuracy: 0.9736 - val_loss: 0.1208 - val_accuracy: 0.9685Epoch 5/5469/469 [==============================] - 10s 21ms/step - loss: 0.0846 - accuracy: 0.9773&lt;tensorflow.python.keras.callbacks.History at 0x7f893e44de90&gt;</code></pre><p>使用evaluate评估模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.evaluate(ds_val)</span><br></pre></td></tr></table></figure><pre><code>79/79 [==============================] - 3s 36ms/step - loss: 0.1085 - accuracy: 0.9738[0.10845260255486716, 0.9738]</code></pre><p>使用predict预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(ds_val))</span><br><span class="line">x = sample[<span class="number">0</span>]</span><br><span class="line">y = sample[<span class="number">1</span>] <span class="comment"># one-hot</span></span><br><span class="line">pred = network.predict(x) <span class="comment"># [b, 10]</span></span><br><span class="line"><span class="comment"># convert back to number </span></span><br><span class="line">y = tf.argmax(y, axis=<span class="number">1</span>)</span><br><span class="line">pred = tf.argmax(pred, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(pred)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 0 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 9 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)tf.Tensor([7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3 1 3 4 7 2 7 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 4 6 4 3 0 7 0 2 9 1 7 3 2 9 7 7 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9 6 0 5 4 9 9 2 1 9 4 8 7 3 9 7 4 4 4 9 2 5 4 7 6 7 9 0 5], shape=(128,), dtype=int64)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tensorflow.keras metrics应用</title>
      <link href="/2021/08/04/tensorflow.keras%20metrics%E5%BA%94%E7%94%A8/"/>
      <url>/2021/08/04/tensorflow.keras%20metrics%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="tensorflow-keras-metrics应用"><a href="#tensorflow-keras-metrics应用" class="headerlink" title="tensorflow.keras metrics应用"></a>tensorflow.keras metrics应用</h1><blockquote><p>不使用metrics实现的博客参考：</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210804195738.png" alt="image-20210804195738825"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br></pre></td></tr></table></figure><p>更改数据类型并归一化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">x, y</span>):</span></span><br><span class="line"></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x,y</span><br></pre></td></tr></table></figure><p>加载数据集并进行预处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">batchsz = <span class="number">128</span></span><br><span class="line">(x, y), (x_val, y_val) = datasets.mnist.load_data()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;datasets:&#x27;</span>, x.shape, y.shape, x.<span class="built_in">min</span>(), x.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line">db = tf.data.Dataset.from_tensor_slices((x,y))</span><br><span class="line">db = db.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">60000</span>).batch(batchsz).repeat(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))</span><br><span class="line">ds_val = ds_val.<span class="built_in">map</span>(preprocess).batch(batchsz) </span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>datasets: (60000, 28, 28) (60000,) 0 255</code></pre><p>构建模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">network = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">network.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">network.summary() <span class="comment"># 打印模型详细信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化器</span></span><br><span class="line">optimizer = optimizers.Adam(lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================dense (Dense)                multiple                  200960    _________________________________________________________________dense_1 (Dense)              multiple                  32896     _________________________________________________________________dense_2 (Dense)              multiple                  8256      _________________________________________________________________dense_3 (Dense)              multiple                  2080      _________________________________________________________________dense_4 (Dense)              multiple                  330       =================================================================Total params: 244,522Trainable params: 244,522Non-trainable params: 0_________________________________________________________________</code></pre><p>模型训练并应用metrics</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用metrics计算准确率和loss的均值</span></span><br><span class="line">acc_meter = metrics.Accuracy()</span><br><span class="line">loss_meter = metrics.Mean()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step, (x,y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(db):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        <span class="comment"># [b, 28, 28] =&gt; [b, 784]</span></span><br><span class="line">        x = tf.reshape(x, (-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">        <span class="comment"># [b, 784] =&gt; [b, 10]</span></span><br><span class="line">        out = network(x)</span><br><span class="line">        <span class="comment"># [b] =&gt; [b, 10]</span></span><br><span class="line">        y_onehot = tf.one_hot(y, depth=<span class="number">10</span>) </span><br><span class="line">        <span class="comment"># [b]</span></span><br><span class="line">        <span class="comment"># 使用交叉熵损失</span></span><br><span class="line">        <span class="comment"># from_logits=True确保数据稳定性 out必须是网络直接输出的结果，不经过激活函数</span></span><br><span class="line">        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=<span class="literal">True</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加loss</span></span><br><span class="line">        loss_meter.update_state(loss)</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 梯度更新 反向传播</span></span><br><span class="line">    grads = tape.gradient(loss, network.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(<span class="built_in">zip</span>(grads, network.trainable_variables))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(step, <span class="string">&#x27;loss_meter:&#x27;</span>,loss_meter.result().numpy(),<span class="string">&#x27;  loss:&#x27;</span>, loss,) </span><br><span class="line">        <span class="comment"># 下一轮计算时应清零</span></span><br><span class="line">        loss_meter.reset_states()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># evaluate</span></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">        total, total_correct = <span class="number">0.</span>, <span class="number">0</span></span><br><span class="line">        <span class="comment"># 使用前清空历史状态</span></span><br><span class="line">        acc_meter.reset_states()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step1, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(ds_val): </span><br><span class="line">            <span class="comment"># [b, 28, 28] =&gt; [b, 784]</span></span><br><span class="line">            x = tf.reshape(x, (-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">            <span class="comment"># [b, 784] =&gt; [b, 10]</span></span><br><span class="line">            out = network(x) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># [b, 10] =&gt; [b] </span></span><br><span class="line">            pred = tf.argmax(out, axis=<span class="number">1</span>) </span><br><span class="line">            pred = tf.cast(pred, dtype=tf.int32)</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 方法一</span></span><br><span class="line">            <span class="comment"># bool type </span></span><br><span class="line">            correct = tf.equal(pred, y)</span><br><span class="line">            <span class="comment"># bool tensor =&gt; int tensor =&gt; numpy</span></span><br><span class="line">            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()</span><br><span class="line">            total += x.shape[<span class="number">0</span>]</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 方法二</span></span><br><span class="line">            acc_meter.update_state(y, pred)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(step, <span class="string">&#x27;Evaluate Acc:&#x27;</span>, total_correct/total, acc_meter.result().numpy())</span><br></pre></td></tr></table></figure><pre><code>0 loss_meter: 0.0147538865   loss: tf.Tensor(0.0147538865, shape=(), dtype=float32)78 Evaluate Acc: 0.9743 0.9743100 loss_meter: 0.04805827   loss: tf.Tensor(0.041749448, shape=(), dtype=float32)200 loss_meter: 0.053051163   loss: tf.Tensor(0.0131300185, shape=(), dtype=float32)300 loss_meter: 0.07365899   loss: tf.Tensor(0.0278976, shape=(), dtype=float32)400 loss_meter: 0.07007911   loss: tf.Tensor(0.05961611, shape=(), dtype=float32)500 loss_meter: 0.059413455   loss: tf.Tensor(0.04578472, shape=(), dtype=float32)78 Evaluate Acc: 0.976 0.976600 loss_meter: 0.045514174   loss: tf.Tensor(0.1006662, shape=(), dtype=float32)700 loss_meter: 0.05224053   loss: tf.Tensor(0.061094068, shape=(), dtype=float32)800 loss_meter: 0.06696898   loss: tf.Tensor(0.08473669, shape=(), dtype=float32)900 loss_meter: 0.06490257   loss: tf.Tensor(0.05812662, shape=(), dtype=float32)1000 loss_meter: 0.056545332   loss: tf.Tensor(0.10347018, shape=(), dtype=float32)78 Evaluate Acc: 0.9745 0.97451100 loss_meter: 0.0515905   loss: tf.Tensor(0.045466803, shape=(), dtype=float32)1200 loss_meter: 0.06225908   loss: tf.Tensor(0.046285823, shape=(), dtype=float32)1300 loss_meter: 0.057779107   loss: tf.Tensor(0.05366286, shape=(), dtype=float32)1400 loss_meter: 0.06661249   loss: tf.Tensor(0.10940219, shape=(), dtype=float32)1500 loss_meter: 0.059498344   loss: tf.Tensor(0.05784896, shape=(), dtype=float32)78 Evaluate Acc: 0.974 0.9741600 loss_meter: 0.06252271   loss: tf.Tensor(0.0287047, shape=(), dtype=float32)1700 loss_meter: 0.060016934   loss: tf.Tensor(0.006867729, shape=(), dtype=float32)1800 loss_meter: 0.05751593   loss: tf.Tensor(0.13693535, shape=(), dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Top-k准确率</title>
      <link href="/2021/08/02/Top-k%E5%87%86%E7%A1%AE%E7%8E%87/"/>
      <url>/2021/08/02/Top-k%E5%87%86%E7%A1%AE%E7%8E%87/</url>
      
        <content type="html"><![CDATA[<h1 id="Top-k准确率"><a href="#Top-k准确率" class="headerlink" title="Top-k准确率"></a>Top-k准确率</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span>  os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span> <span class="comment">#限制控制台打印日志级别</span></span><br><span class="line">tf.random.set_seed(<span class="number">2467</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">output, target, topk=(<span class="params"><span class="number">1</span>,</span>)</span>):</span></span><br><span class="line">    <span class="comment"># output [10,6]</span></span><br><span class="line">    maxk = <span class="built_in">max</span>(topk)</span><br><span class="line">    batch_size = target.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    pred = tf.math.top_k(output, maxk).indices <span class="comment"># 前K个最大值的索引 [10,maxk]</span></span><br><span class="line"><span class="comment">#     print(&#x27;每行top-6 最大值&#x27;,tf.math.top_k(output, maxk).values)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;每行top-6 最大值下标&#x27;</span>,tf.math.top_k(output, maxk).indices)</span><br><span class="line">    pred = tf.transpose(pred, perm=[<span class="number">1</span>, <span class="number">0</span>]) <span class="comment"># 转置 [maxk,10] 方便统计比较</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;转置 每行top-6 最大值下标&#x27;</span>,pred)</span><br><span class="line">    </span><br><span class="line">    target_ = tf.broadcast_to(target, pred.shape) <span class="comment"># target [10]广播成相同的形状 [maxk,10]</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;准确值&#x27;</span>,target_)</span><br><span class="line">    correct = tf.equal(pred, target_)</span><br><span class="line">    <span class="built_in">print</span>(correct)</span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> topk:</span><br><span class="line">        <span class="comment"># 分别计算top-1 到 top-k的准确率</span></span><br><span class="line">        correct_k = tf.cast(tf.reshape(correct[:k], [-<span class="number">1</span>]), dtype=tf.float32)</span><br><span class="line">        <span class="comment"># 展成行统计1的个数</span></span><br><span class="line">        correct_k = tf.reduce_sum(correct_k)</span><br><span class="line">        acc = <span class="built_in">float</span>(correct_k* (<span class="number">100.0</span> / batch_size) )</span><br><span class="line">        res.append(acc)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">output = tf.random.normal([<span class="number">10</span>, <span class="number">6</span>])</span><br><span class="line">output = tf.math.softmax(output, axis=<span class="number">1</span>)  <span class="comment"># 使得每行概率之和为1</span></span><br><span class="line">target = tf.random.uniform([<span class="number">10</span>], maxval=<span class="number">6</span>, dtype=tf.int32) <span class="comment"># 生成6类样本 因此top-6准确率一定为100%</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;prob:&#x27;</span>, output.numpy())</span><br><span class="line"></span><br><span class="line">pred = tf.argmax(output, axis=<span class="number">1</span>) <span class="comment"># argmax() 每行最大值的索引</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;pred:&#x27;</span>, pred.numpy())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;label:&#x27;</span>, target.numpy())</span><br><span class="line"></span><br><span class="line">acc = accuracy(output, target, topk=(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\ntop-1-6 acc:&#x27;</span>, acc)</span><br></pre></td></tr></table></figure><pre><code>prob: [[0.22184627 0.1221462  0.07409586 0.34996933 0.07511458 0.15682773] [0.14504947 0.04924896 0.21993972 0.07217006 0.08854685 0.42504498] [0.1542809  0.14255568 0.07593964 0.09910513 0.395387   0.13273162] [0.16668463 0.11025342 0.11436021 0.03997175 0.28128707 0.28744298] [0.05896802 0.02670637 0.3851833  0.13821954 0.27897805 0.11194469] [0.16363983 0.24467127 0.08584066 0.08326607 0.3861453  0.03643688] [0.28560603 0.22363636 0.06274495 0.26323685 0.03589749 0.12887837] [0.38431036 0.09477527 0.1130109  0.0730463  0.15465215 0.18020503] [0.05116006 0.15413527 0.16139452 0.32532734 0.14692572 0.16105707] [0.10868432 0.05033949 0.30445468 0.13251573 0.3949189  0.00908681]]pred: [3 5 4 5 2 4 0 0 3 4]label: [1 3 5 2 1 0 4 4 1 1]每行top-6 最大值下标 tf.Tensor([[3 0 5 1 4 2] [5 2 0 4 3 1] [4 0 1 5 3 2] [5 4 0 2 1 3] [2 4 3 5 0 1] [4 1 0 2 3 5] [0 3 1 5 2 4] [0 5 4 2 1 3] [3 2 5 1 4 0] [4 2 3 0 1 5]], shape=(10, 6), dtype=int32)转置 每行top-6 最大值下标 tf.Tensor([[3 5 4 5 2 4 0 0 3 4] [0 2 0 4 4 1 3 5 2 2] [5 0 1 0 3 0 1 4 5 3] [1 4 5 2 5 2 5 2 1 0] [4 3 3 1 0 3 2 1 4 1] [2 1 2 3 1 5 4 3 0 5]], shape=(6, 10), dtype=int32)准确值 tf.Tensor([[1 3 5 2 1 0 4 4 1 1] [1 3 5 2 1 0 4 4 1 1] [1 3 5 2 1 0 4 4 1 1] [1 3 5 2 1 0 4 4 1 1] [1 3 5 2 1 0 4 4 1 1] [1 3 5 2 1 0 4 4 1 1]], shape=(6, 10), dtype=int32)tf.Tensor([[False False False False False False False False False False] [False False False False False False False False False False] [False False False False False  True False  True False False] [ True False  True  True False False False False  True False] [False  True False False False False False False False  True] [False False False False  True False  True False False False]], shape=(6, 10), dtype=bool)top-1-6 acc: [0.0, 0.0, 20.0, 60.0, 80.0, 100.0]</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python求解回归问题</title>
      <link href="/2021/08/01/Python%E6%B1%82%E8%A7%A3%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/"/>
      <url>/2021/08/01/Python%E6%B1%82%E8%A7%A3%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="Python求解回归问题"><a href="#Python求解回归问题" class="headerlink" title="Python求解回归问题"></a>Python求解回归问题</h1><p>y=wx+b</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算给定(w,b)的平均误差</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_error_for_line_given_points</span>(<span class="params">b, w, points</span>):</span></span><br><span class="line">    totalError = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(points)):</span><br><span class="line">        x = points[i, <span class="number">0</span>]</span><br><span class="line">        y = points[i, <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># computer mean-squared-error</span></span><br><span class="line">        totalError += (y - (w * x + b)) ** <span class="number">2</span></span><br><span class="line">    <span class="comment"># average loss for each point</span></span><br><span class="line">    <span class="keyword">return</span> totalError / <span class="built_in">float</span>(<span class="built_in">len</span>(points))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_gradient</span>(<span class="params">b_current, w_current, points, learningRate</span>):</span></span><br><span class="line">    b_gradient = <span class="number">0</span></span><br><span class="line">    w_gradient = <span class="number">0</span></span><br><span class="line">    N = <span class="built_in">float</span>(<span class="built_in">len</span>(points))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(points)):</span><br><span class="line">        x = points[i, <span class="number">0</span>]</span><br><span class="line">        y = points[i, <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 求导数 除N取平均值</span></span><br><span class="line">        <span class="comment"># grad_b = 2(wx+b-y)</span></span><br><span class="line">        b_gradient += (<span class="number">2</span>/N) * ((w_current * x + b_current) - y)</span><br><span class="line">        <span class="comment"># grad_w = 2(wx+b-y)*x</span></span><br><span class="line">        w_gradient += (<span class="number">2</span>/N) * x * ((w_current * x + b_current) - y)</span><br><span class="line">    <span class="comment"># update b&#x27; w&#x27; </span></span><br><span class="line">    <span class="comment"># 梯度指向极大值方向 因此反方向更新梯度</span></span><br><span class="line">    new_b = b_current - (learningRate * b_gradient)</span><br><span class="line">    new_w = w_current - (learningRate * w_gradient)</span><br><span class="line">    temploss = compute_error_for_line_given_points(new_b, new_w, points)</span><br><span class="line">    loss.append(temploss)</span><br><span class="line">    <span class="keyword">return</span> [new_b, new_w]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent_runner</span>(<span class="params">points, starting_b, starting_w, learning_rate, num_iterations</span>):</span></span><br><span class="line">    b = starting_b</span><br><span class="line">    w = starting_w</span><br><span class="line">    <span class="comment"># update for several times</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">        b, w = step_gradient(b, w, np.array(points), learning_rate)</span><br><span class="line">    <span class="keyword">return</span> [b, w]</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span>():</span></span><br><span class="line">    points = np.genfromtxt(<span class="string">&quot;data.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>)</span><br><span class="line">    learning_rate = <span class="number">0.0001</span></span><br><span class="line">    initial_b = <span class="number">0</span> <span class="comment"># initial y-intercept guess</span></span><br><span class="line">    initial_w = <span class="number">0</span> <span class="comment"># initial slope guess</span></span><br><span class="line">    num_iterations = <span class="number">1000</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Starting gradient descent at b = &#123;0&#125;, w = &#123;1&#125;, error = &#123;2&#125;&quot;</span></span><br><span class="line">          .<span class="built_in">format</span>(initial_b, initial_w,</span><br><span class="line">                  compute_error_for_line_given_points(initial_b, initial_w, points))</span><br><span class="line">          )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Running...&quot;</span>)</span><br><span class="line">    [b, w] = gradient_descent_runner(points, initial_b, initial_w, learning_rate, num_iterations)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;After &#123;0&#125; iterations b = &#123;1&#125;, w = &#123;2&#125;, error = &#123;3&#125;&quot;</span>.</span><br><span class="line">          <span class="built_in">format</span>(num_iterations, b, w,</span><br><span class="line">                 compute_error_for_line_given_points(b, w, points))</span><br><span class="line">          )</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss = []</span><br><span class="line">run()</span><br></pre></td></tr></table></figure><pre><code>Starting gradient descent at b = 0, w = 0, error = 5565.107834483211Running...After 1000 iterations b = 0.08893651993741346, w = 1.4777440851894448, error = 112.61481011613473</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(loss))]</span><br><span class="line">plt.plot(x,loss)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7f82b2c8bd90&gt;]</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210801104603.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow实现手写数字识别</title>
      <link href="/2021/08/01/TensorFlow%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
      <url>/2021/08/01/TensorFlow%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="TensorFlow实现手写数字识别"><a href="#TensorFlow实现手写数字识别" class="headerlink" title="TensorFlow实现手写数字识别"></a>TensorFlow实现手写数字识别</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 设置GPU使用方式</span></span><br><span class="line"><span class="comment"># 获取GPU列表</span></span><br><span class="line">gpus = tf.config.experimental.list_physical_devices(<span class="string">&#x27;GPU&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(gpus)</span><br><span class="line"><span class="keyword">if</span> gpus:</span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 设置GPU为增长式占用</span></span><br><span class="line">    <span class="keyword">for</span> gpu <span class="keyword">in</span> gpus:</span><br><span class="line">      tf.config.experimental.set_memory_growth(gpu, <span class="literal">True</span>) </span><br><span class="line">  <span class="keyword">except</span> RuntimeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="comment"># 打印异常</span></span><br><span class="line">    <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure><pre><code>[]</code></pre><p>加载数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(xs, ys),_ = datasets.mnist.load_data() <span class="comment">#自动下载</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;datasets:&#x27;</span>, xs.shape, ys.shape, xs.<span class="built_in">min</span>(), xs.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">xs = tf.convert_to_tensor(xs, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">db = tf.data.Dataset.from_tensor_slices((xs,ys))  </span><br><span class="line">db = db.batch(batch_size).repeat(<span class="number">30</span>) <span class="comment">#将数据集分隔成batch_size个batch  repeat(30)代表训练30轮</span></span><br></pre></td></tr></table></figure><pre><code>datasets: (60000, 28, 28) (60000,) 0 255</code></pre><p>模型构建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Dense 全连接层</span></span><br><span class="line">model = Sequential([layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>), </span><br><span class="line">                     layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">                     layers.Dense(<span class="number">10</span>)])</span><br><span class="line">model.build(input_shape=(<span class="number">4</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">model.summary() <span class="comment">#打印模型信息</span></span><br><span class="line"></span><br><span class="line">optimizer = optimizers.SGD(lr=<span class="number">0.01</span>)</span><br><span class="line">acc_meter = metrics.Accuracy()</span><br></pre></td></tr></table></figure><pre><code>Model: &quot;sequential_3&quot;_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================dense_9 (Dense)              multiple                  200960    _________________________________________________________________dense_10 (Dense)             multiple                  32896     _________________________________________________________________dense_11 (Dense)             multiple                  1290      =================================================================Total params: 235,146Trainable params: 235,146Non-trainable params: 0_________________________________________________________________</code></pre><p>模型训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">total_acc = []</span><br><span class="line">total_loss = []</span><br><span class="line"><span class="keyword">for</span> step, (x,y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(db):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        <span class="comment"># 打平操作，[b, 28, 28] =&gt; [b, 784]</span></span><br><span class="line">        x = tf.reshape(x, (-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">        <span class="comment"># Step1. 得到模型输出output [b, 784] =&gt; [b, 10]</span></span><br><span class="line">        out = model(x)</span><br><span class="line">        <span class="comment"># [b] =&gt; [b, 10]</span></span><br><span class="line">        y_onehot = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">        <span class="comment"># 计算差的平方和，[b, 10]</span></span><br><span class="line">        loss = tf.square(out-y_onehot)</span><br><span class="line">        <span class="comment"># 计算每个样本的平均误差，[b]</span></span><br><span class="line">        loss = tf.reduce_sum(loss) / x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    acc_meter.update_state(tf.argmax(out, axis=<span class="number">1</span>), y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新梯度</span></span><br><span class="line">    grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">    optimizer.apply_gradients(<span class="built_in">zip</span>(grads, model.trainable_variables))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">200</span>==<span class="number">0</span>:</span><br><span class="line">        total_acc.append(acc_meter.result().numpy())</span><br><span class="line">        total_loss.append(<span class="built_in">float</span>(loss))</span><br><span class="line">        <span class="built_in">print</span>(step, <span class="string">&#x27;loss:&#x27;</span>, <span class="built_in">float</span>(loss), <span class="string">&#x27;acc:&#x27;</span>, acc_meter.result().numpy())</span><br><span class="line">        acc_meter.reset_states()</span><br></pre></td></tr></table></figure><pre><code>0 loss: 0.15352573990821838 acc: 0.95457846200 loss: 0.1597624123096466 acc: 0.95765626400 loss: 0.1545962393283844 acc: 0.9475600 loss: 0.1637483835220337 acc: 0.94578123800 loss: 0.15958964824676514 acc: 0.94765631000 loss: 0.20374062657356262 acc: 0.940781241200 loss: 0.18700677156448364 acc: 0.949218751400 loss: 0.15020117163658142 acc: 0.951406241600 loss: 0.14052757620811462 acc: 0.94218751800 loss: 0.15347686409950256 acc: 0.951093732000 loss: 0.15199950337409973 acc: 0.9652200 loss: 0.08358028531074524 acc: 0.953906242400 loss: 0.16466480493545532 acc: 0.954843762600 loss: 0.14589539170265198 acc: 0.9543752800 loss: 0.10357476770877838 acc: 0.952031253000 loss: 0.1552669256925583 acc: 0.951093733200 loss: 0.13997772336006165 acc: 0.956406243400 loss: 0.10184890031814575 acc: 0.95046883600 loss: 0.0966319739818573 acc: 0.9506253800 loss: 0.14316204190254211 acc: 0.96609384000 loss: 0.14158621430397034 acc: 0.96609384200 loss: 0.11101004481315613 acc: 0.95593754400 loss: 0.10630815476179123 acc: 0.960468774600 loss: 0.1794758141040802 acc: 0.954843764800 loss: 0.10882129520177841 acc: 0.95578125000 loss: 0.11497728526592255 acc: 0.961255200 loss: 0.20665663480758667 acc: 0.95593755400 loss: 0.22054731845855713 acc: 0.953906245600 loss: 0.08281977474689484 acc: 0.968281275800 loss: 0.1415213942527771 acc: 0.96968756000 loss: 0.10287574678659439 acc: 0.962343756200 loss: 0.14125148952007294 acc: 0.9593756400 loss: 0.0872105211019516 acc: 0.962968776600 loss: 0.09639552235603333 acc: 0.958906236800 loss: 0.09451914578676224 acc: 0.962031257000 loss: 0.09597232937812805 acc: 0.965156267200 loss: 0.27553442120552063 acc: 0.953906247400 loss: 0.11118196696043015 acc: 0.96359377600 loss: 0.13853389024734497 acc: 0.97421877800 loss: 0.0864826887845993 acc: 0.967656258000 loss: 0.12683367729187012 acc: 0.96578138200 loss: 0.0835743099451065 acc: 0.966718738400 loss: 0.07526201754808426 acc: 0.962031258600 loss: 0.08792373538017273 acc: 0.96343758800 loss: 0.1303400695323944 acc: 0.966259000 loss: 0.11500948667526245 acc: 0.96156259200 loss: 0.07716777920722961 acc: 0.962031259400 loss: 0.06136278063058853 acc: 0.97406259600 loss: 0.16090892255306244 acc: 0.973759800 loss: 0.050481319427490234 acc: 0.9679687610000 loss: 0.12725922465324402 acc: 0.967812510200 loss: 0.10010596364736557 acc: 0.965312510400 loss: 0.12236626446247101 acc: 0.96437510600 loss: 0.06595691293478012 acc: 0.9701562510800 loss: 0.16140709817409515 acc: 0.9673437511000 loss: 0.07903225719928741 acc: 0.9614062311200 loss: 0.09545521438121796 acc: 0.9707812711400 loss: 0.08132430166006088 acc: 0.9757812611600 loss: 0.14214324951171875 acc: 0.970312511800 loss: 0.0826168805360794 acc: 0.9692187312000 loss: 0.07449790835380554 acc: 0.9687512200 loss: 0.052427180111408234 acc: 0.968437512400 loss: 0.10587689280509949 acc: 0.9698437512600 loss: 0.14333687722682953 acc: 0.9692187312800 loss: 0.1134927049279213 acc: 0.966406213000 loss: 0.07688809186220169 acc: 0.9687513200 loss: 0.1413525640964508 acc: 0.976718713400 loss: 0.09582379460334778 acc: 0.9748437413600 loss: 0.10331477224826813 acc: 0.9704687613800 loss: 0.1101207584142685 acc: 0.97187514000 loss: 0.05487038940191269 acc: 0.9687514200 loss: 0.1763731837272644 acc: 0.971562514400 loss: 0.08923567831516266 acc: 0.97062514600 loss: 0.14577150344848633 acc: 0.9695312414800 loss: 0.07163411378860474 acc: 0.96687515000 loss: 0.09502746164798737 acc: 0.9782812615200 loss: 0.08452443033456802 acc: 0.9762515400 loss: 0.09686124324798584 acc: 0.9732812615600 loss: 0.0802001953125 acc: 0.9729687615800 loss: 0.10131652653217316 acc: 0.972812516000 loss: 0.12712924182415009 acc: 0.9701562516200 loss: 0.10623563826084137 acc: 0.97312516400 loss: 0.07512909919023514 acc: 0.9748437416600 loss: 0.08629828691482544 acc: 0.967516800 loss: 0.09165250509977341 acc: 0.9732812617000 loss: 0.08541638404130936 acc: 0.979687517200 loss: 0.03573321923613548 acc: 0.973906317400 loss: 0.08292931318283081 acc: 0.9751562517600 loss: 0.09117152541875839 acc: 0.974687517800 loss: 0.055078715085983276 acc: 0.9726562518000 loss: 0.07413016259670258 acc: 0.974218718200 loss: 0.10115832090377808 acc: 0.974218718400 loss: 0.06299661844968796 acc: 0.972812518600 loss: 0.056077420711517334 acc: 0.9704687618800 loss: 0.08558100461959839 acc: 0.9785937719000 loss: 0.0742747038602829 acc: 0.980312519200 loss: 0.06931197643280029 acc: 0.973437519400 loss: 0.07148833572864532 acc: 0.976718719600 loss: 0.11700235307216644 acc: 0.973906319800 loss: 0.06992246210575104 acc: 0.973593820000 loss: 0.05687614157795906 acc: 0.975937520200 loss: 0.14907342195510864 acc: 0.9745312320400 loss: 0.1653566211462021 acc: 0.9726562520600 loss: 0.03767940402030945 acc: 0.979531220800 loss: 0.07523676753044128 acc: 0.979218721000 loss: 0.07417837530374527 acc: 0.976562521200 loss: 0.08299359679222107 acc: 0.976406321400 loss: 0.04976201429963112 acc: 0.9776562521600 loss: 0.04690690338611603 acc: 0.97521800 loss: 0.04981674998998642 acc: 0.974687522000 loss: 0.0513470321893692 acc: 0.9782812622200 loss: 0.22548101842403412 acc: 0.97187522400 loss: 0.07231388241052628 acc: 0.9762522600 loss: 0.09100791811943054 acc: 0.982812522800 loss: 0.06141120195388794 acc: 0.9779687523000 loss: 0.0918603241443634 acc: 0.979531223200 loss: 0.04934592917561531 acc: 0.9779687523400 loss: 0.046293482184410095 acc: 0.9757812623600 loss: 0.055974338203668594 acc: 0.9754687523800 loss: 0.10047663748264313 acc: 0.9770312324000 loss: 0.0761006623506546 acc: 0.976562524200 loss: 0.03693201392889023 acc: 0.974218724400 loss: 0.03466993570327759 acc: 0.982187524600 loss: 0.10374853014945984 acc: 0.98187524800 loss: 0.026225175708532333 acc: 0.9825000 loss: 0.10136633366346359 acc: 0.978437525200 loss: 0.07362035661935806 acc: 0.97812525400 loss: 0.10292142629623413 acc: 0.9745312325600 loss: 0.03838391602039337 acc: 0.978437525800 loss: 0.1306307017803192 acc: 0.979062526000 loss: 0.056037187576293945 acc: 0.9754687526200 loss: 0.06480588018894196 acc: 0.980312526400 loss: 0.0460970476269722 acc: 0.9826562426600 loss: 0.11328999698162079 acc: 0.9807812626800 loss: 0.052961524575948715 acc: 0.980937527000 loss: 0.046149395406246185 acc: 0.978437527200 loss: 0.03660104423761368 acc: 0.9785937727400 loss: 0.07231131196022034 acc: 0.9779687527600 loss: 0.0969608873128891 acc: 0.9785937727800 loss: 0.07953917980194092 acc: 0.97812528000 loss: 0.05938175320625305 acc: 0.9776562528200 loss: 0.10404374450445175 acc: 0.98437528400 loss: 0.07486425340175629 acc: 0.9832812528600 loss: 0.06746675819158554 acc: 0.9807812628800 loss: 0.10037437081336975 acc: 0.9807812629000 loss: 0.04371890425682068 acc: 0.979062529200 loss: 0.1544964462518692 acc: 0.9798437429400 loss: 0.06675610691308975 acc: 0.979531229600 loss: 0.11682221293449402 acc: 0.9804687529800 loss: 0.055132970213890076 acc: 0.9776562530000 loss: 0.06676920503377914 acc: 0.984531230200 loss: 0.061399221420288086 acc: 0.98437530400 loss: 0.0784747451543808 acc: 0.98187530600 loss: 0.05704239010810852 acc: 0.98187530800 loss: 0.06897450983524323 acc: 0.9807812631000 loss: 0.09554265439510345 acc: 0.979218731200 loss: 0.07846721261739731 acc: 0.9798437431400 loss: 0.05001729726791382 acc: 0.982812531600 loss: 0.06418764591217041 acc: 0.97812531800 loss: 0.06677256524562836 acc: 0.9807812632000 loss: 0.06099291145801544 acc: 0.9860937632200 loss: 0.02437475323677063 acc: 0.982532400 loss: 0.054472584277391434 acc: 0.9829687532600 loss: 0.07025627791881561 acc: 0.982187532800 loss: 0.043403904885053635 acc: 0.98062533000 loss: 0.05405097454786301 acc: 0.981718833200 loss: 0.07893810421228409 acc: 0.981406333400 loss: 0.04618637263774872 acc: 0.981562533600 loss: 0.03955160081386566 acc: 0.978437533800 loss: 0.06573085486888885 acc: 0.98534000 loss: 0.05302225425839424 acc: 0.985937534200 loss: 0.04989982396364212 acc: 0.982812534400 loss: 0.06038925424218178 acc: 0.983437534600 loss: 0.08686563372612 acc: 0.9823437334800 loss: 0.05421433597803116 acc: 0.980937535000 loss: 0.04355776682496071 acc: 0.982812535200 loss: 0.12376898527145386 acc: 0.9812535400 loss: 0.12621557712554932 acc: 0.9807812635600 loss: 0.025318723171949387 acc: 0.98535800 loss: 0.047489866614341736 acc: 0.984218836000 loss: 0.06456907093524933 acc: 0.9839062736200 loss: 0.05885958671569824 acc: 0.984218836400 loss: 0.038796693086624146 acc: 0.983437536600 loss: 0.028620203956961632 acc: 0.982031236800 loss: 0.03317582234740257 acc: 0.981406337000 loss: 0.03372523933649063 acc: 0.983437537200 loss: 0.18894273042678833 acc: 0.9785937737400 loss: 0.06384888291358948 acc: 0.9823437337600 loss: 0.07211901247501373 acc: 0.987031237800 loss: 0.05046132951974869 acc: 0.984687538000 loss: 0.07783858478069305 acc: 0.98562538200 loss: 0.03523237258195877 acc: 0.984687538400 loss: 0.03408464789390564 acc: 0.982187538600 loss: 0.044989801943302155 acc: 0.982812538800 loss: 0.07720053195953369 acc: 0.9829687539000 loss: 0.05239255353808403 acc: 0.981718839200 loss: 0.026881976053118706 acc: 0.9807812639400 loss: 0.022131649777293205 acc: 0.9860937639600 loss: 0.0717465877532959 acc: 0.986562539800 loss: 0.020211482420563698 acc: 0.9848437340000 loss: 0.09074624627828598 acc: 0.98540200 loss: 0.05809881165623665 acc: 0.9851562440400 loss: 0.08850902318954468 acc: 0.98187540600 loss: 0.02669745683670044 acc: 0.984218840800 loss: 0.11308488249778748 acc: 0.983437541000 loss: 0.0438566729426384 acc: 0.980937541200 loss: 0.04586176574230194 acc: 0.984687541400 loss: 0.036804813891649246 acc: 0.9862541600 loss: 0.09279486536979675 acc: 0.9854687541800 loss: 0.03883099555969238 acc: 0.986718842000 loss: 0.033931516110897064 acc: 0.98542200 loss: 0.03281283751130104 acc: 0.984062542400 loss: 0.05394122377038002 acc: 0.983437542600 loss: 0.0685659870505333 acc: 0.98312542800 loss: 0.058388061821460724 acc: 0.9832812543000 loss: 0.05259823054075241 acc: 0.982543200 loss: 0.0837898999452591 acc: 0.98687543400 loss: 0.06377860903739929 acc: 0.987031243600 loss: 0.04784414917230606 acc: 0.9864062743800 loss: 0.08819957822561264 acc: 0.9864062744000 loss: 0.033343978226184845 acc: 0.9839062744200 loss: 0.1391856074333191 acc: 0.9860937644400 loss: 0.05300295725464821 acc: 0.9848437344600 loss: 0.1040736585855484 acc: 0.9835937644800 loss: 0.041021399199962616 acc: 0.981718845000 loss: 0.050329744815826416 acc: 0.988437545200 loss: 0.04664241150021553 acc: 0.987187545400 loss: 0.06599676609039307 acc: 0.9864062745600 loss: 0.04718659818172455 acc: 0.9876562445800 loss: 0.04680747911334038 acc: 0.9860937646000 loss: 0.0784095823764801 acc: 0.984531246200 loss: 0.062429361045360565 acc: 0.9862546400 loss: 0.03825797885656357 acc: 0.98546600 loss: 0.04770933836698532 acc: 0.98312546800 loss: 0.05306899920105934 acc: 0.98562547000 loss: 0.0469331368803978 acc: 0.9879687447200 loss: 0.018814777955412865 acc: 0.986718847400 loss: 0.04082533344626427 acc: 0.98812547600 loss: 0.05882826820015907 acc: 0.9864062747800 loss: 0.035880930721759796 acc: 0.9860937648000 loss: 0.04324483126401901 acc: 0.9864062748200 loss: 0.06581659615039825 acc: 0.9851562448400 loss: 0.038081344217061996 acc: 0.985312548600 loss: 0.032461464405059814 acc: 0.9829687548800 loss: 0.05362715572118759 acc: 0.9879687449000 loss: 0.04097782447934151 acc: 0.98937549200 loss: 0.038341302424669266 acc: 0.986718849400 loss: 0.05667734891176224 acc: 0.987187549600 loss: 0.06505107134580612 acc: 0.9862549800 loss: 0.048090700060129166 acc: 0.986718850000 loss: 0.038220785558223724 acc: 0.98687550200 loss: 0.10568118095397949 acc: 0.98550400 loss: 0.10147371888160706 acc: 0.98550600 loss: 0.02043035626411438 acc: 0.9889062650800 loss: 0.03445787355303764 acc: 0.987187551000 loss: 0.05728784203529358 acc: 0.987187551200 loss: 0.04533722251653671 acc: 0.9879687451400 loss: 0.03492813929915428 acc: 0.98812551600 loss: 0.020884167402982712 acc: 0.98687551800 loss: 0.025441624224185944 acc: 0.98562552000 loss: 0.026575148105621338 acc: 0.9864062752200 loss: 0.16384227573871613 acc: 0.984218852400 loss: 0.05616907402873039 acc: 0.986718852600 loss: 0.059886958450078964 acc: 0.9889062652800 loss: 0.04272538423538208 acc: 0.9879687453000 loss: 0.06959083676338196 acc: 0.988437553200 loss: 0.026869554072618484 acc: 0.987812553400 loss: 0.027034994214773178 acc: 0.9864062753600 loss: 0.03967958688735962 acc: 0.9879687453800 loss: 0.060415420681238174 acc: 0.9854687554000 loss: 0.03867259994149208 acc: 0.9864062754200 loss: 0.021209895610809326 acc: 0.984531254400 loss: 0.017180444672703743 acc: 0.989218854600 loss: 0.0526532307267189 acc: 0.9889062654800 loss: 0.015818050131201744 acc: 0.987812555000 loss: 0.08110405504703522 acc: 0.9885937655200 loss: 0.04867621138691902 acc: 0.988437555400 loss: 0.07329011708498001 acc: 0.986718855600 loss: 0.0186185110360384 acc: 0.987555800 loss: 0.09356825053691864 acc: 0.9864062756000 loss: 0.034789077937603 acc: 0.9848437356200 loss: 0.03775575011968613 acc: 0.9878125</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(total_loss))]</span><br><span class="line">plt.plot(x,total_loss)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7f8643ca4290&gt;]</code></pre><p>​<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210801143549.png" alt="png"><br>​    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(total_acc))]</span><br><span class="line">plt.plot(x,total_acc)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7f8643e6c2d0&gt;]</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210801143559.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow学习笔记（一）TensorFlow基础</title>
      <link href="/2021/07/31/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89TensorFlow%E5%9F%BA%E7%A1%80/"/>
      <url>/2021/07/31/TensorFlow%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89TensorFlow%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="TensorFlow学习笔记（一）TensorFlow基础"><a href="#TensorFlow学习笔记（一）TensorFlow基础" class="headerlink" title="TensorFlow学习笔记（一）TensorFlow基础"></a>TensorFlow学习笔记（一）TensorFlow基础</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras <span class="keyword">as</span> keras</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras.layers <span class="keyword">as</span> layers</span><br><span class="line"></span><br><span class="line"><span class="comment"># physical_devices = tf.config.experimental.list_physical_devices(&#x27;GPU&#x27;)</span></span><br><span class="line"><span class="comment"># assert len(physical_devices) &gt; 0, &quot;Not enough GPU hardware devices available&quot;</span></span><br><span class="line"><span class="comment"># tf.config.experimental.set_memory_growth(physical_devices[0], True)</span></span><br></pre></td></tr></table></figure><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h3><p>标量在 TensorFlow 是如何创建的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python 语言方式创建标量</span></span><br><span class="line">a = <span class="number">1.2</span> </span><br><span class="line"><span class="comment"># TF 方式创建标量</span></span><br><span class="line">aa = tf.constant(<span class="number">1.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">type</span>(a), <span class="built_in">type</span>(aa), tf.is_tensor(aa)</span><br></pre></td></tr></table></figure><pre><code>(float, tensorflow.python.framework.ops.EagerTensor, True)</code></pre><p>如果要使用 TensorFlow 提供的功能函数， 须通过 TensorFlow 规定的方式去创建张量，而不能使用 Python 语言的标准变量创建方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([<span class="number">1</span>,<span class="number">2.</span>,<span class="number">3.3</span>])</span><br><span class="line"><span class="comment"># 打印 TF 张量的相关信息                </span></span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=1, shape=(3,), dtype=float32, numpy=array([1. , 2. , 3.3], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将 TF 张量的数据导出为 numpy 数组格式</span></span><br><span class="line">x.numpy() </span><br></pre></td></tr></table></figure><pre><code>array([1. , 2. , 3.3], dtype=float32)</code></pre><p>与标量不同，向量的定义须通过 List 容器传给 tf.constant()函数。</p><p>创建一个元素的向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个元素的向量</span></span><br><span class="line">a = tf.constant([<span class="number">1.2</span>]) </span><br><span class="line">a, a.shape</span><br></pre></td></tr></table></figure><pre><code>(&lt;tf.Tensor: id=2, shape=(1,), dtype=float32, numpy=array([1.2], dtype=float32)&gt;, TensorShape([1]))</code></pre><p>创建 3 个元素的向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 创建 3 个元素的向量</span></span><br><span class="line">a = tf.constant([<span class="number">1</span>,<span class="number">2</span>, <span class="number">3.</span>])</span><br><span class="line">a, a.shape</span><br></pre></td></tr></table></figure><pre><code>(&lt;tf.Tensor: id=3, shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)&gt;, TensorShape([3]))</code></pre><p>定义矩阵</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 2 行 2 列的矩阵</span></span><br><span class="line">a = tf.constant([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]) </span><br><span class="line">a, a.shape</span><br></pre></td></tr></table></figure><pre><code>(&lt;tf.Tensor: id=4, shape=(2, 2), dtype=int32, numpy= array([[1, 2],        [3, 4]], dtype=int32)&gt;, TensorShape([2, 2]))</code></pre><p>三维张量可以定义为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 3 维张量</span></span><br><span class="line">tf.constant([[[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]],[[<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>]]]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=5, shape=(2, 2, 2), dtype=int32, numpy=array([[[1, 2],        [3, 4]],       [[5, 6],        [7, 8]]], dtype=int32)&gt;</code></pre><p>通过传入字符串对象即可创建字符串类型的张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建字符串</span></span><br><span class="line">a = tf.constant(<span class="string">&#x27;Hello, Deep Learning.&#x27;</span>) </span><br><span class="line">a</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=6, shape=(), dtype=string, numpy=b&#39;Hello, Deep Learning.&#39;&gt;</code></pre><h3 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h3><p>通过传入字符串对象即可创建字符串类型的张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建字符串</span></span><br><span class="line">a = tf.constant(<span class="string">&#x27;Hello, Deep Learning.&#x27;</span>) </span><br><span class="line">a</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=7, shape=(), dtype=string, numpy=b&#39;Hello, Deep Learning.&#39;&gt;</code></pre><p>在 tf.strings 模块中，提供了常见的字符串类型的工具函数，如小写化 lower()、 拼接<br>join()、 长度 length()、 切分 split()等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 小写化字符串</span></span><br><span class="line">tf.strings.lower(a) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=8, shape=(), dtype=string, numpy=b&#39;hello, deep learning.&#39;&gt;</code></pre><h3 id="布尔类型"><a href="#布尔类型" class="headerlink" title="布尔类型"></a>布尔类型</h3><p>布尔类型的张量只需要传入 Python 语言的布尔类型数据，转换成 TensorFlow 内部布尔型即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建布尔类型标量</span></span><br><span class="line">tf.constant(<span class="literal">True</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=9, shape=(), dtype=bool, numpy=True&gt;</code></pre><p>创建布尔类型的向量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 创建布尔类型向量</span></span><br><span class="line">tf.constant([<span class="literal">True</span>, <span class="literal">False</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=10, shape=(2,), dtype=bool, numpy=array([ True, False])&gt;</code></pre><p>需要注意的是， TensorFlow 的布尔类型和 Python 语言的布尔类型并不等价，不能通用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 TF 布尔张量</span></span><br><span class="line">a = tf.constant(<span class="literal">True</span>) </span><br><span class="line"><span class="comment"># TF 布尔类型张量与 python 布尔类型比较</span></span><br><span class="line"><span class="built_in">print</span>(a <span class="keyword">is</span> <span class="literal">True</span>) </span><br><span class="line"><span class="comment"># 仅数值比较</span></span><br><span class="line"><span class="built_in">print</span>(a == <span class="literal">True</span>) </span><br></pre></td></tr></table></figure><pre><code>Falsetf.Tensor(True, shape=(), dtype=bool)</code></pre><h2 id="数值精度"><a href="#数值精度" class="headerlink" title="数值精度"></a>数值精度</h2><p>在创建张量时，可以指定张量的保存精度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建指定精度的张量</span></span><br><span class="line">tf.constant(<span class="number">123456789</span>, dtype=tf.int16)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=14, shape=(), dtype=int16, numpy=-13035&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.constant(<span class="number">123456789</span>, dtype=tf.int32)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=15, shape=(), dtype=int32, numpy=123456789&gt;</code></pre><p>对于浮点数， 高精度的张量可以表示更精准的数据，例如采用 tf.float32 精度保存π时，实际保存的数据为 3.1415927</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 从 numpy 中导入 pi 常量</span></span><br><span class="line">np.pi </span><br><span class="line"><span class="comment"># 32 位</span></span><br><span class="line">tf.constant(np.pi, dtype=tf.float32) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=16, shape=(), dtype=float32, numpy=3.1415927&gt;</code></pre><p>如果采用 tf.float64 精度保存π，则能获得更高的精度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.constant(np.pi, dtype=tf.float64) <span class="comment"># 64 位</span></span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=17, shape=(), dtype=float64, numpy=3.141592653589793&gt;</code></pre><h3 id="读取精度"><a href="#读取精度" class="headerlink" title="读取精度"></a>读取精度</h3><p>通过访问张量的 dtype 成员属性可以判断张量的保存精度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(np.pi, dtype=tf.float16)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取原有张量的数值精度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;before:&#x27;</span>,a.dtype) </span><br><span class="line"><span class="comment"># 如果精度不符合要求，则进行转换</span></span><br><span class="line"><span class="keyword">if</span> a.dtype != tf.float32: </span><br><span class="line">    <span class="comment"># tf.cast 函数可以完成精度转换</span></span><br><span class="line">    a = tf.cast(a,tf.float32) </span><br><span class="line"><span class="comment"># 打印转换后的精度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;after :&#x27;</span>,a.dtype) </span><br></pre></td></tr></table></figure><pre><code>before: &lt;dtype: &#39;float16&#39;&gt;after : &lt;dtype: &#39;float32&#39;&gt;</code></pre><h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><p>系统的每个模块使用的数据类型、 数值精度可能各不相同， 对于不符合要求的张量的类型及精度， 需要通过 tf.cast 函数进行转换</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 tf.float16 低精度张量</span></span><br><span class="line">a = tf.constant(np.pi, dtype=tf.float16) </span><br><span class="line"><span class="comment"># 转换为高精度张量</span></span><br><span class="line">tf.cast(a, tf.double) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=21, shape=(), dtype=float64, numpy=3.140625&gt;</code></pre><p>进行类型转换时，需要保证转换操作的合法性， 例如将高精度的张量转换为低精度的张量时，可能发生数据溢出隐患：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(<span class="number">123456789</span>, dtype=tf.int32)</span><br><span class="line"><span class="comment"># 转换为低精度整型</span></span><br><span class="line">tf.cast(a, tf.int16) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=23, shape=(), dtype=int16, numpy=-13035&gt;</code></pre><p>布尔类型与整型之间相互转换也是合法的， 是比较常见的操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([<span class="literal">True</span>, <span class="literal">False</span>])</span><br><span class="line"><span class="comment"># 布尔类型转整型</span></span><br><span class="line">tf.cast(a, tf.int32) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=25, shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)&gt;</code></pre><p>一般默认 0 表示 False， 1 表示 True，在 TensorFlow 中，将非 0 数字都视为 True，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="comment"># 整型转布尔类型</span></span><br><span class="line">tf.cast(a, tf.<span class="built_in">bool</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=27, shape=(4,), dtype=bool, numpy=array([ True, False,  True,  True])&gt;</code></pre><h2 id="待优化张量"><a href="#待优化张量" class="headerlink" title="待优化张量"></a>待优化张量</h2><p>TensorFlow 增加了一种专门的数据类型来支持梯度信息的记录： tf.Variable。 tf.Variable 类型在普通的张量类型基础上添加了 name， trainable 等属性来支持计算图的构建。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 TF 张量</span></span><br><span class="line">a = tf.constant([-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]) </span><br><span class="line"><span class="comment"># 转换为 Variable 类型</span></span><br><span class="line">aa = tf.Variable(a) </span><br><span class="line"><span class="comment"># Variable 类型张量的属性</span></span><br><span class="line">aa.name, aa.trainable </span><br></pre></td></tr></table></figure><pre><code>(&#39;Variable:0&#39;, True)</code></pre><p>name 属性用于命名计算图中的变量，这套命名体系是 TensorFlow 内部维护的， 一般不需要用户关注 name 属性；<br>trainable属性表征当前张量是否需要被优化，创建 Variable 对象时是默认启用优化标志，可以设置trainable=False 来设置张量不需要优化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接创建 Variable 张量</span></span><br><span class="line">tf.Variable([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Variable &#39;Variable:0&#39; shape=(2, 2) dtype=int32, numpy=array([[1, 2],       [3, 4]], dtype=int32)&gt;</code></pre><h2 id="创建张量"><a href="#创建张量" class="headerlink" title="创建张量"></a>创建张量</h2><h3 id="从数组、列表对象创建"><a href="#从数组、列表对象创建" class="headerlink" title="从数组、列表对象创建"></a>从数组、列表对象创建</h3><p>通过 tf.convert_to_tensor 函数可以创建新 Tensor，并将保存在 Python List 对象或者Numpy Array 对象中的数据导入到新 Tensor 中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从列表创建张量</span></span><br><span class="line">tf.convert_to_tensor([<span class="number">1</span>,<span class="number">2.</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=44, shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从数组中创建张量</span></span><br><span class="line">tf.convert_to_tensor(np.array([[<span class="number">1</span>,<span class="number">2.</span>],[<span class="number">3</span>,<span class="number">4</span>]])) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=45, shape=(2, 2), dtype=float64, numpy=array([[1., 2.],       [3., 4.]])&gt;</code></pre><h3 id="创建全0或全1张量"><a href="#创建全0或全1张量" class="headerlink" title="创建全0或全1张量"></a>创建全0或全1张量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建全 0，全 1 的标量</span></span><br><span class="line">tf.zeros([]),tf.ones([]) </span><br></pre></td></tr></table></figure><pre><code>(&lt;tf.Tensor: id=46, shape=(), dtype=float32, numpy=0.0&gt;, &lt;tf.Tensor: id=47, shape=(), dtype=float32, numpy=1.0&gt;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建全 0，全 1 的向量</span></span><br><span class="line">tf.zeros([<span class="number">1</span>]),tf.ones([<span class="number">1</span>]) </span><br></pre></td></tr></table></figure><pre><code>(&lt;tf.Tensor: id=50, shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)&gt;, &lt;tf.Tensor: id=53, shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)&gt;)</code></pre><p>创建全 0 的矩阵</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建全 0 矩阵，指定 shape 为 2 行 2 列</span></span><br><span class="line">tf.zeros([<span class="number">2</span>,<span class="number">2</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=56, shape=(2, 2), dtype=float32, numpy=array([[0., 0.],       [0., 0.]], dtype=float32)&gt;</code></pre><p>创建全 1 的矩阵</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建全 1 矩阵，指定 shape 为 3 行 2 列</span></span><br><span class="line">tf.ones([<span class="number">3</span>,<span class="number">2</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=59, shape=(3, 2), dtype=float32, numpy=array([[1., 1.],       [1., 1.],       [1., 1.]], dtype=float32)&gt;</code></pre><p>通过 tf.zeros_like, tf.ones_like 可以方便地新建与某个张量 shape 一致， 且内容为全 0 或全 1 的张量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个矩阵</span></span><br><span class="line">a = tf.ones([<span class="number">2</span>,<span class="number">3</span>]) </span><br><span class="line"><span class="comment"># 创建一个与 a 形状相同，但是全 0 的新矩阵</span></span><br><span class="line">tf.zeros_like(a) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=63, shape=(2, 3), dtype=float32, numpy=array([[0., 0., 0.],       [0., 0., 0.]], dtype=float32)&gt;</code></pre><p>创建与张量A形状一样的全 1 张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个矩阵</span></span><br><span class="line">a = tf.zeros([<span class="number">3</span>,<span class="number">2</span>]) </span><br><span class="line"><span class="comment"># 创建一个与 a 形状相同，但是全 1 的新矩阵</span></span><br><span class="line">tf.ones_like(a) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=69, shape=(3, 2), dtype=float32, numpy=array([[1., 1.],       [1., 1.],       [1., 1.]], dtype=float32)&gt;</code></pre><h3 id="创建自定义数值张量"><a href="#创建自定义数值张量" class="headerlink" title="创建自定义数值张量"></a>创建自定义数值张量</h3><p>通过 tf.fill(shape, value)可以创建全为自定义数值 value 的张量，形状由 shape 参数指定。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建-1 的标量</span></span><br><span class="line">tf.fill([], -<span class="number">1</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=72, shape=(), dtype=int32, numpy=-1&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建-1 的向量</span></span><br><span class="line">tf.fill([<span class="number">1</span>], -<span class="number">1</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=75, shape=(1,), dtype=int32, numpy=array([-1], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 2 行 2 列，元素全为 99 的矩阵</span></span><br><span class="line">tf.fill([<span class="number">2</span>,<span class="number">2</span>], <span class="number">99</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=78, shape=(2, 2), dtype=int32, numpy=array([[99, 99],       [99, 99]], dtype=int32)&gt;</code></pre><h3 id="创建已知分布的张量"><a href="#创建已知分布的张量" class="headerlink" title="创建已知分布的张量"></a>创建已知分布的张量</h3><p>通过 tf.random.normal(shape, mean=0.0, stddev=1.0)可以创建形状为 shape，均值为mean，标准差为 stddev 的正态分布$\mathcal{N}(mean, stddev^2)$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建标准正态分布的张量</span></span><br><span class="line">tf.random.normal([<span class="number">2</span>,<span class="number">2</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=84, shape=(2, 2), dtype=float32, numpy=array([[ 0.8372936 , -0.00487547],       [ 0.5917305 ,  0.9924748 ]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建均值为 1，标准差为 2 的正态分布的张量</span></span><br><span class="line">tf.random.normal([<span class="number">2</span>,<span class="number">2</span>], mean=<span class="number">1</span>,stddev=<span class="number">2</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=90, shape=(2, 2), dtype=float32, numpy=array([[1.6426632 , 0.9099915 ],       [1.7133203 , 0.14123482]], dtype=float32)&gt;</code></pre><p>通过 tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.float32)可以创建采样自[minval, maxval)区间的均匀分布的张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建采样自[0,1)均匀分布的矩阵</span></span><br><span class="line">tf.random.uniform([<span class="number">3</span>,<span class="number">2</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=97, shape=(3, 2), dtype=float32, numpy=array([[0.80524087, 0.5057876 ],       [0.5653434 , 0.21946168],       [0.48825264, 0.09415054]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建采样自[0,10)均匀分布的矩阵</span></span><br><span class="line">tf.random.uniform([<span class="number">2</span>,<span class="number">2</span>],maxval=<span class="number">10</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=104, shape=(2, 2), dtype=float32, numpy=array([[8.02882  , 9.814098 ],       [5.9886417, 1.3643861]], dtype=float32)&gt;</code></pre><p>如果需要均匀采样整形类型的数据，必须指定采样区间的最大值 maxval 参数，同时指定数据类型为 tf.int*型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建采样自[0,100)均匀分布的整型矩阵</span></span><br><span class="line">tf.random.uniform([<span class="number">2</span>,<span class="number">2</span>],maxval=<span class="number">100</span>,dtype=tf.int32)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=108, shape=(2, 2), dtype=int32, numpy=array([[ 5, 91],       [33, 20]], dtype=int32)&gt;</code></pre><h3 id="创建序列"><a href="#创建序列" class="headerlink" title="创建序列"></a>创建序列</h3><p>tf.range(limit, delta=1)可以创建[0, limit)之间，步长为 delta 的整型序列，不包含 limit 本身。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0~10，不包含 10</span></span><br><span class="line">tf.<span class="built_in">range</span>(<span class="number">10</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=112, shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 0~10，步长为 2 的整形序列</span></span><br><span class="line">tf.<span class="built_in">range</span>(<span class="number">10</span>,delta=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=116, shape=(5,), dtype=int32, numpy=array([0, 2, 4, 6, 8], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>,delta=<span class="number">2</span>) <span class="comment"># 1~10</span></span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=120, shape=(5,), dtype=int32, numpy=array([1, 3, 5, 7, 9], dtype=int32)&gt;</code></pre><h2 id="张量的典型应用"><a href="#张量的典型应用" class="headerlink" title="张量的典型应用"></a>张量的典型应用</h2><h3 id="标量"><a href="#标量" class="headerlink" title="标量"></a>标量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机模拟网络输出</span></span><br><span class="line">out = tf.random.uniform([<span class="number">4</span>,<span class="number">10</span>]) </span><br><span class="line"><span class="comment"># 随机构造样本真实标签</span></span><br><span class="line">y = tf.constant([<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>]) </span><br><span class="line"><span class="comment"># one-hot 编码</span></span><br><span class="line">y = tf.one_hot(y, depth=<span class="number">10</span>) </span><br><span class="line"><span class="comment"># 计算每个样本的 MSE</span></span><br><span class="line">loss = tf.keras.losses.mse(y, out) </span><br><span class="line"><span class="comment"># 平均 MSE,loss 应是标量</span></span><br><span class="line">loss = tf.reduce_mean(loss) </span><br><span class="line"><span class="built_in">print</span>(loss)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor(0.26203847, shape=(), dtype=float32)</code></pre><ul><li>tf.reduce_mean()函数用于计算张量tensor沿着指定的数轴（tensor的某一维度）上的的平均值，主要用作降维或者计算tensor（图像）的平均值。</li></ul><h3 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h3><p>考虑 2 个输出节点的网络层， 我们创建长度为 2 的偏置向量b，并累加在每个输出节点上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># z=wx,模拟获得激活函数的输入 z</span></span><br><span class="line">z = tf.random.normal([<span class="number">4</span>,<span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(z)</span><br><span class="line"><span class="comment"># 创建偏置向量</span></span><br><span class="line">b = tf.zeros([<span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># 累加上偏置向量</span></span><br><span class="line">z = z + b </span><br><span class="line">z</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([[ 0.8107377   1.2481661 ] [-0.9203342  -0.55204725] [ 0.944986    0.00977302] [ 0.65324616  0.9092525 ]], shape=(4, 2), dtype=float32)tf.Tensor([0. 0.], shape=(2,), dtype=float32)&lt;tf.Tensor: id=432714, shape=(4, 2), dtype=float32, numpy=array([[ 0.8107377 ,  1.2481661 ],       [-0.9203342 , -0.55204725],       [ 0.944986  ,  0.00977302],       [ 0.65324616,  0.9092525 ]], dtype=float32)&gt;</code></pre><p>创建输入节点数为 4，输出节点数为 3 的线性层网络，那么它的偏置向量 b 的长度应为 3</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一层 Wx+b，输出节点为 3</span></span><br><span class="line">fc = tf.keras.layers.Dense(<span class="number">3</span>) </span><br><span class="line"><span class="comment"># 通过 build 函数创建 W,b 张量，输入节点为 4</span></span><br><span class="line">fc.build(input_shape=(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line"><span class="comment"># 查看偏置向量</span></span><br><span class="line">fc.bias </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Variable &#39;bias:0&#39; shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)&gt;</code></pre><h3 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2 个样本，特征长度为 4 的张量</span></span><br><span class="line">x = tf.random.normal([<span class="number">2</span>,<span class="number">4</span>]) </span><br><span class="line"><span class="comment"># 定义 W 张量</span></span><br><span class="line">w = tf.ones([<span class="number">4</span>,<span class="number">3</span>])</span><br><span class="line"><span class="comment"># 定义 b 张量</span></span><br><span class="line">b = tf.zeros([<span class="number">3</span>]) </span><br><span class="line"><span class="comment"># X@W+b 运算</span></span><br><span class="line">o = x@w+b </span><br><span class="line">o</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=184, shape=(2, 3), dtype=float32, numpy=array([[-5.028141  , -5.028141  , -5.028141  ],       [ 0.67261326,  0.67261326,  0.67261326]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义全连接层的输出节点为 3</span></span><br><span class="line">fc = tf.keras.layers.Dense(<span class="number">3</span>) </span><br><span class="line"><span class="comment"># 定义全连接层的输入节点为 4</span></span><br><span class="line">fc.build(input_shape=(<span class="number">2</span>,<span class="number">4</span>)) </span><br><span class="line"><span class="comment"># 查看权值矩阵 W</span></span><br><span class="line">fc.kernel </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Variable &#39;kernel:0&#39; shape=(4, 3) dtype=float32, numpy=array([[ 0.5571135 ,  0.40619254,  0.7768836 ],       [-0.61082566, -0.13341528, -0.90817606],       [-0.16371965, -0.00938004,  0.6606846 ],       [ 0.38958526, -0.87978166, -0.36103284]], dtype=float32)&gt;</code></pre><h3 id="三维张量"><a href="#三维张量" class="headerlink" title="三维张量"></a>三维张量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自动加载 IMDB 电影评价数据集</span></span><br><span class="line">(x_train,y_train),(x_test,y_test)=keras.datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># 将句子填充、截断为等长 80 个单词的句子</span></span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train,maxlen=<span class="number">80</span>)</span><br><span class="line"><span class="built_in">print</span>(x_train[<span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">x_train.shape</span><br></pre></td></tr></table></figure><pre><code>/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/datasets/imdb.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray.  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/datasets/imdb.py:130: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray.  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])[[  15  256    4    2    7 3766    5  723   36   71   43  530  476   26   400  317   46    7    4    2 1029   13  104   88    4  381   15  297    98   32 2071   56   26  141    6  194 7486   18    4  226   22   21   134  476   26  480    5  144   30 5535   18   51   36   28  224   92    25  104    4  226   65   16   38 1334   88   12   16  283    5   16  4472  113  103   32   15   16 5345   19  178   32] [ 125   68    2 6853   15  349  165 4362   98    5    4  228    9   43     2 1157   15  299  120    5  120  174   11  220  175  136   50    9  4373  228 8255    5    2  656  245 2350    5    4 9837  131  152  491    18    2   32 7464 1212   14    9    6  371   78   22  625   64 1382     9    8  168  145   23    4 1690   15   16    4 1355    5   28    6    52  154  462   33   89   78  285   16  145   95]](25000, 80)</code></pre><p>可以看到 x_train 张量的 shape 为[25000,80]，其中 25000 表示句子个数， 80 表示每个句子共 80 个单词，每个单词使用数字编码方式表示。</p><p>我们通过 layers.Embedding 层将数字编码的单词转换为长度为 100 个词向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建词向量 Embedding 层类</span></span><br><span class="line">embedding = tf.keras.layers.Embedding(<span class="number">10000</span>, <span class="number">100</span>)</span><br><span class="line"><span class="comment"># 将数字编码的单词转换为词向量</span></span><br><span class="line">out = embedding(x_train)</span><br><span class="line">out.shape</span><br></pre></td></tr></table></figure><pre><code>TensorShape([25000, 80, 100])</code></pre><p>可以看到，经过 Embedding 层编码后，句子张量的 shape 变为[25000,80,100]，其中 100 表示每个单词编码为长度是 100 的向量。</p><h3 id="四维张量"><a href="#四维张量" class="headerlink" title="四维张量"></a>四维张量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 32x32 的彩色图片输入，个数为 4</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>])</span><br><span class="line"><span class="comment"># 创建卷积神经网络</span></span><br><span class="line">layer = layers.Conv2D(<span class="number">16</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 前向计算</span></span><br><span class="line">out = layer(x) </span><br><span class="line"><span class="comment"># 输出大小</span></span><br><span class="line">out.shape </span><br></pre></td></tr></table></figure><pre><code>TensorShape([4, 30, 30, 16])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 访问卷积核张量</span></span><br><span class="line">layer.kernel.shape </span><br></pre></td></tr></table></figure><pre><code>TensorShape([3, 3, 3, 16])</code></pre><h2 id="索引与切片"><a href="#索引与切片" class="headerlink" title="索引与切片"></a>索引与切片</h2><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建4维张量</span></span><br><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>]) </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取第 1 张图片的数据</span></span><br><span class="line">x[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=265, shape=(32, 32, 3), dtype=float32, numpy=array([[[ 2.2041936 , -1.9026781 ,  0.8702505 ],        [-1.2282028 , -0.33232537,  0.40958533],        [ 0.11558069, -0.95446974, -1.5603778 ],        ...,        [ 1.8689036 ,  1.3471965 ,  0.46157768],        [-0.04014067,  0.8095603 ,  1.0308311 ],        [-0.2001917 , -1.0876633 , -0.35982683]],       [[-0.6193978 , -1.1049955 , -0.06628878],        [ 0.5612249 ,  1.5542006 ,  0.6287516 ],        [ 0.34846973,  0.44159728,  0.8838649 ],        ...,        [-0.7220847 ,  0.67017406,  0.1659171 ],        [ 0.17958985, -0.65319884,  0.39171842],        [ 0.8067303 ,  0.43496   ,  0.2798552 ]],       [[-1.163977  , -0.06057478, -0.4857398 ],        [ 1.3414443 , -0.6038178 , -0.23302878],        [-2.0975337 ,  0.94285005, -0.27974698],        ...,        [-0.5631729 ,  1.0614241 , -0.3096405 ],        [-0.9624238 ,  1.3738877 , -1.8948269 ],        [ 1.132725  , -0.20089822, -1.7373965 ]],       ...,       [[-0.14071971, -0.5568062 ,  0.01075767],        [-1.7140628 ,  1.3289738 , -0.8903278 ],        [-1.0916421 , -0.3162519 , -1.249703  ],        ...,        [ 1.325685  ,  1.5440601 , -0.4913852 ],        [-1.3840119 ,  0.23958059, -0.20719068],        [ 0.877472  ,  1.3066201 , -1.4298698 ]],       [[ 0.3794225 ,  0.8216657 , -0.3639167 ],        [-1.4976484 , -1.0524081 , -1.302156  ],        [ 0.26988387,  0.34318095,  0.06246407],        ...,        [ 2.7228684 , -0.2831678 , -1.0059422 ],        [-0.7020755 , -1.4222299 ,  0.9356876 ],        [ 0.4152088 , -0.04397644, -0.73320246]],       [[ 0.65700305, -1.7467034 , -1.5898855 ],        [ 1.1514107 , -1.0907453 , -0.5877316 ],        [ 0.86260825, -0.59653807,  0.0976033 ],        ...,        [-0.04578071, -1.2980894 ,  0.9463795 ],        [-0.09251038,  0.25678882, -0.1819165 ],        [-0.36038232, -0.53460985,  1.2337509 ]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取第 1 张图片的第 2 行</span></span><br><span class="line">x[<span class="number">0</span>][<span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=273, shape=(32, 3), dtype=float32, numpy=array([[-0.6193978 , -1.1049955 , -0.06628878],       [ 0.5612249 ,  1.5542006 ,  0.6287516 ],       [ 0.34846973,  0.44159728,  0.8838649 ],       [-0.66014725, -0.29447266, -0.8719525 ],       [-0.53212637,  0.6360704 ,  0.02135803],       [ 0.40355667,  0.14078747, -0.39829007],       [-1.3842081 ,  0.04412093, -0.91313547],       [-0.37355164, -2.0390503 , -0.50824887],       [-0.7682212 ,  1.4448624 , -0.37302288],       [ 0.13697726,  0.57252467, -1.0642116 ],       [-0.17128809,  0.7596571 ,  0.37190843],       [-0.8967074 , -0.18937345, -0.5372808 ],       [ 0.33156198, -0.66581064, -0.21653776],       [-0.11285859, -2.4033732 ,  0.0636418 ],       [-0.31247538, -0.8419992 ,  0.4025044 ],       [ 1.2428769 ,  0.34773824,  0.8888833 ],       [-1.5594406 , -0.0539138 ,  0.7797568 ],       [-0.5584576 ,  0.44812298, -0.26227227],       [-0.4017965 , -1.6668578 , -2.0081973 ],       [ 1.7921695 ,  1.1685921 , -0.537693  ],       [-0.16341975, -0.42829806,  0.09798718],       [ 0.49063244, -0.19753823,  0.28310525],       [ 0.73069364,  0.33411032,  0.06241602],       [ 0.1417386 ,  0.46909812,  0.90380406],       [-0.32593566, -0.98549616,  0.36107165],       [ 1.5818663 , -0.362372  ,  1.0220544 ],       [ 0.26198712, -1.6119221 ,  0.07946812],       [ 1.1173558 , -0.677369  ,  0.9825754 ],       [ 1.2875233 ,  0.2511964 ,  0.9508616 ],       [-0.7220847 ,  0.67017406,  0.1659171 ],       [ 0.17958985, -0.65319884,  0.39171842],       [ 0.8067303 ,  0.43496   ,  0.2798552 ]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取第 1 张图片，第 2 行，第 3 列的数据</span></span><br><span class="line">x[<span class="number">0</span>][<span class="number">1</span>][<span class="number">2</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=285, shape=(3,), dtype=float32, numpy=array([0.34846973, 0.44159728, 0.8838649 ], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取第 3 张图片，第 2 行，第 1 列的像素， B 通道(第 2 个通道)颜色强度值</span></span><br><span class="line">x[<span class="number">2</span>][<span class="number">1</span>][<span class="number">0</span>][<span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=301, shape=(), dtype=float32, numpy=-0.39595583&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取第 2 张图片，第 10 行，第 3 列的数据</span></span><br><span class="line">x[<span class="number">1</span>,<span class="number">9</span>,<span class="number">2</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=305, shape=(3,), dtype=float32, numpy=array([ 0.58523804,  0.50835484, -0.7443932 ], dtype=float32)&gt;</code></pre><h3 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取第 2,3 张图片</span></span><br><span class="line">x[<span class="number">1</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=309, shape=(2, 32, 32, 3), dtype=float32, numpy=array([[[[-2.4223676 ,  0.2596306 , -0.5293948 ],         [-0.3967986 ,  0.6624346 ,  0.41745508],         [ 1.5329486 ,  0.30801037,  0.54265577],         ...,         [-1.2883576 , -0.4979994 , -0.5336313 ],         [ 1.9402784 , -0.6301418 ,  1.2783034 ],         [ 0.689839  ,  1.1910218 , -1.9886026 ]],        [[-0.14839938, -0.34305233,  0.30521095],         [ 0.4915458 ,  0.29830953, -0.6410243 ],         [-0.3882759 , -0.1322335 ,  1.2989053 ],         ...,         [ 0.52465385, -1.5790194 ,  1.9075392 ],         [-0.8763953 ,  0.33148092, -1.2615253 ],         [-2.1037416 , -1.7750245 , -0.8264196 ]],        [[ 0.42436486, -2.744681  ,  0.68191504],         [-0.62411004,  1.1706539 ,  0.187509  ],         [ 0.60655576, -1.426237  ,  0.24151424],         ...,         [-1.3997802 ,  0.7346194 , -0.8587046 ],         [-0.04108864,  2.2934608 ,  0.23547095],         [ 2.0110242 ,  0.73926306,  0.20124955]],        ...,        [[ 1.0731583 , -0.3252651 ,  0.75498104],         [ 1.177519  , -0.5143665 , -0.90076303],         [ 0.47401938, -0.43510988, -0.01301517],         ...,         [-1.0437206 , -0.66972613, -0.97535443],         [-0.6570767 , -0.00988437,  0.32322738],         [-0.4847873 ,  0.40703028,  0.06685828]],        [[-1.5480559 ,  0.48287508, -1.4049336 ],         [-0.13378212,  0.5845828 , -0.05725988],         [ 2.9124444 , -1.2632277 ,  1.6553665 ],         ...,         [ 0.9075061 ,  1.5838726 ,  0.01311778],         [-1.538471  , -0.48859388, -0.18985108],         [ 0.7335186 , -0.23191583, -0.6732001 ]],        [[ 0.45795447, -1.0244572 ,  2.6291482 ],         [-0.11982027, -0.66913885,  0.39017648],         [-0.46456242, -1.7838262 ,  1.0729996 ],         ...,         [ 1.6933389 ,  1.4940627 ,  0.14956625],         [-1.2214607 , -0.03956367,  0.54512376],         [ 0.65640074,  1.2754624 , -1.4749504 ]]],</code></pre><p>​<br>           [[[-0.90663576,  0.15839997,  0.32161254],<br>             [-0.9101076 , -0.1349041 ,  0.95145386],<br>             [ 0.378604  , -1.4983795 , -0.48038518],<br>             …,<br>             [ 0.8427316 ,  1.3538293 , -0.21184391],<br>             [-0.30419785, -2.1156309 ,  0.59961736],<br>             [-1.1520345 ,  0.7595469 ,  0.30996034]],</p><pre><code>        [[-1.1446227 , -0.39595583,  0.05506114],         [ 1.1072568 , -0.14321956, -0.83200383],         [-0.12360169, -2.973433  , -0.9375662 ],         ...,         [-0.93852717,  0.16133627,  0.45352787],         [-0.66656876,  0.12624261, -0.7791581 ],         [ 2.5405667 ,  0.7748032 , -2.2527237 ]],        [[ 0.01577527,  1.0519909 , -1.3275864 ],         [ 0.83748966,  1.8404965 , -0.30619964],         [ 1.6023983 , -1.5017103 , -0.30663648],         ...,         [-0.8523438 , -0.3250353 ,  0.9320171 ],         [ 0.32578966, -0.22678792, -0.13579275],         [ 1.7109146 , -1.1671449 ,  0.06491743]],        ...,        [[ 0.44134948,  0.5566953 , -0.47516817],         [-1.2281955 , -0.27368283,  1.4019957 ],         [-0.7539954 , -0.2248977 , -1.0345727 ],         ...,         [-1.0997441 , -0.5867889 ,  0.24920598],         [-1.1366905 , -0.33894378,  1.2943493 ],         [ 0.866115  ,  0.09259874,  0.5898721 ]],        [[-1.042004  , -0.42821613,  0.2879594 ],         [-0.8600638 , -0.4365882 ,  0.82840854],         [ 0.76567596, -0.46973774, -1.0789526 ],         ...,         [-0.19796038,  0.558751  , -0.75277686],         [-0.60283434, -1.0192461 , -0.12388539],         [-0.5070267 ,  0.08337619, -1.4103692 ]],        [[ 0.9950036 , -1.3551532 ,  0.5169268 ],         [ 0.59422225, -0.87916857,  0.7648795 ],         [ 0.32365948, -1.6526997 , -1.1206408 ],         ...,         [ 0.05121538,  1.2883476 , -0.6445231 ],         [ 0.86587644,  0.9763926 , -0.08709614],         [ 1.4661231 , -1.8772072 ,  0.2751547 ]]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取第一张图片</span></span><br><span class="line">x[<span class="number">0</span>,::] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=313, shape=(32, 32, 3), dtype=float32, numpy=array([[[ 2.2041936 , -1.9026781 ,  0.8702505 ],        [-1.2282028 , -0.33232537,  0.40958533],        [ 0.11558069, -0.95446974, -1.5603778 ],        ...,        [ 1.8689036 ,  1.3471965 ,  0.46157768],        [-0.04014067,  0.8095603 ,  1.0308311 ],        [-0.2001917 , -1.0876633 , -0.35982683]],       [[-0.6193978 , -1.1049955 , -0.06628878],        [ 0.5612249 ,  1.5542006 ,  0.6287516 ],        [ 0.34846973,  0.44159728,  0.8838649 ],        ...,        [-0.7220847 ,  0.67017406,  0.1659171 ],        [ 0.17958985, -0.65319884,  0.39171842],        [ 0.8067303 ,  0.43496   ,  0.2798552 ]],       [[-1.163977  , -0.06057478, -0.4857398 ],        [ 1.3414443 , -0.6038178 , -0.23302878],        [-2.0975337 ,  0.94285005, -0.27974698],        ...,        [-0.5631729 ,  1.0614241 , -0.3096405 ],        [-0.9624238 ,  1.3738877 , -1.8948269 ],        [ 1.132725  , -0.20089822, -1.7373965 ]],       ...,       [[-0.14071971, -0.5568062 ,  0.01075767],        [-1.7140628 ,  1.3289738 , -0.8903278 ],        [-1.0916421 , -0.3162519 , -1.249703  ],        ...,        [ 1.325685  ,  1.5440601 , -0.4913852 ],        [-1.3840119 ,  0.23958059, -0.20719068],        [ 0.877472  ,  1.3066201 , -1.4298698 ]],       [[ 0.3794225 ,  0.8216657 , -0.3639167 ],        [-1.4976484 , -1.0524081 , -1.302156  ],        [ 0.26988387,  0.34318095,  0.06246407],        ...,        [ 2.7228684 , -0.2831678 , -1.0059422 ],        [-0.7020755 , -1.4222299 ,  0.9356876 ],        [ 0.4152088 , -0.04397644, -0.73320246]],       [[ 0.65700305, -1.7467034 , -1.5898855 ],        [ 1.1514107 , -1.0907453 , -0.5877316 ],        [ 0.86260825, -0.59653807,  0.0976033 ],        ...,        [-0.04578071, -1.2980894 ,  0.9463795 ],        [-0.09251038,  0.25678882, -0.1819165 ],        [-0.36038232, -0.53460985,  1.2337509 ]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[:,<span class="number">0</span>:<span class="number">28</span>:<span class="number">2</span>,<span class="number">0</span>:<span class="number">28</span>:<span class="number">2</span>,:]</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=317, shape=(4, 14, 14, 3), dtype=float32, numpy=array([[[[ 2.2041936 , -1.9026781 ,  0.8702505 ],         [ 0.11558069, -0.95446974, -1.5603778 ],         [-0.10582599,  0.4360513 ,  0.37447408],         ...,         [-0.04653996,  1.6447414 ,  0.5684349 ],         [ 0.9232003 , -0.30295762, -0.33417934],         [-1.0266304 , -1.0249001 , -0.05951962]],        [[-1.163977  , -0.06057478, -0.4857398 ],         [-2.0975337 ,  0.94285005, -0.27974698],         [ 0.8568684 , -2.3641932 , -2.787721  ],         ...,         [-0.02272389,  0.7538776 ,  0.05307977],         [ 1.3103249 , -2.8305936 , -0.02025553],         [ 0.72770905, -0.2757186 , -1.2772908 ]],        [[-0.48045605,  0.7057281 ,  0.767962  ],         [ 1.4860299 , -1.2072684 , -2.6429942 ],         [-2.1154718 , -0.4968008 ,  0.40296978],         ...,         [ 0.6735097 , -0.37706473,  0.30742761],         [ 1.5466257 ,  0.01344285,  0.4478075 ],         [ 0.52647936,  0.3019742 , -0.04138045]],        ...,        [[ 0.06652974, -1.310362  ,  0.52491206],         [ 0.20300347,  0.4878598 ,  1.1967695 ],         [ 0.26188427, -1.1881219 , -0.8308305 ],         ...,         [-0.9027409 ,  0.49990463, -0.31936365],         [ 0.14605626,  1.6312102 ,  0.5990152 ],         [-0.22002122,  1.550344  ,  0.8017888 ]],        [[-1.8214884 ,  0.18888037, -0.7315172 ],         [ 1.1054498 ,  0.02177003, -0.80032647],         [ 0.832248  ,  0.30545396, -0.00517098],         ...,         [-0.8079335 , -1.0006244 ,  1.7094636 ],         [ 0.3665858 ,  0.12043276,  1.5349431 ],         [ 1.451506  ,  1.7146869 ,  1.1798096 ]],        [[-0.02927143, -0.662752  ,  1.7197117 ],         [-0.07830945,  0.19495389,  1.0558871 ],         [ 0.09200678, -2.0492928 , -1.149692  ],         ...,         [ 0.84948075, -0.7274614 , -0.6107158 ],         [-1.04149   , -0.8495479 ,  0.4960098 ],         [-0.00758181,  1.1287268 , -1.1791425 ]]],</code></pre><p>​<br>           [[[-2.4223676 ,  0.2596306 , -0.5293948 ],<br>             [ 1.5329486 ,  0.30801037,  0.54265577],<br>             [-0.25038302, -1.505699  ,  0.22218615],<br>             …,<br>             [ 1.8112099 , -0.4017005 ,  0.316382  ],<br>             [-0.18795913,  0.21327318,  0.13639478],<br>             [ 0.88907754, -1.068848  ,  0.49985337]],</p><pre><code>        [[ 0.42436486, -2.744681  ,  0.68191504],         [ 0.60655576, -1.426237  ,  0.24151424],         [ 0.83602005,  0.02829585, -0.19792575],         ...,         [-0.4921264 ,  0.47025818, -0.20402747],         [-0.19556889,  0.71231675, -1.1210784 ],         [-0.50484693,  0.29336897,  0.0850678 ]],        [[-0.3722062 ,  0.18532671,  1.7206814 ],         [-0.85221314,  0.557481  ,  1.8532947 ],         [-0.05675818, -0.56605554, -0.846615  ],         ...,         [ 0.0248818 , -1.263318  ,  1.0077718 ],         [ 1.1570826 ,  0.1613118 ,  0.20786911],         [-1.0473794 ,  1.0830846 ,  1.0416656 ]],        ...,        [[ 0.0331895 ,  1.7457578 , -0.35708535],         [ 1.0369142 , -0.62837493, -0.5342489 ],         [ 0.7757275 ,  0.535828  , -2.2308693 ],         ...,         [-0.9503758 , -1.3476964 ,  0.17882505],         [-0.25491032, -0.85506326, -2.003958  ],         [ 0.92684764, -0.4062368 , -1.5470201 ]],        [[-0.9265145 , -1.143782  , -0.9362721 ],         [ 0.9630645 ,  0.65629876,  1.1364145 ],         [ 2.0485058 , -0.6168327 ,  0.16756117],         ...,         [ 1.1698273 ,  2.6709888 , -0.45540768],         [-0.3581334 ,  1.1361488 ,  1.4096297 ],         [-0.03351761, -0.9961699 ,  0.81231606]],        [[ 0.26294824, -0.0122492 , -1.2524768 ],         [ 0.19943246,  0.7689961 ,  0.2076496 ],         [ 0.22466388,  0.8513927 , -0.12332796],         ...,         [ 0.13668203, -0.14629023, -0.49706447],         [ 1.6254246 ,  1.1169688 ,  0.69922197],         [ 0.38690066,  1.3984909 , -0.7125247 ]]],</code></pre><p>​<br>           [[[-0.90663576,  0.15839997,  0.32161254],<br>             [ 0.378604  , -1.4983795 , -0.48038518],<br>             [-0.0130377 , -0.6399751 ,  0.7394333 ],<br>             …,<br>             [-0.6753409 ,  0.01053149, -1.4270033 ],<br>             [ 1.1157323 , -0.5980183 ,  0.49497938],<br>             [ 1.4786468 , -0.4598702 , -0.08252096]],</p><pre><code>        [[ 0.01577527,  1.0519909 , -1.3275864 ],         [ 1.6023983 , -1.5017103 , -0.30663648],         [ 1.065943  ,  1.1778338 , -0.5005816 ],         ...,         [-1.4590057 ,  0.95748615,  1.4595517 ],         [ 0.9277145 ,  0.87606174,  0.69505954],         [-1.105703  , -0.0888804 , -0.15580973]],        [[-0.08234025,  1.0907137 , -2.2424757 ],         [-1.2051404 , -0.03379055,  0.74277437],         [ 0.24598132, -0.5550462 ,  0.8092795 ],         ...,         [-2.91178   ,  0.20674153,  0.40773728],         [-0.28130236, -1.4947956 ,  0.0447046 ],         [-1.4446735 , -0.08543364, -1.2267051 ]],        ...,        [[ 0.12023102,  1.2192281 ,  1.8644665 ],         [ 0.71077096, -0.407154  , -0.3728209 ],         [-1.4906154 ,  1.4894596 ,  2.1380718 ],         ...,         [ 0.1265301 , -0.46740493,  0.03761578],         [-0.7213555 , -0.2611885 ,  2.1900265 ],         [-0.32233417, -0.7339213 ,  1.4348257 ]],        [[ 0.15944216,  1.0575757 , -0.32219157],         [ 1.0994414 ,  0.89874107, -0.74534416],         [ 0.55564195,  0.22377524,  0.79618496],         ...,         [-1.1586384 , -0.5727887 ,  0.0525245 ],         [ 1.1248014 , -0.3213812 , -0.6321217 ],         [ 1.1729585 ,  0.6997143 , -1.1535952 ]],        [[ 0.1488529 , -0.5701219 ,  0.6574311 ],         [ 0.7145128 , -0.57302225,  0.7365589 ],         [-1.3955393 ,  0.2823049 , -0.25600722],         ...,         [-1.3540319 ,  0.27442855, -0.48966768],         [ 2.1693397 , -0.41355062, -0.1416041 ],         [-0.6702472 , -0.21834244,  0.3533043 ]]],</code></pre><p>​<br>           [[[-1.2110972 , -0.9158722 ,  0.4041985 ],<br>             [-0.08361922,  0.46396288,  0.6809368 ],<br>             [-0.3673456 ,  0.902671  , -0.4238117 ],<br>             …,<br>             [-1.4638704 ,  0.10005575,  0.33722964],<br>             [-0.5335524 , -0.07159513, -0.98311245],<br>             [ 0.35258508, -0.7577552 ,  0.00567928]],</p><pre><code>        [[ 0.8245692 ,  1.0927265 , -0.5207532 ],         [-0.1369488 , -0.3078722 , -1.3035924 ],         [-0.45273212, -0.2587627 , -0.85130745],         ...,         [ 1.0517457 , -1.6728585 , -0.07226256],         [ 0.68702376,  1.2428858 ,  0.93717146],         [-1.006323  , -0.5241735 ,  0.77420044]],        [[-0.51503855, -0.1137079 ,  0.52393454],         [-1.1306531 , -0.38302454, -0.16332257],         [ 1.2486451 ,  0.33851364,  0.2546582 ],         ...,         [ 1.7983892 , -1.6029406 ,  0.42837998],         [-0.44229293, -1.100362  ,  0.43953687],         [ 0.0773904 ,  0.14096828, -0.69741434]],        ...,        [[-1.687785  ,  0.19534737,  0.84400016],         [ 1.4822593 ,  0.51837   , -0.5977481 ],         [ 0.72277683, -0.84718037, -1.4383492 ],         ...,         [ 0.09861249,  2.7846844 ,  0.06162486],         [ 0.9868257 ,  0.8325828 , -1.0587668 ],         [ 1.9446942 , -0.40730464,  0.8500739 ]],        [[-1.3877448 , -0.56070095,  0.57353336],         [ 0.23248737, -0.5203832 , -0.26604426],         [ 0.22834507, -0.02200814,  0.56439346],         ...,         [-0.8777562 , -0.42350784, -0.05138672],         [-0.67386514,  0.6522291 , -0.8428607 ],         [-0.1801546 , -0.2436022 , -0.32848358]],        [[ 0.15476868, -1.3199596 , -1.1284592 ],         [ 2.1280808 ,  0.68520063,  0.5801554 ],         [ 0.4836316 , -0.4967644 , -0.5746127 ],         ...,         [-1.9212904 ,  0.39191443, -2.5196192 ],         [-0.04232699, -0.31231558, -1.8565068 ],         [-1.2433186 , -1.3967386 , -3.036623  ]]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 考虑一个 0~9 的简单序列向量， 逆序取到第 1 号元素，不包含第 1 号</span></span><br><span class="line"><span class="comment"># 创建 0~9 向量</span></span><br><span class="line">x = tf.<span class="built_in">range</span>(<span class="number">9</span>) </span><br><span class="line"><span class="comment"># 从 8 取到 0，逆序，不包含 0</span></span><br><span class="line">x[<span class="number">8</span>:<span class="number">0</span>:-<span class="number">1</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=325, shape=(8,), dtype=int32, numpy=array([8, 7, 6, 5, 4, 3, 2, 1], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 逆序全部元素</span></span><br><span class="line">x[::-<span class="number">1</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=329, shape=(9,), dtype=int32, numpy=array([8, 7, 6, 5, 4, 3, 2, 1, 0], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 逆序间隔采样</span></span><br><span class="line">x[::-<span class="number">2</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=333, shape=(5,), dtype=int32, numpy=array([8, 6, 4, 2, 0], dtype=int32)&gt;</code></pre><p>读取每张图片的所有通道，其中行按着逆序隔行采样，列按着逆序隔行采样</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.normal([<span class="number">4</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>])</span><br><span class="line"><span class="comment"># 行、列逆序间隔采样</span></span><br><span class="line">x[<span class="number">0</span>,::-<span class="number">2</span>,::-<span class="number">2</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=343, shape=(16, 16, 3), dtype=float32, numpy=array([[[ 1.32819211e+00, -1.52891368e-01, -2.68408567e-01],        [-1.74235809e+00,  5.97050309e-01, -2.14324856e+00],        [-1.28296447e+00,  6.17663026e-01,  1.12792604e-01],        [-2.07204247e+00, -1.18166316e+00, -8.19493711e-01],        [-1.47719014e+00, -7.35922277e-01, -3.67488146e-01],        [-3.82268518e-01,  8.88675451e-03,  1.29524207e+00],        [-3.21091980e-01,  2.21426225e+00,  9.91399765e-01],        [ 2.05135364e-02,  1.74879110e+00, -2.37907872e-01],        [-2.91886926e-01, -9.75054145e-01, -8.84131372e-01],        [-1.99409172e-01, -9.77180898e-02, -6.13150775e-01],        [-2.09669054e-01, -3.75757724e-01,  9.72125709e-01],        [ 8.99972498e-01, -1.29678416e+00, -1.20591462e+00],        [-1.59504545e+00,  1.60751998e+00,  1.36306405e-01],        [-1.19246662e+00, -1.64794803e+00,  1.45283183e-02],        [ 4.74597424e-01, -1.27889240e+00,  4.06340212e-02],        [-1.79539633e+00, -9.81691927e-02, -6.85885489e-01]],       [[-1.05812716e+00, -1.30784822e+00, -6.80017769e-01],        [ 3.65186512e-01, -3.48650187e-01, -1.54725778e+00],        [ 1.51886746e-01, -2.09844962e-01,  1.39984548e+00],        [-5.62044561e-01, -1.41484439e+00, -4.25017208e-01],        [-6.71886727e-02,  1.13901690e-01,  1.71582669e-01],        [ 1.66557586e+00, -9.23811913e-01, -1.95637453e+00],        [-6.33425772e-01, -2.03683758e+00, -5.52891195e-01],        [ 4.30578351e-01,  4.01591599e-01,  7.07811356e-01],        [ 7.40033031e-01,  7.59029865e-01, -4.48047101e-01],        [-4.86449093e-01, -7.00091779e-01,  5.79828203e-01],        [ 1.56244147e+00, -7.40261674e-01, -7.41748929e-01],        [-3.04721802e-01,  3.59575897e-01,  9.25536156e-01],        [ 9.93468523e-01,  9.88783717e-01,  9.81922805e-01],        [ 1.08223462e+00,  7.46599495e-01,  5.29822886e-01],        [ 3.31095785e-01, -4.47714269e-01, -4.05531228e-01],        [ 1.60369647e+00, -5.92184007e-01,  2.54667439e-02]],       [[-4.86227632e-01, -1.10030425e+00,  9.10474122e-01],        [-9.61585999e-01, -1.19987130e+00,  4.75821495e-01],        [ 2.26800650e-01, -4.53597531e-02,  4.84708756e-01],        [ 9.83571932e-02, -5.63235462e-01, -7.65108049e-01],        [-4.45220917e-01,  1.46985579e+00, -3.55396181e-01],        [-6.69205308e-01, -9.33043242e-01, -9.96201992e-01],        [ 7.35680684e-02,  5.58141649e-01, -5.32615781e-01],        [ 6.23787344e-01,  6.98106110e-01,  5.59944332e-01],        [ 1.89795434e-01,  5.20511985e-01,  3.45360667e-01],        [-5.39386809e-01,  7.92361617e-01,  7.72233069e-01],        [-1.37562764e+00, -7.65306532e-01,  1.22537184e+00],        [-9.93735671e-01, -2.28927445e+00, -3.30761880e-01],        [ 3.47521663e-01,  1.81813228e+00,  1.49911916e+00],        [-5.90717047e-03, -3.43079537e-01, -6.15450263e-01],        [ 6.11240566e-01,  6.44246340e-01, -7.47387826e-01],        [-3.00381750e-01,  3.15724164e-01,  1.64138222e+00]],       [[ 1.14825201e+00,  1.13074481e+00, -4.92495179e-01],        [ 2.25241870e-01, -5.84089123e-02,  9.25830454e-02],        [-1.82172522e-01, -9.57806230e-01, -3.77334505e-01],        [ 3.15930390e+00, -5.52801453e-02,  1.61293708e-02],        [ 4.44656760e-01,  1.07683194e+00,  9.81891006e-02],        [-1.31772089e+00,  1.09420873e-01,  1.52856982e+00],        [-2.39866480e-01, -6.98523045e-01, -1.24893987e+00],        [ 1.29468739e+00,  3.06010634e-01, -5.18583715e-01],        [-4.67290908e-01,  2.67672628e-01,  7.30149746e-02],        [-1.74860966e+00,  9.92399633e-01, -7.79615223e-01],        [ 2.40579620e-01,  2.39096731e-01, -1.05543458e+00],        [-2.80319154e-01, -3.87402582e+00,  5.01442015e-01],        [ 8.12131941e-01,  5.19016683e-01, -9.54104364e-01],        [ 1.14224434e+00,  6.78500652e-01, -1.34504056e+00],        [ 3.85929286e-01,  9.36694257e-03, -5.74368834e-01],        [-3.63719165e-01,  2.71460544e-02,  2.09300327e+00]],       [[-2.35270150e-02, -2.96098262e-01,  8.58490467e-01],        [-1.98163879e+00, -8.91919672e-01, -4.12080497e-01],        [ 2.83049166e-01, -3.09135169e-01, -1.37894654e+00],        [ 9.72408593e-01, -3.07032514e+00,  6.41499221e-01],        [-5.71825683e-01,  1.70615464e-01,  2.49677584e-01],        [-2.03208899e+00, -4.59082909e-02, -1.12768102e+00],        [-5.74081719e-01,  1.36184072e+00, -1.35754287e+00],        [-7.02018738e-01, -1.22644699e+00,  1.23843646e+00],        [-1.86847806e+00, -7.55038798e-01, -1.55198109e+00],        [ 1.59925127e+00, -1.77682626e+00, -4.47454542e-01],        [-8.89484346e-01,  4.06048335e-02, -2.12907586e-02],        [ 1.55495811e+00, -9.46091533e-01, -1.12370884e+00],        [-6.63149476e-01, -1.48054332e-01, -8.66370499e-01],        [-9.72609699e-01,  8.09224486e-01, -1.08757228e-01],        [-1.84078431e+00, -1.07596278e+00, -8.74609530e-01],        [ 9.88747358e-01,  9.55015272e-02, -2.35948014e+00]],       [[ 1.40270567e+00,  1.50841713e-01, -5.54310754e-02],        [ 2.03900361e+00, -2.81785190e-01,  4.42986637e-02],        [ 1.21783614e+00, -1.34693730e+00, -1.44243157e+00],        [ 5.76931775e-01,  1.62811887e+00,  6.39955223e-01],        [-1.74793065e+00,  2.07304955e-01, -2.25865468e-01],        [-4.15330142e-01, -1.55576670e+00, -1.13930893e+00],        [ 1.11974978e+00, -1.79331243e-01, -9.33242738e-01],        [-5.40467203e-01, -8.10507298e-01,  7.65565455e-01],        [-1.25150323e-01,  2.45413408e-01, -8.35556448e-01],        [-6.55914128e-01, -5.80529928e-01, -1.20343566e-01],        [-2.26229757e-01, -1.95507139e-01, -1.70554236e-01],        [-3.00912589e-01, -4.94531870e-01,  1.16584015e+00],        [ 4.59960520e-01,  6.07771397e-01,  4.26176339e-02],        [ 7.55990624e-01, -1.91223100e-02, -3.85362864e-01],        [-1.14951158e+00,  6.91074133e-01,  1.67067599e+00],        [-3.21438015e-01, -7.53839314e-02, -9.35887218e-01]],       [[ 5.47035635e-01, -5.23284450e-02,  4.02895719e-01],        [ 1.32033587e-01, -4.70424891e-01,  1.16757905e+00],        [ 3.76113653e-01,  1.76386505e-01, -1.63666332e+00],        [ 6.88591599e-01, -2.48966232e-01,  1.59020257e+00],        [-4.79439110e-01,  1.28868616e+00,  2.21981835e+00],        [ 5.40017374e-02,  6.91947281e-01,  1.94959357e-01],        [-9.36701447e-02,  3.91052485e-01, -4.17478114e-01],        [-1.12415302e+00,  1.05244577e-01, -8.60867977e-01],        [-3.53260577e-01,  8.07365239e-01,  1.98053196e-01],        [ 1.44271660e+00, -4.19594377e-01, -1.77386373e-01],        [ 1.36769521e+00, -1.38748944e+00,  5.03023248e-03],        [-2.43702188e-01, -1.36886001e+00,  4.11833525e-01],        [ 3.02441150e-01, -4.80698109e-01, -1.39226437e+00],        [ 2.36330613e-01,  1.66690373e+00,  2.00038359e-01],        [-1.22779334e+00, -1.39988613e+00, -3.50548536e-01],        [ 2.32266456e-01, -7.95637667e-01,  1.97104156e+00]],       [[-5.69649875e-01, -2.46080613e+00, -9.10816312e-01],        [-1.53168082e-01,  2.16495895e+00, -1.27430940e+00],        [-1.75009024e+00,  5.70950091e-01, -9.35105205e-01],        [-2.02183932e-01, -7.59766936e-01,  2.29213595e-01],        [-1.39746463e+00,  2.65763164e-01, -4.06110078e-01],        [-1.84702861e+00, -6.93249941e-01,  9.25590456e-01],        [ 1.45949423e-01, -4.35498893e-01,  1.90595949e+00],        [-3.57079446e-01, -1.51399589e+00, -9.99029800e-02],        [-9.42782313e-02,  1.21779490e+00,  3.88828933e-01],        [ 2.00789642e+00,  1.02215707e-02,  3.21455784e-02],        [ 1.45261729e+00, -8.86097327e-02, -6.89221799e-01],        [-2.26393327e-01,  6.15001380e-01, -1.28379261e+00],        [-2.23580487e-02,  9.74746525e-01, -9.66164768e-01],        [ 3.50023448e-01,  1.82733262e+00, -2.53733128e-01],        [-1.11022592e+00, -1.86617315e+00, -2.11713147e+00],        [ 2.80960530e-01, -4.51435268e-01,  1.90480697e+00]],       [[-2.77264547e+00,  9.57480609e-01,  6.22376800e-01],        [ 9.52174425e-01, -4.27199155e-01,  1.14266515e+00],        [ 8.86744082e-01, -6.22356236e-01, -5.81559777e-01],        [ 5.89285254e-01, -6.01863384e-01,  1.73346370e-01],        [ 1.54971564e+00, -8.13169956e-01,  1.47795677e+00],        [-4.01796371e-01, -1.46614432e+00,  1.30820823e+00],        [-2.98423506e-02,  1.06418443e+00, -4.78232026e-01],        [ 1.82253325e+00, -3.88808012e-01,  1.80159080e+00],        [ 1.64312124e-01,  1.27614602e-01, -1.71271533e-01],        [-1.74178255e+00,  9.71022546e-01,  1.55694091e+00],        [ 2.64798254e-01, -1.31978318e-01, -1.27089739e-01],        [-2.90385246e-01, -2.81607056e+00, -2.51615524e-01],        [ 1.50572884e+00,  1.02218115e+00,  1.16663694e-01],        [ 3.35120916e-01, -8.72932673e-01, -6.25664711e-01],        [-3.21538270e-01, -7.99890280e-01, -6.18392229e-01],        [ 3.06067228e+00, -1.26156688e-01,  1.18348384e+00]],       [[-5.11001945e-01,  1.37932420e+00, -3.48675430e-01],        [ 2.76659799e+00, -4.34706032e-01,  1.66739762e-01],        [-1.10698283e-01, -7.76158631e-01,  1.86271176e-01],        [ 1.22287059e+00,  8.22692811e-01,  7.54150748e-01],        [ 4.93106544e-01,  6.56304955e-01,  1.21033490e+00],        [ 3.89292389e-01,  1.74910271e+00,  4.62190390e-01],        [ 2.27324545e-01,  5.73735595e-01, -2.48087004e-01],        [-3.79279375e-01,  3.78067166e-01,  1.46806073e+00],        [ 2.30334461e-01, -1.67860663e+00, -7.74816453e-01],        [ 6.61772549e-01,  9.88777637e-01, -2.18693733e+00],        [ 1.29639733e+00, -2.89914489e-01, -6.09108448e-01],        [-5.62642634e-01,  1.12929857e+00,  1.78704515e-01],        [ 1.59194541e+00,  4.59247902e-02,  3.04074079e-01],        [-9.05971676e-02,  2.23558825e-02,  6.90295696e-01],        [-1.76028121e+00,  1.30459869e+00,  1.10061681e+00],        [ 5.74148335e-02,  1.37532806e+00, -5.93708098e-01]],       [[-5.62136054e-01,  1.11537382e-01,  1.86342442e+00],        [-7.76148736e-01, -8.18978250e-01,  1.35009933e+00],        [-4.34110254e-01, -5.29790819e-01, -6.76819623e-01],        [ 8.09686065e-01,  1.00224167e-01, -1.14079773e+00],        [ 6.72304094e-01,  8.45222652e-01,  8.68369520e-01],        [ 1.88847947e+00,  6.60299420e-01, -1.01915455e+00],        [ 4.52204853e-01, -7.47173548e-01, -1.01478136e+00],        [ 6.49616838e-01, -3.51152241e-01, -3.22207630e-01],        [-1.56287539e+00, -8.39486599e-01,  4.92055297e-01],        [ 1.12434494e+00, -4.15864557e-01,  2.98760504e-01],        [-4.64543775e-02,  5.32227039e-01,  5.67610443e-01],        [-2.64979064e-01,  5.11899471e-01, -5.91439664e-01],        [-1.96026877e-01,  1.25646031e+00, -2.65661448e-01],        [ 1.50221694e+00, -6.95784390e-01, -4.32838410e-01],        [-9.25149560e-01,  1.55666733e+00,  7.89082229e-01],        [ 1.03696835e+00,  1.14898336e+00,  2.37887636e-01]],       [[ 4.73943323e-01,  4.90469962e-01, -6.27518237e-01],        [-1.11759044e-01,  1.31907976e+00, -1.92628849e+00],        [-6.40158474e-01,  1.16672480e+00, -5.82574248e-01],        [ 1.82465971e-01,  5.98510027e-01, -1.54943538e+00],        [ 1.23925221e+00,  1.85171413e+00, -4.11800183e-02],        [ 5.96398175e-01, -5.77813566e-01,  2.84586579e-01],        [-2.33158922e+00,  4.85183299e-01, -6.45461261e-01],        [-1.00312984e+00,  3.38520497e-01, -2.68755138e-01],        [ 3.27760369e-01, -6.05535984e-01,  5.60963929e-01],        [ 4.49014939e-02,  1.46062136e+00, -2.22097754e+00],        [ 1.37192681e-01,  2.33995080e-01,  1.73316765e+00],        [-1.01195645e+00, -1.36518753e+00, -2.85154253e-01],        [ 7.14541018e-01, -7.50025034e-01,  1.12300861e+00],        [-9.05730128e-01, -2.49278724e-01,  8.21055114e-01],        [ 1.36068606e+00,  1.04029274e+00, -4.62492704e-01],        [-8.05677921e-02,  2.65979171e-01,  2.23054901e-01]],       [[-1.24165677e-01, -9.52346399e-02,  4.24239188e-01],        [ 5.64876080e-01, -1.03957675e-01, -5.80752552e-01],        [-2.28657699e+00, -8.04197013e-01,  4.47991550e-01],        [-3.88402313e-01,  4.04412657e-01, -1.15122008e+00],        [-2.26028576e-01,  4.98672754e-01,  1.82685316e-01],        [-1.02170885e-01, -7.63889849e-01,  2.21727896e+00],        [-1.21248543e+00, -1.18503594e+00, -1.04385889e+00],        [-6.25540912e-01,  1.21357477e+00, -1.37694407e+00],        [-1.06482141e-01,  1.24098301e+00,  4.69377786e-01],        [ 5.69198370e-01,  1.34320125e-01,  2.64150798e-01],        [-8.89743328e-01,  7.29027569e-01, -3.96091849e-01],        [-5.38439631e-01,  7.89792895e-01, -2.41921830e+00],        [ 1.78635567e-01,  6.26172364e-01,  1.26544416e+00],        [ 9.92504656e-01,  8.01704347e-01, -1.41732895e+00],        [ 3.73012841e-01, -3.74639213e-01, -1.93168428e-02],        [ 6.25086367e-01, -1.16802764e+00, -1.35501802e-01]],       [[ 7.90464222e-01,  3.84943634e-01,  1.34319830e+00],        [-1.04067123e+00,  1.20278490e+00, -9.86785233e-01],        [-2.10872635e-01, -2.94924617e-01,  2.18456030e+00],        [-1.25211585e+00, -4.26412076e-01,  3.85715276e-01],        [ 4.80433226e-01, -2.17810750e+00,  1.72025964e-01],        [-1.36507463e+00, -5.88170290e-01, -1.12746871e+00],        [ 4.61366147e-01,  8.17801833e-01,  2.02035308e+00],        [-2.33708096e+00,  2.93909404e-02,  5.49295485e-01],        [ 5.44144630e-01,  8.78731012e-01,  5.76293409e-01],        [-3.52834463e-01, -2.13488245e+00, -9.02048647e-02],        [-2.68439913e+00, -7.18059778e-01,  1.58271170e+00],        [ 7.84022629e-01,  1.80395007e-01,  9.44528505e-02],        [ 1.11435282e+00, -7.96168029e-01, -9.54501331e-01],        [ 1.08020775e-01,  4.66115266e-01,  1.13831210e+00],        [ 1.40373373e+00, -6.06358469e-01, -6.87408030e-01],        [-5.19226313e-01,  6.26494050e-01,  7.20157683e-01]],       [[-1.53032497e-01, -2.31825694e-01,  2.38443211e-01],        [ 1.17578602e+00,  8.96336198e-01,  1.00056005e+00],        [-8.06149364e-01,  1.67887485e+00,  1.31185651e+00],        [-4.14346933e-01,  9.25169349e-01, -8.90269935e-01],        [ 4.75324124e-01,  6.48465008e-02, -1.17474127e+00],        [ 8.11189532e-01,  4.58558321e-01, -1.89462161e+00],        [-8.52047384e-01, -1.95253909e+00, -1.18440950e+00],        [ 5.65351129e-01,  3.13308030e-01,  1.34290731e+00],        [-8.23011279e-01,  4.34110940e-01, -1.57076240e-01],        [-7.66083777e-01,  1.53549409e+00, -6.54839098e-01],        [ 1.29202247e-01,  6.42492482e-03,  9.93899703e-02],        [ 2.33376041e-01, -8.38140726e-01,  9.34675157e-01],        [-9.31392252e-01, -1.87041914e+00, -6.32766664e-01],        [-3.24939862e-02, -6.08937442e-01,  4.31290448e-01],        [-9.14271355e-01,  8.74976039e-01,  7.50481248e-01],        [ 1.18830375e-01,  1.08729470e+00,  1.97146928e+00]],       [[-9.39358115e-01, -1.37552381e-01,  1.66079611e-01],        [ 1.00940740e+00, -5.13267696e-01,  1.12969530e+00],        [ 2.46125221e+00, -1.14048445e+00, -7.83394337e-01],        [-1.23253345e+00,  1.30130267e+00, -1.51509032e-01],        [ 1.01419091e+00,  2.42352739e-01,  7.56354570e-01],        [ 7.67537236e-01,  9.57925975e-01, -1.85001838e+00],        [ 1.54104221e+00,  9.20635283e-01,  3.35547149e-01],        [ 8.05710435e-01, -7.26651132e-01,  3.50032095e-03],        [-2.14763775e-01, -1.70537174e+00,  9.35129881e-01],        [-5.43601632e-01, -6.72167778e-01, -9.50358927e-01],        [-8.49173665e-01, -1.43499419e-01, -9.19315442e-02],        [ 5.55126607e-01, -7.18098879e-01,  1.32945049e+00],        [-1.82561159e-01,  2.36541009e+00,  4.69969809e-01],        [ 7.36051142e-01,  8.05300534e-01,  4.18028831e-01],        [ 1.13606131e+00, -9.57732141e-01,  1.11834717e+00],        [-4.51551750e-02, -1.14675157e-01, -2.38522816e+00]]],      dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取 G 通道数据</span></span><br><span class="line">x[:,:,:,<span class="number">1</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=347, shape=(4, 32, 32), dtype=float32, numpy=array([[[ 1.14909673e+00, -4.06459235e-02, -5.78127801e-01, ...,          1.55137196e-01,  7.60451019e-01,  9.85731423e-01],        [-1.13586128e+00, -1.14675157e-01,  1.63204148e-01, ...,         -5.13267696e-01, -1.18245673e+00, -1.37552381e-01],        [ 9.94689882e-01,  5.30135810e-01,  3.25026214e-01, ...,         -1.92351151e+00, -1.82740724e+00,  1.64374709e-01],        ...,        [-1.52717039e-01, -5.92184007e-01, -1.48266196e+00, ...,         -3.48650187e-01,  4.83299762e-01, -1.30784822e+00],        [-1.26717579e+00, -5.01342475e-01,  9.09223035e-02, ...,          2.43971795e-02,  5.13184786e-01,  6.98500574e-01],        [-8.86834741e-01, -9.81691927e-02,  7.17816591e-01, ...,          5.97050309e-01,  1.22520790e-01, -1.52891368e-01]],       [[ 5.27211905e-01,  5.10949850e-01,  6.68793380e-01, ...,          1.01723397e+00, -9.20990646e-01,  1.55521703e+00],        [ 5.97045481e-01, -1.12161386e+00,  1.01290178e+00, ...,         -1.12059198e-01,  1.63329244e+00,  9.03684914e-01],        [-3.70465130e-01,  1.35258186e+00,  1.91781148e-02, ...,          7.91784763e-01, -5.38403928e-01,  1.19437456e+00],        ...,        [-2.66319364e-02,  4.80187714e-01, -6.81482777e-02, ...,         -8.33781809e-02, -2.15396023e+00, -1.00828364e-01],        [-5.73343694e-01,  1.27166235e+00, -5.36300726e-02, ...,          6.65309191e-01,  1.02147615e+00,  7.86082864e-01],        [-6.50614142e-01,  8.00769866e-01, -3.60975653e-01, ...,          3.29060793e-01, -7.21324742e-01, -1.71777833e+00]],       [[-5.47546387e-01, -1.24894366e-01, -6.13053203e-01, ...,         -4.76122051e-01, -6.67316198e-01, -5.32188356e-01],        [ 7.25843370e-01,  1.25086391e+00,  6.61642969e-01, ...,         -1.11920547e+00,  8.22943971e-02,  8.71762872e-01],        [ 6.10169657e-02,  8.98746789e-01, -1.89981267e-01, ...,          1.32393092e-03,  7.66479552e-01,  4.74087834e-01],        ...,        [ 1.36904991e+00,  1.88162339e+00, -1.29588962e+00, ...,          2.02118421e+00,  2.84831226e-01, -8.29148889e-01],        [ 3.66007835e-01,  5.39520979e-01, -1.21468163e+00, ...,          1.26315391e+00, -1.57071245e+00,  3.33765388e-01],        [ 3.69738698e-01, -3.00485075e-01,  3.49693507e-01, ...,         -1.00170338e+00, -8.53059292e-01, -1.43128681e+00]],       [[ 9.08448339e-01, -7.05780163e-02, -5.45533061e-01, ...,          1.39675033e+00, -9.83740449e-01,  4.93973970e-01],        [-2.29770586e-01, -1.70520768e-01,  4.63991873e-02, ...,          1.25932079e-02,  2.69956380e-01, -2.21568316e-01],        [-1.71562707e+00, -2.53337473e-01,  1.14060119e-01, ...,          1.60762429e+00, -3.74208689e-01,  1.31152779e-01],        ...,        [ 6.35229349e-01, -3.34331602e-01, -2.70434052e-01, ...,         -4.81671304e-01, -1.03246319e+00,  1.72697484e+00],        [-3.85653168e-01, -3.87742639e-01, -7.38137007e-01, ...,         -4.67593260e-02,  8.60109150e-01,  4.53103155e-01],        [-3.68833989e-01,  6.17409274e-02,  2.55871916e+00, ...,         -7.19225705e-02, -1.25733685e+00,  6.05888307e-01]]],      dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取第 1~2 张图片的 G/B 通道数据</span></span><br><span class="line"><span class="comment"># 高宽维度全部采集</span></span><br><span class="line">x[<span class="number">0</span>:<span class="number">2</span>,...,<span class="number">1</span>:] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=351, shape=(2, 32, 32, 2), dtype=float32, numpy=array([[[[ 1.1490967 ,  1.7380066 ],         [-0.04064592,  0.48029   ],         [-0.5781278 , -1.291669  ],         ...,         [ 0.1551372 ,  0.8534301 ],         [ 0.760451  ,  0.587535  ],         [ 0.9857314 ,  0.1369431 ]],        [[-1.1358613 , -0.06066316],         [-0.11467516, -2.3852282 ],         [ 0.16320415,  0.01811434],         ...,         [-0.5132677 ,  1.1296953 ],         [-1.1824567 ,  0.7329599 ],         [-0.13755238,  0.16607961]],        [[ 0.9946899 ,  0.48675606],         [ 0.5301358 , -1.0126823 ],         [ 0.3250262 , -0.6064818 ],         ...,         [-1.9235115 , -0.41639256],         [-1.8274072 , -0.5375008 ],         [ 0.16437471, -0.4204572 ]],        ...,        [[-0.15271704,  0.02707502],         [-0.592184  ,  0.02546674],         [-1.482662  , -1.4665922 ],         ...,         [-0.3486502 , -1.5472578 ],         [ 0.48329976, -2.0207098 ],         [-1.3078482 , -0.68001777]],        [[-1.2671758 ,  0.03466341],         [-0.5013425 ,  0.1263919 ],         [ 0.0909223 ,  0.29931667],         ...,         [ 0.02439718,  0.5069986 ],         [ 0.5131848 , -0.6002897 ],         [ 0.6985006 , -1.3119441 ]],        [[-0.88683474, -0.14877406],         [-0.09816919, -0.6858855 ],         [ 0.7178166 ,  0.44352156],         ...,         [ 0.5970503 , -2.1432486 ],         [ 0.12252079, -0.15961307],         [-0.15289137, -0.26840857]]],</code></pre><p>​<br>           [[[ 0.5272119 ,  0.6869629 ],<br>             [ 0.51094985,  0.2770362 ],<br>             [ 0.6687934 , -1.4204    ],<br>             …,<br>             [ 1.017234  ,  0.35187325],<br>             [-0.92099065, -0.585941  ],<br>             [ 1.555217  , -0.6104895 ]],</p><pre><code>        [[ 0.5970455 ,  0.7830326 ],         [-1.1216139 ,  0.16928901],         [ 1.0129018 ,  0.71436375],         ...,         [-0.1120592 ,  0.37095946],         [ 1.6332924 ,  0.4852164 ],         [ 0.9036849 ,  0.84450924]],        [[-0.37046513, -0.4693162 ],         [ 1.3525819 , -0.66847706],         [ 0.01917811, -0.40561342],         ...,         [ 0.79178476,  1.6169451 ],         [-0.5384039 , -2.6904156 ],         [ 1.1943746 ,  0.15126795]],        ...,        [[-0.02663194, -0.42372993],         [ 0.4801877 , -1.6053843 ],         [-0.06814828,  0.39376357],         ...,         [-0.08337818, -0.56289715],         [-2.1539602 ,  0.7823069 ],         [-0.10082836,  0.64499325]],        [[-0.5733437 ,  0.8600085 ],         [ 1.2716624 ,  1.4874613 ],         [-0.05363007, -1.5294101 ],         ...,         [ 0.6653092 ,  0.31750998],         [ 1.0214761 ,  0.22179288],         [ 0.78608286, -1.4824792 ]],        [[-0.65061414, -0.6899978 ],         [ 0.80076987, -1.4741213 ],         [-0.36097565, -0.48046836],         ...,         [ 0.3290608 , -1.5610422 ],         [-0.72132474,  0.18023647],         [-1.7177783 , -0.53801376]]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取 R/G 通道数据</span></span><br><span class="line"><span class="comment"># 所有样本，所有高、宽的前 2 个通道</span></span><br><span class="line">x[...,:<span class="number">2</span>] </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=359, shape=(4, 32, 32, 2), dtype=float32, numpy=array([[[[-1.30701756e+00,  1.14909673e+00],         [ 3.61870110e-01, -4.06459235e-02],         [ 6.26487672e-01, -5.78127801e-01],         ...,         [ 1.38576820e-01,  1.55137196e-01],         [-1.29257798e+00,  7.60451019e-01],         [-3.25585663e-01,  9.85731423e-01]],        [[-2.72432625e-01, -1.13586128e+00],         [-4.51551750e-02, -1.14675157e-01],         [-4.10570800e-01,  1.63204148e-01],         ...,         [ 1.00940740e+00, -5.13267696e-01],         [-1.04479229e+00, -1.18245673e+00],         [-9.39358115e-01, -1.37552381e-01]],        [[-1.14408398e+00,  9.94689882e-01],         [-2.45610863e-01,  5.30135810e-01],         [ 3.69893968e-01,  3.25026214e-01],         ...,         [ 1.47702467e+00, -1.92351151e+00],         [-8.77718687e-01, -1.82740724e+00],         [-1.90951622e+00,  1.64374709e-01]],        ...,        [[-8.38505983e-01, -1.52717039e-01],         [ 1.60369647e+00, -5.92184007e-01],         [ 2.45542109e-01, -1.48266196e+00],         ...,         [ 3.65186512e-01, -3.48650187e-01],         [-6.50465429e-01,  4.83299762e-01],         [-1.05812716e+00, -1.30784822e+00]],        [[ 7.95438468e-01, -1.26717579e+00],         [ 9.37338114e-01, -5.01342475e-01],         [-1.69611961e-01,  9.09223035e-02],         ...,         [ 1.64364791e+00,  2.43971795e-02],         [ 1.96424723e-01,  5.13184786e-01],         [ 8.26264262e-01,  6.98500574e-01]],        [[ 2.59421289e-01, -8.86834741e-01],         [-1.79539633e+00, -9.81691927e-02],         [ 3.78742844e-01,  7.17816591e-01],         ...,         [-1.74235809e+00,  5.97050309e-01],         [ 6.53830469e-01,  1.22520790e-01],         [ 1.32819211e+00, -1.52891368e-01]]],</code></pre><p>​<br>           [[[-5.31493947e-02,  5.27211905e-01],<br>             [-8.06730747e-01,  5.10949850e-01],<br>             [ 1.84080076e+00,  6.68793380e-01],<br>             …,<br>             [ 1.31973469e+00,  1.01723397e+00],<br>             [ 4.49128337e-02, -9.20990646e-01],<br>             [-1.32044387e+00,  1.55521703e+00]],</p><pre><code>        [[ 7.68865108e-01,  5.97045481e-01],         [-7.52771422e-02, -1.12161386e+00],         [ 1.21640265e+00,  1.01290178e+00],         ...,         [ 1.01818316e-01, -1.12059198e-01],         [ 1.12015426e+00,  1.63329244e+00],         [ 1.95406660e-01,  9.03684914e-01]],        [[-3.43454480e-02, -3.70465130e-01],         [-3.47994983e-01,  1.35258186e+00],         [ 1.07138467e+00,  1.91781148e-02],         ...,         [ 9.40576553e-01,  7.91784763e-01],         [ 5.54417372e-01, -5.38403928e-01],         [-1.44541347e+00,  1.19437456e+00]],        ...,        [[ 1.11028528e+00, -2.66319364e-02],         [-1.03816831e+00,  4.80187714e-01],         [ 5.60190491e-02, -6.81482777e-02],         ...,         [ 4.46985304e-01, -8.33781809e-02],         [-1.76779434e-01, -2.15396023e+00],         [-1.36233258e+00, -1.00828364e-01]],        [[ 1.25010625e-01, -5.73343694e-01],         [ 4.23534930e-01,  1.27166235e+00],         [ 6.20880544e-01, -5.36300726e-02],         ...,         [-4.97313976e-01,  6.65309191e-01],         [-6.49542287e-02,  1.02147615e+00],         [ 1.87847123e-01,  7.86082864e-01]],        [[-8.89460385e-01, -6.50614142e-01],         [ 6.55708909e-01,  8.00769866e-01],         [ 1.00335670e+00, -3.60975653e-01],         ...,         [-7.29620278e-01,  3.29060793e-01],         [ 2.53696367e-02, -7.21324742e-01],         [-4.38493162e-01, -1.71777833e+00]]],</code></pre><p>​<br>           [[[-5.11693060e-01, -5.47546387e-01],<br>             [-2.56009412e+00, -1.24894366e-01],<br>             [-1.66868377e+00, -6.13053203e-01],<br>             …,<br>             [-3.40102255e-01, -4.76122051e-01],<br>             [-2.68808216e-01, -6.67316198e-01],<br>             [ 1.95494068e+00, -5.32188356e-01]],</p><pre><code>        [[-6.79937303e-01,  7.25843370e-01],         [ 7.51152635e-01,  1.25086391e+00],         [ 1.31343961e+00,  6.61642969e-01],         ...,         [ 3.19355845e-01, -1.11920547e+00],         [-4.93650079e-01,  8.22943971e-02],         [ 1.77995250e-01,  8.71762872e-01]],        [[ 5.79456747e-01,  6.10169657e-02],         [-3.90781134e-01,  8.98746789e-01],         [-1.64386973e-01, -1.89981267e-01],         ...,         [ 1.72087538e+00,  1.32393092e-03],         [-1.03725746e-01,  7.66479552e-01],         [ 8.60096216e-01,  4.74087834e-01]],        ...,        [[ 2.98859119e-01,  1.36904991e+00],         [-1.31470454e+00,  1.88162339e+00],         [ 3.38255256e-01, -1.29588962e+00],         ...,         [ 4.79147226e-01,  2.02118421e+00],         [ 3.93357724e-01,  2.84831226e-01],         [-1.07760859e+00, -8.29148889e-01]],        [[-7.26247966e-01,  3.66007835e-01],         [ 6.38583839e-01,  5.39520979e-01],         [ 2.58788407e-01, -1.21468163e+00],         ...,         [ 3.30879092e-01,  1.26315391e+00],         [-9.85577762e-01, -1.57071245e+00],         [ 1.34247553e+00,  3.33765388e-01]],        [[ 3.28157872e-01,  3.69738698e-01],         [-4.69663978e-01, -3.00485075e-01],         [ 8.08599889e-01,  3.49693507e-01],         ...,         [ 1.20650291e-01, -1.00170338e+00],         [-1.25450063e+00, -8.53059292e-01],         [-5.60456105e-02, -1.43128681e+00]]],</code></pre><p>​<br>           [[[ 6.02736592e-01,  9.08448339e-01],<br>             [ 1.45205522e+00, -7.05780163e-02],<br>             [ 1.12210441e+00, -5.45533061e-01],<br>             …,<br>             [-1.61648536e+00,  1.39675033e+00],<br>             [ 3.89932483e-01, -9.83740449e-01],<br>             [-3.43187571e-01,  4.93973970e-01]],</p><pre><code>        [[-4.33481991e-01, -2.29770586e-01],         [ 4.20535475e-01, -1.70520768e-01],         [ 1.40664136e+00,  4.63991873e-02],         ...,         [ 3.30364525e-01,  1.25932079e-02],         [-5.44138372e-01,  2.69956380e-01],         [ 5.51277101e-01, -2.21568316e-01]],        [[-2.39359438e-01, -1.71562707e+00],         [ 8.63479078e-02, -2.53337473e-01],         [-5.11896372e-01,  1.14060119e-01],         ...,         [-7.51873851e-01,  1.60762429e+00],         [-1.85268188e+00, -3.74208689e-01],         [-4.49496716e-01,  1.31152779e-01]],        ...,        [[-1.24805138e-01,  6.35229349e-01],         [ 1.62983191e+00, -3.34331602e-01],         [-3.98483366e-01, -2.70434052e-01],         ...,         [ 2.51731694e-01, -4.81671304e-01],         [ 1.65011346e+00, -1.03246319e+00],         [-1.56109953e+00,  1.72697484e+00]],        [[ 3.73855352e-01, -3.85653168e-01],         [-1.18297446e+00, -3.87742639e-01],         [-5.74579597e-01, -7.38137007e-01],         ...,         [ 5.06586790e-01, -4.67593260e-02],         [ 4.67046916e-01,  8.60109150e-01],         [-8.88322115e-01,  4.53103155e-01]],        [[-1.47322047e+00, -3.68833989e-01],         [ 3.80937368e-01,  6.17409274e-02],         [-1.07242978e+00,  2.55871916e+00],         ...,         [ 1.02848232e+00, -7.19225705e-02],         [-1.13464808e+00, -1.25733685e+00],         [-6.02429748e-01,  6.05888307e-01]]]], dtype=float32)&gt;</code></pre><h2 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h2><h3 id="改变视图"><a href="#改变视图" class="headerlink" title="改变视图"></a>改变视图</h3><p>我们通过 tf.range()模拟生成一个向量数据，并通过 tf.reshape 视图改变函数产生不同的视图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成向量</span></span><br><span class="line">x=tf.<span class="built_in">range</span>(<span class="number">96</span>)</span><br><span class="line"><span class="comment"># 改变 x 的视图，获得 4D 张量，存储并未改变</span></span><br><span class="line">x=tf.reshape(x,[<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">3</span>]) </span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=365, shape=(2, 4, 4, 3), dtype=int32, numpy=array([[[[ 0,  1,  2],         [ 3,  4,  5],         [ 6,  7,  8],         [ 9, 10, 11]],        [[12, 13, 14],         [15, 16, 17],         [18, 19, 20],         [21, 22, 23]],        [[24, 25, 26],         [27, 28, 29],         [30, 31, 32],         [33, 34, 35]],        [[36, 37, 38],         [39, 40, 41],         [42, 43, 44],         [45, 46, 47]]],</code></pre><p>​<br>           [[[48, 49, 50],<br>             [51, 52, 53],<br>             [54, 55, 56],<br>             [57, 58, 59]],</p><pre><code>        [[60, 61, 62],         [63, 64, 65],         [66, 67, 68],         [69, 70, 71]],        [[72, 73, 74],         [75, 76, 77],         [78, 79, 80],         [81, 82, 83]],        [[84, 85, 86],         [87, 88, 89],         [90, 91, 92],         [93, 94, 95]]]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取张量的维度数和形状列表</span></span><br><span class="line">x.ndim,x.shape </span><br></pre></td></tr></table></figure><pre><code>(4, TensorShape([2, 4, 4, 3]))</code></pre><p>通过 tf.reshape(x, new_shape)，可以将张量的视图任意地合法改变</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reshape(x,[<span class="number">2</span>,-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=373, shape=(2, 48), dtype=int32, numpy=array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],       [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,        64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,        80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]],      dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reshape(x,[<span class="number">2</span>,<span class="number">4</span>,<span class="number">12</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=375, shape=(2, 4, 12), dtype=int32, numpy=array([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]],       [[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59],        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71],        [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83],        [84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reshape(x,[<span class="number">2</span>,-<span class="number">1</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=377, shape=(2, 16, 3), dtype=int32, numpy=array([[[ 0,  1,  2],        [ 3,  4,  5],        [ 6,  7,  8],        [ 9, 10, 11],        [12, 13, 14],        [15, 16, 17],        [18, 19, 20],        [21, 22, 23],        [24, 25, 26],        [27, 28, 29],        [30, 31, 32],        [33, 34, 35],        [36, 37, 38],        [39, 40, 41],        [42, 43, 44],        [45, 46, 47]],       [[48, 49, 50],        [51, 52, 53],        [54, 55, 56],        [57, 58, 59],        [60, 61, 62],        [63, 64, 65],        [66, 67, 68],        [69, 70, 71],        [72, 73, 74],        [75, 76, 77],        [78, 79, 80],        [81, 82, 83],        [84, 85, 86],        [87, 88, 89],        [90, 91, 92],        [93, 94, 95]]], dtype=int32)&gt;</code></pre><h3 id="增、删维度"><a href="#增、删维度" class="headerlink" title="增、删维度"></a>增、删维度</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 产生矩阵</span></span><br><span class="line">x = tf.random.uniform([<span class="number">28</span>,<span class="number">28</span>],maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=381, shape=(28, 28), dtype=int32, numpy=array([[4, 1, 1, 5, 4, 1, 3, 5, 4, 0, 8, 8, 0, 1, 8, 6, 4, 9, 5, 1, 8, 0,        1, 3, 3, 5, 0, 4],       [5, 9, 2, 1, 8, 6, 3, 8, 6, 3, 6, 4, 7, 7, 5, 9, 2, 8, 4, 6, 6, 4,        9, 0, 5, 9, 9, 0],       [8, 0, 0, 1, 4, 2, 5, 8, 9, 3, 5, 7, 0, 1, 3, 6, 2, 0, 4, 7, 7, 5,        8, 2, 7, 8, 6, 0],       [9, 6, 4, 8, 5, 5, 7, 1, 2, 8, 6, 9, 5, 3, 3, 6, 5, 9, 4, 4, 1, 0,        5, 9, 3, 7, 1, 6],       [5, 8, 7, 4, 6, 5, 4, 5, 7, 5, 1, 3, 2, 2, 9, 0, 9, 5, 3, 3, 4, 9,        5, 1, 7, 0, 4, 6],       [9, 2, 6, 7, 5, 7, 9, 3, 1, 8, 2, 0, 0, 8, 2, 7, 2, 2, 1, 1, 7, 1,        9, 5, 2, 2, 6, 4],       [6, 4, 2, 2, 7, 2, 8, 0, 1, 5, 9, 5, 0, 8, 0, 3, 8, 6, 3, 7, 0, 5,        8, 1, 6, 1, 5, 4],       [3, 9, 2, 4, 1, 8, 1, 5, 7, 0, 0, 2, 9, 0, 5, 0, 5, 1, 7, 0, 5, 0,        1, 3, 2, 6, 3, 8],       [2, 9, 2, 6, 0, 4, 8, 7, 7, 4, 0, 3, 0, 9, 1, 6, 1, 8, 5, 2, 0, 6,        4, 0, 7, 5, 5, 9],       [4, 6, 8, 6, 5, 5, 8, 8, 2, 5, 1, 7, 0, 7, 7, 2, 3, 2, 5, 3, 3, 4,        4, 1, 2, 4, 7, 1],       [8, 3, 0, 5, 0, 4, 4, 0, 2, 1, 3, 0, 8, 8, 3, 0, 5, 8, 6, 4, 3, 2,        1, 4, 2, 4, 9, 5],       [4, 3, 1, 4, 7, 0, 4, 9, 3, 2, 5, 9, 2, 4, 1, 5, 5, 8, 0, 5, 0, 7,        0, 1, 0, 0, 2, 6],       [2, 4, 9, 9, 4, 2, 0, 0, 2, 5, 6, 0, 0, 9, 7, 3, 6, 2, 7, 3, 8, 8,        7, 2, 9, 9, 7, 3],       [2, 8, 8, 8, 5, 7, 7, 9, 1, 8, 6, 5, 4, 8, 4, 4, 4, 5, 6, 5, 8, 2,        5, 1, 1, 3, 5, 9],       [2, 3, 8, 5, 2, 1, 6, 9, 5, 9, 0, 5, 7, 5, 7, 8, 8, 0, 9, 9, 3, 0,        4, 3, 3, 3, 4, 5],       [9, 6, 3, 8, 8, 3, 6, 0, 3, 4, 1, 1, 2, 9, 8, 0, 5, 3, 0, 7, 0, 9,        2, 0, 8, 1, 1, 9],       [4, 8, 7, 0, 3, 6, 1, 7, 7, 9, 0, 1, 4, 6, 7, 0, 9, 5, 2, 2, 6, 5,        5, 0, 3, 1, 1, 7],       [9, 2, 4, 6, 0, 5, 8, 2, 2, 7, 7, 9, 1, 1, 9, 5, 5, 8, 0, 3, 8, 4,        2, 7, 0, 4, 2, 7],       [9, 2, 3, 7, 7, 6, 3, 7, 4, 6, 4, 8, 4, 9, 3, 3, 2, 4, 8, 4, 7, 6,        6, 2, 0, 7, 1, 9],       [6, 1, 2, 0, 2, 0, 0, 0, 5, 8, 7, 6, 9, 7, 9, 0, 6, 6, 6, 5, 3, 1,        3, 2, 3, 2, 3, 4],       [7, 4, 8, 9, 8, 3, 4, 0, 8, 0, 5, 2, 0, 3, 9, 8, 3, 8, 4, 2, 5, 3,        6, 1, 9, 8, 6, 5],       [6, 3, 1, 6, 4, 1, 8, 1, 6, 7, 2, 7, 1, 2, 8, 1, 4, 5, 0, 0, 4, 9,        9, 4, 6, 9, 7, 5],       [4, 0, 1, 1, 8, 7, 0, 8, 1, 2, 8, 6, 2, 1, 4, 6, 9, 2, 6, 9, 4, 0,        9, 0, 7, 9, 8, 4],       [2, 8, 3, 1, 9, 6, 1, 0, 0, 4, 5, 7, 1, 2, 3, 5, 9, 4, 7, 9, 5, 5,        8, 5, 0, 0, 5, 8],       [4, 6, 7, 6, 4, 1, 6, 8, 4, 2, 4, 5, 6, 1, 6, 6, 4, 2, 1, 1, 2, 6,        8, 3, 0, 0, 4, 0],       [6, 3, 3, 6, 8, 4, 6, 3, 6, 3, 8, 9, 7, 2, 2, 9, 0, 5, 7, 7, 2, 6,        3, 4, 6, 9, 4, 2],       [2, 7, 0, 8, 7, 0, 7, 8, 2, 2, 8, 3, 9, 6, 3, 0, 0, 5, 5, 7, 3, 9,        4, 7, 4, 4, 5, 0],       [3, 5, 7, 5, 4, 6, 8, 5, 9, 4, 7, 1, 6, 8, 0, 3, 1, 5, 2, 0, 3, 5,        9, 7, 6, 3, 3, 1]], dtype=int32)&gt;</code></pre><p>通过 tf.expand_dims(x, axis)可在指定的 axis 轴前可以插入一个新的维度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># axis=2 表示宽维度后面的一个维度</span></span><br><span class="line">x = tf.expand_dims(x,axis=<span class="number">2</span>) </span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=383, shape=(28, 28, 1), dtype=int32, numpy=array([[[4],        [1],        [1],        [5],        [4],        [1],        [3],        [5],        [4],        [0],        [8],        [8],        [0],        [1],        [8],        [6],        [4],        [9],        [5],        [1],        [8],        [0],        [1],        [3],        [3],        [5],        [0],        [4]],       [[5],        [9],        [2],        [1],        [8],        [6],        [3],        [8],        [6],        [3],        [6],        [4],        [7],        [7],        [5],        [9],        [2],        [8],        [4],        [6],        [6],        [4],        [9],        [0],        [5],        [9],        [9],        [0]],       [[8],        [0],        [0],        [1],        [4],        [2],        [5],        [8],        [9],        [3],        [5],        [7],        [0],        [1],        [3],        [6],        [2],        [0],        [4],        [7],        [7],        [5],        [8],        [2],        [7],        [8],        [6],        [0]],       [[9],        [6],        [4],        [8],        [5],        [5],        [7],        [1],        [2],        [8],        [6],        [9],        [5],        [3],        [3],        [6],        [5],        [9],        [4],        [4],        [1],        [0],        [5],        [9],        [3],        [7],        [1],        [6]],       [[5],        [8],        [7],        [4],        [6],        [5],        [4],        [5],        [7],        [5],        [1],        [3],        [2],        [2],        [9],        [0],        [9],        [5],        [3],        [3],        [4],        [9],        [5],        [1],        [7],        [0],        [4],        [6]],       [[9],        [2],        [6],        [7],        [5],        [7],        [9],        [3],        [1],        [8],        [2],        [0],        [0],        [8],        [2],        [7],        [2],        [2],        [1],        [1],        [7],        [1],        [9],        [5],        [2],        [2],        [6],        [4]],       [[6],        [4],        [2],        [2],        [7],        [2],        [8],        [0],        [1],        [5],        [9],        [5],        [0],        [8],        [0],        [3],        [8],        [6],        [3],        [7],        [0],        [5],        [8],        [1],        [6],        [1],        [5],        [4]],       [[3],        [9],        [2],        [4],        [1],        [8],        [1],        [5],        [7],        [0],        [0],        [2],        [9],        [0],        [5],        [0],        [5],        [1],        [7],        [0],        [5],        [0],        [1],        [3],        [2],        [6],        [3],        [8]],       [[2],        [9],        [2],        [6],        [0],        [4],        [8],        [7],        [7],        [4],        [0],        [3],        [0],        [9],        [1],        [6],        [1],        [8],        [5],        [2],        [0],        [6],        [4],        [0],        [7],        [5],        [5],        [9]],       [[4],        [6],        [8],        [6],        [5],        [5],        [8],        [8],        [2],        [5],        [1],        [7],        [0],        [7],        [7],        [2],        [3],        [2],        [5],        [3],        [3],        [4],        [4],        [1],        [2],        [4],        [7],        [1]],       [[8],        [3],        [0],        [5],        [0],        [4],        [4],        [0],        [2],        [1],        [3],        [0],        [8],        [8],        [3],        [0],        [5],        [8],        [6],        [4],        [3],        [2],        [1],        [4],        [2],        [4],        [9],        [5]],       [[4],        [3],        [1],        [4],        [7],        [0],        [4],        [9],        [3],        [2],        [5],        [9],        [2],        [4],        [1],        [5],        [5],        [8],        [0],        [5],        [0],        [7],        [0],        [1],        [0],        [0],        [2],        [6]],       [[2],        [4],        [9],        [9],        [4],        [2],        [0],        [0],        [2],        [5],        [6],        [0],        [0],        [9],        [7],        [3],        [6],        [2],        [7],        [3],        [8],        [8],        [7],        [2],        [9],        [9],        [7],        [3]],       [[2],        [8],        [8],        [8],        [5],        [7],        [7],        [9],        [1],        [8],        [6],        [5],        [4],        [8],        [4],        [4],        [4],        [5],        [6],        [5],        [8],        [2],        [5],        [1],        [1],        [3],        [5],        [9]],       [[2],        [3],        [8],        [5],        [2],        [1],        [6],        [9],        [5],        [9],        [0],        [5],        [7],        [5],        [7],        [8],        [8],        [0],        [9],        [9],        [3],        [0],        [4],        [3],        [3],        [3],        [4],        [5]],       [[9],        [6],        [3],        [8],        [8],        [3],        [6],        [0],        [3],        [4],        [1],        [1],        [2],        [9],        [8],        [0],        [5],        [3],        [0],        [7],        [0],        [9],        [2],        [0],        [8],        [1],        [1],        [9]],       [[4],        [8],        [7],        [0],        [3],        [6],        [1],        [7],        [7],        [9],        [0],        [1],        [4],        [6],        [7],        [0],        [9],        [5],        [2],        [2],        [6],        [5],        [5],        [0],        [3],        [1],        [1],        [7]],       [[9],        [2],        [4],        [6],        [0],        [5],        [8],        [2],        [2],        [7],        [7],        [9],        [1],        [1],        [9],        [5],        [5],        [8],        [0],        [3],        [8],        [4],        [2],        [7],        [0],        [4],        [2],        [7]],       [[9],        [2],        [3],        [7],        [7],        [6],        [3],        [7],        [4],        [6],        [4],        [8],        [4],        [9],        [3],        [3],        [2],        [4],        [8],        [4],        [7],        [6],        [6],        [2],        [0],        [7],        [1],        [9]],       [[6],        [1],        [2],        [0],        [2],        [0],        [0],        [0],        [5],        [8],        [7],        [6],        [9],        [7],        [9],        [0],        [6],        [6],        [6],        [5],        [3],        [1],        [3],        [2],        [3],        [2],        [3],        [4]],       [[7],        [4],        [8],        [9],        [8],        [3],        [4],        [0],        [8],        [0],        [5],        [2],        [0],        [3],        [9],        [8],        [3],        [8],        [4],        [2],        [5],        [3],        [6],        [1],        [9],        [8],        [6],        [5]],       [[6],        [3],        [1],        [6],        [4],        [1],        [8],        [1],        [6],        [7],        [2],        [7],        [1],        [2],        [8],        [1],        [4],        [5],        [0],        [0],        [4],        [9],        [9],        [4],        [6],        [9],        [7],        [5]],       [[4],        [0],        [1],        [1],        [8],        [7],        [0],        [8],        [1],        [2],        [8],        [6],        [2],        [1],        [4],        [6],        [9],        [2],        [6],        [9],        [4],        [0],        [9],        [0],        [7],        [9],        [8],        [4]],       [[2],        [8],        [3],        [1],        [9],        [6],        [1],        [0],        [0],        [4],        [5],        [7],        [1],        [2],        [3],        [5],        [9],        [4],        [7],        [9],        [5],        [5],        [8],        [5],        [0],        [0],        [5],        [8]],       [[4],        [6],        [7],        [6],        [4],        [1],        [6],        [8],        [4],        [2],        [4],        [5],        [6],        [1],        [6],        [6],        [4],        [2],        [1],        [1],        [2],        [6],        [8],        [3],        [0],        [0],        [4],        [0]],       [[6],        [3],        [3],        [6],        [8],        [4],        [6],        [3],        [6],        [3],        [8],        [9],        [7],        [2],        [2],        [9],        [0],        [5],        [7],        [7],        [2],        [6],        [3],        [4],        [6],        [9],        [4],        [2]],       [[2],        [7],        [0],        [8],        [7],        [0],        [7],        [8],        [2],        [2],        [8],        [3],        [9],        [6],        [3],        [0],        [0],        [5],        [5],        [7],        [3],        [9],        [4],        [7],        [4],        [4],        [5],        [0]],       [[3],        [5],        [7],        [5],        [4],        [6],        [8],        [5],        [9],        [4],        [7],        [1],        [6],        [8],        [0],        [3],        [1],        [5],        [2],        [0],        [3],        [5],        [9],        [7],        [6],        [3],        [3],        [1]]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 产生矩阵</span></span><br><span class="line">x = tf.random.uniform([<span class="number">28</span>,<span class="number">28</span>],maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432726, shape=(28, 28), dtype=int32, numpy=array([[5, 3, 3, 6, 9, 3, 0, 4, 1, 6, 3, 8, 7, 7, 5, 4, 0, 0, 8, 5, 2, 3,        6, 4, 4, 8, 8, 3],       [8, 4, 7, 9, 3, 6, 1, 7, 5, 9, 4, 9, 7, 4, 4, 8, 4, 9, 7, 9, 6, 1,        3, 5, 0, 2, 4, 2],       [3, 5, 5, 5, 7, 9, 5, 3, 6, 0, 7, 8, 0, 0, 4, 7, 8, 7, 4, 1, 9, 9,        2, 6, 6, 2, 0, 3],       [3, 5, 5, 2, 4, 0, 2, 5, 0, 2, 3, 2, 1, 0, 1, 4, 5, 3, 1, 9, 5, 3,        0, 5, 8, 1, 9, 4],       [6, 0, 1, 4, 0, 0, 7, 7, 0, 4, 3, 3, 3, 5, 2, 3, 5, 6, 4, 6, 4, 1,        3, 2, 8, 5, 8, 4],       [1, 2, 9, 3, 2, 3, 4, 4, 0, 0, 6, 6, 4, 0, 2, 7, 2, 2, 4, 2, 6, 0,        4, 0, 5, 5, 4, 5],       [3, 2, 6, 7, 7, 1, 0, 3, 3, 5, 5, 7, 8, 1, 6, 5, 5, 4, 3, 2, 9, 0,        0, 3, 7, 0, 0, 0],       [7, 7, 0, 7, 9, 8, 4, 5, 3, 7, 3, 3, 6, 1, 4, 8, 9, 2, 2, 8, 3, 1,        0, 9, 3, 3, 2, 4],       [9, 8, 8, 1, 4, 9, 3, 0, 5, 9, 6, 6, 8, 1, 4, 9, 8, 9, 8, 9, 3, 8,        7, 5, 8, 0, 3, 6],       [0, 8, 3, 1, 2, 1, 9, 4, 5, 0, 7, 1, 3, 5, 4, 4, 7, 3, 6, 5, 5, 6,        2, 0, 6, 1, 4, 8],       [4, 2, 6, 1, 7, 5, 6, 2, 4, 0, 9, 8, 0, 0, 0, 6, 8, 2, 3, 0, 0, 5,        6, 6, 9, 8, 4, 9],       [7, 3, 2, 5, 2, 5, 4, 3, 6, 4, 9, 2, 1, 7, 6, 4, 4, 5, 7, 7, 1, 6,        4, 0, 3, 6, 4, 8],       [1, 7, 6, 0, 4, 8, 0, 3, 0, 2, 0, 7, 0, 5, 6, 5, 3, 1, 4, 3, 8, 8,        8, 6, 7, 3, 1, 7],       [0, 8, 0, 5, 5, 2, 2, 5, 2, 1, 4, 4, 1, 4, 9, 4, 4, 1, 7, 1, 7, 7,        4, 1, 8, 2, 3, 2],       [5, 3, 5, 6, 6, 0, 9, 2, 9, 2, 8, 2, 1, 4, 0, 4, 7, 3, 0, 3, 8, 1,        5, 7, 5, 4, 6, 6],       [4, 7, 0, 1, 9, 6, 1, 1, 2, 1, 8, 2, 2, 9, 4, 7, 5, 1, 2, 4, 7, 5,        7, 6, 6, 4, 1, 5],       [4, 5, 7, 8, 2, 0, 5, 3, 4, 6, 3, 4, 5, 4, 9, 3, 6, 0, 2, 7, 1, 0,        1, 7, 2, 4, 4, 0],       [5, 3, 9, 1, 2, 4, 4, 8, 8, 2, 2, 1, 6, 4, 5, 2, 5, 0, 0, 1, 6, 4,        5, 9, 5, 8, 9, 5],       [6, 1, 1, 8, 9, 6, 8, 9, 9, 8, 2, 0, 9, 7, 9, 0, 9, 7, 0, 5, 3, 8,        0, 9, 1, 8, 9, 4],       [9, 1, 7, 3, 3, 7, 8, 3, 2, 2, 6, 3, 2, 1, 0, 5, 8, 2, 8, 4, 5, 5,        2, 9, 9, 6, 8, 3],       [0, 3, 8, 2, 5, 1, 6, 3, 5, 0, 2, 3, 9, 9, 4, 6, 1, 9, 3, 8, 7, 8,        8, 7, 2, 4, 4, 8],       [6, 7, 8, 6, 6, 6, 5, 2, 1, 8, 4, 7, 8, 9, 9, 4, 5, 2, 4, 7, 8, 5,        9, 3, 0, 0, 9, 1],       [7, 8, 4, 9, 4, 8, 9, 3, 5, 4, 8, 3, 7, 9, 2, 0, 2, 3, 8, 5, 6, 0,        4, 3, 6, 1, 6, 3],       [2, 4, 3, 9, 0, 2, 5, 9, 0, 0, 0, 3, 1, 2, 4, 3, 1, 4, 5, 7, 4, 3,        9, 6, 9, 3, 6, 6],       [3, 8, 6, 4, 0, 0, 3, 8, 1, 1, 5, 4, 8, 4, 8, 3, 3, 1, 1, 9, 6, 4,        9, 7, 6, 7, 3, 7],       [4, 3, 7, 5, 3, 4, 0, 4, 8, 2, 5, 1, 2, 8, 2, 6, 4, 7, 7, 6, 3, 5,        9, 6, 4, 2, 5, 9],       [4, 9, 2, 7, 8, 6, 1, 1, 9, 4, 1, 3, 1, 8, 6, 5, 3, 0, 2, 2, 3, 0,        3, 6, 9, 1, 2, 4],       [0, 7, 3, 6, 4, 2, 3, 7, 5, 0, 9, 5, 5, 2, 7, 5, 0, 3, 6, 8, 7, 3,        3, 6, 1, 2, 3, 6]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.expand_dims(x,axis=<span class="number">0</span>) <span class="comment"># 高维度之前插入新维度</span></span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432728, shape=(1, 28, 28), dtype=int32, numpy=array([[[5, 3, 3, 6, 9, 3, 0, 4, 1, 6, 3, 8, 7, 7, 5, 4, 0, 0, 8, 5, 2,         3, 6, 4, 4, 8, 8, 3],        [8, 4, 7, 9, 3, 6, 1, 7, 5, 9, 4, 9, 7, 4, 4, 8, 4, 9, 7, 9, 6,         1, 3, 5, 0, 2, 4, 2],        [3, 5, 5, 5, 7, 9, 5, 3, 6, 0, 7, 8, 0, 0, 4, 7, 8, 7, 4, 1, 9,         9, 2, 6, 6, 2, 0, 3],        [3, 5, 5, 2, 4, 0, 2, 5, 0, 2, 3, 2, 1, 0, 1, 4, 5, 3, 1, 9, 5,         3, 0, 5, 8, 1, 9, 4],        [6, 0, 1, 4, 0, 0, 7, 7, 0, 4, 3, 3, 3, 5, 2, 3, 5, 6, 4, 6, 4,         1, 3, 2, 8, 5, 8, 4],        [1, 2, 9, 3, 2, 3, 4, 4, 0, 0, 6, 6, 4, 0, 2, 7, 2, 2, 4, 2, 6,         0, 4, 0, 5, 5, 4, 5],        [3, 2, 6, 7, 7, 1, 0, 3, 3, 5, 5, 7, 8, 1, 6, 5, 5, 4, 3, 2, 9,         0, 0, 3, 7, 0, 0, 0],        [7, 7, 0, 7, 9, 8, 4, 5, 3, 7, 3, 3, 6, 1, 4, 8, 9, 2, 2, 8, 3,         1, 0, 9, 3, 3, 2, 4],        [9, 8, 8, 1, 4, 9, 3, 0, 5, 9, 6, 6, 8, 1, 4, 9, 8, 9, 8, 9, 3,         8, 7, 5, 8, 0, 3, 6],        [0, 8, 3, 1, 2, 1, 9, 4, 5, 0, 7, 1, 3, 5, 4, 4, 7, 3, 6, 5, 5,         6, 2, 0, 6, 1, 4, 8],        [4, 2, 6, 1, 7, 5, 6, 2, 4, 0, 9, 8, 0, 0, 0, 6, 8, 2, 3, 0, 0,         5, 6, 6, 9, 8, 4, 9],        [7, 3, 2, 5, 2, 5, 4, 3, 6, 4, 9, 2, 1, 7, 6, 4, 4, 5, 7, 7, 1,         6, 4, 0, 3, 6, 4, 8],        [1, 7, 6, 0, 4, 8, 0, 3, 0, 2, 0, 7, 0, 5, 6, 5, 3, 1, 4, 3, 8,         8, 8, 6, 7, 3, 1, 7],        [0, 8, 0, 5, 5, 2, 2, 5, 2, 1, 4, 4, 1, 4, 9, 4, 4, 1, 7, 1, 7,         7, 4, 1, 8, 2, 3, 2],        [5, 3, 5, 6, 6, 0, 9, 2, 9, 2, 8, 2, 1, 4, 0, 4, 7, 3, 0, 3, 8,         1, 5, 7, 5, 4, 6, 6],        [4, 7, 0, 1, 9, 6, 1, 1, 2, 1, 8, 2, 2, 9, 4, 7, 5, 1, 2, 4, 7,         5, 7, 6, 6, 4, 1, 5],        [4, 5, 7, 8, 2, 0, 5, 3, 4, 6, 3, 4, 5, 4, 9, 3, 6, 0, 2, 7, 1,         0, 1, 7, 2, 4, 4, 0],        [5, 3, 9, 1, 2, 4, 4, 8, 8, 2, 2, 1, 6, 4, 5, 2, 5, 0, 0, 1, 6,         4, 5, 9, 5, 8, 9, 5],        [6, 1, 1, 8, 9, 6, 8, 9, 9, 8, 2, 0, 9, 7, 9, 0, 9, 7, 0, 5, 3,         8, 0, 9, 1, 8, 9, 4],        [9, 1, 7, 3, 3, 7, 8, 3, 2, 2, 6, 3, 2, 1, 0, 5, 8, 2, 8, 4, 5,         5, 2, 9, 9, 6, 8, 3],        [0, 3, 8, 2, 5, 1, 6, 3, 5, 0, 2, 3, 9, 9, 4, 6, 1, 9, 3, 8, 7,         8, 8, 7, 2, 4, 4, 8],        [6, 7, 8, 6, 6, 6, 5, 2, 1, 8, 4, 7, 8, 9, 9, 4, 5, 2, 4, 7, 8,         5, 9, 3, 0, 0, 9, 1],        [7, 8, 4, 9, 4, 8, 9, 3, 5, 4, 8, 3, 7, 9, 2, 0, 2, 3, 8, 5, 6,         0, 4, 3, 6, 1, 6, 3],        [2, 4, 3, 9, 0, 2, 5, 9, 0, 0, 0, 3, 1, 2, 4, 3, 1, 4, 5, 7, 4,         3, 9, 6, 9, 3, 6, 6],        [3, 8, 6, 4, 0, 0, 3, 8, 1, 1, 5, 4, 8, 4, 8, 3, 3, 1, 1, 9, 6,         4, 9, 7, 6, 7, 3, 7],        [4, 3, 7, 5, 3, 4, 0, 4, 8, 2, 5, 1, 2, 8, 2, 6, 4, 7, 7, 6, 3,         5, 9, 6, 4, 2, 5, 9],        [4, 9, 2, 7, 8, 6, 1, 1, 9, 4, 1, 3, 1, 8, 6, 5, 3, 0, 2, 2, 3,         0, 3, 6, 9, 1, 2, 4],        [0, 7, 3, 6, 4, 2, 3, 7, 5, 0, 9, 5, 5, 2, 7, 5, 0, 3, 6, 8, 7,         3, 3, 6, 1, 2, 3, 6]]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.squeeze(x, axis=<span class="number">0</span>) <span class="comment"># 删除图片数量维度</span></span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432729, shape=(28, 28), dtype=int32, numpy=array([[5, 3, 3, 6, 9, 3, 0, 4, 1, 6, 3, 8, 7, 7, 5, 4, 0, 0, 8, 5, 2, 3,        6, 4, 4, 8, 8, 3],       [8, 4, 7, 9, 3, 6, 1, 7, 5, 9, 4, 9, 7, 4, 4, 8, 4, 9, 7, 9, 6, 1,        3, 5, 0, 2, 4, 2],       [3, 5, 5, 5, 7, 9, 5, 3, 6, 0, 7, 8, 0, 0, 4, 7, 8, 7, 4, 1, 9, 9,        2, 6, 6, 2, 0, 3],       [3, 5, 5, 2, 4, 0, 2, 5, 0, 2, 3, 2, 1, 0, 1, 4, 5, 3, 1, 9, 5, 3,        0, 5, 8, 1, 9, 4],       [6, 0, 1, 4, 0, 0, 7, 7, 0, 4, 3, 3, 3, 5, 2, 3, 5, 6, 4, 6, 4, 1,        3, 2, 8, 5, 8, 4],       [1, 2, 9, 3, 2, 3, 4, 4, 0, 0, 6, 6, 4, 0, 2, 7, 2, 2, 4, 2, 6, 0,        4, 0, 5, 5, 4, 5],       [3, 2, 6, 7, 7, 1, 0, 3, 3, 5, 5, 7, 8, 1, 6, 5, 5, 4, 3, 2, 9, 0,        0, 3, 7, 0, 0, 0],       [7, 7, 0, 7, 9, 8, 4, 5, 3, 7, 3, 3, 6, 1, 4, 8, 9, 2, 2, 8, 3, 1,        0, 9, 3, 3, 2, 4],       [9, 8, 8, 1, 4, 9, 3, 0, 5, 9, 6, 6, 8, 1, 4, 9, 8, 9, 8, 9, 3, 8,        7, 5, 8, 0, 3, 6],       [0, 8, 3, 1, 2, 1, 9, 4, 5, 0, 7, 1, 3, 5, 4, 4, 7, 3, 6, 5, 5, 6,        2, 0, 6, 1, 4, 8],       [4, 2, 6, 1, 7, 5, 6, 2, 4, 0, 9, 8, 0, 0, 0, 6, 8, 2, 3, 0, 0, 5,        6, 6, 9, 8, 4, 9],       [7, 3, 2, 5, 2, 5, 4, 3, 6, 4, 9, 2, 1, 7, 6, 4, 4, 5, 7, 7, 1, 6,        4, 0, 3, 6, 4, 8],       [1, 7, 6, 0, 4, 8, 0, 3, 0, 2, 0, 7, 0, 5, 6, 5, 3, 1, 4, 3, 8, 8,        8, 6, 7, 3, 1, 7],       [0, 8, 0, 5, 5, 2, 2, 5, 2, 1, 4, 4, 1, 4, 9, 4, 4, 1, 7, 1, 7, 7,        4, 1, 8, 2, 3, 2],       [5, 3, 5, 6, 6, 0, 9, 2, 9, 2, 8, 2, 1, 4, 0, 4, 7, 3, 0, 3, 8, 1,        5, 7, 5, 4, 6, 6],       [4, 7, 0, 1, 9, 6, 1, 1, 2, 1, 8, 2, 2, 9, 4, 7, 5, 1, 2, 4, 7, 5,        7, 6, 6, 4, 1, 5],       [4, 5, 7, 8, 2, 0, 5, 3, 4, 6, 3, 4, 5, 4, 9, 3, 6, 0, 2, 7, 1, 0,        1, 7, 2, 4, 4, 0],       [5, 3, 9, 1, 2, 4, 4, 8, 8, 2, 2, 1, 6, 4, 5, 2, 5, 0, 0, 1, 6, 4,        5, 9, 5, 8, 9, 5],       [6, 1, 1, 8, 9, 6, 8, 9, 9, 8, 2, 0, 9, 7, 9, 0, 9, 7, 0, 5, 3, 8,        0, 9, 1, 8, 9, 4],       [9, 1, 7, 3, 3, 7, 8, 3, 2, 2, 6, 3, 2, 1, 0, 5, 8, 2, 8, 4, 5, 5,        2, 9, 9, 6, 8, 3],       [0, 3, 8, 2, 5, 1, 6, 3, 5, 0, 2, 3, 9, 9, 4, 6, 1, 9, 3, 8, 7, 8,        8, 7, 2, 4, 4, 8],       [6, 7, 8, 6, 6, 6, 5, 2, 1, 8, 4, 7, 8, 9, 9, 4, 5, 2, 4, 7, 8, 5,        9, 3, 0, 0, 9, 1],       [7, 8, 4, 9, 4, 8, 9, 3, 5, 4, 8, 3, 7, 9, 2, 0, 2, 3, 8, 5, 6, 0,        4, 3, 6, 1, 6, 3],       [2, 4, 3, 9, 0, 2, 5, 9, 0, 0, 0, 3, 1, 2, 4, 3, 1, 4, 5, 7, 4, 3,        9, 6, 9, 3, 6, 6],       [3, 8, 6, 4, 0, 0, 3, 8, 1, 1, 5, 4, 8, 4, 8, 3, 3, 1, 1, 9, 6, 4,        9, 7, 6, 7, 3, 7],       [4, 3, 7, 5, 3, 4, 0, 4, 8, 2, 5, 1, 2, 8, 2, 6, 4, 7, 7, 6, 3, 5,        9, 6, 4, 2, 5, 9],       [4, 9, 2, 7, 8, 6, 1, 1, 9, 4, 1, 3, 1, 8, 6, 5, 3, 0, 2, 2, 3, 0,        3, 6, 9, 1, 2, 4],       [0, 7, 3, 6, 4, 2, 3, 7, 5, 0, 9, 5, 5, 2, 7, 5, 0, 3, 6, 8, 7, 3,        3, 6, 1, 2, 3, 6]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.uniform([<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>],maxval=<span class="number">10</span>,dtype=tf.int32)</span><br><span class="line">tf.squeeze(x) <span class="comment"># 删除所有长度为 1 的维度</span></span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=391, shape=(28, 28), dtype=int32, numpy=array([[3, 5, 3, 9, 7, 0, 0, 8, 3, 1, 4, 8, 5, 7, 8, 6, 9, 4, 1, 1, 5, 8,        6, 2, 8, 3, 5, 3],       [4, 8, 9, 7, 6, 0, 8, 7, 8, 3, 1, 3, 5, 9, 3, 6, 6, 2, 3, 1, 7, 6,        9, 6, 2, 7, 4, 2],       [5, 1, 2, 0, 3, 7, 5, 0, 7, 4, 7, 7, 5, 8, 9, 2, 2, 6, 7, 3, 8, 9,        4, 1, 6, 5, 4, 7],       [2, 5, 3, 4, 4, 7, 5, 5, 1, 1, 7, 0, 9, 8, 4, 3, 8, 6, 9, 3, 3, 2,        1, 2, 4, 4, 4, 7],       [9, 2, 3, 0, 3, 5, 4, 5, 8, 7, 0, 8, 6, 4, 9, 7, 1, 8, 3, 6, 5, 7,        0, 4, 4, 2, 6, 9],       [9, 3, 4, 4, 6, 8, 1, 7, 0, 8, 6, 0, 0, 2, 8, 3, 5, 0, 6, 6, 8, 4,        8, 9, 4, 0, 9, 4],       [3, 8, 5, 9, 4, 5, 1, 8, 5, 3, 5, 9, 7, 8, 9, 2, 8, 8, 5, 5, 5, 9,        1, 9, 3, 4, 4, 8],       [9, 5, 9, 4, 2, 0, 8, 1, 4, 2, 0, 3, 6, 9, 7, 6, 0, 5, 8, 9, 0, 8,        0, 0, 3, 1, 1, 7],       [4, 6, 9, 0, 6, 6, 7, 6, 2, 3, 1, 7, 8, 7, 8, 5, 2, 5, 4, 5, 1, 9,        9, 6, 6, 4, 4, 8],       [1, 4, 2, 6, 7, 8, 4, 9, 2, 7, 8, 8, 0, 7, 0, 3, 8, 2, 3, 1, 9, 2,        7, 9, 1, 1, 6, 7],       [0, 1, 7, 6, 4, 1, 4, 3, 0, 0, 7, 4, 7, 2, 6, 1, 3, 1, 8, 9, 1, 5,        7, 3, 4, 3, 4, 6],       [7, 7, 7, 3, 6, 6, 3, 6, 2, 8, 0, 3, 5, 5, 9, 1, 5, 0, 1, 8, 3, 9,        7, 6, 7, 8, 0, 9],       [3, 3, 9, 2, 4, 8, 1, 8, 8, 7, 5, 7, 4, 0, 1, 8, 5, 2, 9, 1, 1, 5,        7, 5, 4, 0, 5, 5],       [7, 9, 7, 1, 7, 7, 1, 5, 7, 1, 8, 3, 0, 5, 1, 9, 4, 0, 2, 4, 4, 4,        5, 1, 8, 0, 2, 8],       [8, 6, 4, 6, 5, 3, 3, 6, 7, 6, 1, 9, 0, 3, 6, 3, 9, 3, 0, 0, 4, 2,        5, 5, 7, 1, 2, 0],       [6, 7, 0, 4, 3, 2, 7, 8, 4, 4, 5, 8, 5, 0, 0, 4, 3, 4, 4, 9, 6, 6,        8, 8, 4, 9, 8, 7],       [1, 3, 5, 7, 6, 0, 2, 2, 1, 9, 8, 6, 6, 6, 0, 3, 6, 8, 9, 4, 0, 4,        4, 0, 8, 0, 8, 9],       [4, 6, 1, 4, 4, 8, 9, 7, 6, 8, 7, 9, 0, 8, 8, 3, 0, 5, 9, 8, 6, 6,        9, 6, 5, 1, 0, 9],       [0, 3, 1, 4, 2, 1, 2, 7, 6, 2, 1, 3, 0, 6, 6, 0, 7, 9, 5, 7, 7, 9,        7, 6, 9, 9, 2, 7],       [2, 8, 2, 1, 4, 4, 8, 8, 0, 3, 4, 6, 8, 2, 4, 5, 8, 3, 7, 5, 1, 6,        7, 5, 6, 3, 1, 2],       [4, 0, 7, 4, 0, 8, 3, 4, 9, 0, 0, 8, 9, 1, 1, 9, 7, 8, 9, 1, 9, 2,        0, 7, 3, 6, 6, 2],       [0, 4, 0, 9, 8, 3, 2, 5, 9, 1, 0, 2, 7, 9, 9, 7, 4, 5, 0, 0, 2, 7,        7, 2, 1, 7, 5, 3],       [9, 6, 3, 2, 6, 3, 1, 5, 1, 6, 6, 8, 9, 8, 3, 9, 6, 2, 8, 2, 3, 5,        9, 6, 8, 0, 9, 5],       [0, 3, 4, 7, 3, 5, 5, 0, 7, 3, 7, 7, 2, 1, 8, 4, 9, 7, 9, 1, 2, 5,        9, 7, 7, 7, 8, 0],       [6, 7, 3, 1, 2, 6, 4, 8, 5, 5, 4, 3, 7, 5, 4, 4, 1, 9, 6, 7, 6, 6,        5, 2, 4, 0, 3, 3],       [8, 8, 4, 5, 9, 3, 2, 7, 6, 5, 8, 4, 5, 4, 8, 3, 4, 6, 7, 3, 3, 4,        9, 8, 0, 4, 1, 2],       [5, 5, 9, 3, 6, 7, 4, 5, 2, 3, 4, 8, 0, 5, 3, 4, 1, 0, 3, 7, 6, 9,        3, 8, 9, 4, 9, 8],       [1, 4, 2, 1, 9, 3, 4, 7, 8, 1, 9, 3, 5, 8, 9, 4, 8, 3, 6, 9, 2, 1,        7, 7, 4, 4, 9, 3]], dtype=int32)&gt;</code></pre><h3 id="交换维度"><a href="#交换维度" class="headerlink" title="交换维度"></a>交换维度</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = tf.random.uniform([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([[[[0.5282526  0.3555627  0.41090894 0.47944117]   [0.06685734 0.73899055 0.274917   0.786981  ]   [0.5963073  0.47864938 0.4129647  0.9002305 ]]  [[0.70865    0.46636987 0.76260746 0.23017025]   [0.2235589  0.3718114  0.8150687  0.30672145]   [0.78165174 0.63648796 0.61503696 0.35355854]]]], shape=(1, 2, 3, 4), dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 交换维度</span></span><br><span class="line">tf.transpose(x,perm=[<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432771, shape=(1, 4, 2, 3), dtype=float32, numpy=array([[[[0.5282526 , 0.06685734, 0.5963073 ],         [0.70865   , 0.2235589 , 0.78165174]],        [[0.3555627 , 0.73899055, 0.47864938],         [0.46636987, 0.3718114 , 0.63648796]],        [[0.41090894, 0.274917  , 0.4129647 ],         [0.76260746, 0.8150687 , 0.61503696]],        [[0.47944117, 0.786981  , 0.9002305 ],         [0.23017025, 0.30672145, 0.35355854]]]], dtype=float32)&gt;</code></pre><h3 id="复制数据"><a href="#复制数据" class="headerlink" title="复制数据"></a>复制数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建向量 b</span></span><br><span class="line">b = tf.constant([<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># 插入新维度，变成矩阵</span></span><br><span class="line">b = tf.expand_dims(b, axis=<span class="number">0</span>) </span><br><span class="line">b</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([1 2], shape=(2,), dtype=int32)&lt;tf.Tensor: id=432780, shape=(1, 2), dtype=int32, numpy=array([[1, 2]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 样本行维度上复制一份</span></span><br><span class="line">b = tf.tile(b, multiples=[<span class="number">2</span>,<span class="number">1</span>]) </span><br><span class="line">b</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=412, shape=(2, 2), dtype=int32, numpy=array([[1, 2],       [1, 2]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.<span class="built_in">range</span>(<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 创建 2 行 2 列矩阵</span></span><br><span class="line">x=tf.reshape(x,[<span class="number">2</span>,<span class="number">2</span>]) </span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432787, shape=(2, 2), dtype=int32, numpy=array([[0, 1],       [2, 3]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列维度复制一份</span></span><br><span class="line">x = tf.tile(x,multiples=[<span class="number">1</span>,<span class="number">2</span>]) </span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432789, shape=(2, 4), dtype=int32, numpy=array([[0, 1, 0, 1],       [2, 3, 2, 3]], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 行维度复制一份</span></span><br><span class="line">x = tf.tile(x,multiples=[<span class="number">2</span>,<span class="number">1</span>]) </span><br><span class="line">x</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432791, shape=(4, 4), dtype=int32, numpy=array([[0, 1, 0, 1],       [2, 3, 2, 3],       [0, 1, 0, 1],       [2, 3, 2, 3]], dtype=int32)&gt;</code></pre><h2 id="Broadcasting"><a href="#Broadcasting" class="headerlink" title="Broadcasting"></a>Broadcasting</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建矩阵</span></span><br><span class="line">A = tf.random.normal([<span class="number">32</span>,<span class="number">1</span>]) </span><br><span class="line"><span class="comment"># 扩展为 4D 张量</span></span><br><span class="line">tf.broadcast_to(A, [<span class="number">2</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>]) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=430, shape=(2, 32, 32, 3), dtype=float32, numpy=array([[[[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        ...,        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]]],</code></pre><p>​<br>           [[[ 0.04447514,  0.04447514,  0.04447514],<br>             [-0.8540972 , -0.8540972 , -0.8540972 ],<br>             [ 0.30159432,  0.30159432,  0.30159432],<br>             …,<br>             [-0.84129137, -0.84129137, -0.84129137],<br>             [ 0.58230823,  0.58230823,  0.58230823],<br>             [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],</p><pre><code>        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        ...,        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]],        [[ 0.04447514,  0.04447514,  0.04447514],         [-0.8540972 , -0.8540972 , -0.8540972 ],         [ 0.30159432,  0.30159432,  0.30159432],         ...,         [-0.84129137, -0.84129137, -0.84129137],         [ 0.58230823,  0.58230823,  0.58230823],         [ 0.1573652 ,  0.1573652 ,  0.1573652 ]]]], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">A = tf.random.normal([<span class="number">32</span>,<span class="number">2</span>])</span><br><span class="line"><span class="comment"># 不符合 Broadcasting 条件</span></span><br><span class="line"><span class="keyword">try</span>: </span><br><span class="line">    tf.broadcast_to(A, [<span class="number">2</span>,<span class="number">32</span>,<span class="number">32</span>,<span class="number">4</span>])</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure><pre><code>Incompatible shapes: [32,2] vs. [2,32,32,4] [Op:BroadcastTo]</code></pre><h2 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h2><h3 id="加、减、乘、除运算"><a href="#加、减、乘、除运算" class="headerlink" title="加、减、乘、除运算"></a>加、减、乘、除运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line">b = tf.constant(<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 整除运算</span></span><br><span class="line">a//b </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=443, shape=(5,), dtype=int32, numpy=array([0, 0, 1, 1, 2], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 余除运算</span></span><br><span class="line">a%b </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=444, shape=(5,), dtype=int32, numpy=array([0, 1, 0, 1, 0], dtype=int32)&gt;</code></pre><h3 id="乘方运算"><a href="#乘方运算" class="headerlink" title="乘方运算"></a>乘方运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.<span class="built_in">range</span>(<span class="number">4</span>)</span><br><span class="line"><span class="comment"># 乘方运算</span></span><br><span class="line">tf.<span class="built_in">pow</span>(x,<span class="number">3</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=450, shape=(4,), dtype=int32, numpy=array([ 0,  1,  8, 27], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 乘方运算符</span></span><br><span class="line">x**<span class="number">2</span> </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=452, shape=(4,), dtype=int32, numpy=array([0, 1, 4, 9], dtype=int32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x=tf.constant([<span class="number">1.</span>,<span class="number">4.</span>,<span class="number">9.</span>])</span><br><span class="line"><span class="comment"># 平方根</span></span><br><span class="line">x**(<span class="number">0.5</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=455, shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = tf.<span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># 转换为浮点数</span></span><br><span class="line">x = tf.cast(x, dtype=tf.float32) </span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># 平方</span></span><br><span class="line">x = tf.square(x) </span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)tf.Tensor([0. 1. 2. 3. 4.], shape=(5,), dtype=float32)tf.Tensor([ 0.  1.  4.  9. 16.], shape=(5,), dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 平方根</span></span><br><span class="line">tf.sqrt(x) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=432798, shape=(5,), dtype=float32, numpy=array([0.        , 0.99999994, 1.9999999 , 2.9999998 , 4.        ],      dtype=float32)&gt;</code></pre><h3 id="指数和对数运算"><a href="#指数和对数运算" class="headerlink" title="指数和对数运算"></a>指数和对数运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([<span class="number">1.</span>,<span class="number">2.</span>,<span class="number">3.</span>])</span><br><span class="line"><span class="comment"># 指数运算</span></span><br><span class="line"><span class="number">2</span>**x </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=465, shape=(3,), dtype=float32, numpy=array([2., 4., 8.], dtype=float32)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自然指数运算</span></span><br><span class="line">tf.exp(<span class="number">1.</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=467, shape=(), dtype=float32, numpy=2.7182817&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = tf.exp(<span class="number">3.</span>)</span><br><span class="line"><span class="comment"># 对数运算</span></span><br><span class="line">tf.math.log(x) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=470, shape=(), dtype=float32, numpy=3.0&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([<span class="number">1.</span>,<span class="number">2.</span>])</span><br><span class="line">x = <span class="number">10</span>**x</span><br><span class="line"><span class="comment"># 换底公式</span></span><br><span class="line">tf.math.log(x)/tf.math.log(<span class="number">10.</span>) </span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=477, shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)&gt;</code></pre><h3 id="矩阵相乘运算"><a href="#矩阵相乘运算" class="headerlink" title="矩阵相乘运算"></a>矩阵相乘运算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">32</span>])</span><br><span class="line">b = tf.random.normal([<span class="number">4</span>,<span class="number">3</span>,<span class="number">32</span>,<span class="number">2</span>])</span><br><span class="line"><span class="comment"># 批量形式的矩阵相乘</span></span><br><span class="line"><span class="built_in">print</span>(a@b)</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([[[[ 2.93815994e+00  1.80159616e+00]   [-4.95495558e+00 -2.65059781e+00]   [ 6.36351776e+00  8.27180672e+00]   [-2.50184441e+00 -3.22499895e+00]   [-6.89737129e+00  6.43845701e+00]   [ 4.72115231e+00 -7.39528358e-01]   [-5.87444019e+00 -6.75603390e+00]   [ 8.61762238e+00  4.49309635e+00]   [ 3.18081021e+00 -1.84904563e+00]   [-5.71209073e-01  1.76863492e+00]   [-8.77548409e+00 -2.09427929e+00]   [ 6.11399221e+00  3.75506377e+00]   [-5.72681367e-01 -5.56786919e+00]   [ 1.03334942e+01 -6.21349716e+00]   [ 2.05781221e+00 -2.48031449e+00]   [-1.05474174e-01  1.17951145e+01]   [-8.32847595e+00  8.04420090e+00]   [ 1.10347319e+01 -7.15183640e+00]   [-1.10890408e+01  2.06656051e+00]   [ 2.04201794e+00 -1.72195137e-01]   [ 4.16003466e+00  2.92319274e+00]   [ 1.00829735e+01  3.50188327e+00]   [ 1.60061455e+01 -3.23914313e+00]   [-1.34949207e+00 -2.27372718e+00]   [ 1.16594486e+01 -1.30499089e+00]   [ 2.90008926e+00  6.59213543e+00]   [-3.04731274e+00 -1.17982030e-01]   [-6.25353050e+00 -1.59929824e+00]]  [[ 2.35922217e+00 -1.44711876e+00]   [-2.82181549e+00 -4.16362000e+00]   [-4.13206530e+00  1.96330786e-01]   [-1.13723636e+00 -1.90036798e+00]   [-1.42907238e+00  4.24102306e-01]   [ 1.01430655e+01  2.54081345e+00]   [-4.05478477e+00 -9.29689407e+00]   [ 1.36705666e+01  1.40576875e+00]   [-5.09379244e+00  4.66089153e+00]   [ 6.25803471e-02 -2.86052656e+00]   [-1.12946069e+00 -4.28373003e+00]   [ 5.32545996e+00  1.97562897e+00]   [ 7.16341162e+00  6.10791969e+00]   [-4.77171421e+00 -1.75261497e+00]   [-1.43213348e+01  5.44925928e+00]   [-2.13357735e+00 -2.74817157e+00]   [-6.38115454e+00  6.48117113e+00]   [-1.21313601e+01 -1.16765201e+00]   [-1.98863697e+00  1.22314978e+01]   [ 3.63174462e+00  5.20076323e+00]   [-1.05080090e+01  4.47047186e+00]   [ 8.52560043e+00 -3.26042938e+00]   [ 1.86961699e+00  1.04149675e+00]   [ 3.27967310e+00  4.52322531e+00]   [-1.08596125e+01  4.40047550e+00]   [ 3.30025196e+00 -3.57261777e-01]   [-4.17899323e+00 -5.29293346e+00]   [-6.29359818e+00  2.55025506e-01]]  [[ 2.79792500e+00 -1.14968262e+01]   [ 6.42120302e-01  8.60604167e-01]   [ 8.26789284e+00  9.11268139e+00]   [-1.24864876e+00 -1.29506755e+00]   [ 1.83019781e+00  1.32512970e+01]   [-4.38226223e+00  2.93613434e+00]   [-1.01948481e+01 -2.50259852e+00]   [-6.08818817e+00  5.71516156e-01]   [ 8.14604282e-01  8.74936581e-01]   [-9.27050591e-01  1.68381357e+00]   [-2.39078522e+00 -4.39953446e-01]   [-1.79722738e+00  2.44799304e+00]   [-6.19097829e-01  4.20792866e+00]   [-3.59187007e+00  2.05337834e+00]   [-2.02478099e+00  3.92844319e+00]   [-2.78609324e+00 -1.00785866e+01]   [ 1.35041237e-01  9.82832527e+00]   [ 3.77985573e+00 -2.92683578e+00]   [ 2.50951290e+00 -1.10158062e+00]   [-2.69217896e+00  7.27837420e+00]   [ 4.59399509e+00 -4.81438732e+00]   [ 9.01638508e+00  5.12754726e+00]   [ 5.19506645e+00 -2.35464978e+00]   [ 2.05791235e-01  3.24537897e+00]   [-6.17561936e-02  1.22012386e+01]   [ 8.34735334e-01  2.56306553e+00]   [-8.42908740e-01 -4.72223663e+00]   [ 7.59096265e-01 -8.70975971e-01]]]</code></pre><p>​<br>     [[[-1.25730896e+01  1.73365784e+00]<br>       [-8.16483736e-01 -3.12521791e+00]<br>       [ 4.31258678e+00 -3.65629935e+00]<br>       [ 7.81925964e+00  2.67266393e+00]<br>       [-1.45902622e+00 -1.69710827e+00]<br>       [-4.97250271e+00  1.06699669e+00]<br>       [-1.15320644e+01  3.67050219e+00]<br>       [ 9.82042491e-01 -8.96060181e+00]<br>       [ 4.24584293e+00 -2.03312969e+00]<br>       [-8.90874267e-02 -2.19113445e+00]<br>       [ 7.03373575e+00  4.82089567e+00]<br>       [ 2.19787431e+00 -1.35815620e+00]<br>       [-4.33743429e+00 -2.77082419e+00]<br>       [-6.55539846e+00 -5.28619862e+00]<br>       [-4.10456562e+00  1.53431883e+01]<br>       [-6.97701550e+00  5.58186054e-01]<br>       [-4.06244993e+00 -1.29598303e+01]<br>       [ 1.80246496e+00 -2.77987790e+00]<br>       [-7.30259180e+00 -5.11505365e+00]<br>       [ 2.12593174e+00 -3.25598717e+00]<br>       [ 7.80677795e+00  1.99891090e-01]<br>       [ 8.46464539e+00  2.72348213e+00]<br>       [-2.32167172e+00  4.69824505e+00]<br>       [ 3.97749400e+00 -9.19138908e+00]<br>       [ 2.90814090e+00  1.26416731e+00]<br>       [-8.01068783e-01  5.13629675e+00]<br>       [-1.10610142e+01  4.88826132e+00]<br>       [-1.75804818e+00  1.23052418e+00]]</p><pre><code>  [[-5.49224281e+00 -1.18972950e+01]   [-1.71067417e+00 -7.94510078e+00]   [ 8.11289787e+00  2.97325039e+00]   [-6.18529272e+00 -1.07129316e+01]   [ 5.09897184e+00 -5.09968042e+00]   [-7.61364222e+00  5.40171003e+00]   [-6.47705889e+00 -1.68601739e+00]   [ 5.09246063e+00 -4.75051785e+00]   [-8.07900906e+00 -1.01351190e+00]   [-5.56266832e+00 -5.98014545e+00]   [-1.84528065e+00 -2.55948591e+00]   [ 1.63680077e-01 -4.52482510e+00]   [-6.17208385e+00  8.61810780e+00]   [ 2.54550838e+00  1.04630842e+01]   [ 6.78235245e+00  2.36592340e+00]   [ 5.33071947e+00  7.77984023e-01]   [ 1.59947419e+00  3.40054178e+00]   [ 9.72853303e-01  1.95867562e+00]   [-5.11668110e+00  9.07939816e+00]   [-9.91412735e+00  5.33779049e+00]   [ 6.93627453e+00  9.98051357e+00]   [-1.49268985e+00 -1.61656654e+00]   [ 6.77412367e+00  5.89341736e+00]   [-9.02515793e+00 -4.86350346e+00]   [-2.65398359e+00  6.53871584e+00]   [ 7.60008812e+00  2.23823214e+00]   [ 3.48978114e+00  7.77210045e+00]   [-1.89859509e+00  1.36791458e+01]]  [[ 6.16735172e+00 -3.06368208e+00]   [-6.22440147e+00  2.49987888e+00]   [ 1.23477805e+00 -9.58612680e-01]   [-6.32274055e+00 -3.50495398e-01]   [-2.37460756e+00  2.89988756e+00]   [ 6.76133537e+00 -4.97397709e+00]   [ 4.19915617e-01 -1.44209051e+00]   [-8.48055720e-01 -1.34412467e+00]   [ 1.47503817e+00 -4.57327032e+00]   [-8.83791351e+00  1.30507603e+01]   [ 5.04546928e+00  2.96709967e+00]   [ 1.21958218e+01 -3.70147228e-01]   [-9.32716131e-02  8.25912094e+00]   [-6.88422298e+00 -2.94276452e+00]   [-8.92567754e-01  7.48677373e-01]   [ 1.13859291e+01 -4.54786253e+00]   [ 4.14542294e+00  3.62407827e+00]   [-4.84375191e+00  7.60643148e+00]   [-3.99736214e+00  8.38322639e-01]   [ 8.50940418e+00 -3.18443274e+00]   [ 3.02693796e+00 -1.08982430e+01]   [ 5.94771481e+00  1.90185285e+00]   [ 1.79021060e-02  2.71560931e+00]   [ 1.28265166e+00  1.35003614e+00]   [-5.15541887e+00  3.48176098e+00]   [ 1.35739307e+01  1.13081062e+00]   [-1.13344326e+01  2.02814102e+00]   [-3.78427625e+00 -3.41797924e+00]]]</code></pre><p>​<br>     [[[ 7.51625490e+00 -8.01126385e+00]<br>       [ 8.94779682e-01 -1.39191675e+00]<br>       [-6.38634396e+00 -7.54839706e+00]<br>       [ 5.90809202e+00 -4.73860931e+00]<br>       [ 2.89039660e+00 -5.74475765e-01]<br>       [-3.24619865e+00 -4.33766127e+00]<br>       [ 7.45817757e+00  8.72869968e+00]<br>       [ 1.70315895e+01 -1.43109741e+01]<br>       [ 6.71465302e+00  2.36530209e+00]<br>       [ 2.37234616e+00  9.54824162e+00]<br>       [ 1.24315548e+01 -8.32226753e-01]<br>       [ 1.15248704e+00  6.42775774e+00]<br>       [-2.05694604e+00 -5.29237223e+00]<br>       [ 1.06061993e+01  4.43905163e+00]<br>       [ 3.32259560e+00  2.86404061e+00]<br>       [-1.26070702e+00 -3.86716032e+00]<br>       [-7.17960167e+00 -5.47068119e+00]<br>       [ 6.13063002e+00 -1.27777729e+01]<br>       [-4.77525711e+00 -2.89896202e+00]<br>       [ 5.04258776e+00  1.05476036e+01]<br>       [-4.72102404e+00  4.53035545e+00]<br>       [ 8.30504322e+00 -6.72617435e+00]<br>       [ 1.51879632e+00 -7.57512569e+00]<br>       [ 5.25161076e+00 -6.00039482e+00]<br>       [-2.66712689e+00 -3.15567350e+00]<br>       [ 6.98167515e+00  1.21508999e+01]<br>       [-3.58145714e+00  1.01358452e+01]<br>       [-7.68432474e+00  6.27517796e+00]]</p><pre><code>  [[-3.85787821e+00  4.13319540e+00]   [ 4.08870316e+00  8.98323441e+00]   [ 2.88623333e-01  2.08936238e+00]   [-1.27303381e+01 -3.72204494e+00]   [-1.63620949e-01  4.14640725e-01]   [-9.77903843e+00 -9.83979321e+00]   [ 1.20987940e+01 -1.00569272e+00]   [-9.52555597e-01 -7.21974373e-01]   [-7.53700542e+00 -1.03328714e+01]   [ 3.82278275e+00  7.92873979e-01]   [ 1.62820339e+01  9.25348282e-01]   [-2.99300981e+00 -4.05044317e+00]   [-1.71284425e+00  3.32610369e-01]   [ 8.45957184e+00  3.01560092e+00]   [ 9.61618781e-01  4.84845543e+00]   [-5.04883003e+00 -4.64504576e+00]   [-4.88548994e-01  4.22385454e+00]   [-3.06538558e+00 -2.68467999e+00]   [ 1.44536438e+01 -1.67332339e+00]   [-1.20380235e+00 -3.01969767e-01]   [-1.25808067e+01 -1.83691287e+00]   [ 7.00172246e-01 -5.44080067e+00]   [ 3.71728969e+00 -6.50164127e+00]   [ 3.44825792e+00  2.27989483e+00]   [-1.16813726e+01  3.55064964e+00]   [-6.76289463e+00 -1.25415869e+01]   [ 1.86627662e+00  4.91928959e+00]   [ 2.37216616e+00 -3.23613596e+00]]  [[ 5.60678053e+00  6.07894707e+00]   [-6.23391962e+00 -1.82450306e+00]   [ 6.90571690e+00 -2.60890079e+00]   [ 3.98191905e+00 -2.60109711e+00]   [ 3.79411244e+00 -7.30271769e+00]   [-8.19082737e+00 -4.81762362e+00]   [ 1.01562176e+01 -9.18346643e-02]   [ 5.15106916e-01 -1.88746595e+00]   [-7.10526466e-01  4.75524092e+00]   [ 4.28777647e+00 -4.28609967e-01]   [ 2.94255161e+00 -2.76411390e+00]   [-5.01211119e+00 -1.35121047e-01]   [ 4.88255644e+00  7.48982000e+00]   [-2.94339252e+00 -1.49728453e+00]   [-5.28226614e-01  1.13798523e+01]   [-3.26653433e+00 -1.12711830e+01]   [ 6.92280245e+00  4.46824360e+00]   [-1.07686818e-02  5.99187469e+00]   [-2.30055904e+00 -2.35181737e+00]   [-1.86744165e+00 -9.12775040e-01]   [ 5.70386982e+00  2.56417489e+00]   [-4.37073708e-01 -4.62391090e+00]   [-8.43499756e+00  9.08772826e-01]   [-5.64418888e+00 -5.02650261e+00]   [ 3.92685270e+00 -5.31071186e+00]   [ 6.36297584e-01  2.63665223e+00]   [-7.71557522e+00  4.19800425e+00]   [ 3.64932895e+00  2.46329069e+00]]]</code></pre><p>​<br>     [[[ 6.65752888e-01  3.40558529e-01]<br>       [ 4.08683634e+00  6.27357101e+00]<br>       [-2.77316380e+00  5.83889532e+00]<br>       [-2.01864777e+01 -8.63007069e+00]<br>       [ 4.85101509e+00  1.56102419e-01]<br>       [ 5.13551521e+00  7.00347781e-01]<br>       [ 4.66926765e+00  1.13918304e+01]<br>       [ 1.17937775e+01 -5.75443983e+00]<br>       [ 5.18499660e+00  2.47753906e+01]<br>       [-4.94616604e+00  1.09324312e+00]<br>       [ 7.08940148e-01  5.36628440e-02]<br>       [-6.22777748e+00 -6.08889389e+00]<br>       [ 8.21062326e-01  5.73018026e+00]<br>       [-1.01816578e+01 -5.96292210e+00]<br>       [-3.45601702e+00 -5.80823088e+00]<br>       [-7.81425619e+00 -1.54714165e+01]<br>       [ 6.15157843e+00  4.41321850e+00]<br>       [ 2.28190422e-02 -1.40392697e+00]<br>       [ 5.86180115e+00  2.66614532e+00]<br>       [-1.21994901e+00  6.87365246e+00]<br>       [ 7.62740707e+00 -1.52388859e+00]<br>       [-8.03575134e+00 -1.35383148e+01]<br>       [-1.75186968e+00 -1.95710063e+00]<br>       [-8.72407794e-01 -8.31413174e+00]<br>       [-1.38678074e+01 -3.35018563e+00]<br>       [ 1.02961273e+01  5.95636034e+00]<br>       [ 7.15158939e+00  9.47603941e-01]<br>       [ 3.59655428e+00 -3.57616353e+00]]</p><pre><code>  [[-7.15814590e+00 -1.73663855e-01]   [-5.33630848e+00  2.23019302e-01]   [-3.60880065e+00  1.16919529e+00]   [ 1.65422618e+00  3.21728516e+00]   [ 1.86843979e+00  1.13296022e+01]   [-6.71664524e+00  8.06290245e+00]   [-3.82262254e+00  4.57042742e+00]   [-7.61132431e+00  7.53255653e+00]   [ 1.63969231e+00 -1.19336343e+00]   [ 2.03410006e+00  5.48414516e+00]   [ 7.98875904e+00 -6.00354958e+00]   [ 5.37972260e+00 -3.13939238e+00]   [ 6.52196217e+00  5.99524212e+00]   [-3.65084100e+00  5.70605898e+00]   [ 5.66238022e+00 -4.25603628e-01]   [ 1.31335664e+00  3.34762931e-01]   [ 4.95460320e+00 -7.73174858e+00]   [-6.06322289e-02  7.14966822e+00]   [ 4.30868864e+00 -4.49330187e+00]   [ 3.00062609e+00 -3.45171928e+00]   [-8.88646841e-01  4.49364281e+00]   [-1.37166762e+00 -9.60632420e+00]   [ 2.72169065e+00 -2.02102685e+00]   [ 4.06615162e+00  2.21987987e+00]   [ 4.58932543e+00 -6.33985901e+00]   [-7.59764194e+00 -8.69492054e-01]   [ 6.72914386e-01  3.37907672e-02]   [-9.57373238e+00  4.29612064e+00]]  [[ 2.07057667e+00  2.49500203e+00]   [-2.39765930e+00  6.45140171e-01]   [ 9.70951462e+00  1.52998376e+00]   [ 9.77593803e+00  8.06670094e+00]   [ 8.35551929e+00  7.26291513e+00]   [-9.06231880e-01 -9.31769133e-01]   [-6.77584314e+00  3.27285552e+00]   [ 5.13162661e+00 -5.17782736e+00]   [-3.71608639e+00 -5.12819290e-01]   [ 1.48577709e+01 -2.64512122e-01]   [ 6.44747496e-01 -9.95941162e-02]   [ 1.04961805e+01 -3.98670554e+00]   [ 2.51394081e+00  1.80438447e+00]   [-5.59201813e+00  1.18733444e+01]   [-2.31048003e-01 -1.12039871e+01]   [-1.62683907e+01  2.02177715e+00]   [ 1.14540329e+01  2.30115056e-02]   [-1.10159683e+01 -3.24261713e+00]   [-1.33181334e+01 -8.00105953e+00]   [ 6.21838617e+00  8.89258957e+00]   [ 1.58339548e+00 -2.27107620e+00]   [-4.17989254e-01 -2.85755348e+00]   [-2.48508906e+00  9.64674568e+00]   [-1.08764257e+01  2.08483315e+00]   [ 9.77210236e+00  2.50418329e+00]   [-1.62253022e+00  1.67334347e+01]   [ 6.42501354e-01  2.53464675e+00]   [-1.12935200e+01  3.39891338e+00]]]], shape=(4, 3, 28, 2), dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(tf.matmul(a,b))</span><br></pre></td></tr></table></figure><pre><code>tf.Tensor([[[[ 2.93815994e+00  1.80159616e+00]   [-4.95495558e+00 -2.65059781e+00]   [ 6.36351776e+00  8.27180672e+00]   [-2.50184441e+00 -3.22499895e+00]   [-6.89737129e+00  6.43845701e+00]   [ 4.72115231e+00 -7.39528358e-01]   [-5.87444019e+00 -6.75603390e+00]   [ 8.61762238e+00  4.49309635e+00]   [ 3.18081021e+00 -1.84904563e+00]   [-5.71209073e-01  1.76863492e+00]   [-8.77548409e+00 -2.09427929e+00]   [ 6.11399221e+00  3.75506377e+00]   [-5.72681367e-01 -5.56786919e+00]   [ 1.03334942e+01 -6.21349716e+00]   [ 2.05781221e+00 -2.48031449e+00]   [-1.05474174e-01  1.17951145e+01]   [-8.32847595e+00  8.04420090e+00]   [ 1.10347319e+01 -7.15183640e+00]   [-1.10890408e+01  2.06656051e+00]   [ 2.04201794e+00 -1.72195137e-01]   [ 4.16003466e+00  2.92319274e+00]   [ 1.00829735e+01  3.50188327e+00]   [ 1.60061455e+01 -3.23914313e+00]   [-1.34949207e+00 -2.27372718e+00]   [ 1.16594486e+01 -1.30499089e+00]   [ 2.90008926e+00  6.59213543e+00]   [-3.04731274e+00 -1.17982030e-01]   [-6.25353050e+00 -1.59929824e+00]]  [[ 2.35922217e+00 -1.44711876e+00]   [-2.82181549e+00 -4.16362000e+00]   [-4.13206530e+00  1.96330786e-01]   [-1.13723636e+00 -1.90036798e+00]   [-1.42907238e+00  4.24102306e-01]   [ 1.01430655e+01  2.54081345e+00]   [-4.05478477e+00 -9.29689407e+00]   [ 1.36705666e+01  1.40576875e+00]   [-5.09379244e+00  4.66089153e+00]   [ 6.25803471e-02 -2.86052656e+00]   [-1.12946069e+00 -4.28373003e+00]   [ 5.32545996e+00  1.97562897e+00]   [ 7.16341162e+00  6.10791969e+00]   [-4.77171421e+00 -1.75261497e+00]   [-1.43213348e+01  5.44925928e+00]   [-2.13357735e+00 -2.74817157e+00]   [-6.38115454e+00  6.48117113e+00]   [-1.21313601e+01 -1.16765201e+00]   [-1.98863697e+00  1.22314978e+01]   [ 3.63174462e+00  5.20076323e+00]   [-1.05080090e+01  4.47047186e+00]   [ 8.52560043e+00 -3.26042938e+00]   [ 1.86961699e+00  1.04149675e+00]   [ 3.27967310e+00  4.52322531e+00]   [-1.08596125e+01  4.40047550e+00]   [ 3.30025196e+00 -3.57261777e-01]   [-4.17899323e+00 -5.29293346e+00]   [-6.29359818e+00  2.55025506e-01]]  [[ 2.79792500e+00 -1.14968262e+01]   [ 6.42120302e-01  8.60604167e-01]   [ 8.26789284e+00  9.11268139e+00]   [-1.24864876e+00 -1.29506755e+00]   [ 1.83019781e+00  1.32512970e+01]   [-4.38226223e+00  2.93613434e+00]   [-1.01948481e+01 -2.50259852e+00]   [-6.08818817e+00  5.71516156e-01]   [ 8.14604282e-01  8.74936581e-01]   [-9.27050591e-01  1.68381357e+00]   [-2.39078522e+00 -4.39953446e-01]   [-1.79722738e+00  2.44799304e+00]   [-6.19097829e-01  4.20792866e+00]   [-3.59187007e+00  2.05337834e+00]   [-2.02478099e+00  3.92844319e+00]   [-2.78609324e+00 -1.00785866e+01]   [ 1.35041237e-01  9.82832527e+00]   [ 3.77985573e+00 -2.92683578e+00]   [ 2.50951290e+00 -1.10158062e+00]   [-2.69217896e+00  7.27837420e+00]   [ 4.59399509e+00 -4.81438732e+00]   [ 9.01638508e+00  5.12754726e+00]   [ 5.19506645e+00 -2.35464978e+00]   [ 2.05791235e-01  3.24537897e+00]   [-6.17561936e-02  1.22012386e+01]   [ 8.34735334e-01  2.56306553e+00]   [-8.42908740e-01 -4.72223663e+00]   [ 7.59096265e-01 -8.70975971e-01]]]</code></pre><p>​<br>     [[[-1.25730896e+01  1.73365784e+00]<br>       [-8.16483736e-01 -3.12521791e+00]<br>       [ 4.31258678e+00 -3.65629935e+00]<br>       [ 7.81925964e+00  2.67266393e+00]<br>       [-1.45902622e+00 -1.69710827e+00]<br>       [-4.97250271e+00  1.06699669e+00]<br>       [-1.15320644e+01  3.67050219e+00]<br>       [ 9.82042491e-01 -8.96060181e+00]<br>       [ 4.24584293e+00 -2.03312969e+00]<br>       [-8.90874267e-02 -2.19113445e+00]<br>       [ 7.03373575e+00  4.82089567e+00]<br>       [ 2.19787431e+00 -1.35815620e+00]<br>       [-4.33743429e+00 -2.77082419e+00]<br>       [-6.55539846e+00 -5.28619862e+00]<br>       [-4.10456562e+00  1.53431883e+01]<br>       [-6.97701550e+00  5.58186054e-01]<br>       [-4.06244993e+00 -1.29598303e+01]<br>       [ 1.80246496e+00 -2.77987790e+00]<br>       [-7.30259180e+00 -5.11505365e+00]<br>       [ 2.12593174e+00 -3.25598717e+00]<br>       [ 7.80677795e+00  1.99891090e-01]<br>       [ 8.46464539e+00  2.72348213e+00]<br>       [-2.32167172e+00  4.69824505e+00]<br>       [ 3.97749400e+00 -9.19138908e+00]<br>       [ 2.90814090e+00  1.26416731e+00]<br>       [-8.01068783e-01  5.13629675e+00]<br>       [-1.10610142e+01  4.88826132e+00]<br>       [-1.75804818e+00  1.23052418e+00]]</p><pre><code>  [[-5.49224281e+00 -1.18972950e+01]   [-1.71067417e+00 -7.94510078e+00]   [ 8.11289787e+00  2.97325039e+00]   [-6.18529272e+00 -1.07129316e+01]   [ 5.09897184e+00 -5.09968042e+00]   [-7.61364222e+00  5.40171003e+00]   [-6.47705889e+00 -1.68601739e+00]   [ 5.09246063e+00 -4.75051785e+00]   [-8.07900906e+00 -1.01351190e+00]   [-5.56266832e+00 -5.98014545e+00]   [-1.84528065e+00 -2.55948591e+00]   [ 1.63680077e-01 -4.52482510e+00]   [-6.17208385e+00  8.61810780e+00]   [ 2.54550838e+00  1.04630842e+01]   [ 6.78235245e+00  2.36592340e+00]   [ 5.33071947e+00  7.77984023e-01]   [ 1.59947419e+00  3.40054178e+00]   [ 9.72853303e-01  1.95867562e+00]   [-5.11668110e+00  9.07939816e+00]   [-9.91412735e+00  5.33779049e+00]   [ 6.93627453e+00  9.98051357e+00]   [-1.49268985e+00 -1.61656654e+00]   [ 6.77412367e+00  5.89341736e+00]   [-9.02515793e+00 -4.86350346e+00]   [-2.65398359e+00  6.53871584e+00]   [ 7.60008812e+00  2.23823214e+00]   [ 3.48978114e+00  7.77210045e+00]   [-1.89859509e+00  1.36791458e+01]]  [[ 6.16735172e+00 -3.06368208e+00]   [-6.22440147e+00  2.49987888e+00]   [ 1.23477805e+00 -9.58612680e-01]   [-6.32274055e+00 -3.50495398e-01]   [-2.37460756e+00  2.89988756e+00]   [ 6.76133537e+00 -4.97397709e+00]   [ 4.19915617e-01 -1.44209051e+00]   [-8.48055720e-01 -1.34412467e+00]   [ 1.47503817e+00 -4.57327032e+00]   [-8.83791351e+00  1.30507603e+01]   [ 5.04546928e+00  2.96709967e+00]   [ 1.21958218e+01 -3.70147228e-01]   [-9.32716131e-02  8.25912094e+00]   [-6.88422298e+00 -2.94276452e+00]   [-8.92567754e-01  7.48677373e-01]   [ 1.13859291e+01 -4.54786253e+00]   [ 4.14542294e+00  3.62407827e+00]   [-4.84375191e+00  7.60643148e+00]   [-3.99736214e+00  8.38322639e-01]   [ 8.50940418e+00 -3.18443274e+00]   [ 3.02693796e+00 -1.08982430e+01]   [ 5.94771481e+00  1.90185285e+00]   [ 1.79021060e-02  2.71560931e+00]   [ 1.28265166e+00  1.35003614e+00]   [-5.15541887e+00  3.48176098e+00]   [ 1.35739307e+01  1.13081062e+00]   [-1.13344326e+01  2.02814102e+00]   [-3.78427625e+00 -3.41797924e+00]]]</code></pre><p>​<br>     [[[ 7.51625490e+00 -8.01126385e+00]<br>       [ 8.94779682e-01 -1.39191675e+00]<br>       [-6.38634396e+00 -7.54839706e+00]<br>       [ 5.90809202e+00 -4.73860931e+00]<br>       [ 2.89039660e+00 -5.74475765e-01]<br>       [-3.24619865e+00 -4.33766127e+00]<br>       [ 7.45817757e+00  8.72869968e+00]<br>       [ 1.70315895e+01 -1.43109741e+01]<br>       [ 6.71465302e+00  2.36530209e+00]<br>       [ 2.37234616e+00  9.54824162e+00]<br>       [ 1.24315548e+01 -8.32226753e-01]<br>       [ 1.15248704e+00  6.42775774e+00]<br>       [-2.05694604e+00 -5.29237223e+00]<br>       [ 1.06061993e+01  4.43905163e+00]<br>       [ 3.32259560e+00  2.86404061e+00]<br>       [-1.26070702e+00 -3.86716032e+00]<br>       [-7.17960167e+00 -5.47068119e+00]<br>       [ 6.13063002e+00 -1.27777729e+01]<br>       [-4.77525711e+00 -2.89896202e+00]<br>       [ 5.04258776e+00  1.05476036e+01]<br>       [-4.72102404e+00  4.53035545e+00]<br>       [ 8.30504322e+00 -6.72617435e+00]<br>       [ 1.51879632e+00 -7.57512569e+00]<br>       [ 5.25161076e+00 -6.00039482e+00]<br>       [-2.66712689e+00 -3.15567350e+00]<br>       [ 6.98167515e+00  1.21508999e+01]<br>       [-3.58145714e+00  1.01358452e+01]<br>       [-7.68432474e+00  6.27517796e+00]]</p><pre><code>  [[-3.85787821e+00  4.13319540e+00]   [ 4.08870316e+00  8.98323441e+00]   [ 2.88623333e-01  2.08936238e+00]   [-1.27303381e+01 -3.72204494e+00]   [-1.63620949e-01  4.14640725e-01]   [-9.77903843e+00 -9.83979321e+00]   [ 1.20987940e+01 -1.00569272e+00]   [-9.52555597e-01 -7.21974373e-01]   [-7.53700542e+00 -1.03328714e+01]   [ 3.82278275e+00  7.92873979e-01]   [ 1.62820339e+01  9.25348282e-01]   [-2.99300981e+00 -4.05044317e+00]   [-1.71284425e+00  3.32610369e-01]   [ 8.45957184e+00  3.01560092e+00]   [ 9.61618781e-01  4.84845543e+00]   [-5.04883003e+00 -4.64504576e+00]   [-4.88548994e-01  4.22385454e+00]   [-3.06538558e+00 -2.68467999e+00]   [ 1.44536438e+01 -1.67332339e+00]   [-1.20380235e+00 -3.01969767e-01]   [-1.25808067e+01 -1.83691287e+00]   [ 7.00172246e-01 -5.44080067e+00]   [ 3.71728969e+00 -6.50164127e+00]   [ 3.44825792e+00  2.27989483e+00]   [-1.16813726e+01  3.55064964e+00]   [-6.76289463e+00 -1.25415869e+01]   [ 1.86627662e+00  4.91928959e+00]   [ 2.37216616e+00 -3.23613596e+00]]  [[ 5.60678053e+00  6.07894707e+00]   [-6.23391962e+00 -1.82450306e+00]   [ 6.90571690e+00 -2.60890079e+00]   [ 3.98191905e+00 -2.60109711e+00]   [ 3.79411244e+00 -7.30271769e+00]   [-8.19082737e+00 -4.81762362e+00]   [ 1.01562176e+01 -9.18346643e-02]   [ 5.15106916e-01 -1.88746595e+00]   [-7.10526466e-01  4.75524092e+00]   [ 4.28777647e+00 -4.28609967e-01]   [ 2.94255161e+00 -2.76411390e+00]   [-5.01211119e+00 -1.35121047e-01]   [ 4.88255644e+00  7.48982000e+00]   [-2.94339252e+00 -1.49728453e+00]   [-5.28226614e-01  1.13798523e+01]   [-3.26653433e+00 -1.12711830e+01]   [ 6.92280245e+00  4.46824360e+00]   [-1.07686818e-02  5.99187469e+00]   [-2.30055904e+00 -2.35181737e+00]   [-1.86744165e+00 -9.12775040e-01]   [ 5.70386982e+00  2.56417489e+00]   [-4.37073708e-01 -4.62391090e+00]   [-8.43499756e+00  9.08772826e-01]   [-5.64418888e+00 -5.02650261e+00]   [ 3.92685270e+00 -5.31071186e+00]   [ 6.36297584e-01  2.63665223e+00]   [-7.71557522e+00  4.19800425e+00]   [ 3.64932895e+00  2.46329069e+00]]]</code></pre><p>​<br>     [[[ 6.65752888e-01  3.40558529e-01]<br>       [ 4.08683634e+00  6.27357101e+00]<br>       [-2.77316380e+00  5.83889532e+00]<br>       [-2.01864777e+01 -8.63007069e+00]<br>       [ 4.85101509e+00  1.56102419e-01]<br>       [ 5.13551521e+00  7.00347781e-01]<br>       [ 4.66926765e+00  1.13918304e+01]<br>       [ 1.17937775e+01 -5.75443983e+00]<br>       [ 5.18499660e+00  2.47753906e+01]<br>       [-4.94616604e+00  1.09324312e+00]<br>       [ 7.08940148e-01  5.36628440e-02]<br>       [-6.22777748e+00 -6.08889389e+00]<br>       [ 8.21062326e-01  5.73018026e+00]<br>       [-1.01816578e+01 -5.96292210e+00]<br>       [-3.45601702e+00 -5.80823088e+00]<br>       [-7.81425619e+00 -1.54714165e+01]<br>       [ 6.15157843e+00  4.41321850e+00]<br>       [ 2.28190422e-02 -1.40392697e+00]<br>       [ 5.86180115e+00  2.66614532e+00]<br>       [-1.21994901e+00  6.87365246e+00]<br>       [ 7.62740707e+00 -1.52388859e+00]<br>       [-8.03575134e+00 -1.35383148e+01]<br>       [-1.75186968e+00 -1.95710063e+00]<br>       [-8.72407794e-01 -8.31413174e+00]<br>       [-1.38678074e+01 -3.35018563e+00]<br>       [ 1.02961273e+01  5.95636034e+00]<br>       [ 7.15158939e+00  9.47603941e-01]<br>       [ 3.59655428e+00 -3.57616353e+00]]</p><pre><code>  [[-7.15814590e+00 -1.73663855e-01]   [-5.33630848e+00  2.23019302e-01]   [-3.60880065e+00  1.16919529e+00]   [ 1.65422618e+00  3.21728516e+00]   [ 1.86843979e+00  1.13296022e+01]   [-6.71664524e+00  8.06290245e+00]   [-3.82262254e+00  4.57042742e+00]   [-7.61132431e+00  7.53255653e+00]   [ 1.63969231e+00 -1.19336343e+00]   [ 2.03410006e+00  5.48414516e+00]   [ 7.98875904e+00 -6.00354958e+00]   [ 5.37972260e+00 -3.13939238e+00]   [ 6.52196217e+00  5.99524212e+00]   [-3.65084100e+00  5.70605898e+00]   [ 5.66238022e+00 -4.25603628e-01]   [ 1.31335664e+00  3.34762931e-01]   [ 4.95460320e+00 -7.73174858e+00]   [-6.06322289e-02  7.14966822e+00]   [ 4.30868864e+00 -4.49330187e+00]   [ 3.00062609e+00 -3.45171928e+00]   [-8.88646841e-01  4.49364281e+00]   [-1.37166762e+00 -9.60632420e+00]   [ 2.72169065e+00 -2.02102685e+00]   [ 4.06615162e+00  2.21987987e+00]   [ 4.58932543e+00 -6.33985901e+00]   [-7.59764194e+00 -8.69492054e-01]   [ 6.72914386e-01  3.37907672e-02]   [-9.57373238e+00  4.29612064e+00]]  [[ 2.07057667e+00  2.49500203e+00]   [-2.39765930e+00  6.45140171e-01]   [ 9.70951462e+00  1.52998376e+00]   [ 9.77593803e+00  8.06670094e+00]   [ 8.35551929e+00  7.26291513e+00]   [-9.06231880e-01 -9.31769133e-01]   [-6.77584314e+00  3.27285552e+00]   [ 5.13162661e+00 -5.17782736e+00]   [-3.71608639e+00 -5.12819290e-01]   [ 1.48577709e+01 -2.64512122e-01]   [ 6.44747496e-01 -9.95941162e-02]   [ 1.04961805e+01 -3.98670554e+00]   [ 2.51394081e+00  1.80438447e+00]   [-5.59201813e+00  1.18733444e+01]   [-2.31048003e-01 -1.12039871e+01]   [-1.62683907e+01  2.02177715e+00]   [ 1.14540329e+01  2.30115056e-02]   [-1.10159683e+01 -3.24261713e+00]   [-1.33181334e+01 -8.00105953e+00]   [ 6.21838617e+00  8.89258957e+00]   [ 1.58339548e+00 -2.27107620e+00]   [-4.17989254e-01 -2.85755348e+00]   [-2.48508906e+00  9.64674568e+00]   [-1.08764257e+01  2.08483315e+00]   [ 9.77210236e+00  2.50418329e+00]   [-1.62253022e+00  1.67334347e+01]   [ 6.42501354e-01  2.53464675e+00]   [-1.12935200e+01  3.39891338e+00]]]], shape=(4, 3, 28, 2), dtype=float32)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = tf.random.normal([<span class="number">4</span>,<span class="number">28</span>,<span class="number">32</span>])</span><br><span class="line">b = tf.random.normal([<span class="number">32</span>,<span class="number">16</span>])</span><br><span class="line"><span class="comment"># 先自动扩展，再矩阵相乘</span></span><br><span class="line">tf.matmul(a,b)</span><br></pre></td></tr></table></figure><pre><code>&lt;tf.Tensor: id=503, shape=(4, 28, 16), dtype=float32, numpy=array([[[ -2.7598646 ,   7.0569715 ,  -2.0019226 , ...,  -1.2552259 ,          -5.3215303 ,  -1.2467324 ],        [ -3.5755327 ,  -3.8002384 , -12.492091  , ...,   6.249779  ,          -3.7607257 ,  -2.4373896 ],        [  1.3191882 ,  -4.4746413 ,   2.4289536 , ...,  -1.8787553 ,          -0.10033526,  -1.4797553 ],        ...,        [ -2.0344322 ,   5.086643  ,  -7.6664243 , ...,  -3.0846074 ,          -8.448284  ,  -1.7322202 ],        [  0.57995903,  -3.7676647 ,  -3.6173913 , ...,   7.0568666 ,           2.3793366 ,   3.498049  ],        [  0.5311534 ,   3.0278618 ,   3.9090858 , ...,   4.8734083 ,          -6.3130484 ,  -3.7237642 ]],       [[  4.89592   ,  -2.8002422 ,  -0.7761507 , ...,   9.516954  ,          11.723758  ,  -2.5442433 ],        [ -0.47682646, -13.358232  , -11.200428  , ...,  -0.46236166,          -2.9554985 ,  -1.4849511 ],        [ 11.57021   ,  -8.973025  ,   2.9124722 , ...,  -5.2608457 ,           1.2784045 ,  -5.1128254 ],        ...,        [  2.318095  ,   2.843607  ,   4.602457  , ...,   5.6242056 ,           6.1018414 ,  -5.076501  ],        [ -4.3738413 ,  -5.2155914 ,   8.190216  , ...,  -3.7748199 ,          -4.86178   ,   2.7263112 ],        [ -1.4741284 ,   0.5153975 ,  -2.7228315 , ...,  -0.1337083 ,          -8.092061  ,  -3.1821835 ]],       [[  0.28089905,   9.784105  ,   2.9840403 , ...,   0.33226973,          -0.6826554 ,  -4.040504  ],        [ -5.8831253 ,  12.158736  ,  -7.0445533 , ...,   2.2380865 ,          -8.451615  ,   3.1144416 ],        [-12.613248  , -10.317265  ,  -5.9143896 , ...,  -2.8576682 ,         -10.0681925 ,   6.5913053 ],        ...,        [  5.002187  ,   0.69802207,   4.616313  , ...,   1.8524637 ,           1.6469531 ,   1.4813223 ],        [ -1.0592954 ,  -1.9839575 ,   6.1675334 , ...,  -3.4000485 ,           9.097794  ,   3.3264492 ],        [ -2.3593228 ,  -6.8569756 , -14.06582   , ...,  -9.968381  ,           9.856624  ,   5.7211127 ]],       [[  0.79352164, -12.076045  ,   4.5146046 , ...,  -0.5590708 ,          -0.44884235,   4.5407653 ],        [  3.3152225 ,  -1.2491262 ,   8.590666  , ...,   0.24038552,          12.144938  ,  11.659479  ],        [ -0.8445607 ,   6.594575  ,  -2.8742118 , ...,  -2.4811752 ,           3.3992496 ,   4.638756  ],        ...,        [ -8.9465065 ,  -6.0752807 ,  -4.039912  , ...,  -0.8335391 ,          -3.9777448 ,   3.659201  ],        [  4.1183553 ,   3.9281585 ,  -4.132287  , ...,  -7.197991  ,           5.790247  ,  -8.167656  ],        [ -4.423063  , -20.040358  ,  -9.854829  , ...,  -3.0150864 ,          -5.763957  ,   4.594075  ]]], dtype=float32)&gt;</code></pre><h2 id="前向传播实战"><a href="#前向传播实战" class="headerlink" title="前向传播实战"></a>前向传播实战</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.keras.datasets <span class="keyword">as</span> datasets</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.size&#x27;</span>] = <span class="number">16</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = [<span class="string">&#x27;STKaiti&#x27;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span>():</span></span><br><span class="line">    <span class="comment"># 加载 MNIST 数据集</span></span><br><span class="line">    (x, y), (x_val, y_val) = datasets.mnist.load_data()</span><br><span class="line">    <span class="comment"># 转换为浮点张量， 并缩放到-1~1</span></span><br><span class="line">    x = tf.convert_to_tensor(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    <span class="comment"># 转换为整形张量</span></span><br><span class="line">    y = tf.convert_to_tensor(y, dtype=tf.int32)</span><br><span class="line">    <span class="comment"># one-hot 编码</span></span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 改变视图， [b, 28, 28] =&gt; [b, 28*28]</span></span><br><span class="line">    x = tf.reshape(x, (-<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建数据集对象</span></span><br><span class="line">    train_dataset = tf.data.Dataset.from_tensor_slices((x, y))</span><br><span class="line">    <span class="comment"># 批量训练</span></span><br><span class="line">    train_dataset = train_dataset.batch(<span class="number">200</span>)</span><br><span class="line">    <span class="keyword">return</span> train_dataset</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_paramaters</span>():</span></span><br><span class="line">    <span class="comment"># 每层的张量都需要被优化，故使用 Variable 类型，并使用截断的正太分布初始化权值张量</span></span><br><span class="line">    <span class="comment"># 偏置向量初始化为 0 即可</span></span><br><span class="line">    <span class="comment"># 第一层的参数</span></span><br><span class="line">    w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">    b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))</span><br><span class="line">    <span class="comment"># 第二层的参数</span></span><br><span class="line">    w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">    b2 = tf.Variable(tf.zeros([<span class="number">128</span>]))</span><br><span class="line">    <span class="comment"># 第三层的参数</span></span><br><span class="line">    w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">    b3 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line">    <span class="keyword">return</span> w1, b1, w2, b2, w3, b3</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_epoch</span>(<span class="params">epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=<span class="number">0.001</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataset):</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            <span class="comment"># 第一层计算， [b, 784]@[784, 256] + [256] =&gt; [b, 256] + [256] =&gt; [b,256] + [b, 256]</span></span><br><span class="line">            h1 = x @ w1 + tf.broadcast_to(b1, (x.shape[<span class="number">0</span>], <span class="number">256</span>))</span><br><span class="line">            h1 = tf.nn.relu(h1)  <span class="comment"># 通过激活函数</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 第二层计算， [b, 256] =&gt; [b, 128]</span></span><br><span class="line">            h2 = h1 @ w2 + b2</span><br><span class="line">            h2 = tf.nn.relu(h2)</span><br><span class="line">            <span class="comment"># 输出层计算， [b, 128] =&gt; [b, 10]</span></span><br><span class="line">            out = h2 @ w3 + b3</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算网络输出与标签之间的均方差， mse = mean(sum(y-out)^2)</span></span><br><span class="line">            <span class="comment"># [b, 10]</span></span><br><span class="line">            loss = tf.square(y - out)</span><br><span class="line">            <span class="comment"># 误差标量， mean: scalar</span></span><br><span class="line">            loss = tf.reduce_mean(loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 自动梯度，需要求梯度的张量有[w1, b1, w2, b2, w3, b3]</span></span><br><span class="line">            grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 梯度更新， assign_sub 将当前值减去参数值，原地更新</span></span><br><span class="line">        w1.assign_sub(lr * grads[<span class="number">0</span>])</span><br><span class="line">        b1.assign_sub(lr * grads[<span class="number">1</span>])</span><br><span class="line">        w2.assign_sub(lr * grads[<span class="number">2</span>])</span><br><span class="line">        b2.assign_sub(lr * grads[<span class="number">3</span>])</span><br><span class="line">        w3.assign_sub(lr * grads[<span class="number">4</span>])</span><br><span class="line">        b3.assign_sub(lr * grads[<span class="number">5</span>])    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss.numpy()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epochs</span>):</span></span><br><span class="line">    losses = []</span><br><span class="line">    train_dataset = load_data()</span><br><span class="line">    w1, b1, w2, b2, w3, b3 = init_paramaters()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        loss = train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=<span class="number">0.001</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;epoch:&#x27;</span>, epoch, <span class="string">&#x27;loss:&#x27;</span>, loss)</span><br><span class="line">        losses.append(loss)</span><br><span class="line"></span><br><span class="line">    x = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, epochs)]</span><br><span class="line">    <span class="comment"># 绘制曲线</span></span><br><span class="line">    plt.plot(x, losses, color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, label=<span class="string">&#x27;训练&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epoch&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;MSE&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train(epochs=<span class="number">20</span>)</span><br></pre></td></tr></table></figure><pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz11493376/11490434 [==============================] - 2s 0us/stepepoch: 0 loss: 0.16654462epoch: 1 loss: 0.14800379epoch: 2 loss: 0.13541555epoch: 3 loss: 0.12577298epoch: 4 loss: 0.11817748epoch: 5 loss: 0.11203371epoch: 6 loss: 0.1069127epoch: 7 loss: 0.10258315epoch: 8 loss: 0.09884895epoch: 9 loss: 0.095569395epoch: 10 loss: 0.092678epoch: 11 loss: 0.09010928epoch: 12 loss: 0.0878074epoch: 13 loss: 0.08572935epoch: 14 loss: 0.08384038epoch: 15 loss: 0.0821046epoch: 16 loss: 0.08050328epoch: 17 loss: 0.079019025epoch: 18 loss: 0.07763501findfont: Font family [&#39;STKaiti&#39;] not found. Falling back to DejaVu Sans.epoch: 19 loss: 0.07634819/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 35757 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 32451 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 35757 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 32451 missing from current font.  font.set_text(s, 0, flags=flags)</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210731145651.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Low-Resource Knowledge-Grounded Dialogue Generatio</title>
      <link href="/2021/07/30/Low-Resource%20Knowledge-Grounded%20Dialogue%20Generatio/"/>
      <url>/2021/07/30/Low-Resource%20Knowledge-Grounded%20Dialogue%20Generatio/</url>
      
        <content type="html"><![CDATA[<h1 id="Low-Resource-Knowledge-Grounded-Dialogue-Generatio"><a href="#Low-Resource-Knowledge-Grounded-Dialogue-Generatio" class="headerlink" title="Low-Resource Knowledge-Grounded Dialogue Generatio"></a>Low-Resource Knowledge-Grounded Dialogue Generatio</h1><blockquote><p> <a href="https://arxiv.org/abs/2002.10348">论文：https://arxiv.org/abs/2002.10348</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>以知识为基础的对话，作为反应生成模型的训练数据，很难获得。本文在有限的训练数据下，进行以知识为基础的对话生成。</p><p>在这项工作中，专注于以文档为基础的对话生成，但所提出的方法实际上为低资源知识为基础的对话生成提供了一个通用的解决方案，其中的知识可以是结构化的知识库、图像或视频。要做到这一点，只需要修改知识编码器和知识处理器，使其与特定类型的知识兼容，并预先训练知识编码器。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>在低资源环境下，设计了一个分解反应解码器(disentangled response decoder)，以便从整个生成模型中分离出依赖于knowledge-grounded的对话的参数。通过这种方式，模型的主要部分可以从大量无基础的对话和非结构化文档中学习，而剩余的小参数则可以用有限的训练实例很好地拟合。</p><p>贡献：</p><ul><li>在低资源环境下探索以知识为基础的对话生成</li><li>提出了用无基础的对话和文档对以知识为基础的对话生成模型进行预训练的建议</li><li>在两个基准上对该模型的有效性进行了实证验证</li></ul><p>dataset $D_S$:</p><script type="math/tex; mode=display">D_S= {(U^S_i, D^S_i, r^S_i)}^n_{i=1}</script><p>$D^S_i$：文档</p><p>$U^S_i$：上下文</p><ul><li><script type="math/tex; mode=display">U^S_i=(u^S_{i,1},...u^S_{i,n_i})</script></li></ul><p>$r^S_i$：关于$U^S_i ， D^S_i$的response</p><p>学习目标：生成式模型$P(r|U, D; θ)$</p><p>给定文档D和与之关联的对话上下文U，通过$P(r|U, D; θ)$生成响应r。</p><p>反应的形成可以分解为三个不相关的行为：</p><ul><li>根据已经产生的内容选择一个词，使句子在语言上有效（对应于语言模型）</li><li>根据上下文选择一个词，使对话连贯（对应于上下文处理器）</li><li>根据额外的知识选择一个词，使对话有基础（对应于知识处理器）</li></ul><p><strong>模型结构：*</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210715213320.png" alt="image-20210715213320064"></p><p>组成：context encoder,  knowledge encoder, decoder,  decoding manager</p><p>解码器分解为语言模型、语境处理器和知识处理器。这三个部分的隐藏状态是独立的，由Manager协调。</p><h3 id="ENCODERS"><a href="#ENCODERS" class="headerlink" title="ENCODERS"></a>ENCODERS</h3><p>dialogue context使用GRU编码，将单词序列转化为隐藏层向量序列：</p><script type="math/tex; mode=display">h^u_ 1, . . . , h^u_ i, . . . , h^u _{lu}= GRU_{θe}(e^u_ 1, . . . , e^u_ i, . . . , e^u_{lu}),</script><p>$e^u<em> 1$是$w^u</em> 1$使用GloVe初始化的embedding。</p><p>document使用BiGRU编码：</p><script type="math/tex; mode=display">h^d_ 1, . . . , h^d_ i, . . . , h^d _{ld}= BiGRU_{θk}(e^d_ {i,1}, . . . , e^d_ {i,j}, . . . , e^d_{i,ld}),</script><p>$e^d_{i,j}$是第j个单词使用GloVe初始化的embedding。</p><p>编码阶段没有进行knowledge selection，这可以消除上下文编码和知识编码之间的依赖性。</p><h3 id="DISENTANGLED-DECODER"><a href="#DISENTANGLED-DECODER" class="headerlink" title="DISENTANGLED DECODER"></a>DISENTANGLED DECODER</h3><p>解码器维护隐藏的序列${s<em>t}^{l_r}</em>{t=1}$表示t-1步的单词预测embedding，$s_t$定义为：</p><script type="math/tex; mode=display">s_t= GRU_{θd}(e^r_{ t−1}, s_{t−1})</script><h3 id="DECODING-MANAGER"><a href="#DECODING-MANAGER" class="headerlink" title="DECODING MANAGER"></a>DECODING MANAGER</h3><p>三个decoder组件由解码管理器控制，在响应预测的每一步都有一个组件被拾起。</p><p>使用了一个Gumbel trick $π_t$，定义为：</p><script type="math/tex; mode=display">π_t= gumbel\ softmax(f_π(s_{t−1}), τ)</script><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>Wizard of Wikipedia (Wizard)</li><li>CMU Document Grounded Conversations(CMU DoG)</li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><ul><li>Wizard respectively</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210717113229.png" alt="image-20210717113229400"></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210717113305.png" alt="image-20210717113305198"></p><ul><li>CMU DoG</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210717113348.png" alt="image-20210717113348840"></p><p>即使数据集缩小，Test Unseen性能相比于Test seen依然稳定，与基线模型相比Test Unseen性能提升更加显著。</p><p>ITDD在Test Seen和CMU DoG上都取得了较低的PPL，这可能是由于two_pass解码器的过度拟合。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文研究了在低资源环境下以知识为基础的对话生成。为了克服训练数据不足带来的挑战，将响应解码器分解为独立的组件，其中大部分参数不再依赖训练数据，可以从大规模的无基础对话和非结构化文档中估计出来。对两个基准的评估结果表明，模型在只有1/8的训练数据的情况下达到了最先进的性能，并且对领域外的知识表现出良好的泛化能力。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Low-Resource </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ubuntu开启ssh服务远程登录</title>
      <link href="/2021/07/30/ubuntu%E5%BC%80%E5%90%AFssh%E6%9C%8D%E5%8A%A1%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95/"/>
      <url>/2021/07/30/ubuntu%E5%BC%80%E5%90%AFssh%E6%9C%8D%E5%8A%A1%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h1 id="ubuntu开启ssh服务远程登录"><a href="#ubuntu开启ssh服务远程登录" class="headerlink" title="ubuntu开启ssh服务远程登录"></a>ubuntu开启ssh服务远程登录</h1><p><strong>1. 查看当前的ubuntu是否安装了ssh-server服务。默认只安装ssh-client服务</strong><br><code>dpkg -l | grep ssh</code></p><p><strong>2. 安装ssh-server服务</strong><br><code>sudo apt-get install openssh-server</code></p><p>然后确认ssh-server是否启动了：</p><p><code>ps -e | grep ssh</code></p><p>如果看到sshd那说明ssh-server已经启动了。如果没有则可以这样启动：</p><p><code>sudo /etc/init.d/ssh start</code>或<code>sudo service ssh start</code></p><p><strong>3. 登陆SSH（Linux）</strong><br><code>ssh username@192.168.1.103</code><br>其中，username为192.168.1.103机器上的用户，需要输入密码。<br>断开连接：exit</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210730183519.png" alt="image-20210730183519466" style="zoom:50%;" /></p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ssh </tag>
            
            <tag> ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>服务器 jupyter notebook配置</title>
      <link href="/2021/07/30/%E6%9C%8D%E5%8A%A1%E5%99%A8%20jupyter%20notebook%E9%85%8D%E7%BD%AE/"/>
      <url>/2021/07/30/%E6%9C%8D%E5%8A%A1%E5%99%A8%20jupyter%20notebook%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="服务器-jupyter-notebook配置"><a href="#服务器-jupyter-notebook配置" class="headerlink" title="服务器 jupyter notebook配置"></a>服务器 jupyter notebook配置</h1><p><strong>1. 建立config文件</strong></p><p><code>jupyter notebook --generate-config</code></p><p><strong>2. 进入.jupyter文件夹</strong></p><p><code>cd ~/.jupyter</code></p><p><strong>3. 打开 jupyter_notebook_config.py文件</strong></p><p><code>vim jupyter_notebook_config.py</code></p><p><strong>4. 修改jupyter_notebook_config.py文件，添加如下命令</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">#获取配置</span><br><span class="line">c = get_config()</span><br><span class="line">#设置为 * 表示所有 IP 都可以访问</span><br><span class="line">c.NotebookApp.ip = &#x27;*&#x27;</span><br><span class="line">#禁止Notebook 启动时自动打开浏览器</span><br><span class="line">c.NotebookApp.open_browser = False</span><br><span class="line">#指定访问的端口，默认是8888,自己设置一个即可</span><br><span class="line">c.NotebookApp.port = 6006</span><br><span class="line">#全0表示接受任何IP地址的访问</span><br><span class="line">c.ConnectionFileMixin.ip = &#x27;0.0.0.0&#x27;</span><br><span class="line">#允许远程访问</span><br><span class="line">c.NotebookApp.allow_remote_access = True</span><br></pre></td></tr></table></figure><p><strong>5. 尝试打开jupyter notebook</strong></p><p><code>jupyter notebook --ip=服务器ip</code></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210730182424.png" alt="image-20210730182424455"></p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ubuntu </tag>
            
            <tag> jupyter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cross-Lingual Machine Reading Comprehension</title>
      <link href="/2021/07/23/Cross-Lingual%20Machine%20Reading%20Comprehension/"/>
      <url>/2021/07/23/Cross-Lingual%20Machine%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="Cross-Lingual-Machine-Reading-Comprehension"><a href="#Cross-Lingual-Machine-Reading-Comprehension" class="headerlink" title="Cross-Lingual Machine Reading Comprehension"></a>Cross-Lingual Machine Reading Comprehension</h1><blockquote><p> <a href="https://arxiv.org/abs/1909.00361">论文：https://arxiv.org/abs/1909.00361</a></p><p> <a href="https://github.com/ymcui/Cross-Lingual-MRC">代码：https://github.com/ymcui/Cross-Lingual-MRC</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><ul><li>虽然机器阅读理解研究得到了飞速发展，多数工作面向的是英文数据，而忽略了机器阅读理解在其他语言上的表现，其根本原因在于大规模训练数据的缺失。本文提出跨语言机器阅读理解（Cross-Lingual MachineReading Comprehension，CLMRC）任务来解决非英文下的机器阅读理解。</li><li>本文所提出的方法具有良好的通用性，可适配多种机器阅读理解任务。在本文中将着重解决基于篇章片段抽取的机器阅读理解（Span-Extraction MRC），这也是目前在该领域中研究最为广泛的任务之一。该任务需要对&lt;篇章，问题&gt;进行建模，并从篇章中抽取出一个连续的片段作为答案。最广为熟知的是由斯坦福大学提出的SQuAD（Stanford Question Answering Dataset）数据集。</li><li>利用英文（源语言）数据来提升中文（目标语言）机器阅读理解系统效果。</li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><ul><li><p>首先给出了基于回译（Back-Translation）的跨语言阅读理解方法来解决目标语言没有训练数据的情况。</p></li><li><p>对于目标语言存在一定的训练数据时，创新地提出了Dual BERT模型来进一步借用富资源语言（例如：英文）的训练数据来帮助低资源语言下的机器阅读理解效果。该模型能够对&lt;篇章，问题&gt;在双语环境中建模，并且最终融合成一种统一的语义表示，进而得到更加精准的答案预测。</p></li></ul><p>主要贡献：</p><ol><li>提出了跨语言机器阅读理解任务来进一步提升低资源语言下的机器阅读理解系统效果</li><li>提出了Dual BERT模型，对输入文本和问题在双语环境中建模，进一步丰富了语义表示</li><li>所提出的Dual BERT模型在两个中文机器阅读理解数据集上获得state-of-the-art效果</li></ol><h3 id="Back-Translation-Approaches"><a href="#Back-Translation-Approaches" class="headerlink" title="Back-Translation Approaches"></a>Back-Translation Approaches</h3><ul><li>源语言：具有大规模的语料资源的语种。我们需要从该语种的资源中抽取出丰富的知识。下文中使用下标S来代表源语言变量。</li><li>目标语言：希望优化系统性能的语种，即目标系统的语种。该语种没有可用或仅有少量的语料资源。下文中使用下标T来代表目标语言变量。</li></ul><p>本文利用英文（源语言）数据来提升中文（目标语言）机器阅读理解系统效果。</p><h3 id="several-back-translation-approaches"><a href="#several-back-translation-approaches" class="headerlink" title="several back-translation approaches"></a>several back-translation approaches</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210721102357.png" alt="image-20210721102357216"></p><h4 id="GNMT"><a href="#GNMT" class="headerlink" title="GNMT"></a>GNMT</h4><blockquote><p>(Google Neural MachineTranslation,GNMT)</p></blockquote><p>使用翻译系统来实现跨语言机器阅读理解是很直接的方法，主要流程（Figure1 left）：</p><ol><li>将目标语言输入&lt;篇章，问题&gt;翻译成源语言</li><li>通过源语言的阅读理解系统得到一个源语言的答案</li><li>将源语言答案回译为目标语言</li></ol><p><strong>存在问题：</strong>经过回译的答案不一定是原文中的某个精准片段。</p><p><strong>解决方法：</strong></p><h4 id="Simple-Match"><a href="#Simple-Match" class="headerlink" title="Simple Match"></a>Simple Match</h4><p>利用滑动窗口在目标语言篇章中进行滑动，假设翻译出的答案与真实答案长度基本相似，由此计算出候选span和翻译答案的F1-score，从这些窗口中选取一个字级别F1-score最高的窗口作为最终的预测答案C。使用所提出的SimpleMatch可以确保预测的答案是目标段落中的精确跨度。</p><h4 id="Answer-Aligner"><a href="#Answer-Aligner" class="headerlink" title="Answer Aligner"></a>Answer Aligner</h4><blockquote><p>Figure 1 middle</p></blockquote><p>如果目标语言有一定量的训练数据，那么可以进一步提升答案对齐的效果。将对齐后的答案C与目标语言篇章P输入到BERT中，并以目标语言真实答案作为目标进行训练，就可以得到答案对齐器（Answer Aligner）。</p><h4 id="Answer-Verifier"><a href="#Answer-Verifier" class="headerlink" title="Answer Verifier"></a>Answer Verifier</h4><blockquote><p>Figure 1 right</p></blockquote><p>在答案对齐器的基础上进一步加入目标语言问题Q，即可成为答案验证器（Answer Verifier），使用翻译答案验证正确性。</p><h3 id="Dual-BERT"><a href="#Dual-BERT" class="headerlink" title="Dual BERT"></a>Dual BERT</h3><blockquote><p>适用于目标语言存在一定的训练数据的情况。</p></blockquote><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210722214244.png" alt="image-20210722214244596"></p><h4 id="Dual-Encoder"><a href="#Dual-Encoder" class="headerlink" title="Dual Encoder"></a>Dual Encoder</h4><p>本文使用BERT作为文本表示模型,对于给定的目标语言篇章$P_T$和问题$Q_T$，BERT的输入$X_T$可以表示为:</p><script type="math/tex; mode=display">[CLS] \ Q_T \ [SEP]\ P_T\ [SEP]</script><p>利用GNMT系统，可以将目标语言数据翻译成源语言，从而获得源语言输入$X_S$。经过BERT编码后，分别获得目标语言表示$B_T$和源语言表示$B_S$。</p><h4 id="Bilingual-Decoder"><a href="#Bilingual-Decoder" class="headerlink" title="Bilingual Decoder"></a>Bilingual Decoder</h4><blockquote><p>双语解码器</p></blockquote><p>为了将源语言表示融合到目标语言表示中，提出了一种自适应注意力机制（Self-Adaptive Attention, SAA）。</p><p>在原始Attention矩阵计算：</p><script type="math/tex; mode=display">A_{T S}= B_T· B_S^\mathsf{T}</script><p>修改后：</p><script type="math/tex; mode=display">A_{T}= sotmax(B_T· B_T^\mathsf{T})</script><script type="math/tex; mode=display">A_{S}= sotmax(B_S· B_S^\mathsf{T})</script><script type="math/tex; mode=display">\hat{A}_{T S}= A_T· A_{TS}·A_S^\mathsf{T}</script><p>该操作的目的是，在$B_T$和$B_S$计算注意力之前，首先让$B_T$和$B_S$先对自身进行Self-attention计算，过滤掉相对无用的部分，然后再计算两者之间的注意力，从而进一步提升注意力计算的精准度。</p><p>得到Attended表示$R’$后，并进一步通过残差连接（Residual Connection）和层归一化（Layer Normalization）获得最终的表示$H_T$。</p><script type="math/tex; mode=display">R’=softmax(\hat{A}_{TS})·B_S</script><script type="math/tex; mode=display">R = W_rR'+ b_r</script><script type="math/tex; mode=display">H_T= concat[B_T, LayerNorm(B_T+ R)]</script><p>最终利用$H_T$计算目标语言上的开始和结尾指针并计算对应的交叉熵损失。</p><h4 id="Auxiliary-Output"><a href="#Auxiliary-Output" class="headerlink" title="Auxiliary Output"></a>Auxiliary Output</h4><blockquote><p>辅助损失</p></blockquote><p>同时对源语言进行预测并计算对应的交叉熵$L<em>{aux}$作为辅助损失。最终的损失函数为$L=L_T+\lambda L</em>{aux}$，其中λ∈[0,1]为比例系数。源语言是经过翻译得到的，存在一定的信息缺失，$\lambda$为动态计算，控制辅助损失对主损失的影响。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><blockquote><p>两个篇章片段抽取型（Span-Extraction）中文机器阅读理解数据集</p></blockquote><p>CMRC 2018（简体中文）</p><p>DRCD（繁体中文）</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>实验结果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210722221231.png" alt="image-20210722221231365"></p><ul><li>基于回译的系统中，简单匹配能够带来显著性能提升；在有一定训练数据的情况下，答案验证器和答案验证器能够进一步带来性能提升</li><li>采用源语言预训练的模型对目标语言的机器阅读理解系统有显著性能提升</li><li>Dual BERT的双语建模能够在上述基础上带来进一步的性能提升</li></ul><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p><strong>阅读理解系统性能提升：</strong></p><ul><li><p>在数据量差异不大的情况下，无需根据语种的远近选择源语言数据；</p></li><li><p>在数据量差异较大的情况下，应首要考虑源语言数据的规模而非语种的远近。</p></li></ul><p>在两个中文机器阅读理解数据集上验证得知该方法能够显著提升低资源下的机器阅读理解效果，为未来低资源下的机器阅读理解提供了一种解决方案。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Low-Resource </tag>
            
            <tag> CLMRC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用sklearn对文档进行向量化的程序</title>
      <link href="/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E5%AF%B9%E6%96%87%E6%A1%A3%E8%BF%9B%E8%A1%8C%E5%90%91%E9%87%8F%E5%8C%96%E7%9A%84%E7%A8%8B%E5%BA%8F/"/>
      <url>/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E5%AF%B9%E6%96%87%E6%A1%A3%E8%BF%9B%E8%A1%8C%E5%90%91%E9%87%8F%E5%8C%96%E7%9A%84%E7%A8%8B%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="使用sklearn对文档进行向量化的程序"><a href="#使用sklearn对文档进行向量化的程序" class="headerlink" title="使用sklearn对文档进行向量化的程序"></a>使用sklearn对文档进行向量化的程序</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">演示内容：文档的向量化</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">corpus = [</span><br><span class="line"><span class="string">&#x27;Jobs was the chairman of Apple Inc., and he was very famous&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;I like to use apple computer&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;And I also like to eat apple&#x27;</span></span><br><span class="line">] </span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#未经停用词过滤的文档向量化</span></span><br><span class="line">vectorizer =CountVectorizer()</span><br><span class="line"><span class="built_in">print</span>(vectorizer.fit_transform(corpus).todense())  <span class="comment">#转化为完整特征矩阵</span></span><br><span class="line"><span class="built_in">print</span>(vectorizer.vocabulary_)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>[[0 1 1 1 0 0 1 1 1 1 0 1 1 0 0 1 2] [0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0] [1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0]]&#123;&#39;jobs&#39;: 9, &#39;was&#39;: 16, &#39;the&#39;: 12, &#39;chairman&#39;: 3, &#39;of&#39;: 11, &#39;apple&#39;: 2, &#39;inc&#39;: 8, &#39;and&#39;: 1, &#39;he&#39;: 7, &#39;very&#39;: 15, &#39;famous&#39;: 6, &#39;like&#39;: 10, &#39;to&#39;: 13, &#39;use&#39;: 14, &#39;computer&#39;: 4, &#39;also&#39;: 0, &#39;eat&#39;: 5&#125;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#经过停用词过滤后的文档向量化</span></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download(<span class="string">&#x27;stopwords&#x27;</span>)</span><br><span class="line">stopwords = nltk.corpus.stopwords.words(<span class="string">&#x27;english&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> (stopwords)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line">vectorizer =CountVectorizer(stop_words=<span class="string">&#x27;english&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;after stopwords removal:  &quot;</span>, vectorizer.fit_transform(corpus).todense())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;after stopwords removal:  &quot;</span>, vectorizer.vocabulary_)</span><br></pre></td></tr></table></figure><pre><code>[nltk_data] Downloading package stopwords to /Users/maqi/nltk_data...[&#39;i&#39;, &#39;me&#39;, &#39;my&#39;, &#39;myself&#39;, &#39;we&#39;, &#39;our&#39;, &#39;ours&#39;, &#39;ourselves&#39;, &#39;you&#39;, &quot;you&#39;re&quot;, &quot;you&#39;ve&quot;, &quot;you&#39;ll&quot;, &quot;you&#39;d&quot;, &#39;your&#39;, &#39;yours&#39;, &#39;yourself&#39;, &#39;yourselves&#39;, &#39;he&#39;, &#39;him&#39;, &#39;his&#39;, &#39;himself&#39;, &#39;she&#39;, &quot;she&#39;s&quot;, &#39;her&#39;, &#39;hers&#39;, &#39;herself&#39;, &#39;it&#39;, &quot;it&#39;s&quot;, &#39;its&#39;, &#39;itself&#39;, &#39;they&#39;, &#39;them&#39;, &#39;their&#39;, &#39;theirs&#39;, &#39;themselves&#39;, &#39;what&#39;, &#39;which&#39;, &#39;who&#39;, &#39;whom&#39;, &#39;this&#39;, &#39;that&#39;, &quot;that&#39;ll&quot;, &#39;these&#39;, &#39;those&#39;, &#39;am&#39;, &#39;is&#39;, &#39;are&#39;, &#39;was&#39;, &#39;were&#39;, &#39;be&#39;, &#39;been&#39;, &#39;being&#39;, &#39;have&#39;, &#39;has&#39;, &#39;had&#39;, &#39;having&#39;, &#39;do&#39;, &#39;does&#39;, &#39;did&#39;, &#39;doing&#39;, &#39;a&#39;, &#39;an&#39;, &#39;the&#39;, &#39;and&#39;, &#39;but&#39;, &#39;if&#39;, &#39;or&#39;, &#39;because&#39;, &#39;as&#39;, &#39;until&#39;, &#39;while&#39;, &#39;of&#39;, &#39;at&#39;, &#39;by&#39;, &#39;for&#39;, &#39;with&#39;, &#39;about&#39;, &#39;against&#39;, &#39;between&#39;, &#39;into&#39;, &#39;through&#39;, &#39;during&#39;, &#39;before&#39;, &#39;after&#39;, &#39;above&#39;, &#39;below&#39;, &#39;to&#39;, &#39;from&#39;, &#39;up&#39;, &#39;down&#39;, &#39;in&#39;, &#39;out&#39;, &#39;on&#39;, &#39;off&#39;, &#39;over&#39;, &#39;under&#39;, &#39;again&#39;, &#39;further&#39;, &#39;then&#39;, &#39;once&#39;, &#39;here&#39;, &#39;there&#39;, &#39;when&#39;, &#39;where&#39;, &#39;why&#39;, &#39;how&#39;, &#39;all&#39;, &#39;any&#39;, &#39;both&#39;, &#39;each&#39;, &#39;few&#39;, &#39;more&#39;, &#39;most&#39;, &#39;other&#39;, &#39;some&#39;, &#39;such&#39;, &#39;no&#39;, &#39;nor&#39;, &#39;not&#39;, &#39;only&#39;, &#39;own&#39;, &#39;same&#39;, &#39;so&#39;, &#39;than&#39;, &#39;too&#39;, &#39;very&#39;, &#39;s&#39;, &#39;t&#39;, &#39;can&#39;, &#39;will&#39;, &#39;just&#39;, &#39;don&#39;, &quot;don&#39;t&quot;, &#39;should&#39;, &quot;should&#39;ve&quot;, &#39;now&#39;, &#39;d&#39;, &#39;ll&#39;, &#39;m&#39;, &#39;o&#39;, &#39;re&#39;, &#39;ve&#39;, &#39;y&#39;, &#39;ain&#39;, &#39;aren&#39;, &quot;aren&#39;t&quot;, &#39;couldn&#39;, &quot;couldn&#39;t&quot;, &#39;didn&#39;, &quot;didn&#39;t&quot;, &#39;doesn&#39;, &quot;doesn&#39;t&quot;, &#39;hadn&#39;, &quot;hadn&#39;t&quot;, &#39;hasn&#39;, &quot;hasn&#39;t&quot;, &#39;haven&#39;, &quot;haven&#39;t&quot;, &#39;isn&#39;, &quot;isn&#39;t&quot;, &#39;ma&#39;, &#39;mightn&#39;, &quot;mightn&#39;t&quot;, &#39;mustn&#39;, &quot;mustn&#39;t&quot;, &#39;needn&#39;, &quot;needn&#39;t&quot;, &#39;shan&#39;, &quot;shan&#39;t&quot;, &#39;shouldn&#39;, &quot;shouldn&#39;t&quot;, &#39;wasn&#39;, &quot;wasn&#39;t&quot;, &#39;weren&#39;, &quot;weren&#39;t&quot;, &#39;won&#39;, &quot;won&#39;t&quot;, &#39;wouldn&#39;, &quot;wouldn&#39;t&quot;]after stopwords removal:   [[1 1 0 0 1 1 0 0] [1 0 1 0 0 0 1 1] [1 0 0 1 0 0 1 0]]after stopwords removal:   &#123;&#39;jobs&#39;: 5, &#39;chairman&#39;: 1, &#39;apple&#39;: 0, &#39;famous&#39;: 4, &#39;like&#39;: 6, &#39;use&#39;: 7, &#39;computer&#39;: 2, &#39;eat&#39;: 3&#125;[nltk_data]   Unzipping corpora/stopwords.zip.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"><span class="comment">#采用ngram模式进行文档向量化</span></span><br><span class="line">vectorizer =CountVectorizer(ngram_range=(<span class="number">1</span>,<span class="number">2</span>))<span class="comment">#表示从1-2，既包括unigram，也包括bigram</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;N-gram mode:     &quot;</span>,vectorizer.fit_transform(corpus).todense())  <span class="comment">#转化为完整特征矩阵</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;N-gram mode:         &quot;</span>,vectorizer.vocabulary_)</span><br></pre></td></tr></table></figure><pre><code>N-gram mode:      [[0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 2 1 1] [0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0] [1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0]]N-gram mode:          &#123;&#39;jobs&#39;: 18, &#39;was&#39;: 33, &#39;the&#39;: 24, &#39;chairman&#39;: 8, &#39;of&#39;: 22, &#39;apple&#39;: 5, &#39;inc&#39;: 16, &#39;and&#39;: 2, &#39;he&#39;: 14, &#39;very&#39;: 31, &#39;famous&#39;: 13, &#39;jobs was&#39;: 19, &#39;was the&#39;: 34, &#39;the chairman&#39;: 25, &#39;chairman of&#39;: 9, &#39;of apple&#39;: 23, &#39;apple inc&#39;: 7, &#39;inc and&#39;: 17, &#39;and he&#39;: 4, &#39;he was&#39;: 15, &#39;was very&#39;: 35, &#39;very famous&#39;: 32, &#39;like&#39;: 20, &#39;to&#39;: 26, &#39;use&#39;: 29, &#39;computer&#39;: 10, &#39;like to&#39;: 21, &#39;to use&#39;: 28, &#39;use apple&#39;: 30, &#39;apple computer&#39;: 6, &#39;also&#39;: 0, &#39;eat&#39;: 11, &#39;and also&#39;: 3, &#39;also like&#39;: 1, &#39;to eat&#39;: 27, &#39;eat apple&#39;: 12&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
            <tag> 文档向量化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用sklearn进行线性回归和二次回归的比较程序</title>
      <link href="/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E8%BF%9B%E8%A1%8C%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%92%8C%E4%BA%8C%E6%AC%A1%E5%9B%9E%E5%BD%92%E7%9A%84%E6%AF%94%E8%BE%83%E7%A8%8B%E5%BA%8F/"/>
      <url>/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E8%BF%9B%E8%A1%8C%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%92%8C%E4%BA%8C%E6%AC%A1%E5%9B%9E%E5%BD%92%E7%9A%84%E6%AF%94%E8%BE%83%E7%A8%8B%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="使用sklearn进行线性回归和二次回归的比较程序"><a href="#使用sklearn进行线性回归和二次回归的比较程序" class="headerlink" title="使用sklearn进行线性回归和二次回归的比较程序"></a>使用sklearn进行线性回归和二次回归的比较程序</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">#演示内容：二次回归和线性回归的拟合效果的对比</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(__doc__)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line">font_set = FontProperties(fname=<span class="string">r&quot;/System/Library/Fonts/STHeiti Medium.ttc&quot;</span>, size=<span class="number">20</span>) </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runplt</span>():</span></span><br><span class="line">    plt.figure()<span class="comment"># 定义figure</span></span><br><span class="line">    plt.title(<span class="string">u&#x27;披萨的价格和直径&#x27;</span>,fontproperties=font_set)</span><br><span class="line">    plt.xlabel(<span class="string">u&#x27;直径（inch）&#x27;</span>,fontproperties=font_set)</span><br><span class="line">    plt.ylabel(<span class="string">u&#x27;价格（美元）&#x27;</span>,fontproperties=font_set)</span><br><span class="line">    plt.axis([<span class="number">0</span>, <span class="number">25</span>, <span class="number">0</span>, <span class="number">25</span>])</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> plt</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>#演示内容：二次回归和线性回归的拟合效果的对比</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#训练集和测试集数据</span></span><br><span class="line">X_train = [[<span class="number">6</span>], [<span class="number">8</span>], [<span class="number">10</span>], [<span class="number">14</span>], [<span class="number">18</span>]]</span><br><span class="line">y_train = [[<span class="number">7</span>], [<span class="number">9</span>], [<span class="number">13</span>], [<span class="number">17.5</span>], [<span class="number">18</span>]]</span><br><span class="line">X_test = [[<span class="number">7</span>], [<span class="number">9</span>], [<span class="number">11</span>], [<span class="number">15</span>]]</span><br><span class="line">y_test = [[<span class="number">8</span>], [<span class="number">12</span>], [<span class="number">15</span>], [<span class="number">18</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment">#画出横纵坐标以及若干散点图</span></span><br><span class="line">plt1 = runplt()</span><br><span class="line">plt1.scatter(X_train, y_train,s=<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#给出一些点，并画出线性回归的曲线</span></span><br><span class="line">xx = np.linspace(<span class="number">0</span>, <span class="number">26</span>, <span class="number">5</span>)</span><br><span class="line">regressor = LinearRegression()</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line">yy = regressor.predict(xx.reshape(xx.shape[<span class="number">0</span>], <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">plt.plot(xx, yy, label=<span class="string">&quot;linear equation&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#多项式回归（本例中为二次回归）</span></span><br><span class="line"><span class="comment">#首先生成多项式特征</span></span><br><span class="line">quadratic_featurizer = PolynomialFeatures(degree=<span class="number">2</span>)</span><br><span class="line">X_train_quadratic = quadratic_featurizer.fit_transform(X_train)</span><br><span class="line"></span><br><span class="line">regressor_quadratic = LinearRegression()</span><br><span class="line">regressor_quadratic.fit(X_train_quadratic, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#numpy.reshape（重塑）给数组一个新的形状而不改变其数据。在指定的间隔内返回均匀间隔的数字</span></span><br><span class="line"><span class="comment">#给出一些点，并画出线性回归的曲线</span></span><br><span class="line">xx = np.linspace(<span class="number">0</span>, <span class="number">26</span>, <span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span> (xx.shape)</span><br><span class="line"><span class="built_in">print</span> (xx.shape[<span class="number">0</span>])</span><br><span class="line">xx_quadratic = quadratic_featurizer.transform(xx.reshape(xx.shape[<span class="number">0</span>], <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span> (xx.reshape(xx.shape[<span class="number">0</span>], <span class="number">1</span>).shape)</span><br><span class="line"></span><br><span class="line">plt.plot(xx, regressor_quadratic.predict(xx_quadratic), <span class="string">&#x27;r-&#x27;</span>,label=<span class="string">&quot;quadratic equation&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">X_test_quadratic = quadratic_featurizer.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算R^2得分 得分越高越好</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;linear equation  r-squared&#x27;</span>, regressor.score(X_test, y_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;quadratic equation r-squared&#x27;</span>, regressor_quadratic.score(X_test_quadratic, y_test))</span><br></pre></td></tr></table></figure><pre><code>(5,)5(5, 1)</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210714231113.png" alt="output_2_1"></p><pre><code>linear equation  r-squared 0.8283656795834485quadratic equation r-squared 0.9785451046983036</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
            <tag> 线性回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用sklearn进行量纲缩放的程序</title>
      <link href="/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E8%BF%9B%E8%A1%8C%E9%87%8F%E7%BA%B2%E7%BC%A9%E6%94%BE%E7%9A%84%E7%A8%8B%E5%BA%8F/"/>
      <url>/2021/07/14/%E4%BD%BF%E7%94%A8sklearn%E8%BF%9B%E8%A1%8C%E9%87%8F%E7%BA%B2%E7%BC%A9%E6%94%BE%E7%9A%84%E7%A8%8B%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="使用sklearn进行量纲缩放的程序"><a href="#使用sklearn进行量纲缩放的程序" class="headerlink" title="使用sklearn进行量纲缩放的程序"></a>使用sklearn进行量纲缩放的程序</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">演示内容：量纲的特征缩放</span></span><br><span class="line"><span class="string">（两种方法：标准化缩放法和区间缩放法。每种方法举了两个例子：简单二维矩阵和iris数据集）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment">#方法1：标准化缩放法 例1：对简单示例二维矩阵的列数据进行</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing   </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="comment">#采用numpy的array表示，因为要用到其mean等函数，而list没有这些函数</span></span><br><span class="line">X = np.array([[<span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">100</span>, <span class="number">1</span>], </span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>]])  </span><br><span class="line"><span class="comment"># calculate mean  </span></span><br><span class="line">X_mean = X.mean(axis=<span class="number">0</span>)  </span><br><span class="line"><span class="comment"># calculate variance   </span></span><br><span class="line">X_std = X.std(axis=<span class="number">0</span>)  </span><br><span class="line"><span class="comment">#print (X_std)</span></span><br><span class="line"><span class="comment"># standardize X  </span></span><br><span class="line">X1 = (X-X_mean)/X_std</span><br><span class="line"><span class="built_in">print</span> (X1)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># we can also use function preprocessing.scale to standardize X  </span></span><br><span class="line">X_scale = preprocessing.scale(X)  </span><br><span class="line"><span class="built_in">print</span> (X_scale)</span><br></pre></td></tr></table></figure><pre><code>[[-0.58504784 -1.        ] [-0.58504784 -1.        ] [ 1.73197332  1.        ] [-0.56187763  1.        ]][[-0.58504784 -1.        ] [-0.58504784 -1.        ] [ 1.73197332  1.        ] [-0.56187763  1.        ]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#方法1： 标准化缩放法 例2：对iris数据二维矩阵的列数据进行。这次采用一个集成的方法StandardScaler</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X_scale = preprocessing.scale(iris.data)  </span><br><span class="line"><span class="built_in">print</span> (X_scale)</span><br></pre></td></tr></table></figure><pre><code>[[-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.31544430e+00] [-1.14301691e+00 -1.31979479e-01 -1.34022653e+00 -1.31544430e+00] [-1.38535265e+00  3.28414053e-01 -1.39706395e+00 -1.31544430e+00] [-1.50652052e+00  9.82172869e-02 -1.28338910e+00 -1.31544430e+00] [-1.02184904e+00  1.24920112e+00 -1.34022653e+00 -1.31544430e+00] [-5.37177559e-01  1.93979142e+00 -1.16971425e+00 -1.05217993e+00] [-1.50652052e+00  7.88807586e-01 -1.34022653e+00 -1.18381211e+00] [-1.02184904e+00  7.88807586e-01 -1.28338910e+00 -1.31544430e+00] [-1.74885626e+00 -3.62176246e-01 -1.34022653e+00 -1.31544430e+00] [-1.14301691e+00  9.82172869e-02 -1.28338910e+00 -1.44707648e+00] [-5.37177559e-01  1.47939788e+00 -1.28338910e+00 -1.31544430e+00] [-1.26418478e+00  7.88807586e-01 -1.22655167e+00 -1.31544430e+00] [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.44707648e+00] [-1.87002413e+00 -1.31979479e-01 -1.51073881e+00 -1.44707648e+00] [-5.25060772e-02  2.16998818e+00 -1.45390138e+00 -1.31544430e+00] [-1.73673948e-01  3.09077525e+00 -1.28338910e+00 -1.05217993e+00] [-5.37177559e-01  1.93979142e+00 -1.39706395e+00 -1.05217993e+00] [-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.18381211e+00] [-1.73673948e-01  1.70959465e+00 -1.16971425e+00 -1.18381211e+00] [-9.00681170e-01  1.70959465e+00 -1.28338910e+00 -1.18381211e+00] [-5.37177559e-01  7.88807586e-01 -1.16971425e+00 -1.31544430e+00] [-9.00681170e-01  1.47939788e+00 -1.28338910e+00 -1.05217993e+00] [-1.50652052e+00  1.24920112e+00 -1.56757623e+00 -1.31544430e+00] [-9.00681170e-01  5.58610819e-01 -1.16971425e+00 -9.20547742e-01] [-1.26418478e+00  7.88807586e-01 -1.05603939e+00 -1.31544430e+00] [-1.02184904e+00 -1.31979479e-01 -1.22655167e+00 -1.31544430e+00] [-1.02184904e+00  7.88807586e-01 -1.22655167e+00 -1.05217993e+00] [-7.79513300e-01  1.01900435e+00 -1.28338910e+00 -1.31544430e+00] [-7.79513300e-01  7.88807586e-01 -1.34022653e+00 -1.31544430e+00] [-1.38535265e+00  3.28414053e-01 -1.22655167e+00 -1.31544430e+00] [-1.26418478e+00  9.82172869e-02 -1.22655167e+00 -1.31544430e+00] [-5.37177559e-01  7.88807586e-01 -1.28338910e+00 -1.05217993e+00] [-7.79513300e-01  2.40018495e+00 -1.28338910e+00 -1.44707648e+00] [-4.16009689e-01  2.63038172e+00 -1.34022653e+00 -1.31544430e+00] [-1.14301691e+00  9.82172869e-02 -1.28338910e+00 -1.31544430e+00] [-1.02184904e+00  3.28414053e-01 -1.45390138e+00 -1.31544430e+00] [-4.16009689e-01  1.01900435e+00 -1.39706395e+00 -1.31544430e+00] [-1.14301691e+00  1.24920112e+00 -1.34022653e+00 -1.44707648e+00] [-1.74885626e+00 -1.31979479e-01 -1.39706395e+00 -1.31544430e+00] [-9.00681170e-01  7.88807586e-01 -1.28338910e+00 -1.31544430e+00] [-1.02184904e+00  1.01900435e+00 -1.39706395e+00 -1.18381211e+00] [-1.62768839e+00 -1.74335684e+00 -1.39706395e+00 -1.18381211e+00] [-1.74885626e+00  3.28414053e-01 -1.39706395e+00 -1.31544430e+00] [-1.02184904e+00  1.01900435e+00 -1.22655167e+00 -7.88915558e-01] [-9.00681170e-01  1.70959465e+00 -1.05603939e+00 -1.05217993e+00] [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.18381211e+00] [-9.00681170e-01  1.70959465e+00 -1.22655167e+00 -1.31544430e+00] [-1.50652052e+00  3.28414053e-01 -1.34022653e+00 -1.31544430e+00] [-6.58345429e-01  1.47939788e+00 -1.28338910e+00 -1.31544430e+00] [-1.02184904e+00  5.58610819e-01 -1.34022653e+00 -1.31544430e+00] [ 1.40150837e+00  3.28414053e-01  5.35408562e-01  2.64141916e-01] [ 6.74501145e-01  3.28414053e-01  4.21733708e-01  3.95774101e-01] [ 1.28034050e+00  9.82172869e-02  6.49083415e-01  3.95774101e-01] [-4.16009689e-01 -1.74335684e+00  1.37546573e-01  1.32509732e-01] [ 7.95669016e-01 -5.92373012e-01  4.78571135e-01  3.95774101e-01] [-1.73673948e-01 -5.92373012e-01  4.21733708e-01  1.32509732e-01] [ 5.53333275e-01  5.58610819e-01  5.35408562e-01  5.27406285e-01] [-1.14301691e+00 -1.51316008e+00 -2.60315415e-01 -2.62386821e-01] [ 9.16836886e-01 -3.62176246e-01  4.78571135e-01  1.32509732e-01] [-7.79513300e-01 -8.22569778e-01  8.07091462e-02  2.64141916e-01] [-1.02184904e+00 -2.43394714e+00 -1.46640561e-01 -2.62386821e-01] [ 6.86617933e-02 -1.31979479e-01  2.51221427e-01  3.95774101e-01] [ 1.89829664e-01 -1.97355361e+00  1.37546573e-01 -2.62386821e-01] [ 3.10997534e-01 -3.62176246e-01  5.35408562e-01  2.64141916e-01] [-2.94841818e-01 -3.62176246e-01 -8.98031345e-02  1.32509732e-01] [ 1.03800476e+00  9.82172869e-02  3.64896281e-01  2.64141916e-01] [-2.94841818e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01] [-5.25060772e-02 -8.22569778e-01  1.94384000e-01 -2.62386821e-01] [ 4.32165405e-01 -1.97355361e+00  4.21733708e-01  3.95774101e-01] [-2.94841818e-01 -1.28296331e+00  8.07091462e-02 -1.30754636e-01] [ 6.86617933e-02  3.28414053e-01  5.92245988e-01  7.90670654e-01] [ 3.10997534e-01 -5.92373012e-01  1.37546573e-01  1.32509732e-01] [ 5.53333275e-01 -1.28296331e+00  6.49083415e-01  3.95774101e-01] [ 3.10997534e-01 -5.92373012e-01  5.35408562e-01  8.77547895e-04] [ 6.74501145e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01] [ 9.16836886e-01 -1.31979479e-01  3.64896281e-01  2.64141916e-01] [ 1.15917263e+00 -5.92373012e-01  5.92245988e-01  2.64141916e-01] [ 1.03800476e+00 -1.31979479e-01  7.05920842e-01  6.59038469e-01] [ 1.89829664e-01 -3.62176246e-01  4.21733708e-01  3.95774101e-01] [-1.73673948e-01 -1.05276654e+00 -1.46640561e-01 -2.62386821e-01] [-4.16009689e-01 -1.51316008e+00  2.38717193e-02 -1.30754636e-01] [-4.16009689e-01 -1.51316008e+00 -3.29657076e-02 -2.62386821e-01] [-5.25060772e-02 -8.22569778e-01  8.07091462e-02  8.77547895e-04] [ 1.89829664e-01 -8.22569778e-01  7.62758269e-01  5.27406285e-01] [-5.37177559e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01] [ 1.89829664e-01  7.88807586e-01  4.21733708e-01  5.27406285e-01] [ 1.03800476e+00  9.82172869e-02  5.35408562e-01  3.95774101e-01] [ 5.53333275e-01 -1.74335684e+00  3.64896281e-01  1.32509732e-01] [-2.94841818e-01 -1.31979479e-01  1.94384000e-01  1.32509732e-01] [-4.16009689e-01 -1.28296331e+00  1.37546573e-01  1.32509732e-01] [-4.16009689e-01 -1.05276654e+00  3.64896281e-01  8.77547895e-04] [ 3.10997534e-01 -1.31979479e-01  4.78571135e-01  2.64141916e-01] [-5.25060772e-02 -1.05276654e+00  1.37546573e-01  8.77547895e-04] [-1.02184904e+00 -1.74335684e+00 -2.60315415e-01 -2.62386821e-01] [-2.94841818e-01 -8.22569778e-01  2.51221427e-01  1.32509732e-01] [-1.73673948e-01 -1.31979479e-01  2.51221427e-01  8.77547895e-04] [-1.73673948e-01 -3.62176246e-01  2.51221427e-01  1.32509732e-01] [ 4.32165405e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01] [-9.00681170e-01 -1.28296331e+00 -4.30827696e-01 -1.30754636e-01] [-1.73673948e-01 -5.92373012e-01  1.94384000e-01  1.32509732e-01] [ 5.53333275e-01  5.58610819e-01  1.27429511e+00  1.71209594e+00] [-5.25060772e-02 -8.22569778e-01  7.62758269e-01  9.22302838e-01] [ 1.52267624e+00 -1.31979479e-01  1.21745768e+00  1.18556721e+00] [ 5.53333275e-01 -3.62176246e-01  1.04694540e+00  7.90670654e-01] [ 7.95669016e-01 -1.31979479e-01  1.16062026e+00  1.31719939e+00] [ 2.12851559e+00 -1.31979479e-01  1.61531967e+00  1.18556721e+00] [-1.14301691e+00 -1.28296331e+00  4.21733708e-01  6.59038469e-01] [ 1.76501198e+00 -3.62176246e-01  1.44480739e+00  7.90670654e-01] [ 1.03800476e+00 -1.28296331e+00  1.16062026e+00  7.90670654e-01] [ 1.64384411e+00  1.24920112e+00  1.33113254e+00  1.71209594e+00] [ 7.95669016e-01  3.28414053e-01  7.62758269e-01  1.05393502e+00] [ 6.74501145e-01 -8.22569778e-01  8.76433123e-01  9.22302838e-01] [ 1.15917263e+00 -1.31979479e-01  9.90107977e-01  1.18556721e+00] [-1.73673948e-01 -1.28296331e+00  7.05920842e-01  1.05393502e+00] [-5.25060772e-02 -5.92373012e-01  7.62758269e-01  1.58046376e+00] [ 6.74501145e-01  3.28414053e-01  8.76433123e-01  1.44883158e+00] [ 7.95669016e-01 -1.31979479e-01  9.90107977e-01  7.90670654e-01] [ 2.24968346e+00  1.70959465e+00  1.67215710e+00  1.31719939e+00] [ 2.24968346e+00 -1.05276654e+00  1.78583195e+00  1.44883158e+00] [ 1.89829664e-01 -1.97355361e+00  7.05920842e-01  3.95774101e-01] [ 1.28034050e+00  3.28414053e-01  1.10378283e+00  1.44883158e+00] [-2.94841818e-01 -5.92373012e-01  6.49083415e-01  1.05393502e+00] [ 2.24968346e+00 -5.92373012e-01  1.67215710e+00  1.05393502e+00] [ 5.53333275e-01 -8.22569778e-01  6.49083415e-01  7.90670654e-01] [ 1.03800476e+00  5.58610819e-01  1.10378283e+00  1.18556721e+00] [ 1.64384411e+00  3.28414053e-01  1.27429511e+00  7.90670654e-01] [ 4.32165405e-01 -5.92373012e-01  5.92245988e-01  7.90670654e-01] [ 3.10997534e-01 -1.31979479e-01  6.49083415e-01  7.90670654e-01] [ 6.74501145e-01 -5.92373012e-01  1.04694540e+00  1.18556721e+00] [ 1.64384411e+00 -1.31979479e-01  1.16062026e+00  5.27406285e-01] [ 1.88617985e+00 -5.92373012e-01  1.33113254e+00  9.22302838e-01] [ 2.49201920e+00  1.70959465e+00  1.50164482e+00  1.05393502e+00] [ 6.74501145e-01 -5.92373012e-01  1.04694540e+00  1.31719939e+00] [ 5.53333275e-01 -5.92373012e-01  7.62758269e-01  3.95774101e-01] [ 3.10997534e-01 -1.05276654e+00  1.04694540e+00  2.64141916e-01] [ 2.24968346e+00 -1.31979479e-01  1.33113254e+00  1.44883158e+00] [ 5.53333275e-01  7.88807586e-01  1.04694540e+00  1.58046376e+00] [ 6.74501145e-01  9.82172869e-02  9.90107977e-01  7.90670654e-01] [ 1.89829664e-01 -1.31979479e-01  5.92245988e-01  7.90670654e-01] [ 1.28034050e+00  9.82172869e-02  9.33270550e-01  1.18556721e+00] [ 1.03800476e+00  9.82172869e-02  1.04694540e+00  1.58046376e+00] [ 1.28034050e+00  9.82172869e-02  7.62758269e-01  1.44883158e+00] [-5.25060772e-02 -8.22569778e-01  7.62758269e-01  9.22302838e-01] [ 1.15917263e+00  3.28414053e-01  1.21745768e+00  1.44883158e+00] [ 1.03800476e+00  5.58610819e-01  1.10378283e+00  1.71209594e+00] [ 1.03800476e+00 -1.31979479e-01  8.19595696e-01  1.44883158e+00] [ 5.53333275e-01 -1.28296331e+00  7.05920842e-01  9.22302838e-01] [ 7.95669016e-01 -1.31979479e-01  8.19595696e-01  1.05393502e+00] [ 4.32165405e-01  7.88807586e-01  9.33270550e-01  1.44883158e+00] [ 6.86617933e-02 -1.31979479e-01  7.62758269e-01  7.90670654e-01]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#方法2： 区间缩放法 例3：对简单示例二维矩阵的列数据进行</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">data = [[<span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>], </span><br><span class="line">        [<span class="number">100</span>, <span class="number">1</span>], </span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line"><span class="built_in">print</span>(scaler.fit(data))</span><br><span class="line"><span class="built_in">print</span>(scaler.transform(data))</span><br></pre></td></tr></table></figure><pre><code>MinMaxScaler(copy=True, feature_range=(0, 1))[[0.   0.  ] [0.   0.  ] [1.   1.  ] [0.01 1.  ]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#方法2： 区间缩放法 例4：对iris数据二维矩阵的列数据进行</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">data = iris.data</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line"><span class="built_in">print</span>(scaler.fit(data))</span><br><span class="line"><span class="built_in">print</span>(scaler.transform(data))</span><br></pre></td></tr></table></figure><pre><code>MinMaxScaler(copy=True, feature_range=(0, 1))[[0.22222222 0.625      0.06779661 0.04166667] [0.16666667 0.41666667 0.06779661 0.04166667] [0.11111111 0.5        0.05084746 0.04166667] [0.08333333 0.45833333 0.08474576 0.04166667] [0.19444444 0.66666667 0.06779661 0.04166667] [0.30555556 0.79166667 0.11864407 0.125     ] [0.08333333 0.58333333 0.06779661 0.08333333] [0.19444444 0.58333333 0.08474576 0.04166667] [0.02777778 0.375      0.06779661 0.04166667] [0.16666667 0.45833333 0.08474576 0.        ] [0.30555556 0.70833333 0.08474576 0.04166667] [0.13888889 0.58333333 0.10169492 0.04166667] [0.13888889 0.41666667 0.06779661 0.        ] [0.         0.41666667 0.01694915 0.        ] [0.41666667 0.83333333 0.03389831 0.04166667] [0.38888889 1.         0.08474576 0.125     ] [0.30555556 0.79166667 0.05084746 0.125     ] [0.22222222 0.625      0.06779661 0.08333333] [0.38888889 0.75       0.11864407 0.08333333] [0.22222222 0.75       0.08474576 0.08333333] [0.30555556 0.58333333 0.11864407 0.04166667] [0.22222222 0.70833333 0.08474576 0.125     ] [0.08333333 0.66666667 0.         0.04166667] [0.22222222 0.54166667 0.11864407 0.16666667] [0.13888889 0.58333333 0.15254237 0.04166667] [0.19444444 0.41666667 0.10169492 0.04166667] [0.19444444 0.58333333 0.10169492 0.125     ] [0.25       0.625      0.08474576 0.04166667] [0.25       0.58333333 0.06779661 0.04166667] [0.11111111 0.5        0.10169492 0.04166667] [0.13888889 0.45833333 0.10169492 0.04166667] [0.30555556 0.58333333 0.08474576 0.125     ] [0.25       0.875      0.08474576 0.        ] [0.33333333 0.91666667 0.06779661 0.04166667] [0.16666667 0.45833333 0.08474576 0.04166667] [0.19444444 0.5        0.03389831 0.04166667] [0.33333333 0.625      0.05084746 0.04166667] [0.16666667 0.66666667 0.06779661 0.        ] [0.02777778 0.41666667 0.05084746 0.04166667] [0.22222222 0.58333333 0.08474576 0.04166667] [0.19444444 0.625      0.05084746 0.08333333] [0.05555556 0.125      0.05084746 0.08333333] [0.02777778 0.5        0.05084746 0.04166667] [0.19444444 0.625      0.10169492 0.20833333] [0.22222222 0.75       0.15254237 0.125     ] [0.13888889 0.41666667 0.06779661 0.08333333] [0.22222222 0.75       0.10169492 0.04166667] [0.08333333 0.5        0.06779661 0.04166667] [0.27777778 0.70833333 0.08474576 0.04166667] [0.19444444 0.54166667 0.06779661 0.04166667] [0.75       0.5        0.62711864 0.54166667] [0.58333333 0.5        0.59322034 0.58333333] [0.72222222 0.45833333 0.66101695 0.58333333] [0.33333333 0.125      0.50847458 0.5       ] [0.61111111 0.33333333 0.61016949 0.58333333] [0.38888889 0.33333333 0.59322034 0.5       ] [0.55555556 0.54166667 0.62711864 0.625     ] [0.16666667 0.16666667 0.38983051 0.375     ] [0.63888889 0.375      0.61016949 0.5       ] [0.25       0.29166667 0.49152542 0.54166667] [0.19444444 0.         0.42372881 0.375     ] [0.44444444 0.41666667 0.54237288 0.58333333] [0.47222222 0.08333333 0.50847458 0.375     ] [0.5        0.375      0.62711864 0.54166667] [0.36111111 0.375      0.44067797 0.5       ] [0.66666667 0.45833333 0.57627119 0.54166667] [0.36111111 0.41666667 0.59322034 0.58333333] [0.41666667 0.29166667 0.52542373 0.375     ] [0.52777778 0.08333333 0.59322034 0.58333333] [0.36111111 0.20833333 0.49152542 0.41666667] [0.44444444 0.5        0.6440678  0.70833333] [0.5        0.33333333 0.50847458 0.5       ] [0.55555556 0.20833333 0.66101695 0.58333333] [0.5        0.33333333 0.62711864 0.45833333] [0.58333333 0.375      0.55932203 0.5       ] [0.63888889 0.41666667 0.57627119 0.54166667] [0.69444444 0.33333333 0.6440678  0.54166667] [0.66666667 0.41666667 0.6779661  0.66666667] [0.47222222 0.375      0.59322034 0.58333333] [0.38888889 0.25       0.42372881 0.375     ] [0.33333333 0.16666667 0.47457627 0.41666667] [0.33333333 0.16666667 0.45762712 0.375     ] [0.41666667 0.29166667 0.49152542 0.45833333] [0.47222222 0.29166667 0.69491525 0.625     ] [0.30555556 0.41666667 0.59322034 0.58333333] [0.47222222 0.58333333 0.59322034 0.625     ] [0.66666667 0.45833333 0.62711864 0.58333333] [0.55555556 0.125      0.57627119 0.5       ] [0.36111111 0.41666667 0.52542373 0.5       ] [0.33333333 0.20833333 0.50847458 0.5       ] [0.33333333 0.25       0.57627119 0.45833333] [0.5        0.41666667 0.61016949 0.54166667] [0.41666667 0.25       0.50847458 0.45833333] [0.19444444 0.125      0.38983051 0.375     ] [0.36111111 0.29166667 0.54237288 0.5       ] [0.38888889 0.41666667 0.54237288 0.45833333] [0.38888889 0.375      0.54237288 0.5       ] [0.52777778 0.375      0.55932203 0.5       ] [0.22222222 0.20833333 0.33898305 0.41666667] [0.38888889 0.33333333 0.52542373 0.5       ] [0.55555556 0.54166667 0.84745763 1.        ] [0.41666667 0.29166667 0.69491525 0.75      ] [0.77777778 0.41666667 0.83050847 0.83333333] [0.55555556 0.375      0.77966102 0.70833333] [0.61111111 0.41666667 0.81355932 0.875     ] [0.91666667 0.41666667 0.94915254 0.83333333] [0.16666667 0.20833333 0.59322034 0.66666667] [0.83333333 0.375      0.89830508 0.70833333] [0.66666667 0.20833333 0.81355932 0.70833333] [0.80555556 0.66666667 0.86440678 1.        ] [0.61111111 0.5        0.69491525 0.79166667] [0.58333333 0.29166667 0.72881356 0.75      ] [0.69444444 0.41666667 0.76271186 0.83333333] [0.38888889 0.20833333 0.6779661  0.79166667] [0.41666667 0.33333333 0.69491525 0.95833333] [0.58333333 0.5        0.72881356 0.91666667] [0.61111111 0.41666667 0.76271186 0.70833333] [0.94444444 0.75       0.96610169 0.875     ] [0.94444444 0.25       1.         0.91666667] [0.47222222 0.08333333 0.6779661  0.58333333] [0.72222222 0.5        0.79661017 0.91666667] [0.36111111 0.33333333 0.66101695 0.79166667] [0.94444444 0.33333333 0.96610169 0.79166667] [0.55555556 0.29166667 0.66101695 0.70833333] [0.66666667 0.54166667 0.79661017 0.83333333] [0.80555556 0.5        0.84745763 0.70833333] [0.52777778 0.33333333 0.6440678  0.70833333] [0.5        0.41666667 0.66101695 0.70833333] [0.58333333 0.33333333 0.77966102 0.83333333] [0.80555556 0.41666667 0.81355932 0.625     ] [0.86111111 0.33333333 0.86440678 0.75      ] [1.         0.75       0.91525424 0.79166667] [0.58333333 0.33333333 0.77966102 0.875     ] [0.55555556 0.33333333 0.69491525 0.58333333] [0.5        0.25       0.77966102 0.54166667] [0.94444444 0.41666667 0.86440678 0.91666667] [0.55555556 0.58333333 0.77966102 0.95833333] [0.58333333 0.45833333 0.76271186 0.70833333] [0.47222222 0.41666667 0.6440678  0.70833333] [0.72222222 0.45833333 0.74576271 0.83333333] [0.66666667 0.45833333 0.77966102 0.95833333] [0.72222222 0.45833333 0.69491525 0.91666667] [0.41666667 0.29166667 0.69491525 0.75      ] [0.69444444 0.5        0.83050847 0.91666667] [0.66666667 0.54166667 0.79661017 1.        ] [0.66666667 0.41666667 0.71186441 0.91666667] [0.55555556 0.20833333 0.6779661  0.75      ] [0.61111111 0.41666667 0.71186441 0.79166667] [0.52777778 0.58333333 0.74576271 0.91666667] [0.44444444 0.41666667 0.69491525 0.70833333]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
            <tag> 量纲缩放 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Sklearn进行精确率-召回率曲线的绘制</title>
      <link href="/2021/07/13/%E4%BD%BF%E7%94%A8Sklearn%E8%BF%9B%E8%A1%8C%E7%B2%BE%E7%A1%AE%E7%8E%87-%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%9B%B2%E7%BA%BF%E7%9A%84%E7%BB%98%E5%88%B6/"/>
      <url>/2021/07/13/%E4%BD%BF%E7%94%A8Sklearn%E8%BF%9B%E8%A1%8C%E7%B2%BE%E7%A1%AE%E7%8E%87-%E5%8F%AC%E5%9B%9E%E7%8E%87%E6%9B%B2%E7%BA%BF%E7%9A%84%E7%BB%98%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="使用Sklearn进行精确率-召回率曲线的绘制"><a href="#使用Sklearn进行精确率-召回率曲线的绘制" class="headerlink" title="使用Sklearn进行精确率-召回率曲线的绘制"></a>使用Sklearn进行精确率-召回率曲线的绘制</h1><ul><li>精确率：模型判定的正例中真正正例所占的比重</li><li>召回率：总正例中被模型判定为正例的比重</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">#演示目的：利用鸢尾花数据集画出P-R曲线</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(__doc__)</span><br></pre></td></tr></table></figure><pre><code>#演示目的：利用鸢尾花数据集画出P-R曲线</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> average_precision_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> label_binarize</span><br><span class="line"><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsRestClassifier</span><br><span class="line"><span class="comment">#from sklearn.cross_validation import train_test_split  #适用于anaconda 3.6及以前版本</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split<span class="comment">#适用于anaconda 3.7</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以iris数据为例，画出P-R曲线</span></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="comment"># 标签二值化,将三个类转为001, 010, 100的格式.因为这是个多类分类问题，后面将要采用</span></span><br><span class="line"><span class="comment">#OneVsRestClassifier策略转为二类分类问题</span></span><br><span class="line">y = label_binarize(y, classes=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">n_classes = y.shape[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(y.shape)</span><br><span class="line"><span class="built_in">print</span> (y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加了800维的 噪声特征</span></span><br><span class="line">random_state = np.random.RandomState(<span class="number">0</span>)</span><br><span class="line">n_samples, n_features = X.shape</span><br><span class="line"><span class="comment"># print(X.shape)  (150, 4)</span></span><br><span class="line">X = np.c_[X, random_state.randn(n_samples, <span class="number">200</span> * n_features)]</span><br><span class="line"><span class="comment"># print(X.shape)  (150, 804)</span></span><br><span class="line"><span class="comment"># Split into training and test</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">.5</span>, random_state=random_state) <span class="comment">#随机数，填0或不填，每次都会不一样</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run classifier probability : boolean, optional (default=False)Whether to enable probability estimates. This must be enabled prior to calling fit, and will slow down that method.</span></span><br><span class="line">classifier = OneVsRestClassifier(svm.SVC(kernel=<span class="string">&#x27;linear&#x27;</span>, probability=<span class="literal">True</span>, random_state=random_state))</span><br><span class="line">y_score = classifier.fit(X_train, y_train).decision_function(X_test)</span><br></pre></td></tr></table></figure><pre><code>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2](150, 3)[[1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [1 0 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 1 0] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1] [0 0 1]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Compute Precision-Recall and plot curve  </span></span><br><span class="line"><span class="comment">#下面的下划线是返回的阈值。作为一个名称：此时“_”作为临时性的名称使用。</span></span><br><span class="line"><span class="comment">#表示分配了一个特定的名称，但是并不会在后面再次用到该名称。</span></span><br><span class="line">precision = <span class="built_in">dict</span>()</span><br><span class="line">recall = <span class="built_in">dict</span>()</span><br><span class="line">average_precision = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_classes):</span><br><span class="line">    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],  y_score[:, i]) <span class="comment">#The last precision and recall values are 1. and 0. respectively and do not have a corresponding threshold. This ensures that the graph starts on the x axis.</span></span><br><span class="line">    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])<span class="comment">#切片，第i个类的分类结果性能</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute micro-average curve and area. ravel()将多维数组降为一维</span></span><br><span class="line">precision[<span class="string">&quot;micro&quot;</span>], recall[<span class="string">&quot;micro&quot;</span>], _ = precision_recall_curve(y_test.ravel(),  y_score.ravel())</span><br><span class="line">average_precision[<span class="string">&quot;micro&quot;</span>] = average_precision_score(y_test, y_score, average=<span class="string">&quot;micro&quot;</span>) <span class="comment">#This score corresponds to the area under the precision-recall curve.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot Precision-Recall curve for each class</span></span><br><span class="line">plt.clf()<span class="comment">#clf 函数用于清除当前图像窗口</span></span><br><span class="line">plt.plot(recall[<span class="string">&quot;micro&quot;</span>], precision[<span class="string">&quot;micro&quot;</span>],</span><br><span class="line">         label=<span class="string">&#x27;micro-average Precision-recall curve (area = &#123;0:0.2f&#125;)&#x27;</span>.<span class="built_in">format</span>(average_precision[<span class="string">&quot;micro&quot;</span>]))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_classes):</span><br><span class="line">    plt.plot(recall[i], precision[i],</span><br><span class="line">             label=<span class="string">&#x27;Precision-recall curve of class &#123;0&#125; (area = &#123;1:0.2f&#125;)&#x27;</span>.<span class="built_in">format</span>(i, average_precision[i]))</span><br><span class="line"></span><br><span class="line">plt.xlim([<span class="number">0.0</span>, <span class="number">1.0</span>])</span><br><span class="line">plt.ylim([<span class="number">0.0</span>, <span class="number">1.05</span>]) <span class="comment">#xlim、ylim：分别设置X、Y轴的显示范围。</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Recall&#x27;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Precision&#x27;</span>,fontsize=<span class="number">16</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Extension of Precision-Recall curve to multi-class&#x27;</span>,fontsize=<span class="number">16</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;lower right&quot;</span>)<span class="comment">#legend 是用于设置图例的函数</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210713112440.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sklearn </tag>
            
            <tag> P-R曲线 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zero-Resource Knowledge-Grounded Dialogue Generation</title>
      <link href="/2021/07/10/2020%20-%20Zero-Resource%20Knowledge-Grounded%20Dialogue%20Generati/"/>
      <url>/2021/07/10/2020%20-%20Zero-Resource%20Knowledge-Grounded%20Dialogue%20Generati/</url>
      
        <content type="html"><![CDATA[<h1 id="Zero-Resource-Knowledge-Grounded-Dialogue-Generation"><a href="#Zero-Resource-Knowledge-Grounded-Dialogue-Generation" class="headerlink" title="Zero-Resource Knowledge-Grounded Dialogue Generation"></a>Zero-Resource Knowledge-Grounded Dialogue Generation</h1><blockquote><p><a href="https://arxiv.org/abs/2008.12918">论文：https://arxiv.org/abs/2008.12918</a></p><p><a href="https://github.com/nlpxucan/ZRKGC">代码：https://github.com/nlpxucan/ZRKGC</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>神经网络对话模型需要以知识为基础的对话，而这些对话很难获得。为了克服数据方面的挑战并降低构建知识基础对话系统的成本，本文通过假设训练时不需要context-knowledge-response三要素，在零资源环境下探索这个问题。</p><p>贡献：</p><ul><li>在零资源环境下探索以知识为基础的对话生成；</li><li>提出了一个double latent variable model，不仅描述了连接context和response的知识，还描述了知识的表达方式；</li><li>提出了一个variational学习方法；</li><li>在知识为基础的对话生成的三个基准上对所提方法的有效性进行了经验验证。</li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>本文提出将连接context 和response的知识以及知识的表达方式表现为潜在变量，并设计了一种variational方法，可以有效地从对话语料和知识语料中估计出一个相互独立的生成模型。</p><p>在预训练的语言模型的基础上建立概率模型。不使用生成模型，而是建议用一个检索模型来实例化后验，在这个模型中，知识的搜索空间被限制在几个相关的候选之内。</p><p>dialogue corpus：</p><script type="math/tex; mode=display">D_{cov}= \{(C_i, R_i)\}^n_{i=1}</script><blockquote><p>$C_i$指的是dialogue context</p><p>$R_i$指的是response</p></blockquote><p>knowledge base：</p><script type="math/tex; mode=display">K_{kg}= \{K_j\}^m _{j=1}</script><blockquote><p>$K_j$指的是一段知识，例如数据集中的句子。</p></blockquote><p>模型：</p><script type="math/tex; mode=display">p(R∣C, K)</script><p>与外部知识关联的K和新的上下文C，根据$p(R∣C, K)$生成响应R。</p><h2 id="Zero-Resource-Learning-Framework"><a href="#Zero-Resource-Learning-Framework" class="headerlink" title="Zero-Resource Learning Framework"></a>Zero-Resource Learning Framework</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210709120019.png" alt="image-20210709120019816" style="zoom: 67%;" /></p><blockquote><p>dialogue context C</p><p>response R</p><p>latent knowledge $Z_k$</p><p>grounding rate $Z_α$，表示根据C关于R在$Z_k$中携带了多少知识。</p></blockquote><h2 id="Neural-Parameterization"><a href="#Neural-Parameterization" class="headerlink" title="Neural Parameterization"></a>Neural Parameterization</h2><p>define $q(Z_k)$ with a retrieval model：</p><script type="math/tex; mode=display">q(Z_k∣C, R) = \frac{exp^{F(C,R,Z_k)} }{∑_{K′∈S(R)}exp^{F(C,R,K')}}</script><blockquote><p>S(R)表示对潜在知识的推断，该知识由相关性模型rel(⋅, ⋅)从$K_{kg}$中通过R查询检索到的前l个结果组成。</p><p>$F（⋅,⋅,⋅）$是一个三层transformer，将（c,r,$z_k$）映射到匹配分数。</p></blockquote><p>优化算法：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210709220311.png" alt="image-20210709220311538"></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>Wizard</li><li>TC</li><li>CMU_DoG</li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>测试结果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210710000506.png" alt="image-20210710000506505"></p><p>F1:虽然ZRKGC在基准中没有获取任何训练实例，但它仍然优于MTASK-RF、TMN和ITDD，并在所有测试集上取得了与DRD相当的性能，表明该模型能够有效地学习如何通过variational方法利用外部知识来生成响应。</p><p>ZRKGC在Test Seen和Test Unseen上几乎没有差异，该模型不受特定训练数据的影响，因此在不同主题上表现稳定，这揭示了该模型良好的泛化能力是零资源方法的优势。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>对三个以知识为基础的对话生成基准的评估结果表明，本文的模型可以达到与依靠以知识为基础的对话进行训练的先进方法相当的性能，并在不同的主题和不同的数据集上表现出良好的泛化能力。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> ZRKGC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zero-Resource Knowledge-Grounded Dialogue Generation</title>
      <link href="/2021/07/10/Zero-Resource%20Knowledge-Grounded%20Dialogue%20Generati/"/>
      <url>/2021/07/10/Zero-Resource%20Knowledge-Grounded%20Dialogue%20Generati/</url>
      
        <content type="html"><![CDATA[<h1 id="Zero-Resource-Knowledge-Grounded-Dialogue-Generation"><a href="#Zero-Resource-Knowledge-Grounded-Dialogue-Generation" class="headerlink" title="Zero-Resource Knowledge-Grounded Dialogue Generation"></a>Zero-Resource Knowledge-Grounded Dialogue Generation</h1><blockquote><p><a href="https://arxiv.org/abs/2008.12918">论文：https://arxiv.org/abs/2008.12918</a></p><p><a href="https://github.com/nlpxucan/ZRKGC">代码：https://github.com/nlpxucan/ZRKGC</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>神经网络对话模型需要以知识为基础的对话，而这些对话很难获得。为了克服数据方面的挑战并降低构建知识基础对话系统的成本，本文通过假设训练时不需要context-knowledge-response三要素，在零资源环境下探索这个问题。</p><p>贡献：</p><ul><li>在零资源环境下探索以知识为基础的对话生成；</li><li>提出了一个double latent variable model，不仅描述了连接context和response的知识，还描述了知识的表达方式；</li><li>提出了一个variational学习方法；</li><li>在知识为基础的对话生成的三个基准上对所提方法的有效性进行了经验验证。</li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>本文提出将连接context 和response的知识以及知识的表达方式表现为潜在变量，并设计了一种variational方法，可以有效地从对话语料和知识语料中估计出一个相互独立的生成模型。</p><p>在预训练的语言模型的基础上建立概率模型。不使用生成模型，而是建议用一个检索模型来实例化后验，在这个模型中，知识的搜索空间被限制在几个相关的候选之内。</p><p>dialogue corpus：</p><script type="math/tex; mode=display">D_{cov}= \{(C_i, R_i)\}^n_{i=1}</script><blockquote><p>$C_i$指的是dialogue context</p><p>$R_i$指的是response</p></blockquote><p>knowledge base：</p><script type="math/tex; mode=display">K_{kg}= \{K_j\}^m _{j=1}</script><blockquote><p>$K_j$指的是一段知识，例如数据集中的句子。</p></blockquote><p>模型：</p><script type="math/tex; mode=display">p(R∣C, K)</script><p>与外部知识关联的K和新的上下文C，根据$p(R∣C, K)$生成响应R。</p><h2 id="Zero-Resource-Learning-Framework"><a href="#Zero-Resource-Learning-Framework" class="headerlink" title="Zero-Resource Learning Framework"></a>Zero-Resource Learning Framework</h2><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210709120019.png" alt="image-20210709120019816" style="zoom: 67%;" /></p><blockquote><p>dialogue context C</p><p>response R</p><p>latent knowledge $Z_k$</p><p>grounding rate $Z_α$，表示根据C关于R在$Z_k$中携带了多少知识。</p></blockquote><h2 id="Neural-Parameterization"><a href="#Neural-Parameterization" class="headerlink" title="Neural Parameterization"></a>Neural Parameterization</h2><p>define $q(Z_k)$ with a retrieval model：</p><script type="math/tex; mode=display">q(Z_k∣C, R) = \frac{exp^{F(C,R,Z_k)} }{∑_{K′∈S(R)}exp^{F(C,R,K')}}</script><blockquote><p>S(R)表示对潜在知识的推断，该知识由相关性模型rel(⋅, ⋅)从$K_{kg}$中通过R查询检索到的前l个结果组成。</p><p>$F（⋅,⋅,⋅）$是一个三层transformer，将（c,r,$z_k$）映射到匹配分数。</p></blockquote><p>优化算法：</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210709220311.png" alt="image-20210709220311538"></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>Wizard</li><li>TC</li><li>CMU_DoG</li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>测试结果：</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210710000506.png" alt="image-20210710000506505"></p><p>F1:虽然ZRKGC在基准中没有获取任何训练实例，但它仍然优于MTASK-RF、TMN和ITDD，并在所有测试集上取得了与DRD相当的性能，表明该模型能够有效地学习如何通过variational方法利用外部知识来生成响应。</p><p>ZRKGC在Test Seen和Test Unseen上几乎没有差异，该模型不受特定训练数据的影响，因此在不同主题上表现稳定，这揭示了该模型良好的泛化能力是零资源方法的优势。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>对三个以知识为基础的对话生成基准的评估结果表明，本文的模型可以达到与依靠以知识为基础的对话进行训练的先进方法相当的性能，并在不同的主题和不同的数据集上表现出良好的泛化能力。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> ZRKGC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用注意力机制实现中英文互译</title>
      <link href="/2021/07/07/%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E4%B8%AD%E8%8B%B1%E6%96%87%E4%BA%92%E8%AF%91/"/>
      <url>/2021/07/07/%E7%94%A8%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E4%B8%AD%E8%8B%B1%E6%96%87%E4%BA%92%E8%AF%91/</url>
      
        <content type="html"><![CDATA[<h3>用注意力机制实现中英文互译</h3><p>[KEY: &gt; input, = target, &lt; output]</p><blockquote><p>il est en train de peindre un tableau .<br>= he is painting a picture .<br>&lt; he is painting a picture .</p><p>pourquoi ne pas essayer ce vin delicieux ?<br>= why not try that delicious wine ?<br>&lt; why not try that delicious wine ?</p><p>elle n est pas poete mais romanciere .<br>= she is not a poet but a novelist .<br>&lt; she not not a poet but a novelist .</p><h3>导入需要的模块及数据</h3></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">import</span> unicodedata</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.font_manager <span class="keyword">as</span> fm</span><br><span class="line">myfont = fm.FontProperties(fname=<span class="string">&#x27;/Users/maqi/opt/anaconda3/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf&#x27;</span>)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure><h3>预处理数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">SOS_token = <span class="number">0</span></span><br><span class="line">EOS_token = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lang</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, name</span>):</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.word2index = &#123;&#125;</span><br><span class="line">        self.word2count = &#123;&#125;</span><br><span class="line">        self.index2word = &#123;<span class="number">0</span>: <span class="string">&quot;SOS&quot;</span>, <span class="number">1</span>: <span class="string">&quot;EOS&quot;</span>&#125;</span><br><span class="line">        self.n_words = <span class="number">2</span>  <span class="comment"># Count SOS and EOS</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addSentence</span>(<span class="params">self, sentence</span>):</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> sentence.split(<span class="string">&#x27; &#x27;</span>):</span><br><span class="line">            self.addWord(word)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addSentence_cn</span>(<span class="params">self, sentence</span>):</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> <span class="built_in">list</span>(jieba.cut(sentence)):</span><br><span class="line">            self.addWord(word)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addWord</span>(<span class="params">self, word</span>):</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.word2index:</span><br><span class="line">            self.word2index[word] = self.n_words</span><br><span class="line">            self.word2count[word] = <span class="number">1</span></span><br><span class="line">            self.index2word[self.n_words] = word</span><br><span class="line">            self.n_words += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.word2count[word] += <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为便于数据处理，把Unicode字符串转换为ASCII编码</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unicodeToAscii</span>(<span class="params">s</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(</span><br><span class="line">        c <span class="keyword">for</span> c <span class="keyword">in</span> unicodedata.normalize(<span class="string">&#x27;NFD&#x27;</span>, s)</span><br><span class="line">        <span class="keyword">if</span> unicodedata.category(c) != <span class="string">&#x27;Mn&#x27;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对英文转换为小写，去空格及非字母符号等处理</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalizeString</span>(<span class="params">s</span>):</span></span><br><span class="line">    s = unicodeToAscii(s.lower().strip())</span><br><span class="line">    s = re.sub(<span class="string">r&quot;([.!?])&quot;</span>, <span class="string">r&quot; \1&quot;</span>, s)</span><br><span class="line">    <span class="comment">#s = re.sub(r&quot;[^a-zA-Z.!?]+&quot;, r&quot; &quot;, s)</span></span><br><span class="line">    <span class="keyword">return</span> s</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readLangs</span>(<span class="params">lang1, lang2, reverse=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Reading lines...&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读文件，然后分成行</span></span><br><span class="line">    lines = <span class="built_in">open</span>(<span class="string">&#x27;eng-cmn/%s-%s.txt&#x27;</span> % (lang1, lang2), encoding=<span class="string">&#x27;utf-8&#x27;</span>).\</span><br><span class="line">        read().strip().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 把行分成语句对，并进行规范化</span></span><br><span class="line">    pairs = [[normalizeString(s) <span class="keyword">for</span> s <span class="keyword">in</span> l.split(<span class="string">&#x27;\t&#x27;</span>)] <span class="keyword">for</span> l <span class="keyword">in</span> lines]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断是否需要转换语句对的次序，如[英文，中文]转换为[中文，英文]次序</span></span><br><span class="line">    <span class="keyword">if</span> reverse:</span><br><span class="line">        pairs = [<span class="built_in">list</span>(<span class="built_in">reversed</span>(p)) <span class="keyword">for</span> p <span class="keyword">in</span> pairs]</span><br><span class="line">        input_lang = Lang(lang2)</span><br><span class="line">        output_lang = Lang(lang1)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        input_lang = Lang(lang1)</span><br><span class="line">        output_lang = Lang(lang2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> input_lang, output_lang, pairs</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为便于训练，这里选择部分数据</span></span><br><span class="line">MAX_LENGTH = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">eng_prefixes = (</span><br><span class="line">    <span class="string">&quot;i am &quot;</span>, <span class="string">&quot;i m &quot;</span>,</span><br><span class="line">    <span class="string">&quot;he is&quot;</span>, <span class="string">&quot;he s &quot;</span>,</span><br><span class="line">    <span class="string">&quot;she is&quot;</span>, <span class="string">&quot;she s &quot;</span>,</span><br><span class="line">    <span class="string">&quot;you are&quot;</span>, <span class="string">&quot;you re &quot;</span>,</span><br><span class="line">    <span class="string">&quot;we are&quot;</span>, <span class="string">&quot;we re &quot;</span>,</span><br><span class="line">    <span class="string">&quot;they are&quot;</span>, <span class="string">&quot;they re &quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filterPair</span>(<span class="params">p</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(p[<span class="number">0</span>].split(<span class="string">&#x27; &#x27;</span>)) &lt; MAX_LENGTH <span class="keyword">and</span> \</span><br><span class="line">        <span class="built_in">len</span>(p[<span class="number">1</span>].split(<span class="string">&#x27; &#x27;</span>)) &lt; MAX_LENGTH <span class="keyword">and</span> \</span><br><span class="line">        p[<span class="number">1</span>].startswith(eng_prefixes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filterPairs</span>(<span class="params">pairs</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [pair <span class="keyword">for</span> pair <span class="keyword">in</span> pairs <span class="keyword">if</span> filterPair(pair)]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepareData</span>(<span class="params">lang1, lang2, reverse=<span class="literal">False</span></span>):</span></span><br><span class="line">    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Read %s sentence pairs&quot;</span> % <span class="built_in">len</span>(pairs))</span><br><span class="line">    pairs = filterPairs(pairs)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Trimmed to %s sentence pairs&quot;</span> % <span class="built_in">len</span>(pairs))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Counting words...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> pair <span class="keyword">in</span> pairs:</span><br><span class="line">        input_lang.addSentence_cn(pair[<span class="number">0</span>])</span><br><span class="line">        output_lang.addSentence(pair[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Counted words:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(input_lang.name, input_lang.n_words)</span><br><span class="line">    <span class="built_in">print</span>(output_lang.name, output_lang.n_words)</span><br><span class="line">    <span class="keyword">return</span> input_lang, output_lang, pairs</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input_lang, output_lang, pairs = prepareData(<span class="string">&#x27;eng&#x27;</span>, <span class="string">&#x27;cmn&#x27;</span>,<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(random.choice(pairs))</span><br></pre></td></tr></table></figure><pre><code>Reading lines...Building prefix dict from the default dictionary ...Loading model from cache /var/folders/7t/wvjcfn5575g892qb2nqbd9kw0000gn/T/jieba.cacheRead 21007 sentence pairsTrimmed to 640 sentence pairsCounting words...Loading model cost 0.571 seconds.Prefix dict has been built succesfully.Counted words:cmn 1063eng 808[&#39;他很穷。&#39;, &#39;he is poor .&#39;]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pairs[:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><pre><code>[[&#39;我冷。&#39;, &#39;i am cold .&#39;], [&#39;我沒事。&#39;, &#39;i am okay .&#39;], [&#39;我生病了。&#39;, &#39;i am sick .&#39;]]</code></pre><h3>构建模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderRNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, hidden_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(EncoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(input_size, hidden_size)</span><br><span class="line">        self.gru = nn.GRU(hidden_size, hidden_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden</span>):</span></span><br><span class="line">        embedded = self.embedding(<span class="built_in">input</span>).view(<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        output = embedded</span><br><span class="line">        output, hidden = self.gru(output, hidden)</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.hidden_size, device=device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderRNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, hidden_size, output_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DecoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(output_size, hidden_size)</span><br><span class="line">        self.gru = nn.GRU(hidden_size, hidden_size)</span><br><span class="line">        self.out = nn.Linear(hidden_size, output_size)</span><br><span class="line">        self.softmax = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden</span>):</span></span><br><span class="line">        output = self.embedding(<span class="built_in">input</span>).view(<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        output = F.relu(output)</span><br><span class="line">        output, hidden = self.gru(output, hidden)</span><br><span class="line">        output = self.softmax(self.out(output[<span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.hidden_size, device=device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AttnDecoderRNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, hidden_size, output_size, dropout_p=<span class="number">0.1</span>, max_length=MAX_LENGTH</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(AttnDecoderRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.output_size = output_size</span><br><span class="line">        self.dropout_p = dropout_p</span><br><span class="line">        self.max_length = max_length</span><br><span class="line"></span><br><span class="line">        self.embedding = nn.Embedding(self.output_size, self.hidden_size)</span><br><span class="line">        self.attn = nn.Linear(self.hidden_size * <span class="number">2</span>, self.max_length)</span><br><span class="line">        self.attn_combine = nn.Linear(self.hidden_size * <span class="number">2</span>, self.hidden_size)</span><br><span class="line">        self.dropout = nn.Dropout(self.dropout_p)</span><br><span class="line">        self.gru = nn.GRU(self.hidden_size, self.hidden_size)</span><br><span class="line">        self.out = nn.Linear(self.hidden_size, self.output_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden, encoder_outputs</span>):</span></span><br><span class="line">        embedded = self.embedding(<span class="built_in">input</span>).view(<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        embedded = self.dropout(embedded)</span><br><span class="line"></span><br><span class="line">        attn_weights = F.softmax(</span><br><span class="line">            self.attn(torch.cat((embedded[<span class="number">0</span>], hidden[<span class="number">0</span>]), <span class="number">1</span>)), dim=<span class="number">1</span>)</span><br><span class="line">        attn_applied = torch.bmm(attn_weights.unsqueeze(<span class="number">0</span>),</span><br><span class="line">                                 encoder_outputs.unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        output = torch.cat((embedded[<span class="number">0</span>], attn_applied[<span class="number">0</span>]), <span class="number">1</span>)</span><br><span class="line">        output = self.attn_combine(output).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        output = F.relu(output)</span><br><span class="line">        output, hidden = self.gru(output, hidden)</span><br><span class="line"></span><br><span class="line">        output = F.log_softmax(self.out(output[<span class="number">0</span>]), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output, hidden, attn_weights</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, <span class="number">1</span>, self.hidden_size, device=device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">indexesFromSentence</span>(<span class="params">lang, sentence</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [lang.word2index[word] <span class="keyword">for</span> word <span class="keyword">in</span> sentence.split(<span class="string">&#x27; &#x27;</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">indexesFromSentence_cn</span>(<span class="params">lang, sentence</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [lang.word2index[word] <span class="keyword">for</span> word <span class="keyword">in</span> <span class="built_in">list</span>(jieba.cut(sentence))]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensorFromSentence</span>(<span class="params">lang, sentence</span>):</span></span><br><span class="line">    indexes = indexesFromSentence(lang, sentence)</span><br><span class="line">    indexes.append(EOS_token)</span><br><span class="line">    <span class="keyword">return</span> torch.tensor(indexes, dtype=torch.long, device=device).view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensorFromSentence_cn</span>(<span class="params">lang, sentence</span>):</span></span><br><span class="line">    indexes = indexesFromSentence_cn(lang, sentence)</span><br><span class="line">    indexes.append(EOS_token)</span><br><span class="line">    <span class="keyword">return</span> torch.tensor(indexes, dtype=torch.long, device=device).view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tensorsFromPair</span>(<span class="params">pair</span>):</span></span><br><span class="line">    input_tensor = tensorFromSentence_cn(input_lang, pair[<span class="number">0</span>])</span><br><span class="line">    target_tensor = tensorFromSentence(output_lang, pair[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> (input_tensor, target_tensor)</span><br></pre></td></tr></table></figure><h3>训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">teacher_forcing_ratio = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH</span>):</span></span><br><span class="line">    encoder_hidden = encoder.initHidden()</span><br><span class="line"></span><br><span class="line">    encoder_optimizer.zero_grad()</span><br><span class="line">    decoder_optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    input_length = input_tensor.size(<span class="number">0</span>)</span><br><span class="line">    target_length = target_tensor.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ei <span class="keyword">in</span> <span class="built_in">range</span>(input_length):</span><br><span class="line">        encoder_output, encoder_hidden = encoder(</span><br><span class="line">            input_tensor[ei], encoder_hidden)</span><br><span class="line">        encoder_outputs[ei] = encoder_output[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    decoder_input = torch.tensor([[SOS_token]], device=device)</span><br><span class="line"></span><br><span class="line">    decoder_hidden = encoder_hidden</span><br><span class="line"></span><br><span class="line">    use_teacher_forcing = <span class="literal">True</span> <span class="keyword">if</span> random.random() &lt; teacher_forcing_ratio <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> use_teacher_forcing:</span><br><span class="line">        <span class="comment"># Teacher forcing: Feed the target as the next input</span></span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> <span class="built_in">range</span>(target_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            loss += criterion(decoder_output, target_tensor[di])</span><br><span class="line">            decoder_input = target_tensor[di]  <span class="comment"># Teacher forcing</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Without teacher forcing: use its own predictions as the next input</span></span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> <span class="built_in">range</span>(target_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            topv, topi = decoder_output.topk(<span class="number">1</span>)</span><br><span class="line">            decoder_input = topi.squeeze().detach()  <span class="comment"># detach from history as input</span></span><br><span class="line"></span><br><span class="line">            loss += criterion(decoder_output, target_tensor[di])</span><br><span class="line">            <span class="keyword">if</span> decoder_input.item() == EOS_token:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    encoder_optimizer.step()</span><br><span class="line">    decoder_optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss.item() / target_length</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">asMinutes</span>(<span class="params">s</span>):</span></span><br><span class="line">    m = math.floor(s / <span class="number">60</span>)</span><br><span class="line">    s -= m * <span class="number">60</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;%dm %ds&#x27;</span> % (m, s)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timeSince</span>(<span class="params">since, percent</span>):</span></span><br><span class="line">    now = time.time()</span><br><span class="line">    s = now - since</span><br><span class="line">    es = s / (percent)</span><br><span class="line">    rs = es - s</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;%s (- %s)&#x27;</span> % (asMinutes(s), asMinutes(rs))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainIters</span>(<span class="params">encoder, decoder, n_iters, print_every=<span class="number">1000</span>, plot_every=<span class="number">100</span>, learning_rate=<span class="number">0.01</span></span>):</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    plot_losses = []</span><br><span class="line">    print_loss_total = <span class="number">0</span>  </span><br><span class="line">    plot_loss_total = <span class="number">0</span> </span><br><span class="line"></span><br><span class="line">    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)</span><br><span class="line">    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)</span><br><span class="line">    training_pairs = [tensorsFromPair(random.choice(pairs))</span><br><span class="line">                      <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_iters)]</span><br><span class="line">    criterion = nn.NLLLoss()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_iters + <span class="number">1</span>):</span><br><span class="line">        training_pair = training_pairs[<span class="built_in">iter</span> - <span class="number">1</span>]</span><br><span class="line">        input_tensor = training_pair[<span class="number">0</span>]</span><br><span class="line">        target_tensor = training_pair[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        loss = train(input_tensor, target_tensor, encoder,</span><br><span class="line">                     decoder, encoder_optimizer, decoder_optimizer, criterion)</span><br><span class="line">        print_loss_total += loss</span><br><span class="line">        plot_loss_total += loss</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">iter</span> % print_every == <span class="number">0</span>:</span><br><span class="line">            print_loss_avg = print_loss_total / print_every</span><br><span class="line">            print_loss_total = <span class="number">0</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;%s (%d %d%%) %.4f&#x27;</span> % (timeSince(start, <span class="built_in">iter</span> / n_iters),</span><br><span class="line">                                         <span class="built_in">iter</span>, <span class="built_in">iter</span> / n_iters * <span class="number">100</span>, print_loss_avg))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">iter</span> % plot_every == <span class="number">0</span>:</span><br><span class="line">            plot_loss_avg = plot_loss_total / plot_every</span><br><span class="line">            plot_losses.append(plot_loss_avg)</span><br><span class="line">            plot_loss_total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    showPlot(plot_losses)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#plt.switch_backend(&#x27;agg&#x27;)</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> ticker</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showPlot</span>(<span class="params">points</span>):</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    <span class="comment"># this locator puts ticks at regular intervals</span></span><br><span class="line">    loc = ticker.MultipleLocator(base=<span class="number">0.2</span>)</span><br><span class="line">    ax.yaxis.set_major_locator(loc)</span><br><span class="line">    plt.plot(points)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">encoder, decoder, sentence, max_length=MAX_LENGTH</span>):</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        input_tensor = tensorFromSentence_cn(input_lang, sentence)</span><br><span class="line">        input_length = input_tensor.size()[<span class="number">0</span>]</span><br><span class="line">        encoder_hidden = encoder.initHidden()</span><br><span class="line"></span><br><span class="line">        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> ei <span class="keyword">in</span> <span class="built_in">range</span>(input_length):</span><br><span class="line">            encoder_output, encoder_hidden = encoder(input_tensor[ei],</span><br><span class="line">                                                     encoder_hidden)</span><br><span class="line">            encoder_outputs[ei] += encoder_output[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        decoder_input = torch.tensor([[SOS_token]], device=device)  <span class="comment"># SOS</span></span><br><span class="line"></span><br><span class="line">        decoder_hidden = encoder_hidden</span><br><span class="line"></span><br><span class="line">        decoded_words = []</span><br><span class="line">        decoder_attentions = torch.zeros(max_length, max_length)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> di <span class="keyword">in</span> <span class="built_in">range</span>(max_length):</span><br><span class="line">            decoder_output, decoder_hidden, decoder_attention = decoder(</span><br><span class="line">                decoder_input, decoder_hidden, encoder_outputs)</span><br><span class="line">            decoder_attentions[di] = decoder_attention.data</span><br><span class="line">            topv, topi = decoder_output.data.topk(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> topi.item() == EOS_token:</span><br><span class="line">                decoded_words.append(<span class="string">&#x27;&lt;EOS&gt;&#x27;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                decoded_words.append(output_lang.index2word[topi.item()])</span><br><span class="line"></span><br><span class="line">            decoder_input = topi.squeeze().detach()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> decoded_words, decoder_attentions[:di + <span class="number">1</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateRandomly</span>(<span class="params">encoder, decoder, n=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        pair = random.choice(pairs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&gt;&#x27;</span>, pair[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>, pair[<span class="number">1</span>])</span><br><span class="line">        output_words, attentions = evaluate(encoder, decoder, pair[<span class="number">0</span>])</span><br><span class="line">        output_sentence = <span class="string">&#x27; &#x27;</span>.join(output_words)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&lt;&#x27;</span>, output_sentence)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hidden_size = <span class="number">256</span></span><br><span class="line">encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)</span><br><span class="line">attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=<span class="number">0.1</span>).to(device)</span><br><span class="line"></span><br><span class="line">trainIters(encoder1, attn_decoder1, <span class="number">75000</span>, print_every=<span class="number">5000</span>)</span><br></pre></td></tr></table></figure><pre><code>1m 54s (- 26m 36s) (5000 6%) 2.63943m 43s (- 24m 10s) (10000 13%) 1.09165m 34s (- 22m 19s) (15000 20%) 0.20577m 29s (- 20m 36s) (20000 26%) 0.04459m 27s (- 18m 54s) (25000 33%) 0.025311m 25s (- 17m 7s) (30000 40%) 0.020213m 20s (- 15m 14s) (35000 46%) 0.017515m 17s (- 13m 23s) (40000 53%) 0.016717m 15s (- 11m 30s) (45000 60%) 0.014119m 13s (- 9m 36s) (50000 66%) 0.013721m 12s (- 7m 42s) (55000 73%) 0.011023m 12s (- 5m 48s) (60000 80%) 0.011625m 12s (- 3m 52s) (65000 86%) 0.012527m 11s (- 1m 56s) (70000 93%) 0.009129m 11s (- 0m 0s) (75000 100%) 0.0095&lt;Figure size 432x288 with 0 Axes&gt;</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210707193941.png" alt="png"></p><h3>随机采样，对模型进行测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">evaluateRandomly(encoder1, attn_decoder1)</span><br></pre></td></tr></table></figure><pre><code>&gt; 今天下午我會外出。= i am going out this afternoon .&lt; i am going out this afternoon . &lt;EOS&gt;&gt; 我相信他是無辜的。= i am convinced that he is innocent .&lt; i am convinced that he is innocent . &lt;EOS&gt;&gt; 他在自己房里玩。= he is playing in his room .&lt; he is playing in his room . &lt;EOS&gt;&gt; 我來自四國。= i am from shikoku .&lt; i am from shikoku . &lt;EOS&gt;&gt; 她戴著一頂帽子。= she is wearing a hat .&lt; she is wearing a hat . &lt;EOS&gt;&gt; 您非常勇敢。= you are very courageous .&lt; you are very brave . &lt;EOS&gt;&gt; 他有几分像学者。= he is something of a scholar .&lt; he is something of a scholar . &lt;EOS&gt;&gt; 你真傻。= you are so stupid .&lt; you are so stupid . &lt;EOS&gt;&gt; 他年紀夠大可以瞭解它。= he is old enough to understand it .&lt; he is old enough to understand it . &lt;EOS&gt;&gt; 你別小看了他。= you are selling him short .&lt; you are selling him short . &lt;EOS&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_randomly</span>():</span></span><br><span class="line">    pair = random.choice(pairs)</span><br><span class="line">    </span><br><span class="line">    output_words, decoder_attn = evaluate(pair[<span class="number">0</span>])</span><br><span class="line">    output_sentence = <span class="string">&#x27; &#x27;</span>.join(output_words)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&gt;&#x27;</span>, pair[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>, pair[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&lt;&#x27;</span>, output_sentence)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateRandomly</span>(<span class="params">encoder, decoder, n=<span class="number">20</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        pair = random.choice(pairs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&gt;&#x27;</span>, pair[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;=&#x27;</span>, pair[<span class="number">1</span>])</span><br><span class="line">        output_words, attentions = evaluate(encoder, decoder, pair[<span class="number">0</span>])</span><br><span class="line">        output_sentence = <span class="string">&#x27; &#x27;</span>.join(output_words)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&lt;&#x27;</span>, output_sentence)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure><h3>可视化注意力</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showAttention</span>(<span class="params">input_sentence, output_words, attentions</span>):</span></span><br><span class="line">    <span class="comment"># Set up figure with colorbar</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    cax = ax.matshow(attentions.numpy(), cmap=<span class="string">&#x27;bone&#x27;</span>)</span><br><span class="line">    fig.colorbar(cax)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set up axes</span></span><br><span class="line">    ax.set_xticklabels([<span class="string">&#x27;&#x27;</span>] + <span class="built_in">list</span>(jieba.cut(input_sentence)) +</span><br><span class="line">                       [<span class="string">&#x27;&lt;EOS&gt;&#x27;</span>], rotation=<span class="number">90</span>,fontproperties=myfont)</span><br><span class="line">    ax.set_yticklabels([<span class="string">&#x27;&#x27;</span>] + output_words)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Show label at every tick</span></span><br><span class="line">    ax.xaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line">    ax.yaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluateAndShowAttention</span>(<span class="params">input_sentence</span>):</span></span><br><span class="line">    output_words, attentions = evaluate(</span><br><span class="line">        encoder1, attn_decoder1, input_sentence)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;input =&#x27;</span>, input_sentence)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;output =&#x27;</span>, <span class="string">&#x27; &#x27;</span>.join(output_words))</span><br><span class="line">    showAttention(input_sentence, output_words, attentions)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">evaluateAndShowAttention(<span class="string">&quot;我很幸福。&quot;</span>)</span><br><span class="line"></span><br><span class="line">evaluateAndShowAttention(<span class="string">&quot;我们在严肃地谈论你的未来。&quot;</span>)</span><br><span class="line"></span><br><span class="line">evaluateAndShowAttention(<span class="string">&quot;我在家。&quot;</span>)</span><br><span class="line"></span><br><span class="line">evaluateAndShowAttention(<span class="string">&quot;我们在严肃地谈论你的未来。&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>input = 我很幸福。output = i am very happy . &lt;EOS&gt;&lt;ipython-input-23-2d6791f485ef&gt;:9: UserWarning: FixedFormatter should only be used together with FixedLocator  ax.set_xticklabels([&#39;&#39;] + list(jieba.cut(input_sentence)) +&lt;ipython-input-23-2d6791f485ef&gt;:11: UserWarning: FixedFormatter should only be used together with FixedLocator  ax.set_yticklabels([&#39;&#39;] + output_words)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 25105 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24456 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 24184 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 31119 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 12290 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 25105 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24456 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 24184 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 31119 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 12290 missing from current font.  font.set_text(s, 0, flags=flags)</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210707193959.png" alt="png"></p><pre><code>input = 我们在严肃地谈论你的未来。output = we are having a serious talk about your future . &lt;EOS&gt;/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20204 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 22312 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20005 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 32899 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 22320 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 35848 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 35770 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 20320 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 30340 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 26410 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 26469 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20204 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 22312 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20005 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 32899 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 22320 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 35848 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 35770 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 20320 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 30340 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 26410 missing from current font.  font.set_text(s, 0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 26469 missing from current font.  font.set_text(s, 0, flags=flags)</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210707194006.png" alt="png"></p><pre><code>input = 我在家。output = i am at home . &lt;EOS&gt;/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 23478 missing from current font.  font.set_text(s, 0.0, flags=flags)/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 23478 missing from current font.  font.set_text(s, 0, flags=flags)</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210707194008.png" alt="png"></p><pre><code>input = 我们在严肃地谈论你的未来。output = we are having a serious talk about your future . &lt;EOS&gt;</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210707194010.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-paragraph Reading Comprehension with Token-level Dynamic Reader and Hybrid Verifier</title>
      <link href="/2021/07/06/IJCNN2019-MRC-%E5%A4%9A%E6%8C%87%E9%92%88%E5%8F%82%E8%80%83/"/>
      <url>/2021/07/06/IJCNN2019-MRC-%E5%A4%9A%E6%8C%87%E9%92%88%E5%8F%82%E8%80%83/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-paragraph-Reading-Comprehension-with-Token-level-Dynamic-Reader-and-Hybrid-Verifier"><a href="#Multi-paragraph-Reading-Comprehension-with-Token-level-Dynamic-Reader-and-Hybrid-Verifier" class="headerlink" title="Multi-paragraph Reading Comprehension with Token-level Dynamic Reader and Hybrid Verifier"></a>Multi-paragraph Reading Comprehension with Token-level Dynamic Reader and Hybrid Verifier</h1><blockquote><p> 论文：<a href="http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/IEEE_WCCI_2020/IJCNN/Papers/N-20242.pdf">http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/IEEE_WCCI_2020/IJCNN/Papers/N-20242.pdf</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>多段式阅读理解要求模型通过推理跨段落信息来推断任意用户生成的问题的答案。以前的工作通常通过直接采用指针网络预测答案的开始和结束位置来生成答案。然而，对于跨度级别的阅读理解是不够的，因为中间的词可能更重要。本文提出了一个统一的网络，包括一个选择器，一个token级动态阅读器，和一个混合验证器（TH-Net）。本文侧重于解决文档级数据而不是单段数据的挑战。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>提出了token级动态阅读器和混合验证器，以避免边界和内容的相似性。</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210704190423.png" alt="image-20210704190423456" style="zoom: 67%;" /></p><ul><li>采用统一的方法（Unified approach），通过共享相同的上下文嵌入来提高三个组件的整体性能。这三个部分由预训练的LM初始化，并在训练过程中同时进行优化。</li><li>引入了token级动态阅读器，通过边界和中间标记来决定候选答案的分数。这种策略在段落阅读中被证明是非常有效的，因为它可以更好地解决跨度级阅读器选择的答案代表性不足的问题。</li><li>在答案验证中，采用了一个混合网络，将候选答案之间的相关语义关系与问题和答案之间的必然关系结合起来。这种机制也提高了验证器的性能。</li></ul><h3 id="Segmentation-and-Encoding"><a href="#Segmentation-and-Encoding" class="headerlink" title="Segmentation and Encoding"></a>Segmentation and Encoding</h3><p>将所有作为输入的段落串联后使用滑窗分段，再进行编码。</p><p>输入序列表示：</p><script type="math/tex; mode=display">S_i= [< CLS >, Q, < SEP >, P_i, < SEP >]</script><ul><li>&lt; SEP &gt;标记用来分隔问题和段落。</li></ul><p>序列$S_i$中第$j^th$个token表示为：</p><script type="math/tex; mode=display">h^0_{ij}= s^{tok}_{ij} + s^{pos}_{ij}+ s^{seg}_{ij}</script><ul><li>分别表示token, position,和segment的embeddings。</li><li>position相同的token可以共享相同的position embedding。</li><li>同一问题或段落的token可以共享相同的segment embedding。</li></ul><h3 id="Paragraph-Selector"><a href="#Paragraph-Selector" class="headerlink" title="Paragraph Selector"></a>Paragraph Selector</h3><p>由于读取并为每个段落生成几个候选答案可能导致OOM问题，因此将第一个$L^{‘}$transformer blocks作为Paragraph Selector的输入。</p><h3 id="Token-level-Dynamic-Paragraph-Reader"><a href="#Token-level-Dynamic-Paragraph-Reader" class="headerlink" title="Token-level Dynamic Paragraph Reader"></a>Token-level Dynamic Paragraph Reader</h3><p>这一层旨在理解选择器中的S个段落，并为每个段落返回M个候选答案，分数按token级别而不是span级别计算。</p><p>token-level dynamic network 结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210705092003.png" alt="image-20210705092003366" style="zoom: 67%;" /></p><p>token-level dynamic network得到答案之间的分数，表明每个词是答案内容的概率。</p><p>动态是因为它可以根据边界token自动选择重要的token。</p><p>门控机制用于选择最重要的K个单词 。</p><h3 id="Hybrid-Answer-Verifier"><a href="#Hybrid-Answer-Verifier" class="headerlink" title="Hybrid Answer Verifier"></a>Hybrid Answer Verifier</h3><p>该模块通过构建两个模型的混合网络，可以有效地在候选答案中修剪噪音答案。</p><p>网络结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210705094738.png" alt="image-20210705094738594" style="zoom:67%;" /></p><ul><li>模型I旨在捕捉候选答案之间的语义关系。</li><li>模型II则寻找候选答案与输入序列之间的包含关系。</li></ul><h3 id="Joint-Training-and-Prediction"><a href="#Joint-Training-and-Prediction" class="headerlink" title="Joint Training and Prediction"></a>Joint Training and Prediction</h3><p>joint objective function：</p><script type="math/tex; mode=display">L = L_{PS}+ L_{PR}+ L_{AV}</script><p>在预测最终答案时，首先计算每个输入序列的selector得分，并选择前S段。然后，对于每个段落，生成M个具有边界分数和内容分数的候选答案。内容得分是通过使用动态门机制来计算的，该机制特别考虑了答案跨度中的重要词汇。还通过一个混合验证器对有噪声的候选答案进行修剪。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>SQuAD-document</li><li>SQuAD-open</li><li>Trivia-wiki</li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210705103045.png" alt="image-20210705103045073"></p><p>提出的TH-Net模型在SQuAD-document 和 SQuADopen上表现出了最佳的性能。</p><p>REQA采用了与本文类似的统一架构，但性能略低，证明token-level dynamic reader和hybrid verifier对性能提升有影响。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210705103110.png" alt="image-20210705103110529" style="zoom:67%;" /></p><p>在Trivia-wiki上模型依然取得了最佳的性能。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文提出的TH-Net旨在解决多段MRC任务。所提出的方法的优点是可以有效地理解token级的段落，并将答案之间的语义信息与答案和输入序列之间的关系信息结合起来。在三个具有挑战性的数据集上都表现出优秀的性能。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> TH-Net </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用LSTM预测股票行情</title>
      <link href="/2021/07/06/%E7%94%A8LSTM%E9%A2%84%E6%B5%8B%E8%82%A1%E7%A5%A8%E8%A1%8C%E6%83%85/"/>
      <url>/2021/07/06/%E7%94%A8LSTM%E9%A2%84%E6%B5%8B%E8%82%A1%E7%A5%A8%E8%A1%8C%E6%83%85/</url>
      
        <content type="html"><![CDATA[<p>这里采用沪深300指数数据，时间跨度为2010-10-10至今，选择每天最高价格。假设当天最高价依赖当天的前n（如30）天的沪深300的最高价。用LSTM模型来捕捉最高价的时序信息，通过训练模型，使之学会用前n天的最高价，判断当天的最高价（作为训练的标签值）。</p><h1 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h1><p>这里使用tushare来下载沪深300指数数据。可以用pip 安装tushare。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tushare <span class="keyword">as</span> ts  <span class="comment">#导入</span></span><br><span class="line">cons = ts.get_apis()   <span class="comment">#建立连接</span></span><br><span class="line"><span class="comment">#获取沪深指数(000300)的信息，包括交易日期（datetime）、开盘价(open)、收盘价(close)，</span></span><br><span class="line"><span class="comment">#最高价(high)、最低价(low)、成交量(vol)、成交金额(amount)、涨跌幅(p_change)</span></span><br><span class="line">df = ts.bar(<span class="string">&#x27;000300&#x27;</span>, conn=cons, asset=<span class="string">&#x27;INDEX&#x27;</span>, start_date=<span class="string">&#x27;2010-01-01&#x27;</span>, end_date=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"><span class="comment">#删除有null值的行</span></span><br><span class="line">df = df.dropna()</span><br><span class="line"><span class="comment">#把df保存到当前目录下的sh300.csv文件中，以便后续使用</span></span><br><span class="line">df.to_csv(<span class="string">&#x27;sh300.csv&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>本接口即将停止更新，请尽快使用Pro版接口：https://waditu.com/document/2</code></pre><h1 id="数据概览"><a href="#数据概览" class="headerlink" title="数据概览"></a>数据概览</h1><p>（1）查看下载数据的字段、统计信息等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看df涉及的列名</span></span><br><span class="line"><span class="built_in">print</span>(df.columns)</span><br><span class="line"><span class="comment"># Index([&#x27;code&#x27;, &#x27;open&#x27;, &#x27;close&#x27;, &#x27;high&#x27;, &#x27;low&#x27;, &#x27;vol&#x27;, &#x27;amount&#x27;, &#x27;p_change&#x27;], #dtype=&#x27;object&#x27;)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#查看df的统计信息</span></span><br><span class="line">df.describe()</span><br></pre></td></tr></table></figure><pre><code>Index([&#39;code&#39;, &#39;open&#39;, &#39;close&#39;, &#39;high&#39;, &#39;low&#39;, &#39;vol&#39;, &#39;amount&#39;, &#39;p_change&#39;], dtype=&#39;object&#39;)</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>open</th>      <th>close</th>      <th>high</th>      <th>low</th>      <th>vol</th>      <th>amount</th>      <th>p_change</th>    </tr>  </thead>  <tbody>    <tr>      <th>count</th>      <td>2795.000000</td>      <td>2795.000000</td>      <td>2795.000000</td>      <td>2795.000000</td>      <td>2.795000e+03</td>      <td>2.795000e+03</td>      <td>2795.000000</td>    </tr>    <tr>      <th>mean</th>      <td>3342.024819</td>      <td>3344.784845</td>      <td>3370.611827</td>      <td>3314.019947</td>      <td>1.146134e+06</td>      <td>1.499518e+11</td>      <td>0.023324</td>    </tr>    <tr>      <th>std</th>      <td>809.944990</td>      <td>810.070118</td>      <td>816.521375</td>      <td>800.923783</td>      <td>8.775841e+05</td>      <td>1.306605e+11</td>      <td>1.448982</td>    </tr>    <tr>      <th>min</th>      <td>2079.870000</td>      <td>2086.970000</td>      <td>2118.790000</td>      <td>2023.170000</td>      <td>2.190120e+05</td>      <td>2.120044e+10</td>      <td>-8.750000</td>    </tr>    <tr>      <th>25%</th>      <td>2618.540000</td>      <td>2620.265000</td>      <td>2645.770000</td>      <td>2598.400000</td>      <td>6.107925e+05</td>      <td>6.605147e+10</td>      <td>-0.640000</td>    </tr>    <tr>      <th>50%</th>      <td>3292.280000</td>      <td>3293.870000</td>      <td>3315.730000</td>      <td>3258.310000</td>      <td>8.908120e+05</td>      <td>1.074772e+11</td>      <td>0.040000</td>    </tr>    <tr>      <th>75%</th>      <td>3836.075000</td>      <td>3837.775000</td>      <td>3859.115000</td>      <td>3813.550000</td>      <td>1.344036e+06</td>      <td>1.847992e+11</td>      <td>0.720000</td>    </tr>    <tr>      <th>max</th>      <td>5922.070000</td>      <td>5807.720000</td>      <td>5930.910000</td>      <td>5747.660000</td>      <td>6.864391e+06</td>      <td>9.494980e+11</td>      <td>6.710000</td>    </tr>  </tbody></table></div><p>（2）可视化最高价数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df_index=df.code</span><br><span class="line">df_index = df_index.index.tolist()</span><br><span class="line"><span class="comment"># df_index=[str(year)[0:4] for year in df_index]</span></span><br><span class="line">df_all = np.array(df[<span class="string">&#x27;high&#x27;</span>].tolist())</span><br><span class="line">df=df[<span class="string">&#x27;high&#x27;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.plotting <span class="keyword">import</span> register_matplotlib_converters</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">register_matplotlib_converters()</span><br><span class="line"><span class="comment">#  获取训练数据、原始数据、索引等信息</span></span><br><span class="line">df, df_all, df_index = readData(<span class="string">&#x27;high&#x27;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#可视化最高价</span></span><br><span class="line">df_all = np.array(df_all.tolist())</span><br><span class="line">plt.plot(df_index, df_all, label=<span class="string">&#x27;real-data&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)  </span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.legend.Legend at 0x7fc8a932bfa0&gt;</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210706213411.png" alt="png"></p><h1 id="预处理数据"><a href="#预处理数据" class="headerlink" title="预处理数据"></a>预处理数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><p>（1）生成训练数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过一个序列来生成一个31*(count(*)-train_end)矩阵（用于处理时序的数据）</span></span><br><span class="line"><span class="comment">#其中最后一列维标签数据。就是把当天的前n天作为参数，当天的数据作为label</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_data_by_n_days</span>(<span class="params">series, n, index=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(series) &lt;= n:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">&quot;The Length of series is %d, while affect by (n=%d).&quot;</span> % (<span class="built_in">len</span>(series), n))</span><br><span class="line">    df = pd.DataFrame()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        df[<span class="string">&#x27;c%d&#x27;</span> % i] = series.tolist()[i:-(n - i)]        </span><br><span class="line">    df[<span class="string">&#x27;y&#x27;</span>] = series.tolist()[n:]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> index:</span><br><span class="line">        df.index = series.index[n:]</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"> </span><br><span class="line"><span class="comment">#参数n与上相同。train_end表示的是后面多少个数据作为测试集。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readData</span>(<span class="params">column=<span class="string">&#x27;high&#x27;</span>, n=<span class="number">30</span>, all_too=<span class="literal">True</span>, index=<span class="literal">False</span>, train_end=-<span class="number">500</span></span>):</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;sh300.csv&quot;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">    <span class="comment">#以日期为索引</span></span><br><span class="line">    df.index = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: datetime.datetime.strptime(x, <span class="string">&quot;%Y-%m-%d&quot;</span>), df.index))</span><br><span class="line">    <span class="comment">#获取每天的最高价</span></span><br><span class="line">    df_column = df[column].copy()</span><br><span class="line">    <span class="comment">#拆分为训练集和测试集</span></span><br><span class="line">    df_column_train, df_column_test = df_column[:train_end], df_column[train_end - n:]</span><br><span class="line">    <span class="comment">#生成训练数据</span></span><br><span class="line">    df_generate_train = generate_data_by_n_days(df_column_train, n, index=index)</span><br><span class="line">    <span class="keyword">if</span> all_too:</span><br><span class="line">        <span class="keyword">return</span> df_generate_train, df_column, df.index.tolist()</span><br><span class="line">    <span class="keyword">return</span> df_generate_train</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>（1）定义模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RNN, self).__init__()</span><br><span class="line">        self.rnn = nn.LSTM(</span><br><span class="line">            input_size=input_size,</span><br><span class="line">            hidden_size=<span class="number">64</span>,</span><br><span class="line">            num_layers=<span class="number">1</span>,</span><br><span class="line">            batch_first=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        self.out = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        r_out, (h_n, h_c) = self.rnn(x, <span class="literal">None</span>)  <span class="comment">#None即隐层状态用0初始化</span></span><br><span class="line">        out = self.out(r_out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mytrainset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data</span>):</span>        </span><br><span class="line">        self.data, self.label = data[:, :-<span class="number">1</span>].<span class="built_in">float</span>(), data[:, -<span class="number">1</span>].<span class="built_in">float</span>()</span><br><span class="line">             </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.data[index], self.label[index]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">2</span>）超参数设置</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">30</span></span><br><span class="line">LR = <span class="number">0.001</span></span><br><span class="line">EPOCH = <span class="number">200</span></span><br><span class="line">batch_size=<span class="number">20</span></span><br><span class="line">train_end =-<span class="number">600</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure><p>（3）训练模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas.plotting <span class="keyword">import</span> register_matplotlib_converters</span><br><span class="line">register_matplotlib_converters()</span><br><span class="line"><span class="comment"># 获取训练数据、原始数据、索引等信息</span></span><br><span class="line">df, df_all, df_index = readData(<span class="string">&#x27;high&#x27;</span>, n=n, train_end=train_end)</span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化原高价数据</span></span><br><span class="line">df_all = np.array(df_all.tolist())</span><br><span class="line">plt.plot(df_index, df_all, label=<span class="string">&#x27;real-data&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#对数据进行预处理，规范化及转换为Tensor</span></span><br><span class="line">df_numpy = np.array(df)</span><br><span class="line"></span><br><span class="line">df_numpy_mean = np.mean(df_numpy)</span><br><span class="line">df_numpy_std = np.std(df_numpy)</span><br><span class="line"></span><br><span class="line">df_numpy = (df_numpy - df_numpy_mean) / df_numpy_std</span><br><span class="line">df_tensor = torch.Tensor(df_numpy)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">trainset = mytrainset(df_tensor)</span><br><span class="line">trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210706213425.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#记录损失值，并用tensorboardx在web上展示</span></span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line">writer = SummaryWriter(log_dir=<span class="string">&#x27;logs&#x27;</span>)</span><br><span class="line"></span><br><span class="line">rnn = RNN(n).to(device)</span><br><span class="line">optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)  </span><br><span class="line">loss_func = nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH):</span><br><span class="line">    <span class="keyword">for</span> tx, ty <span class="keyword">in</span> trainloader:</span><br><span class="line">        tx=tx.to(device)</span><br><span class="line">        ty=ty.to(device)</span><br><span class="line">        <span class="comment">#在第1个维度上添加一个维度为1的维度，形状变为[batch,seq_len,input_size]</span></span><br><span class="line">        output = rnn(torch.unsqueeze(tx, dim=<span class="number">1</span>)).to(device)</span><br><span class="line">        loss = loss_func(torch.squeeze(output), ty)</span><br><span class="line">        optimizer.zero_grad()  </span><br><span class="line">        loss.backward()  </span><br><span class="line">        optimizer.step()</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;sh300_loss&#x27;</span>, loss, step)</span><br></pre></td></tr></table></figure><p>（4）测试模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">generate_data_train = []</span><br><span class="line">generate_data_test = []</span><br><span class="line"></span><br><span class="line">test_index = <span class="built_in">len</span>(df_all) + train_end</span><br><span class="line"></span><br><span class="line">df_all_normal = (df_all - df_numpy_mean) / df_numpy_std</span><br><span class="line">df_all_normal_tensor = torch.Tensor(df_all_normal)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n, <span class="built_in">len</span>(df_all)):</span><br><span class="line">    x = df_all_normal_tensor[i - n:i].to(device)</span><br><span class="line">    <span class="comment">#rnn的输入必须是3维，故需添加两个1维的维度，最后成为[1,1,input_size]</span></span><br><span class="line">    x = torch.unsqueeze(torch.unsqueeze(x, dim=<span class="number">0</span>), dim=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    y = rnn(x).to(device)</span><br><span class="line">    <span class="keyword">if</span> i &lt; test_index:</span><br><span class="line">        generate_data_train.append(torch.squeeze(y).detach().cpu().numpy() * df_numpy_std + df_numpy_mean)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        generate_data_test.append(torch.squeeze(y).detach().cpu().numpy() * df_numpy_std + df_numpy_mean)</span><br><span class="line">plt.plot(df_index[n:train_end], generate_data_train, label=<span class="string">&#x27;generate_train&#x27;</span>)</span><br><span class="line">plt.plot(df_index[train_end:], generate_data_test, label=<span class="string">&#x27;generate_test&#x27;</span>)</span><br><span class="line">plt.plot(df_index[train_end:], df_all[train_end:], label=<span class="string">&#x27;real-data&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210706213446.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.clf()</span><br><span class="line">plt.plot(df_index[train_end:-<span class="number">500</span>], df_all[train_end:-<span class="number">500</span>], label=<span class="string">&#x27;real-data&#x27;</span>)</span><br><span class="line">plt.plot(df_index[train_end:-<span class="number">500</span>], generate_data_test[-<span class="number">600</span>:-<span class="number">500</span>], label=<span class="string">&#x27;generate_test&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210706213449.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN——使用字符级RNN对名称进行分类</title>
      <link href="/2021/07/04/char_rnn_classification_tutorial/"/>
      <url>/2021/07/04/char_rnn_classification_tutorial/</url>
      
        <content type="html"><![CDATA[<h1 id="使用字符级-RNN-对名称进行分类"><a href="#使用字符级-RNN-对名称进行分类" class="headerlink" title="使用字符级 RNN 对名称进行分类"></a>使用字符级 RNN 对名称进行分类</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><p>字符级 RNN 将单词读取为一系列字符，在每一步输出预测和隐藏状态，将其先前的隐藏状态输入到下一时间步。将最终预测作为输出，即单词属于哪个类。</p><p>具体来说，我们将训练来自 18 种起源语言的数千个姓氏，并根据拼写预测名称来自哪种语言：<br>示例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ python predict.py Hinton</span><br><span class="line">(-0.47) Scottish</span><br><span class="line">(-1.52) English</span><br><span class="line">(-3.57) Irish</span><br><span class="line"></span><br><span class="line">$ python predict.py Schmidhuber</span><br><span class="line">(-0.19) German</span><br><span class="line">(-2.48) Czech</span><br><span class="line">(-2.68) Dutch</span><br></pre></td></tr></table></figure><p><strong>Note:</strong><br>   Download the data from<br>   <code>here &lt;https://download.pytorch.org/tutorial/data.zip&gt;</code>_<br>   and extract it to the current directory.</p><p>Included in the <code>data/names</code> directory are 18 text files named as<br>“[Language].txt”. Each file contains a bunch of names, one name per<br>line, mostly romanized (but we still need to convert from Unicode to<br>ASCII).</p><p>We’ll end up with a dictionary of lists of names per language,<br><code>&#123;language: [names ...]&#125;</code>. The generic variables “category” and “line”<br>(for language and name in our case) are used for later extensibility.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> unicode_literals, print_function, division</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">findFiles</span>(<span class="params">path</span>):</span> <span class="keyword">return</span> glob.glob(path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(findFiles(<span class="string">&#x27;data/names/*.txt&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> unicodedata</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成单词列表all_letters，后续one-hot编码中用来查找索引</span></span><br><span class="line">all_letters = string.ascii_letters + <span class="string">&quot; .,;&#x27;&quot;</span></span><br><span class="line"><span class="comment"># n_letters 字符总数</span></span><br><span class="line">n_letters = <span class="built_in">len</span>(all_letters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unicodeToAscii</span>(<span class="params">s</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(</span><br><span class="line">        c <span class="keyword">for</span> c <span class="keyword">in</span> unicodedata.normalize(<span class="string">&#x27;NFD&#x27;</span>, s)</span><br><span class="line">        <span class="keyword">if</span> unicodedata.category(c) != <span class="string">&#x27;Mn&#x27;</span></span><br><span class="line">        <span class="keyword">and</span> c <span class="keyword">in</span> all_letters</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nunicodeToAscii:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(unicodeToAscii(<span class="string">&#x27;Ślusàrski&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build the category_lines dictionary, a list of names per language</span></span><br><span class="line">category_lines = &#123;&#125;</span><br><span class="line">all_categories = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read a file and split into lines</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readLines</span>(<span class="params">filename</span>):</span></span><br><span class="line">    lines = <span class="built_in">open</span>(filename, encoding=<span class="string">&#x27;utf-8&#x27;</span>).read().strip().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> [unicodeToAscii(line) <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> findFiles(<span class="string">&#x27;data/names/*.txt&#x27;</span>):</span><br><span class="line">    category = os.path.splitext(os.path.basename(filename))[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># os.path.splitext 分割文件名和扩展名</span></span><br><span class="line"><span class="comment"># os.path.basename 返回文件名</span></span><br><span class="line">    all_categories.append(category)</span><br><span class="line">    lines = readLines(filename)</span><br><span class="line">    category_lines[category] = lines</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="comment"># print(category_lines)</span></span><br><span class="line">n_categories = <span class="built_in">len</span>(all_categories)</span><br><span class="line"><span class="built_in">print</span>(n_categories)</span><br></pre></td></tr></table></figure><pre><code>[&#39;data/names/Czech.txt&#39;, &#39;data/names/German.txt&#39;, &#39;data/names/Arabic.txt&#39;, &#39;data/names/Japanese.txt&#39;, &#39;data/names/Chinese.txt&#39;, &#39;data/names/Vietnamese.txt&#39;, &#39;data/names/Russian.txt&#39;, &#39;data/names/French.txt&#39;, &#39;data/names/Irish.txt&#39;, &#39;data/names/English.txt&#39;, &#39;data/names/Spanish.txt&#39;, &#39;data/names/Greek.txt&#39;, &#39;data/names/Italian.txt&#39;, &#39;data/names/Portuguese.txt&#39;, &#39;data/names/Scottish.txt&#39;, &#39;data/names/Dutch.txt&#39;, &#39;data/names/Korean.txt&#39;, &#39;data/names/Polish.txt&#39;]unicodeToAscii:Slusarski18</code></pre><p>得到category_lines字典后，查看样例数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(category_lines[<span class="string">&#x27;Italian&#x27;</span>][:<span class="number">5</span>])</span><br></pre></td></tr></table></figure><pre><code>[&#39;Abandonato&#39;, &#39;Abatangelo&#39;, &#39;Abatantuono&#39;, &#39;Abate&#39;, &#39;Abategiovanni&#39;]</code></pre><h2 id="把名字转换成-Tensors"><a href="#把名字转换成-Tensors" class="headerlink" title="把名字转换成 Tensors"></a>把名字转换成 Tensors</h2><p>为了表示单个字母，使用one-hot向量。除了当前字母的索引处为1外，其余用0填充，例如<code>&quot;b&quot; = &lt;0 1 0 0 0 ...&gt;</code></p><p>为了创建一个单词，我们将一堆单词连接到一个 2D 矩阵中。<code>&lt;line_length x 1 x n_letters&gt;</code></p><p>额外的 1 维是因为 PyTorch 假设一切都是批量的，在这里使批量大小1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(all_letters)</span><br><span class="line"><span class="comment"># Find letter index from all_letters, e.g. &quot;a&quot; = 0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">letterToIndex</span>(<span class="params">letter</span>):</span></span><br><span class="line">    <span class="keyword">return</span> all_letters.find(letter)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Just for demonstration, turn a letter into a &lt;1 x n_letters&gt; Tensor</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">letterToTensor</span>(<span class="params">letter</span>):</span></span><br><span class="line">    tensor = torch.zeros(<span class="number">1</span>, n_letters)</span><br><span class="line"><span class="comment">#     print(tensor)</span></span><br><span class="line">    tensor[<span class="number">0</span>][letterToIndex(letter)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> tensor</span><br><span class="line"></span><br><span class="line"><span class="comment"># Turn a line into a &lt;line_length x 1 x n_letters&gt;,</span></span><br><span class="line"><span class="comment"># or an array of one-hot letter vectors</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lineToTensor</span>(<span class="params">line</span>):</span></span><br><span class="line">    tensor = torch.zeros(<span class="built_in">len</span>(line), <span class="number">1</span>, n_letters)</span><br><span class="line">    <span class="keyword">for</span> li, letter <span class="keyword">in</span> <span class="built_in">enumerate</span>(line):</span><br><span class="line">        tensor[li][<span class="number">0</span>][letterToIndex(letter)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> tensor</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(letterToTensor(<span class="string">&#x27;a&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;lineToTensor\n&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(lineToTensor(<span class="string">&#x27;Jones&#x27;</span>).size())</span><br><span class="line"><span class="built_in">print</span>(lineToTensor(<span class="string">&#x27;Jones&#x27;</span>))</span><br></pre></td></tr></table></figure><pre><code>abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;&#39;tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0.]])lineToTensortorch.Size([5, 1, 57])tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0.]],        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0.]],        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0.]],        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0.]],        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,          0., 0., 0., 0., 0., 0.]]])</code></pre><h1 id="创建网络"><a href="#创建网络" class="headerlink" title="创建网络"></a>创建网络</h1><p>该RNN网络有2个线性层，对输入和隐藏状态进行操作，输出后有一个 LogSoftmax层。<br><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210704010147.png" alt="Unknown"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, hidden_size, output_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(RNN, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.hidden_size = hidden_size <span class="comment">#隐藏层大小</span></span><br><span class="line"></span><br><span class="line">        self.i2h = nn.Linear(input_size + hidden_size, hidden_size) <span class="comment">#输入到隐藏层的矩阵</span></span><br><span class="line">        self.i2o = nn.Linear(input_size + hidden_size, output_size) <span class="comment">#输入到输出的矩阵</span></span><br><span class="line">        self.softmax = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span>, hidden</span>):</span></span><br><span class="line">        combined = torch.cat((<span class="built_in">input</span>, hidden), <span class="number">1</span>)</span><br><span class="line">        hidden = self.i2h(combined)</span><br><span class="line"><span class="comment">#         output = self.i2o(combined)</span></span><br><span class="line">        output = self.softmax(self.i2o(combined))</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initHidden</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, self.hidden_size)</span><br><span class="line"></span><br><span class="line">n_hidden = <span class="number">128</span></span><br><span class="line"><span class="built_in">print</span>(n_letters, n_hidden, n_categories)</span><br><span class="line">rnn = RNN(n_letters, n_hidden, n_categories)</span><br><span class="line"><span class="built_in">print</span>(rnn.i2h)</span><br></pre></td></tr></table></figure><pre><code>57 128 18Linear(in_features=185, out_features=128, bias=True)</code></pre><p>为了运行这个网络的一个时间步长，需要传递一个输入（在我们的例子中，为当前字母的张量）和一个先前的隐藏状态（首先将其初始化为零。得到输出（每种语言的概率）和下一个隐藏状态。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = letterToTensor(<span class="string">&#x27;A&#x27;</span>)</span><br><span class="line">hidden = torch.zeros(<span class="number">1</span>, n_hidden)</span><br><span class="line"></span><br><span class="line">output, next_hidden = rnn(<span class="built_in">input</span>, hidden)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure><pre><code>tensor([[-3.0130, -2.8982, -2.9242, -2.9052, -2.8677, -2.8176, -2.9350, -2.9060,         -2.8688, -2.9518, -2.9790, -2.9274, -2.8601, -2.8504, -2.8594, -2.8165,         -2.8698, -2.8037]], grad_fn=&lt;LogSoftmaxBackward&gt;)</code></pre><p>为了效率起见，不想为每一步都创建一个新的张量，所以将使用lineToTensor代替letterToTensor和使用切片。这可以通过预先计算批量张量来进一步优化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">input</span> = lineToTensor(<span class="string">&#x27;Albert&#x27;</span>)</span><br><span class="line">hidden = torch.zeros(<span class="number">1</span>, n_hidden)</span><br><span class="line"></span><br><span class="line">output, next_hidden = rnn(<span class="built_in">input</span>[<span class="number">0</span>], hidden)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>tensor([[-3.0130, -2.8982, -2.9242, -2.9052, -2.8677, -2.8176, -2.9350, -2.9060,         -2.8688, -2.9518, -2.9790, -2.9274, -2.8601, -2.8504, -2.8594, -2.8165,         -2.8698, -2.8037]], grad_fn=&lt;LogSoftmaxBackward&gt;)</code></pre><p>输出是一个张量，其中每个项目都是该类别的可能性（越高可能性越大）。<code>&lt;1 x n_categories&gt;</code></p><h1 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h1><h2 id="Preparing-for-Training"><a href="#Preparing-for-Training" class="headerlink" title="Preparing for Training"></a>Preparing for Training</h2><p>解释网络的输出：输出是每个类别的可能性。可以使用Tensor.topk获取最大值的索引：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">categoryFromOutput</span>(<span class="params">output</span>):</span></span><br><span class="line">    top_n, top_i = output.topk(<span class="number">1</span>)</span><br><span class="line"><span class="comment">#     print(top_n, top_i)</span></span><br><span class="line">    category_i = top_i[<span class="number">0</span>].item()</span><br><span class="line">    <span class="keyword">return</span> all_categories[category_i], category_i</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(categoryFromOutput(output))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>(&#39;Portuguese&#39;, 13)</code></pre><p>需要一种快速获取训练示例（名称及其语言）的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomChoice</span>(<span class="params">l</span>):</span></span><br><span class="line">    <span class="keyword">return</span> l[random.randint(<span class="number">0</span>, <span class="built_in">len</span>(l) - <span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randomTrainingExample</span>():</span></span><br><span class="line">    category = randomChoice(all_categories)</span><br><span class="line">    line = randomChoice(category_lines[category])</span><br><span class="line">    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)</span><br><span class="line">    line_tensor = lineToTensor(line)</span><br><span class="line">    <span class="keyword">return</span> category, line, category_tensor, line_tensor</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    category, line, category_tensor, line_tensor = randomTrainingExample()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;category =&#x27;</span>, category, <span class="string">&#x27;/ line =&#x27;</span>, line)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><pre><code>category = Vietnamese / line = Macategory = Japanese / line = Aidacategory = Portuguese / line = De santigocategory = Italian / line = Piovenecategory = Scottish / line = Taylorcategory = Spanish / line = Benitezcategory = Vietnamese / line = Quachcategory = Arabic / line = Sleimancategory = Russian / line = To The First Pagecategory = Korean / line = Kwang </code></pre><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>RNN 的最后一层是nn.LogSoftmax，所以选择损失函数nn.NLLLoss。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.NLLLoss()</span><br></pre></td></tr></table></figure><p>Each loop of training will:</p><ul><li>Create input and target tensors</li><li>Create a zeroed initial hidden state</li><li>Read each letter in and Keep hidden state for next letter</li><li>Compare final output to target</li><li>Back-propagate</li><li>Return the output and loss</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.005</span> <span class="comment"># If you set this too high, it might explode. If too low, it might not learn</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">category_tensor, line_tensor</span>):</span></span><br><span class="line">    hidden = rnn.initHidden()</span><br><span class="line"></span><br><span class="line">    rnn.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(line_tensor.size()[<span class="number">0</span>]):</span><br><span class="line"><span class="comment">#  line_tensor是多个字母tensor的组合列表</span></span><br><span class="line"><span class="comment">#  循环中更新 hidden</span></span><br><span class="line">        output, hidden = rnn(line_tensor[i], hidden)</span><br><span class="line"></span><br><span class="line">    loss = criterion(output, category_tensor)</span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add parameters&#x27; gradients to their values, multiplied by learning rate</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> rnn.parameters():</span><br><span class="line">        p.data.add_(p.grad.data, alpha=-learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output, loss.item()</span><br></pre></td></tr></table></figure><p>现在只需要用一堆例子来运行它。由于该 train函数返回输出和损失，我们可以打印它的预测值并绘制损失变化图。由于有 1000 个示例，我们只打印每个print_every示例，并取损失的平均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">n_iters = <span class="number">100000</span></span><br><span class="line">print_every = <span class="number">5000</span></span><br><span class="line">plot_every = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Keep track of losses for plotting</span></span><br><span class="line">current_loss = <span class="number">0</span></span><br><span class="line">all_losses = []</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timeSince</span>(<span class="params">since</span>):</span></span><br><span class="line">    now = time.time()</span><br><span class="line">    s = now - since</span><br><span class="line">    m = math.floor(s / <span class="number">60</span>)</span><br><span class="line">    s -= m * <span class="number">60</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;%dm %ds&#x27;</span> % (m, s)</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_iters + <span class="number">1</span>):</span><br><span class="line">    category, line, category_tensor, line_tensor = randomTrainingExample()</span><br><span class="line">    output, loss = train(category_tensor, line_tensor)</span><br><span class="line">    current_loss += loss</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print iter number, loss, name and guess</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">iter</span> % print_every == <span class="number">0</span>:</span><br><span class="line">        guess, guess_i = categoryFromOutput(output)</span><br><span class="line">        correct = <span class="string">&#x27;✓&#x27;</span> <span class="keyword">if</span> guess == category <span class="keyword">else</span> <span class="string">&#x27;✗ (%s)&#x27;</span> % category</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%d %d%% (%s) %.4f %s / %s %s&#x27;</span> % (<span class="built_in">iter</span>, <span class="built_in">iter</span> / n_iters * <span class="number">100</span>, timeSince(start), loss, line, guess, correct))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add current loss avg to list of losses</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">iter</span> % plot_every == <span class="number">0</span>:</span><br><span class="line">        all_losses.append(current_loss / plot_every)</span><br><span class="line">        current_loss = <span class="number">0</span></span><br></pre></td></tr></table></figure><pre><code>tensor([[-2.4746]], grad_fn=&lt;TopkBackward&gt;) tensor([[3]])5000 5% (0m 6s) 2.6255 Ventura / Japanese ✗ (Portuguese)tensor([[-1.8169]], grad_fn=&lt;TopkBackward&gt;) tensor([[16]])10000 10% (0m 13s) 3.0541 Kron / Korean ✗ (German)tensor([[-1.0685]], grad_fn=&lt;TopkBackward&gt;) tensor([[4]])15000 15% (0m 20s) 1.0685 Ming / Chinese ✓tensor([[-1.7141]], grad_fn=&lt;TopkBackward&gt;) tensor([[1]])20000 20% (0m 27s) 1.7141 Sommer / German ✓tensor([[-1.7253]], grad_fn=&lt;TopkBackward&gt;) tensor([[7]])25000 25% (0m 34s) 1.8872 Maurice / French ✗ (Irish)tensor([[-0.1941]], grad_fn=&lt;TopkBackward&gt;) tensor([[3]])30000 30% (0m 41s) 0.1941 Jukodo / Japanese ✓tensor([[-1.1135]], grad_fn=&lt;TopkBackward&gt;) tensor([[2]])35000 35% (0m 48s) 1.1135 Khouri / Arabic ✓tensor([[-0.2534]], grad_fn=&lt;TopkBackward&gt;) tensor([[12]])40000 40% (0m 55s) 0.2534 Pietri / Italian ✓tensor([[-0.3285]], grad_fn=&lt;TopkBackward&gt;) tensor([[11]])45000 45% (1m 3s) 0.3285 Panayiotopoulos / Greek ✓tensor([[-0.7564]], grad_fn=&lt;TopkBackward&gt;) tensor([[4]])50000 50% (1m 11s) 0.7564 Song / Chinese ✓tensor([[-0.6697]], grad_fn=&lt;TopkBackward&gt;) tensor([[12]])55000 55% (1m 18s) 2.2053 Castellano / Italian ✗ (Spanish)tensor([[-1.1335]], grad_fn=&lt;TopkBackward&gt;) tensor([[1]])60000 60% (1m 26s) 2.1380 Nunez / German ✗ (Spanish)tensor([[-1.0437]], grad_fn=&lt;TopkBackward&gt;) tensor([[3]])65000 65% (1m 33s) 1.0437 Ichiyusai / Japanese ✓tensor([[-0.9454]], grad_fn=&lt;TopkBackward&gt;) tensor([[12]])70000 70% (1m 40s) 1.7417 Cardozo / Italian ✗ (Portuguese)tensor([[-1.5786]], grad_fn=&lt;TopkBackward&gt;) tensor([[1]])75000 75% (1m 47s) 2.0613 Macclelland / German ✗ (Irish)tensor([[-0.9435]], grad_fn=&lt;TopkBackward&gt;) tensor([[16]])80000 80% (1m 55s) 0.9435 Ri / Korean ✓tensor([[-1.7442]], grad_fn=&lt;TopkBackward&gt;) tensor([[14]])85000 85% (2m 3s) 2.6989 Bran / Scottish ✗ (Irish)tensor([[-1.1392]], grad_fn=&lt;TopkBackward&gt;) tensor([[7]])90000 90% (2m 11s) 1.1392 Victor / French ✓tensor([[-0.8626]], grad_fn=&lt;TopkBackward&gt;) tensor([[5]])95000 95% (2m 19s) 0.8626 Ton / Vietnamese ✓tensor([[-0.7950]], grad_fn=&lt;TopkBackward&gt;) tensor([[14]])100000 100% (2m 28s) 4.5470 Budny / Scottish ✗ (Polish)</code></pre><h2 id="Plotting-the-Results"><a href="#Plotting-the-Results" class="headerlink" title="Plotting the Results"></a>Plotting the Results</h2><p>Plotting the historical loss from <code>all_losses</code> shows the network<br>learning:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> ticker</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(all_losses)</span><br></pre></td></tr></table></figure><pre><code>[&lt;matplotlib.lines.Line2D at 0x7fbbb7b60f10&gt;]</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210704005859.png" alt="png"></p><h1 id="Evaluating-the-Results"><a href="#Evaluating-the-Results" class="headerlink" title="Evaluating the Results"></a>Evaluating the Results</h1><p>To see how well the network performs on different categories, we will<br>create a confusion matrix, indicating for every actual language (rows)<br>which language the network guesses (columns). To calculate the confusion<br>matrix a bunch of samples are run through the network with<br><code>evaluate()</code>, which is the same as <code>train()</code> minus the backprop.</p><p>为了查看网络在不同类别上的表现如何，我们将创建一个混淆矩阵，actual language (rows)，the network guesses (columns)。运行 evaluate()计算混淆矩阵，这与train()减去反向传播相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Keep track of correct guesses in a confusion matrix</span></span><br><span class="line">confusion = torch.zeros(n_categories, n_categories)</span><br><span class="line">n_confusion = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Just return an output given a line</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">line_tensor</span>):</span></span><br><span class="line">    hidden = rnn.initHidden()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(line_tensor.size()[<span class="number">0</span>]):</span><br><span class="line">        output, hidden = rnn(line_tensor[i], hidden)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># Go through a bunch of examples and record which are correctly guessed</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_confusion):</span><br><span class="line">    category, line, category_tensor, line_tensor = randomTrainingExample()</span><br><span class="line">    output = evaluate(line_tensor)</span><br><span class="line">    guess, guess_i = categoryFromOutput(output)</span><br><span class="line">    category_i = all_categories.index(category)</span><br><span class="line">    confusion[category_i][guess_i] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize by dividing every row by its sum</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_categories):</span><br><span class="line">    confusion[i] = confusion[i] / confusion[i].<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up plot</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">cax = ax.matshow(confusion.numpy())</span><br><span class="line">fig.colorbar(cax)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up axes</span></span><br><span class="line">ax.set_xticklabels([<span class="string">&#x27;&#x27;</span>] + all_categories, rotation=<span class="number">90</span>)</span><br><span class="line">ax.set_yticklabels([<span class="string">&#x27;&#x27;</span>] + all_categories)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Force label at every tick</span></span><br><span class="line">ax.xaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line">ax.yaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># sphinx_gallery_thumbnail_number = 2</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><pre><code>&lt;ipython-input-61-a5b341ffc3a3&gt;:33: UserWarning: FixedFormatter should only be used together with FixedLocator  ax.set_xticklabels([&#39;&#39;] + all_categories, rotation=90)&lt;ipython-input-61-a5b341ffc3a3&gt;:34: UserWarning: FixedFormatter should only be used together with FixedLocator  ax.set_yticklabels([&#39;&#39;] + all_categories)</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210704005908.png" alt="png"></p><p>You can pick out bright spots off the main axis that show which<br>languages it guesses incorrectly, e.g. Chinese for Korean, and Spanish<br>for Italian. It seems to do very well with Greek, and very poorly with<br>English (perhaps because of overlap with other languages).</p><h2 id="Running-on-User-Input"><a href="#Running-on-User-Input" class="headerlink" title="Running on User Input"></a>Running on User Input</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">input_line, n_predictions=<span class="number">3</span></span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\n&gt; %s&#x27;</span> % input_line)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        output = evaluate(lineToTensor(input_line))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Get top N categories</span></span><br><span class="line">        topv, topi = output.topk(n_predictions, <span class="number">1</span>, <span class="literal">True</span>)</span><br><span class="line">        predictions = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_predictions):</span><br><span class="line">            value = topv[<span class="number">0</span>][i].item()</span><br><span class="line">            category_index = topi[<span class="number">0</span>][i].item()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;(%.2f) %s&#x27;</span> % (value, all_categories[category_index]))</span><br><span class="line">            predictions.append([value, all_categories[category_index]])</span><br><span class="line"></span><br><span class="line">predict(<span class="string">&#x27;Dovesky&#x27;</span>)</span><br><span class="line">predict(<span class="string">&#x27;Jackson&#x27;</span>)</span><br><span class="line">predict(<span class="string">&#x27;Satoshi&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>&gt; Dovesky(-0.55) Russian(-1.52) Czech(-1.98) Polish&gt; Jackson(-1.27) Scottish(-1.61) French(-1.83) English&gt; Satoshi(-1.15) Italian(-1.88) Portuguese(-1.96) Polish</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN循环神经网络</title>
      <link href="/2021/07/03/RNN%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2021/07/03/RNN%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="RNN循环神经网络"><a href="#RNN循环神经网络" class="headerlink" title="RNN循环神经网络"></a>RNN循环神经网络</h1><ul><li>序列数据：与先后顺序有关的数据。</li><li>对于序列数据，可以使用循环神经网络。</li></ul><script type="math/tex; mode=display">H_t=ϕ(X_tW_{xh}+H_{t−1}W_{hh}+b_h)</script><script type="math/tex; mode=display">O_t=H_tW_{hq}+b_q</script><blockquote><p>$X_t∈R^{n×d}$是序列中时间步$t$小批量输入。</p><p>$H_t∈R^{n×h}$是该时间步的隐藏变量。</p><p>隐藏层的权重$W<em>{xh}∈R^{d×h}$、$W</em>{hh}∈R^{h×h}$和偏差 $b_h∈R^{1×h}$ </p><p>输出层的权重$W_{hq}∈R^{h×q}$和偏差$b_q∈R^{1×q}$</p><p>时间步$t$的隐藏变量的计算由当前时间步的输入和上一时间步的隐藏变量共同决定。</p></blockquote><p>其中：$X<em>tW</em>{xh}+H<em>{t−1}W</em>{hh}$可以写成矩阵$[X<em>t,H</em>{t−1}]^T$与$[W<em>{xh},W</em>{hh}]$连接后的乘积。</p><p>含隐藏状态的循环神经网络:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201119164943.png" alt="image-20201119164943208" style="zoom:50%;" /></p><blockquote><p>在时间步$t$，隐藏状态的计算可以看成是将输入$X<em>t$和前一时间步隐藏状态$H</em>{t−1}$连结后输入一个激活函数为$ϕ$的全连接层。</p><p>该全连接层的输出就是当前时间步的隐藏状态$Ht$ ，且模型参数为W<em>xh与$W</em>{hh}$ 的连结，偏差为$b_h$。</p><p>当前时间步$t$的隐藏状态$H<em>t$将参与下一个时间步$t+1$的隐藏状态$H</em>{t+1}$ 的计算，并输入到当前时间步的全连接输出层。</p></blockquote><p>前面说到$X<em>tW</em>{xh}+H<em>{t−1}W</em>{hh}$等价于矩阵$[X<em>t,H</em>{t−1}]^T$与$[W<em>{xh},W</em>{hh}]$连接后的乘积，我们来验证一下：</p><p>构造矩阵：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line">X, W_xh = torch.randn(3, 1), torch.randn(1, 4)</span><br><span class="line">H, W_hh = torch.randn(3, 4), torch.randn(4, 4)</span><br></pre></td></tr></table></figure><p>代入公式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.matmul(X, W_xh) + torch.matmul(H, W_hh)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.2453, -0.3466,  1.1116, -2.0741],</span><br><span class="line">        [ 7.5939,  0.3180,  0.7647,  2.4541],</span><br><span class="line">        [ 2.9573, -0.0598,  0.1762,  0.1142]])</span><br></pre></td></tr></table></figure><p>矩阵连接之后：</p><blockquote><p>dim=1：列拼接</p><p>dim=0：行拼接</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.matmul(torch.cat((X, H), dim=1), torch.cat((W_xh, W_hh), dim=0))</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.2453, -0.3466,  1.1116, -2.0741],</span><br><span class="line">        [ 7.5939,  0.3180,  0.7647,  2.4541],</span><br><span class="line">        [ 2.9573, -0.0598,  0.1762,  0.1142]])</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python——os.path模块常用方法汇总</title>
      <link href="/2021/07/03/python%E2%80%94%E2%80%94os.path%E6%A8%A1%E5%9D%97%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/"/>
      <url>/2021/07/03/python%E2%80%94%E2%80%94os.path%E6%A8%A1%E5%9D%97%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="os-path模块常用方法汇总"><a href="#os-path模块常用方法汇总" class="headerlink" title="os.path模块常用方法汇总"></a>os.path模块常用方法汇总</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">os.path.abspath(path) #返回绝对路径</span><br><span class="line">os.path.basename(path) #返回文件名</span><br><span class="line">os.path.commonprefix(list) #返回list(多个路径)中，所有path共有的最长的路径。</span><br><span class="line">os.path.dirname(path) #返回文件路径</span><br><span class="line">os.path.exists(path)  #路径存在则返回True,路径损坏返回False</span><br><span class="line">os.path.lexists  #路径存在则返回True,路径损坏也返回True</span><br><span class="line">os.path.expanduser(path)  #把path中包含的&quot;~&quot;和&quot;~user&quot;转换成用户目录</span><br><span class="line">os.path.expandvars(path)  #根据环境变量的值替换path中包含的”$name”和”$&#123;name&#125;”</span><br><span class="line">os.path.getatime(path)  #返回最后一次进入此path的时间。</span><br><span class="line">os.path.getmtime(path)  #返回在此path下最后一次修改的时间。</span><br><span class="line">os.path.getctime(path)  #返回path的大小</span><br><span class="line">os.path.getsize(path)  #返回文件大小，如果文件不存在就返回错误</span><br><span class="line">os.path.isabs(path)  #判断是否为绝对路径</span><br><span class="line">os.path.isfile(path)  #判断路径是否为文件</span><br><span class="line">os.path.isdir(path)  #判断路径是否为目录</span><br><span class="line">os.path.islink(path)  #判断路径是否为链接</span><br><span class="line">os.path.ismount(path)  #判断路径是否为挂载点（）</span><br><span class="line">os.path.join(path1[, path2[, ...]])  #把目录和文件名合成一个路径</span><br><span class="line">os.path.normcase(path)  #转换path的大小写和斜杠</span><br><span class="line">os.path.normpath(path)  #规范path字符串形式</span><br><span class="line">os.path.realpath(path)  #返回path的真实路径</span><br><span class="line">os.path.relpath(path[, start])  #从start开始计算相对路径</span><br><span class="line">os.path.samefile(path1, path2)  #判断目录或文件是否相同</span><br><span class="line">os.path.sameopenfile(fp1, fp2)  #判断fp1和fp2是否指向同一文件</span><br><span class="line">os.path.samestat(stat1, stat2)  #判断stat tuple stat1和stat2是否指向同一个文件</span><br><span class="line">os.path.split(path)  #把路径分割成dirname和basename，返回一个元组</span><br><span class="line">os.path.splitdrive(path)   #一般用在windows下，返回驱动器名和路径组成的元组</span><br><span class="line">os.path.splitext(path)  #分割路径，返回路径名和文件扩展名的元组</span><br><span class="line">os.path.splitunc(path)  #把路径分割为加载点与文件</span><br><span class="line">os.path.walk(path, visit, arg)  #遍历path，进入每个目录都调用visit函数，visit函数必须有</span><br><span class="line">3个参数(arg, dirname, names)，dirname表示当前目录的目录名，names代表当前目录下的所有</span><br><span class="line">文件名，args则为walk的第三个参数</span><br><span class="line">os.path.supports_unicode_filenames  #设置是否支持unicode路径名</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> os.path </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension</title>
      <link href="/2021/07/02/Recurrent%20Chunking%20Mechanisms%20for%20Long-Text%20Machine%20Reading%20Comprehension/"/>
      <url>/2021/07/02/Recurrent%20Chunking%20Mechanisms%20for%20Long-Text%20Machine%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="Recurrent-Chunking-Mechanisms-for-Long-Text-Machine-Reading-Comprehension"><a href="#Recurrent-Chunking-Mechanisms-for-Long-Text-Machine-Reading-Comprehension" class="headerlink" title="Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension"></a>Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension</h1><blockquote><p><a href="https://arxiv.org/abs/2005.08056">论文：https://arxiv.org/abs/2005.08056</a></p><p>代码：<a href="https://github.com/HongyuGong/RCM-Question-Answering">https://github.com/HongyuGong/RCM-Question-Answering</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>传统的基于transformer的模型只能接受固定长度（如512）的文本作为其输入。为了处理更长的文本输入，以前的方法通常将它们分割成等距的片段，并根据每个片段独立预测答案，而不考虑其他片段的信息。因此，可能会形成不能覆盖正确答案跨度的片段，或在其周围保留不充分的上下文，大大降低性能。此外，回答需要跨段信息的问题的能力较差。本文提出recurrent chunking机制(RCM)提升长文本机器阅读理解的性能，以防止答案跨度过于接近段的边界和覆盖不完整的答案。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>通过强化学习，让模型以更灵活的方式学习分块：模型可以决定它要处理的下一个片段的方向。还采用了递归机制，使信息能够跨段流动。</p><p><strong>传统方法：</strong></p><p>首先将输入的文本分成等距的片段，然后预测每个单独片段的答案，最后将多个片段的答案集合在一起。</p><ul><li>传统方法缺陷<ul><li>预先确定的大跨度的分块可能会导致答案不完整，并且当答案在段的边界附近时，与答案在段的中心，周围有更丰富的上下文时相比，模型更容易失败。</li><li>根据经验观察到，较小跨度的分块对模型性能的贡献很小（有时甚至伤害了）。</li></ul></li></ul><p>recurrent chunking mechanisms (RCM)</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210703105842.png" alt="image-20210703105842803"></p><ul><li>特征<ul><li>可以让meachine reader通过强化学习来学习如何在阅读冗长的文件时智能地选择步幅大小，有助于防止从片段中提取不完整的答案，并在答案周围保留足够的语境</li><li>应用递归机制，让信息在各段之间流动。该模型可以访问当前片段以外的全局上下文信息。</li></ul></li></ul><p>使用BERT生成向量表示，使用max pooling实现答案融合。</p><p>基线模型对每个文档段进行独立的答案预测，由于缺乏文档级别的信息，可能会导致不同段的答案得分无法比较。本文使用一个递归层来传播不同片段的信息，并使用分块评分器模型（chunking scorer model）来估计一个片段包含答案的概率。</p><p>两个递归机制：</p><ul><li>gated recurrence</li><li>Long Short Term Memory (LSTM)</li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li><p>CoQA</p></li><li><p>QuAC</p></li><li>TriviaQA</li></ul><h2 id="性能水平-amp-结论"><a href="#性能水平-amp-结论" class="headerlink" title="性能水平&amp;结论"></a>性能水平&amp;结论</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210703114724.png" alt="image-20210703114724411"></p><p>BERT-Large模型的性能随着最大序列长度的减小，性能急剧下降。当最大输入长度从512下降到192时，CoQA数据集的F1分数下降了8.6%，QuAC数据集的F1分数下降了27.0%。</p><p>具有recurrent机制的BERT-RCM性能优于BERT-Large和BERT-Sent-Selector。</p><p>RCM模型对最大序列长度不太敏感，而LSTM的性能与gated recurrence性能接近。</p><p><strong>不同stride size的性能比较：</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210703122850.png" alt="image-20210703122850502"></p><p>过小的stride size不会提升模型准确率反而会降低模型性能。</p><p><strong>效果展示</strong>：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210703123834.png" alt="image-20210703123834755"></p><p>在三个MRC数据集CoQA、QuAC和TriviaQA上的实验证明了本文提出的递归分块机制的有效性，可以获得更有可能包含完整答案的片段，同时为更好的预测提供围绕真实答案的足够上下文。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> RCM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamic Sampling Strategies for Multi-Task Reading Comprehension.md</title>
      <link href="/2021/06/04/Dynamic%20Sampling%20Strategies%20for%20Multi-Task%20Reading%20Comprehension/"/>
      <url>/2021/06/04/Dynamic%20Sampling%20Strategies%20for%20Multi-Task%20Reading%20Comprehension/</url>
      
        <content type="html"><![CDATA[<h1 id="Dynamic-Sampling-Strategies-for-Multi-Task-Reading-Comprehension"><a href="#Dynamic-Sampling-Strategies-for-Multi-Task-Reading-Comprehension" class="headerlink" title="Dynamic Sampling Strategies for Multi-Task Reading Comprehension"></a>Dynamic Sampling Strategies for Multi-Task Reading Comprehension</h1><blockquote><p> <a href="https://www.aclweb.org/anthology/2020.acl-main.86.pdf">论文：https://www.aclweb.org/anthology/2020.acl-main.86.pdf</a></p><p> <a href="https://github.com/mrqa/MRQA-Shared-Task-2019">代码：https://github.com/mrqa/MRQA-Shared-Task-2019</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>根据多任务模型在数据集上的当前表现与单任务表现的比例来选择训练实例，比较哪种实例抽样方法和历时调度策略能提供最佳性能。</p><blockquote><p>catastrophic forgetting：在一个不平衡的训练集中，当训练从该数据集开始时，特定数据集的性能会急剧下降。</p><p>多任务训练的两个基本方面：</p><ul><li>how many instances are sampled from each task per epoch </li><li>how those instances are organized within the epoch</li></ul></blockquote><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>本文引入了一种动态抽样策略，从数据集中选择实例，其概率与当前某些指标（如EM或F1得分）的性能和同一模型在该数据集中的单任务性能之间的差距成正比。</p><h3 id="Sampling-and-Scheduling-Strategies"><a href="#Sampling-and-Scheduling-Strategies" class="headerlink" title="Sampling and Scheduling Strategies"></a>Sampling and Scheduling Strategies</h3><p>本文探讨了多任务学习中实例排序的两个主要方面：</p><ul><li>从每个数据集中进行实例抽样，以获得用于一个周期的实例集合</li><li>在周期内对这些实例进行调度，确定它们应该如何排序和分批。</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210604155741.png" alt="image-20210604155741020"></p><p>四个抽样方法：</p><blockquote><p>Uniform，By Size，Uniform→Size，Dynamic</p></blockquote><p>Dynamic：首先计算正在训练的模型的单任务验证指标。对于每个任务，计算当前的多任务性能和相应的单任务性能之间的差距，并将这些指标的差异归一化，以创建一个概率分布。然后，对于第一个epoch之后的每一个epoch，从这个分布中按任务取样。如果一个数据集的性能与单任务性能相差甚远，它将被大量抽样，而达到或超过单任务性能的数据集将被少量抽样。</p><p>修改用于计算差值的指标的方法，最终决定使用EM+F1差分，性能比EM或F1差分更好，并且明显比损失差分的性能好。</p><p>Epoch Scheduling：</p><ul><li>Partitioned：该调度策略按任务划分epoch中的实例。</li><li>Homogeneous Batches：这种调度策略并不强迫实例基于数据集的分区。相反，每个数据集的实例都被分到一起，然后对分批的实例进行打乱。</li><li>Heterogeneous Batches：这种调度策略对所有选定的实例打乱，然后将它们分批进行。每个批次可能有来自许多不同数据集的实例。</li><li>Uniform Batches：这种方法在每个批次中为每个数据集放置一个实例，直到最小的数据集的实例用完。这种策略在其余的数据集上继续进行，直到所有数据集都用完。</li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>小型数据集：</p><blockquote><p>Quoref,ROPES</p></blockquote><p>中型数据集：</p><blockquote><p>DuoRC,NarrativeQA</p></blockquote><p>大型数据集：</p><blockquote><p>DROP,NewsQA,SQuAD1.1,SQuAD2.0</p></blockquote><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>动态抽样，根据各自的度量差对每个任务的实例进行抽样，可以提高性能。在每个epoch内将不同任务的实例交错在一起，形成异质的批次，对于优化多任务性能至关重要。最终模型与其他的多任务阅读理解在ORB基准上的模型性能有很大的提高。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> Dynamic Sampling Strategies </tag>
            
            <tag> ORB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Semantic Graphs for Generating Deep Questions</title>
      <link href="/2021/05/28/Semantic%20Graphs%20for%20Generating%20Deep%20Questions/"/>
      <url>/2021/05/28/Semantic%20Graphs%20for%20Generating%20Deep%20Questions/</url>
      
        <content type="html"><![CDATA[<h1 id="Semantic-Graphs-for-Generating-Deep-Questions"><a href="#Semantic-Graphs-for-Generating-Deep-Questions" class="headerlink" title="Semantic Graphs for Generating Deep Questions"></a>Semantic Graphs for Generating Deep Questions</h1><blockquote><p> <a href="https://arxiv.org/abs/2004.12704">论文：https://arxiv.org/abs/2004.12704</a></p><p> <a href="https://github.com/WING-NUS/SG-Deep-Question-Generation">代码：https://github.com/WING-NUS/SG-Deep-Question-Generation</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>本文提出了深度问题生成（DQG）的问题，其目的是生成需要对输入段落的多个信息进行推理的复杂问题。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>为了捕捉文件的全局结构并促进推理，本文提出了一个新的框架，首先为输入的文件构建一个语义层面的图，然后通过引入一个基于注意力的GGNN（Att-GGNN）对语义图进行编码。之后，融合文档层面和图层面的表示，对内容选择和问题解码进行联合训练。</p><p>问题定义：</p><script type="math/tex; mode=display">\overline{Q} = arg\ \underset{Q}max P(Q|D, A)</script><blockquote><p>$\overline{Q}$：生成的问题</p><p>D：文档</p><p>A：答案</p></blockquote><p><strong>模型结构：</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210525200100.png" alt="image-20210525200100849"></p><p>三个模块：</p><ul><li><p>semantic graph construction</p><blockquote><p>为输入构建DP(Dependency Parsing) or SRL-based semantic graph。</p></blockquote></li><li><p>semantic-enriched document representation</p><blockquote><p>使用 Attention-enhanced Gated Graph Neural Network (Att-GGNN)学习语义图表示。</p></blockquote></li><li><p>joint-task question generation</p><blockquote><p>通过节点级内容选择和单词级问题解码的联合训练来生成深度问题。</p></blockquote></li></ul><h3 id="Semantic-Graph-Construction"><a href="#Semantic-Graph-Construction" class="headerlink" title="Semantic Graph Construction"></a>Semantic Graph Construction</h3><p>实体之间的语义关系是决定询问什么以及它所包括的推理类型的有力线索。为了提炼出文档中的这种语义信息，本文使用基于SRL（语义角色标签）和DP-（依赖分析）的方法来构建语义图。</p><h3 id="Semantic-Enriched-Document-Representations"><a href="#Semantic-Enriched-Document-Representations" class="headerlink" title="Semantic-Enriched Document Representations"></a>Semantic-Enriched Document Representations</h3><p>本文分别通过基于RNN的段落编码器和新颖的Att-GGN图编码器对文档D和语义图G进行编码，然后将其融合，得到用于问题生成的语义丰富的文档表示。</p><p>使用 bi-directional Gated Recurrent Unit (GRU)编码上下文。</p><p>采用一种新的AttGGNN，通过聚合来自其邻居的信息来更新节点表征。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>HotpotQA</p><h2 id="性能水平-amp-结论"><a href="#性能水平-amp-结论" class="headerlink" title="性能水平&amp;结论"></a>性能水平&amp;结论</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210529095840.png" alt="image-20210529095642633"></p><p>本文提出的模型P1和P2在BLEU评测上都表现出了最优的效果。</p><p>与采用门控自注意机制并使用与本文相同的解码器的B5模型相比，本文带有基于DP的语义图的模型（P2）在BLEU-4中性能提升显著。这表明了semantic-enriched文档表示的显著效果。</p><p><strong>结论：</strong></p><p>本文提出的框架结合了语义图来增强输入文件的表征，并通过与内容选择任务的联合训练来生成问题。在HotpotQA数据集上的实验表明，引入语义图大大减少了语义错误，而内容选择有利于对不相干的相关内容进行选择和推理，问题的质量提高显著提高。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> DQG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hierarchical Graph Network for Multi-hop Question Answering</title>
      <link href="/2021/05/21/Hierarchical%20Graph%20Network%20for%20Multi-hop%20Question%20Answering/"/>
      <url>/2021/05/21/Hierarchical%20Graph%20Network%20for%20Multi-hop%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="Hierarchical-Graph-Network-for-Multi-hop-Question-Answering"><a href="#Hierarchical-Graph-Network-for-Multi-hop-Question-Answering" class="headerlink" title="Hierarchical Graph Network for Multi-hop Question Answering"></a>Hierarchical Graph Network for Multi-hop Question Answering</h1><blockquote><p> <a href="https://arxiv.org/abs/1911.03631">论文：https://arxiv.org/abs/1911.03631</a></p><p> <a href="https://github.com/yuwfan/HGN">代码：https://github.com/yuwfan/HGN</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        提出了用于多跳问题回答的 Hierarchical Graph Network（HGN）。为了将分散在多个段落的文本中的线索汇总起来，通过构建不同粒度级别的节点（问题、段落、句子和实体）来创建一个层次图。将异质节点被编织成一个完整的图，不同颗粒度的节点被用于不同的子任务（例如，段落选择、支持事实提取和答案预测）。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>​        为了将分散在多个段落的文本中的线索汇总起来，通过构建不同粒度级别的节点（即问题、段落、句子和实体）来创建一个hierarchical graph，这些节点的表示是由基于BERT的上下文编码器初始化的。</p><h3 id="Hierarchical-Graph-Network"><a href="#Hierarchical-Graph-Network" class="headerlink" title="Hierarchical Graph Network"></a>Hierarchical Graph Network</h3><p>四个主要的组件：</p><ul><li><p>Graph Construction Module</p><blockquote><p>构建层次图以连接不同来源的线索。</p></blockquote><p>构建步骤</p><ul><li>识别相关的多跳段</li><li>添加代表所选段落内句子和实体之间联系的边</li></ul></li><li><p>Context Encoding Module</p><blockquote><p>通过基于BERT的编码器获得图形节点的初始表示。</p></blockquote><p>将所选段落和问题串联后输入到BERT预训练模型。</p></li><li><p>Graph Reasoning Module</p><blockquote><p>应用基于图形注意力的消息传递算法来共同更新节点表示。</p></blockquote><p>GAT(Graph Attention Network)，将节点作为输入，GAT通过邻居$N_i$更新节点的特征表示$h_i^{‘}$。</p><script type="math/tex; mode=display">h_i^{'}= σ(\sum_{j \in N_i}a_{ij}Wh_j)</script><p>σ(·)表示激活函数，$α_{ij}$为注意力系数。</p></li></ul><ul><li><p>Multi-task Prediction Module</p><blockquote><p>同时执行多个子任务，包括段落选择、支持事实预测、实体预测和答案跨度提取。</p></blockquote><p>段落选择基于段落节点，支持事实预测基于句子节点，答案预测基于实体节点。</p></li></ul><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210521175510.png" alt="image-20210521175510269"></p><p>支持事实预测过程：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210521222206.png" alt="image-20210521222206209"></p><p>左侧问题：Q → P1 → S4 → P2 → S7</p><p>右侧问题：Q → P1 → S1 → S2 → P2 → S3</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>HotpotQA Distractor and Fullwiki setting </p><h2 id="性能水平-amp-结论"><a href="#性能水平-amp-结论" class="headerlink" title="性能水平 &amp; 结论"></a>性能水平 &amp; 结论</h2><p>性能水平：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210521192345.png" alt="image-20210521192345886"></p><p>HGN方法在Distractor和Fullwiki设置中都取得了领先的性能水平。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> HGN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Reinforced Multi-task Approach for Multi-hop Question Generation</title>
      <link href="/2021/05/14/COLING%202020-Reinforced%20Multi-task%20Approach%20for%20Multi-hop%20Question%20Generation/"/>
      <url>/2021/05/14/COLING%202020-Reinforced%20Multi-task%20Approach%20for%20Multi-hop%20Question%20Generation/</url>
      
        <content type="html"><![CDATA[<h1 id="Reinforced-Multi-task-Approach-for-Multi-hop-Question-Generation"><a href="#Reinforced-Multi-task-Approach-for-Multi-hop-Question-Generation" class="headerlink" title="Reinforced Multi-task Approach for Multi-hop Question Generation"></a>Reinforced Multi-task Approach for Multi-hop Question Generation</h1><blockquote><p> <a href="https://arxiv.org/abs/2004.02143">论文：https://arxiv.org/abs/2004.02143</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>问题生成试图解决问题回答的逆向问题，通过给定一个文件和一个答案来生成一个自然语言问题。本文旨在使用多个支持性事实来生成高质量的问题。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>采用了多跳问题生成，根据上下文中的支持事实生成相关问题。采用了多任务学习的方式，并辅以answer-aware支持性事实预测的任务来指导问题生成器。</p><p>问题生成示例：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210513095858.png" alt="image-20210513095855246"></p><p>处理多跳问题生成的两个阶段：</p><p>在第一阶段，学习支持性事实意aware的编码器表示，通过与问题生成的联合训练来预测文档中的支持性事实，随后增强这些支持性事实的利用。</p><p>后者的目标被表述为一个问题意识到的支持性事实预测奖励，它与监督序列损失一起被优化。此外，我们观察到多任务框架为问题生成的性能提供了实质性的改进，也避免了在生成的问题中包含噪声句子信息，而强化学习（RL）将完整和复杂的问题带到其他最大似然估计（MLE）优化的QG模型中。</p><h3 id="Multi-Hop-Question-Generation-Model"><a href="#Multi-Hop-Question-Generation-Model" class="headerlink" title="Multi-Hop Question Generation Model"></a>Multi-Hop Question Generation Model</h3><p>组件：</p><ul><li><p>Document and Answer Encoder</p><blockquote><p>编码文档集并回答以进一步生成问题。</p><p>使用Bi-LSTM网络。</p></blockquote></li><li><p>Multi-task Learning</p><blockquote><p>方便QG模型自动选择支持事实以产生问题。</p></blockquote></li><li><p>Question Decoder</p><blockquote><p>使用pointer-generator机制生成问题。</p></blockquote></li><li><p>MultiHop-Enhanced QG</p><blockquote><p>最大限度地提高基于奖励的支持事实预测。</p><p>Question-Aware Supporting Fact Prediction 网络用来预测每个候选句子的支持事实概率。</p><p>使用binary cross-entropy损失函数。</p></blockquote></li></ul><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210513104059.png" alt="image-20210513104057610"></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>HotPotQA</li></ul><h2 id="性能水平-amp-结论"><a href="#性能水平-amp-结论" class="headerlink" title="性能水平&amp;结论"></a>性能水平&amp;结论</h2><ul><li>性能比较：</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210514093029.png" alt="image-20210514093025859"></p><p>在HotpotQA测试集上，本文提出的模型在BLEU评测指标上都取得了最优的性能。在支持事实覆盖（SF coverage）的多跳问题推理中也取得了最优的效果。</p><ul><li>消融实验：</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210514145811.png" alt="image-20210514145811434" style="zoom:50%;" /></p><p>使用共享编码器提供多任务学习有助于模型 在BLEU-4评测下提高QG性能。 </p><p>从答案感知支持事实预测任务中获得的支持事实信息进一步提高BLEU-4的QG性能。</p><p>通过在两个任务之间共享文档编码器，网络对输入文档可以更好的进行编码。 能够在处理多个文档时有效地过滤不相关的信息并对问题生成进行多跳推理。</p><ul><li>结论</li></ul><p>通过在多跳问题回答数据集HotPotQA上的实验，证明了本文方法的有效性。经验评估表明，本文的模型在自动评估指标（如BLEU、METEOR和ROUGE）和人工评估指标（如生成问题的质量和覆盖率）方面都优于单跳神经问题生成模型。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> QG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-Hop Paragraph Retrieval for Open-Domain Question Answering</title>
      <link href="/2021/05/07/Multi-Hop%20Paragraph%20Retrieval%20for%20Open-Domain%20Question%20Answering/"/>
      <url>/2021/05/07/Multi-Hop%20Paragraph%20Retrieval%20for%20Open-Domain%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-Hop-Paragraph-Retrieval-for-Open-Domain-Question-Answering"><a href="#Multi-Hop-Paragraph-Retrieval-for-Open-Domain-Question-Answering" class="headerlink" title="Multi-Hop Paragraph Retrieval for Open-Domain Question Answering"></a>Multi-Hop Paragraph Retrieval for Open-Domain Question Answering</h1><blockquote><p> <a href="https://arxiv.org/abs/1906.06606">论文：https://arxiv.org/abs/1906.06606</a></p><p> <a href="https://github.com/yairf11/MUPPET">代码：https://github.com/yairf11/MUPPET</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>多跳开放域问题回答(QA)任务，需要同时进行文本推理和高效搜索。本文提出了一种检索多个支持段落的方法，这些段落嵌套在一个庞大的，包含回答一个给定问题的必要证据的知识库中。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>本文提出的方法通过形成一个问题和段落的联合向量表示来反复检索支持性段落。检索是通过考虑知识源中段落的上下文句子层面的表示来进行的。</p><ul><li><strong>任务定义：</strong></li></ul><p>$(KS, Q, A)$</p><p>Background knowledge source：$KS = {P<em>1, P_2, . . . , P</em>{|KS|}}$</p><p>由$l<em>i$ 个tokens组成的文本段落：$P_i = (p_1, p_2, . . . , p</em>{l_i})$</p><p>m个tokens组成的段落：$Q = (q_1, q_2, . . . , q_m)$</p><p>n个tokens组成的答案：$A = (a_1, a_2, . . . , a_n)$</p><ul><li><strong>目标：</strong></li></ul><p>使用背景知识源KS找到对问题Q的答案A。</p><p>$A = φ(Q, KS)$</p><ul><li><strong>方法：</strong></li></ul><p><strong>MUPPET (multi-hop paragraph retrieval)</strong></p><p>两个组件</p><blockquote><p>paragraph and question encoder</p><ul><li>段落编码不依赖于问题。</li></ul><p>paragraph reader</p></blockquote><p>使用MIPS(maximum inner product search)算法检索最有可能包含答案的段落，然后将的段落传递给阅读器模块，提取问题最有可能的答案。</p><p>支持多跳检索：</p><p>对于问题$Q$，编码为$q$，转换成搜索空间向量$q^s$，用来检索（使用MIPS算法）top-k相关段落${P^Q<em> 1, P^Q _2, . . . , P^Q</em> k} ⊂ KS$，从检索段落中重构搜索向量，${\tilde q^s<em> 1, \tilde q^s</em> 2, . . . , \tilde q^s_ k}$，再执行一遍检索过程，可检索出下一个top-k相关段落。</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210506144838.png" alt="image-20210506144811702"></p><h3 id="Paragraph-and-Question-Encoder"><a href="#Paragraph-and-Question-Encoder" class="headerlink" title="Paragraph and Question Encoder"></a>Paragraph and Question Encoder</h3><p>段落P由k个段落组成</p><p>$P=(s_1, s_2, . . . , s_k)$</p><p>每个段落由$l$个tokens组成</p><p>$s<em>i=(t</em>{i<em>1}, t</em>{i<em>2}, . . . , t</em>{i_l})$</p><blockquote><p>$l$：句子长度</p></blockquote><p>编码：</p><script type="math/tex; mode=display">(s_1, s_2, . . . , s_k)= f(P)</script><script type="math/tex; mode=display">q = f(Q)</script><h3 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h3><p>$t^w$：word-level embedding 通过预训练的Word Embedding获得。</p><p>$t^c$：character-level embedding</p><p>token t 有$l<em>t$个字符$(t</em>{1}^c, t<em>{2}^c, . . . , t</em>{l_t}^c)$</p><script type="math/tex; mode=display">t^c= max(CNN(t_{1}^c, t_{2}^c, . . . , t_{l_t}^c))</script><p>连接两种嵌入形式：</p><script type="math/tex; mode=display">t = [t^w; t^c]</script><h3 id="Recurrent-Layer"><a href="#Recurrent-Layer" class="headerlink" title="Recurrent Layer"></a>Recurrent Layer</h3><p>获得word representations之后，通过BiGRU获得 contextualized word representations。</p><script type="math/tex; mode=display">(c_1, c_2, . . . , c_m) = BiGRU(t_1, t_2, . . . , t_m)</script><h3 id="Sentence-wise-max-pooling"><a href="#Sentence-wise-max-pooling" class="headerlink" title="Sentence-wise max-pooling"></a>Sentence-wise max-pooling</h3><p>使用max-pooling获得sentence representations。</p><script type="math/tex; mode=display">s_i=max(c_{i_1}, c_{i_2}, . . . , c_{i_l})</script><h3 id="Reformulation-Component"><a href="#Reformulation-Component" class="headerlink" title="Reformulation Component"></a>Reformulation Component</h3><p>使用recurrent layers初始化问题Q和段落P的编码。</p><p>$(c^q<em> 1, c^q</em> 2, . . . , c^q_{ n_q})$</p><p>$(c^p<em> 1, c^p</em> 2, . . . , c^p_{ n_p})$</p><p>传递给bidirectional attention layer。使用ReLU作为激活函数。最终得到reformulated question representation, $\tilde q$</p><p>Reformulation Component图示：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210506145718.png" alt="image-20210506145716584" style="zoom:50%;" /></p><p>Sentence Encoder 图示：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210506145108.png" alt="image-20210506145106251" style="zoom:50%;" /></p><h3 id="Paragraph-Reader"><a href="#Paragraph-Reader" class="headerlink" title="Paragraph Reader"></a>Paragraph Reader</h3><p>段落阅读器接输入为问题Q和段落P，并从P中提取最可能的答案跨度。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>HotpotQA</li><li>SQuAD-Open</li></ul><h2 id="性能水平和结论"><a href="#性能水平和结论" class="headerlink" title="性能水平和结论"></a>性能水平和结论</h2><ul><li>HotpotQA数据集：</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210507110944.png" alt="image-20210507110940732"></p><p>在HotpotQA distractor setting下，Joint EM和F1评分提升最为显著，分别提升了17.12和13.22。</p><p>在HotpotQA full wiki setting下，MUPPET在段落级别编码时，性能要优于句子级编码。</p><ul><li>SQuAD-Open数据集：</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210507111826.png" alt="image-20210507111825276" style="zoom:50%;" /></p><p>在SQuAD-Open数据集上，句子级别编码的MUPPET取得了最优的性能，表明本文提出的编码器不仅适用于多跳问题，还可以用于单跳问题。</p><p>结论：</p><p>本文提出的MUPPET，用于多跳段落检索在单跳和多跳QA数据集上都取得了不错的效果。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> MUPPET </tag>
            
            <tag> BiGRU </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning to Prune Dependency Trees with Rethinking for Neural Relation Extraction</title>
      <link href="/2021/05/01/Learning%20to%20Prune%20Dependency%20Trees%20with%20Rethinking%20for%20Neural%20Relation%20Extraction/"/>
      <url>/2021/05/01/Learning%20to%20Prune%20Dependency%20Trees%20with%20Rethinking%20for%20Neural%20Relation%20Extraction/</url>
      
        <content type="html"><![CDATA[<h1 id="Learning-to-Prune-Dependency-Trees-with-Rethinking-for-Neural-Relation-Extraction"><a href="#Learning-to-Prune-Dependency-Trees-with-Rethinking-for-Neural-Relation-Extraction" class="headerlink" title="Learning to Prune Dependency Trees with Rethinking for Neural Relation Extraction"></a>Learning to Prune Dependency Trees with Rethinking for Neural Relation Extraction</h1><blockquote><p> <a href="https://www.aclweb.org/anthology/2020.coling-main.341/">论文：https://www.aclweb.org/anthology/2020.coling-main.341/</a></p><p> <a href="2https://github.com/Cartus/AGGCN">代码：https://github.com/Cartus/AGGCN</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        预测给定句子中的两个实体之间的关系。</p><p>​        利用输入句子的依赖树模型在捕获目标实体之间的长距离关系方面是有效的。但并不是所有依赖树中的标记都需要表达目标实体对的关系，一些与目标不相关的标记可能会引入噪音。如何有选择地强调目标相关的信息，并从依赖树上删除不相关的内容，仍然是一个开放的问题。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><blockquote><p>RE：Relation extraction  旨在检测出现在句子中出现的两个特定实体之间的语义关系（通常分别被称为主题和对象）。</p></blockquote><p>​        由于自然语言的可变性和模糊性，之前手工制定的修剪规则可能导致有用的信息被遗漏。本文提出了一个动态修剪图卷积网络（DP-GCN）的新架构，它在端到端的方案中学习修剪依赖树，并进行重新思考。在DP-GCN的每一层，采用了一个选择模块，动态地识别依赖树中的关键节点子集，这些节点提供足够的信息来提取两个实体之间的关系，考虑到每个节点和目标实体的语义，生成一组依赖输入的二进制门来决定是否应该保留该节点。为了解决依赖树的稀疏阻碍节点之间的信息传播，使用自注意力机制产生的修剪过的语义图来加强修剪过的树，以确保连通性。之后，利用GCN模块来更新实体特定的上下文表征。引入了一个反思机制，通过反复反馈高级别的学习特征来指导和完善剪枝操作。</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210428111023.png" alt="image-20210428105439620"></p><h3 id="BiLSTM-encoder：将输入单词转换为上下文化表示。"><a href="#BiLSTM-encoder：将输入单词转换为上下文化表示。" class="headerlink" title="BiLSTM encoder：将输入单词转换为上下文化表示。"></a>BiLSTM encoder：将输入单词转换为上下文化表示。</h3><p>DP-GCN：将实体信息结合到图形建模过程中，并为给定实体过滤无用的信息。</p><p>pooling module：聚合DP-GCN层包含的的节点表示。</p><p>Contextual Encoder：</p><script type="math/tex; mode=display">hi= [\overrightarrow{LSTM}(x_i);\leftarrow{LSTM}(x_i)], i ∈ [1, n]</script><p>$X = [x_1, …, x_n]$：表示句子中的n个单词。</p><p>$H = [h_1, · · · , h_n]$：LSTM隐藏层向量。</p><h3 id="Dynamically-Pruned-GCN"><a href="#Dynamically-Pruned-GCN" class="headerlink" title="Dynamically Pruned GCN"></a>Dynamically Pruned GCN</h3><p>依赖树中的节点表示句子中的单词，边表示单词之间语法依赖路径。</p><p>采用自注意力机制保证图的连通性。</p><p>GCN：</p><script type="math/tex; mode=display">h^l_i= g(\sum ^n _{j=1}A_{ij}W^lh^{l-1}_j+ b^l)</script><p>$A$：依赖树图中n个节点的邻接矩阵。</p><p>$W^l$：线性transformation。</p><p>$g$ ：非线性激活函数（RELU）。</p><p><strong>选择模块：</strong></p><p>​        矩阵<strong>A</strong>包含了许多与目标实体对无关的节点。因此，在每一层，设计了一个选择模块来理解实体的具体环境，并从图中动态地选择出关键的目标相关节点。</p><p>​    引入一组二进制门${z^l _1, · · · , z_l ^n}$，关联到每个节点。$z_l ^n$：取值为0/1，表示第$l$层底$i$个门。</p><script type="math/tex; mode=display">\hat{A}^l_{ij}=\frac{z^l_j \cdot A_{ij}}{\epsilon +\sum^n_{m=1}z^l_m\cdot A_{im}}</script><p>$\hat{A}^l$：表示第l层修剪之后的依赖矩阵。</p><h3 id="Pooling（max-pooling）"><a href="#Pooling（max-pooling）" class="headerlink" title="Pooling（max-pooling）"></a>Pooling（max-pooling）</h3><p>使用了一个线性组合来整合来自不同层的表征，允许捕获丰富的本地和非本地信息。</p><script type="math/tex; mode=display">h^{comb}_ i = W^{comb}[h^1_ i; · · · ; h^L_ i] + b^{comb}</script><script type="math/tex; mode=display">h_{sent}= F(h^{comb}_{1:n})</script><script type="math/tex; mode=display">r = [h_{sent}; h_{subj}; h_{obj}]</script><p>$h^{comb}_ i $：token i的组合向量。</p><p>$W_{comb}$：权值矩阵。</p><p>F：max-pooling</p><h3 id="Rethinking-Mechanism"><a href="#Rethinking-Mechanism" class="headerlink" title="Rethinking Mechanism"></a>Rethinking Mechanism</h3><p>在池化过程后引入Rethinking Mechanism机制，将池化模块的输出作为高级特征，并通过在每个DP-GCN层引入反馈连接，利用这些特征来调整选择模块的门值。网络被赋予了自适应完善修剪操作的能力，以便更好地理解特定目标的语义。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>TACRED</li><li>SemEval</li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210501094735.png" alt="image-20210501094449787"></p><p>在TACRED测试数据集上，性能超过了基线模型，相比大多数模型性能都有所提升，并取得了最高的F1得分。</p><p>准确度和召回率的提高也表明了动态修剪的有效性。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210501095848.png" alt="image-20210501095848865" style="zoom:50%;" /></p><p>在SemEval数据集上，DP-GCN同样取得了最优的性能。证明了利用输入句子的依赖树模型在捕获目标实体之间的长距离关系方面是有效的。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><h3 id="消融实验："><a href="#消融实验：" class="headerlink" title="消融实验："></a>消融实验：</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210501101611.png" alt="image-20210501101139982" style="zoom:50%;" /></p><p>实验表明选择模块、思考机制、依赖树结构、二进制门控函数对模型性能都有影响。</p><p>结论：</p><p>​        本文提出的DP-GCN模型，通过在每个GCN层中加入选择模型，过滤掉与目标不相关的信息，不依赖任何预先定义的规则。并且加入一个反思机制，动态实现剪枝操作。在两个公共数据集上的实验表明，提出的模型达到了最先进的性能。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> DP-GCN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-hop Reading Comprehension through Question Decomposition and Rescoring</title>
      <link href="/2021/04/24/ACL2019-Multi-hop%20Reading%20Comprehension%20through%20Question%20Decomposition%20and%20Rescoring.pdf/"/>
      <url>/2021/04/24/ACL2019-Multi-hop%20Reading%20Comprehension%20through%20Question%20Decomposition%20and%20Rescoring.pdf/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-hop-Reading-Comprehension-through-Question-Decomposition-and-Rescoring"><a href="#Multi-hop-Reading-Comprehension-through-Question-Decomposition-and-Rescoring" class="headerlink" title="Multi-hop Reading Comprehension through Question Decomposition and Rescoring"></a>Multi-hop Reading Comprehension through Question Decomposition and Rescoring</h1><blockquote><p> <a href="https://arxiv.org/abs/1906.02916">论文：https://arxiv.org/abs/1906.02916</a></p><p> <a href="https://github.com/shmsw25/DecompRC">代码：https://github.com/shmsw25/DecompRC</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>多跳阅读理解（RC）需要在几个段落中进行推理和汇总。本文提出了将一个组合式问题分解为更简单的子问题的多跳阅读理解系统，似的这些分解的子问题可以由现成的单跳阅读模型来回答。由于这种分解的注释代价很高，本文将子问题的生成重塑为一个跨度预测问题，来生成类似于人类提出的问题。</p><p>多跳问题分解为单跳子问题示例：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210423100215.png" alt="image-20210423100215572" style="zoom:50%;" /></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>本文提出了一种重新评分的方法，从不同的可能的分解中获得答案，并对每个分解的答案重新评分，以决定最终的答案，而不是一开始就决定分解的答案。</p><p><strong>DECOMPRC模型实现方法：</strong></p><ol><li>首先，DECOMPRC根据跨度预测，将原始的多跳问题按照几个推理类型平行地分解成几个单跳的子问题。</li><li>然后，对于每个推理类型，DECOMPRC利用单跳阅读理解模型来回答每个子问题，并根据推理类型来组合答案。</li><li>最后，DECOMPRC利用了分解得分数来判断哪个分解是最合适的，并将该分解的答案输出为最终答案。</li></ol><p>示例：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210423103807.png" alt="image-20210423103807723"></p><p><strong>推理类型</strong>：bridging, intersection and comparison</p><p>HotpotQA数据集中推理类型分布。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210423104159.png" alt="image-20210423104159546"></p><h3 id="Span-Prediction-for-Sub-question-Generation"><a href="#Span-Prediction-for-Sub-question-Generation" class="headerlink" title="Span Prediction for Sub-question Generation"></a>Span Prediction for Sub-question Generation</h3><p>训练$Pointer_c$模型，将一个问题映射成$c$个点，通过映射生成的点来收集注释，随后将这些点用于为每个推理类型组成子问题。</p><p>$S = [s_1, . . . , s_n]$：表示句子中的n个单词。</p><p>使用BERT编码输入序列S:</p><script type="math/tex; mode=display">U = BERT(S) ∈ R^{n×h}</script><blockquote><p>n是输入句子单词个数</p><p>h是编码器的输出尺寸</p></blockquote><p>计算每个映射点的概率：</p><script type="math/tex; mode=display">ind_1, . . . , ind_c=   \underset{i_1<<...<<i_c} {argmax}\Pi^c_{j=1}P(i_j==ind_j)</script><p>使用single-hop RC model回答划分的子问题，预测4种类型问题的概率，进行下一步问题回答。</p><script type="math/tex; mode=display">[y^{span}_ i ; y^{yes} _i ; y^{no} _i; y^{none} _i ] = max(U_i)W_1∈ R_4</script><p>选定4种类型中概率较大的一个作为预测概率，对不同的问题类型，进行下一步处理。</p><p>如果是跨度问题还需要预测跨度的区间。</p><script type="math/tex; mode=display">p^{start}_ i = softmax(U_iW_{start}) ∈ R_n</script><script type="math/tex; mode=display">p^{end}_ i = softmax(U_iW_{end}) ∈ R_n</script><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>HotpotQA数据集 </p><blockquote><p>Distractor setting和Full wiki setting</p></blockquote><h2 id="性能水平-amp-结论"><a href="#性能水平-amp-结论" class="headerlink" title="性能水平&amp;结论"></a>性能水平&amp;结论</h2><p>实验结果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210423184100.png" alt="image-20210423184100910"></p><p>HOTPOTQA development set：</p><ul><li>DECOMPRC在distractor and full wiki settings 中都优于所有的基线。</li><li><p>没有经过多跳QA对训练的DECOMPRC（DECOMPRC-1hop train）在所有数据分割中都表现出不错的性能。</p></li><li><p>在单跳RC上训练的BERT获得了很高的F1分数（87.21）</p></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210423184955.png" alt="image-20210423184955624" style="zoom:50%;" /></p><p>HOTPOTQA test set</p><blockquote><p> distractor setting and full wiki setting </p></blockquote><p>DECOMPRC在distractor setting 和 full wiki setting 相对于其他模型取得了最高的F1分数。</p><p>该方法也有一定的局限性</p><ul><li>有些问题不是组合式的，但是需要隐含的多跳推理，因此不能被分解。</li><li>有些问题可以被分解，但每个子问题的答案在文本中并不明确存在，而是必须通过常识推理来推断。</li><li>所需的推理有时超出了模型设定的四种推理类型，例如算数类问题无法推理。</li></ul><p>本文引入一种新的全局重评分方法，考虑每个分解（即子问题和它们的答案）来选择最佳的最终答案，极大地提高了整体性能。在HOTPOTQA上的实验表明，这种方法取得了最先进的结果，同时以子问题的形式为其决策提供了可解释的证据。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> DECOMPRC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dynamically Fused Graph Network for Multi-hop Reasoning</title>
      <link href="/2021/04/16/Dynamically%20Fused%20Graph%20Network%20for%20Multi-hop%20Reasoning/"/>
      <url>/2021/04/16/Dynamically%20Fused%20Graph%20Network%20for%20Multi-hop%20Reasoning/</url>
      
        <content type="html"><![CDATA[<h1 id="Dynamically-Fused-Graph-Network-for-Multi-hop-Reasoning"><a href="#Dynamically-Fused-Graph-Network-for-Multi-hop-Reasoning" class="headerlink" title="Dynamically Fused Graph Network for Multi-hop Reasoning"></a>Dynamically Fused Graph Network for Multi-hop Reasoning</h1><blockquote><p> <a href="https://arxiv.org/abs/1905.06933">论文：https://arxiv.org/abs/1905.06933</a></p><p> <a href="https://github.com/woshiyyya/DFGN-pytorch">代码：https://github.com/woshiyyya/DFGN-pytorch</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>处理基于文本的问题回答（TBQA）,现有的大多数方法都侧重于在一个段落中寻找问题的答案。但是许多复杂的问题需要从两个或更多的文档中分散的文本中寻找多个支持证据。本文提出了动态融合图网络（<strong>DFGN</strong>），来回答需要从多个分散的证据推理的问题。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>DFGN包含一个动态融合层，它从给定查询中提到的实体开始，沿着从文本中动态构建的实体图进行探索，并逐渐从给定文档中找到相关的支持实体。</p><p>工作方式：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210413205008.png" alt="image-20210413205001014" style="zoom:50%;" /></p><p>两个挑战：</p><ul><li><p>并非每个文档都包含相关信息，因此基于多跳文本的质量检查要求从多个段落中过滤掉噪音并提取有用的信息。</p></li><li><p>以前的多跳Qa工作通常会将文档信息汇聚到实体图形，然后在实体图的实体上直接选择答案。 但是，在更真实的情况下，答案甚至可能不会驻留在提取的实体图的实体中 。</p></li></ul><p>解决：</p><ul><li>对于第一个挑战，DFGN根据查询和文档中提及的实体，构建一个动态实体图。这个过程经过多轮迭代，实现多跳推理。在每一轮中，DFGN都会在动态图上生成和推理，通过掩码预测模块(mask prediction module)，将不相关的实体屏蔽掉，只保留推理源。</li><li>提出fusion process，不仅将文档中的信息聚合到实体图（doc2graph），还将实体图的信息传播回文档表示（graph2doc）。融合过程在每一跳都会通过文档标记和实体进行迭代，然后从文档标记中得到最终的结果答案。doc2graph和graph2doc的融合过程与动态实体图共同提高了文档信息与实体图之间的交互性，使得实体图的噪声更小，从而使答案更加准确。</li></ul><h3 id="Dynamically-Fused-Graph-Network-DFGN"><a href="#Dynamically-Fused-Graph-Network-DFGN" class="headerlink" title="Dynamically Fused Graph Network(DFGN)"></a>Dynamically Fused Graph Network(<strong>DFGN</strong>)</h3><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210414091728.png" alt="image-20210414091718194" style="zoom:50%;" /></p><p>5个组件：paragraph selection sub-network, entity graph construction, encoding layer, a fusion block for multi-hop reasoning, final prediction layer</p><ul><li><p>paragraph selection sub-network</p><p>通过sub-network选择相似度较高的段落。</p></li><li><p>Constructing Entity Graph：</p><p>使用Stanford corenlp toolkit进行命名实体识别。</p><p>边添加规则：</p><ol><li>实体在上下文C中出现在同一句子中（句子级链接）</li><li>每对实体在C中具有相同提及文本的实体（上下文级别的链接）</li><li>在中间实体节点和同一段落内的其他实体之间（段落级链接）</li></ol><p>中间实体从标题中提取。</p></li><li><p>Encoding Query and Context</p><p>实验BERT预训练模型编码。</p><script type="math/tex; mode=display">Q = [q_1, . . . , q_L] ∈ R^{L×d_{1}}</script><script type="math/tex; mode=display">C= [c_1, . . . , c_M] ∈R^{M×d_1}</script></li></ul><p>  Q,C代表问题和上下文。L,M分别表示问题和上下文的长度，$d_1$是BERT隐藏层的尺寸。</p><ul><li><p>Reasoning with the Fusion Block</p><p>模仿人类的one-step推理行为。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210414094506.png" alt="image-20210414094506444" style="zoom:50%;" /></p><ol><li>将文档中的信息聚合到实体图（doc2graph</li><li>将实体图的信息传播回文档表示（graph2doc）</li><li>然后从文档标记中得到最终的结果答案</li></ol></li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>HotpotQA ：distractor setting</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210414104935.png" alt="image-20210414104935396"></p><p>答案性能和联合表现达到了当前最优性能，DFGN可以产生可解释的推理链。</p><p>消融研究：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210414105356.png" alt="image-20210414105356961" style="zoom:50%;" /></p><p>每个模型组件都可以提供1％至2％的性能提升。</p><p>并且模型对于黄金段落和支持事实并不敏感。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>提出的动态融合的图形网络（DFGN）以解决多跳推理。在HotpotQA上对DFGN评估取得了领先的结果。DFGN可以产生可靠和可解释的推理链。从文本中构建实体图，可解决更多困难的推理问题。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> TBQA </tag>
            
            <tag> DFGN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Answering Complex Open-domain Questions Through Iterative Query Generation</title>
      <link href="/2021/04/10/Answering%20Complex%20Open-domain%20Questions%20Through%20Iterative%20Query%20Generation/"/>
      <url>/2021/04/10/Answering%20Complex%20Open-domain%20Questions%20Through%20Iterative%20Query%20Generation/</url>
      
        <content type="html"><![CDATA[<h1 id="Answering-Complex-Open-domain-Questions-Through-Iterative-Query-Generation"><a href="#Answering-Complex-Open-domain-Questions-Through-Iterative-Query-Generation" class="headerlink" title="Answering Complex Open-domain Questions Through Iterative Query Generation"></a>Answering Complex Open-domain Questions Through Iterative Query Generation</h1><blockquote><p> <a href="">论文：Answering Complex Open-domain Questions Through Iterative Query Generation</a></p><p> <a href="https://github.com/qipeng/golden-retriever">代码：https://github.com/qipeng/golden-retriever</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>对于目前的单跳检索和阅读问题回答系统来说，问题很少包含关于缺失实体的可检索线索。回答这样的问题需要进行多跳推理，必须收集关于缺失实体（或事实）的信息才能进行进一步的推理。本文提出了<strong>GOLDEN（Gold Entity）Retriever</strong>，它在阅读上下文和检索更多支持文档之间进行迭代，以回答开放领域的多跳问题。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>GOLDEN Retriever不使用不透明和计算代价较高的神经检索模型，而是根据问题和可用的上下文生成自然语言搜索查询，在每一步中，该模型也会使用前几跳推理的IR结果生成新的自然语言查询，并利用现成的信息检索系统来查询缺失的实体或证据来回答原问题，而不是纯粹依靠原问题来检索段落。这使得GOLDEN Retriever能够在保持可解释性的同时，有效地扩展开放领域的多跳推理。</p><ul><li>GOLDEN Retriever</li></ul><p>在推理的第一跳中，GOLDEN Retriever基于给定的原始问题q，从中生成一个检索支持文档$d<em>1$，然后对后续的每一个推理步骤$(\ k = 2，……，S\ ）$，GOLDEN Retriever从问题和可用上下文$\ (q，d_1，……，d</em>{k-1}\ )$中生成一个查询$q_k$，使得模型根据支持事实中揭示的信息生成查询。</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210406142938.png" alt="image-20210406142937978"></p><ul><li>Query Generation</li></ul><p>使用DrQA’s Document Reader model。</p><p>从$C_k$中选择一个跨度作为查询: $q_k= G_k(q, C_k)$</p><blockquote><p>$C_k$:retrieval context</p><p>gold supporting documents: $d<em>1,….,d</em>{k-1}$</p><p>generate a search query: $q_k$</p><p>$G_k$ : the query generator</p></blockquote><ul><li>Deriving Supervision Signal for Query Generation</li></ul><p>采用几种启发式方法来生成候选查询：计算当前检索上下文与目的段落的标题/文本之间最长的共同字符串/序列，忽略停顿词，然后取检索上下文中与此重叠对应的连续文本跨度。这样不仅可以利用实体名称，还可以利用文字描述，更好地引出黄金实体。</p><ul><li>Question Answering Component</li></ul><p>之前的模型将所有上下文段落连缀成一个长字符串，以预测答案的跨度开始和结束偏移，这对这些段落呈现给模型的顺序有潜在的敏感性。本文用共享编码器RNN参数分别处理，以获得每个段落的段落顺序不敏感的表示。跨度偏移分数从每个段落中独立预测，最后用全局 softmax 操作进行聚合和归一化，以产生跨度的概率。</p><p>将原模型中的所有注意力机制都替换成了并联问题和上下文的自注意力层。为了区分上下文段落表征和问题表征在这个自注意机制中的区别，在输入层用一个0/1的特征来表示问题和上下文标记。</p><p>QA模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210409220949.png" alt="image-20210409220949967" style="zoom:50%;" /></p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>HOTPOTQA: fullwiki setting</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210410095902.png" alt="image-20210410095902227"></p><p>与CogQA相比，GOLDEN Retriever 在维基百科中找到正确支持事实的效果更好，证明尽管没有使用BERT等预训练语言模型，但它的表现优于之前发表的最佳模型。</p><p>GOLDEN Retriever几乎将召回率翻倍，通过单跳基线模型，为QA组件提供了一个更好的上下文文档来预测答案。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文提出了GOLDEN Retriever，这是一个可扩展的多跳推理的开放域多跳问题回答系统。通过迭代推理和检索，GOLDEN Retriever极大地提高了黄金支持事实的召回率，从而为问题回答模型提供了一个更好的上下文文档集来产生答案，并展示了具有竞争力的性能，达到了最先进的水平。为每一步推理生成自然语言查询，与之前的神经检索方法相比，GOLDEN Retriever对人类的解释能力也更强，并能更好地理解和验证模型行为。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> GOLDEN Retriever </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-hop Question Generation with Graph Convolutional Network</title>
      <link href="/2021/04/01/Multi-hop%20Question%20Generation%20with%20Graph%20Convolutional%20Network/"/>
      <url>/2021/04/01/Multi-hop%20Question%20Generation%20with%20Graph%20Convolutional%20Network/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-hop-Question-Generation-with-Graph-Convolutional-Network"><a href="#Multi-hop-Question-Generation-with-Graph-Convolutional-Network" class="headerlink" title="Multi-hop Question Generation with Graph Convolutional Network"></a>Multi-hop Question Generation with Graph Convolutional Network</h1><blockquote><p> <a href="https://arxiv.org/abs/2010.09240">论文:https://arxiv.org/abs/2010.09240</a></p><p> <a href="https://github.com/HLTCHKUST/MulQG">代码:https://github.com/HLTCHKUST/MulQG</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>多跳问题生成(Multi-hop Question Generation,<strong>QG</strong>)的目的是通过对不同段落中多个分散的证据进行汇总和推理，生成与答案相关的问题。解决两个问题：1.如何有效地识别分散的证据，可以连接答案和问题的推理路径。2.如何推理多个分散的证据来产生事实连贯的问题。</p><p>识别分散的证据，可以连接答案和问题的推理路径：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210401093135.png" alt="image-20210401093128346" style="zoom:50%;" /></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>为了解决多跳QG<strong>(MulQG)</strong>中的额外挑战，本文提出了问题生成的多跳编码融合网络(Multi-Hop Encoding Fusion Network)，它通过Graph Convolutional Network在多跳中进行上下文编码，并通过编码器推理门(Encoder Reasoning Gate)进行编码融合。</p><p>MulQG将Seq2Seq QG框架从单跳扩展到多跳进行上下文编码。利用图卷积网络（GCN）对答案感知的动态实体图（由答案和输入段落中的实体构建），以聚合与问题相关的潜在证据。在多跳生成过程中，使用不同的注意力机制来模仿人类的推理过程。</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210401101356.png" alt="image-20210401101356256"></p><h3 id="Multi-hop-Encoder"><a href="#Multi-hop-Encoder" class="headerlink" title="Multi-hop Encoder"></a>Multi-hop Encoder</h3><p>包含3个模块：</p><p>(1) Answer-aware context encoder</p><p>(2) GCN-based entity-aware answer encoder </p><p>(3) Gated encoder reasoning layer.</p><p>上下文和答案分割为word-level token，表示为：</p><p>$c ={c_1, c_2, …, c_n}$ </p><p>$a = {a_1, a_2, …, a_m}$</p><p>单次使用预训练的GloVe embedding表示，对于上下文中的单词，加入答案标记嵌入。上下文和答案嵌入分别输入两个双向LSTM-RNN，获得其初始上下文表示。</p><p>$C_0∈ R^{d×n}$ </p><p>$A_0 ∈ R^{d×m}$</p><p>d是LSTM隐藏层维度。</p><ul><li>GCN-based Entity-aware Answer Encoder</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210401104651.png" alt="image-20210401104651769" style="zoom: 33%;" /></p><p>为了获得多跳答案表示，首先从答案感知上下文编码$C_1$计算实体编码，然后我们将GCN应用于在答案感知的子图上传播多跳信息。 最后，通过双向注意力机制获得编码$A_1$的更新答案。</p><p>Entity Graph Construction：</p><p>使用BERT-based命名实体识别构建节点。</p><p>处于同一句子或出现在相同段落的节点添加边。</p><ul><li>Encoder Reasoning Gate</li></ul><p>在之前上下文context encoder hops的答案感知上下文表示$C_1$和$C_2$上应用门控特征融合模块，保留和遗忘信息，形成最终的上下文表示。</p><ul><li>Maxout Pointer Decoder</li></ul><p>decoder:Uni-directional LSTM model（单向）</p><p>为了减少迭代的重复。</p><ul><li>Breadth-First Search Loss</li></ul><p>cross-entropy loss:Breadth-First Search (BFS) Loss</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>HotpotQA</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210401131731.png" alt="image-20210401131731134"></p><p>本文提出的MulQG模型效果远好于基线模型，表明多跳过程可以显着提高编码表示的质量，从而提高了多跳问题生成性能。</p><p>BFS loss也可以通过鼓励学习答案感知的动态实体图更好地提高系统性能。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210401133530.png" alt="image-20210401133530810"></p><p>基于GCN的实体感知答案编码器模块和门控上下文推理模块都对模型很重要（GCN-based entity-aware answer encoder module and Gated Context Reasoning module）。</p><p> 模型效果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210401133518.png" alt="image-20210401133518720"></p><p>从评估来看，本文提出的模型能够生成高完整性的流畅问题，并且在多跳评估中比最强的基线高出20.8%，人工评价结果进一步验证了我们提出的模型更容易生成多跳问题，并且在流畅性、可回答性和完整性得分方面具有较高的质量。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> QG </tag>
            
            <tag> GCN </tag>
            
            <tag> MulQG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Avoiding Reasoning Shortcuts Adversarial Evaluation, Training, and Model Development for Multi-HopQA</title>
      <link href="/2021/03/26/ACL2019-Avoiding%20Reasoning%20Shortcuts%20Adversarial%20Evaluation,%20Training,%20and%20Model%20Development%20for%20Multi-HopQA/"/>
      <url>/2021/03/26/ACL2019-Avoiding%20Reasoning%20Shortcuts%20Adversarial%20Evaluation,%20Training,%20and%20Model%20Development%20for%20Multi-HopQA/</url>
      
        <content type="html"><![CDATA[<h1 id="Avoiding-Reasoning-Shortcuts-Adversarial-Evaluation-Training-and-Model-Development-for-Multi-HopQA"><a href="#Avoiding-Reasoning-Shortcuts-Adversarial-Evaluation-Training-and-Model-Development-for-Multi-HopQA" class="headerlink" title="Avoiding Reasoning Shortcuts Adversarial Evaluation, Training, and Model Development for Multi-HopQA"></a>Avoiding Reasoning Shortcuts Adversarial Evaluation, Training, and Model Development for Multi-HopQA</h1><blockquote><p> <a href="https://arxiv.org/abs/1906.07132">论文：https://arxiv.org/abs/1906.07132</a></p><p> <a href="https://github.com/jiangycTarheel/Adversarial-MultiHopQA">代码：https://github.com/jiangycTarheel/Adversarial-MultiHopQA</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        多跳答题需要模型将分散在长上下文中的多个证据连接起来来回答问题。本文在HotpotQA数据集上，通过构建对抗性文档（由于在生成问题时，人工并没有提供干扰文档，因此无法保证支持文档必须在整个上下文推断答案）来证明，通过数据集中部分例子包含的捷径，模型可以直接将问题与上下文中的句子进行词义匹配来定位答案。生成的这些对抗性文档会对捷径产生矛盾的答案，但不会影响原始答案的有效性。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>为探究神经网络模型是否利用推理快捷方式而不是探索所需的推理路径，使用HotpotQA中原始数据以消除这些快捷方式(shortcuts)。</p><p>context-question-answer tuple ：(C, q, a)</p><p>去除快捷方式后：(C‘, q, a)</p><p>由于新生成的文档形成了另一个将问题与假答案联系起来的有效推理链，因此需要替换连接两条证据的bridge实体与另一个实体，以便所生成的答案不再是问题的有效答案。</p><p><strong>ADDDOC</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210325130113.png" alt="image-20210325130113477"></p><h3 id="Encoding"><a href="#Encoding" class="headerlink" title="Encoding"></a>Encoding</h3><p>embedding：<strong>x: context q: question</strong></p><p>contextualized word representations:<strong>h = BiLSTM(x); u = BiLSTM(q)</strong>（使用bi-directional LSTM-RNN）</p><h3 id="Single-Hop-Baseline"><a href="#Single-Hop-Baseline" class="headerlink" title="Single-Hop Baseline"></a>Single-Hop Baseline</h3><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210325131930.png" alt="image-20210325131930096"></p><p>使用bi-attention + self-attention model做contextualized encoding。</p><script type="math/tex; mode=display">Ms,j= W_1u_s+ W_2h_j+ W_3(u_s\O h_j)</script><script type="math/tex; mode=display">p_{s,j}= \frac{exp(M_{s,j})} {\sum ^S_{s=1}exp(M_{s,j})}</script><script type="math/tex; mode=display">c_{q_j}=\sum^S_{s=1}p_{s,j}u_s</script><p>得到 question-aware context下文表示后传递给BiLSTM。</p><script type="math/tex; mode=display">h^{'}_j= [h_j; c_{q_j}; h_j \O c_{q_j}; c_{q_j}\O qc]</script><script type="math/tex; mode=display">h^1= BiLSTM(h^{'})</script><h3 id="Compositional-Attention-over-Question"><a href="#Compositional-Attention-over-Question" class="headerlink" title="Compositional Attention over Question"></a>Compositional Attention over Question</h3><p>将控制单元与最新的多跳VQA模型和基于文本的QA上采用的bi-attention mechanism相结合，以对上下文和问题进行综合推理。</p><p>由于不知道问题的哪一部分对当前的推理步骤是重要的，从而使控制单元无法学习复合推理技能。为解决此问题，查找连接两个支持文档的桥接实体。监督主要模型来预测桥实体跨度，在第一个 biattention layer之后，间接鼓励控制单元在第一跳寻找与此实体相关的问题信息。对于答案同时出现在两个支持文档中的例子，intermediate supervision给出的是第一个支持文档中出现的答案，而第二个支持文档中的答案作为答案预测监督。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p><strong>HotpotQA  distractor setting</strong></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210326113429.png" alt="image-20210326113429142" style="zoom:50%;" /></p><p>regular training set：前两列</p><p>在常规数据上训练的单跳基线在对抗性评价上表现不佳，这说明它确实是在利用推理捷径，而不是实际执行多跳推理来定位答案。添加了支持性事实监督后（第2行），在对抗性评价上有显著的改善。</p><p>2-hop模型被额外监督预测句子级支持事实后，在常规评价和对抗性评价中的性能都有所下降。</p><p>adversarial training set：后两列</p><p>经过对抗式训练后，基线和带有控制单元的2-hop模型在对抗式评价上性能都有显著提升。</p><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><h4 id="Adversary-Ablation"><a href="#Adversary-Ablation" class="headerlink" title="Adversary Ablation"></a>Adversary Ablation</h4><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210326115935.png" alt="image-20210326115935475" style="zoom:50%;" /></p><p>为了测试对抗训练的模型的鲁棒性，具有不同数量的对抗文档和不同对抗策略的dev集上对它们进行评估。当对抗文档被预置到上下文中时，基线和2-hop模型都不会受到影响。当每个有答案的支持文档的对抗性文件数量增加到8个时，4个模型的性能都下降了，但2-hop模型的性能依然优于单跳模型。</p><h4 id="Control-Unit-Ablation"><a href="#Control-Unit-Ablation" class="headerlink" title="Control Unit Ablation"></a>Control Unit Ablation</h4><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210326120528.png" alt="image-20210326120528188" style="zoom:50%;" /></p><p>对2-hop模型进行了去掉控制单元的消融研究。前两行在4种不同训练和评估数据组合的设置下，带有控制单元的模型都优于替代模型。即控制单元可以提高模型的多跳推理能力和对对抗性文档的鲁棒性。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>​        在本文的对抗性评估中，强基线模型的性能显著下降，表明它们确实在利用捷径而不是进行多跳推理。经过对抗性训练后，基线的性能有所提高，但在对抗性评价上仍然受到限制。因此，使用一个在不同推理跳数上动态关注问题的控制单元来引导模型的多跳推理。结果表明，这个在常规数据上训练的2跳模型比基线模型对对抗者更加稳健。经过对抗训练后，这个2跳模型不仅比在常规数据上训练的对应模型实现了改进，而且还优于对抗训练的1跳基线模型。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> HotpotQA </tag>
            
            <tag> ADDDOC </tag>
            
            <tag> KGE </tag>
            
            <tag> KG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Answering while Summarizing Multi-task Learning for Multi-hop QA with Evidence Extraction</title>
      <link href="/2021/03/18/ACL2019-Answering%20while%20Summarizing%20Multi-task%20Learning%20for%20Multi-hop%20QA%20with%20Evidence%20Extraction/"/>
      <url>/2021/03/18/ACL2019-Answering%20while%20Summarizing%20Multi-task%20Learning%20for%20Multi-hop%20QA%20with%20Evidence%20Extraction/</url>
      
        <content type="html"><![CDATA[<h1 id="Answering-while-Summarizing-Multi-task-Learning-for-Multi-hop-QA-with-Evidence-Extraction"><a href="#Answering-while-Summarizing-Multi-task-Learning-for-Multi-hop-QA-with-Evidence-Extraction" class="headerlink" title="Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction"></a>Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction</h1><blockquote><p><a href="https://arxiv.org/pdf/1905.08511.pdf">论文：https://arxiv.org/pdf/1905.08511.pdf</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>本文聚焦于可解释的多跳QA任务，要求系统通过推理和收集参考文本的不相交片段来返回带有证据句子的答案。提出了<strong>Query Focused Extractor(QFE)</strong>模型用于证据提取，并使用多任务学习与QA模型。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><h3 id="Query-Focused-Extractor-QFE"><a href="#Query-Focused-Extractor-QFE" class="headerlink" title="Query Focused Extractor (QFE)"></a>Query Focused Extractor (QFE)</h3><blockquote><p>整体模型采用多任务学习，答案选择采用QA模型，证据提取采用QFE模型。</p></blockquote><p>​        QFE的灵感来自于提取式摘要模型<strong>(extractive summarization models)</strong>，将可解释的多跳QA的证据提取看作是一个以查询为中心的摘要任务，与现有方法独立提取每个证据句相比，它通过使用RNN对问题句的关注机制<strong>(attention mechanism)</strong>，依次提取证据句。它使QFE考虑到证据句之间的依赖性，覆盖了问题句中的重要信息。</p><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><blockquote><p>除了evidence layer其他部分和HotpotQA的baseline模型一样。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210316140120.png" alt="image-20210316140119983" style="zoom:50%;" /></p><p>Input: Context C (multiple texts), Query Q (text)</p><h4 id="The-Word-Embedding-Layer"><a href="#The-Word-Embedding-Layer" class="headerlink" title="The Word Embedding Layer"></a>The Word Embedding Layer</h4><p>将C和Q编码为词向量(word vectors)序列。</p><p>output: $C_1, Q_1$</p><h4 id="The-Context-Layer"><a href="#The-Context-Layer" class="headerlink" title="The Context Layer"></a>The Context Layer</h4><p>encodes $C_1, Q_1$as contextual vectors  $C_2, Q_2$ by using a bi-directional RNN<strong>(Bi-RNN)</strong>.</p><p>output:  $C_2, Q_2$</p><h4 id="The-Matching-Layer"><a href="#The-Matching-Layer" class="headerlink" title="The Matching Layer"></a>The Matching Layer</h4><p>encodes $C_2, Q_2$as matching vectors $C_3$ by using bi-directional attention,a Bi-RNN, and selfattention.</p><h4 id="The-Evidence-Layer"><a href="#The-Evidence-Layer" class="headerlink" title="The Evidence Layer"></a>The Evidence Layer</h4><p>first encodes $C_3$ as $[\overrightarrow{C4};\overleftarrow{C4}]$ by a Bi-RNN.</p><p>设$j_1(i)$为C中第i句的第一个词的索引，$j_2(i)$为最后一个词的索引。</p><script type="math/tex; mode=display">xi= [\overrightarrow{c4,j_2(i)};\overleftarrow{c4,j_1(i)}] \in R^{2d_c}</script><p>QFE输出第i句为证据的概率分布:</p><script type="math/tex; mode=display">Pr(i) = QFE(X, Y = Q_2)</script><blockquote><p>X:句子级上下文向量</p><p>Y:上下文查询向量Q2</p></blockquote><p>证据层将单词级向量和句子级向量连接起来。</p><script type="math/tex; mode=display">c_5,j= [c_3,j; x_{i(j)}] \in R^{3d_c}</script><h4 id="The-Answer-Layer"><a href="#The-Answer-Layer" class="headerlink" title="The Answer Layer"></a>The Answer Layer</h4><p>predicts the answer type $A_T$ and the answer string $A_S$ from $C_5$.</p><p>Answer Layer有多个堆叠的Bi-RNN。每个Bi-RNN的输出被全连接层和softmax函数映射到概率分布上。</p><h3 id="Query-Focused-Extractor"><a href="#Query-Focused-Extractor" class="headerlink" title="Query Focused Extractor"></a>Query Focused Extractor</h3><p>QFE结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210316152458.png" alt="image-20210316152458943" style="zoom:50%;" /></p><p>input:</p><blockquote><p>X:句子级上下文向量</p><p>Y:上下文查询向量</p></blockquote><p>将timestep定义为提取句子的操作。</p><p>RNN状态更新：</p><script type="math/tex; mode=display">z^t= RNN(z^{t−1}, x_{e^t}) \in R^{2d_c}</script><blockquote><p>$e^t∈ {1, · · · , l_s}$ is the index of the sentence extracted at step t</p><p>$E^t= {e^1, · · · , e^t}$ to be the set of sentences extracted until step t</p></blockquote><p>QFE根据概率分布提取第i个句子：</p><script type="math/tex; mode=display">Pr(i; E^{t−1}) = softmax_i(u_i^t)</script><p>QFE选择$e^t$:</p><script type="math/tex; mode=display">et= argmax Pr(i; E^{t−1})</script><p>RNN的初始状态是通过全连接层和X的最大池获得的向量。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>HotpotQA</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210316130622.png" alt="image-20210316130615098" style="zoom: 50%;" /></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210316193625.png" alt="image-20210316193625423" style="zoom:50%;" /></p><ul><li>在distractor setting下，QFE证据提取得分方面表现最好。在joint EM and F1 metrics上取得了最先进的性能。QFE在所有指标上都优于基线模型的表现。</li><li>QFE没有使用预训练模型，但在Evidence的评测下性能要比比DFGN + BERT 和 BERT Plus出色。</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210316194952.png" alt="image-20210316194952729" style="zoom:50%;" /></p><ul><li>在fullwiki setting下，QFE性能优于baseline模型。</li><li>因为fullwiki的gold evidence sentences可能会少于两个甚至无法回答，出现数据集移位的问题导致性能未超越Cognitive Graph。</li></ul><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210316195539.png" alt="image-20210316195539401" style="zoom:50%;" /></p><ul><li>evidence extraction model对证据提取和答案提取有效。</li><li>到达EOE句子自适应终止提取，对模型效果有所提升。</li></ul><p>​        实验结果表明，采用简单RC基线模型的QFE在HotpotQA上实现了最先进的证据提取得分。虽然是为RC设计的，但在FEVER上也取得了最先进的证据提取成绩。（FEVER是一个在大型文本数据库上识别文本的任务），QFE替代证据提取模块可提高性能，自适应终止提取有助于确切匹配和证据提取的精确度，QFE问题的难度取决于所需证据句子的数量。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> HotpotQA </tag>
            
            <tag> QFE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用逻辑回归对鸢尾花进行分类</title>
      <link href="/2021/03/18/%E4%BD%BF%E7%94%A8%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%AF%B9%E9%B8%A2%E5%B0%BE%E8%8A%B1%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/"/>
      <url>/2021/03/18/%E4%BD%BF%E7%94%A8%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%AF%B9%E9%B8%A2%E5%B0%BE%E8%8A%B1%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="使用逻辑回归对鸢尾花进行分类"><a href="#使用逻辑回归对鸢尾花进行分类" class="headerlink" title="使用逻辑回归对鸢尾花进行分类"></a>使用逻辑回归对鸢尾花进行分类</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">iris = load_iris()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印数据集描述</span></span><br><span class="line"><span class="built_in">print</span>(iris.DESCR)</span><br></pre></td></tr></table></figure><pre><code>.. _iris_dataset:Iris plants dataset--------------------**Data Set Characteristics:**    :Number of Instances: 150 (50 in each of three classes)    :Number of Attributes: 4 numeric, predictive attributes and the class    :Attribute Information:        - sepal length in cm        - sepal width in cm        - petal length in cm        - petal width in cm        - class:                - Iris-Setosa                - Iris-Versicolour                - Iris-Virginica    :Summary Statistics:    ============== ==== ==== ======= ===== ====================                    Min  Max   Mean    SD   Class Correlation    ============== ==== ==== ======= ===== ====================    sepal length:   4.3  7.9   5.84   0.83    0.7826    sepal width:    2.0  4.4   3.05   0.43   -0.4194    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)    ============== ==== ==== ======= ===== ====================    :Missing Attribute Values: None    :Class Distribution: 33.3% for each of 3 classes.    :Creator: R.A. Fisher    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)    :Date: July, 1988The famous Iris database, first used by Sir R.A. Fisher. The dataset is takenfrom Fisher&#39;s paper. Note that it&#39;s the same as in R, but not as in the UCIMachine Learning Repository, which has two wrong data points.This is perhaps the best known database to be found in thepattern recognition literature.  Fisher&#39;s paper is a classic in the field andis referenced frequently to this day.  (See Duda &amp; Hart, for example.)  Thedata set contains 3 classes of 50 instances each, where each class refers to atype of iris plant.  One class is linearly separable from the other 2; thelatter are NOT linearly separable from each other... topic:: References   - Fisher, R.A. &quot;The use of multiple measurements in taxonomic problems&quot;     Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to     Mathematical Statistics&quot; (John Wiley, NY, 1950).   - Duda, R.O., &amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.     (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.   - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System     Structure and Classification Rule for Recognition in Partially Exposed     Environments&quot;.  IEEE Transactions on Pattern Analysis and Machine     Intelligence, Vol. PAMI-2, No. 1, 67-71.   - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;.  IEEE Transactions     on Information Theory, May 1972, 431-433.   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al&quot;s AUTOCLASS II     conceptual clustering system finds 3 classes in the data.   - Many, many more ...</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(iris)</span><br></pre></td></tr></table></figure><pre><code>&#123;&#39;data&#39;: array([[5.1, 3.5, 1.4, 0.2],       [4.9, 3. , 1.4, 0.2],       [4.7, 3.2, 1.3, 0.2],       [4.6, 3.1, 1.5, 0.2],       [5. , 3.6, 1.4, 0.2],       [5.4, 3.9, 1.7, 0.4],       [4.6, 3.4, 1.4, 0.3],       [5. , 3.4, 1.5, 0.2],       [4.4, 2.9, 1.4, 0.2],       [4.9, 3.1, 1.5, 0.1],       [5.4, 3.7, 1.5, 0.2],       [4.8, 3.4, 1.6, 0.2],       [4.8, 3. , 1.4, 0.1],       [4.3, 3. , 1.1, 0.1],       [5.8, 4. , 1.2, 0.2],       [5.7, 4.4, 1.5, 0.4],       [5.4, 3.9, 1.3, 0.4],       [5.1, 3.5, 1.4, 0.3],       [5.7, 3.8, 1.7, 0.3],       [5.1, 3.8, 1.5, 0.3],       [5.4, 3.4, 1.7, 0.2],       [5.1, 3.7, 1.5, 0.4],       [4.6, 3.6, 1. , 0.2],       [5.1, 3.3, 1.7, 0.5],       [4.8, 3.4, 1.9, 0.2],       [5. , 3. , 1.6, 0.2],       [5. , 3.4, 1.6, 0.4],       [5.2, 3.5, 1.5, 0.2],       [5.2, 3.4, 1.4, 0.2],       [4.7, 3.2, 1.6, 0.2],       [4.8, 3.1, 1.6, 0.2],       [5.4, 3.4, 1.5, 0.4],       [5.2, 4.1, 1.5, 0.1],       [5.5, 4.2, 1.4, 0.2],       [4.9, 3.1, 1.5, 0.2],       [5. , 3.2, 1.2, 0.2],       [5.5, 3.5, 1.3, 0.2],       [4.9, 3.6, 1.4, 0.1],       [4.4, 3. , 1.3, 0.2],       [5.1, 3.4, 1.5, 0.2],       [5. , 3.5, 1.3, 0.3],       [4.5, 2.3, 1.3, 0.3],       [4.4, 3.2, 1.3, 0.2],       [5. , 3.5, 1.6, 0.6],       [5.1, 3.8, 1.9, 0.4],       [4.8, 3. , 1.4, 0.3],       [5.1, 3.8, 1.6, 0.2],       [4.6, 3.2, 1.4, 0.2],       [5.3, 3.7, 1.5, 0.2],       [5. , 3.3, 1.4, 0.2],       [7. , 3.2, 4.7, 1.4],       [6.4, 3.2, 4.5, 1.5],       [6.9, 3.1, 4.9, 1.5],       [5.5, 2.3, 4. , 1.3],       [6.5, 2.8, 4.6, 1.5],       [5.7, 2.8, 4.5, 1.3],       [6.3, 3.3, 4.7, 1.6],       [4.9, 2.4, 3.3, 1. ],       [6.6, 2.9, 4.6, 1.3],       [5.2, 2.7, 3.9, 1.4],       [5. , 2. , 3.5, 1. ],       [5.9, 3. , 4.2, 1.5],       [6. , 2.2, 4. , 1. ],       [6.1, 2.9, 4.7, 1.4],       [5.6, 2.9, 3.6, 1.3],       [6.7, 3.1, 4.4, 1.4],       [5.6, 3. , 4.5, 1.5],       [5.8, 2.7, 4.1, 1. ],       [6.2, 2.2, 4.5, 1.5],       [5.6, 2.5, 3.9, 1.1],       [5.9, 3.2, 4.8, 1.8],       [6.1, 2.8, 4. , 1.3],       [6.3, 2.5, 4.9, 1.5],       [6.1, 2.8, 4.7, 1.2],       [6.4, 2.9, 4.3, 1.3],       [6.6, 3. , 4.4, 1.4],       [6.8, 2.8, 4.8, 1.4],       [6.7, 3. , 5. , 1.7],       [6. , 2.9, 4.5, 1.5],       [5.7, 2.6, 3.5, 1. ],       [5.5, 2.4, 3.8, 1.1],       [5.5, 2.4, 3.7, 1. ],       [5.8, 2.7, 3.9, 1.2],       [6. , 2.7, 5.1, 1.6],       [5.4, 3. , 4.5, 1.5],       [6. , 3.4, 4.5, 1.6],       [6.7, 3.1, 4.7, 1.5],       [6.3, 2.3, 4.4, 1.3],       [5.6, 3. , 4.1, 1.3],       [5.5, 2.5, 4. , 1.3],       [5.5, 2.6, 4.4, 1.2],       [6.1, 3. , 4.6, 1.4],       [5.8, 2.6, 4. , 1.2],       [5. , 2.3, 3.3, 1. ],       [5.6, 2.7, 4.2, 1.3],       [5.7, 3. , 4.2, 1.2],       [5.7, 2.9, 4.2, 1.3],       [6.2, 2.9, 4.3, 1.3],       [5.1, 2.5, 3. , 1.1],       [5.7, 2.8, 4.1, 1.3],       [6.3, 3.3, 6. , 2.5],       [5.8, 2.7, 5.1, 1.9],       [7.1, 3. , 5.9, 2.1],       [6.3, 2.9, 5.6, 1.8],       [6.5, 3. , 5.8, 2.2],       [7.6, 3. , 6.6, 2.1],       [4.9, 2.5, 4.5, 1.7],       [7.3, 2.9, 6.3, 1.8],       [6.7, 2.5, 5.8, 1.8],       [7.2, 3.6, 6.1, 2.5],       [6.5, 3.2, 5.1, 2. ],       [6.4, 2.7, 5.3, 1.9],       [6.8, 3. , 5.5, 2.1],       [5.7, 2.5, 5. , 2. ],       [5.8, 2.8, 5.1, 2.4],       [6.4, 3.2, 5.3, 2.3],       [6.5, 3. , 5.5, 1.8],       [7.7, 3.8, 6.7, 2.2],       [7.7, 2.6, 6.9, 2.3],       [6. , 2.2, 5. , 1.5],       [6.9, 3.2, 5.7, 2.3],       [5.6, 2.8, 4.9, 2. ],       [7.7, 2.8, 6.7, 2. ],       [6.3, 2.7, 4.9, 1.8],       [6.7, 3.3, 5.7, 2.1],       [7.2, 3.2, 6. , 1.8],       [6.2, 2.8, 4.8, 1.8],       [6.1, 3. , 4.9, 1.8],       [6.4, 2.8, 5.6, 2.1],       [7.2, 3. , 5.8, 1.6],       [7.4, 2.8, 6.1, 1.9],       [7.9, 3.8, 6.4, 2. ],       [6.4, 2.8, 5.6, 2.2],       [6.3, 2.8, 5.1, 1.5],       [6.1, 2.6, 5.6, 1.4],       [7.7, 3. , 6.1, 2.3],       [6.3, 3.4, 5.6, 2.4],       [6.4, 3.1, 5.5, 1.8],       [6. , 3. , 4.8, 1.8],       [6.9, 3.1, 5.4, 2.1],       [6.7, 3.1, 5.6, 2.4],       [6.9, 3.1, 5.1, 2.3],       [5.8, 2.7, 5.1, 1.9],       [6.8, 3.2, 5.9, 2.3],       [6.7, 3.3, 5.7, 2.5],       [6.7, 3. , 5.2, 2.3],       [6.3, 2.5, 5. , 1.9],       [6.5, 3. , 5.2, 2. ],       [6.2, 3.4, 5.4, 2.3],       [5.9, 3. , 5.1, 1.8]]), &#39;target&#39;: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), &#39;target_names&#39;: array([&#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39;], dtype=&#39;&lt;U10&#39;), &#39;DESCR&#39;: &#39;.. _iris_dataset:\n\nIris plants dataset\n--------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 150 (50 in each of three classes)\n    :Number of Attributes: 4 numeric, predictive attributes and the class\n    :Attribute Information:\n        - sepal length in cm\n        - sepal width in cm\n        - petal length in cm\n        - petal width in cm\n        - class:\n                - Iris-Setosa\n                - Iris-Versicolour\n                - Iris-Virginica\n                \n    :Summary Statistics:\n\n    ============== ==== ==== ======= ===== ====================\n                    Min  Max   Mean    SD   Class Correlation\n    ============== ==== ==== ======= ===== ====================\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n    ============== ==== ==== ======= ===== ====================\n\n    :Missing Attribute Values: None\n    :Class Distribution: 33.3% for each of 3 classes.\n    :Creator: R.A. Fisher\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n    :Date: July, 1988\n\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\nfrom Fisher\&#39;s paper. Note that it\&#39;s the same as in R, but not as in the UCI\nMachine Learning Repository, which has two wrong data points.\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher\&#39;s paper is a classic in the field and\nis referenced frequently to this day.  (See Duda &amp; Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\n.. topic:: References\n\n   - Fisher, R.A. &quot;The use of multiple measurements in taxonomic problems&quot;\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to\n     Mathematical Statistics&quot; (John Wiley, NY, 1950).\n   - Duda, R.O., &amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n     (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.\n   - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System\n     Structure and Classification Rule for Recognition in Partially Exposed\n     Environments&quot;.  IEEE Transactions on Pattern Analysis and Machine\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n   - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;.  IEEE Transactions\n     on Information Theory, May 1972, 431-433.\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al&quot;s AUTOCLASS II\n     conceptual clustering system finds 3 classes in the data.\n   - Many, many more ...&#39;, &#39;feature_names&#39;: [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;], &#39;filename&#39;: &#39;/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/sklearn/datasets/data/iris.csv&#39;&#125;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X[<span class="number">0</span>:<span class="number">50</span>,<span class="number">0</span>]</span><br></pre></td></tr></table></figure><pre><code>array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9, 5.4, 4.8, 4.8,       4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.1, 5.4, 5.1, 4.6, 5.1, 4.8, 5. ,       5. , 5.2, 5.2, 4.7, 4.8, 5.4, 5.2, 5.5, 4.9, 5. , 5.5, 4.9, 4.4,       5.1, 5. , 4.5, 4.4, 5. , 5.1, 4.8, 5.1, 4.6, 5.3, 5. ])</code></pre><h3 id="任取两个特征画图"><a href="#任取两个特征画图" class="headerlink" title="任取两个特征画图"></a>任取两个特征画图</h3><blockquote><p>共有4个特征，无法画在同一张二维平面</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">feature = <span class="number">2</span></span><br><span class="line">feature_other = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">plt.scatter(X[<span class="number">0</span>:<span class="number">50</span>, feature], X[<span class="number">0</span>:<span class="number">50</span>, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;setosa&#x27;</span>)  <span class="comment"># 前50个样本</span></span><br><span class="line">plt.scatter(X[<span class="number">50</span>:<span class="number">100</span>, feature], X[<span class="number">50</span>:<span class="number">100</span>, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, label=<span class="string">&#x27;versicolor&#x27;</span>)  <span class="comment"># 中间50个</span></span><br><span class="line">plt.scatter(X[<span class="number">100</span>:, feature], X[<span class="number">100</span>:, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, label=<span class="string">&#x27;Virginica&#x27;</span>)  <span class="comment"># 后50个样本</span></span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x7ff42bef14f0&gt;</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210318193437.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据代入模型</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 逻辑回归模型</span></span><br><span class="line">model = linear_model.LogisticRegression(C=<span class="number">100.0</span>)</span><br><span class="line">model.fit(X, y)</span><br></pre></td></tr></table></figure><pre><code>/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.Increase the number of iterations (max_iter) or scale the data as shown in:    https://scikit-learn.org/stable/modules/preprocessing.htmlPlease also refer to the documentation for alternative solver options:    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression  n_iter_i = _check_optimize_result(LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,                   intercept_scaling=1, l1_ratio=None, max_iter=100,                   multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;,                   random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=0,                   warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(model.coef_) <span class="comment"># 系数 theta1,theta2...</span></span><br><span class="line"><span class="built_in">print</span>(model.intercept_) <span class="comment"># 截距 theta0</span></span><br><span class="line">y_hat = model.predict(X)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确度=&quot;</span>, accuracy_score(y, y_hat))</span><br></pre></td></tr></table></figure><pre><code>[[-0.27165929  3.28412217 -6.15316158 -4.05114224] [ 1.28462627  0.47872193 -0.5863018  -4.15124947] [-1.01296698 -3.7628441   6.73946338  8.20239171]][ 19.35565008   5.44146183 -24.79711191]准确度= 0.98</code></pre><h3 id="可视化分类结果"><a href="#可视化分类结果" class="headerlink" title="可视化分类结果"></a>可视化分类结果</h3><p>为了可视化分类结果，我们取2个特征进行训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">feature = <span class="number">2</span></span><br><span class="line">feature_other = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">X = iris.data</span><br><span class="line">X_2 = X[:, [feature, feature_other]] <span class="comment">#X_2为仅包含两个特征的数据集</span></span><br><span class="line">y = iris.target</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model_2 = linear_model.LogisticRegression(C=<span class="number">100.0</span>)</span><br><span class="line">model_2.fit(X_2, y)</span><br></pre></td></tr></table></figure><pre><code>LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,                   intercept_scaling=1, l1_ratio=None, max_iter=100,                   multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;,                   random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=0,                   warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># meshgrid函数生成两个网格矩阵</span></span><br><span class="line">h = <span class="number">.02</span> <span class="comment">#步长</span></span><br><span class="line">x_min, x_max = X[:, feature].<span class="built_in">min</span>() - <span class="number">.5</span>, X[:, feature].<span class="built_in">max</span>() + <span class="number">.5</span></span><br><span class="line">y_min, y_max = X[:, feature_other].<span class="built_in">min</span>() - <span class="number">.5</span>, X[:, feature_other].<span class="built_in">max</span>() + <span class="number">.5</span></span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xx.shape</span><br></pre></td></tr></table></figure><pre><code>(170, 345)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yy</span><br></pre></td></tr></table></figure><pre><code>array([[-0.4 , -0.4 , -0.4 , ..., -0.4 , -0.4 , -0.4 ],       [-0.38, -0.38, -0.38, ..., -0.38, -0.38, -0.38],       [-0.36, -0.36, -0.36, ..., -0.36, -0.36, -0.36],       ...,       [ 2.94,  2.94,  2.94, ...,  2.94,  2.94,  2.94],       [ 2.96,  2.96,  2.96, ...,  2.96,  2.96,  2.96],       [ 2.98,  2.98,  2.98, ...,  2.98,  2.98,  2.98]])</code></pre><p>注意: [[1,2,3]]表示一行三列，[1,2,3]表示3行一列，所以下面代码要执行xx.ravel()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成新的数据点 为了填充平面</span></span><br><span class="line">np.c_[xx.ravel(), yy.ravel()]</span><br></pre></td></tr></table></figure><pre><code>array([[ 0.5 , -0.4 ],       [ 0.52, -0.4 ],       [ 0.54, -0.4 ],       ...,       [ 7.34,  2.98],       [ 7.36,  2.98],       [ 7.38,  2.98]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z = model_2.predict(np.c_[xx.ravel(), yy.ravel()])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z</span><br></pre></td></tr></table></figure><pre><code>array([0, 0, 0, ..., 2, 2, 2])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z.shape</span><br></pre></td></tr></table></figure><pre><code>(58650,)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xx.shape</span><br></pre></td></tr></table></figure><pre><code>(170, 345)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置成相同纬度</span></span><br><span class="line">z = z.reshape(xx.shape)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用新生成的数据点绘制密密麻麻的网格平面图</span></span><br><span class="line">plt.pcolormesh(xx, yy, z, cmap=plt.cm.Paired)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制原始数据点</span></span><br><span class="line">plt.scatter(X[<span class="number">0</span>:<span class="number">50</span>, feature], X[<span class="number">0</span>:<span class="number">50</span>, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;setosa&#x27;</span>)  <span class="comment"># 前50个样本</span></span><br><span class="line">plt.scatter(X[<span class="number">50</span>:<span class="number">100</span>, feature], X[<span class="number">50</span>:<span class="number">100</span>, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, label=<span class="string">&#x27;versicolor&#x27;</span>)  <span class="comment"># 中间50个</span></span><br><span class="line">plt.scatter(X[<span class="number">100</span>:, feature], X[<span class="number">100</span>:, feature_other],</span><br><span class="line">            color=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, label=<span class="string">&#x27;Virginica&#x27;</span>)  <span class="comment"># 后50个样本</span></span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.collections.PathCollection at 0x7ff42c464d00&gt;</code></pre><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210318193446.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用专业术语</title>
      <link href="/2021/03/16/%E5%B8%B8%E7%94%A8%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/"/>
      <url>/2021/03/16/%E5%B8%B8%E7%94%A8%E4%B8%93%E4%B8%9A%E6%9C%AF%E8%AF%AD/</url>
      
        <content type="html"><![CDATA[<h1 id="常用专业术语"><a href="#常用专业术语" class="headerlink" title="常用专业术语"></a>常用专业术语</h1><p>​    ◦    comes in handy 派上用场<br>​    ◦    future-proofs 面向未来<br>​    ◦    deserialized 反序列化<br>​    ◦    Instantiate 实例化<br>​    ◦    Simply put 简单的说<br>​    ◦    separate indices 单独的索引<br>​    ◦    diagram 图<br>​    ◦    customize 定制<br>​    ◦    explicitly 明确地<br>​    ◦    prune 修剪<br>​    ◦    threshold 阈<br>​    ◦    deep dive 深入探讨<br>​    ◦    back-propagation 反向传播<br>​    ◦    accumulator 累加器<br>​    ◦    cumbersome 麻烦的<br>​    ◦    analogous 类似的<br>​    ◦    compatible 兼容<br>​    ◦    encapsulates 封装<br>​    ◦    arbitrary 任意的<br>​    ◦    explicit 显式的<br>​    ◦    heuristics 启发式<br>​    ◦    discarding 丢弃<br>​    ◦    mechanism 机制<br>​    ◦    notion 概念<br>​    ◦    pseudo 伪<br>​    ◦    arbitrary 任意的<br>​    ◦    nested 嵌套的<br>​    ◦    quantifiable 可量化的<br>​    ◦    spark 引发<br>​    ◦    inherently 固有的<br>​    ◦    distant supervision 远程监督<br>​    ◦    desiderata 需求<br>​    ◦    nontrivial 非平凡的<br>​    ◦    overall setting 试点研究<br>​    ◦    counterproductive 适得其反<br>​    ◦    corpus 语料库<br>​    ◦    alleviate 减轻<br>​    ◦    non-negligible 不可忽略的<br>​    ◦    subsumes 包含<br>​    ◦    Intuitively 直观地<br>​    ◦    marginally 边际的聚合<br>​    ◦    deterioration 恶化<br>​    ◦    To the best of our knowledge 据我们所知<br>​    ◦    in terms of 在…方面<br>​    ◦    aggregation 聚合<br>​    ◦    lexical 词汇的<br>​    ◦    iterative 反复的<br>​    ◦    dampens 抑制<br>​    ◦    iteratively 反复地<br>​    ◦    facilitates 促进<br>​    ◦    adaptively 适应性的<br>​    ◦    compression 压缩<br>​    ◦    arbitrary 随意的<br>​    ◦    propagate 传播<br>​    ◦    corpus 语料库<br>​    ◦    capability 能力<br>​    ◦    To address this challenge 应对这一挑战<br>​    ◦    off-the-shelf 现成的<br>​    ◦    In contrast 相比之下<br>​    ◦    spread out 扩散;传播开<br>​    ◦    complementary 补充<br>​    ◦    cast 投向<br>​    ◦    jointly 共同<br>​    ◦    explicitly 明确<br>​    ◦    coreference 参考资料<br>​    ◦    heterogeneous 异质<br>​    ◦    diagram 图表<br>​    ◦    formulate 制定<br>​    ◦    examine 检查<br>​    ◦    threshold 阈值 临界点<br>​    ◦    relevance 关联<br>​    ◦    circumstances 情况<br>​    ◦    conjecture 推测<br>​    ◦    entailment 征服<br>​    ◦    coverage 范围</p>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 单词 </tag>
            
            <tag> 专业术语 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>波士顿房价预测</title>
      <link href="/2021/03/15/%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/"/>
      <url>/2021/03/15/%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="波士顿房价预测"><a href="#波士顿房价预测" class="headerlink" title="波士顿房价预测"></a>波士顿房价预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span>  linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br></pre></td></tr></table></figure><h2 id="1-获取数据"><a href="#1-获取数据" class="headerlink" title="1.获取数据"></a>1.获取数据</h2><h3 id="1-1通过load-boston-获取数据"><a href="#1-1通过load-boston-获取数据" class="headerlink" title="1.1通过load_boston()获取数据"></a>1.1通过load_boston()获取数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boston = load_boston()</span><br></pre></td></tr></table></figure><h5 id="特征含义"><a href="#特征含义" class="headerlink" title="特征含义"></a>特征含义</h5><p>CRIM：城镇人均犯罪率。<br/><br>ZN：住宅用地超过 25000 sq.ft. 的比例。<br/><br>INDUS：城镇非零售商用土地的比例。<br/><br>CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）。<br/><br>NOX：一氧化氮浓度。<br/><br>RM：住宅平均房间数。<br/><br>AGE：1940 年之前建成的自用房屋比例。<br/><br>DIS：到波士顿五个中心区域的加权距离。<br/><br>RAD：辐射性公路的接近指数。<br/><br>TAX：每 10000 美元的全值财产税率。<br/><br>PTRATIO：城镇师生比例。<br/><br>B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。<br/><br>LSTAT：人口中地位低下者的比例。<br/><br>MEDV：自住房的平均房价，以千美元计。<br/></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据描述</span></span><br><span class="line"><span class="built_in">print</span>(boston.DESCR)</span><br></pre></td></tr></table></figure><pre><code>.. _boston_dataset:Boston house prices dataset---------------------------**Data Set Characteristics:**      :Number of Instances: 506     :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.    :Attribute Information (in order):        - CRIM     per capita crime rate by town        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.        - INDUS    proportion of non-retail business acres per town        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)        - NOX      nitric oxides concentration (parts per 10 million)        - RM       average number of rooms per dwelling        - AGE      proportion of owner-occupied units built prior to 1940        - DIS      weighted distances to five Boston employment centres        - RAD      index of accessibility to radial highways        - TAX      full-value property-tax rate per $10,000        - PTRATIO  pupil-teacher ratio by town        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town        - LSTAT    % lower status of the population        - MEDV     Median value of owner-occupied homes in $1000&#39;s    :Missing Attribute Values: None    :Creator: Harrison, D. and Rubinfeld, D.L.This is a copy of UCI ML housing dataset.https://archive.ics.uci.edu/ml/machine-learning-databases/housing/</code></pre><p>​<br>​    This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.<br>​<br>    The Boston house-price data of Harrison, D. and Rubinfeld, D.L. ‘Hedonic<br>    prices and the demand for clean air’, J. Environ. Economics &amp; Management,<br>    vol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, ‘Regression diagnostics<br>    …’, Wiley, 1980.   N.B. Various transformations are used in the table on<br>    pages 244-261 of the latter.</p><pre><code>The Boston house-price data has been used in many machine learning papers that address regressionproblems.   .. topic:: References   - Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics: Identifying Influential Data and Sources of Collinearity&#39;, Wiley, 1980. 244-261.   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数据</span></span><br><span class="line"><span class="built_in">print</span>(boston)</span><br></pre></td></tr></table></figure><pre><code>&#123;&#39;data&#39;: array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,        4.9800e+00],       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,        9.1400e+00],       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,        4.0300e+00],       ...,       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,        5.6400e+00],       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,        6.4800e+00],       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,        7.8800e+00]]), &#39;target&#39;: array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]), &#39;feature_names&#39;: array([&#39;CRIM&#39;, &#39;ZN&#39;, &#39;INDUS&#39;, &#39;CHAS&#39;, &#39;NOX&#39;, &#39;RM&#39;, &#39;AGE&#39;, &#39;DIS&#39;, &#39;RAD&#39;,       &#39;TAX&#39;, &#39;PTRATIO&#39;, &#39;B&#39;, &#39;LSTAT&#39;], dtype=&#39;&lt;U7&#39;), &#39;DESCR&#39;: &quot;.. _boston_dataset:\n\nBoston house prices dataset\n---------------------------\n\n**Data Set Characteristics:**  \n\n    :Number of Instances: 506 \n\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n    :Attribute Information (in order):\n        - CRIM     per capita crime rate by town\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS    proportion of non-retail business acres per town\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX      nitric oxides concentration (parts per 10 million)\n        - RM       average number of rooms per dwelling\n        - AGE      proportion of owner-occupied units built prior to 1940\n        - DIS      weighted distances to five Boston employment centres\n        - RAD      index of accessibility to radial highways\n        - TAX      full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n        - LSTAT    % lower status of the population\n        - MEDV     Median value of owner-occupied homes in $1000&#39;s\n\n    :Missing Attribute Values: None\n\n    :Creator: Harrison, D. and Rubinfeld, D.L.\n\nThis is a copy of UCI ML housing dataset.\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n\n\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. &#39;Hedonic\nprices and the demand for clean air&#39;, J. Environ. Economics &amp; Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics\n...&#39;, Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.\n\nThe Boston house-price data has been used in many machine learning papers that address regression\nproblems.   \n     \n.. topic:: References\n\n   - Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics: Identifying Influential Data and Sources of Collinearity&#39;, Wiley, 1980. 244-261.\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n&quot;, &#39;filename&#39;: &#39;/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/sklearn/datasets/data/boston_house_prices.csv&#39;&#125;</code></pre><h4 id="取特征X和标签y"><a href="#取特征X和标签y" class="headerlink" title="取特征X和标签y"></a>取特征X和标签y</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = boston.data</span><br><span class="line">y = boston.target</span><br></pre></td></tr></table></figure><h3 id="1-2-从文件读取"><a href="#1-2-从文件读取" class="headerlink" title="1.2 从文件读取"></a>1.2 从文件读取</h3><p>使用pandas读取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_excel(<span class="string">&#x27;data/boston.xls&#x27;</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }    .dataframe tbody tr th {        vertical-align: top;    }    .dataframe thead th {        text-align: right;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>Unnamed: 0</th>      <th>CRIM</th>      <th>ZN</th>      <th>INDUS</th>      <th>CHAS</th>      <th>NOX</th>      <th>RM</th>      <th>AGE</th>      <th>DIS</th>      <th>RAD</th>      <th>TAX</th>      <th>PTRATIO</th>      <th>B</th>      <th>LSTAT</th>      <th>price</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>0</td>      <td>0.00632</td>      <td>18.0</td>      <td>2.31</td>      <td>0</td>      <td>0.538</td>      <td>6.575</td>      <td>65.2</td>      <td>4.0900</td>      <td>1</td>      <td>296</td>      <td>15.3</td>      <td>396.90</td>      <td>4.98</td>      <td>24.0</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>0.02731</td>      <td>0.0</td>      <td>7.07</td>      <td>0</td>      <td>0.469</td>      <td>6.421</td>      <td>78.9</td>      <td>4.9671</td>      <td>2</td>      <td>242</td>      <td>17.8</td>      <td>396.90</td>      <td>9.14</td>      <td>21.6</td>    </tr>    <tr>      <th>2</th>      <td>2</td>      <td>0.02729</td>      <td>0.0</td>      <td>7.07</td>      <td>0</td>      <td>0.469</td>      <td>7.185</td>      <td>61.1</td>      <td>4.9671</td>      <td>2</td>      <td>242</td>      <td>17.8</td>      <td>392.83</td>      <td>4.03</td>      <td>34.7</td>    </tr>    <tr>      <th>3</th>      <td>3</td>      <td>0.03237</td>      <td>0.0</td>      <td>2.18</td>      <td>0</td>      <td>0.458</td>      <td>6.998</td>      <td>45.8</td>      <td>6.0622</td>      <td>3</td>      <td>222</td>      <td>18.7</td>      <td>394.63</td>      <td>2.94</td>      <td>33.4</td>    </tr>    <tr>      <th>4</th>      <td>4</td>      <td>0.06905</td>      <td>0.0</td>      <td>2.18</td>      <td>0</td>      <td>0.458</td>      <td>7.147</td>      <td>54.2</td>      <td>6.0622</td>      <td>3</td>      <td>222</td>      <td>18.7</td>      <td>396.90</td>      <td>5.33</td>      <td>36.2</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>501</th>      <td>501</td>      <td>0.06263</td>      <td>0.0</td>      <td>11.93</td>      <td>0</td>      <td>0.573</td>      <td>6.593</td>      <td>69.1</td>      <td>2.4786</td>      <td>1</td>      <td>273</td>      <td>21.0</td>      <td>391.99</td>      <td>9.67</td>      <td>22.4</td>    </tr>    <tr>      <th>502</th>      <td>502</td>      <td>0.04527</td>      <td>0.0</td>      <td>11.93</td>      <td>0</td>      <td>0.573</td>      <td>6.120</td>      <td>76.7</td>      <td>2.2875</td>      <td>1</td>      <td>273</td>      <td>21.0</td>      <td>396.90</td>      <td>9.08</td>      <td>20.6</td>    </tr>    <tr>      <th>503</th>      <td>503</td>      <td>0.06076</td>      <td>0.0</td>      <td>11.93</td>      <td>0</td>      <td>0.573</td>      <td>6.976</td>      <td>91.0</td>      <td>2.1675</td>      <td>1</td>      <td>273</td>      <td>21.0</td>      <td>396.90</td>      <td>5.64</td>      <td>23.9</td>    </tr>    <tr>      <th>504</th>      <td>504</td>      <td>0.10959</td>      <td>0.0</td>      <td>11.93</td>      <td>0</td>      <td>0.573</td>      <td>6.794</td>      <td>89.3</td>      <td>2.3889</td>      <td>1</td>      <td>273</td>      <td>21.0</td>      <td>393.45</td>      <td>6.48</td>      <td>22.0</td>    </tr>    <tr>      <th>505</th>      <td>505</td>      <td>0.04741</td>      <td>0.0</td>      <td>11.93</td>      <td>0</td>      <td>0.573</td>      <td>6.030</td>      <td>80.8</td>      <td>2.5050</td>      <td>1</td>      <td>273</td>      <td>21.0</td>      <td>396.90</td>      <td>7.88</td>      <td>11.9</td>    </tr>  </tbody></table><p>506 rows × 15 columns</p></div><h4 id="取特征X和标签y-1"><a href="#取特征X和标签y-1" class="headerlink" title="取特征X和标签y"></a>取特征X和标签y</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = df[df.columns[<span class="number">0</span>:-<span class="number">1</span>]]</span><br><span class="line">y = df[df.columns[-<span class="number">1</span>]]</span><br></pre></td></tr></table></figure><h2 id="2、选择合适的机器学习模型"><a href="#2、选择合适的机器学习模型" class="headerlink" title="2、选择合适的机器学习模型"></a>2、选择合适的机器学习模型</h2><p>该问题是房价预测问题，线性回归能很好的应用于预测问题，因此我们选择使用线性回归模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = linear_model.Ridge(alpha=<span class="number">0.1</span>)</span><br><span class="line">model.fit(X,y)</span><br><span class="line">y_hat = model.predict(X)</span><br></pre></td></tr></table></figure><h2 id="3、训练模型-使用交叉验证选择合适的参数"><a href="#3、训练模型-使用交叉验证选择合适的参数" class="headerlink" title="3、训练模型(使用交叉验证选择合适的参数)"></a>3、训练模型(使用交叉验证选择合适的参数)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 切分数据集</span></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ridge_model = linear_model.Ridge()</span><br><span class="line"><span class="comment"># 可选参数范围</span></span><br><span class="line">param = &#123;<span class="string">&#x27;alpha&#x27;</span>:[<span class="number">0.01</span>,<span class="number">0.03</span>,<span class="number">0.05</span>,<span class="number">0.07</span>,<span class="number">0.1</span>,<span class="number">0.5</span>,<span class="number">0.8</span>,<span class="number">1</span>],<span class="string">&#x27;normalize&#x27;</span>:[<span class="literal">True</span>,<span class="literal">False</span>]&#125;</span><br><span class="line"><span class="comment"># cv=5 5折交叉验证</span></span><br><span class="line">gsearch = GridSearchCV(estimator=ridge_model,param_grid=param,cv=<span class="number">5</span>,scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>)</span><br><span class="line">gsearch.fit(X_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>GridSearchCV(cv=5, error_score=nan,             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,                             max_iter=None, normalize=False, random_state=None,                             solver=&#39;auto&#39;, tol=0.001),             iid=&#39;deprecated&#39;, n_jobs=None,             param_grid=&#123;&#39;alpha&#39;: [0.01, 0.03, 0.05, 0.07, 0.1, 0.5, 0.8, 1],                         &#39;normalize&#39;: [True, False]&#125;,             pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=False,             scoring=&#39;neg_mean_squared_error&#39;, verbose=0)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最优参数</span></span><br><span class="line">gsearch.best_params_,gsearch.best_score_</span><br></pre></td></tr></table></figure><pre><code>(&#123;&#39;alpha&#39;: 0.03, &#39;normalize&#39;: True&#125;, -26.79889044849392)</code></pre><h2 id="4、模型评价"><a href="#4、模型评价" class="headerlink" title="4、模型评价"></a>4、模型评价</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">final_model = linear_model.Ridge(alpha=<span class="number">0.03</span>,normalize=<span class="literal">True</span>)</span><br><span class="line">final_model.fit(X_train,y_train)</span><br><span class="line">y_train_hat = final_model.predict(X_train)</span><br><span class="line">y_test_hat = final_model.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train-MSE=&quot;</span>,mean_squared_error(y_train,y_train_hat))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test-MSE=&quot;</span>,mean_squared_error(y_test,y_test_hat))</span><br></pre></td></tr></table></figure><pre><code>train-MSE= 23.97025486039045test-MSE= 14.309867058504892</code></pre><h2 id="5、上线部署使用"><a href="#5、上线部署使用" class="headerlink" title="5、上线部署使用"></a>5、上线部署使用</h2><h3 id="5-1-保存模型"><a href="#5-1-保存模型" class="headerlink" title="5.1 保存模型"></a>5.1 保存模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br><span class="line">joblib.dump(final_model,<span class="string">&quot;house_train_model.m&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>/Users/maqi/opt/anaconda3/envs/mq_env/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.  warnings.warn(msg, category=FutureWarning)[&#39;house_train_model.m&#39;]</code></pre><h3 id="5-2-模型读取"><a href="#5-2-模型读取" class="headerlink" title="5.2 模型读取"></a>5.2 模型读取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load_model = joblib.load(<span class="string">&quot;house_train_model.m&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load_model.predict(X_test)</span><br></pre></td></tr></table></figure><pre><code>array([30.86303512, 32.79968797, 18.13455905, 20.40093887, 22.55648762,       18.52481884,  5.79687417, 21.9629842 ,  9.0068248 ,  9.96212273,       17.65398317, 30.25054533, 25.10003805, 17.40790836, 21.33936858,       33.59055899, 16.86450916, 19.61200224,  6.91328576, 25.14956329,       29.29708671, 15.44101851, 38.50687743, 15.56660779, 28.75792533,       14.87142875, 26.98223834, 15.26065778, 18.16696527, 28.15512538,       24.97284918, 21.69102163, 32.29555697, 20.20588182, 20.21130528,       19.51947782, 26.97609243, 17.12827828, 22.2803063 , 22.64121736,        8.72866157, 22.17943575, 28.66894552, 22.05452734, 18.08105446,       27.06372036, 29.40518658, 20.53498735, 34.30239592, 25.2630965 ,       17.91569653, 16.47077539, 24.93826934, 17.02902032, 28.46656821,       19.43795752, 31.32818684, 39.21693664, 10.21290457, 29.7576716 ,       18.44035523, 21.47856043, 15.61795029, 27.61939858, 32.41498347,       23.21414905, 13.9004624 , 21.08777079, 21.59304958, 19.0168253 ,       16.66463116, 34.61710439, 20.45793411, 23.45252405, 23.49866486,       25.68604367, 22.90430613, 18.7968677 , 21.45816043, 25.57413156,       27.04579564, 14.41884812, 14.45022443, 13.35822713, 13.6005322 ,       27.78762317, 23.48920868,  6.76428576, 22.03442767, 20.09361292,       21.33547403, 36.87517116, 37.20038258, 31.35625611, 25.66105111,       23.32712931, 35.89108294, 16.60310795, 19.15123475, 22.65298319,       24.98301704, 36.00402402])</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> sklearn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Select, Answer and Explain Interpretable Multi-hop Reading Comprehension over Multiple Documents</title>
      <link href="/2021/03/12/Select%20Answer%20and%20Explain%20Interpretable%20Multi-hop%20Reading%20Comprehension%20over%20Multiple%20Documents/"/>
      <url>/2021/03/12/Select%20Answer%20and%20Explain%20Interpretable%20Multi-hop%20Reading%20Comprehension%20over%20Multiple%20Documents/</url>
      
        <content type="html"><![CDATA[<h1 id="Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents"><a href="#Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents" class="headerlink" title="Select Answer and Explain Interpretable Multi-hop Reading Comprehension over Multiple Documents"></a>Select Answer and Explain Interpretable Multi-hop Reading Comprehension over Multiple Documents</h1><blockquote><p>论文：<a href="https://arxiv.org/abs/1911.00484">https://arxiv.org/abs/1911.00484</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        在多文档的多跳阅读理解(RC)是一个具有挑战性的问题，因为它需要对多个信息源进行推理，并通过提供支持证据来解释答案预测。本文提出了一个有效的、可解释性的选择、回答和解释<strong>Select, Answer and Explain(SAE)</strong>，系统来解决多文档的RC问题。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>​        首先过滤掉与答案无关的文档，从而减少干扰信息量。由一个用新颖的pairwise learning-to-rank loss训练的文档分类器(document classifier)实现。然后将所选的答案相关文档输入到模型中，共同预测答案和支持句。该模型通过多任务学习目标进行了优化，在token层面上进行答案预测，在句子层面上进行辅助句子预测，同时在这两个任务之间进行了基于注意力的交互。答案预测是通过以开始和结束标记为目标的序列标签来完成的，将支持句预测投向(cast)了节点分类任务。建立了一个GNN模型，在上下文句子嵌入上做推理，基于一种新颖的混合注意力池化机制(a novel mixed attentive pooling mechanism)，在token表示上进行总结，多任务学习加上这两个任务之间基于混合注意力的交互，保证了两个任务之间信息的互补性得到利用。</p><h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210309194459.png" alt="image-20210309194459126" style="zoom:50%;" /></p><p>输入到BERT的数据格式：<strong>“[CLS]” + question + “[SEP]” + document + “[SEP]”</strong></p><p>binary cross entropy loss：</p><script type="math/tex; mode=display">L = −\sum ^n _{i=0} t_ilogP(D_i) + (1 − t_i)log(1 − P (D_i))</script><blockquote><p>$t_i$是$D_i$的标签</p><p>n是文档的数量</p><p>$P(D_i)$是文档i在标签$t_i$下的概率</p></blockquote><h4 id="不足："><a href="#不足：" class="headerlink" title="不足："></a>不足：</h4><p>这种简单的方法单独处理每个文档，而不考虑文档间的交互和关系，而这些关系对于下游的多跳推理任务至关重要。</p><h4 id="改进："><a href="#改进：" class="headerlink" title="改进："></a>改进：</h4><p>加入multi-head self-attention (MHSA) 层。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210309200203.png" alt="image-20210309200203672" style="zoom:50%;" /></p><h4 id="MHSA层定义："><a href="#MHSA层定义：" class="headerlink" title="MHSA层定义："></a>MHSA层定义：</h4><script type="math/tex; mode=display">Attention = softmax( \frac{QK^T}{\sqrt{dk}}  )</script><script type="math/tex; mode=display">Multihead = Concat(head_i...head_n)W^o</script><script type="math/tex; mode=display">headi= Attention(QW^Q_i, KW^k_i, V W^v_i)</script><blockquote><p>Q、K、V是文档的 “CLS “嵌入的线性投影，分别代表注意力查询、键和值。</p></blockquote><p>通过让文档/问题表示相互作用，模型能够在更好的输入信号上进行训练，以选择一组需要的黄金文档进行答案提取和支持句预测。</p><p>binary cross entropy:</p><script type="math/tex; mode=display">L = −\sum^n  _{i=0}\sum ^i_{j=0}l_i,l_j logP (D_i, D_j)+(1−l_{i,j})log(1−P (D_i, D_j))</script><blockquote><p>$l_i,l_j$是一对文档$(D_i, D_j)$的标签</p><p>$P(D_i，D_j)$是模型预测的$D_i$比$D_j$更相关的概率</p></blockquote><p>支持句预测：</p><p>​        答案预测任务总是可以帮助支持句预测任务，因为有答案的句子总是一个证据；但反过来就不一样了，因为可能有多个支持句，而概率最高的句子可能不包含答案。因此，为了利用两个互补任务之间的相互作用，提出了一种基于注意力的总结句子表示法(attention-based summarized sentence representation)，从答案预测中引入互补信息。</p><p>注意力权重的计算方法：一部分注意力是用$S_j$上的自注意力计算的；另一部分来自答案预测任务中的起点和终点位置logits的相加。</p><p>在句子嵌入$s_j$上建立一个GNN模型，促进对预测黄金文档中所有句子的多跳推理，以更好地利用复杂的关系信息。</p><h4 id="GNN模型结构："><a href="#GNN模型结构：" class="headerlink" title="GNN模型结构："></a>GNN模型结构：</h4><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210310093815.png" alt="image-20210310093815685" style="zoom:50%;" /></p><p>三种类型边：</p><ol><li>如果它们最初来自同一文档，则在两个节点之间添加边。</li><li>如果表示两个节点的句子在问题中都包含命名实体或名词短语（可能是不同的），则在来自不同文档的两个节点之间增加一条边。</li><li>如果表示两个节点的句子具有相同的命名实体或名词短语，则在来自不同文档的两个节点之间添加一条边。</li></ol><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p><strong>HotpotQA</strong></p><p>例子：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210308200628.png" alt="image-20210308200628718" style="zoom: 33%;" /></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210310195756.png" alt="image-20210310195756747"></p><ul><li>BERT base uncased model (“SAE”)</li><li>Roberta large model (“SAE-large”)</li><li>使用wordpiece tokenizer</li><li>使用$spaCy^3$进行命名实体识别</li></ul><p>本文提出的方法比基线模型在Joint上的EM和F1得分分别提高了28%和25%以上，与之前提出的模型相比都有较明显的改善。</p><p>本文使用的预测黄金文档的模型与oracle黄金文档之间的差距约为3-4%，表明本文提出的的文档选择模块的有效性。</p><p>使用large pre-trained language models作为encoders，性能得到了极大的改善。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><ul><li>SAE</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210310202431.png" alt="image-20210310202416212" style="zoom:50%;" /></p><blockquote><p>“$EM_S$ “和 “$Recalls_S$ “衡量的是两个黄金文档被选中的准确率和召回率</p><p>“$Acc_{span}$ “衡量的是包含答案跨度的黄金文档的被选中的准确率。</p></blockquote><p>MHSA机制允许来自不同文件的信息相互作用，从测试结果来看，对模型的效果很有必要。</p><ul><li>提出的SAE系统在<strong>distractor setting</strong>下取得了比其他现有系统更高的竞争性能。</li><li>提出的系统在HotpotQA盲测集上达到了比现有系统更有竞争力的结果。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> HotpotQA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>修改默认的markdown渲染引擎实现Mathjax效果</title>
      <link href="/2021/03/12/%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E7%9A%84markdown%E6%B8%B2%E6%9F%93%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0Mathjax%E6%95%88%E6%9E%9C/"/>
      <url>/2021/03/12/%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E7%9A%84markdown%E6%B8%B2%E6%9F%93%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0Mathjax%E6%95%88%E6%9E%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="修改默认的markdown渲染引擎实现Mathjax效果"><a href="#修改默认的markdown渲染引擎实现Mathjax效果" class="headerlink" title="修改默认的markdown渲染引擎实现Mathjax效果"></a>修改默认的markdown渲染引擎实现Mathjax效果</h1><ul><li><p>支持更复杂的公式渲染</p></li><li><p><a href="https://www.npmjs.com/package/hexo-renderer-kramed">hexo-renderer-kramed</a></p></li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>先卸载默认渲染引擎</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save</span><br><span class="line">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><ul><li>若安装cnpm也可以使用</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cnpm uninstall hexo-renderer-marked --save</span><br><span class="line">cnpm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><ul><li>修改博客根目录配置文件<code>_config.yml</code></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kramed:</span><br><span class="line">  gfm: true</span><br><span class="line">  pedantic: false</span><br><span class="line">  sanitize: false</span><br><span class="line">  tables: true</span><br><span class="line">  breaks: true</span><br><span class="line">  smartLists: true</span><br><span class="line">  smartypants: true</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> 博客 </tag>
            
            <tag> mathjax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DDRQA:Dynamic Document Reranking for Open-domain Multi-hop Question Answering</title>
      <link href="/2021/03/05/DDRQA%20Dynamic%20Document%20Reranking%20for%20Open-domain%20Multi-hop%20Question%20Answering/"/>
      <url>/2021/03/05/DDRQA%20Dynamic%20Document%20Reranking%20for%20Open-domain%20Multi-hop%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="DDRQA-Dynamic-Document-Reranking-for-Open-domain-Multi-hop-Question-Answering"><a href="#DDRQA-Dynamic-Document-Reranking-for-Open-domain-Multi-hop-Question-Answering" class="headerlink" title="DDRQA: Dynamic Document Reranking for Open-domain Multi-hop Question Answering"></a>DDRQA: Dynamic Document Reranking for Open-domain Multi-hop Question Answering</h1><blockquote><p>论文：<a href="https://arxiv.org/abs/2009.07465">https://arxiv.org/abs/2009.07465</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        开放领域多跳答题(QA)需要检索多个支持性文档，其中一些文档与问题的词义重合度不高，无法直接检索，只能通过迭代文档检索来定位。然而，多步骤的文档检索往往会产生更多的相关但非支持性的文档，这就抑制了下游噪声敏感的reader模块的答案提取。为了解决这一难题，本文提出了动态文档重排序(DDR)，对文档进行迭代检索、重排序和过滤，并自适应地决定何时停止检索过程。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p><strong>Dynamic Document Reranking (DDR)</strong></p><blockquote><p>学习迭代检索带有更新问题的文档，重新排序和过滤文档，并自适应地决定何时停止检索过程。</p></blockquote><p>​        通过利用多文档信息，本文的重新排序模型拥有更多的知识来区分支持性文档和不相关文档。在初始检索后，该方法在每一个检索步骤中都会用从检索文档中提取的文本跨度来更新问题，然后用更新后的问题作为查询来检索补充文档，这些文档被添加到文档图中，进行新一轮的交互。再利用重新排序模型(reranking model)对文档再次进行打分，过滤出最不相关的文档。全局控制器(global controller)检查剩余文档是否足以回答问题，并据此决定是否继续检索循环。检索完成后，将维护好的高质量的文档清单送入阅读器模块，进行答案跨度抽取。</p><p>检索方式和效果比较：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210302200427.png" alt="image-20210302200420421" style="zoom:50%;" /></p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210302200608.png" alt="image-20210302200608508"></p><p>​        该系统由动态文件重新排序(DDR)阶段和回答问题阶段组成。给定一个多跳问题，DDR迭代检索、重新排序和过滤文档，并自适应地决定何时停止检索过程。在初始检索后，DDR会将提取的文本跨度作为新的查询更新问题，以在每次迭代时检索更多的文档。检索完成后，最后得分最高的文档会被送入下游的阅读器模块进行答案提取。</p><h3 id="Graph-based-Reranking-Model"><a href="#Graph-based-Reranking-Model" class="headerlink" title="Graph-based Reranking Model"></a>Graph-based Reranking Model</h3><blockquote><p>用于精确识别文档图中的支持文档。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210303192902.png" alt="image-20210303192902322"></p><h4 id="Contextual-Encoding"><a href="#Contextual-Encoding" class="headerlink" title="Contextual Encoding"></a>Contextual Encoding</h4><p>输入到pre-trained language model的格式：</p><script type="math/tex; mode=display">I_{q,d_k}= {[CLS] }q_1. . . q_{|q|}{[SEP]} t^{(k)}_1{. . . }t^{(k)}_{|dk|}{[SEP]}</script><blockquote><p>$| q |$ 和$| dk |$ 表示问题q和文档$d_k$中的token数量。</p></blockquote><h4 id="Graph-Attention"><a href="#Graph-Attention" class="headerlink" title="Graph Attention"></a>Graph Attention</h4><ul><li>Graph Attention Network (GAT)</li></ul><p>采用图注意力网络来传播文档图谱上的信息，如果两个文档有共享实体，那么它们就会被连接起来。</p><h4 id="Multi-document-Fusion"><a href="#Multi-document-Fusion" class="headerlink" title="Multi-document Fusion"></a>Multi-document Fusion</h4><p>为了进一步将信息传播到non-entity tokens，首先将每个entity toke的嵌入融合为:</p><script type="math/tex; mode=display">\hat t^{(i)}_j= W_3[t^{(i)}_j; g_i^{(T)})]</script><p>$\hat v$被输入到Transformer层进行多文档融合，该层更新所有token的表示并输出融合的表示向量$\tilde{v}$。</p><h4 id="Document-Filter-and-Global-Controller"><a href="#Document-Filter-and-Global-Controller" class="headerlink" title="Document Filter and Global Controller"></a>Document Filter and Global Controller</h4><p>​        对于每个文档，使用$\tilde{v}$中的[CLS] token嵌入作为文档表示，将其送入二进制分类器中，对文档的支持级别进行评分。选择得分最高的前K个文档，其余文档进行筛选。如果正向段数小于超参数阈值S，全局控制器发出信号，继续检索过程。</p><h3 id="Reader-Module"><a href="#Reader-Module" class="headerlink" title="Reader Module"></a>Reader Module</h3><p>将问题q的tokens和最终排名前K的重新排序的文档进行串联，反馈到阅读器模块。</p><p>寻找找到最佳候选答案跨度：</p><script type="math/tex; mode=display">arg\ max \underset{i,j, i≤j}P^{start}_iP^{end}_j</script><p>$P^{start}_iP^{end}_j$表示第i和第j个token在串联文本中的开始和结束位置的概率，即答案跨度。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p><strong>HotpotQA full wiki setting</strong></p><p>该数据集由113K个众包多跳问题组成，这些问题需要维基百科的介绍段落来回答。每个训练用的问题都带有两个由人工注释的黄金支持段落。</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>实验结果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210304092847.png" alt="image-20210304092847547"></p><p>提出的reranking model在Dev和Test数据集上都表现出了最佳的效果，Paragraph效果提升最为显著。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><ul><li><p>禁用Iterative Reranking, Graph-based Reranking and Question Updater模块，段落重排序和QA性能下降较为明显。</p></li><li><p>QA性能在bridge questions下降比comparison questions更显著。</p></li></ul><p>本文提出的DDRQA，是一个开放领域的多跳QA系统，它可以从一个大型语料库中准确定位支持文档。DDRQA通过基于图的重排序模型对文档进行迭代检索、重排序和过滤，并在HotpotQA full wiki设置上显著优于之前的方法。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> hotpot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>scp自动填充密码shell脚本</title>
      <link href="/2021/03/03/scp%E8%87%AA%E5%8A%A8%E5%A1%AB%E5%85%85%E5%AF%86%E7%A0%81shell%E8%84%9A%E6%9C%AC/"/>
      <url>/2021/03/03/scp%E8%87%AA%E5%8A%A8%E5%A1%AB%E5%85%85%E5%AF%86%E7%A0%81shell%E8%84%9A%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<h1 id="scp自动填充密码shell脚本"><a href="#scp自动填充密码shell脚本" class="headerlink" title="scp自动填充密码shell脚本"></a>scp自动填充密码shell脚本</h1><h2 id="安装expect"><a href="#安装expect" class="headerlink" title="安装expect"></a>安装expect</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install ecpect</span><br></pre></td></tr></table></figure><h2 id="编写脚本mq-scp-sh"><a href="#编写脚本mq-scp-sh" class="headerlink" title="编写脚本mq_scp.sh"></a>编写脚本mq_scp.sh</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/expect</span><br><span class="line">#*************************************************************************</span><br><span class="line">#        ./mq_scp.sh 目标上传文件</span><br><span class="line">#*************************************************************************</span><br><span class="line">set timeout 30</span><br><span class="line">set user root</span><br><span class="line">set pass 12398qq.</span><br><span class="line">set dir /root/mq_blog/source/_posts</span><br><span class="line">set ip 39.96.68.13</span><br><span class="line">set filen [lrange $argv 0 0] </span><br><span class="line"># [lrange $argv 0 0] 0 0表示第一个参数 </span><br><span class="line"></span><br><span class="line">spawn scp $&#123;filen&#125; $&#123;user&#125;@$&#123;ip&#125;:$&#123;dir&#125;</span><br><span class="line">expect &quot;$&#123;user&#125;@$&#123;ip&#125;&#x27;s password:&quot;</span><br><span class="line">send &quot;$&#123;pass&#125;\r&quot;</span><br><span class="line">interact</span><br></pre></td></tr></table></figure><h2 id="软连接到环境变量目录"><a href="#软连接到环境变量目录" class="headerlink" title="软连接到环境变量目录"></a>软连接到环境变量目录</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /home/maqi/blog/test/mq_scp.sh /usr/local/bin/mq_scp</span><br></pre></td></tr></table></figure><p>之后任意终端输入<code>mq_scp 目标上传文件</code>即可。</p><h2 id="except介绍"><a href="#except介绍" class="headerlink" title="except介绍"></a>except介绍</h2><ul><li><h1 id="usr-bin-expect"><a href="#usr-bin-expect" class="headerlink" title="!/usr/bin/expect"></a>!/usr/bin/expect</h1><p>告诉操作系统脚本里的代码使用那一个shell来执行。这里的expect其实和linux下的bash、windows下的cmd是一类东西。</p></li><li><p>set timeout 30</p><p>设置超时时间。</p></li><li><p>spawn</p><p>spawn是进入expect环境后才可以执行的expect内部命令，主要的功能是给ssh运行进程加个壳，用来传递交互指令。</p></li><li><p>expect “password:”<br>这里的expect也是expect的一个内部命令。这个命令的意思是判断上次输出结果里是否包含“password:”的字符串，如果有则立即返回，否则就等待一段时间后返回，这里等待时长就是前面设置的30秒。</p></li><li><p>send “${pass}\r”<br>执行交互动作，与手工输入密码的动作等效。</p><p><strong>命令字符串结尾别忘记加上“\r”。</strong></p></li><li><p>interact</p><p>执行完成后保持交互状态，把控制权交给控制台，这个时候就可以手工操作了，如果没有这一句登录完成后会退出。</p></li></ul><h2 id="编写脚本同步博客"><a href="#编写脚本同步博客" class="headerlink" title="编写脚本同步博客"></a>编写脚本同步博客</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/expect</span><br><span class="line">#*************************************************************************</span><br><span class="line">#        ./mq_sync_blog.sh 目标上传文件</span><br><span class="line">#*************************************************************************</span><br><span class="line">set timeout 30</span><br><span class="line">set user root</span><br><span class="line">set pass 12398qq.</span><br><span class="line">set ip 39.96.68.13</span><br><span class="line"></span><br><span class="line">spawn ssh $&#123;user&#125;@$&#123;ip&#125;</span><br><span class="line">expect &quot;$&#123;user&#125;@$&#123;ip&#125;&#x27;s password:&quot;</span><br><span class="line">send &quot;$&#123;pass&#125;\r&quot;</span><br><span class="line">expect &quot;#&quot;</span><br><span class="line">send &quot;cd /root/mq_blog\r&quot;</span><br><span class="line">expect &quot;#&quot;</span><br><span class="line">send &quot;./quick_push\r&quot;</span><br><span class="line"></span><br><span class="line">expect &quot;#&quot;</span><br><span class="line">send &quot;cd /root/fluid_blog\r&quot;</span><br><span class="line">expect &quot;#&quot;</span><br><span class="line">send &quot;./quick_push\r&quot;</span><br><span class="line">interact</span><br><span class="line">#expect eof</span><br></pre></td></tr></table></figure><h2 id="软连接到环境变量目录-1"><a href="#软连接到环境变量目录-1" class="headerlink" title="软连接到环境变量目录"></a>软连接到环境变量目录</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /home/maqi/blog/test/mq_sync_blog.sh /usr/local/bin/mq_sync_blog</span><br></pre></td></tr></table></figure><p>之后任意终端输入<code>mq_sync_blog</code>即可。</p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> shell </tag>
            
            <tag> except </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PID参数调节</title>
      <link href="/2021/03/01/PID%E5%8F%82%E6%95%B0%E8%B0%83%E8%8A%82/"/>
      <url>/2021/03/01/PID%E5%8F%82%E6%95%B0%E8%B0%83%E8%8A%82/</url>
      
        <content type="html"><![CDATA[<h1 id="PID参数调节"><a href="#PID参数调节" class="headerlink" title="PID参数调节"></a>PID参数调节</h1><p>最优参数：</p><ul><li>x100：34 15 18</li><li>x80：26 17 2</li></ul><h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><p>control_keyboard.cpp</p><p>KP KI KP 通过键盘按键动态调节</p><p>加1：I O P</p><p>减1：J K L</p><h2 id="调节方法"><a href="#调节方法" class="headerlink" title="调节方法"></a>调节方法</h2><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><ul><li>先调P，从小到大调节P使曲线震荡稳定。</li><li>调节I使得曲线偏离目标值最小</li><li>调节Ｄ使震荡稳定，震荡频率降低。</li></ul><p>注意：</p><blockquote><p>空载时表现较好的参数在负载或速度较大时可能会出现运行时噪音较大的问题，需要综合考虑。</p></blockquote><ol><li>先调P，从小到大调节P使曲线震荡稳定。</li></ol><p>P=15</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226102521631.png" alt="image-20210226102521631"></p><p>p=34</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226170551440.png" alt="image-20210226170551440"></p><p>P=42</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226102401389.png" alt=""></p><p>kp=34和kp=42效果接近，但kp=42噪音较大。</p><ol><li>调节I使得曲线偏离目标值最小</li></ol><p>p=34 i=5</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226170959661.png" alt="image-20210226170959661"></p><p>P=34 I=15</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226171135272.png" alt="image-20210226171135272"></p><p>P=34 I=20</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226171548299.png" alt="image-20210226171548299"></p><ol><li>调节d使震荡稳定，震荡频率降低。</li></ol><p><strong>空载：</strong></p><p>34 12 13</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226172623763.png" alt="image-20210226172623763"></p><p>34 12 0</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226172858816.png" alt="image-20210226172858816"></p><p>34 15 16</p><p><img src="../.config/Typora/typora-user-images/image-20210226165509225.png" alt="image-20210226165509225"></p><p>34 15 18 </p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226165933457.png" alt="image-20210226165933457"></p><p>根据震荡频率和幅度选择参数kp=34,ki=15,kd=18</p><p><strong>负载：</strong></p><p>34 12 13</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226174907240.png" alt="image-20210226174907240"></p><p>34 12 0</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226174729477.png" alt="image-20210226174729477"></p><p>34 15 18</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210226173434718.png" alt="image-20210226173434718"></p><ul><li>34 15 18 *</li><li>35 14 15</li><li>34 15 17</li><li>34 15 16</li></ul><h2 id="跟踪曲线"><a href="#跟踪曲线" class="headerlink" title="跟踪曲线"></a>跟踪曲线</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export LCM_DEFAULT_URL=udpm://239.255.76.67:7666</span><br><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/app/lib</span><br></pre></td></tr></table></figure><p>34 14 0</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302104113288.png" alt="image-20210302104113288"></p><p>34 15 18</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302101225620.png" alt="image-20210302101225620"></p><p>35 14 15</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302104322620.png" alt="image-20210302104322620"></p><p>34 15 17</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302103526539.png" alt="image-20210302103526539"></p><p>34 15 16</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302103845153.png" alt="image-20210302103845153"></p><p>34 16 2</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302110527330.png" alt="image-20210302110527330"></p><p>34 16 12</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302110851191.png" alt="image-20210302110851191"></p><p>34 16 18</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302111233819.png" alt="image-20210302111233819"></p><p>34 16 15</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/linux/image-20210302111638689.png" alt="image-20210302111638689"></p>]]></content>
      
      
      <categories>
          
          <category> 硬件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch常用操作</title>
      <link href="/2021/03/01/PyTorch%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
      <url>/2021/03/01/PyTorch%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorch常用操作"><a href="#PyTorch常用操作" class="headerlink" title="PyTorch常用操作"></a>PyTorch常用操作</h1><h2 id="指定GPU"><a href="#指定GPU" class="headerlink" title="指定GPU"></a>指定GPU</h2><ul><li>终端指定</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 nohup python demo.py &gt;&gt; base_log.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><ul><li>程序指定</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">int id = &#123;0-max_gpu_num&#125;</span><br><span class="line">torch.cuda.set_device(id)</span><br></pre></td></tr></table></figure><h2 id="检测GPU是否可用"><a href="#检测GPU是否可用" class="headerlink" title="检测GPU是否可用"></a>检测GPU是否可用</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import torch </span><br><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Typora+PicGo-core 实现图片自动上传</title>
      <link href="/2021/03/01/Typora+PicGo-core%20%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%89%87%E8%87%AA%E5%8A%A8%E4%B8%8A%E4%BC%A0/"/>
      <url>/2021/03/01/Typora+PicGo-core%20%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%89%87%E8%87%AA%E5%8A%A8%E4%B8%8A%E4%BC%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="Typora-PicGo-core-实现图片自动上传"><a href="#Typora-PicGo-core-实现图片自动上传" class="headerlink" title="Typora+PicGo-core 实现图片自动上传"></a>Typora+PicGo-core 实现图片自动上传</h1><h2 id="在Typora中安装PicGo-core"><a href="#在Typora中安装PicGo-core" class="headerlink" title="在Typora中安装PicGo-core"></a>在Typora中安装PicGo-core</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/linux/image-20210301151027421.png" alt="image-20210301151027421"></p><h2 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h2><ol><li><p>找到PicGo安装路径</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/maqi/.config/Typora/picgo/linux/picgo</span><br></pre></td></tr></table></figure></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/linux/image-20210301151218251.png" alt="image-20210301151218251"></p></li><li><p>安装插件</p><blockquote><p>gitee-uploader即可</p></blockquote></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.\picgo install smms-user</span><br><span class="line">.\picgo install gitee-uploader</span><br><span class="line">.\picgo install github-plus</span><br></pre></td></tr></table></figure><ol><li>修改配置文件</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;picBed&quot;: &#123;</span><br><span class="line">    &quot;current&quot;: &quot;gitee&quot;,</span><br><span class="line">    &quot;uploader&quot;: &quot;gitee&quot;,</span><br><span class="line">    &quot;githubPlus&quot;: &#123;</span><br><span class="line">      &quot;branch&quot;: &quot;master&quot;,</span><br><span class="line">      &quot;customUrl&quot;: &quot;https://cdn.jsdelivr.net/gh/用户名/项目名&quot;,</span><br><span class="line">      &quot;path&quot;: &quot;img/&quot;,</span><br><span class="line">      &quot;repo&quot;: &quot;github用户名/github仓库名&quot;,</span><br><span class="line">      &quot;token&quot;: &quot;自己的token&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;gitee&quot;: &#123;</span><br><span class="line">      &quot;customUrl&quot;: &quot;&quot;,</span><br><span class="line">      &quot;repo&quot;: &quot;Asimok/picgo&quot;,</span><br><span class="line">      &quot;branch&quot;: &quot;master&quot;,</span><br><span class="line">      &quot;token&quot;: &quot;ae27b6635e613294f7131c20669d940d&quot;,</span><br><span class="line">      &quot;path&quot;: &quot;img/linux&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;smms-user&quot;: &#123;</span><br><span class="line">      &quot;Authorization&quot;: &quot;替换成你自己的token&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;transformer&quot;: &quot;path&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;picgoPlugins&quot;: &#123;</span><br><span class="line">    &quot;picgo-plugin-gitee-uploader&quot;: true,</span><br><span class="line">    &quot;picgo-plugin-smms-user&quot;: true,</span><br><span class="line">    &quot;picgo-plugin-github-plus&quot;: true</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;picgo-plugin-gitee-uploader&quot;: &#123;</span><br><span class="line">    &quot;lastSync&quot;: &quot;2021-03-01 03:12:33&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;picgo-plugin-github-plus&quot;: &#123;</span><br><span class="line">    &quot;lastSync&quot;: &quot;2020-04-07 11:09:08&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>验证即可</li></ol>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gitee </tag>
            
            <tag> PicGo </tag>
            
            <tag> Typora </tag>
            
            <tag> 图床 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git常用操作</title>
      <link href="/2021/03/01/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
      <url>/2021/03/01/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="git常用操作"><a href="#git常用操作" class="headerlink" title="git常用操作"></a>git常用操作</h1><h2 id="克隆指定分支"><a href="#克隆指定分支" class="headerlink" title="克隆指定分支"></a>克隆指定分支</h2><ul><li>-b</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone -b 分支名 git 地址</span><br></pre></td></tr></table></figure><h2 id="查看远程分支"><a href="#查看远程分支" class="headerlink" title="查看远程分支"></a>查看远程分支</h2><p><strong>查看远程分支</strong></p><ul><li>-r</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -r</span><br></pre></td></tr></table></figure><p><strong>查看远程和本地所有分支</strong></p><ul><li>-a</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -a</span><br></pre></td></tr></table></figure><p><strong>查看本地分支</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure><h2 id="拉取远程分支并创建本地分支"><a href="#拉取远程分支并创建本地分支" class="headerlink" title="拉取远程分支并创建本地分支"></a>拉取远程分支并创建本地分支</h2><ul><li>-b</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b 本地分支名 orign/远程分支名</span><br></pre></td></tr></table></figure><ul><li>fetch</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git fetch orign 远程分支名:本地分支名</span><br></pre></td></tr></table></figure><blockquote><p>checkout会自动切换到新创建的分支，fetch不会。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux top 命令详解</title>
      <link href="/2021/03/01/linux%20top%20%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
      <url>/2021/03/01/linux%20top%20%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="linux-top-命令详解"><a href="#linux-top-命令详解" class="headerlink" title="linux top 命令详解"></a>linux top 命令详解</h1><blockquote><p>top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/linux/image-20210127170328319.png" alt="image-20210127170328319"></p><h2 id="参数"><a href="#参数" class="headerlink" title="　参数"></a>　参数</h2><ul><li>cpu<ul><li>usr：用户空间cpu占用率</li><li>sys：系统内核cpu占用率</li><li>nic：改变过优先级的进程占用CPU的百分比</li><li>idle：空闲CPU百分比</li><li>io：IO等待占用CPU的百分比</li><li>irq： 硬中断占用CPU的百分比</li><li>sirq： 软中断占用CPU的百分比</li><li>Load average：负载均衡，1分钟、5分钟、15分钟的负载情况。</li></ul></li></ul><h2 id="htop"><a href="#htop" class="headerlink" title="htop"></a>htop</h2>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> top </tag>
            
            <tag> htop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Asking Complex Questions with Multi-hop Answer-focused Reasoning</title>
      <link href="/2021/02/27/Asking%20Complex%20Questions%20with%20Multi-hop%20Answer-focused%20Reasoning/"/>
      <url>/2021/02/27/Asking%20Complex%20Questions%20with%20Multi-hop%20Answer-focused%20Reasoning/</url>
      
        <content type="html"><![CDATA[<h1 id="Asking-Complex-Questions-with-Multi-hop-Answer-focused-Reasoning"><a href="#Asking-Complex-Questions-with-Multi-hop-Answer-focused-Reasoning" class="headerlink" title="Asking Complex Questions with Multi-hop Answer-focused Reasoning"></a>Asking Complex Questions with Multi-hop Answer-focused Reasoning</h1><blockquote><p>论文：<a href="https://arxiv.org/abs/2009.07402">Asking Complex Questions with Multi-hop Answer-focused Reasoning</a></p><p>代码：<a href="https://github.com/Shawn617/Multi-hop-NQG">https://github.com/Shawn617/Multi-hop-NQG</a></p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p><strong>multihop question generation</strong></p><p>大多数先进的方法都集中在涉及单跳关系的简单问题的提问上，本文提出了一种名为多跳问题生成的新任务，通过额外发现和建模给定文档集合和相应答案的多个实体及其语义关系来提出复杂的和语义相关的问题。</p><p>示例：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210225085024.png" alt="image-20210225085017189" style="zoom:50%;" /></p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p><strong>multi-hop answer-focused reasoning model</strong></p><p>本文提出了在以答案为中心的实体图上进行以答案为中心的多跳推理，以包括不同粒度级别的语义信息，包括实体的词级和文档级语义及其语义关系。</p><p>通过提取文档中各个实体之间不同类型的语义关系来构建以答案为中心(<strong>answer-centric entity graph</strong>)的实体图，从而实现多跳推理。</p><h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><p>(i) answer-focused document encoding.</p><p>(ii) multi-hop answer-centric reasoning.</p><p>(iii) aggregation layer, finally providing an answer-focused and enriched contextual representation.</p><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210225192912.png" alt="image-20210225192912200"></p><h3 id="Answer-focused-Document-Encoding"><a href="#Answer-focused-Document-Encoding" class="headerlink" title="Answer-focused Document Encoding"></a>Answer-focused Document Encoding</h3><blockquote><p>以答案为中心的文档编码</p></blockquote><h4 id="Document-Encoding"><a href="#Document-Encoding" class="headerlink" title="Document Encoding"></a>Document Encoding</h4><p>级联文本和标题</p><script type="math/tex; mode=display">X =\{X_0^{text}, X_0^{title}, ..., X_I^{text}, X_I^{title}\}</script><p>one-layer bi-directional LSTM作为encoder获得文档表示。</p><script type="math/tex; mode=display">H = [h_1, h_2, ..., h_m]\in R^{M∗D}</script><script type="math/tex; mode=display">h_i= LSTM_{enc}(x_i, h_{i−1})</script><h4 id="Gated-Self-attention-Layer"><a href="#Gated-Self-attention-Layer" class="headerlink" title="Gated Self-attention Layer"></a>Gated Self-attention Layer</h4><p>文档表示对上下文表示有局限，利用gated selfattention layer和Bi-GRU学习上下文表示$h_i$。</p><script type="math/tex; mode=display">\hat h_i= Bi-GRU(\hat h^D_{i-1}, [h_i, o_i])</script><p>$v_i$是通过上下文获得的向量：</p><script type="math/tex; mode=display">d^i_j= W_d^Ttanh(W^{'}_vh_j+ W_vh_i)</script><script type="math/tex; mode=display">a^i_k= exp(d^i_k)/\sum^n_{j=1}exp(d^i_j)</script><script type="math/tex; mode=display">o_i= \sum ^n _{k=1}a^i_kh_k</script><blockquote><p>$W_d, W_v,W^{‘}_v$是可训练的权重。</p></blockquote><h4 id="Answer-Gating-Mechanism"><a href="#Answer-Gating-Mechanism" class="headerlink" title="Answer Gating Mechanism"></a>Answer Gating Mechanism</h4><p>授权模型学习以答案为中心的文档表示形式。</p><script type="math/tex; mode=display">H^a= \{\hat h^a_i\}^M_{i=1}</script><p>将上层gate的计算结果通过sigmoid函数过滤，仅将文档的与答案相关的语义信息转发给下游多跳推理 。</p><script type="math/tex; mode=display">h^a_i= σ(aW_a\hat h_i) ∗ \hat h_i</script><blockquote><p>$a$：第一个答案词的隐藏状态。</p><p>$W_a$：是可训练权重。</p></blockquote><h3 id="Multi-hop-Answer-focused-Reasoning-Answer-centric-Entity-Graph-Grounding"><a href="#Multi-hop-Answer-focused-Reasoning-Answer-centric-Entity-Graph-Grounding" class="headerlink" title="Multi-hop Answer-focused Reasoning Answer-centric Entity Graph Grounding"></a>Multi-hop Answer-focused Reasoning Answer-centric Entity Graph Grounding</h3><p>以答案为中心的实体图表示为：$G = {V, E}$</p><blockquote><p>$V$：表示不同级别的实体节点。</p><p>E：表示带有不同语义关系的节点之间的边。</p></blockquote><p>将完全匹配的不停词，命名实体，答案和标题视为节点。</p><p>上下文表示的不同粒度级别：</p><ul><li>完全匹配的不停词和实体节点对特定文档上下文中的单词级别和本地表示进行编码。</li><li>标题节点代表文档级语义。</li><li>答案节点提供图推理的答案感知表示，并跨文档建模全局表示。</li></ul><p>节点之间边的定义：</p><ul><li>将所有完全匹配的命名实体连接在一起，无论它们在同一文档中还是在不同文档中。</li><li>将所有文档间和文档内完全匹配的不停词（例如“歌手，词曲作者”）连接起来。</li><li>将所有共指词相互链接。</li><li>将标题节点与同一文档中的所有实体节点连接起来。</li><li>在所有标题节点之间添加密集连接。</li><li>答案节点连接到图中的所有其他节点，从而形成一个以答案为中心的实体图。</li></ul><p>示例：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210225201957.png" alt="image-20210225201957327" style="zoom:50%;" /></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210225201936.png" alt="image-20210225201936243" style="zoom:50%;" /></p><h3 id="Multi-hop-Reasoning-with-RGCN"><a href="#Multi-hop-Reasoning-with-RGCN" class="headerlink" title="Multi-hop Reasoning with RGCN"></a>Multi-hop Reasoning with RGCN</h3><p>使用GNN-based model进行多跳推理。——<strong>RGCN</strong></p><p>经过L层推理后，最多可以捕获到L跳关系。</p><h2 id="Aggregation-Layer"><a href="#Aggregation-Layer" class="headerlink" title="Aggregation Layer"></a>Aggregation Layer</h2><p>通过使用可训练的layer-wise权重选择性地汇总每个RGCN层的输出和答案感知文档表示生成来计算最终的答案感知上下文表示。</p><p>每层的答案节点表示形式和LSTM的最后一个隐藏状态堆叠在一起，以产生更准确的文档级和全局表示形式。</p><h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p>将隐藏状态初始化为$s_0 = z$时，将单向LSTM用作解码器以生成问题，在给定先前生成的单词和先前隐藏状态的情况下，更新当前隐藏状态。</p><script type="math/tex; mode=display">s_t= LSTM_{Dec}([w_t; c_{t−1}], s_{t−1})</script><p>解决词汇量不足的问题：</p><p>在encoder的每个步骤中，计算概率，从而决定基于注意力矩阵从输入文档中复制单词，或通过具有softmax功能的输出层从词汇表生成单词。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>HOTPOTQA</p><p>丢弃“comparison”类型的问题，并且仅收集文档集中标有“supporting facts”的文本。 由于缺乏对原始testing dataset的访问权限，将training set和development set结合在一起，并将它们随机分为training set,development set,testing dataset。</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>实验结果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210226193222.png" alt="image-20210226193222793"></p><p>本文提出的以多跳回答为重点的推理模型比基线获得更高的分数，因为它在利用以回答为中心的实体图上的基础上使用不同的回答感知上下文实体表示形式和实体之间的语义关系的粒度级别，从而对解码器产生了精确而丰富的语义。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210226194739.png" alt="image-20210226194739677" style="zoom:50%;" /></p><p>DecompRC模型使用本文模型生成的问题，取得了除人工提出的问题外最佳效果。</p><blockquote><p>DecompRC在不同生成问题上的性能直观地反映了生成问题的质量和模型的多跳推理能力。</p></blockquote><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>以答案为中心的多跳推理模型的设计是利用它们之间的各种语义关系来发现和捕获与答案有关的实体。</p><p>本文通过发现和建模文档中的多个实体及其语义关系，对给定文档集合和相应答案的复杂问题进行询问。 为了解决该问题，本文通过利用以自然语言文本构建的以答案为中心的实体图中的语义信息的不同粒度级别，提出了针对答案的多跳推理。 实验结果证明在机器评估和人工评估方面都取得优秀的结果。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> hotpot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tag-based-multi-span-extraction</title>
      <link href="/2021/02/19/tag-based-multi-span-extraction/"/>
      <url>/2021/02/19/tag-based-multi-span-extraction/</url>
      
        <content type="html"><![CDATA[<h1 id="tag-based-multi-span-extraction"><a href="#tag-based-multi-span-extraction" class="headerlink" title="tag-based-multi-span-extraction"></a>tag-based-multi-span-extraction</h1><blockquote><p><a href="https://github.com/eladsegal/tag-based-multi-span-extraction">代码：https://github.com/eladsegal/tag-based-multi-span-extraction</a></p><p><a href="https://arxiv.org/abs/1909.13375">论文：A Simple and Effective Model for Answering Multi-span Questions</a></p></blockquote><ul><li>配置环境变量添加代理</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r zhaoxiaofeng@219.216.64.175:~/.proxychains ./</span><br></pre></td></tr></table></figure><p>修改~/.bashrc，在末尾添加指令别名</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alias proxy=/data0/zhaoxiaofeng/usr/bin/proxychains4 # 77, 175, 206只添加这条 </span><br><span class="line">alias aliasproxy=/home/zhaoxiaofeng/usr/bin/proxychains4 # 154只添加这条</span><br></pre></td></tr></table></figure><ul><li>下载代码：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/eladsegal/tag-based-multi-span-extraction</span><br></pre></td></tr></table></figure><ul><li>配置环境</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">proxy conda create -n allennlp python=3.6.9</span><br><span class="line">proxy pip install -r requirements.txt</span><br><span class="line">proxy conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch</span><br><span class="line">pip install en_core_web_sm-2.1.0.tar.gz</span><br><span class="line">加载本地预训练模型（参考 预训练模型——替换为本地文件）</span><br></pre></td></tr></table></figure><ul><li><p>训练模型</p><blockquote><p>可以使用nohup + &amp;在后台训练</p><p>tail -f nohup.txt 可以实时查看日志</p><p>nohup command &gt;&gt; nohup.out 2&gt;&amp;1 &amp;</p><ul><li>2&gt;&amp;1的意思是将标准错误(2)也定向到标准输出(1)的输出文件中。</li></ul></blockquote></li></ul><p><strong>RoBERTa TASE_IO + SSE</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp train configs/drop/roberta/drop_roberta_large_TASE_IO_SSE.jsonnet -s training_directory -f --include-package src</span><br></pre></td></tr></table></figure><p>服务器运行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup allennlp train configs/drop/roberta/drop_roberta_large_TASE_IO_SSE.jsonnet -s training_directory_base -f --include-package src &gt;&gt; base_log.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>或：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp train download_data/config.json -s training_directory --include-package src</span><br></pre></td></tr></table></figure><p><strong>Bert_large TASE_BIO + SSE</strong></p><blockquote><p>-f ：可以清空训练数据文件夹，重新训练</p><p>-r：可以从之前的训练状态恢复</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp train configs/drop/bert/drop_bert_large_TASE_BIO_SSE.jsonnet -s training_directory_bert -f --include-package src</span><br></pre></td></tr></table></figure><p>服务器运行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup allennlp train configs/drop/bert/drop_bert_large_TASE_BIO_SSE.jsonnet -s training_directory_bert -f --include-package src &gt;&gt; bertlog.out 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><ul><li><p>预测模型</p><blockquote><p>cuda-device 只能使用一个GPU</p><p>后文详细介绍</p></blockquote></li><li><p>评估模型</p><blockquote><p>后文详细介绍</p></blockquote></li></ul><h2 id="预训练模型——替换为本地文件"><a href="#预训练模型——替换为本地文件" class="headerlink" title="预训练模型——替换为本地文件"></a>预训练模型——替换为本地文件</h2><p><strong>定位技巧：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find 路径 | grep -ri  “字符串” -l</span><br></pre></td></tr></table></figure><p>下载文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt</span><br></pre></td></tr></table></figure><p><strong>快速下载文件技巧：</strong></p><blockquote><p>由于python中无法执行proxy，报错<code>sh: 1: proxy: not found</code>只能通过手动方式进行，故编写如下脚本，实现命令生成，打印，复制打印的内容并执行可实现批量下载。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">BERT_PRETRAINED_MODEL_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;bert-base-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-cased-pytorch_model.bin&quot;</span><br><span class="line">&#125;</span><br><span class="line">for url in BERT_PRETRAINED_MODEL_ARCHIVE_MAP.values():</span><br><span class="line">    urls= &#x27;proxy wget &#x27;+url</span><br><span class="line">    print(urls)</span><br></pre></td></tr></table></figure><p>执行结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json</span><br><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json</span><br><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json</span><br><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json</span><br><span class="line">proxy wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json</span><br></pre></td></tr></table></figure><p>涉及文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_roberta.py</span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_roberta.py</span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_roberta.py</span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_utils.py </span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_bert.py</span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_bert.py</span><br><span class="line"></span><br><span class="line">/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_bert.py</span><br></pre></td></tr></table></figure><ul><li>各服务器路径</li></ul><div class="table-container"><table><thead><tr><th>服务器</th><th>路径</th></tr></thead><tbody><tr><td>202.199.6.77</td><td>/data0/maqi</td></tr><tr><td>219.216.64.206</td><td>/data0/maqi</td></tr><tr><td>219.216.64.175</td><td></td></tr><tr><td>219.216.64.154</td></tr></tbody></table></div><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_roberta.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_roberta.py</span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_roberta.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_roberta.py </span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_roberta.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_roberta.py </span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_utils.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_utils.py</span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_bert.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_bert.py</span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_bert.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_bert.py</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scp  /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_bert.py  maqi@202.199.6.77:/data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_bert.py</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>tokenization_roberta.py</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/tokenization_roberta.py</span><br></pre></td></tr></table></figure><p>原始：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_VOCAB_FILES_MAP = &#123;</span><br><span class="line">    &#x27;vocab_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;roberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large-mnli&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-vocab.json&quot;,</span><br><span class="line">        &#x27;distilroberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-base-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#x27;merges_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;roberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large-mnli&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-merges.txt&quot;,</span><br><span class="line">        &#x27;distilroberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-base-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>替换：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_VOCAB_FILES_MAP = &#123;</span><br><span class="line">    &#x27;vocab_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;roberta-base&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large-mnli&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-mnli-vocab.json&quot;,</span><br><span class="line">        &#x27;distilroberta-base&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/distilroberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-base-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-base-vocab.json&quot;,</span><br><span class="line">        &#x27;roberta-large-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-vocab.json&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#x27;merges_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;roberta-base&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large-mnli&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-mnli-merges.txt&quot;,</span><br><span class="line">        &#x27;distilroberta-base&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/distilroberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-base-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-base-merges.txt&quot;,</span><br><span class="line">        &#x27;roberta-large-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_roberta/roberta-large-merges.txt&quot;,</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>modeling_roberta.py</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_roberta.py</span><br></pre></td></tr></table></figure><p>原始：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;roberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large-mnli&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;distilroberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-base-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-openai-detector-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-openai-detector-pytorch_model.bin&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>替换：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;roberta-base&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/roberta-base-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/roberta-large-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large-mnli&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/roberta-large-mnli-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;distilroberta-base&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/distilroberta-base-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-base-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/roberta-base-openai-detector-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;roberta-large-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/modeling_roberta/roberta-large-openai-detector-pytorch_model.bin&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>configuration_roberta.py</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_roberta.py</span><br></pre></td></tr></table></figure><p>原始：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;roberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large-mnli&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-config.json&quot;,</span><br><span class="line">    &#x27;distilroberta-base&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-config.json&quot;,</span><br><span class="line">    &#x27;roberta-base-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-openai-detector-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large-openai-detector&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-openai-detector-config.json&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>替换：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;roberta-base&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/roberta-base-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/roberta-large-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large-mnli&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/roberta-large-mnli-config.json&quot;,</span><br><span class="line">    &#x27;distilroberta-base&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/distilroberta-base-config.json&quot;,</span><br><span class="line">    &#x27;roberta-base-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/roberta-base-openai-detector-config.json&quot;,</span><br><span class="line">    &#x27;roberta-large-openai-detector&#x27;: &quot;/data0/maqi/pretrained_model/configuration_roberta/roberta-large-openai-detector-config.json&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>tokenization_bert.py</li></ul><p>原始：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_VOCAB_FILES_MAP = &#123;</span><br><span class="line">    &#x27;vocab_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;bert-base-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-multilingual-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-multilingual-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-chinese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-cased&#x27;: &quot;https://int-deepset-models-bert.s3.eu-central-1.amazonaws.com/pytorch/bert-base-german-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-finnish-cased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-uncased-v1/vocab.txt&quot;,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>替换：</p><blockquote><p>本地文件路径：/data0/maqi/pretrained_model/tokenization_bert</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_VOCAB_FILES_MAP = &#123;</span><br><span class="line">    &#x27;vocab_file&#x27;:</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;bert-base-uncased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-large-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-cased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-multilingual-uncased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-multilingual-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-multilingual-cased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-multilingual-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-chinese&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-chinese-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-cased&#x27;: &quot;https://int-deepset-models-bert.s3.eu-central-1.amazonaws.com/pytorch/bert-base-german-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-large-uncased-whole-word-masking-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-large-cased-whole-word-masking-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-large-uncased-whole-word-masking-finetuned-squad-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-large-cased-whole-word-masking-finetuned-squad-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-cased-finetuned-mrpc-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-german-dbmdz-cased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/bert-base-german-dbmdz-uncased-vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-finnish-cased-v1&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/TurkuNLP/bert-base-finnish-cased-v1/vocab.txt&quot;,</span><br><span class="line">        &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;/data0/maqi/pretrained_model/tokenization_bert/TurkuNLP/bert-base-finnish-uncased-v1/vocab.txt&quot;,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>configuration_bert.py</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/configuration_bert.py</span><br></pre></td></tr></table></figure><p>原始：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">BERT_PRETRAINED_CONFIG_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;bert-base-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-chinese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-cased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/config.json&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-uncased-v1/config.json&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>替换：</p><blockquote><p>本地文件：/data0/maqi/pretrained_model/configuration_bert</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">BERT_PRETRAINED_CONFIG_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;bert-base-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-chinese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-config.json&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-config.json&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-cased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/config.json&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-uncased-v1/config.json&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>modeling_bert.py</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /data0/maqi/.conda/envs/allennlp/lib/python3.6/site-packages/transformers/modeling_bert.py</span><br></pre></td></tr></table></figure><p>原始：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">BERT_PRETRAINED_MODEL_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;bert-base-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-chinese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char-whole-word-masking&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-cased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-uncased-v1/pytorch_model.bin&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>替换：</p><blockquote><p>本地路径：/data0/maqi/pretrained_model/modeling_bert</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">BERT_PRETRAINED_MODEL_ARCHIVE_MAP = &#123;</span><br><span class="line">    &#x27;bert-base-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-multilingual-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-multilingual-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-multilingual-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-chinese&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-chinese-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-german-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-uncased-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-cased-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-uncased-whole-word-masking-finetuned-squad&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-uncased-whole-word-masking-finetuned-squad-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-large-cased-whole-word-masking-finetuned-squad&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-cased-finetuned-mrpc&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-cased-finetuned-mrpc-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-cased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-german-dbmdz-cased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-german-dbmdz-uncased&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/bert-base-german-dbmdz-uncased-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/cl-tohoku/bert-base-japanese-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/cl-tohoku/bert-base-japanese-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/cl-tohoku/bert-base-japanese-char-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-japanese-char-whole-word-masking&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-cased-v1&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/TurkuNLP/bert-base-finnish-cased-v1/pytorch_model.bin&quot;,</span><br><span class="line">    &#x27;bert-base-finnish-uncased-v1&#x27;: &quot;/data0/maqi/pretrained_model/modeling_bert/TurkuNLP/bert-base-finnish-uncased-v1/pytorch_model.bin&quot;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="执行流程"><a href="#执行流程" class="headerlink" title="执行流程"></a>执行流程</h2><blockquote><p>针对tag-based-multi-span-extraction/configs/drop/roberta/drop_roberta_large_TASE_IO_SSE.jsonnet​分析</p></blockquote><ul><li><p>dataset_reader</p><blockquote><p>“is_training”: true,设置为训练模式</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">&quot;dataset_reader&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;tbmse_drop&quot;,//选择src/data/dataset_readers/drop/drop_reader.py</span><br><span class="line">    &quot;answer_field_generators&quot;: &#123;</span><br><span class="line">        &quot;arithmetic_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;arithmetic_answer_generator&quot;,//选择src/data/dataset_readers/answer_field_generators/arithmetic_answer_generator.py</span><br><span class="line">            &quot;special_numbers&quot;: [</span><br><span class="line">                100,</span><br><span class="line">                1</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;count_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;count_answer_generator&quot;//选择src/data/dataset_readers/answer_field_generators/count_answer_generator.py</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;passage_span_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;span_answer_generator&quot;,//选择src/data/dataset_readers/answer_field_generators/span_answer_generator.py</span><br><span class="line">            &quot;text_type&quot;: &quot;passage&quot;//参数</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;question_span_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;span_answer_generator&quot;,//选择src/data/dataset_readers/answer_field_generators/span_answer_generator.py</span><br><span class="line">            &quot;text_type&quot;: &quot;question&quot;//参数</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;tagged_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;tagged_answer_generator&quot;,//选择src/data/dataset_readers/answer_field_generators/tagged_answer_generator.py</span><br><span class="line">            &quot;ignore_question&quot;: false,</span><br><span class="line">            &quot;labels&quot;: &#123;</span><br><span class="line">                &quot;I&quot;: 1,</span><br><span class="line">                &quot;O&quot;: 0</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;answer_generator_names_per_type&quot;: &#123;//drop_reader.py的参数</span><br><span class="line">        &quot;date&quot;: [</span><br><span class="line">            &quot;arithmetic_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;,</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;multiple_span&quot;: [</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;number&quot;: [</span><br><span class="line">            &quot;arithmetic_answer&quot;,</span><br><span class="line">            &quot;count_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;,</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;single_span&quot;: [</span><br><span class="line">            &quot;tagged_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;is_training&quot;: true,</span><br><span class="line">    &quot;lazy&quot;: true,</span><br><span class="line">    &quot;old_reader_behavior&quot;: true,</span><br><span class="line">    &quot;pickle&quot;: &#123;</span><br><span class="line">        &quot;action&quot;: &quot;load&quot;,</span><br><span class="line">        &quot;file_name&quot;: &quot;all_heads_IO_roberta-large&quot;,</span><br><span class="line">        &quot;path&quot;: &quot;../pickle/drop&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;huggingface_transformers&quot;,//选择src/data/tokenizers/huggingface_transformers_tokenizer.py</span><br><span class="line">        &quot;pretrained_model&quot;: &quot;roberta-large&quot;//参数</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ul><li>model</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line">&quot;model&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;multi_head&quot;,//选择src/models/multi_head_model.py</span><br><span class="line">    &quot;dataset_name&quot;: &quot;drop&quot;,</span><br><span class="line">    &quot;head_predictor&quot;: &#123;</span><br><span class="line">        &quot;activations&quot;: [</span><br><span class="line">            &quot;relu&quot;,</span><br><span class="line">            &quot;linear&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;dropout&quot;: [</span><br><span class="line">            0.1,</span><br><span class="line">            0</span><br><span class="line">        ],</span><br><span class="line">        &quot;hidden_dims&quot;: [</span><br><span class="line">            1024,</span><br><span class="line">            5</span><br><span class="line">        ],</span><br><span class="line">        &quot;input_dim&quot;: 2048,</span><br><span class="line">        &quot;num_layers&quot;: 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;heads&quot;: &#123;</span><br><span class="line">        &quot;arithmetic&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;arithmetic_head&quot;,//选择src/modules/heads/arithmetic_head.py</span><br><span class="line">            &quot;output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: [</span><br><span class="line">                    &quot;relu&quot;,</span><br><span class="line">                    &quot;linear&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;dropout&quot;: [</span><br><span class="line">                    0.1,</span><br><span class="line">                    0</span><br><span class="line">                ],</span><br><span class="line">                &quot;hidden_dims&quot;: [</span><br><span class="line">                    1024,</span><br><span class="line">                    3</span><br><span class="line">                ],</span><br><span class="line">                &quot;input_dim&quot;: 2048,</span><br><span class="line">                &quot;num_layers&quot;: 2</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;special_embedding_dim&quot;: 1024,</span><br><span class="line">            &quot;special_numbers&quot;: [</span><br><span class="line">                100,</span><br><span class="line">                1</span><br><span class="line">            ],</span><br><span class="line">            &quot;training_style&quot;: &quot;soft_em&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;count&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;count_head&quot;,//选择src/modules/heads/count_head.py</span><br><span class="line">            &quot;max_count&quot;: 10,</span><br><span class="line">            &quot;output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: [</span><br><span class="line">                    &quot;relu&quot;,</span><br><span class="line">                    &quot;linear&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;dropout&quot;: [</span><br><span class="line">                    0.1,</span><br><span class="line">                    0</span><br><span class="line">                ],</span><br><span class="line">                &quot;hidden_dims&quot;: [</span><br><span class="line">                    1024,</span><br><span class="line">                    11</span><br><span class="line">                ],</span><br><span class="line">                &quot;input_dim&quot;: 1024,</span><br><span class="line">                &quot;num_layers&quot;: 2</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;multi_span&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;multi_span_head&quot;,//选择src/modules/heads/multi_span_head.py</span><br><span class="line">            &quot;decoding_style&quot;: &quot;at_least_one&quot;,</span><br><span class="line">            &quot;ignore_question&quot;: false,</span><br><span class="line">            &quot;labels&quot;: &#123;</span><br><span class="line">                &quot;I&quot;: 1,</span><br><span class="line">                &quot;O&quot;: 0</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: [</span><br><span class="line">                    &quot;relu&quot;,</span><br><span class="line">                    &quot;linear&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;dropout&quot;: [</span><br><span class="line">                    0.1,</span><br><span class="line">                    0</span><br><span class="line">                ],</span><br><span class="line">                &quot;hidden_dims&quot;: [</span><br><span class="line">                    1024,</span><br><span class="line">                    2</span><br><span class="line">                ],</span><br><span class="line">                &quot;input_dim&quot;: 1024,</span><br><span class="line">                &quot;num_layers&quot;: 2</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;prediction_method&quot;: &quot;viterbi&quot;,</span><br><span class="line">            &quot;training_style&quot;: &quot;soft_em&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;passage_span&quot;: &#123;//继承了src/modules/heads/single_span_head.py </span><br><span class="line">            &quot;type&quot;: &quot;passage_span_head&quot;,//选择src/modules/heads/passage_span_head.py</span><br><span class="line">            &quot;end_output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: &quot;linear&quot;,</span><br><span class="line">                &quot;hidden_dims&quot;: 1,</span><br><span class="line">                &quot;input_dim&quot;: 1024,</span><br><span class="line">                &quot;num_layers&quot;: 1</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;start_output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: &quot;linear&quot;,</span><br><span class="line">                &quot;hidden_dims&quot;: 1,</span><br><span class="line">                &quot;input_dim&quot;: 1024,</span><br><span class="line">                &quot;num_layers&quot;: 1</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;training_style&quot;: &quot;soft_em&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;question_span&quot;: &#123;//继承了src/modules/heads/single_span_head.py </span><br><span class="line">            &quot;type&quot;: &quot;question_span_head&quot;,//选择src/modules/heads/question_span_head.py  </span><br><span class="line">            &quot;end_output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: [</span><br><span class="line">                    &quot;relu&quot;,</span><br><span class="line">                    &quot;linear&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;dropout&quot;: [</span><br><span class="line">                    0.1,</span><br><span class="line">                    0</span><br><span class="line">                ],</span><br><span class="line">                &quot;hidden_dims&quot;: [</span><br><span class="line">                    1024,</span><br><span class="line">                    1</span><br><span class="line">                ],</span><br><span class="line">                &quot;input_dim&quot;: 2048,</span><br><span class="line">                &quot;num_layers&quot;: 2</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;start_output_layer&quot;: &#123;</span><br><span class="line">                &quot;activations&quot;: [</span><br><span class="line">                    &quot;relu&quot;,</span><br><span class="line">                    &quot;linear&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;dropout&quot;: [</span><br><span class="line">                    0.1,</span><br><span class="line">                    0</span><br><span class="line">                ],</span><br><span class="line">                &quot;hidden_dims&quot;: [</span><br><span class="line">                    1024,</span><br><span class="line">                    1</span><br><span class="line">                ],</span><br><span class="line">                &quot;input_dim&quot;: 2048,</span><br><span class="line">                &quot;num_layers&quot;: 2</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;training_style&quot;: &quot;soft_em&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;passage_summary_vector_module&quot;: &#123;</span><br><span class="line">        &quot;activations&quot;: &quot;linear&quot;,</span><br><span class="line">        &quot;hidden_dims&quot;: 1,</span><br><span class="line">        &quot;input_dim&quot;: 1024,</span><br><span class="line">        &quot;num_layers&quot;: 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;pretrained_model&quot;: &quot;roberta-large&quot;,</span><br><span class="line">    &quot;question_summary_vector_module&quot;: &#123;</span><br><span class="line">        &quot;activations&quot;: &quot;linear&quot;,</span><br><span class="line">        &quot;hidden_dims&quot;: 1,</span><br><span class="line">        &quot;input_dim&quot;: 1024,</span><br><span class="line">        &quot;num_layers&quot;: 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ul><li>数据集</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;train_data_path&quot;: &quot;drop_data/drop_dataset_train.json&quot;,</span><br><span class="line">&quot;validation_data_path&quot;: &quot;drop_data/drop_dataset_dev.json&quot;,</span><br></pre></td></tr></table></figure><ul><li><p>trainer</p><blockquote><p>“cuda_device”: -1,表示使用cpu</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&quot;trainer&quot;: &#123;</span><br><span class="line">    &quot;cuda_device&quot;: 0,</span><br><span class="line">    &quot;keep_serialized_model_every_num_seconds&quot;: 3600,</span><br><span class="line">    &quot;num_epochs&quot;: 35,</span><br><span class="line">    &quot;num_steps_to_accumulate&quot;: 6,</span><br><span class="line">    &quot;optimizer&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;adamw&quot;,</span><br><span class="line">        &quot;lr&quot;: 5e-06</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;patience&quot;: 10,</span><br><span class="line">    &quot;summary_interval&quot;: 100,</span><br><span class="line">    &quot;validation_metric&quot;: &quot;+f1&quot;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><ul><li><p>validation_dataset_reader</p><blockquote><p>“is_training”: false,设置为评估</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">&quot;validation_dataset_reader&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;tbmse_drop&quot;,//选择src/data/dataset_readers/drop/drop_reader.py</span><br><span class="line">    &quot;answer_field_generators&quot;: &#123;</span><br><span class="line">        &quot;arithmetic_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;arithmetic_answer_generator&quot;,</span><br><span class="line">            &quot;special_numbers&quot;: [</span><br><span class="line">                100,</span><br><span class="line">                1</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;count_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;count_answer_generator&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;passage_span_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;span_answer_generator&quot;,</span><br><span class="line">            &quot;text_type&quot;: &quot;passage&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;question_span_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;span_answer_generator&quot;,</span><br><span class="line">            &quot;text_type&quot;: &quot;question&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;tagged_answer&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;tagged_answer_generator&quot;,</span><br><span class="line">            &quot;ignore_question&quot;: false,</span><br><span class="line">            &quot;labels&quot;: &#123;</span><br><span class="line">                &quot;I&quot;: 1,</span><br><span class="line">                &quot;O&quot;: 0</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;answer_generator_names_per_type&quot;: &#123;</span><br><span class="line">        &quot;date&quot;: [</span><br><span class="line">            &quot;arithmetic_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;,</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;multiple_span&quot;: [</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;number&quot;: [</span><br><span class="line">            &quot;arithmetic_answer&quot;,</span><br><span class="line">            &quot;count_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;,</span><br><span class="line">            &quot;tagged_answer&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;single_span&quot;: [</span><br><span class="line">            &quot;tagged_answer&quot;,</span><br><span class="line">            &quot;passage_span_answer&quot;,</span><br><span class="line">            &quot;question_span_answer&quot;</span><br><span class="line">        ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;is_training&quot;: false,//设置为评估</span><br><span class="line">    &quot;lazy&quot;: true,</span><br><span class="line">    &quot;old_reader_behavior&quot;: true,</span><br><span class="line">    &quot;pickle&quot;: &#123;</span><br><span class="line">        &quot;action&quot;: &quot;load&quot;,</span><br><span class="line">        &quot;file_name&quot;: &quot;all_heads_IO_roberta-large&quot;,</span><br><span class="line">        &quot;path&quot;: &quot;../pickle/drop&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;tokenizer&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;huggingface_transformers&quot;,</span><br><span class="line">        &quot;pretrained_model&quot;: &quot;roberta-large&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><p>训练模型打包为<strong>model.tar.gz</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp predict training_directory/model.tar.gz drop_data/drop_dataset_dev.json --predictor machine-comprehension --cuda-device 0 --output-file predictions.jsonl --use-dataset-reader --include-package src</span><br></pre></td></tr></table></figure><p>预测结果保存在根目录的predictions.jsonl</p><h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><p><strong>DROP</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp evaluate training_directory/model.tar.gz drop_data/drop_dataset_dev.json --cuda-device 3 --output-file eval.json --include-package src</span><br></pre></td></tr></table></figure><p><strong>BERT</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">allennlp evaluate training_directory_bert/model.tar.gz drop_data/drop_dataset_dev.json --cuda-device 1 --output-file eval_bert.json --include-package src</span><br></pre></td></tr></table></figure><p>预测结果保存在根目录的eval.json</p><h3 id="评估结果——DROP"><a href="#评估结果——DROP" class="headerlink" title="评估结果——DROP"></a>评估结果——<strong>DROP</strong></h3><p><strong>TASE_IO+SSE</strong></p><div class="table-container"><table><thead><tr><th>em_all_spans</th><th>f1_all_spans</th><th>em_multi_span</th><th>f1_multi_span</th><th>em_span</th><th>f1_span</th></tr></thead><tbody><tr><td>80.6</td><td>87.8</td><td>60.8</td><td>82.6</td><td>84.2</td><td>89.0</td></tr></tbody></table></div><p><strong>TASE_IO+SSE(BLOCK)</strong></p><div class="table-container"><table><thead><tr><th>em_all_spans</th><th>f1_all_spans</th><th>em_multi_span</th><th>f1_multi_span</th><th>em_span</th><th>f1_span</th></tr></thead><tbody><tr><td>55.3</td><td>62.8</td><td>0</td><td>0</td><td>56.5</td><td>64.2</td></tr></tbody></table></div><p><strong>TASE_IO+SSE(BERT_large)</strong></p><div class="table-container"><table><thead><tr><th>em_all_spans</th><th>f1_all_spans</th><th>em_multi_span</th><th>f1_multi_span</th><th>em_span</th><th>f1_span</th></tr></thead><tbody><tr><td>76.4</td><td>83.9</td><td>54.5</td><td>80.1</td><td>80.7</td><td>85.2</td></tr></tbody></table></div><p><strong>TASE_IO+SSE(只对包含答案的句子做IO标记)</strong></p><div class="table-container"><table><thead><tr><th>em_all_spans</th><th>f1_all_spans</th><th>em_multi_span</th><th>f1_multi_span</th><th>em_span</th><th>f1_span</th></tr></thead><tbody><tr><td>57.8</td><td>64.5</td><td>16.7</td><td>23.3</td><td>58.1</td><td>64.2</td></tr></tbody></table></div><p>论文结果：</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210212155322.png" alt="image-20210212155315238"></p>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> DROP </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> QUOREF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HOTPOTQA A Dataset for Diverse, Explainable Multi-hop Question Answering</title>
      <link href="/2021/02/05/HOTPOTQA%20A%20Dataset%20for%20Diverse,%20Explainable%20Multi-hop%20Question%20Answering/"/>
      <url>/2021/02/05/HOTPOTQA%20A%20Dataset%20for%20Diverse,%20Explainable%20Multi-hop%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="HOTPOTQA-A-Dataset-for-Diverse-Explainable-Multi-hop-Question-Answering"><a href="#HOTPOTQA-A-Dataset-for-Diverse-Explainable-Multi-hop-Question-Answering" class="headerlink" title="HOTPOTQA A Dataset for Diverse, Explainable Multi-hop Question Answering"></a>HOTPOTQA A Dataset for Diverse, Explainable Multi-hop Question Answering</h1><blockquote><p><a href="https://arxiv.org/pdf/1809.09600.pdf">论文：https://arxiv.org/pdf/1809.09600.pdf</a></p><p>一个多样的，可解释的多跳问答数据集。</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>现有的问答数据集不能训练QA系统进行复杂的推理并提供答案的解释。提出hotpot数据集，提供支持事实使模型能够改进性能并做出可解释的预测。</p><h2 id="HOTPOTQA介绍"><a href="#HOTPOTQA介绍" class="headerlink" title="HOTPOTQA介绍"></a>HOTPOTQA介绍</h2><p>HOTPOTQA是一个新的数据集，拥有113k个基于Wikipedia的问答对，具有以下四个关键特性：</p><ul><li>这些问题需要在多个支持文档上找到答案并进行推理。</li><li>问题是多样的，不局限于任何预先存在的知识库或知识模式。</li><li>提供推理所需的句子级支持事实，允许QA系统在强监督下推理并解释预测。</li><li>提出了一种新的factoid comparison questions来测试QA系统提取相关事实和进行必要比较的能力。</li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="数据集划分"><a href="#数据集划分" class="headerlink" title="数据集划分"></a>数据集划分</h3><p>single-hop数据集：The train-easy set contains 18,089 mostly single-hop examples.</p><p>将hard examples随机划分为4个子集：</p><ul><li>train-hard, dev, test-distractor, test-fullwiki</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210131161128.png" alt="image-20210131161127920" style="zoom: 67%;" /></p><h3 id="two-benchmark-settings"><a href="#two-benchmark-settings" class="headerlink" title="two benchmark settings"></a>two benchmark settings</h3><ul><li><p>distractor</p><blockquote><p>8 paragraphs from Wikipedia + 2 gold paragraphs</p></blockquote></li><li><p>full wiki</p><blockquote><p>要求模型回答所有Wikipedia文章的第一段给出的问题。</p></blockquote></li></ul><p>两种设置使用不同数据集的原因：distractor设置中的模型可以使用gold paragraphs，但full wiki设置中不可以使用gold paragraphs。</p><h3 id="Question-Types"><a href="#Question-Types" class="headerlink" title="Question Types"></a>Question Types</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210131164223.png" alt="image-20210131164223663"></p><h3 id="Answer-Types"><a href="#Answer-Types" class="headerlink" title="Answer Types"></a>Answer Types</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210131164623.png" alt="image-20210131164623642"></p><ul><li>68%的回答实体相关。</li></ul><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210131171031.png" alt="image-20210131171031628"></p><ul><li>对于每个句子，在第一个和最后一个位置连接selfattention layer的输出，并使用binary linear classifier来预测当前句子成为支持事实的概率。 </li><li>将此分类器的二进制交叉熵损失最小化。 在多任务学习环境中，该目标与正常问答目标共同得到优化，并且它们共享相同的low-level representations。 </li><li>使用该分类器，还可以在支持事实预测的任务上评估模型以评估其可解释性 。</li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><h3 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h3><ul><li><p>exact match (EM) and F1</p></li><li><p>计算F1</p></li></ul><script type="math/tex; mode=display">P^{(joint)}= P^{(ans)}P^{(sup)}</script><script type="math/tex; mode=display">R^{(joint)}= R^{(ans)}R^{(sup)}</script><script type="math/tex; mode=display">Joint \ F1= \frac{2P^{(joint)}R^{(joint)}}{P^{(joint)}+ R^{(joint)}}</script><ul><li>计算EM<ul><li>仅当两个任务都完全匹配时，Joint EM才为1，否则为0。</li><li>逐个示例评估所有指标，然后对评估集中的示例进行平均。</li></ul></li></ul><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210131172445.png" alt="image-20210131172445507"></p><p>在两种设置下，扩大上下文范围会增加问题回答的难度，所有设置下的模型性能均明显低于人工性能。 与distractor相比full wiki设置中的性能要低得多。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210131174126.png" alt="image-20210131174126572"></p><p>按不同问题类型测试：</p><ul><li>distractor setting下comparison questions的F1得分比bridge entities questions低，表明对这种新颖的问题类型进行更好的建模可能需要更好的神经网络结构。</li><li>full wiki setting下bridge entities questions的性能显著下降，而comparison questions的性能仅略有下降，是因为两个实体通常都出现在比较问题中，从而降低了检索难度 。</li></ul><h2 id="单个样本结构"><a href="#单个样本结构" class="headerlink" title="单个样本结构"></a>单个样本结构</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210205091447.png" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> HOTPOTQA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch学习笔记(一)</title>
      <link href="/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/"/>
      <url>/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorch学习笔记-一"><a href="#PyTorch学习笔记-一" class="headerlink" title="PyTorch学习笔记(一)"></a>PyTorch学习笔记(一)</h1><h2 id="创建张量-Tensors"><a href="#创建张量-Tensors" class="headerlink" title="创建张量 Tensors"></a>创建张量 Tensors</h2><h3 id="torch-rand"><a href="#torch-rand" class="headerlink" title="torch.rand"></a>torch.rand</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.rand(*sizes, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个张量，包含了从区间<strong>[0,1)</strong>的均匀分布中抽取的一组随机数，形状由可变参数sizes 定义。</p><p>参数:</p><ul><li>sizes (int…) – 整数序列，定义了输出形状</li><li>out (Tensor, optinal) - 结果张量 </li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.rand(4)</span><br><span class="line"></span><br><span class="line"> 0.9193</span><br><span class="line"> 0.3347</span><br><span class="line"> 0.3232</span><br><span class="line"> 0.7715</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.rand(2, 3)</span><br><span class="line"></span><br><span class="line"> 0.5010  0.5140  0.0719</span><br><span class="line"> 0.1435  0.5636  0.0538</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br></pre></td></tr></table></figure><h3 id="torch-randn"><a href="#torch-randn" class="headerlink" title="torch.randn"></a>torch.randn</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randn(*sizes, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个张量，包含了从标准正态分布(<strong>均值为0，方差为 1，即高斯白噪声</strong>)中抽取一组随机数，形状由可变参数sizes定义。 </p><p>参数:</p><ul><li>sizes (int…) – 整数序列，定义了输出形状</li><li>out (Tensor, optinal) - 结果张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.randn(4)</span><br><span class="line"></span><br><span class="line">-0.1145</span><br><span class="line"> 0.0094</span><br><span class="line">-1.1717</span><br><span class="line"> 0.9846</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.randn(2, 3)</span><br><span class="line"></span><br><span class="line"> 1.4339  0.3351 -1.0999</span><br><span class="line"> 1.5458 -0.9643 -0.3558</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br></pre></td></tr></table></figure><h3 id="torch-randperm"><a href="#torch-randperm" class="headerlink" title="torch.randperm"></a>torch.randperm</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.randperm(n, out=None) → LongTensor</span><br></pre></td></tr></table></figure><p>给定参数n，返回一个从0 到n -1 (<strong>[0,n-1)</strong>)的随机整数排列。</p><p>参数:</p><ul><li>n (int) – 上边界(不包含)</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.randperm(4)</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line"> 1</span><br><span class="line"> 3</span><br><span class="line"> 0</span><br><span class="line">[torch.LongTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-arange"><a href="#torch-arange" class="headerlink" title="torch.arange"></a>torch.arange</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.arange(start, end, step=1, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个1维张量，长度为 <strong>floor((end−start)/step) （向下取整）</strong>。<strong>包含</strong>(闭区间)从start到end，以step为步长的一组序列值(默认步长为1)。</p><p>参数:</p><ul><li>start (float) – 序列的起始点</li><li>end (float) – 序列的终止点</li><li>step (float) – 相邻点的间隔大小</li><li>out (Tensor, optional) – 结果张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.arange(1, 4)</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line">[torch.FloatTensor of size 3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.arange(1, 2.5, 0.5)</span><br><span class="line"></span><br><span class="line"> 1.0000</span><br><span class="line"> 1.5000</span><br><span class="line"> 2.0000</span><br><span class="line">[torch.FloatTensor of size 3]</span><br></pre></td></tr></table></figure><h3 id="torch-range-建议使用-torch-arange"><a href="#torch-range-建议使用-torch-arange" class="headerlink" title="torch.range() 建议使用  torch.arange()"></a>torch.range() 建议使用  torch.arange()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.range(start, end, step=1, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个1维张量，有 <strong>floor((end−start)/step)+1</strong> 个元素。包含在<strong>半开区间[start, end</strong>）从start开始，以step为步长的一组值。 step 是两个值之间的间隔，即 $x_{i+1}=x_i+step$</p><p><strong>警告：建议使用函数 torch.arange()</strong></p><p>参数:</p><ul><li>start (float) – 序列的起始点</li><li>end (float) – 序列的最终值</li><li>step (int) – 相邻点的间隔大小</li><li>out (Tensor, optional) – 结果张量</li></ul><p>特例：</p><ul><li>mean=0.0，所有抽取的样本共享均值</li><li>std=1.0，所有抽取的样本共享标准差</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.range(1, 4)</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.range(1, 4, 0.5)</span><br><span class="line"></span><br><span class="line"> 1.0000</span><br><span class="line"> 1.5000</span><br><span class="line"> 2.0000</span><br><span class="line"> 2.5000</span><br><span class="line"> 3.0000</span><br><span class="line"> 3.5000</span><br><span class="line"> 4.0000</span><br><span class="line">[torch.FloatTensor of size 7]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch学习笔记(三)</title>
      <link href="/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%89)/"/>
      <url>/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%B8%89)/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorch学习笔记-三"><a href="#PyTorch学习笔记-三" class="headerlink" title="PyTorch学习笔记(三)"></a>PyTorch学习笔记(三)</h1><h2 id="随机抽样-Random-sampling"><a href="#随机抽样-Random-sampling" class="headerlink" title="随机抽样 Random sampling"></a>随机抽样 Random sampling</h2><h3 id="torch-manual-seed"><a href="#torch-manual-seed" class="headerlink" title="torch.manual_seed"></a>torch.manual_seed</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(seed)</span><br></pre></td></tr></table></figure><p>设定生成随机数的种子，并返回一个 torch._C.Generator 对象</p><p>参数: </p><ul><li>seed (int or long) – 种子</li></ul><h3 id="torch-initial-seed"><a href="#torch-initial-seed" class="headerlink" title="torch.initial_seed"></a>torch.initial_seed</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.initial_seed()</span><br></pre></td></tr></table></figure><p>返回生成随机数的原始种子值（python long）</p><h3 id="torch-get-rng-state"><a href="#torch-get-rng-state" class="headerlink" title="torch.get_rng_state"></a>torch.get_rng_state</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.get_rng_state</span><br></pre></td></tr></table></figure><p>返回随机生成器状态(ByteTensor)</p><h3 id="torch-set-rng-state"><a href="#torch-set-rng-state" class="headerlink" title="torch.set_rng_state"></a>torch.set_rng_state</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.set_rng_state(new_state)</span><br></pre></td></tr></table></figure><p>设定随机生成器状态 </p><p>参数: </p><ul><li>new_state (torch.ByteTensor) – 期望的状态</li></ul><h3 id="torch-torch-bernoulli"><a href="#torch-torch-bernoulli" class="headerlink" title="torch.torch.bernoulli"></a>torch.torch.bernoulli</h3><p>从<strong>伯努利分布</strong>中抽取二元随机数(0 或者 1)。</p><p>输入张量须包含用于抽取上述二元随机值的概率。 因此，输入中的所有值都必须在<strong>［0,1］</strong>区间，即 $0&lt;=input_i&lt;=1$</p><p>输出张量的第i个元素值， 将会以输入张量的第i个概率值等于1。</p><p>返回值将会是与输入相同大小的张量，每个值为0或者1。</p><p>参数:</p><ul><li>input (Tensor) – 输入为伯努利分布的概率值</li><li>out (Tensor, optional) – 输出张量(可选)</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.Tensor(3, 3).uniform_(0, 1) # generate a uniform random matrix with range [0, 1]</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 0.7544  0.8140  0.9842</span><br><span class="line"> 0.5282  0.0595  0.6445</span><br><span class="line"> 0.1925  0.9553  0.9732</span><br><span class="line">[torch.FloatTensor of size 3x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.bernoulli(a)</span><br><span class="line"></span><br><span class="line"> 1  1  1</span><br><span class="line"> 0  0  1</span><br><span class="line"> 0  1  1</span><br><span class="line">[torch.FloatTensor of size 3x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; a = torch.ones(3, 3) # probability of drawing &quot;1&quot; is 1</span><br><span class="line">&gt;&gt;&gt; torch.bernoulli(a)</span><br><span class="line"></span><br><span class="line"> 1  1  1</span><br><span class="line"> 1  1  1</span><br><span class="line"> 1  1  1</span><br><span class="line">[torch.FloatTensor of size 3x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; a = torch.zeros(3, 3) # probability of drawing &quot;1&quot; is 0</span><br><span class="line">&gt;&gt;&gt; torch.bernoulli(a)</span><br><span class="line"></span><br><span class="line"> 0  0  0</span><br><span class="line"> 0  0  0</span><br><span class="line"> 0  0  0</span><br><span class="line">[torch.FloatTensor of size 3x3]</span><br></pre></td></tr></table></figure><h3 id="torch-multinomial"><a href="#torch-multinomial" class="headerlink" title="torch.multinomial"></a>torch.multinomial</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.multinomial(input, num_samples,replacement=False, out=None) → LongTensor</span><br></pre></td></tr></table></figure><p>返回一个张量，每行包含从<code>input</code>相应<code>行</code>中定义的多项分布中抽取的<code>num_samples</code>个样本。</p><blockquote><p>作用是对input的每一行做n_samples次取值，输出的张量是每一次取值时input张量对应行的下标。</p></blockquote><p>注意：输入<code>input</code>每行的值<strong>不需要总和为1</strong> (这里我们用来做权重)，但是<strong>必须非负且总和不能为0</strong>。</p><p>当抽取样本时，依次从左到右排列(第一个样本对应第一列)。</p><p>如果输入<code>input</code>是一个向量，输出out也是一个相同长度<code>num_samples</code>的向量。如果输入<code>input</code>是有<code>m</code>行的矩阵，输出out是形如<code>m×num_samples</code>的矩阵。</p><p>如果参数<code>replacement</code> 为<code>True</code>, 则样本抽取可以重复。否则，一个样本在每行不能被重复抽取。</p><p>参数<code>num_samples</code>必须小于<code>input</code>长度(即，<code>input</code>的列数，如果是input是一个矩阵)。</p><p>参数:</p><ul><li>input (Tensor) – 包含概率值的张量</li><li>num_samples (int) – 抽取的样本数</li><li>replacement (bool, optional) – 布尔值，决定是否能重复抽取</li><li>out (Tensor, optional) – 结果张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; weights = torch.Tensor([0, 10, 3, 0]) # create a Tensor of weights</span><br><span class="line">&gt;&gt;&gt; torch.multinomial(weights, 4, replacement=True)</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line">[torch.LongTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; weights = torch.rand(3, 4)</span><br><span class="line">tensor([[0.9005, 0.8463, 0.6070, 0.4762],</span><br><span class="line">        [0.6458, 0.0261, 0.7618, 0.7244],</span><br><span class="line">        [0.5225, 0.9317, 0.8163, 0.2554]])</span><br><span class="line">&gt;&gt;&gt; torch.multinomial(weights, 2)</span><br><span class="line">tensor([[0, 1],</span><br><span class="line">        [2, 3],</span><br><span class="line">        [3, 0]])</span><br></pre></td></tr></table></figure><blockquote><p>输入是[0,10,3,0]，也就是说第0个元素和第3个元素权重都是0，在其他元素被取完之前是不会被取到的。</p></blockquote><h3 id="torch-normal"><a href="#torch-normal" class="headerlink" title="torch.normal()"></a>torch.normal()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.normal(means, std, out=None)</span><br></pre></td></tr></table></figure><p>返回一个张量，包含从给定参数<code>means</code>,std的<strong>离散正态分布</strong>中抽取随机数。 <code>均值means</code>是一个张量，包含每个输出元素相关的正态分布的均值。 <code>std</code>是一个张量，包含每个输出元素相关的正态分布的<strong>标准差</strong>。 均值和标准差的形状不须匹配，但每个张量的<strong>元素个数须相同</strong>。</p><p>参数:</p><ul><li>means (Tensor) – 均值</li><li>std (Tensor) – 标准差</li><li>out (Tensor) – 可选的输出张量</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">torch.normal(means=torch.arange(1, 11), std=torch.arange(1, 0, -0.1))</span><br><span class="line"></span><br><span class="line"> 1.5104</span><br><span class="line"> 1.6955</span><br><span class="line"> 2.4895</span><br><span class="line"> 4.9185</span><br><span class="line"> 4.9895</span><br><span class="line"> 6.9155</span><br><span class="line"> 7.3683</span><br><span class="line"> 8.1836</span><br><span class="line"> 8.7164</span><br><span class="line"> 9.8916</span><br><span class="line">[torch.FloatTensor of size 10]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch学习笔记(二)</title>
      <link href="/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%BA%8C)/"/>
      <url>/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E4%BA%8C)/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorch学习笔记-二"><a href="#PyTorch学习笔记-二" class="headerlink" title="PyTorch学习笔记(二)"></a>PyTorch学习笔记(二)</h1><blockquote><p>dimension：0行 1列</p></blockquote><h2 id="张量操作"><a href="#张量操作" class="headerlink" title="张量操作"></a>张量操作</h2><h3 id="torch-cat"><a href="#torch-cat" class="headerlink" title="torch.cat"></a>torch.cat</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cat(inputs, dimension=0) → Tensor</span><br></pre></td></tr></table></figure><p>在给定维度上对输入的张量序列<code>seq</code>进行连接操作。</p><p>torch.cat()可以看做 <code>torch.split()</code> 和 <code>torch.chunk()</code>的反操作。 <code>cat()</code> 函数可以通过下面例子更好的理解。</p><p>参数:</p><ul><li>inputs (sequence of Tensors) – 可以是任意<strong>相同</strong>Tensor 类型的python 序列。</li><li>dimension (int, optional) – 沿着此维连接张量序列。</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.randn(2, 3)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line"></span><br><span class="line"> 0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.cat((x, x, x), 0)</span><br><span class="line"></span><br><span class="line"> 0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735</span><br><span class="line"> 0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735</span><br><span class="line"> 0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735</span><br><span class="line">[torch.FloatTensor of size 6x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.cat((x, x, x), 1)</span><br><span class="line"></span><br><span class="line"> 0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735</span><br><span class="line">[torch.FloatTensor of size 2x9]</span><br></pre></td></tr></table></figure><h3 id="torch-chunk"><a href="#torch-chunk" class="headerlink" title="torch.chunk"></a>torch.chunk</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.chunk(tensor, chunks, dim=0)</span><br></pre></td></tr></table></figure><p>在给定维度(轴)上将输入张量进行分块儿。</p><p>参数:</p><ul><li>tensor (Tensor) – 待分块的输入张量</li><li>chunks (int) – 分块的个数</li><li>dim (int) – 沿着此维度进行分块</li></ul><h3 id="torch-gather"><a href="#torch-gather" class="headerlink" title="torch.gather"></a>torch.gather</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.gather(input, dim, index, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>沿给定轴<code>dim</code>，将输入索引张量<code>index</code>指定位置的值进行聚合。</p><p>参数：</p><ul><li>input (Tensor) – 源张量</li><li>dim (int) – 索引的轴</li><li>index (LongTensor) – 聚合元素的下标</li><li>out (Tensor, optional) – 目标张量</li></ul><p>对一个3维张量，输出可以定义为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">out[i][j][k] = tensor[index[i][j][k]][j][k]  # dim=0</span><br><span class="line">out[i][j][k] = tensor[i][index[i][j][k]][k]  # dim=1</span><br><span class="line">out[i][j][k] = tensor[i][j][index[i][j][k]]  # dim=3</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t = torch.Tensor([[1,2],[3,4]])</span><br><span class="line"> 1  2</span><br><span class="line"> 3  4</span><br><span class="line">&gt;&gt;&gt; torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]]))</span><br><span class="line"> 1  1</span><br><span class="line"> 4  3</span><br><span class="line">[torch.FloatTensor of size 2x2]</span><br></pre></td></tr></table></figure><blockquote><p>dim=1</p><p>i=0,j=0</p><p>out[0][0]=input[0,index[0][0]]=input[0,0]=1</p><p>i=0,j=1</p><p>out[0][1]=input[0,index[0][1]]=input[0,0]]=1</p><p>i=1,j=0</p><p>out[1][0]=input[1,index[1][0]]=input[1,1]]=4</p><p>i=1,j=1</p><p>out[1][1]=input[1,index[1][1]]=input[1,0]]=3</p></blockquote><h3 id="torch-index-select"><a href="#torch-index-select" class="headerlink" title="torch.index_select"></a>torch.index_select</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.index_select(input, dim, index, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>沿着指定维度对输入进行切片，取<code>index</code>中指定的相应项(index为一个LongTensor)，然后返回到一个新的张量， 返回的张量与原始张量<em>Tensor</em>有相同的维度(在指定轴上)。</p><p>注意： 返回的张量<strong>不与原始张量共享内存空间</strong>。</p><p>参数:</p><ul><li>input (Tensor) – 输入张量</li><li>dim (int) – 索引的轴</li><li>index (LongTensor) – 包含索引下标的一维张量</li><li>out (Tensor, optional) – 目标张量</li></ul><p>例子：</p><figure class="highlight plaintext"><figcaption><span>x </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x</span><br><span class="line"></span><br><span class="line"> 1.2045  2.4084  0.4001  1.1372</span><br><span class="line"> 0.5596  1.5677  0.6219 -0.7954</span><br><span class="line"> 1.3635 -1.2313 -0.5414 -1.8478</span><br><span class="line">[torch.FloatTensor of size 3x4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; indices = torch.LongTensor([0, 2])</span><br><span class="line">&gt;&gt;&gt; torch.index_select(x, 0, indices)</span><br><span class="line"></span><br><span class="line"> 1.2045  2.4084  0.4001  1.1372</span><br><span class="line"> 1.3635 -1.2313 -0.5414 -1.8478</span><br><span class="line">[torch.FloatTensor of size 2x4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.index_select(x, 1, indices)</span><br><span class="line"></span><br><span class="line"> 1.2045  0.4001</span><br><span class="line"> 0.5596  0.6219</span><br><span class="line"> 1.3635 -0.5414</span><br><span class="line">[torch.FloatTensor of size 3x2]</span><br></pre></td></tr></table></figure><blockquote><p>dim=0,[0,2]：取第0和第1行。</p><p>dim=1,[0,2]：取第0和第1列。</p></blockquote><h3 id="torch-masked-select"><a href="#torch-masked-select" class="headerlink" title="torch.masked_select"></a>torch.masked_select</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.masked_select(input, mask, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>根据掩码张量mask中的二元值，取输入张量中的指定项(mask为一个 ByteTensor)，将取值返回到一个新的1D张量，张量mask须跟input张量有<strong>相同数量的元素数目</strong>，但形状或维度不需要相同。 </p><p>注意： 返回的张量<strong>不与原始张量共享内存空间</strong>。</p><p>参数:</p><ul><li>input (Tensor) – 输入张量</li><li>mask (ByteTensor) – 掩码张量，包含了二元索引值</li><li>out (Tensor, optional) – 目标张量</li></ul><h3 id="torch-nonzero"><a href="#torch-nonzero" class="headerlink" title="torch.nonzero"></a>torch.nonzero</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nonzero(input, out=None) → LongTensor</span><br></pre></td></tr></table></figure><p>返回输入张量中的非零元素的索引。</p><p>如果输入<code>input</code>有<code>n</code>维，则输出的索引张量output的形状为 <code>z x n</code>, 这里 <code>z</code> 是输入张量input中所有非零元素的个数。</p><p>参数:</p><ul><li>input (Tensor) – 源张量</li><li>out (LongTensor, optional) – 包含索引值的结果张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.nonzero(torch.Tensor([1, 1, 1, 0, 1]))</span><br><span class="line"></span><br><span class="line"> 0</span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 4</span><br><span class="line">[torch.LongTensor of size 4x1]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.nonzero(torch.Tensor([[0.6, 0.0, 0.0, 0.0],</span><br><span class="line">...                             [0.0, 0.4, 0.0, 0.0],</span><br><span class="line">...                             [0.0, 0.0, 1.2, 0.0],</span><br><span class="line">...                             [0.0, 0.0, 0.0,-0.4]]))</span><br><span class="line"></span><br><span class="line"> 0  0</span><br><span class="line"> 1  1</span><br><span class="line"> 2  2</span><br><span class="line"> 3  3</span><br><span class="line">[torch.LongTensor of size 4x2]</span><br></pre></td></tr></table></figure><h3 id="torch-split"><a href="#torch-split" class="headerlink" title="torch.split"></a>torch.split</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.split(tensor, split_size, dim=0)</span><br></pre></td></tr></table></figure><p>将输入张量分割成相等形状的chunks（如果可分）。 如果沿指定维的张量形状大小不能被<code>split_size</code> 整分， 则最后一个分块会小于其它分块。</p><p>参数:</p><ul><li>tensor (Tensor) – 待分割张量</li><li>split_size (int) – 单个分块的形状大小</li><li>dim (int) – 沿着此维进行分割</li></ul><h3 id="torch-squeeze"><a href="#torch-squeeze" class="headerlink" title="torch.squeeze"></a>torch.squeeze</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.squeeze(input, dim=None, out=None)</span><br></pre></td></tr></table></figure><p>输入张量形状中的<code>1</code>去除并返回。 如果输入是形如<code>(A×1×B×1×C×1×D)</code>，那么输出形状就为:<code>(A×B×C×D)</code><br>当给定<code>dim</code>时，那么挤压操作只在给定维度上。例如，输入形状为: <code>(A×1×B), squeeze(input, 0)</code> 将会保持张量不变，只有用 <code>squeeze(input, 1)</code>，形状会变成 <code>(A×B)</code>。</p><p>注意： 返回张量与输入张量<strong>共享内存</strong>，所以改变其中一个的内容会改变另一个。</p><p>参数:</p><ul><li>input (Tensor) – 输入张量</li><li>dim (int, optional) – 如果给定，则input只会在给定维度挤压，若不给定，在所有维度挤压。</li><li>out (Tensor, optional) – 输出张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.zeros(2,1,2,1,2)</span><br><span class="line">&gt;&gt;&gt; x.size()</span><br><span class="line">(2L, 1L, 2L, 1L, 2L)</span><br><span class="line">&gt;&gt;&gt; y = torch.squeeze(x)</span><br><span class="line">&gt;&gt;&gt; y.size()</span><br><span class="line">(2L, 2L, 2L)</span><br><span class="line">&gt;&gt;&gt; y = torch.squeeze(x, 0)</span><br><span class="line">&gt;&gt;&gt; y.size()</span><br><span class="line">(2L, 1L, 2L, 1L, 2L)</span><br><span class="line">&gt;&gt;&gt; y = torch.squeeze(x, 1)</span><br><span class="line">&gt;&gt;&gt; y.size()</span><br><span class="line">(2L, 2L, 1L, 2L)</span><br></pre></td></tr></table></figure><h3 id="torch-stack"><a href="#torch-stack" class="headerlink" title="torch.stack"></a>torch.stack</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.stack(sequence, dim=0)</span><br></pre></td></tr></table></figure><p>沿着一个新维度对输入张量序列进行连接。 序列中所有的张量都应该为相同形状。</p><p>参数:</p><ul><li>sqequence (Sequence) – 待连接的张量序列</li><li>dim (int) – 插入的维度。必须介于0与待连接的张量序列数之间。</li></ul><h3 id="torch-t"><a href="#torch-t" class="headerlink" title="torch.t"></a>torch.t</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.t(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>输入一个矩阵（<strong>2维张量</strong>），并转置0, 1维。 可以被视为函数<code>transpose(input, 0, 1)</code>的简写函数。</p><p>参数:</p><ul><li>input (Tensor) – 输入张量</li><li>out (Tensor, optional) – 结果张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.randn(2, 3)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line"></span><br><span class="line"> 0.4834  0.6907  1.3417</span><br><span class="line">-0.1300  0.5295  0.2321</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.t(x)</span><br><span class="line"></span><br><span class="line"> 0.4834 -0.1300</span><br><span class="line"> 0.6907  0.5295</span><br><span class="line"> 1.3417  0.2321</span><br><span class="line">[torch.FloatTensor of size 3x2]</span><br></pre></td></tr></table></figure><h3 id="torch-transpose"><a href="#torch-transpose" class="headerlink" title="torch.transpose"></a>torch.transpose</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.transpose(input, dim0, dim1, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回输入矩阵<code>input</code>的转置。交换维度<code>dim0</code>和dim1。 输出张量与输入张量<strong>共享内存</strong>，所以改变其中一个会导致另外一个也被修改。</p><p>参数:</p><ul><li>input (Tensor) – 输入张量</li><li>dim0 (int) – 转置的第一维</li><li>dim1 (int) – 转置的第二维</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.randn(2, 3)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line"></span><br><span class="line"> 0.5983 -0.0341  2.4918</span><br><span class="line"> 1.5981 -0.5265 -0.8735</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.transpose(x, 0, 1)</span><br><span class="line"></span><br><span class="line"> 0.5983  1.5981</span><br><span class="line">-0.0341 -0.5265</span><br><span class="line"> 2.4918 -0.8735</span><br><span class="line">[torch.FloatTensor of size 3x2]</span><br></pre></td></tr></table></figure><h3 id="torch-unbind"><a href="#torch-unbind" class="headerlink" title="torch.unbind"></a>torch.unbind</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unbind(tensor, dim=0)</span><br></pre></td></tr></table></figure><p>移除指定维后，返回一个元组，包含了沿着指定维切片后的各个切片。</p><p>参数:</p><ul><li>tensor (Tensor) – 输入张量</li><li>dim (int) – 删除的维度</li></ul><h3 id="torch-unsqueeze"><a href="#torch-unsqueeze" class="headerlink" title="torch.unsqueeze"></a>torch.unsqueeze</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.unsqueeze(input, dim, out=None)</span><br></pre></td></tr></table></figure><p>返回一个新的张量，对输入的制定位置<strong>插入维度 1</strong>。</p><p>注意： 返回张量与输入张量<strong>共享内存</strong>，所以改变其中一个的内容会改变另一个。</p><p>如果<strong>dim为负</strong>，则将会被转化<strong>dim+input.dim()+1</strong><br>参数:</p><ul><li>tensor (Tensor) – 输入张量</li><li>dim (int) – 插入维度的索引</li><li>out (Tensor, optional) – 结果张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = torch.Tensor([1, 2, 3, 4])</span><br><span class="line">&gt;&gt;&gt; torch.unsqueeze(x, 0)</span><br><span class="line"> 1  2  3  4</span><br><span class="line">[torch.FloatTensor of size 1x4]</span><br><span class="line">&gt;&gt;&gt; torch.unsqueeze(x, 1)</span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[torch.FloatTensor of size 4x1]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch学习笔记(四)</title>
      <link href="/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E5%9B%9B)/"/>
      <url>/2021/02/01/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E5%9B%9B)/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorch学习笔记-四"><a href="#PyTorch学习笔记-四" class="headerlink" title="PyTorch学习笔记(四)"></a>PyTorch学习笔记(四)</h1><h2 id="数学操作Math-operations"><a href="#数学操作Math-operations" class="headerlink" title="数学操作Math operations"></a>数学操作Math operations</h2><h3 id="torch-abs"><a href="#torch-abs" class="headerlink" title="torch.abs"></a>torch.abs</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.abs(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>计算输入张量的每个元素绝对值。</p><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.abs(torch.FloatTensor([-1, -2, 3]))</span><br><span class="line">FloatTensor([1, 2, 3])</span><br></pre></td></tr></table></figure><h3 id="torch-add"><a href="#torch-add" class="headerlink" title="torch.add()"></a>torch.add()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.add(input, value, out=None)</span><br></pre></td></tr></table></figure><p>对输入张量<code>input</code>逐元素加上标量值value，并返回结果到一个新的张量out，即 $out=tensor+value$。</p><p>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>value (Number) – 添加到输入每个元素的数</li><li>out (Tensor, optional) – 结果张量</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.add(input, value=1, other, out=None)</span><br></pre></td></tr></table></figure><p><code>other</code>张量的每个元素乘以一个标量值<code>value</code>，并加到<code>input</code> 张量上。返回结果到输出张量<code>out</code>。即，$out=input+(other∗value)$</p><p>两个张量 <code>input and other</code>的尺寸<strong>不需要匹配</strong>，但元素总数必须一样。</p><p>注意 :当两个张量形状不匹配时，输入张量的形状会作为输出张量的尺寸。</p><p>参数:</p><ul><li>input (Tensor) – 第一个输入张量</li><li>value (Number) – 用于第二个张量的尺寸因子</li><li>other (Tensor) – 第二个输入张量</li><li>out (Tensor, optional) – 结果张量</li></ul><h3 id="torch-addcdiv"><a href="#torch-addcdiv" class="headerlink" title="torch.addcdiv"></a>torch.addcdiv</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>用<code>tensor2</code>对<code>tensor1</code>逐元素相除，然后乘以标量值<code>value</code> 并加到tensor。即，$out=t1/t2*value+t$</p><p>张量的<strong>形状不需要匹配</strong>，但元素数量必须一致。</p><p>如果输入是FloatTensor or DoubleTensor类型，则<code>value</code>必须为实数，否则须为整数。</p><p>参数：</p><ul><li>tensor (Tensor) – 张量，输出</li><li>value (Number, optional) – 标量，对 tensor1 ./ tensor2 进行相乘</li><li>tensor1 (Tensor) – 张量，作为被除数(分子)</li><li>tensor2 (Tensor) –张量，作为除数(分母)</li><li>out (Tensor, optional) – 输出张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t = torch.randn(1, 6)</span><br><span class="line">&gt;&gt;&gt; t1 = torch.randn(1, 6)</span><br><span class="line">&gt;&gt;&gt; t2 = torch.randn(6, 1)</span><br><span class="line">&gt;&gt;&gt; torch.addcdiv(t, 0.1, t1, t2)</span><br><span class="line"></span><br><span class="line"> 0.0122 -0.0188 -0.2354</span><br><span class="line"> 0.7396 -1.5721  1.2878</span><br><span class="line">[torch.FloatTensor of size 2x3]</span><br></pre></td></tr></table></figure><h3 id="torch-addcmul"><a href="#torch-addcmul" class="headerlink" title="torch.addcmul"></a>torch.addcmul</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.addcmul(tensor, value=1, tensor1, tensor2, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>用<code>tensor2</code>对<code>tensor1</code>逐元素相乘，并对结果乘以标量值<code>value</code>然后加到tensor。 张量的形状不需要匹配，但元素数量必须一致。 </p><p>如果输入是FloatTensor or DoubleTensor类型，则<code>value</code>必须为实数，否则须为整数。</p><p>参数：</p><ul><li>tensor (Tensor) – 张量，输出</li><li>value (Number, optional) – 标量，对 tensor1 . tensor2 进行相乘</li><li>tensor1 (Tensor) – 张量，作为乘子1</li><li>tensor2 (Tensor) –张量，作为乘子2</li><li>out (Tensor, optional) – 输出张量</li></ul><h3 id="torch-mul"><a href="#torch-mul" class="headerlink" title="torch.mul"></a>torch.mul</h3><ol><li>标量</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.mul(input, value, out=None)</span><br></pre></td></tr></table></figure><p>用<strong>标量值value</strong>乘以输入<code>input</code>的每个元素，并返回一个新的结果张量。 $out=tensor∗value$</p><p>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>value (Number) – 乘到每个元素的数</li><li>out (Tensor, optional) – 输出张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(3)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.9374</span><br><span class="line">-0.5254</span><br><span class="line">-0.6069</span><br><span class="line">[torch.FloatTensor of size 3]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.mul(a, 100)</span><br><span class="line"></span><br><span class="line">-93.7411</span><br><span class="line">-52.5374</span><br><span class="line">-60.6908</span><br><span class="line">[torch.FloatTensor of size 3]</span><br></pre></td></tr></table></figure><ol><li>张量</li></ol><ul><li>对应元素相乘</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.mul(input, other, out=None)</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4,4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.7280  0.0598 -1.4327 -0.5825</span><br><span class="line">-0.1427 -0.0690  0.0821 -0.3270</span><br><span class="line">-0.9241  0.5110  0.4070 -1.1188</span><br><span class="line">-0.8308  0.7426 -0.6240 -1.1582</span><br><span class="line">[torch.FloatTensor of size 4x4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; b = torch.randn(2, 8)</span><br><span class="line">&gt;&gt;&gt; b</span><br><span class="line"></span><br><span class="line"> 0.0430 -1.0775  0.6015  1.1647 -0.6549  0.0308 -0.1670  1.0742</span><br><span class="line">-1.2593  0.0292 -0.0849  0.4530  1.2404 -0.4659 -0.1840  0.5974</span><br><span class="line">[torch.FloatTensor of size 2x8]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.mul(a, b)</span><br><span class="line"></span><br><span class="line">-0.0313 -0.0645 -0.8618 -0.6784</span><br><span class="line"> 0.0934 -0.0021 -0.0137 -0.3513</span><br><span class="line"> 1.1638  0.0149 -0.0346 -0.5068</span><br><span class="line">-1.0304 -0.3460  0.1148 -0.6919</span><br><span class="line">[torch.FloatTensor of size 4x4]</span><br></pre></td></tr></table></figure><h3 id="torch-div"><a href="#torch-div" class="headerlink" title="torch.div()"></a>torch.div()</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.div(input, value, out=None)</span><br></pre></td></tr></table></figure><p>将<code>input</code>逐元素除以标量值value，并返回结果到输出张量<code>out</code>。 即 $out=tensor/value$</p><h3 id="torch-sqrt"><a href="#torch-sqrt" class="headerlink" title="torch.sqrt"></a>torch.sqrt</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sqrt(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入<code>input</code>张量每个元素的平方根。</p><p>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>out (Tensor, optional) – 输出张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 1.2290</span><br><span class="line"> 1.3409</span><br><span class="line">-0.5662</span><br><span class="line">-0.0899</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.sqrt(a)</span><br><span class="line"></span><br><span class="line"> 1.1086</span><br><span class="line"> 1.1580</span><br><span class="line">    nan</span><br><span class="line">    nan</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-neg"><a href="#torch-neg" class="headerlink" title="torch.neg"></a>torch.neg</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.neg(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入input 张量按元素取负。 即， $out=−1∗input$<br>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>out (Tensor, optional) – 输出张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(5)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.4430</span><br><span class="line"> 1.1690</span><br><span class="line">-0.8836</span><br><span class="line">-0.4565</span><br><span class="line"> 0.2968</span><br><span class="line">[torch.FloatTensor of size 5]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.neg(a)</span><br><span class="line"></span><br><span class="line"> 0.4430</span><br><span class="line">-1.1690</span><br><span class="line"> 0.8836</span><br><span class="line"> 0.4565</span><br><span class="line">-0.2968</span><br><span class="line">[torch.FloatTensor of size 5]</span><br></pre></td></tr></table></figure><h3 id="torch-pow"><a href="#torch-pow" class="headerlink" title="torch.pow"></a>torch.pow</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.pow(input, exponent, out=None)</span><br></pre></td></tr></table></figure><p>对输入<code>input</code>的按元素求<code>exponent</code>次幂值，并返回结果张量。 幂值<code>exponent</code> 可以为单一 <code>float</code> 数或者与<code>input</code><strong>相同元素数</strong>的张量。</p><ul><li>当幂值为标量时，执行操作：<br>$out_i=x^{exponent}$</li><li>当幂值为张量时，执行操作：<br>$out_i=x^{exponent_i}$</li></ul><p>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>exponent (float or Tensor) – 幂值</li><li>out (Tensor, optional) – 输出张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.5274</span><br><span class="line">-0.8232</span><br><span class="line">-2.1128</span><br><span class="line"> 1.7558</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.pow(a, 2)</span><br><span class="line"></span><br><span class="line"> 0.2781</span><br><span class="line"> 0.6776</span><br><span class="line"> 4.4640</span><br><span class="line"> 3.0829</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; exp = torch.arange(1, 5)</span><br><span class="line">&gt;&gt;&gt; a = torch.arange(1, 5)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; exp</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.pow(a, exp)</span><br><span class="line"></span><br><span class="line">   1</span><br><span class="line">   4</span><br><span class="line">  27</span><br><span class="line"> 256</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><p>同样底数可以为张量，指数为张量。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.pow(base, input, out=None)</span><br></pre></td></tr></table></figure><p><code>base</code> 为标量浮点值,<code>input</code>为张量， 返回的输出张量 out 与输入张量相同形状。</p><p>执行操作为:<br>$out_i=base^{input_i}$</p><h3 id="torch-exp"><a href="#torch-exp" class="headerlink" title="torch.exp"></a>torch.exp</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.exp(tensor, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入<code>input</code>张量每个元素的指数。</p><h3 id="torch-log"><a href="#torch-log" class="headerlink" title="torch.log"></a>torch.log</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.log(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>计算<code>input</code> 的自然对数。</p><h3 id="torch-acos-input-out-None-→-Tensor"><a href="#torch-acos-input-out-None-→-Tensor" class="headerlink" title="torch.acos(input, out=None) → Tensor"></a>torch.acos(input, out=None) → Tensor</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.acos(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入张量每个元素的反余弦。 </p><p>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>out (Tensor, optional) – 结果张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.6366</span><br><span class="line"> 0.2718</span><br><span class="line"> 0.4469</span><br><span class="line"> 1.3122</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.acos(a)</span><br><span class="line"> 2.2608</span><br><span class="line"> 1.2956</span><br><span class="line"> 1.1075</span><br><span class="line">    nan</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-asin"><a href="#torch-asin" class="headerlink" title="torch.asin"></a>torch.asin</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.asin(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入<code>input</code>张量每个元素的反正弦函数。</p><h3 id="torch-atan"><a href="#torch-atan" class="headerlink" title="torch.atan"></a>torch.atan</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.atan(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入input张量每个元素的反正切函数。</p><h3 id="torch-sin"><a href="#torch-sin" class="headerlink" title="torch.sin"></a>torch.sin</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sin(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入<code>input</code>张量每个元素的正弦。</p><h3 id="torch-cos"><a href="#torch-cos" class="headerlink" title="torch.cos"></a>torch.cos</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cos(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入<code>input</code>张量每个元素的余弦。</p><h3 id="torch-tan"><a href="#torch-tan" class="headerlink" title="torch.tan"></a>torch.tan</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.tan(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入<code>input</code>张量每个元素的正切。</p><h3 id="torch-sinh"><a href="#torch-sinh" class="headerlink" title="torch.sinh"></a>torch.sinh</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sinh(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入<code>input</code>张量每个元素的双曲正弦。</p><h3 id="torch-cosh"><a href="#torch-cosh" class="headerlink" title="torch.cosh"></a>torch.cosh</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.cosh(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入<code>input</code>张量每个元素的双曲余弦。</p><h3 id="torch-tanh"><a href="#torch-tanh" class="headerlink" title="torch.tanh"></a>torch.tanh</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.tanh(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入<code>input</code>张量每个元素的双曲正切。</p><h3 id="torch-ceil"><a href="#torch-ceil" class="headerlink" title="torch.ceil"></a>torch.ceil</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.ceil(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>天井函数，对输入<code>input</code>张量每个元素向上取<strong>整</strong>, 即取不小于每个元素的最小整数，并返回结果到输出。</p><p>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>out (Tensor, optional) – 输出张量</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 1.3869</span><br><span class="line"> 0.3912</span><br><span class="line">-0.8634</span><br><span class="line">-0.5468</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.ceil(a)</span><br><span class="line"></span><br><span class="line"> 2</span><br><span class="line"> 1</span><br><span class="line">-0</span><br><span class="line">-0</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-floor"><a href="#torch-floor" class="headerlink" title="torch.floor"></a>torch.floor</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.floor(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>床函数: 返回一个新张量，包含输入<code>input</code>张量每个元素的<code>floor</code>，即不小于元素的最大整数。向下取整。</p><h3 id="torch-round"><a href="#torch-round" class="headerlink" title="torch.round"></a>torch.round</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.round(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，将输入<code>input</code>张量每个元素<strong>舍入到最近的整数(四舍五入)</strong>。</p><p>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>out (Tensor, optional) – 输出张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 1.2290</span><br><span class="line"> 1.3409</span><br><span class="line">-0.5662</span><br><span class="line">-0.0899</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.round(a)</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 1</span><br><span class="line">-1</span><br><span class="line">-0</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-trunc"><a href="#torch-trunc" class="headerlink" title="torch.trunc"></a>torch.trunc</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.trunc(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回一个新张量，包含输入<code>input</code>张量每个元素的截断值(标量<code>x</code>的截断值是最接近其的整数，其比x更接近零。简而言之，有符号数的小数部分被舍弃)。</p><p>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>out (Tensor, optional) – 输出张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line">-0.4972</span><br><span class="line"> 1.3512</span><br><span class="line"> 0.1056</span><br><span class="line">-0.2650</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.trunc(a)</span><br><span class="line"></span><br><span class="line">-0</span><br><span class="line"> 1</span><br><span class="line"> 0</span><br><span class="line">-0</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-clamp"><a href="#torch-clamp" class="headerlink" title="torch.clamp"></a>torch.clamp</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.clamp(input, min, max, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>将输入<code>input</code>张量每个元素的夹紧到区间 $[min,max]$，并返回结果到一个新张量。</p><p>公式：</p><script type="math/tex; mode=display">y_i = \begin{cases}min, if\ x_i < min\\ x_i, if \ min <= x_i <= max    \\max, if \ x_i > max\end{cases}</script><p>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>min (Number) – 限制范围下限</li><li>max (Number) – 限制范围上限</li><li>out (Tensor, optional) – 输出张量</li></ul><p>将输出限制到不小于0.5</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.clamp(a, min=0.5)</span><br></pre></td></tr></table></figure><p>将输出限制到不大于0.5</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.clamp(a, max=0.5)</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line"></span><br><span class="line"> 1.3869</span><br><span class="line"> 0.3912</span><br><span class="line">-0.8634</span><br><span class="line">-0.5468</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.clamp(a, min=-0.5, max=0.5)</span><br><span class="line"></span><br><span class="line"> 0.5000</span><br><span class="line"> 0.3912</span><br><span class="line">-0.5000</span><br><span class="line">-0.5000</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-fmod"><a href="#torch-fmod" class="headerlink" title="torch.fmod"></a>torch.fmod</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.fmod(input, divisor, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>计算除法余数。 </p><p>除数与被除数可能同时含有整数和浮点数。此时，余数的正负与被除数相同。</p><p>参数：</p><ul><li>input (Tensor) – 被除数 </li><li>divisor (Tensor or float) – 除数，一个数或与被除数相同类型的张量 </li><li>out (Tensor, optional) – 输出张量</li></ul><p><strong>torch.remainde</strong>r用法相同。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.remainder(input, divisor, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.fmod(torch.Tensor([-3, -2, -1, 1, 2, 3]), 2)</span><br><span class="line">torch.FloatTensor([-1, -0, -1, 1, 0, 1])</span><br><span class="line">&gt;&gt;&gt; torch.fmod(torch.Tensor([1, 2, 3, 4, 5]), 1.5)</span><br><span class="line">torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5])</span><br></pre></td></tr></table></figure><h3 id="torch-frac"><a href="#torch-frac" class="headerlink" title="torch.frac"></a>torch.frac</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.frac(tensor, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>返回每个元素的分数部分。</p><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.frac(torch.Tensor([1, 2.5, -3.2])</span><br><span class="line">torch.FloatTensor([0, 0.5, -0.2])</span><br></pre></td></tr></table></figure><h3 id="torch-lerp"><a href="#torch-lerp" class="headerlink" title="torch.lerp"></a>torch.lerp</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.lerp(start, end, weight, out=None)</span><br></pre></td></tr></table></figure><p>对两个张量以<code>start</code>，end做<strong>线性插值</strong>， 将结果返回到输出张量。</p><p>即，$out_i=start_i+weight∗(end_i−start_i)$<br>参数：</p><ul><li>start (Tensor) – 起始点张量</li><li>end (Tensor) – 终止点张量</li><li>weight (float) – 插值公式的weight</li><li>out (Tensor, optional) – 结果张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; start = torch.arange(1, 5)</span><br><span class="line">&gt;&gt;&gt; end = torch.Tensor(4).fill_(10)</span><br><span class="line">&gt;&gt;&gt; start</span><br><span class="line"></span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3</span><br><span class="line"> 4</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; end</span><br><span class="line"></span><br><span class="line"> 10</span><br><span class="line"> 10</span><br><span class="line"> 10</span><br><span class="line"> 10</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.lerp(start, end, 0.5)</span><br><span class="line"></span><br><span class="line"> 5.5000</span><br><span class="line"> 6.0000</span><br><span class="line"> 6.5000</span><br><span class="line"> 7.0000</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure><h3 id="torch-sign"><a href="#torch-sign" class="headerlink" title="torch.sign"></a>torch.sign</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.sign(input, out=None) → Tensor</span><br></pre></td></tr></table></figure><p>符号函数：返回一个新张量，包含输入<code>input</code>张量每个元素的正负。</p><p>参数：</p><ul><li>input (Tensor) – 输入张量</li><li>out (Tensor, optional) – 输出张量</li></ul><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; a = torch.randn(4)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">-0.6366</span><br><span class="line"> 0.2718</span><br><span class="line"> 0.4469</span><br><span class="line"> 1.3122</span><br><span class="line">[torch.FloatTensor of size 4]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; torch.sign(a)</span><br><span class="line"></span><br><span class="line">-1</span><br><span class="line"> 1</span><br><span class="line"> 1</span><br><span class="line"> 1</span><br><span class="line">[torch.FloatTensor of size 4]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Nginx配置同一端口访问不同路径下的文件</title>
      <link href="/2021/02/01/%E4%BD%BF%E7%94%A8Nginx%E9%85%8D%E7%BD%AE%E5%90%8C%E4%B8%80%E7%AB%AF%E5%8F%A3%E8%AE%BF%E9%97%AE%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6/"/>
      <url>/2021/02/01/%E4%BD%BF%E7%94%A8Nginx%E9%85%8D%E7%BD%AE%E5%90%8C%E4%B8%80%E7%AB%AF%E5%8F%A3%E8%AE%BF%E9%97%AE%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="使用Nginx配置同一端口访问不同路径下的文件"><a href="#使用Nginx配置同一端口访问不同路径下的文件" class="headerlink" title="使用Nginx配置同一端口访问不同路径下的文件"></a>使用Nginx配置同一端口访问不同路径下的文件</h1><ol><li>编辑配置文件</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"># http  </span><br><span class="line">  server &#123;</span><br><span class="line">        listen       80 default_server;</span><br><span class="line">        listen       [::]:80 default_server;</span><br><span class="line">        server_name www.asimok.com;</span><br><span class="line">        # Load configuration files for the default server block.</span><br><span class="line">        include /etc/nginx/default.d/*.conf;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">        root /root/mq_blog/public;</span><br><span class="line">        index index.html;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 404 /404.html;</span><br><span class="line">        location = /404.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 500 502 503 504 /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        return 301 https://$host$request_uri;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">#https</span><br><span class="line">   server&#123;</span><br><span class="line">        #监听443端口</span><br><span class="line">        listen 443 ssl;</span><br><span class="line">        #对应的域名，把baofeidyz.com改成你们自己的域名就可以了</span><br><span class="line">        server_name www.asimok.com;</span><br><span class="line">        #从腾讯云获取到的第一个文件的全路径</span><br><span class="line">        ssl_certificate /etc/ssl/1_www.asimok.site_bundle.crt;</span><br><span class="line">        #从腾讯云获取到的第二个文件的全路径</span><br><span class="line">        ssl_certificate_key /etc/ssl/2_www.asimok.site.key;</span><br><span class="line">        ssl_session_timeout 5m;</span><br><span class="line">        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;</span><br><span class="line">        ssl_prefer_server_ciphers on;</span><br><span class="line">        #这是我的主页访问地址，因为使用的是静态的html网页，所以直接使用location就可以完成了。</span><br><span class="line">        location / &#123;</span><br><span class="line">               #文件夹</span><br><span class="line">               root /root/mq_blog/public;</span><br><span class="line">               #主页文件</span><br><span class="line">               index index.html;</span><br><span class="line">        &#125;</span><br><span class="line"># 大西瓜</span><br><span class="line">        location /daxigua &#123;</span><br><span class="line">               alias /root/daxigua;</span><br><span class="line">               index index.html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ol><li>保存退出 </li><li>对配置文件进行校验</li></ol><p>保存配置文件之后执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -t</span><br></pre></td></tr></table></figure><p>susccessful即可</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/night1/image-20201209112907309.png" alt="image-20201209112907309"></p><ol><li>重启nginx服务</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><ol><li>重新加载配置文件</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><h2 id="多个路径配置"><a href="#多个路径配置" class="headerlink" title="多个路径配置"></a>多个路径配置</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location /daxigua &#123;</span><br><span class="line">           alias /root/daxigua;</span><br><span class="line">           index index.html;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>使用root会将location后的daxigua追加在路径的尾部，在访问时就会访问到/root/daxigua/daxigua路径下去。<br>将root改成alias则不会将daxigua追加在路径尾部，访问时就为正确路径/root/daxigua。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p><a href="https://www.asimok.site/daxigua">https://www.asimok.site/daxigua</a></p><p><a href="https://www.asimok.site">https://www.asimok.site</a></p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-hop Question Answering via Reasoning Chains</title>
      <link href="/2021/01/29/Multi-hop%20Question%20Answering%20via%20Reasoning%20Chains%20/"/>
      <url>/2021/01/29/Multi-hop%20Question%20Answering%20via%20Reasoning%20Chains%20/</url>
      
        <content type="html"><![CDATA[<h1 id="Multi-hop-Question-Answering-via-Reasoning-Chains"><a href="#Multi-hop-Question-Answering-via-Reasoning-Chains" class="headerlink" title="Multi-hop Question Answering via Reasoning Chains"></a>Multi-hop Question Answering via Reasoning Chains</h1><blockquote><p><a href="https://arxiv.org/abs/1910.02610">论文：2019-Multi-hop Question Answering via Reasoning Chains</a></p><p>基于推理链的多跳问题回答</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        本文提出了一种在文本中提取离散推理链的方法，模型不依赖于gold annotated chains or “supporting facts，使用基于命名实体识别和共指消解的启发式算法得到的pseudogold reasoning chains。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210124163210.png" alt="image-20210124163210620"></p><blockquote><p>推理链是一系列的句子，逻辑上把问题与一个事实联系起来，这个事实与给出一个合理的答案相关（或部分相关）。</p></blockquote><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>提出一个two-stage model</p><blockquote><p>extractor model：提取推理路径。extractor模型对句子序列进行评分，并通过<strong>beam search</strong>生成<strong>n-best</strong>链列表。</p><p>answer module：将提取的推理链输入到BERT中提取最终的答案。</p></blockquote><h3 id="Learning-to-Extract-Chains"><a href="#Learning-to-Extract-Chains" class="headerlink" title="Learning to Extract Chains"></a>Learning to Extract Chains</h3><h4 id="Heuristic-oracle-chain-construction"><a href="#Heuristic-oracle-chain-construction" class="headerlink" title="Heuristic oracle chain construction"></a>Heuristic oracle chain construction</h4><ul><li><p>使用命名实体识别提取句子中的实体，如果两个句子中有匹配的实体，则在这两个节点上添加一条边。对段落中的所有句子进行这一操作。</p></li><li><p>从问题的节点开始，搜索所有可能的推理链。</p></li></ul><p>使用两种方式选择heuristic oracles：</p><blockquote><p>Shortest Path：选择最短的推理链。</p><p>Question Overlap：计算每条链的Rouge-F1，选择得分最高的推理链，这样可以找到更完整的答案链。</p></blockquote><h4 id="Chain-extraction-model"><a href="#Chain-extraction-model" class="headerlink" title="Chain extraction model"></a>Chain extraction model</h4><blockquote><p>输入：文档+问题</p><p>处理流程：sentence encoding and chain prediction</p></blockquote><h5 id="Sentence-Encoding"><a href="#Sentence-Encoding" class="headerlink" title="Sentence Encoding"></a>Sentence Encoding</h5><ul><li>将输入问题和段落使用BERT编码。句子可以从段落中提取出来。</li></ul><script type="math/tex; mode=display">s_j = Span Extractor(p_i, s^{START}_j , s^{END}_j )</script><blockquote><p>$s_j$表示段落$p_i$中第i句话</p></blockquote><ul><li><p>BERT-para</p><blockquote><p>本文设计的paragraph-factored model，比在整个上下文运行BERT更高的效率和可拓展性。</p><p>使用bert-base-uncased预训练模型。</p></blockquote></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210124182342.png" alt="image-20210124182342557"></p><h5 id="Chain-Prediction"><a href="#Chain-Prediction" class="headerlink" title="Chain Prediction"></a>Chain Prediction</h5><p>​        将所有编码的句子表示作为一个句子包，并采用基于LSTM的pointer network来提取推理链。</p><blockquote><p>在第一步中，使用问题q的max-pooled表示初始化pointer network中的隐藏状态$h_0$，并提供一个特殊的令牌SOS作为第一个输入。</p></blockquote><script type="math/tex; mode=display">P(c_t= i|c_1, . . . , c_{t−1}, s) = softmax(α)[i]</script><script type="math/tex; mode=display">α_i= W[h_{t−1}; s_{c_{t−1}};h_{t−1} \odot s_{c_{t−1}}]</script><blockquote><p>$c<em>1, . . . , c</em>{t−1}$：推理链中句子索引。</p><p>W：要学习的权重。</p></blockquote><h5 id="Training-the-Chain-Extractor"><a href="#Training-the-Chain-Extractor" class="headerlink" title="Training the Chain Extractor"></a>Training the Chain Extractor</h5><p>step t的损失：</p><script type="math/tex; mode=display">loss_t=-log(P(c∗t)|c^∗_1,...,c^∗_{t−1}s)</script><blockquote><p>$c^∗_1$：目标句子</p></blockquote><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>WikiHop</li><li>HotpotQA</li></ul><h2 id="性能水平-amp-结论"><a href="#性能水平-amp-结论" class="headerlink" title="性能水平&amp;结论"></a>性能水平&amp;结论</h2><h3 id="Comparison-of-Chain-Extraction-Methods"><a href="#Comparison-of-Chain-Extraction-Methods" class="headerlink" title="Comparison of Chain Extraction Methods"></a>Comparison of Chain Extraction Methods</h3><ul><li>使用更多的上下文有助于链提取器找到相关的句子。</li><li>one-best推理连通常包含答案。</li><li>Q-Overlap有助于找到更多的支持事实。</li><li>可以通过跨多个链使用并集来提高性能。（BRRT-Para(top5)）</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210124194515.png" alt="image-20210124194515730"></p><h3 id="Results-compared-to-other-systems"><a href="#Results-compared-to-other-systems" class="headerlink" title="Results compared to other systems"></a>Results compared to other systems</h3><blockquote><p>HotpotQA：使用RoBERTa 预模型作为权重。</p></blockquote><ul><li>性能超过了使用标记支持事实的模型，说明本文提出的heuristicallyextracted chains可以有效的替代标记支持事实进行监督。</li></ul><p><img src="/Users/maqi/Library/Application Support/typora-user-images/image-20210129092022793.png" alt="image-20210129092022793" style="zoom:50%;" /></p><h3 id="Evaluation-of-chains"><a href="#Evaluation-of-chains" class="headerlink" title="Evaluation of chains"></a>Evaluation of chains</h3><ul><li><p>有序抽取优于无序抽取。</p><blockquote><p>在HotpotQA-Hard上，更需要多跳推理。</p></blockquote></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210129092925.png" alt="image-20210129092925076"></p><ul><li>链接提取的性能已接近HotpotQA上的性能极限。</li><li>Table4中人类评估的得分与模型在oracle上的F1的分相近，表明本文提出的模型不再需要人工注释的支持事实。</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210129093850.png" alt="image-20210129093850960"></p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> HotpotQA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python——pickle模块的详解</title>
      <link href="/2021/01/29/python%E2%80%94%E2%80%94pickle%E6%A8%A1%E5%9D%97%E7%9A%84%E8%AF%A6%E8%A7%A3/"/>
      <url>/2021/01/29/python%E2%80%94%E2%80%94pickle%E6%A8%A1%E5%9D%97%E7%9A%84%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="python——pickle模块的详解"><a href="#python——pickle模块的详解" class="headerlink" title="python——pickle模块的详解"></a>python——pickle模块的详解</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><ul><li><p>pickle模块实现了用于序列化和反序列化Python对象结构的二进制协议</p></li><li><p>“Pickling”是将Python对象层次结构转换为字节流的过程， “unpickling”是反向操作，从而将字节流（来自二进制文件或类似字节的对象）转换回对象层次结构。</p></li><li><p>pickle协议和JSON（JavaScript Object Notation）的区别 ：</p><ol><li>JSON是一种文本序列化格式（它输出unicode文本，虽然大部分时间它被编码utf-8），而pickle是二进制序列化格式;</li><li>JSON是人类可读的，而pickle则不是;</li><li>JSON是可互操作的，并且在Python生态系统之外广泛使用，而pickle是特定于Python的;</li></ol></li><li>pickle可以表示极其庞大的Python类型（其中许多是自动的，通过巧妙地使用Python的内省工具;复杂的案例可以通过实现特定的对象API来解决）。</li><li>pickle 数据格式是特定于Python的。它的优点是没有外部标准强加的限制， 但是这意味着非Python程序可能无法重建pickled Python对象。</li></ul><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><h3 id="dumps"><a href="#dumps" class="headerlink" title="dumps()"></a>dumps()</h3><ul><li>序列化对象层次结构。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.dump（obj，file，protocol = None，*，fix_imports = True ）</span><br></pre></td></tr></table></figure><p>将obj对象的编码pickle编码表示写入到文件对象中。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.load（file，*，fix_imports = True，encoding =“ASCII”，errors =“strict” ）</span><br></pre></td></tr></table></figure><p>从打开的文件对象 文件中读取pickle对象表示，并返回其中指定的重构对象层次结构。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.dumps（obj，protocol = None，*，fix_imports = True ）</span><br></pre></td></tr></table></figure><p>将对象的pickled表示作为bytes对象返回，而不是将其写入文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pickle.loads（bytes_object，*，fix_imports = True，encoding =“ASCII”，errors =“strict” ）</span><br></pre></td></tr></table></figure><p>从bytes对象读取pickle对象层次结构并返回其中指定的重构对象层次结构。</p><h3 id="loads"><a href="#loads" class="headerlink" title="loads()"></a>loads()</h3><ul><li>对数据流进行反序列化。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pickle</span><br><span class="line">import io</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    path = &#x27;test&#x27;</span><br><span class="line">    f = open(path, &#x27;wb&#x27;)</span><br><span class="line">    data = &#123;&#x27;a&#x27;:123, &#x27;b&#x27;:&#x27;ads&#x27;, &#x27;c&#x27;:[[1,2],[3,4]]&#125;</span><br><span class="line">    pickle.dump(data, f)</span><br><span class="line">    f.close()</span><br><span class="line"></span><br><span class="line">    f1 = open(path, &#x27;rb&#x27;)</span><br><span class="line">    data1 = pickle.load(f1)</span><br><span class="line">    print(data1)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> pickle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python——type hints</title>
      <link href="/2021/01/29/python%E2%80%94%E2%80%94type%20hints/"/>
      <url>/2021/01/29/python%E2%80%94%E2%80%94type%20hints/</url>
      
        <content type="html"><![CDATA[<h1 id="python——type-hints"><a href="#python——type-hints" class="headerlink" title="python——type hints"></a>python——type hints</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><ul><li>type hints 主要是要指示函数的输入和输出的数据类型，数据类型在typing 包中，基本类型有str,list,dict等等。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def hello(name: str) -&gt; None:</span><br><span class="line"> </span><br><span class="line">    print(&#x27;hello &#123;&#125;&#x27;.format(name))</span><br></pre></td></tr></table></figure><h2 id="常用类型"><a href="#常用类型" class="headerlink" title="常用类型"></a>常用类型</h2><h3 id="Union"><a href="#Union" class="headerlink" title="Union"></a>Union</h3><ul><li>Union 是当有多种可能的数据类型时使用，比如函数有可能根据不同情况有时返回str或返回list，那么就可以写成<code>Union[list, str]</code></li></ul><h3 id="Optional"><a href="#Optional" class="headerlink" title="Optional"></a>Optional</h3><ul><li>Optional是Union的一个简化， 当数据类型中有可能是None时，比如有可能是str也有可能是None，则Optional[str], 相当于Union[str, None]. <strong>注意</strong>和函数有默认参数None有区别，不可省略默认参数，如下示例：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">原始：def func(args = None):</span><br><span class="line">错：def func(args:Optional[str]) -&gt; None:</span><br><span class="line">对：def func(args:Optional[str] = None) -&gt; None: #依然要保留默认赋值</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> type hints </tag>
            
            <tag> Optional </tag>
            
            <tag> Union </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>环境配置</title>
      <link href="/2021/01/29/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2021/01/29/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h1><h2 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h2><p>配置文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/.pip/pip.conf</span><br></pre></td></tr></table></figure><p>更换国内镜像源：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">[install]</span><br><span class="line">trusted-host = mirrors.aliyun.com</span><br></pre></td></tr></table></figure><h2 id="TensorFlow-gpu"><a href="#TensorFlow-gpu" class="headerlink" title="TensorFlow-gpu"></a>TensorFlow-gpu</h2><blockquote><p>为避免出错 pytorch和tensorflow都使用conda install安装</p></blockquote><ol><li><p><strong>anconda</strong><br> <code>conda create -n tf python=3.6</code></p></li><li><p><strong>cuda deb</strong></p></li><li><p><strong>pytorch 官网 自动安装cudnn</strong></p><blockquote><p><a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p></blockquote><p> <code>conda install pytorch torchvision torchaudio cudatoolkit=10.1 -c pytorch</code><br> 测试：</p><pre><code>     `import torch`     `torch.cuda.is_available()`</code></pre></li><li><p><strong>TensorFlow gpu</strong><br> <code>conda install tensorflow-gpu</code><br> 测试:</p><p> ​        <code>import tensorflow as tf</code></p><p> ​        <code>tf.test.is_gpu_available()</code></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 环境变量 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AllenNLP实践</title>
      <link href="/2021/01/26/allennlp/"/>
      <url>/2021/01/26/allennlp/</url>
      
        <content type="html"><![CDATA[<h1 id="AllenNLP"><a href="#AllenNLP" class="headerlink" title="AllenNLP"></a>AllenNLP</h1><ul><li><a href="https://allennlp.org/">https://allennlp.org/</a></li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conda create -n allennlp python=3.7</span><br><span class="line">pip install allennlp</span><br><span class="line">pip install allennlp-models</span><br><span class="line">pip install allennlp_optuna</span><br><span class="line">git clone https://github.com/allenai/allennlp-server</span><br><span class="line">cd allennlp-server</span><br><span class="line">pip install --editable .</span><br></pre></td></tr></table></figure><h2 id="安装老版本"><a href="#安装老版本" class="headerlink" title="安装老版本"></a>安装老版本</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n allennlp python=3.6.9</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AllenNLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Simple and Effective Model for Answering Multi-span Questions</title>
      <link href="/2021/01/20/A%20Simple%20and%20Effective%20Model%20for%20Answering%20Multi-span%20Questions/"/>
      <url>/2021/01/20/A%20Simple%20and%20Effective%20Model%20for%20Answering%20Multi-span%20Questions/</url>
      
        <content type="html"><![CDATA[<h1 id="A-Simple-and-Effective-Model-for-Answering-Multi-span-Questions"><a href="#A-Simple-and-Effective-Model-for-Answering-Multi-span-Questions" class="headerlink" title="A Simple and Effective Model for Answering Multi-span Questions"></a>A Simple and Effective Model for Answering Multi-span Questions</h1><blockquote><p>论文：EMNLP20-A Simple and Effective Model for Answering Multi-span Questions</p><p>代码：<a href="https://github.com/eladsegal/tag-based-multi-span-extraction">https://github.com/eladsegal/tag-based-multi-span-extraction</a></p><p>multi-span architecture (TASE: TAg-based Span Extraction)</p><p>traditional single-span extraction (SSE)</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        传统的阅读理解模型将问题的答案限制在单个跨度，对于答案处于多跨度的问题会有限制，本文提出了一个简单的体系结构，通过将任务转换为序列标记问题来回答多跨度问题，为每个输入token预测是否应该将其作为输出的一部分。</p><p>阅读理解(RC)任务：</p><ul><li>在给定一个问题和上下文的情况下提供答案。</li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><h3 id="Single-span-Model"><a href="#Single-span-Model" class="headerlink" title="Single-span Model"></a>Single-span Model</h3><p>question-context-answer triplets $(q<em>i, c_i, a_i)^N</em>{i=1}$</p><p>目标：学习一个函数将一个question-context对映射到answer。</p><p>将question and context编码：</p><script type="math/tex; mode=display">h = Encoder([q, c])</script><p>$h$是所有输入token的上下文表示序列:</p><script type="math/tex; mode=display">h = (h_1, . . . , h_m)</script><p>前馈网络:</p><script type="math/tex; mode=display">p_{start}^ i = softmax (f_{start}(h_1), . . . , f_{start}(h_m))_i</script><script type="math/tex; mode=display">p_{end}^ i = softmax (f_{end}(h_1), . . . , f_{end}(h_m))_i</script><blockquote><p>通过$f<em>{start}(hi) and f</em>{end}(hi)$计算每个token的得分，再通过softmax得到概率分布。</p></blockquote><p>提取答案范围：</p><script type="math/tex; mode=display">(s, e) = \underset {s \le e} {arg max}  \ p_s^{start}  p_e^{end}</script><h3 id="Multi-span-Model"><a href="#Multi-span-Model" class="headerlink" title="Multi-span Model"></a>Multi-span Model</h3><h4 id="Span-Extraction-as-Sequence-Tagging"><a href="#Span-Extraction-as-Sequence-Tagging" class="headerlink" title="Span Extraction as Sequence Tagging"></a>Span Extraction as Sequence Tagging</h4><p>与Single-span Model相同的是：使用相同的上下文表示$h$</p><p>不同的是：不是预测开始和结束概率，而是为每个标记在一组标签上输出概率分布。</p><p>two tagging schemes：</p><ul><li><p>BIO</p><blockquote><p>B：表示输出范围的第一个标记</p><p>I：表示范围中的后续标记</p><p>O：表示不属于输出范围的标记</p></blockquote></li><li><p>IO</p><blockquote><p>I：单词被标记为答案的一部分</p><p>O：单词未被标记为答案的一部分</p></blockquote></li></ul><blockquote><p>本文选择较为简单的<strong>IO</strong></p></blockquote><p><em>这里给一个例子：</em></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210118200430.png" alt="image-20210118200430617" style="zoom:50%;" /></p><p>第i个token的标签的概率：</p><script type="math/tex; mode=display">p_i= softmax(f(h_i))</script><h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><p>给定的答案跨度在输入中多次出现的情况：</p><blockquote><p>input：“X Y Z Y Z”</p><p>answer span：{“X”, “Z”},</p><p>taggings：B O B O B, B O B O O, and B O O O B.</p><ul><li>X必然会出现</li><li>Y必然不会出现</li><li>Z至少出现1次</li></ul></blockquote><p><strong>在这种情况下不能明确确定基本事实BIO。</strong></p><p>为了处理这种情况，列举了所有可能出现的标签组合：</p><script type="math/tex; mode=display">possibly-correct taggings, \tau</script><p>通过最大化所有可能的正确标记的边界概率来训练模型</p><script type="math/tex; mode=display">\log\ p(\tau | h) = log \sum_{T ∈ \tau}(\Pi^m_{i=1}(p_i[T_i]))</script><blockquote><p>$p_i[T_i]$是token i拥有标签$T_i$的概率。</p><p>当p为1是损失最小。</p></blockquote><h4 id="Decoding-Spans-from-a-Tagging"><a href="#Decoding-Spans-from-a-Tagging" class="headerlink" title="Decoding Spans from a Tagging"></a>Decoding Spans from a Tagging</h4><script type="math/tex; mode=display">\hat{T} = \underset{T∈\nu}{arg\max} (\Pi^m_{i=1}(p_i[T_i]))</script><blockquote><p>$\hat{T}$：最有可能的标记</p><p>$\nu$：所有有效标记的集合 </p></blockquote><p>对于<strong>IO</strong>标签，所有标签均有效，并且通过独立预测每个token中概率最高的标签来实现最大化。</p><blockquote><p>由于答案跨度在RC任务中从不相邻，因此<strong>IO</strong>标记通过选择所有以<strong>I</strong>连续标记的最大跨度来生成一组跨度。</p></blockquote><h3 id="“Multi-Head”-Models"><a href="#“Multi-Head”-Models" class="headerlink" title="“Multi-Head” Models"></a>“Multi-Head” Models</h3><p>一些RC数据集包含的一些问题，其输出不一定是跨度的，例如：通过算术运算获取答案。</p><p>对此一些模型使用了<strong><em>multi-head architecture</em></strong></p><script type="math/tex; mode=display">p_z(a | q, c) = p_z(a | h)</script><blockquote><p>每个head z是一个小模块，将上下文表示h作为输入并计算答案的概率分布。</p></blockquote><p>为了确定哪个问题需要使用哪个头，需要训练一个附加模型：</p><script type="math/tex; mode=display">p_{head}(z | q, c) = p_{head}(z | h)</script><p>答案的概率分布：</p><script type="math/tex; mode=display">p(a | q, c) = \sum_z p_{head}(z | q, c) · p_z(a | q, c)</script><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li><p>DROP</p><blockquote><p>DROP’s leaderboard：<a href="https://leaderboard.allenai.org/drop/submissions/public">https://leaderboard.allenai.org/drop/submissions/public</a></p></blockquote></li><li><p>QUOREF</p></li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20210119092212.png" alt="image-20210119092212691"></p><ul><li><p>模型比较：</p><p>在DROP上:</p><p>​        使用$BERT<em>{LARGE}$作为encoder的$TASE</em>{BIO}+SSE (BERT<em>{LARGE})$超越所有处理multi-span questions的模型。相比$BERT-C</em>{ALC}$和$MTMSN$效果较为显著。</p><p>在QUOREF上:</p><p>​        处理multi-span questions是性能远超$CorefRoBERTa_{LARGE}$ 20个百分点。</p></li><li><p>跨度提取架构比较</p><p>​        在DROP和QUOREF中，用多跨度提取替换单跨度提取可以显著改善多跨度问题的性能，而单跨度问题的性能较之前变化不大。这表明多跨度架构本身可以用作通用跨度提取方法。</p></li><li><p>tagging方案的效果比较</p><p>​        <strong>BIO</strong>和<strong>IO</strong>方案，结果非常相似。<strong>IO</strong>略占优势。</p></li></ul><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>​        本文提出的的$TASE_{IO} + SSE$模型在整个测试集上都取得了较高的得分。</p><p>​        本文将回答多跨度问题的任务作为序列标记问题，并提出了一个简单的对应多跨度体系结构。 使用多跨度体系结构替换标准的单跨</p><p>度体系结构可以显著改善多跨度问题的结果，而不会损害单跨度问题的性能，从而获得较好的QUOREF结果。 将多跨度架构集成到现有模</p><p>型中可以进一步提高DROP的性能。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> DROP </tag>
            
            <tag> NLP </tag>
            
            <tag> RC </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> QUOREF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>conda创建新环境</title>
      <link href="/2021/01/19/conda%E5%88%9B%E5%BB%BA%E6%96%B0%E7%8E%AF%E5%A2%83/"/>
      <url>/2021/01/19/conda%E5%88%9B%E5%BB%BA%E6%96%B0%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h1 id="conda创建新环境"><a href="#conda创建新环境" class="headerlink" title="conda创建新环境"></a>conda创建新环境</h1><h2 id="创建新环境"><a href="#创建新环境" class="headerlink" title="创建新环境"></a>创建新环境</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n &#x27;环境名&#x27; python=3.6</span><br></pre></td></tr></table></figure><h2 id="删除环境"><a href="#删除环境" class="headerlink" title="删除环境"></a>删除环境</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda remove -n &#x27;环境名&#x27; --all</span><br></pre></td></tr></table></figure><h2 id="重命名环境"><a href="#重命名环境" class="headerlink" title="重命名环境"></a>重命名环境</h2><p>conda 其实没有重命名指令，实现重命名是通过 clone 完成的，分两步：</p><ol><li>先 clone 一份 new name 的环境</li><li>删除 old name 的环境</li></ol><p>例：比如，想把环境env1 重命名成env2</p><ul><li>第1步</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n env2 --clone env1</span><br></pre></td></tr></table></figure><ul><li>第2步</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda remove -n env1 --all</span><br></pre></td></tr></table></figure><ul><li>结果</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda info -e</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>READING AND ANSWERING GIVEN REASONING PATHS</title>
      <link href="/2021/01/15/READING%20AND%20ANSWERING%20GIVEN%20REASONING%20PATHS/"/>
      <url>/2021/01/15/READING%20AND%20ANSWERING%20GIVEN%20REASONING%20PATHS/</url>
      
        <content type="html"><![CDATA[<h1 id="READING-AND-ANSWERING-GIVEN-REASONING-PATHS"><a href="#READING-AND-ANSWERING-GIVEN-REASONING-PATHS" class="headerlink" title="READING AND ANSWERING GIVEN REASONING PATHS"></a>READING AND ANSWERING GIVEN REASONING PATHS</h1><blockquote><p>reader model</p><p>多任务阅读器模型</p></blockquote><h2 id="多任务阅读器模型"><a href="#多任务阅读器模型" class="headerlink" title="多任务阅读器模型"></a>多任务阅读器模型</h2><ul><li><p>阅读理解任务</p><blockquote><p>使用BERT从推理路径中提取答案范围。</p></blockquote></li><li><p>对推理路径重排序</p><blockquote><p> 使用Bert模型对应于CLS标识符位的输出判断推理路径包括答案的概率。根据概率对推理路径重新排序。</p></blockquote></li></ul><script type="math/tex; mode=display">P(E|q) = σ(w_n· u_E) \ \ s.t. \ \ u_E= BERT_{[CLS]}(q, E) ∈ \R^D</script><blockquote><p>$w_n∈ R^D$：权重向量</p><p>$P(E|q)$：推理路径E的概率</p></blockquote><script type="math/tex; mode=display">E_{best}=\underset{E∈E} {arg\ max } \ P(E|q)</script><blockquote><p>$E_{best}$：最佳路径</p></blockquote><script type="math/tex; mode=display">S_{read}= \underset{i,j, i≤j}{arg \ max}\   P^{start}_i P^{end}_j</script><blockquote><p>$S_{read}$：正确答案的范围</p><p>$P^{start}<em>i，P^{end}_j$表示$E</em>{best}$中第i个token和第j个token分别为开始位置和结束位置的概率</p></blockquote><ul><li>增加负例数据：</li></ul><p>​    为了训练我们的读者模型来区分相关和不相关的推理路径，我们对原始训练数据进行了补充，并附加了其他负面示例来模拟不完全的证据。</p><ul><li>损失函数</li></ul><p>目标是跨度预测和重新排序任务的交叉熵损失之和。 问题q及其候选证据E的损失:</p><script type="math/tex; mode=display">L_{read}= L_{span}+ L_{no\_answer}= (− log P^{start}_{y^{start}} − log P^{end}_{y^{end}}) − log P^r</script><blockquote><p>$y^{start}, y^{end}$是 ground-truth的开始和结束。</p><p>$L_{no_answer}$：重新re-ranking model的损失，辨别没有答案的失真推理路径。</p><p>$P^r$： if E is the ground-truth evidence;   $P^r= P(E|q)$,otherwise $P^r= 1 − P(E|q)$.</p></blockquote><p>屏蔽了负样本跨度损失，以避免对跨度预测产生意外影响。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>优化器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">optimizer = BertAdam(optimizer_grouped_parameters,</span><br><span class="line">                                 lr=args.learning_rate,</span><br><span class="line">                                 warmup=args.warmup_proportion,</span><br><span class="line">                                 t_total=num_train_optimization_steps)</span><br></pre></td></tr></table></figure><p>使用dataloader加载训练数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_sampler = DistributedSampler(train_data)</span><br><span class="line">        train_dataloader = DataLoader(</span><br><span class="line">            train_data, sampler=train_sampler, batch_size=args.train_batch_size)</span><br></pre></td></tr></table></figure><p>显示进度</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for _ in trange(int(args.num_train_epochs), desc=&quot;Epoch&quot;):</span><br></pre></td></tr></table></figure><blockquote><p> Epoch: 100%|██████████| 3/3 [00:03&lt;00:00,  1.00s/it]</p></blockquote><p>创建模型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = BertForQuestionAnsweringConfidence.from_pretrained(args.bert_model,</span><br><span class="line">                                                                   cache_dir=os.path.join(</span><br><span class="line">                                                                       str(PYTORCH_PRETRAINED_BERT_CACHE), &#x27;distributed_&#123;&#125;&#x27;.format(args.local_rank)),</span><br><span class="line">                                                                   num_labels=4,</span><br><span class="line">                                                                   no_masking=args.no_masking,</span><br><span class="line">                                                                   lambda_scale=args.lambda_scale)</span><br></pre></td></tr></table></figure><p>损失函数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss = model(input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask,</span><br><span class="line">                             start_positions=start_positions, end_positions=end_positions, switch_list=switches)</span><br></pre></td></tr></table></figure><p>$L<em>{span}+L</em>{no_answer}$</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">span_mask = (switch_list == 0).type(torch.FloatTensor).cuda()</span><br><span class="line">start_losses = loss_fct(</span><br><span class="line">                    start_logits, start_positions) * span_mask</span><br><span class="line">end_losses = loss_fct(end_logits, end_positions) * span_mask</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">collections.OrderedDict()#实现对字典元素排序</span><br><span class="line">collections.namedtuple()#类似于结构体的用法</span><br><span class="line">json.dumps()#将python对象编码成Json字符串</span><br></pre></td></tr></table></figure><p>仅使用可以找大答案的问题</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">actual_text = &quot; &quot;.join(</span><br><span class="line">    doc_tokens[start_position:(end_position + 1)])</span><br><span class="line">cleaned_answer_text = &quot; &quot;.join(</span><br><span class="line">    whitespace_tokenize(orig_answer_text))</span><br><span class="line">if actual_text.find(cleaned_answer_text) == -1:</span><br><span class="line">    logger.warning(&quot;Could not find answer: &#x27;%s&#x27; vs. &#x27;%s&#x27;&quot;,</span><br><span class="line">                   actual_text, cleaned_answer_text)</span><br><span class="line">    continue</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>过滤掉过长的问题</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if len(orig_answer_text.split()) &gt; max_answer_len:</span><br><span class="line">    logger.info(</span><br><span class="line">        &quot;Omitting a long answer: &#x27;%s&#x27;&quot;, orig_answer_text)</span><br><span class="line">    continue</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_train_optimization_steps // int(save_chunk) #结果取整数</span><br></pre></td></tr></table></figure><p>将答案范围设置为与a匹配并首先出现的字符串。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for i in range(len(index_and_score)):</span><br><span class="line">    if i &gt;= n_best_size:</span><br><span class="line">        break</span><br><span class="line">    best_indexes.append(index_and_score[i][0])</span><br></pre></td></tr></table></figure><p>BRET输入示例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokens: [CLS] this singer of a rather blu ##ster ##y day also voiced what hedge ##hog ? [SEP] &quot; a rather blu ##ster ##y day &quot; is a w ##him ##sic ##al song from the walt disney musical film feature ##tte , &quot; winnie the po ##oh and the blu ##ster ##y day &quot; . it was written by robert &amp; richard sherman and sung by jim cummings as &quot; po ##oh &quot; . james jonah cummings ( born november 3 , 1952 ) is an american voice actor and singer , who has appeared in almost 400 roles . he is known for vo ##icing the title character from &quot; dark ##wing duck &quot; , dr . robot ##nik from &quot; sonic the hedge ##hog &quot; , and pete . his other characters include winnie the po ##oh , ti ##gger , and the tasmanian devil . he has performed in numerous disney and dream ##works animation ##s including &quot; ala ##ddin &quot; , &quot; the lion king &quot; , &quot; bal ##to &quot; , &quot; ant ##z &quot; , &quot; the road to el dora ##do &quot; , &quot; sh ##rek &quot; , and &quot; the princess and the frog &quot; . he has also provided voice - over work for video games , such as &quot; ice ##wind dale &quot; , &quot; fallout &quot; , &quot; &quot; , &quot; bald ##ur &#x27; s gate &quot; , &quot; mass effect 2 &quot; , &quot; &quot; , &quot; &quot; , &quot; &quot; , and &quot; sp ##lat ##ter ##house &quot; . [SEP]</span><br></pre></td></tr></table></figure><p>输入长度不足补0</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">while len(input_ids) &lt; max_seq_length:</span><br><span class="line">    input_ids.append(pad_token)</span><br><span class="line">    input_mask.append(0 if mask_padding_with_zero else 1)</span><br><span class="line">    segment_ids.append(pad_token_segment_id)</span><br><span class="line">    p_mask.append(1)</span><br></pre></td></tr></table></figure><p>示例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span><br></pre></td></tr></table></figure><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>下载程序</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!git clone https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths.git</span><br><span class="line">%cd /content/learning_to_retrieve_reasoning_paths</span><br><span class="line">!pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>下载训练数据</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths</span><br><span class="line">!mkdir data</span><br><span class="line">%cd data</span><br><span class="line">!mkdir hotpot</span><br><span class="line">%cd hotpot</span><br><span class="line">!gdown https://drive.google.com/uc?id=1_a8KliAHKIwrYRrHgHOlzM0Jon3AqZLs</span><br><span class="line">!mv hotpot_reader_train_data.json.json____ hotpot_reader_train_data.json</span><br><span class="line">!gdown https://drive.google.com/uc?id=1R4exuPDaV2yD18xUBsnNyQpXwn0ty5pc</span><br><span class="line">!mv nq_reader_train_data_public.json.json____ nq_reader_train_data_public.json</span><br><span class="line">!gdown https://drive.google.com/uc?id=1FB5gB9aM8rmbpIwYf-1o6lmxMYQsg_rP</span><br><span class="line">!mv squad_reader_train_data.json.json____ squad_reader_train_data.json</span><br><span class="line">!gdown https://drive.google.com/uc?id=1MysthH2TRYoJcK_eLOueoLeYR42T-JhB</span><br><span class="line">!ls</span><br></pre></td></tr></table></figure><p><strong>训练模型</strong></p><blockquote><p>数据集均采用SQuAD v.2 format</p><p>使用hotpot_dev_squad_v2.0_format.json训练</p><p>hotpot_reader_train_data.json太大训练不出来，这里用hotpot_dev_squad_v2.0_format.json只是为了体验下训练的过程！</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths/reader/</span><br><span class="line">!python run_reader_confidence.py \</span><br><span class="line">--bert_model bert-base-uncased \</span><br><span class="line">--output_dir output_hotpot_bert_base \</span><br><span class="line">--train_file /content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json \</span><br><span class="line">--predict_file /content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json \</span><br><span class="line">--max_seq_length 384 \</span><br><span class="line">--do_train \</span><br><span class="line">--do_predict \</span><br><span class="line">--do_lower_case \</span><br><span class="line">--version_2_with_negative \</span><br><span class="line">--train_batch_size 16</span><br></pre></td></tr></table></figure><blockquote><p>—train_batch_size 根据显卡内存调整</p><p>—version_2_with_negative 使用负例数据训练</p></blockquote><p>仅训练</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths/reader/</span><br><span class="line">!python run_reader_confidence.py \</span><br><span class="line">--bert_model bert-base-uncased \</span><br><span class="line">--output_dir output_hotpot_bert_base \</span><br><span class="line">--train_file /content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json \</span><br><span class="line">--max_seq_length 384 \</span><br><span class="line">--do_train \</span><br><span class="line">--do_lower_case \</span><br><span class="line">--version_2_with_negative \</span><br><span class="line">--train_batch_size 16</span><br></pre></td></tr></table></figure><p>仅预测</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths/reader/</span><br><span class="line">!python run_reader_confidence.py \</span><br><span class="line">--bert_model bert-base-uncased \</span><br><span class="line">--output_dir output_hotpot_bert_base \</span><br><span class="line">--predict_file /content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json \</span><br><span class="line">--max_seq_length 384 \</span><br><span class="line">--do_predict \</span><br><span class="line">--do_lower_case \</span><br><span class="line">--version_2_with_negative \</span><br><span class="line">--train_batch_size 16</span><br></pre></td></tr></table></figure><p><strong>评估</strong></p><p>下载评估数据集</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths</span><br><span class="line">!mkdir data</span><br><span class="line">%cd data</span><br><span class="line">!mkdir hotpot</span><br><span class="line">%cd hotpot</span><br><span class="line">!gdown https://drive.google.com/uc?id=1MysthH2TRYoJcK_eLOueoLeYR42T-JhB</span><br><span class="line">!ls</span><br></pre></td></tr></table></figure><p>评估模型</p><blockquote><p>predictions.json 为模型预测后自动生成</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths/reader/</span><br><span class="line">!wget https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/</span><br><span class="line">!mv index.html evaluate-v2.0.py</span><br><span class="line">!python evaluate-v2.0.py \</span><br><span class="line">/content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json \</span><br><span class="line">/content/learning_to_retrieve_reasoning_paths/reader/output_hotpot_bert_base/predictions.json</span><br></pre></td></tr></table></figure><blockquote><p>评估数据：/content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpot_dev_squad_v2.0_format.json </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> BERT </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GRAPH-BASED RECURRENT RETRIEVER</title>
      <link href="/2021/01/09/GRAPH-BASED%20RECURRENT%20RETRIEVER/"/>
      <url>/2021/01/09/GRAPH-BASED%20RECURRENT%20RETRIEVER/</url>
      
        <content type="html"><![CDATA[<h2 id="GRAPH-BASED-RECURRENT-RETRIEVER"><a href="#GRAPH-BASED-RECURRENT-RETRIEVER" class="headerlink" title="GRAPH-BASED RECURRENT RETRIEVER"></a>GRAPH-BASED RECURRENT RETRIEVER</h2><blockquote><p>a new graph-based recurrent retrieval method</p><p>查找证据文档作为回答复杂问题的推理路径。</p></blockquote><script type="math/tex; mode=display">w_i=BERT_{CLS}(q,p_i) \in \R^d</script><script type="math/tex; mode=display">P(p_i|h_t)=\sigma(w_i·h_t+b)</script><script type="math/tex; mode=display">h_{t=1}=RNN(h_t,w_i) \in \R^d</script><blockquote><p>b：偏置项</p></blockquote><ul><li>使用RNN建模问题$Q$的推理路径。</li><li>给定问题$q$，在时间步$t$时，模型从候选段落集$C_t$中找出$p_i$ ，与$q$拼接计算$p_i$的概率。</li><li>遇到$[EOE]$时结束推理，允许它在给定每个问题的情况下捕获具有任意长度的推理路径。</li></ul><h3 id="本文BERT结构："><a href="#本文BERT结构：" class="headerlink" title="本文BERT结构："></a>本文BERT结构：</h3><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210108150704.png" alt="image-20210108150704041" style="zoom:50%;" /></p><h3 id="RNN结构："><a href="#RNN结构：" class="headerlink" title="RNN结构："></a>RNN结构：</h3><p>$P(p_i|h_t)$：表示在时间步$t$选择段落$p_i$的概率。</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20210108151355.png" alt="image-20210108151355616" style="zoom:50%;" /></p><p>最终得到推理路径【$p_1,p_2$】</p><p>beam search </p><ul><li>通过束搜索得到给定时间步长的有限数量的最可能推理路径，减小输入BERT的数据量，减小计算量。</li><li>$C_1$是用在输入问题上 TF-IDF 得分最高的段落。</li><li>$C_t$是在C_1基础上，拓展的连接段落，用输入到BERT。</li><li>推理路径$E = [p<em>i, . . . , p_k]$乘段落概率$P(p_i|h_1) . . . P(p_k|h</em>{|E|})$得到beam search 的输出，即得到top B 推理路径 $E = {E_1, . . . , E_B}$作为BERT输入，再将BERT输出作为RNN输入。</li></ul><h2 id="BERT相关"><a href="#BERT相关" class="headerlink" title="BERT相关"></a>BERT相关</h2><blockquote><p>Bidirectional Encoder Representations from Transformers</p><p>是Google以无监督的方式利用大量无标注文本训练的的语言代表模型，其架构为Transformer中的Encoder。</p></blockquote><ul><li><a href="https://youtu.be/UYPa347-DdE">讲解视频</a>：<a href="https://youtu.be/UYPa347-DdE">https://youtu.be/UYPa347-DdE</a></li></ul><iframe         width="900"         height="675"         src="https://www.youtube.com/embed/UYPa347-DdE"         frameborder="0"         allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"         allowfullscreen></iframe><ul><li>使用BERT预训练模型<code>bert-base-uncased</code>不区分大小写。</li></ul><p>BERT 里5个特殊tokens：</p><ol><li>[CLS]：在做分类任务时其最后一层的repr. 会被视为整个输入序列的repr。</li></ol><blockquote><p>repr指的都是一个可以用来代表某词汇（在某个语境下）的多维连续向量（continuous vector）。</p></blockquote><ol><li>[SEP]：有两个句子的文本会被串接成一个输入序列，并在两句之间插入这个token 以做区隔。</li><li>[UNK]：没出现在BERT 字典里头的字会被这个token 取代。</li><li>[PAD]：zero padding 遮罩，将长度不一的输入序列补齐方便做batch 运算。</li><li>[MASK]：未知遮罩，仅在预训练阶段会用到。</li></ol><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>加载BERT预训练模型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = BertForGraphRetriever.from_pretrained(args.bert_model,cache_dir=PYTORCH_PRETRAINED_BERT_CACHE / &#x27;distributed_&#123;&#125;&#x27;.format(-1),graph_retriever_config=graph_retriever_config)</span><br></pre></td></tr></table></figure><blockquote><p>默认从缓存中加载，下载之后源码中替换自己本地路径即可。</p></blockquote><ul><li>any() 函数用于判断给定的可迭代参数 iterable 是否全部为 False，则返回 False，如果有一个为 True，则返回 True。</li></ul><p>使用BertAdam自定义Adam优化器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">optimizer = BertAdam(optimizer_grouped_parameters,</span><br><span class="line">                             lr=args.learning_rate,</span><br><span class="line">                             warmup=args.warmup_proportion,</span><br><span class="line">                             t_total=t_total,</span><br><span class="line">                             max_grad_norm=1.0)</span><br></pre></td></tr></table></figure><blockquote><p>在前10%的steps中，lr从0线性增加到 init_learning_rate，这个阶段又叫 warmup，然后，lr又从 init_learning_rate 线性衰减到0（完成所有steps）。</p></blockquote><p>对问题和段落加上[CLS],[SEP]</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">def tokenize_question(question, tokenizer):</span><br><span class="line">    tokens_q = tokenizer.tokenize(question)</span><br><span class="line">    tokens_q = [&#x27;[CLS]&#x27;] + tokens_q + [&#x27;[SEP]&#x27;]</span><br><span class="line"></span><br><span class="line">    return tokens_q</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def tokenize_paragraph(p, tokens_q, max_seq_length, tokenizer):</span><br><span class="line">    tokens_p = tokenizer.tokenize(p)[:max_seq_length - len(tokens_q) - 1]</span><br><span class="line">    tokens_p = tokens_p + [&#x27;[SEP]&#x27;]</span><br><span class="line"></span><br><span class="line">    padding = [0] * (max_seq_length - len(tokens_p) - len(tokens_q))</span><br><span class="line"></span><br><span class="line">    input_ids_ = tokenizer.convert_tokens_to_ids(tokens_q + tokens_p)</span><br><span class="line">    input_masks_ = [1] * len(input_ids_)</span><br><span class="line">    segment_ids_ = [0] * len(tokens_q) + [1] * len(tokens_p)</span><br><span class="line"></span><br><span class="line">    input_ids_ += padding</span><br><span class="line">    input_masks_ += padding</span><br><span class="line">    segment_ids_ += padding</span><br><span class="line"></span><br><span class="line">    assert len(input_ids_) == max_seq_length</span><br><span class="line">    assert len(input_masks_) == max_seq_length</span><br><span class="line">    assert len(segment_ids_) == max_seq_length</span><br><span class="line"></span><br><span class="line">    return input_ids_, input_masks_, segment_ids_</span><br></pre></td></tr></table></figure><p>RNN初始化</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.rw = nn.Linear(2 * config.hidden_size, config.hidden_size)</span><br></pre></td></tr></table></figure><p>通过beam search 找出top B 推理路径</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">b = 0</span><br><span class="line">while b &lt; beam:</span><br><span class="line">    s, p = torch.max(score.view(score.size(0) * score.size(1)), dim=0)</span><br><span class="line">    s = s.item()</span><br><span class="line">    p = p.item()</span><br><span class="line">    row = p // score.size(1)</span><br><span class="line">    col = p % score.size(1)</span><br><span class="line"></span><br><span class="line">    if j == 0:</span><br><span class="line">        score[:, col] = 0.0</span><br><span class="line">    else:</span><br><span class="line">        score[row, col] = 0.0</span><br><span class="line"></span><br><span class="line">    p = [[index for index in pred_[row][0]] + [col],</span><br><span class="line">         output[row].topk(k=2, dim=0)[1].tolist(),</span><br><span class="line">         s]</span><br><span class="line">    new_pred_.append(p)</span><br><span class="line"></span><br><span class="line">    p = [[p_ for p_ in prb] for prb in prob_[row]] + [output[row].tolist()]</span><br><span class="line">    new_prob_.append(p)</span><br><span class="line"></span><br><span class="line">    state_tmp[b].copy_(state_[row])</span><br><span class="line">    b += 1</span><br></pre></td></tr></table></figure><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>下载程序：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!git clone https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths.git</span><br><span class="line">%cd /content/learning_to_retrieve_reasoning_paths</span><br><span class="line">!pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>下载数据集</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths</span><br><span class="line">!mkdir data</span><br><span class="line">%cd data</span><br><span class="line">!mkdir hotpot</span><br><span class="line">%cd hotpot</span><br><span class="line">!gdown https://drive.google.com/uc?id=1AIRo66I2Izs80nNLt4MaLu7kqhTuIQ0u</span><br><span class="line">!unzip hotpotqa_new_selector_train_data_db_2017_10_12_fix.zip.zip____</span><br><span class="line">!rm hotpotqa_new_selector_train_data_db_2017_10_12_fix.zip.zip____</span><br></pre></td></tr></table></figure><p>训练模型</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%cd /content/learning_to_retrieve_reasoning_paths/graph_retriever</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">!python3 run_graph_retriever.py \</span><br><span class="line">--task hotpot_distractor \</span><br><span class="line">--bert_model bert-base-uncased --do_lower_case \</span><br><span class="line">--train_file_path /content/learning_to_retrieve_reasoning_paths/data/hotpot/hotpotqa_new_selector_train_data_db_2017_10_12_fix/db=wiki_hotpotqa.db_hotpotqa_new_test_tfidf_k=50.pruning_l=100_tag_me=True.prune_after_agg=False.prune_in_article=False_use_link=True_start=0_end=5000.json \</span><br><span class="line">--output_dir graph_retriever/ \</span><br><span class="line">--max_para_num 10 \</span><br><span class="line">--neg_chunk 8 --train_batch_size 4 --gradient_accumulation_steps 4 \</span><br><span class="line">--learning_rate 3e-5 --num_train_epochs 3 \</span><br><span class="line">--max_select_num 3</span><br></pre></td></tr></table></figure><blockquote><ul><li><p>—max_para_num：与问题相关的段落数量。如果—max_para_num是n，问题的基础真实段落数量是k(2)，那么有n-2个段落作为训练的反例。此时反例数量为8。</p></li><li><p>—neg_chunk：为了控制GPU内存消耗，将负例拆分为小块。</p></li><li>—max_select_num：指定模型推理步骤的最大数量，如果问题的基础真实段落数量是k，这个值应该为k+1，1表示结束符号EOE，此时k+1=3。</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> BERT </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>谷歌翻译接口</title>
      <link href="/2021/01/08/%E8%B0%B7%E6%AD%8C%E7%BF%BB%E8%AF%91%E6%8E%A5%E5%8F%A3/"/>
      <url>/2021/01/08/%E8%B0%B7%E6%AD%8C%E7%BF%BB%E8%AF%91%E6%8E%A5%E5%8F%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="谷歌翻译接口"><a href="#谷歌翻译接口" class="headerlink" title="谷歌翻译接口"></a>谷歌翻译接口</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install google_trans_new</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from google_trans_new import  google_translator  </span><br><span class="line"></span><br><span class="line">translator = google_translator()  </span><br><span class="line">translate_text = translator.translate(&#x27;美国下一届总统将会是谁？&#x27;,lang_src=&#x27;zh-cn&#x27;,lang_tgt=&#x27;en&#x27;)  </span><br><span class="line">print(translate_text)</span><br></pre></td></tr></table></figure><blockquote><p>默认自动检测语种</p></blockquote><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Who will be the next president of the United States? </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SRLGRN</title>
      <link href="/2020/12/31/SRLGRN/"/>
      <url>/2020/12/31/SRLGRN/</url>
      
        <content type="html"><![CDATA[<h1 id="SRLGRN"><a href="#SRLGRN" class="headerlink" title="SRLGRN"></a>SRLGRN</h1><blockquote><p>论文：EMNLP2020-Semantic Role Labeling Graph Reasoning Network</p><p>语义角色标注图推理网络</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>​        提出了一个基于句子语义结构的图推理网络来学习跨段落推理路径，并联合寻找支持事实和答案。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><h3 id="SRLGRN-1"><a href="#SRLGRN-1" class="headerlink" title="SRLGRN"></a>SRLGRN</h3><blockquote><p>该框架在构建推理图网络时会考虑句子的语义结构。 不仅利用节点的语义角色，而且会利用边缘的语义。</p></blockquote><ul><li><p>训练一个段落选择模块来检索gold documents并最小化干扰因素。</p></li><li><p>构建了一个异类文档级图，其中包含以句子为节点以及SRL子图，其中SRL子图包括语义角色标签参数作为节点，谓词作为边。</p></li><li><p>训练图编码器来获得图节点表示，该图节点表示在学习的表示中结合了参数类型和谓词边的语义。</p></li><li><p>最后，共同训练一个multi-hop supporting fact prediction module和answer prediction module。</p><blockquote><p>multi-hop supporting fact prediction module可以找到跨段落推理路径，answer prediction module可以得到最终答案。</p><p>based on contextual semantics graph representations as well as token-level BERT pre-trained representations.</p></blockquote></li></ul><p>模型结构：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201230205729.png" alt="image-20201230205718629"></p><blockquote><p>SRLGRN由段落选择，图形构造，图形编码器，支持事实预测和答案跨度预测模块组成。</p></blockquote><h3 id="Paragraph-Selection"><a href="#Paragraph-Selection" class="headerlink" title="Paragraph Selection"></a>Paragraph Selection</h3><ul><li>based on the pre-trained BERT model</li></ul><p>两轮解释：</p><h4 id="First-Round-Paragraph-Selection"><a href="#First-Round-Paragraph-Selection" class="headerlink" title="First Round Paragraph Selection"></a>First Round Paragraph Selection</h4><p>input:$Q_1$</p><script type="math/tex; mode=display">Q_1= [[CLS]; q; [SEP]; C]</script><blockquote><p>q: question</p><p>C: paragraph content</p></blockquote><script type="math/tex; mode=display">C = \{t, s_1, . . . , s_n\}</script><blockquote><p>t: title</p><p>$s_n$: sentences</p></blockquote><ul><li>将$Q_1$输入到预训练的BERT编码器以获得token表示。</li><li>使用$BERT_{[CLS]}$作为该段的摘要表示。</li><li>利用两层MLP输出相关性得分。</li><li>选择获得最高相关性得分的段落作为第一相关上下文。</li><li>将$q$连接到所选段落作为$q_{new}$，以进行下一轮段落选择。</li></ul><h4 id="Second-Round-Paragraph-Selection"><a href="#Second-Round-Paragraph-Selection" class="headerlink" title="Second Round Paragraph Selection"></a>Second Round Paragraph Selection</h4><ul><li>对于剩余的N-1个候选段落，使用与第一轮段落选择相同的模型来生成相关性得分，该相关性得分以$q_{new}$和段落内容为输入。</li><li>将问题和两个选定的段落连接起来，形成一个新的上下文，用作图形构造的输入文本。</li></ul><h3 id="Heterogeneous-SRL-Graph-Construction"><a href="#Heterogeneous-SRL-Graph-Construction" class="headerlink" title="Heterogeneous SRL Graph Construction"></a>Heterogeneous SRL Graph Construction</h3><p>每个数据实例构建一个包含document-level子图$S$和argument- predicate SRL 子图$Arg$的异构图。</p><ul><li>$S$ </li></ul><blockquote><p>includes question q, title $t_1$and sentences $s_1^{1,…,n}$  from first round se- lected paragraph.and title $t_2$and sentences $s_2^{1,…,n}$ from the second round selected paragraph.</p></blockquote><ul><li>$Arg$</li></ul><blockquote><p>包含使用AllenNLP-SRL模型生成的参数作为节点，谓词作为边。</p></blockquote><script type="math/tex; mode=display">{q, t_1, s_1 1, . . . , s_n 1, t_2, s_1 2, . . . , sn_ 2} ∈ S.</script><p><img src="/Users/maqi/Library/Application Support/typora-user-images/image-20201230214154969.png" alt="image-20201230214154969"></p><p>异构图的边添加规则：</p><ol><li>如果在该句子中有一个argument，则该句子和argument之间将存在一条边（图3中的黑色虚线）</li><li>$s_i$和$s$两个句子，如果他们通过精确匹配共享一个参数，则存在一条边（红色虚线）</li><li>两个argument节点$Arg_i$ 和$Arg_j$之间存在谓词，则存在一条边（黑色实线）</li><li>如果它们共享一个argument，则问题和句子之间会有一条边（红色虚线）</li></ol><p>建立了一个基于谓词的语义边缘矩阵$K$和一个异构边缘权重矩阵$A$。</p><blockquote><p>语义边缘矩阵$K$是一个存储谓词单词索引的矩阵。 </p><p>异构边缘权重矩阵$A$是存储不同类型边权重的矩阵。</p></blockquote><h3 id="Supporting-Fact-Prediction"><a href="#Supporting-Fact-Prediction" class="headerlink" title="Supporting Fact Prediction"></a>Supporting Fact Prediction</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201231111925.png" alt="image-20201231111925399" style="zoom: 67%;" /></p><ol><li>$G_S$: graph sentence embedding(蓝色圆圈)。</li><li>BERT’s [CLS] token representation： 橙色圆圈。</li><li>$X_S^{cand}$: 候选句子。</li><li>$S_{cand}$:候选句子的相邻句子。</li></ol><script type="math/tex; mode=display">X_S^{cand}  = [G_S^{cand} ; BERT[CLS](q, S_{cand})]</script><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>HotpotQA</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201231113847.png" alt="image-20201231113847927"></p><blockquote><p>EM：完全匹配</p><p>F1：部分匹配</p></blockquote><p>在Distractor setting下的测试结果：</p><p>​        该模型在Joint上获得了39.41％的完全精确匹配分数和66.37％的部分匹配分数,远超基线模型，相比其他模型也有明显的提升。这得益于token-level BERT和graph-level SRL node的结合。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><h3 id="Ablation-study"><a href="#Ablation-study" class="headerlink" title="Ablation study"></a>Ablation study</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201231115716.png" alt="image-20201231115716017" style="zoom:50%;" /></p><p>Graph:</p><ul><li><p>删除整个SRL图。 </p><p>与完整的SRLGRN模型相比，在F1评分上下降了8.46％。 如果删除SRL图，而仅使用BERT进行答案预测，则该模型将失去用于多跳推理的连接。</p></li><li><p>从SRL图中删除了基于谓词的边缘信息。</p><p>如果不合并语义边缘信息和参数类型，则答案跨度预测的F1分数降低2.9％。删除谓词边和参数类型将破坏SRL图中的参数-谓词关系，并打破推理链。</p></li></ul><p>Joint:</p><p>​    如果不共同训练模型，性能将下降4.56％。</p><p>Language Models：</p><p>​    尽管BERT获得了相对更好的性能，但ALBERT架构的参数少18X，并且比BERT更快。</p><h2 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h2><p>​        语义角色标注 (Semantic Role Labeling, SRL) 是一种浅层的语义分析技术，标注句子中某些短语为给定谓词的论元 (语义角色) ，如施事、受事、时间和地点等。其能够对问答系统、信息抽取和机器翻译等应用产生推动作用。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> 机器阅读理解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python——Argparse 教程</title>
      <link href="/2020/12/20/python%E2%80%94%E2%80%94Argparse%20%E6%95%99%E7%A8%8B/"/>
      <url>/2020/12/20/python%E2%80%94%E2%80%94Argparse%20%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="python——Argparse-教程"><a href="#python——Argparse-教程" class="headerlink" title="python——Argparse 教程"></a>python——Argparse 教程</h1><blockquote><p>此模块是 Python 标准库中推荐的命令行解析模块。</p></blockquote><h2 id="位置参数"><a href="#位置参数" class="headerlink" title="位置参数"></a>位置参数</h2><ol><li><strong>add_argument()</strong> 方法<ul><li>该方法用于指定程序能够接受哪些命令行选项。</li></ul></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;echo&quot;, help=&quot;echo the string you use here&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">print(args.echo)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py -h</span><br><span class="line">usage: test.py [-h] echo</span><br><span class="line"></span><br><span class="line">positional arguments:</span><br><span class="line">  echo        echo the string you use here</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -h, --help  show this help message and exit</span><br></pre></td></tr></table></figure><ul><li>指定传递参数类型（默认为字符串）</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;square&quot;, help=&quot;display a square of a given number&quot;,</span><br><span class="line">                    type=int)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">print(args.square ** 2)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 </span><br><span class="line">16</span><br></pre></td></tr></table></figure><h2 id="可选参数"><a href="#可选参数" class="headerlink" title="可选参数"></a>可选参数</h2><blockquote><p>参数加”—“符号。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;--verbosity&quot;, help=&quot;increase output verbosity&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">if args.verbosity:</span><br><span class="line">    print(&quot;verbosity turned on&quot;)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py --verbosity 1</span><br><span class="line">verbosity turned on</span><br></pre></td></tr></table></figure><ul><li>当指定 —verbosity 参数时显示某些东西，否则不显示。</li><li>如果一个可选参数没有被使用时，相关变量被赋值为 None，在此例中是 args.verbosity，这也就是为什么它在 if 语句中被当作逻辑假。</li><li>使用 —verbosity 选项时，必须指定一些值（任何值）,例如本例中指定值为“1”。</li></ul><ol><li><strong>action</strong>关键词</li></ol><blockquote><p>参数只有两个值有实际意义：True 或者 False时使用。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;--verbose&quot;, help=&quot;increase output verbosity&quot;,</span><br><span class="line">                    action=&quot;store_true&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">if args.verbose:</span><br><span class="line">    print(&quot;verbosity turned on&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py --verbose  </span><br><span class="line">verbosity turned on</span><br></pre></td></tr></table></figure><ul><li>指定了一个新的关键词 action，并赋值为 “store_true”。这意味着，当这一选项存在时，为 args.verbose 赋值为 True。没有指定时则隐含地赋值为 False。</li><li>当你为其指定一个值时，它会报错，例如：只写—verbose即可，传递任何值会报错。</li></ul><h2 id="短选项"><a href="#短选项" class="headerlink" title="短选项"></a>短选项</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbose&quot;, help=&quot;increase output verbosity&quot;,</span><br><span class="line">                    action=&quot;store_true&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">if args.verbose:</span><br><span class="line">    print(&quot;verbosity turned on&quot;)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py -v </span><br><span class="line">verbosity turned on</span><br></pre></td></tr></table></figure><h2 id="结合位置参数和可选参数"><a href="#结合位置参数和可选参数" class="headerlink" title="结合位置参数和可选参数"></a>结合位置参数和可选参数</h2><blockquote><p>位置参数要注意顺序。</p><p>位置参数和可选参数顺序可以颠倒。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;square&quot;, type=int,</span><br><span class="line">                    help=&quot;display a square of a given number&quot;)</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbose&quot;, action=&quot;store_true&quot;,</span><br><span class="line">                    help=&quot;increase output verbosity&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square ** 2</span><br><span class="line">if args.verbose:</span><br><span class="line">    print(&quot;the square of &#123;&#125; equals &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">else:</span><br><span class="line">    print(answer)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 </span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 --verbose</span><br><span class="line">the square of 4 equals 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -v       </span><br><span class="line">the square of 4 equals 16</span><br></pre></td></tr></table></figure><ul><li>参数顺序无关紧要。</li><li>位置参数必须传值。</li></ul><ol><li><p><strong>count</strong>动作</p><p>来数某一个可选参数出现了几次。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;square&quot;, type=int,</span><br><span class="line">                    help=&quot;display the square of a given number&quot;)</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbosity&quot;, action=&quot;count&quot;,</span><br><span class="line">                    help=&quot;increase output verbosity&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square ** 2</span><br><span class="line">if args.verbosity == 2:</span><br><span class="line">    print(&quot;the square of &#123;&#125; equals &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">elif args.verbosity == 1:</span><br><span class="line">    print(&quot;&#123;&#125;^2 == &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">else:</span><br><span class="line">    print(answer)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 </span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -v</span><br><span class="line">4^2 == 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -vv</span><br><span class="line">the square of 4 equals 16</span><br></pre></td></tr></table></figure></li><li><p><strong>choices</strong>关键字</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;square&quot;, type=int,</span><br><span class="line">                    help=&quot;display a square of a given number&quot;)</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbosity&quot;, type=int, choices=[0, 1, 2],</span><br><span class="line">                    help=&quot;increase output verbosity&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square ** 2</span><br><span class="line">if args.verbosity == 2:</span><br><span class="line">    print(&quot;the square of &#123;&#125; equals &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">elif args.verbosity == 1:</span><br><span class="line">    print(&quot;&#123;&#125;^2 == &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">else:</span><br><span class="line">    print(answer)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 -v 1</span><br><span class="line">4^2 == 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -v 3</span><br><span class="line">usage: test.py [-h] [-v &#123;0,1,2&#125;] square</span><br><span class="line">test.py: error: argument -v/--verbosity: invalid choice: 3 (choose from 0, 1, 2)</span><br></pre></td></tr></table></figure><ol><li><strong>default</strong>关键字</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;square&quot;, type=int,</span><br><span class="line">                    help=&quot;display a square of a given number&quot;)</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbosity&quot;, action=&quot;count&quot;, default=0,</span><br><span class="line">                    help=&quot;increase output verbosity&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.square ** 2</span><br><span class="line">if args.verbosity &gt;= 2:</span><br><span class="line">    print(&quot;the square of &#123;&#125; equals &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">elif args.verbosity &gt;= 1:</span><br><span class="line">    print(&quot;&#123;&#125;^2 == &#123;&#125;&quot;.format(args.square, answer))</span><br><span class="line">else:</span><br><span class="line">    print(answer)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 </span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -v</span><br><span class="line">4^2 == 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 -vv</span><br><span class="line">the square of 4 equals 16</span><br></pre></td></tr></table></figure><ul><li><p>结合使用</p><blockquote><p>位置参数要注意顺序。</p><p>位置参数和可选参数顺序可以颠倒。</p></blockquote></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(&quot;x&quot;, type=int, help=&quot;the base&quot;)</span><br><span class="line">parser.add_argument(&quot;y&quot;, type=int, help=&quot;the exponent&quot;)</span><br><span class="line">parser.add_argument(&quot;-v&quot;, &quot;--verbosity&quot;, action=&quot;count&quot;, default=0)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.x ** args.y</span><br><span class="line">if args.verbosity &gt;= 2:</span><br><span class="line">    print(&quot;Running &#x27;&#123;&#125;&#x27;&quot;.format(__file__))</span><br><span class="line">if args.verbosity &gt;= 1:</span><br><span class="line">    print(&quot;&#123;&#125;^&#123;&#125; == &quot;.format(args.x, args.y), end=&quot;&quot;)</span><br><span class="line">print(answer)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 2   </span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -v</span><br><span class="line">4^2 == 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -vv</span><br><span class="line">Running &#x27;test.py&#x27;</span><br><span class="line">4^2 == 16</span><br></pre></td></tr></table></figure><h2 id="矛盾的选项-add-mutually-exclusive-group"><a href="#矛盾的选项-add-mutually-exclusive-group" class="headerlink" title="矛盾的选项 add_mutually_exclusive_group()"></a>矛盾的选项 add_mutually_exclusive_group()</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">group = parser.add_mutually_exclusive_group()</span><br><span class="line">group.add_argument(&quot;-v&quot;, &quot;--verbose&quot;, action=&quot;store_true&quot;)</span><br><span class="line">group.add_argument(&quot;-q&quot;, &quot;--quiet&quot;, action=&quot;store_true&quot;)</span><br><span class="line">parser.add_argument(&quot;x&quot;, type=int, help=&quot;the base&quot;)</span><br><span class="line">parser.add_argument(&quot;y&quot;, type=int, help=&quot;the exponent&quot;)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line">answer = args.x**args.y</span><br><span class="line"></span><br><span class="line">if args.quiet:</span><br><span class="line">    print(answer)</span><br><span class="line">elif args.verbose:</span><br><span class="line">    print(&quot;&#123;&#125; to the power &#123;&#125; equals &#123;&#125;&quot;.format(args.x, args.y, answer))</span><br><span class="line">else:</span><br><span class="line">    print(&quot;&#123;&#125;^&#123;&#125; == &#123;&#125;&quot;.format(args.x, args.y, answer))</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">python3 test.py 4 2 </span><br><span class="line">4^2 == 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -q</span><br><span class="line">16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -v</span><br><span class="line">4 to the power 2 equals 16</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -vq</span><br><span class="line">usage: test.py [-h] [-v | -q] x y</span><br><span class="line">test.py: error: argument -q/--quiet: not allowed with argument -v/--verbose</span><br><span class="line"></span><br><span class="line">python3 test.py 4 2 -v -q</span><br><span class="line">usage: test.py [-h] [-v | -q] x y</span><br><span class="line">test.py: error: argument -q/--quiet: not allowed with argument -v/--verbose</span><br></pre></td></tr></table></figure><ul><li>add_mutually_exclusive_group()它允许我们指定彼此相互冲突的选项。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> Argparse </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python知识点</title>
      <link href="/2020/12/20/python%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
      <url>/2020/12/20/python%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<h1 id="python知识点"><a href="#python知识点" class="headerlink" title="python知识点"></a>python知识点</h1><ol><li><strong>tqdm</strong>：进度条</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from tqdm import tqdm</span><br><span class="line"></span><br><span class="line">pbar = tqdm([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;])</span><br><span class="line">for char in pbar:</span><br><span class="line">    pbar.set_description(&quot;Processing %s&quot; % char)</span><br></pre></td></tr></table></figure><p>效果：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201220184527.png" alt="image-20201220184518149"></p><ol><li><p><strong>@staticmethod</strong></p><blockquote><p>静态方法无需实例化<br>也可以实例化后调用</p></blockquote></li><li><p><strong>list</strong></p><p>append()：将元素直接内嵌到列表</p><p>+=：拼接同级列表</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = []</span><br><span class="line">a.append([&#x27;s&#x27;])</span><br><span class="line">a += [&#x27;d&#x27;]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[&#x27;s&#x27;], &#x27;d&#x27;]</span><br></pre></td></tr></table></figure></li><li><p><strong>if any python条件判断 all(),any()</strong></p><p>any() 理解成any True的意思，是否存在True，只要有一个是True，结果就是True。</p><p>not any() 全为False则为True。</p></li><li><p><strong>assert</strong></p><p>assert expression</p><p>assert 的作用是现计算表达式 expression ，如果其值为假（即为0），那么它先向 stderr 打印一条出错信息,然后通过调用 abort 来终止程序运行。</p></li><li><p><strong>action=”store_true”</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(&quot;--verbose&quot;, help=&quot;increase output verbosity&quot;,action=&quot;store_true&quot;)</span><br></pre></td></tr></table></figure><p>默认为False</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>智能门锁</title>
      <link href="/2020/12/13/%E6%99%BA%E8%83%BD%E9%97%A8%E9%94%81/"/>
      <url>/2020/12/13/%E6%99%BA%E8%83%BD%E9%97%A8%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h1 id="智能门锁"><a href="#智能门锁" class="headerlink" title="智能门锁"></a>智能门锁</h1><p>演示视频：<a href="https://www.bilibili.com/video/BV1Z5411V7Gh/">https://www.bilibili.com/video/BV1Z5411V7Gh/</a></p><p>教学视频：<a href="https://www.bilibili.com/video/BV1g54y1t7C9/">https://www.bilibili.com/video/BV1g54y1t7C9/</a></p><p>安装效果图</p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201213161946.JPG" alt="IMG_0115"></p><h2 id="清单"><a href="#清单" class="headerlink" title="清单"></a>清单</h2><p><strong>NodeMCU</strong>：ESP8266串口wifi模块 NodeMCU Lua V3物联网开发板 CH340 CP2102(淘宝搜索)</p><p><strong>Arduino uno r3</strong>(可选)</p><p><strong>RFID-RC522</strong></p><p><strong>舵机</strong>：MG996R</p><p><strong>蜂鸣器（有源）</strong></p><p><strong>触摸按键模块</strong>（TTP223/224/226/229皆可）</p><p><strong>电源模块</strong>：提供5v,3.3v输出</p><p><strong>杜邦线</strong> ：公对公  公对母  母对母</p><blockquote><p>esp8266库：<code>https://arduino.esp8266.com/stable/package_esp8266com_index.json</code></p></blockquote><h2 id="接线"><a href="#接线" class="headerlink" title="接线"></a>接线</h2><h3 id="ESP8266-——-MFRC522"><a href="#ESP8266-——-MFRC522" class="headerlink" title="ESP8266 —— MFRC522"></a>ESP8266 —— MFRC522</h3><ul><li>D1 —— RST</li><li>D2 —— NSS(SDA) </li><li>3V3 ——3V3</li><li>GND —— GND</li><li>D5 —— SCK</li><li>D6 —— MIS0</li><li>D7 —— MIS1</li></ul><h3 id="ESP8266-——-舵机"><a href="#ESP8266-——-舵机" class="headerlink" title="ESP8266 —— 舵机"></a>ESP8266 —— 舵机</h3><ul><li>D4</li></ul><h3 id="ESP8266-——-uno-r3"><a href="#ESP8266-——-uno-r3" class="headerlink" title="ESP8266 —— uno r3"></a>ESP8266 —— uno r3</h3><ul><li>D0 —— 3</li><li>D3 —— 2</li></ul><h3 id="uno-r3-——-蜂鸣器"><a href="#uno-r3-——-蜂鸣器" class="headerlink" title="uno r3 —— 蜂鸣器"></a>uno r3 —— 蜂鸣器</h3><ul><li>4</li></ul><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>esp8266代码：<a href="https://github.com/Asimok/unoproject_backup/blob/master/smartlock208/smartlock208/smartlock208.ino">https://github.com/Asimok/unoproject_backup/blob/master/smartlock208/smartlock208/smartlock208.ino</a></p><p>uno r3代码：<a href="https://github.com/Asimok/unoproject_backup/blob/master/smartlock208/smartlock_unor3/smartlock_unor3.ino">https://github.com/Asimok/unoproject_backup/blob/master/smartlock208/smartlock_unor3/smartlock_unor3.ino</a></p>]]></content>
      
      
      <categories>
          
          <category> 硬件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Arduino </tag>
            
            <tag> C </tag>
            
            <tag> ESP8266 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering</title>
      <link href="/2020/12/12/Learning%20to%20Retrieve%20Reasoning%20Paths%20over%20Wikipedia%20Graph%20for%20Question%20Answering/"/>
      <url>/2020/12/12/Learning%20to%20Retrieve%20Reasoning%20Paths%20over%20Wikipedia%20Graph%20for%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="Learning-to-Retrieve-Reasoning-Paths-over-Wikipedia-Graph-for-Question-Answering"><a href="#Learning-to-Retrieve-Reasoning-Paths-over-Wikipedia-Graph-for-Question-Answering" class="headerlink" title="Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering"></a>Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering</h1><blockquote><p><a href="https://arxiv.org/abs/1911.10470">论文：https://arxiv.org/abs/1911.10470</a></p><p><a href="https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths">代码：https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths</a></p><p>学习在维基百科中检索问题的推理路径</p><ul><li>基于推理路径</li></ul></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>从维基百科中提取推理路径实现多轮问答。</p><ul><li><p>多轮问答：</p><p>需要结合多篇文档的“知识推理”能得到最终答案。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201208143543.png" alt="image-20201208143543082"></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201208143557.png" alt="image-20201208143556977"></p></li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><ol><li>通过维基百科的超链接构建一个维基百科图网络，在不同的文档之间建模。</li><li>使用一个RNN给推理路径建模，从而找到最佳推理路径。</li></ol><h3 id="模型结构："><a href="#模型结构：" class="headerlink" title="模型结构："></a>模型结构：</h3><blockquote><p>由一个提取器和阅读器组成</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201208143829.png" alt="image-20201208143829008"></p><p>推理路径提取器（Reasoning Path Retrieval）：根据维基百科之间的超链接关系得到若干推理路径。</p><p>阅读理解答案抽取器（Reading and Answering Reasoning Path）：基于这些路径找到最可能的一条路径作为最终的答案。</p><blockquote><p>将维基百科文章里的每个段落$p$作为基本单元。给定问题$q$，模型首先找到一条推理路径$E = [p<em>i, . . . , p_k]$，用$S</em>{retr}(q, E)$表示；然后在$E$中找到答案$a$，用$S_{read}(q, E, a)$表示。</p></blockquote><script type="math/tex; mode=display">\underset{E,a}{arg \ max} \ S(q, E, a) \ \ \ \  s.t. \ \ S(q, E, a) = S_{retr}(q, E) + S_{read}(q, E, a)</script><h3 id="推理路径提取"><a href="#推理路径提取" class="headerlink" title="推理路径提取"></a>推理路径提取</h3><h4 id="Constructing-the-Wikipedia-graph"><a href="#Constructing-the-Wikipedia-graph" class="headerlink" title="Constructing the Wikipedia graph"></a>Constructing the Wikipedia graph</h4><p>直接使用维基百科中的超链接构建有向图$G$。</p><h4 id="General-formulation-with-a-recurrent-retriever"><a href="#General-formulation-with-a-recurrent-retriever" class="headerlink" title="General formulation with a recurrent retriever"></a>General formulation with a recurrent retriever</h4><p>使用RNN建模问题$Q$的推理路径。</p><p>给定问题$q$，在时间步$t$时，模型从候选段落集$C_t$中找出$p_i$ ，与$q$拼接计算$p_i$的概率。</p><p>遇到$[EOE]$时结束推理，允许它在给定每个问题的情况下捕获具有任意长度的推理路径。</p><script type="math/tex; mode=display">w_i=BERT_{CLS}(q,p_i) \in \R^d</script><script type="math/tex; mode=display">P(p_i|h_t)=\sigma(w_i·h_t+b)</script><script type="math/tex; mode=display">h_{t=1}=RNN(h_t,w_i) \in \R^d</script><h4 id="Beam-search-for-candidate-paragraphs"><a href="#Beam-search-for-candidate-paragraphs" class="headerlink" title="Beam search for candidate paragraphs"></a>Beam search for candidate paragraphs</h4><p>为防止计算量过大，使用Beam Search来构建多个检索路径。</p><h4 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h4><p>对真实的推理路径$g = [p<em>1, . . . , p</em>{|g|}]$增加一条新的推理路径$g = [p<em>r,p_1, . . . , p</em>{|g|}]$，$p_r$是与$p_1$有联系的TF-IDF分最高的一个段落。</p><h4 id="Negative-examples-for-robustness"><a href="#Negative-examples-for-robustness" class="headerlink" title="Negative examples for robustness"></a>Negative examples for robustness</h4><p>使用两种负采样策略：</p><p>​    (1)基于TF-IDF</p><p>​    (2)基于超链接</p><p>单轮QA只用(1)，多轮QA两者都用，负采样数为50。</p><h4 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h4><p>在 $C_t$上使用广泛使用的交叉熵损失和softmax归一化是不理想的，因为同时最大化$g$和增广的$g_r$是矛盾的。因此本文独立评估$P(p_i|h_t)$并使用 binary cross-entropy loss来最大化所有可能路径的概率值。</p><script type="math/tex; mode=display">L_{retr}(p_t, h_t) = − log P(p_t|h_t) − \ \underset{\tilde{p}∈\tilde C_t} \sum log (1 − P(\tilde{p}|h_t))</script><ul><li>$\tilde{p}∈\tilde C_t$是负样本集合。</li></ul><h3 id="READING-AND-ANSWERING-GIVEN-REASONING-PATHS"><a href="#READING-AND-ANSWERING-GIVEN-REASONING-PATHS" class="headerlink" title="READING AND ANSWERING GIVEN REASONING PATHS"></a>READING AND ANSWERING GIVEN REASONING PATHS</h3><p>使用Bert模型计算推理路径和答案概率。</p><blockquote><p>使用Bert模型对应于CLS标识符位的输出判断推理路径包括答案的概率。</p></blockquote><script type="math/tex; mode=display">P(E|q) = σ(w_n· u_E) \ \ s.t. \ \ u_E= BERT_{[CLS]}(q, E) ∈ \R^D</script><script type="math/tex; mode=display">E_{best}=\underset{E∈E} {arg\ max } \ P(E|q)</script><script type="math/tex; mode=display">S_{read}= \underset{i,j, i≤j}{arg \ max}\   P^{start}_i P^{end}_j</script><h3 id="Multi-task-loss-function"><a href="#Multi-task-loss-function" class="headerlink" title="Multi-task loss function"></a>Multi-task loss function</h3><script type="math/tex; mode=display">L_{read}= L_{span}+ L_{no\_answer}= (− log P^{start}_{y^{start}} − log P^{end}_{y^{end}}) − log P^r</script><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li><strong>HotpotQA</strong></li><li>SQuAD Open</li><li>Natural Question Open</li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p>HotpotQA验证集测试结果:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201210141209.png" alt="image-20201210141209866"></p><p>HotpotQA测试集测试结果:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201210141630.png" alt="image-20201210141630169" style="zoom:50%;" /></p><blockquote><p>本文提出的模型在hotpot数据集上取得了非常优秀的测试结果。</p></blockquote><p>SQuAD Open测试结果:</p><p><img src="/Users/maqi/Library/Application Support/typora-user-images/image-20201210141756755.png" alt="image-20201210141756755" style="zoom:50%;" /></p><p>Natural Question Open测试结果:</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201210141817.png" alt="image-20201210141817154" style="zoom:50%;" /></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>不同的路径抽取方法比较：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201210142007.png" alt="image-20201210142007831" style="zoom:50%;" /></p><p><strong>消融实验：</strong></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201210142257.png" alt="image-20201210142257828" style="zoom:50%;" /></p><blockquote><p>可以看到，移除任何一部分对模型的结果影响都比较大。</p></blockquote><p>实体链接：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201210142511.png" alt="image-20201210142511733" style="zoom:50%;" /></p><blockquote><p>使用超链接和实体链接系统对实验结果影响不大，说明超链接并不是必要因素。</p></blockquote><p>推理路径长度：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201210142637.png" alt="image-20201210142637317" style="zoom:50%;" /></p><blockquote><p>推理路径的长度对实验结果有显著的影响，推理路径较短时准确率较低。</p></blockquote><p>​        本文介绍了一种新的基于图的递归检索方法，该方法在维基百科图上检索推理路径，以回答开放领域多轮问答。使用推理路径提取器构建推理路径，使用阅读理解答案抽取器对推理路径进行重新排序，并将最终答案确定为从最佳推理路径中提取的答案。在多个数据集上都表现出了优秀的性能。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><h3 id="搜索算法beam-search（束搜索）"><a href="#搜索算法beam-search（束搜索）" class="headerlink" title="搜索算法beam search（束搜索）"></a>搜索算法beam search（束搜索）</h3><blockquote><p>是exhaustive search和greedy search的折中方案。</p></blockquote><p>​        beam search有一个超参数<strong>beam size</strong>（束宽），设为$k$ 。第一个时间步长，选取当前条件概率最大的 $k$个词，当做候选输出序列的第一个词。之后的每个时间步长，基于上个步长的输出序列，挑选出<strong>所有组合中</strong>条件概率最大的$k$ 个，作为该时间步长下的候选输出序列。始终保持$k$个候选。最后从$k$个候选中挑出最优的。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MRC </tag>
            
            <tag> NLP </tag>
            
            <tag> 机器阅读理解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>智能开关(Android)</title>
      <link href="/2020/12/10/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3(Android)/"/>
      <url>/2020/12/10/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3(Android)/</url>
      
        <content type="html"><![CDATA[<h1 id="智能开关（Android）"><a href="#智能开关（Android）" class="headerlink" title="智能开关（Android）"></a>智能开关（Android）</h1><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201206135913.jpg" alt="Screenshot_2020-12-02-12-39-30-190_com.example.do"></p><h2 id="开发工具"><a href="#开发工具" class="headerlink" title="开发工具"></a>开发工具</h2><ul><li>AndroidStudio</li></ul><h2 id="Android-APP代码"><a href="#Android-APP代码" class="headerlink" title="Android APP代码"></a>Android APP代码</h2><blockquote><p>GitHub:<a href="https://github.com/Asimok/dorm_light">https://github.com/Asimok/dorm_light</a></p></blockquote><h2 id="教学视频"><a href="#教学视频" class="headerlink" title="教学视频"></a>教学视频</h2><blockquote><p>哔哩哔哩：<a href="https://www.bilibili.com/video/BV18Z4y1g7VS/">https://www.bilibili.com/video/BV18Z4y1g7VS/</a></p></blockquote><h2 id="完整教程"><a href="#完整教程" class="headerlink" title="完整教程"></a>完整教程</h2><p>博客：<a href="https://www.asimok.site/2020/12/06/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3/">https://www.asimok.site/2020/12/06/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3/</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQTT </tag>
            
            <tag> Android </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx 服务器证书安装（配置https）</title>
      <link href="/2020/12/09/Nginx%20%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AF%81%E4%B9%A6%E5%AE%89%E8%A3%85%EF%BC%88%E9%85%8D%E7%BD%AEhttps%EF%BC%89/"/>
      <url>/2020/12/09/Nginx%20%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AF%81%E4%B9%A6%E5%AE%89%E8%A3%85%EF%BC%88%E9%85%8D%E7%BD%AEhttps%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="Nginx-服务器证书安装（配置https）"><a href="#Nginx-服务器证书安装（配置https）" class="headerlink" title="Nginx 服务器证书安装（配置https）"></a>Nginx 服务器证书安装（配置https）</h1><h2 id="下载证书"><a href="#下载证书" class="headerlink" title="下载证书"></a>下载证书</h2><ol><li>从证书颁发平台下载证书</li></ol><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/night1/image-20201209111622263.png" alt="image-20201209111622263"></p><ol><li>选择Nginx下的证书文件</li></ol><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/night1/image-20201209111746085.png" alt="image-20201209111746085"></p><ol><li>上传到服务器</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/ssl</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/night1/image-20201209111909373.png" alt="image-20201209111909373"></p><h2 id="配置Nginx"><a href="#配置Nginx" class="headerlink" title="配置Nginx"></a>配置Nginx</h2><ol><li>启动nginx</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><ol><li>查找正在运行中的nginx服务</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep nginx</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/night1/image-20201209112109135.png" alt="image-20201209112109135"></p><ol><li>修改配置文件</li></ol><ul><li>从正在运行中的nginx服务可以知道当前生效的配置文件。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><ol><li>在http节点下添加server节点，并完成重定向</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">http&#123;</span><br><span class="line">server&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体配置如下：</p><ul><li>http节点中可以添加多个server节点。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">    server&#123;</span><br><span class="line">        #监听443端口</span><br><span class="line">        listen 443 ssl;</span><br><span class="line">        #对应的域名，把www.asimok.com改成你们自己的域名就可以了</span><br><span class="line">        server_name www.asimok.com;</span><br><span class="line">        #从腾讯云获取到的第一个文件的全路径</span><br><span class="line">        ssl_certificate /etc/ssl/1_www.asimok.site_bundle.crt;</span><br><span class="line">        #从腾讯云获取到的第二个文件的全路径</span><br><span class="line">        ssl_certificate_key /etc/ssl/2_www.asimok.site.key;</span><br><span class="line">        ssl_session_timeout 5m;</span><br><span class="line">        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;</span><br><span class="line">        ssl_prefer_server_ciphers on;</span><br><span class="line">        #这是我的主页访问地址，因为使用的是静态的html网页，所以直接使用location就可以完成了。</span><br><span class="line">        location / &#123;</span><br><span class="line">                #文件夹</span><br><span class="line">                root /root/mq_blog/public;</span><br><span class="line">                #主页文件</span><br><span class="line">                index index.html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"># 如果用户使用的是http协议进行访问，那么默认打开的端口是80端口，所以我们需要做一个重定向，我们在上一个代码块的基础上增加一个server节点提供重定向服务。</span><br><span class="line"># 将 HTTP 请求自动重定向到 HTTPS</span><br><span class="line">    server&#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        server_name www.asimok.com;</span><br><span class="line">        rewrite ^/(.*)$ https://www.asimok.com:443/$1 permanent;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ol><li>对配置文件进行校验</li></ol><p>保存配置文件之后执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -t</span><br></pre></td></tr></table></figure><p>susccessful即可</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/night1/image-20201209112907309.png" alt="image-20201209112907309"></p><ol><li>重启nginx服务</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><ol><li>重新加载配置文件</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>使用https访问：<a href="https://asimok.site">https://asimok.site</a></p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> https </tag>
            
            <tag> nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>anaconda更换清华源加快下载速度</title>
      <link href="/2020/12/08/anaconda%E6%9B%B4%E6%8D%A2%E6%B8%85%E5%8D%8E%E6%BA%90%E5%8A%A0%E5%BF%AB%E4%B8%8B%E8%BD%BD%E9%80%9F%E5%BA%A6/"/>
      <url>/2020/12/08/anaconda%E6%9B%B4%E6%8D%A2%E6%B8%85%E5%8D%8E%E6%BA%90%E5%8A%A0%E5%BF%AB%E4%B8%8B%E8%BD%BD%E9%80%9F%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<h1 id="anaconda更换清华源加快下载速度"><a href="#anaconda更换清华源加快下载速度" class="headerlink" title="anaconda更换清华源加快下载速度"></a>anaconda更换清华源加快下载速度</h1><p>终端执行以下代码：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --append channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/fastai/</span><br><span class="line">conda config --append channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">conda config --append channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ </span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure><br>可以看到 ~/.condarc文件如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/</span><br><span class="line">  - defaults</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/fastai/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/</span><br><span class="line">show_channel_urls: true</span><br></pre></td></tr></table></figure><p>配置完成后，下载速度会提升很多。</p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux挂载移动硬盘出现错误：mount:unknown filesystem type &#39;exfat&#39;</title>
      <link href="/2020/12/07/Linux%E6%8C%82%E8%BD%BD%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AF/"/>
      <url>/2020/12/07/Linux%E6%8C%82%E8%BD%BD%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux挂载移动硬盘出现错误：mount-unknown-filesystem-type-‘exfat’"><a href="#Linux挂载移动硬盘出现错误：mount-unknown-filesystem-type-‘exfat’" class="headerlink" title="Linux挂载移动硬盘出现错误：mount:unknown filesystem type ‘exfat’"></a>Linux挂载移动硬盘出现错误：mount:unknown filesystem type ‘exfat’</h1><p>exfat是可以在windows,mac,Linux共享的文件系统</p><p><strong>解决办法：</strong></p><ul><li><p>安装exfat-fuse:</p><p><code>sudo apt-get install exfat-fuse</code></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch_pretrained_bert的配置使用</title>
      <link href="/2020/12/07/Bert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2020/12/07/Bert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="pytorch-pretrained-bert的配置使用"><a href="#pytorch-pretrained-bert的配置使用" class="headerlink" title="pytorch_pretrained_bert的配置使用"></a>pytorch_pretrained_bert的配置使用</h1><h2 id="pytorch-pretrained-bert"><a href="#pytorch-pretrained-bert" class="headerlink" title="pytorch_pretrained_bert"></a>pytorch_pretrained_bert</h2><blockquote><p><a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p></blockquote><ul><li><p>安装加载预训练模型和权重的包：pip install pytorch-pretrained-bert</p></li><li><p>修改源码</p><blockquote><p>从亚马逊站点下载非常慢，可以将源码中的地址更换为本地文件。</p></blockquote><ol><li>pytorch_pretrained_bert/modeling.py的 40-51行</li></ol><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201207210830.png" alt="image-20201207210830430"></p><ol><li>pytorch_pretrained_bert/tokenization.py的30-41行</li></ol></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201207210928.png" alt="image-20201207210928928"></p>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
            <tag> bert </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux(Ubuntu)安装配置</title>
      <link href="/2020/12/07/Linux(Ubuntu)%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/12/07/Linux(Ubuntu)%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux-Ubuntu-安装配置"><a href="#Linux-Ubuntu-安装配置" class="headerlink" title="Linux(Ubuntu)安装配置"></a>Linux(Ubuntu)安装配置</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><div class="table-container"><table><thead><tr><th>挂载点</th><th>说明</th><th>大小</th></tr></thead><tbody><tr><td>/</td><td>主分区</td><td>100G</td></tr><tr><td>/home</td><td></td><td>100G</td></tr><tr><td>/efi</td><td>与其他系统共用即可</td><td>200M</td></tr></tbody></table></div><h3 id="挂载分区到-home"><a href="#挂载分区到-home" class="headerlink" title="挂载分区到/home"></a>挂载分区到/home</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo fdisk /dev/vdb</span><br><span class="line">mount /dev/sda4 /home</span><br></pre></td></tr></table></figure><p>开机自动挂载：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/fstab</span><br><span class="line">/dev/sda4        /home        ext4        defaults        0  0</span><br></pre></td></tr></table></figure><p>验证：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df -h</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><ul><li>安装win10双系统会导致时间差问题</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timedatectl set-local-rtc true</span><br></pre></td></tr></table></figure><ul><li>更换镜像源</li></ul><blockquote><p>查看系统代号(Ubuntu19.10)<br><code>lsb_release -c</code></p></blockquote><p>1.镜像源文件存放在/etc/apt/sources.list下，拷贝一份sources.list文件，以防万一。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp -v /etc/apt/sources.list /etc/apt/sources.list.backup</span><br></pre></td></tr></table></figure><p>2.使用gedit编辑镜像源文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo  gedit /etc/apt/sources.list</span><br></pre></td></tr></table></figure><p>3.替换文件，将以下内容拷贝到sources.list,将下面代码中的　 eoan　改为自己版本的系统代号即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse</span><br><span class="line"></span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>４.改好之后更新一下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br></pre></td></tr></table></figure><ul><li>代理</li></ul><div class="table-container"><table><thead><tr><th>协议</th><th>ip</th><th>端口</th></tr></thead><tbody><tr><td>http</td><td>127.0.0.1</td><td>端口一般12333</td></tr><tr><td>socks v5</td><td>127.0.0.1</td><td>1080</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Liunx </tag>
            
            <tag> Ubuntu </tag>
            
            <tag> 配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>智能开关</title>
      <link href="/2020/12/06/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3/"/>
      <url>/2020/12/06/%E6%99%BA%E8%83%BD%E5%BC%80%E5%85%B3/</url>
      
        <content type="html"><![CDATA[<h1 id="智能开关"><a href="#智能开关" class="headerlink" title="智能开关"></a>智能开关</h1><p>演示视频：<a href="https://www.bilibili.com/video/BV1qz4y1k7xS/">https://www.bilibili.com/video/BV1qz4y1k7xS/</a></p><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201202174343.jpeg" alt="图像"></p><p><img src="https://gitee.com/Asimok/picgo/raw/master/img/MacBookPro/20201206135913.jpg" alt="Screenshot_2020-12-02-12-39-30-190_com.example.do"></p><h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><p>完整教学视频：</p><ul><li>第一期：<a href="https://www.bilibili.com/video/BV1Ma4y1W7jh/">https://www.bilibili.com/video/BV1Ma4y1W7jh/</a></li><li>第二期：<a href="https://www.bilibili.com/video/BV1ZK41137YH/">https://www.bilibili.com/video/BV1ZK41137YH/</a></li><li>第三期：<a href="https://www.bilibili.com/video/BV18Z4y1g7VS/">https://www.bilibili.com/video/BV18Z4y1g7VS/</a></li></ul><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><p><strong>硬件部分      服务器       安卓APP</strong></p><blockquote><p>通信协议：MQTT</p></blockquote><h2 id="清单"><a href="#清单" class="headerlink" title="清单"></a>清单</h2><p><strong>NodeMCU</strong>：ESP8266串口wifi模块 NodeMCU Lua V3物联网开发板 CH340 CP2102(淘宝搜索)<br><strong>舵机</strong>：180度<br><strong>电源模块</strong>：提供5v,3.3v输出<br><strong>dht11</strong>温湿度传感器<br><strong>杜邦线</strong> ：公对公  公对母  母对母</p><blockquote><p>esp8266库：<code>https://arduino.esp8266.com/stable/package_esp8266com_index.json</code></p></blockquote><h2 id="开发工具"><a href="#开发工具" class="headerlink" title="开发工具"></a>开发工具</h2><ul><li>Arduino IDE</li><li>EMQ X</li><li>AndroidStudio</li></ul><h2 id="Android-APP代码"><a href="#Android-APP代码" class="headerlink" title="Android APP代码"></a>Android APP代码</h2><blockquote><p>GitHub:<a href="https://github.com/Asimok/dorm_light">https://github.com/Asimok/dorm_light</a></p></blockquote><h2 id="nodeMCU代码"><a href="#nodeMCU代码" class="headerlink" title="nodeMCU代码"></a>nodeMCU代码</h2><blockquote><p>GitHub:<a href="https://github.com/Asimok/unoproject_backup/tree/master/dorm_light/dorm_light_temp_8266">https://github.com/Asimok/unoproject_backup/tree/master/dorm_light/dorm_light_temp_8266</a></p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">  智能开关nodemcu代码</span></span><br><span class="line"><span class="comment">  D0 舵机左</span></span><br><span class="line"><span class="comment">  D1 舵机右</span></span><br><span class="line"><span class="comment">  D2 dht11</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">/*arduino安装自带*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;Servo.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;SoftwareSerial.h&gt;</span></span></span><br><span class="line"><span class="comment">/*自行安装*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ESP8266WiFi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;PubSubClient.h&gt;</span></span></span><br><span class="line"><span class="comment">/*引入本地头文件*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;dht11.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;ArduinoJson-v6.15.2.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> dht11Pin D2   <span class="comment">//定义温湿度针脚号为D2号引脚</span></span></span><br><span class="line"><span class="comment">/*实例化对象*/</span></span><br><span class="line">dht11 dht;</span><br><span class="line">Servo left_servo, right_servo;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**MQTT服务器参数配置*/</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* wifiSSID = <span class="string">&quot;wifi名称&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* password = <span class="string">&quot;密码&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* mqttServer = <span class="string">&quot;IP&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> mqttPort = <span class="number">1883</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* clientId = <span class="string">&quot;设备id&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span>* topic = <span class="string">&quot;订阅主题&quot;</span>;</span><br><span class="line"></span><br><span class="line">WiFiClient espClient;</span><br><span class="line"><span class="function">PubSubClient <span class="title">client</span><span class="params">(espClient)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*开关状态*/</span></span><br><span class="line"><span class="keyword">bool</span> leftStatue = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">bool</span> rightStatue = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">setup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  delay(<span class="number">1000</span>);</span><br><span class="line">  switchlight(<span class="string">&quot;closeLeft&quot;</span>);</span><br><span class="line">  delay(<span class="number">500</span>);</span><br><span class="line">  switchlight(<span class="string">&quot;closeRight&quot;</span>);</span><br><span class="line">  delay(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  <span class="comment">/*连接wifi*/</span></span><br><span class="line">  WiFi.begin(wifiSSID, password);</span><br><span class="line">  <span class="keyword">while</span> (WiFi.status() != WL_CONNECTED) &#123;</span><br><span class="line">    delay(<span class="number">500</span>);</span><br><span class="line">    <span class="comment">// Serial.println(&quot;Connecting to WiFi..&quot;);</span></span><br><span class="line">  &#125;</span><br><span class="line">  Serial.println(<span class="string">&quot;Connected to the WiFi network&quot;</span>);</span><br><span class="line">  <span class="comment">/*连接MQTT服务器*/</span></span><br><span class="line">  client.setServer(mqttServer, mqttPort);</span><br><span class="line">  client.setCallback(callback);</span><br><span class="line">  <span class="keyword">while</span> (!client.connected()) &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;Connecting to MQTT...&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (client.connect(clientId)) &#123;</span><br><span class="line">      Serial.println(<span class="string">&quot;MQTT connected&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      Serial.print(<span class="string">&quot;failed with state &quot;</span>);</span><br><span class="line">      Serial.print(client.state());</span><br><span class="line">      delay(<span class="number">2000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  pinMode(dht11Pin, OUTPUT);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">char</span> buff[<span class="number">50</span>];</span><br><span class="line">  <span class="built_in">memset</span>(buff, <span class="number">0</span>, <span class="keyword">sizeof</span>(buff));</span><br><span class="line">  <span class="built_in">strcpy</span>(buff, clientId);</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span> *buff2 = <span class="string">&quot; 上线&quot;</span>;</span><br><span class="line">  <span class="built_in">strcat</span>(buff, buff2);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//发送连接成功消息</span></span><br><span class="line">  client.publish(topic, buff );</span><br><span class="line">  <span class="comment">//订阅主题</span></span><br><span class="line">  client.subscribe(topic);</span><br><span class="line">  delay(<span class="number">100</span>);</span><br><span class="line">  <span class="comment">//  初始化开关状态</span></span><br><span class="line">  switchlight(<span class="string">&quot;closeLeft&quot;</span>);</span><br><span class="line">  delay(<span class="number">1000</span>);</span><br><span class="line">  switchlight(<span class="string">&quot;closeRight&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">get_dht11</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">char</span> msg[<span class="number">500</span>];</span><br><span class="line">  <span class="keyword">int</span> tol = dht.read(dht11Pin);    <span class="comment">//将读取到的值赋给tol</span></span><br><span class="line">  <span class="keyword">int</span> temp = (<span class="keyword">float</span>)dht.temperature; <span class="comment">//将温度值赋值给temp</span></span><br><span class="line">  <span class="keyword">int</span> humi = (<span class="keyword">float</span>)dht.humidity; <span class="comment">//将湿度值赋给humi</span></span><br><span class="line">  </span><br><span class="line">  delay(<span class="number">10</span>);      <span class="comment">//延时1秒</span></span><br><span class="line">  StaticJsonDocument&lt;<span class="number">200</span>&gt; temperature_data;</span><br><span class="line">  temperature_data[<span class="string">&quot;sensor&quot;</span>] = <span class="string">&quot;DHT11&quot;</span>;</span><br><span class="line">  temperature_data[<span class="string">&quot;temp&quot;</span>] = temp;</span><br><span class="line">  temperature_data[<span class="string">&quot;humi&quot;</span>] = humi;</span><br><span class="line">  serializeJson(temperature_data, msg);</span><br><span class="line">  <span class="comment">//Serial.println(msg);</span></span><br><span class="line">  client.publish(topic, msg);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   断开重连</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reconnect_mqtt</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (!client.connected()) &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;reConnecting to MQTT...&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (client.connect(clientId)) &#123;</span><br><span class="line">      Serial.println(<span class="string">&quot;connected&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      Serial.print(<span class="string">&quot;failed with state &quot;</span>);</span><br><span class="line">      Serial.print(client.state());</span><br><span class="line">      delay(<span class="number">2000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reconnect_wifi</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (WiFi.status() != WL_CONNECTED) &#123;</span><br><span class="line">    delay(<span class="number">500</span>);</span><br><span class="line">    Serial.println(<span class="string">&quot;Connecting to WiFi..&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  Serial.println(<span class="string">&quot;reConnected to the WiFi network&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">callback</span><span class="params">(<span class="keyword">char</span>* topic, byte* payload, <span class="keyword">unsigned</span> <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//收到消息</span></span><br><span class="line">  Serial.print(<span class="string">&quot;Message:&quot;</span>);</span><br><span class="line">  <span class="keyword">char</span> a[<span class="number">2000</span>] = <span class="string">&quot;&quot;</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">    Serial.print((<span class="keyword">char</span>)payload[i]);</span><br><span class="line">    a[i] = (<span class="keyword">char</span>)payload[i];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  docode(a);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">docode</span><span class="params">(<span class="keyword">char</span> json[<span class="number">2000</span>])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="comment">//  解析指令</span></span><br><span class="line">  <span class="comment">//  &#123;&quot;code&quot;:&quot;openLeft&quot;&#125;</span></span><br><span class="line">  StaticJsonDocument&lt;<span class="number">200</span>&gt; doc;</span><br><span class="line">  deserializeJson(doc, json);</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">char</span>* code = doc[<span class="string">&quot;code&quot;</span>];</span><br><span class="line">  Serial.println();</span><br><span class="line">  Serial.println(code);</span><br><span class="line">  String tempcode;</span><br><span class="line">  tempcode = String(code);</span><br><span class="line">  <span class="keyword">if</span> (tempcode == <span class="string">&quot;get_dht11&quot;</span>)</span><br><span class="line">    get_dht11();</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (tempcode == <span class="string">&quot;get_light_status&quot;</span>)</span><br><span class="line">    send_light_data();</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    switchlight(tempcode);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">switchlight</span><span class="params">(String tempcode)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  delay(<span class="number">50</span>);</span><br><span class="line">  <span class="keyword">if</span> (tempcode == <span class="string">&quot;openLeft&quot;</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    left_servo.attach(D0);</span><br><span class="line">    left_servo.write(<span class="number">82</span>);</span><br><span class="line">    delay(<span class="number">300</span>);</span><br><span class="line">    left_servo.write(<span class="number">45</span>);</span><br><span class="line">    delay(<span class="number">100</span>);</span><br><span class="line">    left_servo.detach();</span><br><span class="line">    leftStatue = <span class="literal">true</span>;</span><br><span class="line">    send_light_data();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (tempcode == <span class="string">&quot;openRight&quot;</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    right_servo.attach(D1);</span><br><span class="line">    right_servo.write(<span class="number">8</span>);</span><br><span class="line">    delay(<span class="number">300</span>);</span><br><span class="line">    right_servo.write(<span class="number">65</span>);</span><br><span class="line">    delay(<span class="number">100</span>);</span><br><span class="line">    right_servo.detach();</span><br><span class="line">    rightStatue = <span class="literal">true</span>;</span><br><span class="line">    send_light_data();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (tempcode == <span class="string">&quot;closeLeft&quot;</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    left_servo.attach(D0);</span><br><span class="line">    left_servo.write(<span class="number">2</span>);</span><br><span class="line">    delay(<span class="number">300</span>);</span><br><span class="line">    left_servo.write(<span class="number">45</span>);</span><br><span class="line">    delay(<span class="number">100</span>);</span><br><span class="line">    left_servo.detach();</span><br><span class="line">    leftStatue = <span class="literal">false</span>;</span><br><span class="line">    send_light_data();</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (tempcode == <span class="string">&quot;closeRight&quot;</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    right_servo.attach(D1);</span><br><span class="line">    right_servo.write(<span class="number">130</span>);</span><br><span class="line">    delay(<span class="number">300</span>);</span><br><span class="line">    right_servo.write(<span class="number">65</span>);</span><br><span class="line">    delay(<span class="number">100</span>);</span><br><span class="line">    right_servo.detach();</span><br><span class="line">    rightStatue = <span class="literal">false</span>;</span><br><span class="line">    send_light_data();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">send_light_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  delay(<span class="number">10</span>);</span><br><span class="line">  <span class="keyword">char</span> msg[<span class="number">500</span>];</span><br><span class="line">  StaticJsonDocument&lt;<span class="number">200</span>&gt; light_data;</span><br><span class="line">  light_data[<span class="string">&quot;sensor&quot;</span>] = <span class="string">&quot;servo&quot;</span>;</span><br><span class="line">  light_data[<span class="string">&quot;left&quot;</span>] = leftStatue;</span><br><span class="line">  light_data[<span class="string">&quot;right&quot;</span>] = rightStatue;</span><br><span class="line">  serializeJson(light_data, msg);</span><br><span class="line">  <span class="comment">// Serial.println(msg);</span></span><br><span class="line">  </span><br><span class="line">  client.publish(topic, msg );</span><br><span class="line">  delay(<span class="number">100</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">loop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">//重连机制</span></span><br><span class="line">  <span class="keyword">if</span> (!client.connected()) &#123;</span><br><span class="line">    reconnect_mqtt();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (WiFi.status() != WL_CONNECTED)</span><br><span class="line">  &#123;</span><br><span class="line">    reconnect_wifi();</span><br><span class="line">  &#125;</span><br><span class="line">  client.loop();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 硬件开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MQTT </tag>
            
            <tag> Arduino </tag>
            
            <tag> Android </tag>
            
            <tag> C </tag>
            
            <tag> ESP8266 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Is Graph Structure Necessary for Multi-hop Question Answering?</title>
      <link href="/2020/12/03/Is%20Graph%20Structure%20Necessary%20for%20Multi-hop%20Question%20Answering/"/>
      <url>/2020/12/03/Is%20Graph%20Structure%20Necessary%20for%20Multi-hop%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<h1 id="Is-Graph-Structure-Necessary-for-Multi-hop-Question-Answering"><a href="#Is-Graph-Structure-Necessary-for-Multi-hop-Question-Answering" class="headerlink" title="Is Graph Structure Necessary for Multi-hop Question Answering?"></a>Is Graph Structure Necessary for Multi-hop Question Answering?</h1><blockquote><p>论文：EMNLP 2020-Is Graph Structure Necessary for Multi-hop Question Answering</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>探讨多步推理问答任务中是否需要图结构的问题。</p><p>验证自注意力或者Transformer可能更加擅长处理多步推理问答任务。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><ul><li>本文的实验使用Distractor设定。</li></ul><h3 id="基线模型"><a href="#基线模型" class="headerlink" title="基线模型"></a>基线模型</h3><ul><li><p>使用一个检索模型检出候选段落中的相关段落并输入一个基于图的问答模型，其中图中的所有节点都是由一个额外的NER模型所识别得到的实体构成。</p></li><li><p>使用一个<strong>RoBERTa large</strong>模型来计算每个问题与候选段落之间的相关性。</p></li><li>在编码层，将问题和上下文拼接并输入另一个<strong>RoBERTa large</strong>模型，所得到的输出被输入到一个双向注意力层来得到编码层的输出。</li><li>在图融合层(Graph Fusion Block)，给定第$t-1$步的上下文表示$C<em>{t-1}$，其中所有<strong>token</strong>的向量表示都会通过<strong>mean-max</strong>池化层来得到实体图中的所有节点的表示$H</em>{t-1}\in ℝ^{2d\times N}$，其中N为实体的数量。</li><li>在预测层，这里使用了一种“瀑布式”的结构来预测<strong>HotpotQA</strong>任务所要求的答案文本和线索句子。</li><li>为了寻找文本中的实体并构建实体图，使用一个基于BERT的NER模型并在<strong>CoNLL’03</strong>数据集上进行微调。</li></ul><h3 id="理解图网络"><a href="#理解图网络" class="headerlink" title="理解图网络"></a>理解图网络</h3><p>原始文本中的实体被建模为实体图并使用图注意力网络进行处理，当实体图为全连接时，图注意力层将退化为传统的自注意力层。</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201202220312.png" alt="image-20201202220312314"></p><p>​        为了回答一个需要多步推理的问题，首先需要从原始文本中找到与问题中出现的相同实体，然后以该实体作为起点构建从该实体到其他共现或相同实体的推理链。</p><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><p>预训练模型使用Feature-based的方法。</p><h5 id="包含图结构的模型"><a href="#包含图结构的模型" class="headerlink" title="包含图结构的模型"></a>包含图结构的模型</h5><blockquote><p>验证作为先验知识的邻接矩阵是否必要。</p></blockquote><ul><li><p>验证作为先验知识的邻接矩阵是否必要。</p></li><li><p>评估了不同邻接矩阵密度对于结果的影响。</p><blockquote><p>将一个0-1矩阵的密度定义为其中1的比例。</p></blockquote></li></ul><h5 id="不包含图的模型"><a href="#不包含图的模型" class="headerlink" title="不包含图的模型"></a>不包含图的模型</h5><p>​        为了验证图结构本身是否有必要，这里直接将两层的图结构替换为传统的Transformer层。其中编码层得到的上下文token表示直接输入Transformer。</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p><strong>HotpotQA数据集</strong></p><ul><li>一个广泛使用的多步推理问答数据。</li><li>该数据包含两种设定：<strong>Distractor</strong>,<strong>Fullwiki</strong>。<ul><li>Distractor设定中每个问题对应2个正确段落和8个干扰段落。</li><li>Fullwiki设定则要求模型从整个维基百科中检出正确的段落。</li></ul></li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><h3 id="基线模型-1"><a href="#基线模型-1" class="headerlink" title="基线模型"></a>基线模型</h3><ul><li>基线模型在HotpotQA测试集的结果</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201202214006.png" alt="image-20201202214006013"></p><p>本文提出的模型，在HotpotQA隐藏的测试集上与其他模型相比效果最优化。</p><ul><li>不同设定下图结构的消融实验</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201202214543.png" alt="image-20201202214543544"></p><blockquote><p>为了分析图结构对于整个模型起了多大的贡献，本文的模型移除了整个图融合模块，使预训练的输出直接输入给预测层。</p></blockquote><p>在预训练模型以fine-tuning的方式使用时:</p><ul><li>包含和不包含图结构的模型都取得了相似的结果。</li></ul><p>当固定预训练模型的参数时：</p><ul><li>包含图结构时：EM和F1显著下降。</li><li>移除图结构时：EM和F1略有下降。</li></ul><h3 id="理解图网络-1"><a href="#理解图网络-1" class="headerlink" title="理解图网络"></a>理解图网络</h3><p>设置不同模块条件下EM和F1性能的比较：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201202222312.png" alt="image-20201202222312328"></p><ul><li>与基线模型相比，带有图融合层的模型有非常显著的优势。</li><li>给基线模型添加了图注意力层后，基线模型获得了较为明显的提升，但与添加自注意力机制的效果接近。</li><li>Transformer也表现出了较好的推理能力。</li></ul><p>位于不同分位点样本的邻接矩阵密度：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201203123235.png" alt="image-20201203123235725"></p><p>不同邻接矩阵密度下图注意力和自注意力的效果对比：</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201203123554.png" alt="image-20201203123554888"></p><ul><li>图注意力网络与自注意力在不同邻接矩阵密度的样本上结果相近，证明自注意力确实能够自行学会忽略不相干实体。</li><li>密度越大的样本EM/F1得分越高，这可能是因为这些样本长度普遍更短，因此也更加容易定位答案的位置。</li></ul><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul><li>只有当预训练模型以Feature-based的方式使用时，图结构才会起到比较明显的作用。而当预训练模型以Fine-tuning的方式使用时，图结构并没有对结果起到贡献，因此，图结构可能不是解决多步推理问题所必要的结构。</li><li>图注意力机制和图结构可以被自注意力机制或Transformer代替。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> 机器阅读理解 </tag>
            
            <tag> MC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MemNN</title>
      <link href="/2020/11/26/MemNN/"/>
      <url>/2020/11/26/MemNN/</url>
      
        <content type="html"><![CDATA[<h1 id="MemNN"><a href="#MemNN" class="headerlink" title="MemNN"></a>MemNN</h1><blockquote><p>Memory Networks：记忆网络</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>传统的RNN和其改进模型虽然具有记忆功能，但是在长期记忆中表现并不好，Memory Networks的目的是实现长期记忆。</p><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><h3 id="MEMORY-NETWORKS"><a href="#MEMORY-NETWORKS" class="headerlink" title="MEMORY NETWORKS"></a>MEMORY NETWORKS</h3><p>组成：1个内存模块(m—用索引的数组)，4个组件(I,G,O,R—通过学习得到)</p><h4 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h4><ul><li>$I$:（输入特征映射）—— 将输入转换为内部特征表示。</li><li><p>$G$:（泛化）—— 对于给定新的输入更新旧的内存。称之为泛化是因为在这个阶段网络有机会压缩并泛化其内存以供未来某些需要。</p></li><li><p>$O$:（输出特征映射）—— 给定新的输入与当前的内存状态，产生新的输出（在特征空间中）。</p></li><li>$R$:（回复）—— 将输出转换为特定格式的回复。比如，文本回复或者一个动作。</li></ul><h4 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h4><ul><li>输入$x$（可以是单词，句子，图片，音频）</li><li>将$x$转为内部特征表示：$I(x)$</li><li>更新内存$m_i$：$m_i= G(m_i, I(x), m), ∀i$</li><li>计算输出特征：$o = O(I(x), m)$</li><li>将输出特征解码，得到最终回复：$r = R(o)$</li></ul><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><ul><li>$G$：最简单的实现是利用下述$H(x$)将输入$I(x)$存储到槽中。</li></ul><script type="math/tex; mode=display">m_{H(x)}=I(x)</script><blockquote><p> H(x) 是一个寻址函数（slot choosing function）。</p><p>G 更新的是$m$的$index$，可以直接把新的输入 $I(x)$ 保存到下一个空闲的地址$m_n$，并不更新原有的memory。</p></blockquote><p>更复杂的 G 函数可以去更新更早的memory甚至是所有的memory。</p><h4 id="A-MEMNN-IMPLEMENTATION-FOR-TEXT"><a href="#A-MEMNN-IMPLEMENTATION-FOR-TEXT" class="headerlink" title="A MEMNN IMPLEMENTATION FOR TEXT"></a>A MEMNN IMPLEMENTATION FOR TEXT</h4><ul><li>$I$：sentence</li><li>$G$：将输入保存到下一个可用的地址，仅用于存储新的memory，并不更新原有的memory。</li><li>$O$：输入一个问题$x$，将最合适的$k$个支撑记忆（the supporting memories）返回。</li></ul><p>k=1时：</p><script type="math/tex; mode=display">o1= O1(x, m) =  \underset{i=1,...,N}{arg\max}\ s_O(x, m_i)</script><p>k=2时：</p><script type="math/tex; mode=display">o2= O2(x, m) = \underset{i=1,...,N} {arg\ max} \  s_O([x, m_{o1}], mi)</script><p>输出：$o$：$[x, m<em>{o1}, m</em>{o2}]$</p><blockquote><p>$s_O$：对匹配项的评分函数。</p></blockquote><ul><li>$R$：根据$O$的输出，返回一组词汇。</li></ul><script type="math/tex; mode=display">r = argmax_{w∈W}s_R([x, m_{o1}, m_{o2}], w)</script><blockquote><p>$W$：字典中左右单词的词汇列表。</p><p>$s_R$：对匹配项的评分函数。</p><p>推理的核心：$O,R$组件。</p></blockquote><h5 id="评分函数"><a href="#评分函数" class="headerlink" title="评分函数"></a>评分函数</h5><p>评分函数$s_O,s_R$具有与嵌入模型相同的形式。</p><script type="math/tex; mode=display">s(x, y) = Φ_x(x)^⊤U^⊤UΦ_y(y)</script><ul><li>使用损失函数<strong>MarginRankingLoss</strong>和<strong>SGD</strong>优化器训练。</li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>$QA$</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201124162815.png" alt="image-20201124162815142" style="zoom:50%;" /></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>单个单词回答任务：</p><ul><li>在Difficulty 1任务上，RNN和LSTM在提问之前表现较好，但是提问后效果变差，是由于RNN和LSTM长期记忆较差导致的。</li><li>在Difficulty 5任务上，由于模型限制RNN和LSTM表现较差，随着难度增加，效果还会更差。</li><li>在actor和actor+object任务上加入时间特征，效果提升很明显。</li><li>使用了两段推理的MemNN表现最好。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> MemNN </tag>
            
            <tag> 阅读理解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>emqx配置https并使用nginx反向代理</title>
      <link href="/2020/11/20/emqx%E9%85%8D%E7%BD%AEhttps%E5%B9%B6%E4%BD%BF%E7%94%A8nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"/>
      <url>/2020/11/20/emqx%E9%85%8D%E7%BD%AEhttps%E5%B9%B6%E4%BD%BF%E7%94%A8nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="emqx配置https并使用nginx反向代理"><a href="#emqx配置https并使用nginx反向代理" class="headerlink" title="emqx配置https并使用nginx反向代理"></a>emqx配置https并使用nginx反向代理</h1><ol><li><p>下载域名证书，找到.crt或.key，编辑器打开，复制秘钥文本，找在线转pem工具，生成.pem文件。</p><blockquote><p>ssl证书从DNSpod下载 <a href="https://console.cloud.tencent.com/cns/detail/dengemo.com/records/0">https://console.cloud.tencent.com/cns/detail/dengemo.com/records/0</a></p><p>在线转pem：<a href="https://www.myssl.cn/tools/merge-pem-cert.html">https://www.myssl.cn/tools/merge-pem-cert.html</a></p><p>选择PEM文件包括证书(CRT/CER)</p></blockquote><p>下载的证书如图：</p><blockquote><p>腾讯云已经有pem,crt,key，因此可以不用转pem</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20220208003754.png" alt="image-20220208003754624" style="zoom:50%;" /></p><blockquote><p>如果下载的证书没有pem，使用在线工具进行转换</p></blockquote></li></ol><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201121105009.jpg" alt="621605869569_.pic_hd"></p><ol><li><p>在emq中启动ssl</p><blockquote><p>whereis emqx 可查看安装路径</p></blockquote></li></ol><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201121105109.jpg" alt="641605869642_.pic_hd"></p><blockquote><p>修改emqx.conf如下部分</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">listener.wss.external = 8084</span><br><span class="line">listener.wss.external.keyfile = /root/cert/key.pem</span><br><span class="line">listener.wss.external.certfile = /root/cert/dengemo.com_bundle.pem</span><br></pre></td></tr></table></figure><p>重启emqx</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">emqx stop</span><br><span class="line">emqx start</span><br></pre></td></tr></table></figure><ol><li><p>配置nginx的反向代理</p><blockquote><p>配置文档：<a href="https://docs.emqx.net">https://docs.emqx.net</a> SDK &amp; Tools -&gt; MQTT微信小程序接入</p></blockquote></li></ol><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201121105124.jpg" alt="661605869702_.pic_hd"></p><blockquote><p>编辑/etc/nginx/nginx.conf</p><p>添加一个server</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#https</span><br><span class="line">    server &#123;</span><br><span class="line">    listen  443 ssl;        </span><br><span class="line">    server_name dengemo.com; </span><br><span class="line">    ssl_certificate   &quot;/root/cert/dengemo.com_bundle.crt&quot;;</span><br><span class="line">    ssl_certificate_key  &quot;/root/cert/dengemo.com.key&quot;;</span><br><span class="line">    ssl_session_timeout  5m;      </span><br><span class="line">    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;</span><br><span class="line">    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</span><br><span class="line">    ssl_prefer_server_ciphers on;</span><br><span class="line"></span><br><span class="line">    # 添加反向代理</span><br><span class="line">    location /mqtt &#123;</span><br><span class="line">      proxy_pass http://127.0.0.1:8083/mqtt;</span><br><span class="line">      proxy_set_header Host $host;</span><br><span class="line">      proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">      # client_max_body_size 35m;</span><br><span class="line">      proxy_http_version 1.1;</span><br><span class="line">      proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">      proxy_set_header Connection &quot;upgrade&quot;;    </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><blockquote><p>对配置文件进行校验</p><p>保存配置文件之后执行：</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -t</span><br></pre></td></tr></table></figure><p>susccessful即可</p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/night1/image-20201209112907309.png" alt="image-20201209112907309"></p><p>重启nginx服务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><p>重新加载配置文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure><ul><li>用ngix反向代理后，wss连接端口就成了443，不是8084。</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201121105147.jpg" alt="681605869823_.pic_hd"></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201121105159.jpg" alt="691605869841_.pic_hd"></p><ol><li>配置文件</li></ol><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201121105227.jpg" alt="711605869889_.pic_hd"></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201121105245.jpg" alt="721605869914_.pic_hd"></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201121105709.jpg" alt="751605870352_.pic_hd"></p><ul><li>查看安装路径</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201121105423.jpg" alt="761605870415_.pic_hd"></p><blockquote><p>但不知道什么原因，不使用nginx做反向代理的话，用wss 8084 是无法连接的。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> https </tag>
            
            <tag> nginx </tag>
            
            <tag> emqx </tag>
            
            <tag> MQTT </tag>
            
            <tag> ssl </tag>
            
            <tag> wss </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention Is All You Need</title>
      <link href="/2020/11/19/Attention%20Is%20All%20You%20Need/"/>
      <url>/2020/11/19/Attention%20Is%20All%20You%20Need/</url>
      
        <content type="html"><![CDATA[<h1 id="Attention-Is-All-You-Need"><a href="#Attention-Is-All-You-Need" class="headerlink" title="Attention Is All You Need"></a>Attention Is All You Need</h1><blockquote><p>应用于NLP的机器翻译问题。</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><ul><li>由于RNN的递归结构，导致它无法并行计算，RNN以及他的衍生模型最大的缺点就是计算缓慢。并且缺乏对全局信息的理解。因此提出了完全基于attention的Transformer模型。</li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p>Transformer模型是纯attention模型，完全依赖attention机制来描述输入与输出的全局依赖。</p><h3 id="模型："><a href="#模型：" class="headerlink" title="模型："></a>模型：</h3><ul><li>输入：$x=(x1,x2,⋯,xn)$（是一个离散的符号序列）</li><li>encoder：将它映射成连续值序，$z=(z1,z2,⋯,zn)$</li><li>decoder：对于给定的$z$，生成一个输出符号序列，$y=(y1,y2,⋯,ym)$</li><li>优化器：Adam</li><li>使用dropout和Label Smoothing防止过拟合</li></ul><h3 id="Encoder-and-Decoder-Stacks"><a href="#Encoder-and-Decoder-Stacks" class="headerlink" title="Encoder and Decoder Stacks"></a>Encoder and Decoder Stacks</h3><blockquote><p>Encoder与Decoder堆叠</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201117204449.png" alt="image-20201117204444453" style="zoom:50%;" /></p><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><ul><li>Transformer模型的Encoder由6个基本层堆叠起来，每个基本层包含两个子层。</li><li>第一个子层：注意力机制</li><li>第二个子层：全连接前向神经网络。</li><li>对两个子层都采用了residual connection，并进行了layer normalization。</li></ul><h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><ul><li>Decoder由6个基本层堆叠起来，每个基本层包含三个子层。</li><li>第一个子层：注意力机制</li><li>第二个子层：全连接前向神经网络。</li><li>第三个子层：注意力机制</li><li>对两个子层都采用了residual connection，并进行了layer normalization。</li></ul><h4 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h4><p>注意力机制：将一个<strong>query</strong>和一个<strong>key-value pairs</strong>，映射到正确的输入。</p><ul><li><strong>query、key、value、output</strong>都是向量。</li><li>输出作为一个值的加权和计算得到，其中分配到每个值的权重由请求的兼容函数关于对应键计算得到。</li></ul><h4 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h4><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201117205900.png" alt="image-20201117205900924" style="zoom:50%;" /></p><script type="math/tex; mode=display">Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt {d_k}})V</script><blockquote><p>输入：$d_k$维的<strong>query</strong>、<strong>key</strong>、$d_v$维的<strong>value</strong></p><p>MatMul：计算<strong>query</strong>和各个key的点积</p><p>Scale：除以$\sqrt {d_k}$ 归一化</p><p>softmax：获得权重</p><p>MatMul：和<strong>value</strong>相乘得到输出</p></blockquote><h4 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h4><blockquote><p>多头注意力机制</p><p>参数不共享</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201117211209.png" alt="image-20201117211209369" style="zoom:50%;" /></p><script type="math/tex; mode=display">head_i=Attention(QW^Q_i,KW^K_i,VW^V_i)</script><script type="math/tex; mode=display">MultiHead(Q,K,V)=Concat(head1,⋯,headh)W^O</script><blockquote><p>用h个不同的线性变换分别将$d_{model}$维的<strong>key</strong>、<strong>value</strong>、<strong>query</strong>映射成$d_k$维、$d_k$维和$d_v$维</p><p>代入注意力机制，产生$h×d_v$维输出，然后拼起来</p><p>再用一个线性变换得到最终的输出。</p></blockquote><h4 id="Position-wise-Feed-Forward-Networks"><a href="#Position-wise-Feed-Forward-Networks" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h4><blockquote><p>Position-wise 前向神经网络</p></blockquote><ul><li>encoder和decoder的每一层都包含一个前向神经网络。</li></ul><script type="math/tex; mode=display">FFN(x)=max(0,xW_1+b_1)W_2+b_2</script><blockquote><p>由两个线性变换和ReLU激活函数组成。</p></blockquote><h4 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h4><blockquote><p>位置编码</p><p>论文中的位置编码是根据下述公式计算得到的。</p></blockquote><script type="math/tex; mode=display">PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})</script><script type="math/tex; mode=display">PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})</script><ul><li><p>本文的模型结构没有使用任何递归结构或卷积结构，为了让模型能使用序列的顺序，必须引入某种能表达输入序列每个部分的绝对或相对位置的信息。</p></li><li><p>位置编码：在送入encoder和decoder之前，先对输入进行编码，编码后的向量维度是$d_{model}$，和embedings具有相同的维度，因此可以相加。 </p></li><li>通过结合位置向量和词向量，就给每个词都引入了一定的位置信息，这样 Attention 就可以分辨出不同位置的词了。</li><li>选择正弦曲线版本是因为它可以使模型推断出比训练过程中遇到的序列长度更长的序列长度。</li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>WMT 2014 English-German</p><p>WMT 2014 English-French</p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201118110252.png" alt="image-20201118110252849" style="zoom:50%;" /></p><ul><li>Transformer在英语-德语，英语-法语的翻译任务上都表现出比较好的翻译效果。</li><li>并且Transformer的训练开销也是最小的。</li></ul><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul><li>提出的Transformer，是第一个完全基于attention的序列转导模型，用multi-headed self-attention取代了encoder-decoder结构中最常用的循环层。</li><li>对于翻译任务，Transformer可以比基于循环或卷积层的体系结构训练更快。</li></ul><h2 id="扩展了解"><a href="#扩展了解" class="headerlink" title="扩展了解"></a>扩展了解</h2><p>机器翻译评价指标：<strong>BLEU</strong>（Bilingual Evaluation Understudy）</p><blockquote><p>双语评估替补</p></blockquote><script type="math/tex; mode=display">BLEU=BP⋅exp(\sum _{n=1}^Nw_nlogP_n)</script><script type="math/tex; mode=display">BP=\begin{cases}1 & c\gt r \\ 0 & e^{1-r/c} \leq r \end{cases}</script><ul><li>用于评估模型生成的句子(candidate)和实际句子(reference)的差异的指标。</li><li>取值范围在0到1之间,，如果两个句子完美匹配(perfect match)，那么BLEU是1，反之，如果两个句子完美不匹配(perfect mismatch)，那么BLEU为0。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Transformer </tag>
            
            <tag> 机器翻译 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见报错汇总</title>
      <link href="/2020/11/18/%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99%E6%B1%87%E6%80%BB/"/>
      <url>/2020/11/18/%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="常见报错汇总"><a href="#常见报错汇总" class="headerlink" title="常见报错汇总"></a>常见报错汇总</h1><h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><p>报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device(&#x27;cpu&#x27;) to map your storages to the CPU.</span><br></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.load(xxx)改成 torch.load(xxx,map_location=&#x27;cpu&#x27;)</span><br></pre></td></tr></table></figure><h2 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h2><p>报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorflow2.0加载model出现AttributeError: ‘str‘ object has no attribute ‘decode‘</span><br></pre></td></tr></table></figure><p>解决：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">把h5py降到2.10.0版本就行了！！！！</span><br><span class="line">安装keras自动给下载高版本h5py导致报错！！</span><br><span class="line"></span><br><span class="line">pip install h5py==2.10.0</span><br><span class="line">安装后重启服务</span><br></pre></td></tr></table></figure><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><p>报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx: [emerg] bind() to 0.0.0.0:443 failed (98: Address already in use)</span><br></pre></td></tr></table></figure><p>解决：</p><ol><li>查看443端口是否被占用？是哪个占用的？</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -anon | grep 443</span><br></pre></td></tr></table></figure><ol><li>杀掉占用的443端口的进程</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fuser -k 443/tcp</span><br></pre></td></tr></table></figure><ol><li>重启nginx</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx start</span><br></pre></td></tr></table></figure><ol><li>重新加载配置文件</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 报错 </tag>
            
            <tag> 经验 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习基础</title>
      <link href="/2020/11/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
      <url>/2020/11/17/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h1 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a>机器学习基础</h1><h2 id="1-机器学习的基本内容"><a href="#1-机器学习的基本内容" class="headerlink" title="1. 机器学习的基本内容"></a>1. 机器学习的基本内容</h2><ul><li>监督学习</li><li>无监督学习</li><li>半监督学习</li><li>强化学习</li></ul><h2 id="2-常用的正则化方法"><a href="#2-常用的正则化方法" class="headerlink" title="2. 常用的正则化方法"></a>2. 常用的正则化方法</h2><blockquote><ul><li><p>正则化是解决过拟合的常用方法。</p></li><li><p>正则化是什么呢？</p><ul><li>在机器学习中很多显式的用来减少测试误差的策略，统称为正则化。</li></ul></li><li>正则化的目的是减少泛化误差而不是训练误差。</li></ul></blockquote><h3 id="2-1权重正则化"><a href="#2-1权重正则化" class="headerlink" title="2.1权重正则化"></a>2.1权重正则化</h3><ul><li>L2正则化称为：权重衰减(Weight Deacy)</li></ul><script type="math/tex; mode=display">min_\theta\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+\lambda||W||^2</script><blockquote><p>$\lambda$：权值衰减率</p></blockquote><h3 id="2-2-Dropout-正则化"><a href="#2-2-Dropout-正则化" class="headerlink" title="2.2 Dropout 正则化"></a>2.2 Dropout 正则化</h3><blockquote><ul><li>训练过程中按一定的比例，随机忽略或屏蔽一些神经元。</li><li>被随机忽略或屏蔽的神经元在反向传播中也不会有任何的权值更新，在传播过程中产生于L2范数相同的收缩权重效果。</li><li>加入Dropout之后，输入特征也会随机清除，所以不会给任何一个输入设置太大的权重。</li><li>由于网络模型对神经元特定的权重不那么敏感，反而会增加模型的泛化能力。</li></ul></blockquote><ul><li><p>通常Dropout的丢弃率控制在20%-50%。</p><blockquote><p>太低起不到效果，太高会导致欠拟合。</p></blockquote></li><li><p>在较大型的网络效果更好，会学到多种独立表征。</p></li><li><p>输入层和隐藏层都使用Dropout。</p><blockquote><p>神经元较少的层，设置keep_prob为1或接近1。</p><p>神经元较多的层，设置keep_prob为0.5或更小。</p></blockquote></li><li><p>增加学习率和冲量</p><blockquote><p>学习率：扩大10-100倍</p><p>冲量：提高到0.9-0.99</p></blockquote></li></ul><p><strong>对网络的权重值做最大范数正则，可以提升模型性能。</strong></p><h3 id="2-3-批量正则化-Batch-Normalization"><a href="#2-3-批量正则化-Batch-Normalization" class="headerlink" title="2.3 批量正则化(Batch Normalization)"></a>2.3 批量正则化(Batch Normalization)</h3><blockquote><p>用于隐藏层数据分布不均，导致梯度消失或不起作用的情况。</p></blockquote><ul><li>BN作用在哪里？<ul><li>BN应该作用在非线性映射之前。</li></ul></li><li>BN如何使用？<ul><li>在神经网络训练收敛速度很慢，或者梯度爆炸无法训练的情况下使用。</li><li>BN可以选择比较大的学习率，它具有快速收敛的特性。</li><li>BN具有提高网络泛化能力的特性，因此不必使用过拟合中Dropout和L2正则化。</li></ul></li></ul><h3 id="2-4-权重初始化"><a href="#2-4-权重初始化" class="headerlink" title="2.4 权重初始化"></a>2.4 权重初始化</h3><ul><li>一般使用正态分布或均匀分布的初始值。</li><li>nn.init模块中提供了xavier、kaiming等经典的初始化策略。<ul><li>xavier一般用于激活函数是S型，例如sigmod、tanh</li><li>kaiming适合于ReLU类的权重初始化。</li></ul></li></ul><h2 id="3-选择合适的激活函数"><a href="#3-选择合适的激活函数" class="headerlink" title="3. 选择合适的激活函数"></a>3. 选择合适的激活函数</h2><blockquote><ul><li><p>激活函数主要作用是，给神经网络提供非线性建模能力。</p></li><li><p>如果没有激活函数，神经网络智只能处理线性可分的问题。</p></li></ul></blockquote><h3 id="3-1-常用激活函数"><a href="#3-1-常用激活函数" class="headerlink" title="3.1 常用激活函数"></a>3.1 常用激活函数</h3><div class="table-container"><table><thead><tr><th>名称</th><th>表达式</th><th>导数</th><th>图形</th></tr></thead><tbody><tr><td>sigmoid</td><td>$f(x)=\frac{1}{1+e^{-x}}$</td><td>$f’=f(x)(1-f(x))$</td><td><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115202913.png" alt=""></td></tr><tr><td>tanh</td><td>$f(x=\frac{1-e^{-2x}}{1+e^{2x}})$</td><td>$f’e(x)=1-(f(x))^2$</td><td><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115202919.png" alt="png"></td></tr><tr><td>ReLU</td><td>$f(x)=\max(0,x)$</td><td>$ f’(x)=\begin{cases}1 &amp; x\geq 0 \0 &amp; x\lt0\end{cases}$</td><td><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115202934.png" alt="png"></td></tr><tr><td>LeakyReLU</td><td>$f(x)=\max(ax,0)$</td><td>$ f’(x)=\begin{cases}1 &amp; x\geq 0 \ax &amp; x\lt0\end{cases}$</td><td><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115202927.png" alt="png"></td></tr><tr><td>softmax</td><td>$\sigma<em>i(z)=\frac{e^{z_i}}{\sum</em>{j=1}^me^{z_j}}$</td><td></td></tr></tbody></table></div><ul><li>如何选择激活函数<ul><li>如果网络层数不多，这几种都可以使用。</li><li>网络层数较多时，激活函数的导数大于1将导致梯度爆炸，小于1时，经过多层叠加，根据微积分求导链式法制，导数或者偏导将指数级变小。所以导数为1时最好，<strong>ReLU</strong>正好满足。</li></ul></li><li>softmax激活函数：<ul><li>$\sum_i\sigma_i(z)=1$，常用于多分类神经网络输出层。</li><li>softmax激活函数将一个向量进行”归一化”成概率分布的形式。</li></ul></li></ul><h2 id="4-选择合适的损失函数"><a href="#4-选择合适的损失函数" class="headerlink" title="4. 选择合适的损失函数"></a>4. 选择合适的损失函数</h2><blockquote><p>交叉熵：(Cross Entropy)    <strong>分类问题</strong></p><ul><li>交叉熵损失(Cross-Entropy Loss)，又称对数似然损失(Log-likelihood Loss)，对数损失。二分类时还可称为逻辑回归损失(Logistic Loss)。</li></ul><p>均方差：(Mean squared error，MSE)    <strong>回归问题</strong></p></blockquote><ul><li>正则化项要加在损失函数后面。</li><li>损失函数越小说明模型和参数越符合训练样本。</li></ul><h3 id="4-1-分类问题"><a href="#4-1-分类问题" class="headerlink" title="4.1 分类问题"></a>4.1 分类问题</h3><ul><li><p>损失函数一般使用<strong>交叉熵</strong>。</p><blockquote><p>交叉熵反应两个概率分布的距离。</p></blockquote></li></ul><h3 id="4-2-回归问题"><a href="#4-2-回归问题" class="headerlink" title="4.2 回归问题"></a>4.2 回归问题</h3><ul><li>回归问题预测的不是一个类别，而是一个<strong>任意实数</strong>。神经网络一般只有一个输出节点，即预测值。</li><li>反映真实值与预测值之间的距离可以用欧式距离表示。所以对回归问题一般使用<strong>均方差</strong>作为损失函数。</li></ul><p>均方差定义：</p><script type="math/tex; mode=display">MES=\frac{\sum_{i=1}^n(y_i-y_i')^2}{n}</script><h2 id="5-选择合适的优化器"><a href="#5-选择合适的优化器" class="headerlink" title="5.选择合适的优化器"></a>5.选择合适的优化器</h2><ul><li>影响优化的两个因素：<strong>学习率</strong>，<strong>梯度</strong>。</li></ul><h3 id="5-1-动量算法"><a href="#5-1-动量算法" class="headerlink" title="5.1 动量算法"></a>5.1 动量算法</h3><ul><li><p>梯度下降法在遇到平坦或高曲率区域时，学习过程有时很慢。利用动量算法能比较好解决这个问题。</p></li><li><p>动量算法示意图：</p></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115215631.png" alt="image-20201115215631480" style="zoom:50%;" /></p><ul><li>动量算法每下降一步都是由前面下降方向的一个累积和当前点的梯度方向组合而成。</li></ul><ul><li><p>改进的NGA算法：</p><blockquote><ul><li><p>动量算法每一步都要将两个梯度方向（历史梯度、当前梯度）做一个合并再下降。</p></li><li><p>先按照历史梯度往前走一小步，按照前面一小步位置的“超前梯度”来做梯度合并，得到了动量算法的一种改进算法，称为Nesterov accelerated gradient 简称 NAG 算法。</p></li><li>这种预更新方法能防止大幅振荡，不会错过最小值，并对参数更新更加敏感。</li></ul></blockquote></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115220311.png" alt="image-20201115220311795" style="zoom:50%;" /></p><ul><li>NAG动量法和经典动量法的差别就在B点和C点梯度的不同。动量法，更多关注梯度下降方法的优化。</li></ul><h3 id="5-2-AdaGrad算法"><a href="#5-2-AdaGrad算法" class="headerlink" title="5.2 AdaGrad算法"></a>5.2 AdaGrad算法</h3><ul><li><p>AdaGrad算法是通过参数来调整合适的学习率λ，能独立地自动调整模型参数的学习率，对稀疏参数进行大幅更新和对频繁参数进行小幅更新。</p><blockquote><p>Adagrad方法非常适合处理稀疏数据。</p></blockquote></li></ul><p>特点：</p><ul><li><p>随着迭代时间越长，累积梯度r越大，从而学习速率$\fracλ{(δ+\sqrt r)}$随着时间就减小，在接近 目标值时，不会因为学习速率过大而越过极值点。</p><blockquote><p>小参数δ：一般取一个较小值(如$10^{-7}$)，该参数避免分母为0。</p></blockquote></li><li><p>不同参数之间学习速率不同，因此，与前面固定学习速率相比，不容易在鞍点卡住。</p></li><li><p>如果梯度累积参数r$比较小$，则学习速率会比较大，所以参数迭代的步长就会比较大。 相反，如果梯度累积参数比较大，则学习速率会比较小，所以迭代的步长会比较小。</p></li></ul><h3 id="5-3-RMSProp算法"><a href="#5-3-RMSProp算法" class="headerlink" title="5.3 RMSProp算法"></a>5.3 RMSProp算法</h3><ul><li>RMSProp算法修改AdaGrad，为的是在非凸背景下效果更好。</li><li>针对梯度平方和累计越来越大的问题，RMSProp指数加权的移动平均代替梯度平方和。</li></ul><h3 id="5-4-Adma算法"><a href="#5-4-Adma算法" class="headerlink" title="5.4 Adma算法"></a>5.4 Adma算法</h3><ul><li>Adam(Adaptive Moment Estimation)本质上是带有动量项的RMSprop，它利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。</li><li>Adam的优点主要在于经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。</li></ul><h3 id="5-5总结"><a href="#5-5总结" class="headerlink" title="5.5总结"></a>5.5总结</h3><ul><li>RMSprop，Adadelta和Adam被认为是自适应优化算法，因为它们会自动更新学习率。而使用SGD时，必须手动选择学习率和动量参数，通常会随着时间的推移而降低学习率。</li><li>可以通过先使用Adam优化算法进行训练，这将大大节省训练时间，且不必担心初始化和参数调整，一旦用Adam训练获得较好的参数后，我们可以切换到SGD +动量优化，以达到最佳性能。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 机器学习 </tag>
            
            <tag> 正则化 </tag>
            
            <tag> 激活函数 </tag>
            
            <tag> 损失函数 </tag>
            
            <tag> 优化器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用激活函数</title>
      <link href="/2020/11/16/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
      <url>/2020/11/16/%E5%B8%B8%E7%94%A8%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="常用激活函数"><a href="#常用激活函数" class="headerlink" title="常用激活函数"></a>常用激活函数</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">fig = plt.figure()</span><br></pre></td></tr></table></figure><h2 id="1-sigmoid"><a href="#1-sigmoid" class="headerlink" title="1. sigmoid"></a>1. sigmoid</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">y_sigmoid = <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">221</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">11</span>, <span class="number">11</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.gca()  <span class="comment"># 获得当前axis坐标轴对象</span></span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># 去除右边界线</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># 去除上边界线</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定data 设置的bottom（也就是指定的x轴）绑定到y轴的0这个点上</span></span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))  <span class="comment"># 指定y轴绑定到x轴的0这个点上</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;Sigmoid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y_sigmoid, label=<span class="string">&#x27;sigmoid&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, color=<span class="string">&#x27;darkviolet&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;sigmoid&#x27;</span>])</span><br><span class="line">plt.savefig(<span class="string">&#x27;figs/sigmoid.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115202913.png" alt="png"></p><h2 id="2-tanh"><a href="#2-tanh" class="headerlink" title="2.tanh"></a>2.tanh</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">y_tanh = (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))</span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">222</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">11</span>, <span class="number">11</span>)</span><br><span class="line">plt.ylim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.gca()  <span class="comment"># 获得当前axis坐标轴对象</span></span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># 去除右边界线</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># 去除上边界线</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定data 设置的bottom（也就是指定的x轴）绑定到y轴的0这个点上</span></span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))  <span class="comment"># 指定y轴绑定到x轴的0这个点上</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y_tanh, label=<span class="string">&#x27;tanh&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, color=<span class="string">&#x27;darkviolet&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;tanh&#x27;</span>])</span><br><span class="line">plt.savefig(<span class="string">&#x27;figs/tanh.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115202919.png" alt="png"></p><h2 id="3-ReLU"><a href="#3-ReLU" class="headerlink" title="3.ReLU"></a>3.ReLU</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">y_relu = np.array([<span class="number">0</span>*item <span class="keyword">if</span> item &lt; <span class="number">0</span> <span class="keyword">else</span> item <span class="keyword">for</span> item <span class="keyword">in</span> x])</span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">223</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">11</span>, <span class="number">11</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.gca()  <span class="comment"># 获得当前axis坐标轴对象</span></span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># 去除右边界线</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)  <span class="comment"># 去除上边界线</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定data 设置的bottom（也就是指定的x轴）绑定到y轴的0这个点上</span></span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>, <span class="number">0</span>))  <span class="comment"># 指定y轴绑定到x轴的0这个点上</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;ReLU&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y_relu, label=<span class="string">&#x27;ReLU&#x27;</span>, linestyle=<span class="string">&#x27;-&#x27;</span>, color=<span class="string">&#x27;darkviolet&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;ReLU&#x27;</span>])</span><br><span class="line">plt.savefig(<span class="string">&#x27;figs/ReLU.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115202934.png" alt="png"></p><h2 id="4-LeakyReLU"><a href="#4-LeakyReLU" class="headerlink" title="4. LeakyReLU"></a>4. LeakyReLU</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">y_leakyrelu = np.array([<span class="number">0.2</span>*item <span class="keyword">if</span> item &lt; <span class="number">0</span> <span class="keyword">else</span> item <span class="keyword">for</span> item <span class="keyword">in</span> x])</span><br><span class="line"></span><br><span class="line">ax = fig.add_subplot(<span class="number">224</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">11</span>,<span class="number">11</span>)</span><br><span class="line">plt.ylim(-<span class="number">2</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.gca() <span class="comment"># 获得当前axis坐标轴对象</span></span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>) <span class="comment"># 去除右边界线</span></span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>) <span class="comment"># 去除上边界线</span></span><br><span class="line"></span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>)) <span class="comment"># 指定data 设置的bottom（也就是指定的x轴）绑定到y轴的0这个点上</span></span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>))  <span class="comment"># 指定y轴绑定到x轴的0这个点上</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;LeakyReLU&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x,y_leakyrelu,label = <span class="string">&#x27;LeakyReLU&#x27;</span>,linestyle=<span class="string">&#x27;-&#x27;</span>,color=<span class="string">&#x27;darkviolet&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;LeakyReLU&#x27;</span>])</span><br><span class="line">plt.savefig(<span class="string">&#x27;figs/LeakyReLU.png&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115202927.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用神经网络完成对手写数字进行识别</title>
      <link href="/2020/11/15/%E5%88%A9%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%8C%E6%88%90%E5%AF%B9%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%BF%9B%E8%A1%8C%E8%AF%86%E5%88%AB/"/>
      <url>/2020/11/15/%E5%88%A9%E7%94%A8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%8C%E6%88%90%E5%AF%B9%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%BF%9B%E8%A1%8C%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="利用神经网络完成对手写数字进行识别"><a href="#利用神经网络完成对手写数字进行识别" class="headerlink" title="利用神经网络完成对手写数字进行识别"></a>利用神经网络完成对手写数字进行识别</h1><ul><li>网络结构</li></ul><p>  <img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201114171840.png" alt=""></p><blockquote><p>两个隐藏层<br>每层激活函数为Relu<br>数据集：mnist</p></blockquote><h2 id="1-准备数据"><a href="#1-准备数据" class="headerlink" title="1. 准备数据"></a>1. 准备数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 导入 pytorch 内置的 mnist 数据</span></span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="comment"># 导入预处理模块</span></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="comment"># 导入nn及优化器</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br></pre></td></tr></table></figure><h2 id="2-定义一些超参数"><a href="#2-定义一些超参数" class="headerlink" title="2. 定义一些超参数"></a>2. 定义一些超参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一些超参数</span></span><br><span class="line">train_batch_size = <span class="number">64</span></span><br><span class="line">test_batch_size = <span class="number">128</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">num_epoches = <span class="number">20</span></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">momentum = <span class="number">0.5</span></span><br></pre></td></tr></table></figure><h2 id="3-下载数据并对数据进行预处理"><a href="#3-下载数据并对数据进行预处理" class="headerlink" title="3. 下载数据并对数据进行预处理"></a>3. 下载数据并对数据进行预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义预处理函数，这些预处理依次放在Compose函数中。</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(), transforms.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>])])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断是否需要从网络下载数据集</span></span><br><span class="line">is_downloda = <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(<span class="string">&#x27;./data/MNIST&#x27;</span>):</span><br><span class="line">    is_downloda = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 下载数据，并对数据进行预处理</span></span><br><span class="line">train_dataset = mnist.MNIST(</span><br><span class="line">    <span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, transform=transform, download=is_downloda)</span><br><span class="line">test_dataset = mnist.MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, transform=transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataloader是一个可迭代对象，可以使用迭代器一样使用。</span></span><br><span class="line">train_loader = DataLoader(</span><br><span class="line">    train_dataset, batch_size=train_batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">    test_dataset, batch_size=test_batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li>Normalize([0.5], [0.5])对张量进行归一化，这里两个0.5分别表示对张量进行归一化的全局平均值和方差。因图像是灰色的只有一个通道，如果有多个通道，需要有多个数字，如三个通道，应该是Normalize([m1,m2,m3], [n1,n2,n3])</li><li>用DataLoader得到生成器，可节省内存。</li></ul><h2 id="4-可视化源数据"><a href="#4-可视化源数据" class="headerlink" title="4. 可视化源数据"></a>4. 可视化源数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">examples = <span class="built_in">enumerate</span>(test_loader)</span><br><span class="line"><span class="comment"># enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标。</span></span><br><span class="line">batch_idx, (example_data, example_targets) = <span class="built_in">next</span>(examples)</span><br><span class="line"><span class="comment"># next() 返回迭代器的下一个项目。</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">3</span>, i+<span class="number">1</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.imshow(example_data[i][<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&quot;Ground Truth: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(example_targets[i]))</span><br><span class="line">    <span class="comment"># 关闭x,y轴显示</span></span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201114172136.png" alt="png"></p><h2 id="5-构建模型"><a href="#5-构建模型" class="headerlink" title="5. 构建模型"></a>5. 构建模型</h2><h3 id="5-1-构建网络"><a href="#5-1-构建网络" class="headerlink" title="5.1 构建网络"></a>5.1 构建网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用sequential构建网络，Sequential()函数的功能是将网络的层组合到一起</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, n_hidden_1, n_hidden_2, out_dim</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.layer1 = nn.Sequential(</span><br><span class="line">            nn.Linear(in_dim, n_hidden_1), nn.BatchNorm1d(n_hidden_1))</span><br><span class="line">        self.layer2 = nn.Sequential(</span><br><span class="line">            nn.Linear(n_hidden_1, n_hidden_2), nn.BatchNorm1d(n_hidden_2))</span><br><span class="line">        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = F.relu(self.layer1(x))</span><br><span class="line">        x = F.relu(self.layer2(x))</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="5-2-实例化网络"><a href="#5-2-实例化网络" class="headerlink" title="5.2 实例化网络"></a>5.2 实例化网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检测是否有可用的GPU，有则使用，否则使用CPU</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;GPU是否可用&quot;</span>, torch.cuda.is_available())</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># 实例化网络</span></span><br><span class="line">model = Net(<span class="number">28</span> * <span class="number">28</span>, <span class="number">300</span>, <span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># 输出10维（10个数字）</span></span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)</span><br></pre></td></tr></table></figure><pre><code>GPU是否可用 False</code></pre><h2 id="6-训练模型"><a href="#6-训练模型" class="headerlink" title="6. 训练模型"></a>6. 训练模型</h2><h3 id="6-1-训练模型"><a href="#6-1-训练模型" class="headerlink" title="6.1 训练模型"></a>6.1 训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">losses = []</span><br><span class="line">acces = []</span><br><span class="line">eval_losses = []</span><br><span class="line">eval_acces = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoches):</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    train_acc = <span class="number">0</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment"># 动态修改参数学习率</span></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">        optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>] *= <span class="number">0.1</span></span><br><span class="line">    <span class="keyword">for</span> img, label <span class="keyword">in</span> train_loader:</span><br><span class="line">        img = img.to(device)</span><br><span class="line">        label = label.to(device)</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), -<span class="number">1</span>)  <span class="comment"># 展成1维</span></span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        out = model(img)  <span class="comment"># 传入参数，自动执行forward函数</span></span><br><span class="line">        loss = criterion(out, label)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 梯度清零</span></span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        <span class="comment"># 缺省情况下，梯度是累加的，在梯度反向传播之前，需要梯度清零</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()  <span class="comment"># 基于当前梯度，更新参数</span></span><br><span class="line">        <span class="comment"># 记录误差</span></span><br><span class="line">        train_loss += loss.item()</span><br><span class="line">        <span class="comment"># 计算分类的准确率</span></span><br><span class="line">        _, pred = out.<span class="built_in">max</span>(<span class="number">1</span>)  <span class="comment"># 找出张量out最大值对应索引作为预测值</span></span><br><span class="line">        num_correct = (pred == label).<span class="built_in">sum</span>().item()</span><br><span class="line">        acc = num_correct / img.shape[<span class="number">0</span>]</span><br><span class="line">        train_acc += acc</span><br><span class="line"></span><br><span class="line">    losses.append(train_loss / <span class="built_in">len</span>(train_loader))</span><br><span class="line">    acces.append(train_acc / <span class="built_in">len</span>(train_loader))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在测试集上检验效果</span></span><br><span class="line">    eval_loss = <span class="number">0</span></span><br><span class="line">    eval_acc = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 将模型改为预测模式</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">for</span> img, label <span class="keyword">in</span> test_loader:</span><br><span class="line">        img = img.to(device)</span><br><span class="line">        label = label.to(device)</span><br><span class="line">        img = img.view(img.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        out = model(img)</span><br><span class="line">        loss = criterion(out, label)</span><br><span class="line">        <span class="comment"># 记录误差</span></span><br><span class="line">        eval_loss += loss.item()</span><br><span class="line">        <span class="comment"># 记录准确率</span></span><br><span class="line">        _, pred = out.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">        num_correct = (pred == label).<span class="built_in">sum</span>().item()</span><br><span class="line">        acc = num_correct / img.shape[<span class="number">0</span>]</span><br><span class="line">        eval_acc += acc</span><br><span class="line"></span><br><span class="line">    eval_losses.append(eval_loss / <span class="built_in">len</span>(test_loader))</span><br><span class="line">    eval_acces.append(eval_acc / <span class="built_in">len</span>(test_loader))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch: &#123;&#125;, Train Loss: &#123;:.4f&#125;, Train Acc: &#123;:.4f&#125;, Test Loss: &#123;:.4f&#125;, Test Acc: &#123;:.4f&#125;&#x27;</span></span><br><span class="line">          .<span class="built_in">format</span>(epoch, train_loss / <span class="built_in">len</span>(train_loader), train_acc / <span class="built_in">len</span>(train_loader),</span><br><span class="line">                  eval_loss / <span class="built_in">len</span>(test_loader), eval_acc / <span class="built_in">len</span>(test_loader)))</span><br></pre></td></tr></table></figure><pre><code>epoch: 0, Train Loss: 1.0274, Train Acc: 0.7921, Test Loss: 0.5553, Test Acc: 0.9008epoch: 1, Train Loss: 0.4833, Train Acc: 0.8995, Test Loss: 0.3530, Test Acc: 0.9259epoch: 2, Train Loss: 0.3504, Train Acc: 0.9187, Test Loss: 0.2769, Test Acc: 0.9384epoch: 3, Train Loss: 0.2838, Train Acc: 0.9328, Test Loss: 0.2301, Test Acc: 0.9483epoch: 4, Train Loss: 0.2431, Train Acc: 0.9408, Test Loss: 0.1980, Test Acc: 0.9530epoch: 5, Train Loss: 0.2202, Train Acc: 0.9463, Test Loss: 0.1964, Test Acc: 0.9534epoch: 6, Train Loss: 0.2188, Train Acc: 0.9464, Test Loss: 0.1913, Test Acc: 0.9537epoch: 7, Train Loss: 0.2159, Train Acc: 0.9471, Test Loss: 0.1882, Test Acc: 0.9551epoch: 8, Train Loss: 0.2131, Train Acc: 0.9487, Test Loss: 0.1869, Test Acc: 0.9540epoch: 9, Train Loss: 0.2107, Train Acc: 0.9490, Test Loss: 0.1835, Test Acc: 0.9559epoch: 10, Train Loss: 0.2081, Train Acc: 0.9500, Test Loss: 0.1846, Test Acc: 0.9552epoch: 11, Train Loss: 0.2090, Train Acc: 0.9492, Test Loss: 0.1855, Test Acc: 0.9558epoch: 12, Train Loss: 0.2091, Train Acc: 0.9483, Test Loss: 0.1841, Test Acc: 0.9558epoch: 13, Train Loss: 0.2076, Train Acc: 0.9493, Test Loss: 0.1871, Test Acc: 0.9544epoch: 14, Train Loss: 0.2066, Train Acc: 0.9491, Test Loss: 0.1833, Test Acc: 0.9562epoch: 15, Train Loss: 0.2086, Train Acc: 0.9491, Test Loss: 0.1837, Test Acc: 0.9560epoch: 16, Train Loss: 0.2074, Train Acc: 0.9496, Test Loss: 0.1827, Test Acc: 0.9559epoch: 17, Train Loss: 0.2076, Train Acc: 0.9488, Test Loss: 0.1835, Test Acc: 0.9559epoch: 18, Train Loss: 0.2076, Train Acc: 0.9494, Test Loss: 0.1845, Test Acc: 0.9558epoch: 19, Train Loss: 0.2074, Train Acc: 0.9497, Test Loss: 0.1844, Test Acc: 0.9551</code></pre><h3 id="6-2-可视化训练及测试损失值"><a href="#6-2-可视化训练及测试损失值" class="headerlink" title="6.2 可视化训练及测试损失值"></a>6.2 可视化训练及测试损失值</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.title(<span class="string">&#x27;train loss&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.plot(np.arange(<span class="built_in">len</span>(losses)), losses)</span><br><span class="line">plt.legend([<span class="string">&#x27;Train Loss&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;train acces&#x27;</span>)</span><br><span class="line">plt.plot(np.arange(<span class="built_in">len</span>(acces)),acces,color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;acces&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Train acces&#x27;</span>], loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201114172141.png" alt="png"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Tensor及Autograd实现机器学习</title>
      <link href="/2020/11/14/%E4%BD%BF%E7%94%A8Tensor%E5%8F%8AAutograd%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/11/14/%E4%BD%BF%E7%94%A8Tensor%E5%8F%8AAutograd%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="使用Tensor及Autograd实现机器学习"><a href="#使用Tensor及Autograd实现机器学习" class="headerlink" title="使用Tensor及Autograd实现机器学习"></a>使用Tensor及Autograd实现机器学习</h1><p>表达式：$y=3x^2+2$</p><p>模型：$y=wx^2+b$</p><p>损失函数：$Loss=\frac{1}{2}\sum_{i=1}^{100}(wx^2_i+b-y_i)^2$</p><p>对损失函数求导：<br>$\frac{\partial Loss}{\partial w}=\sum_{i=1}^{100}(wx^2_i+b-y_i)^2x^2_i$</p><p>$\frac{\partial Loss}{\partial b}=\sum_{i=1}^{100}(wx^2_i+b-y_i)^2$</p><p>利用梯度下降法学习参数，学习率为:lr</p><p>$w_1-=lr*\frac{\partial Loss}{\partial w}$</p><p>$b_1-=lr*\frac{\partial Loss}{\partial b}$</p><h3 id="1-生成训练数据"><a href="#1-生成训练数据" class="headerlink" title="1.生成训练数据"></a>1.生成训练数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">100</span>)</span><br><span class="line">dtype = torch.<span class="built_in">float</span></span><br><span class="line"><span class="comment"># 生成x坐标数据，x为tensor，转成100x1的形状</span></span><br><span class="line"><span class="comment"># dim = 1表示列</span></span><br><span class="line">x = torch.unsqueeze(torch.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">100</span>), dim=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(x)</span></span><br><span class="line"><span class="comment"># 生成y坐标数据，y为tensor，100x1的形状，并且加一点噪声</span></span><br><span class="line">y = <span class="number">3</span>*x.<span class="built_in">pow</span>(<span class="number">2</span>)+<span class="number">2</span> + <span class="number">0.2</span>*torch.rand(x.size())</span><br><span class="line"><span class="comment"># 把tensor转成numpy画图</span></span><br><span class="line">plt.scatter(x.numpy(), y.numpy())</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201114110727.png" alt="png"></p><h3 id="2-初始化权重参数"><a href="#2-初始化权重参数" class="headerlink" title="2.初始化权重参数"></a>2.初始化权重参数</h3><blockquote><p>torch.rand和torch.randn有什么区别？</p><ul><li>torch.rand均匀分布，torch.randn是标准正态分布。</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随即初始化参数，参数w,b是需要学习的，所以requires_grad=True</span></span><br><span class="line"></span><br><span class="line">w = torch.randn(<span class="number">1</span>, <span class="number">1</span>, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(w)</span></span><br><span class="line">b = torch.zeros(<span class="number">1</span>, <span class="number">1</span>, dtype=dtype, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(b)</span></span><br></pre></td></tr></table></figure><pre><code>tensor([[0.]], requires_grad=True)</code></pre><h3 id="3-训练模型"><a href="#3-训练模型" class="headerlink" title="3.训练模型"></a>3.训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.001</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8000</span>):</span><br><span class="line">    <span class="comment"># 前向传播 mm()矩阵乘法</span></span><br><span class="line">    y_pred = x.<span class="built_in">pow</span>(<span class="number">2</span>).mm(w)+b</span><br><span class="line">    <span class="comment"># 损失函数</span></span><br><span class="line">    loss = <span class="number">0.5</span>*(y_pred-y)**<span class="number">2</span></span><br><span class="line">    loss = loss.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自动计算梯度</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># 手动更新参数，需要使用torch.no_grad()包围，使上下文中切断自动求导的计算</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w -= lr*w.grad</span><br><span class="line">        b -= lr*b.grad</span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        w.grad.zero_()</span><br><span class="line">        b.grad.zero_()</span><br></pre></td></tr></table></figure><h3 id="4-可视化训练结果"><a href="#4-可视化训练结果" class="headerlink" title="4.可视化训练结果"></a>4.可视化训练结果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x.numpy(), y_pred.detach().numpy(), <span class="string">&#x27;r-&#x27;</span>, label=<span class="string">&#x27;predict&#x27;</span>)</span><br><span class="line"><span class="comment"># 调用detach()不再计算张量梯度</span></span><br><span class="line">plt.scatter(x.numpy(), y.numpy(), color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;true&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">2</span>, <span class="number">6</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 预测结果</span></span><br><span class="line"><span class="built_in">print</span>(w, b)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201114110730.png" alt="png"></p><pre><code>tensor([[2.9668]], requires_grad=True) tensor([[2.1138]], requires_grad=True)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GCN</title>
      <link href="/2020/11/12/GCN/"/>
      <url>/2020/11/12/GCN/</url>
      
        <content type="html"><![CDATA[<h1 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h1><blockquote><p>GCN：图卷积网络</p><p>SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS：基于图卷积网络的半监督分类</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><ul><li>在图结构数据中，一部节点已知标签，剩下的节点标签未知，使用已知标签的节点训练卷积神经网络，使用网络模型对无标签的节点进行分类。</li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><ul><li>提出了一种可扩展的基于图结构数据的半监督分类方法。</li><li>分层传播规则：通过谱图卷积（spectral graph convolutions） 的局部一阶近似，来确定卷积网络结构。</li></ul><h3 id="f-X-A"><a href="#f-X-A" class="headerlink" title="$f(X,A)$"></a>$f(X,A)$</h3><ul><li><p>使用神经网络$f(X,A)$对图的结构进行编码，对所有带标签的节点进行有监督训练。</p></li><li><p>避免显式地对基于图的损失函数进行正则化计算</p></li><li><p>在图的邻接矩阵上调节$f (⋅)$ ，允许模型从监督损失$\mathcal{L}_{0}$中分开梯度信息，使其能够学习所有节点的表示。</p></li><li><blockquote><p>X：输入数据</p><p>A：图邻接矩阵</p></blockquote></li></ul><h3 id="FAST-APPROXIMATE-CONVOLUTIONS-ON-GRAPHS"><a href="#FAST-APPROXIMATE-CONVOLUTIONS-ON-GRAPHS" class="headerlink" title="FAST APPROXIMATE CONVOLUTIONS ON GRAPHS"></a>FAST APPROXIMATE CONVOLUTIONS ON GRAPHS</h3><ul><li>图卷积的前向传播公式：</li></ul><script type="math/tex; mode=display">H^{(l+1)}=σ(\tilde D^{\frac{1}{2}}\tilde A \tilde D ^{-\frac{1}{2}}H^{(l)}W^{(l)})</script><h4 id="SPECTRAL-GRAPH-CONVOLUTIONS"><a href="#SPECTRAL-GRAPH-CONVOLUTIONS" class="headerlink" title="SPECTRAL GRAPH CONVOLUTIONS"></a>SPECTRAL GRAPH CONVOLUTIONS</h4><blockquote><p>频谱图形卷积</p><p>半监督分类图卷积网络是在先前的频谱卷积网络的基础上通过局部一阶近似得到的</p></blockquote><ul><li><p>对于一个输入信号 $x \in \mathbb{R}^N$ ，在傅里叶域中取一个$\theta \in \mathbb{R}^N$为参数的滤波器$g_{\theta} = diag(\theta)$。</p><blockquote><p>将图卷积通过傅里叶变换拓展到图的频域中。</p><p>第一代GCN图卷积公式</p><p>缺点：计算复杂</p></blockquote></li></ul><script type="math/tex; mode=display">gθ⋆x=U_{gθ}U^⊤_{x}</script><ul><li><p>将$g_{\theta}(\Lambda)$用切比雪夫多项式（Chebyshev）进行K阶逼近。</p><blockquote><p>改进的卷积核：</p></blockquote></li></ul><script type="math/tex; mode=display">g_{θ‘}​(Λ)≈\sum_{k=0}^Kθ_k^′T_k(\tilde Λ)</script><ul><li><p>将该卷积核代入图卷积的公式：</p><blockquote><p>将参数减少到了K个，并且不再需要对拉普拉斯矩阵做特征分解。</p></blockquote></li></ul><script type="math/tex; mode=display">g_{θ‘}⋆*≈\sum_{k=0}^Kθ_k^′T_k(\tilde L)x</script><h4 id="LAYER-WISE-LINEAR-MODEL"><a href="#LAYER-WISE-LINEAR-MODEL" class="headerlink" title="LAYER-WISE LINEAR MODEL"></a>LAYER-WISE LINEAR MODEL</h4><blockquote><p>线性模型</p></blockquote><script type="math/tex; mode=display">g_{θ′}∗x=\sum _{k=0}^Kθ^′kT_k(\tilde L)x</script><blockquote><ul><li>限制参数数量可以进一步解决过拟合并将各层的运算量最小化，使得可以通过堆叠多个GCN来获得一个更深的模型，提取特征。</li><li>为解决数值不稳定性和梯度爆炸/消失，进行了再归一化。</li><li>限制参数的数量以解决过度拟合问题，并最小化每层的运算数量(例如矩阵乘法)。</li></ul></blockquote><h2 id="SEMI-SUPERVISED-NODE-CLASSIFICATION"><a href="#SEMI-SUPERVISED-NODE-CLASSIFICATION" class="headerlink" title="SEMI-SUPERVISED NODE CLASSIFICATION"></a>SEMI-SUPERVISED NODE CLASSIFICATION</h2><blockquote><p>半监督节点分类</p></blockquote><ul><li>使用已知的数据$X$和邻接矩阵$A$来训练图卷积网络 $f(X, A)$。</li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201111095929.png" alt="image-20201110211205798" style="zoom: 50%;" /></p><blockquote><p>GCN网络示意图</p><ul><li><p>输入层拥有C个输入，中间有若干隐藏层，在输出层有F个特征映射。</p></li><li><p>图的结构在层之间共享。</p></li><li><p>标签用$Y_{i}$ 表示。</p></li></ul></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201111100059.png" alt="image-20201110211553795" style="zoom:50%;" /></p><blockquote><p>两层GCN在Cora数据集上（使用了5%的标签）训练得到的隐藏层激活值的形象化表示，颜色表示文档类别。</p></blockquote><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>Citeseer,Cora ,Pubmed ,NELL</p><blockquote><p>引文网络数据集：Citeseer,Cora,Pubmed</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201111102914.png" alt="image-20201110211901273" style="zoom:50%;" /></p><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><blockquote><p>比较模型：</p><p>流形正则化(ManiReg)、半监督嵌入(SemiEmb)、标签传播(LP)、基于跳跃文法的图嵌入(DeepWalk)、迭代分类算法(ICA)、两个Logistic回归分类器。</p></blockquote><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201111102922.png" alt="image-20201110213407738" style="zoom: 50%;" /></p><ul><li><p>GCN在四个数据集上的表现都比较突出，分类准确性较高。</p></li><li><p>提出的GCN模型能够同时对图结构和节点特征进行编码，对半监督分类是有用的。</p></li></ul><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><h3 id="有监督学习、无监督学习和半监督学习的分类"><a href="#有监督学习、无监督学习和半监督学习的分类" class="headerlink" title="有监督学习、无监督学习和半监督学习的分类"></a>有监督学习、无监督学习和半监督学习的分类</h3><ul><li>监督学习是使用已知正确答案的示例来训练网络的。</li><li>无监督学习适用于具有数据集但无标签的情况。</li><li>半监督学习在训练阶段结合了大量未标记的数据和少量标签数据。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> KGE </tag>
            
            <tag> KG </tag>
            
            <tag> GCN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux安装nodejs&amp;升级</title>
      <link href="/2020/11/10/Linux%E5%AE%89%E8%A3%85nodejs&amp;%E5%8D%87%E7%BA%A7/"/>
      <url>/2020/11/10/Linux%E5%AE%89%E8%A3%85nodejs&amp;%E5%8D%87%E7%BA%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux安装nodejs-amp-升级"><a href="#Linux安装nodejs-amp-升级" class="headerlink" title="Linux安装nodejs&amp;升级"></a>Linux安装nodejs&amp;升级</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol><li><p>命令窗口</p><p><code>yum install nodejs</code></p></li><li><p>官网（推荐）</p><p>官网：<a href="https://nodes.org/en/">https://nodes.org/en/</a></p><p>a. 下载后解压：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf node.tar.xz</span><br></pre></td></tr></table></figure><p>b. 创建软连接全局访问:</p><p>可执行文件位于/bin目录下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s 当前路径/npm /usr/bin/npm</span><br><span class="line">ln -s 当前路径/node /usr/bin/node</span><br></pre></td></tr></table></figure><p>c. 测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure></li></ol><h2 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h2><p><code>npm install n -g</code></p><p>安装稳定版</p><p><code>n stable</code></p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p><code>node -v</code></p><p><code>npm -v</code></p><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201113162015.png" alt="image-20201113162015591"></p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos </tag>
            
            <tag> nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Numpy实现机器学习</title>
      <link href="/2020/11/08/%E4%BD%BF%E7%94%A8Numpy%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
      <url>/2020/11/08/%E4%BD%BF%E7%94%A8Numpy%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="使用Numpy实现机器学习"><a href="#使用Numpy实现机器学习" class="headerlink" title="使用Numpy实现机器学习"></a>使用Numpy实现机器学习</h1><p>表达式：$y=3x^2+2$</p><p>模型：$y=wx^2+b$</p><p>损失函数：$Loss=\frac{1}{2}\sum_{i=1}^{100}(wx^2_i+b-y_i)^2$</p><p>对损失函数求导：<br>$\frac{\partial Loss}{\partial w}=\sum_{i=1}^{100}(wx^2_i+b-y_i)^2x^2_i$</p><p>$\frac{\partial Loss}{\partial b}=\sum_{i=1}^{100}(wx^2_i+b-y_i)^2$</p><p>利用梯度下降法学习参数，学习率为:lr</p><p>$w_1-=lr*\frac{\partial Loss}{\partial w}$</p><p>$b_1-=lr*\frac{\partial Loss}{\partial b}$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h3 id="1-生成训练数据"><a href="#1-生成训练数据" class="headerlink" title="1.生成训练数据"></a>1.生成训练数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#设置随机种子，生成同一份数据</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">100</span>).reshape(<span class="number">100</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># y在真实值上增加噪声</span></span><br><span class="line">y = <span class="number">3</span>*np.power(x, <span class="number">2</span>)+<span class="number">2</span>+<span class="number">0.2</span>*np.random.rand(x.size).reshape(<span class="number">100</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="2-查看x-y分布"><a href="#2-查看x-y分布" class="headerlink" title="2.查看x,y分布"></a>2.查看x,y分布</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201114102842.png" alt="png"></p><h3 id="3-初始化权重参数"><a href="#3-初始化权重参数" class="headerlink" title="3.初始化权重参数"></a>3.初始化权重参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随即初始化参数</span></span><br><span class="line">w1 = np.random.rand(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">b1 = np.random.rand(<span class="number">1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="4-求解模型"><a href="#4-求解模型" class="headerlink" title="4.求解模型"></a>4.求解模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">0.001</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">800</span>):</span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    y_pred = np.power(x, <span class="number">2</span>)*w1+b1</span><br><span class="line">    <span class="comment"># 定义损失函数</span></span><br><span class="line">    loss = <span class="number">0.5</span> * (y_pred-y)**<span class="number">2</span></span><br><span class="line">    <span class="comment"># print(loss)</span></span><br><span class="line">    <span class="comment"># 对各维度求和</span></span><br><span class="line">    loss = loss.<span class="built_in">sum</span>()</span><br><span class="line">    <span class="comment"># 计算梯度(求导)</span></span><br><span class="line">    grad_w = np.<span class="built_in">sum</span>((y_pred-y)*np.power(x, <span class="number">2</span>))</span><br><span class="line">    grad_b = np.<span class="built_in">sum</span>((y_pred-y))</span><br><span class="line">    <span class="comment"># 使用梯度下降法，使得loss最小</span></span><br><span class="line">    w1 -= lr*grad_w</span><br><span class="line">    b1 -= lr*grad_b</span><br></pre></td></tr></table></figure><h3 id="5-结果可视化"><a href="#5-结果可视化" class="headerlink" title="5.结果可视化"></a>5.结果可视化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(x, y_pred, <span class="string">&#x27;r-&#x27;</span>, label=<span class="string">&#x27;predict&#x27;</span>)</span><br><span class="line">plt.scatter(x, y, color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;true&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.ylim(<span class="number">2</span>, <span class="number">6</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># 预测值</span></span><br><span class="line"><span class="built_in">print</span>(w1, b1)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201114102850.png" alt="png"></p><pre><code>[[2.98927619]] [[2.09818307]]</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 机器学习 </tag>
            
            <tag> Numpy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用tensorboardX可视化神经网络</title>
      <link href="/2020/11/08/%E7%94%A8tensorboardX%E5%8F%AF%E8%A7%86%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/11/08/%E7%94%A8tensorboardX%E5%8F%AF%E8%A7%86%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="用tensorboardX可视化神经网络"><a href="#用tensorboardX可视化神经网络" class="headerlink" title="用tensorboardX可视化神经网络"></a>用tensorboardX可视化神经网络</h1><p>安装：<code>pip install tensorboardX</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;runs/scalar_example&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;quadratic&#x27;</span>, i**<span class="number">2</span>, global_step=i)</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;exponential&#x27;</span>, <span class="number">2</span>**i, global_step=i)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">writer = SummaryWriter(<span class="string">&#x27;runs/another_scalar_example&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;quadratic&#x27;</span>, i**<span class="number">3</span>, global_step=i)</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;exponential&#x27;</span>, <span class="number">3</span>**i, global_step=i)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="1-启动tensorboard服务"><a href="#1-启动tensorboard服务" class="headerlink" title="1.启动tensorboard服务"></a>1.启动tensorboard服务</h2><ul><li>cd到runs目录所在的同级目录，在命令行输入如下命令，logdir等式右边可以是相对路径或绝对路径。<br><code>tensorboard --logdir=runs --port 6006</code></li></ul><h2 id="2-web展示"><a href="#2-web展示" class="headerlink" title="2.web展示"></a>2.web展示</h2><ul><li><a href="http://localhost:6006/">http://localhost:6006/</a></li></ul><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201115115708.png" alt="image-20201115115702543"></p>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jupyter Notebook 实现代码提示自动补全和代码格式化</title>
      <link href="/2020/11/06/jupyter_%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/11/06/jupyter_%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="Jupyter-Notebook-实现代码提示自动补全和代码格式化"><a href="#Jupyter-Notebook-实现代码提示自动补全和代码格式化" class="headerlink" title="Jupyter Notebook 实现代码提示自动补全和代码格式化"></a>Jupyter Notebook 实现代码提示自动补全和代码格式化</h1><h2 id="安装插件nbextensions"><a href="#安装插件nbextensions" class="headerlink" title="安装插件nbextensions"></a>安装插件nbextensions</h2><h3 id="1-安装jupyter-contrib-nbextensions"><a href="#1-安装jupyter-contrib-nbextensions" class="headerlink" title="1.安装jupyter_contrib_nbextensions"></a>1.安装jupyter_contrib_nbextensions</h3><p><code>pip install --user jupyter_contrib_nbextensions -i https://pypi.mirrors.ustc.edu.cn/simple</code></p><p><code>jupyter contrib nbextension install --user</code></p><h3 id="2-安装nbextensions-configurator"><a href="#2-安装nbextensions-configurator" class="headerlink" title="2.安装nbextensions_configurator"></a>2.安装nbextensions_configurator</h3><p><code>pip install --user jupyter_nbextensions_configurator</code><br><code>jupyter nbextensions_configurator enable --user</code></p><p>如果出错提示<code>“Exception: Jupyter command jupyter-contrib not found.”</code></p><ul><li>则使用conda强制安装，<code>conda install -c conda-forge jupyter_nbextensions_configurator</code></li></ul><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201113101420.png" alt="image-20201113101420701"></p>]]></content>
      
      
      <categories>
          
          <category> 工具&amp;教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 配置 </tag>
            
            <tag> Jupyter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HOLE</title>
      <link href="/2020/11/05/HOLE/"/>
      <url>/2020/11/05/HOLE/</url>
      
        <content type="html"><![CDATA[<h1 id="HOLE"><a href="#HOLE" class="headerlink" title="HOLE"></a>HOLE</h1><blockquote><p>Holographic Embeddings of Knowledge Graphs</p><p>基于向量的循环相关</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><ul><li>提出全息嵌入(holographic embeddings，HOLE)来学习整个知识图的组成向量空间表示。</li><li>在组合向量空间模型的框架内研究从知识图谱学习的问题。</li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><h3 id="compositional-vector-space-models"><a href="#compositional-vector-space-models" class="headerlink" title="compositional vector space models"></a>compositional vector space models</h3><ol><li><strong>组合向量空间模型</strong></li></ol><script type="math/tex; mode=display">Pr(\phi_p(s,o)=1|\Theta)=\sigma(\eta_{spo})=\sigma(\mathbf{r}_p^T(\mathbf{e}_s◦\mathbf{e}_o))</script><blockquote><p><script type="math/tex">\phi_p(s,o)</script>：特征函数</p><p>◦ ：复合算子，从嵌入$\mathbf{e}_s$，$\mathbf{e}_o$创建$（s，o）$的复合向量表示。</p></blockquote><ol><li><strong>通过最大限度地减少（正则化）logistic损失来实现最好地解释数据集的实体和关系的表示。</strong></li></ol><script type="math/tex; mode=display">\min\sum_{i=1}^mlog(1+exp(-y_i\eta_i))+\lambda||\Theta||_2^2</script><blockquote><p>对于关系数据，最小化 logistic 损失具有额外的优势，它可以帮助为复杂的关系模式找到低维的嵌入。</p></blockquote><ol><li><strong>KGs只存储正确三元组，这种情况下可以使用 pairwise ranking loss。</strong></li></ol><script type="math/tex; mode=display">\min_\Theta\sum_{i\in{D_+}}\sum_{j\in{D_-}}\max(0,\gamma+\sigma(\eta_j)-\sigma(\eta_i))</script><blockquote><p>例如将现有三元组的概率排序为高于不存在三元组的概率。</p><p>d+，d−：表示存在和不存在的三元组的集合。</p><p>$\eta_j&gt;0$：指定边距的宽度。</p></blockquote><h3 id="Holographic-Embeddings-HOLE"><a href="#Holographic-Embeddings-HOLE" class="headerlink" title="Holographic Embeddings(HOLE)"></a>Holographic Embeddings(HOLE)</h3><blockquote><p>为了将张量积的表达能力与TransE的效率和简单性结合起来，使用向量的循环相关来表示实体对。</p><p>在HOLE中，不只是存储关联，而是学习能最好地解释所观察到数据的嵌入。</p></blockquote><pre><code>1. 复合算子</code></pre><script type="math/tex; mode=display">a◦b=a\ast b</script><blockquote><p>$\mathbf{*}$：表示循环相关</p></blockquote><ol><li>三元组的概率模型</li></ol><script type="math/tex; mode=display">Pr(\phi_p(s,o)=1|\Theta)=\sigma(\mathbf{r}_p^T(\mathbf{e}_s\ast \mathbf{e}_o))</script><blockquote><p>使用复合算子相对于卷积的优点</p><ul><li>Non-commutative：对建模有向图的非对称性很有必要。</li><li>Similiarity Component：对实体相似性的关系建模有帮助。</li></ul></blockquote><ol><li><p>SGD</p><blockquote><p>使用随机梯度下降</p></blockquote></li></ol><script type="math/tex; mode=display">\mathbf{e}_o^{t+1}\leftarrow\mathbf{e}_o^{t}-\mu\frac{\partial L}{\partial f}\frac{\partial f}{\partial \eta}(\mathbf{r}_p^t\ast e_s^t)</script><blockquote><p>$\mu$：学习率</p></blockquote><ol><li>方法</li></ol><ul><li><p>把实体和关系都表示为向量。给定一个事实$(h,r,t)$，首先使用循环相关操作将实体表示形式组成$h*t∈R$。</p></li><li><p>然后将组合向量与关系表示形式匹配，以对事实进行评分。</p></li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><ul><li>WN18</li><li>FB15K</li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><blockquote><p> 公平起见，评价时使用相同的损失和优化方法对参与比较的模型重新训练。</p></blockquote><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201020191901057.png" alt="image-20201020191901057"></p><blockquote><p>Filter：由于对于给定的 predicate-object，测试集中可以存在多个正确的三元组，因此从$R_p（s^{‘},o)=1$ and $ s\neq s^{‘}$的排序中删除所有实例，只考虑测试实例在所有错误实例中的排序。同理从$R_p（s,o^{‘})=1$ and $ o\neq o^{‘}$的排序中删除所有实例。</p></blockquote><ul><li>在WN18数据集的测试中，HOLE的表现都最为出色。</li><li>在FB15k数据集表现也优于其他模型，但是效果不是很显著。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201020193457298.png" alt="image-20201020193457298"></p><ul><li>与Rescal相比，HOLE的参数减少很多。尽管embedding的维数d比rescal的大，但由于其存储复杂度仅线性地依赖于d，所以总体参数数目显著减少。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201020193748054.png" alt="image-20201020193748054"></p><blockquote><p>$locatedIn(c,r)$：c：countries(国家)，r：regions(地区)。</p><p>$locatedIn(c,s)$：s：subregions(次区域)。</p></blockquote><ol><li><p>任务S1</p><p>设置：对于test/valid中，只将$locatedIn(c,r)$的countries设置为missing。</p><p>性能：丢失的三元组几乎可以完美预测。</p></li><li><p>任务S2</p><p>设置：将$locatedIn(c,s)$中countries和subregions设置为missing。</p><p>性能：相对于其他数据集表现最好。</p></li><li><p>任务S3</p><p>设置：将$locatedIn(n,r)$中countriesn的neighbors，regions设置为missing。</p><p>性能：预测难度最大，但相对于其他数据集表现较好。</p></li></ol><blockquote><p>RESCAL和ER-MLP较差的结果很可能是过拟合导致。</p></blockquote><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul><li>HOLE 它利用向量的循环相关性来创建二元关系数据的组合表示。通过使用相关性作为组合算子，可以捕获丰富的交互，同时保持高效的计算，易于训练，并可扩展到非常大的数据集。</li><li>循环相关对成对的相互作用进行压缩。因此，HolE对每个关系只需要$O(d)$参数，并且循环相关是不符合交换律的，即$h<em>t$不等于$t</em>h$。所以HolE能够<strong>对不对称关系进行建模</strong>。</li></ul><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ol><li><strong>循环相关的优势：</strong></li></ol><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201020202711290.png" alt="image-20201020202711290"></p><ul><li>与张量积相比，循环相关具有不增加复合表示的维数的重要优点。</li><li>空间复杂度在实体表示的维度d中是线性的，运行时复杂度在d中是对数线性的。对总体参数的数量和运行效率都有显著影响。</li><li>组合表示与其构成的表示具有相同的维数。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> KGE </tag>
            
            <tag> KG </tag>
            
            <tag> HOLE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyTorch自动求导</title>
      <link href="/2020/11/03/PyTorch%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/"/>
      <url>/2020/11/03/PyTorch%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<h1 id="标量反向传播"><a href="#标量反向传播" class="headerlink" title="标量反向传播"></a>标量反向传播</h1><blockquote><p>当目标张量为标量时，backward()无需传入参数。</p></blockquote><ul><li>例子：假设$w,x,b$都是标量，$z=wx+b$ ，对标量$z$调用backward()方法。</li></ul><h2 id="自动求导的主要步骤"><a href="#自动求导的主要步骤" class="headerlink" title="自动求导的主要步骤"></a>自动求导的主要步骤</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure><h3 id="1-定义叶子结点，算子节点"><a href="#1-定义叶子结点，算子节点" class="headerlink" title="1.定义叶子结点，算子节点"></a>1.定义叶子结点，算子节点</h3><blockquote><p>如果需要对Tensor求导，requires_grad要设置为True。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义输入张量x</span></span><br><span class="line">x = torch.Tensor([<span class="number">2</span>])</span><br><span class="line"><span class="comment"># 初始化权重参数w,偏置b,#设置requires_grad为True，使用自动求导</span></span><br><span class="line">w = torch.randn(<span class="number">1</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.randn(<span class="number">1</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 设置前向传播</span></span><br><span class="line">y = torch.mul(w,x)</span><br><span class="line">z = torch.add(y,b)</span><br><span class="line"><span class="comment"># 查看requires_grad属性</span></span><br><span class="line"><span class="built_in">print</span>(x.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(y.requires_grad)</span><br><span class="line"><span class="comment"># 因为与w,b具有y依赖关系，所以x,y的requires_grad也是True。</span></span><br></pre></td></tr></table></figure><pre><code>FalseTrue</code></pre><h3 id="2-查看叶子结点，非叶子结点的其他属性"><a href="#2-查看叶子结点，非叶子结点的其他属性" class="headerlink" title="2.查看叶子结点，非叶子结点的其他属性"></a>2.查看叶子结点，非叶子结点的其他属性</h3><ul><li>grad_fn:表示梯度函数<blockquote><p>通过运算创建的Tensor(非叶子结点)会自动被赋予grad_fn属性。<br>叶子结点的grad_fn为None。</p></blockquote></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看非叶子结点y,z的requires_grad属性。</span></span><br><span class="line"><span class="built_in">print</span>(y.requires_grad)</span><br><span class="line"><span class="comment"># 查看各节点是不是叶子节点</span></span><br><span class="line"><span class="built_in">print</span>(x.is_leaf)</span><br><span class="line"><span class="built_in">print</span>(y.is_leaf)</span><br><span class="line"><span class="comment"># 叶子结点：x,w,b</span></span><br><span class="line"><span class="comment"># 非叶子结点：y,z</span></span><br><span class="line"><span class="comment"># 查看叶子结点的grad_fn属性</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x的grad_fn属性：&quot;</span>,x.grad_fn)</span><br><span class="line"><span class="comment"># 查看非叶子结点的grad_fn属性</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y的grad_fn属性：&quot;</span>,y.grad_fn)</span><br></pre></td></tr></table></figure><pre><code>TrueTrueFalsex的grad_fn属性： Noney的grad_fn属性： &lt;MulBackward0 object at 0x7fe83935dbb0&gt;</code></pre><h3 id="3-自动求导，实现梯度反向传播"><a href="#3-自动求导，实现梯度反向传播" class="headerlink" title="3.自动求导，实现梯度反向传播"></a>3.自动求导，实现梯度反向传播</h3><blockquote><p>非叶子节点的梯度调用backward()之后，梯度将被清空。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于z对张量进行反向传播，执行backward之后计算图会清空。</span></span><br><span class="line">z.backward()</span><br><span class="line"><span class="comment"># 如果需要多次backward()需要设置参数retain_graph为True。此时梯度是累加的。</span></span><br><span class="line"><span class="comment"># z.backward(retain_graph=True)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看叶子结点的梯度。</span></span><br><span class="line"><span class="comment"># 因为x未设置requires_grad属性,默认为False，不求导，所以grad为None。</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x的梯度是：&quot;</span>,x.grad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;w的梯度是：&quot;</span>,w.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看非叶子结点的梯度</span></span><br><span class="line"><span class="comment"># 非叶子节点的梯度调用backward()之后，梯度将被清空。故y,z此时没有梯度。</span></span><br><span class="line"><span class="comment"># print(&quot;y的梯度是：&quot;,y.grad)</span></span><br><span class="line"><span class="comment"># print(&quot;z的梯度是：&quot;,z.grad)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><pre><code>x的梯度是： Nonew的梯度是： tensor([2.])</code></pre><h1 id="非标量反向传播"><a href="#非标量反向传播" class="headerlink" title="非标量反向传播"></a>非标量反向传播</h1><blockquote><p>Pytorch只允许标量对张量进行求导</p></blockquote><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="1-定义叶子结点，计算结点"><a href="#1-定义叶子结点，计算结点" class="headerlink" title="1.定义叶子结点，计算结点"></a>1.定义叶子结点，计算结点</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义叶子张量x，形状为1x2</span></span><br><span class="line">x = torch.tensor([[<span class="number">2</span>,<span class="number">3</span>]],dtype=torch.<span class="built_in">float</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># 初始化雅可比矩阵</span></span><br><span class="line">J = torch.zeros(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(J[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 初始化目标张量，形状为1x2</span></span><br><span class="line">y = torch.zeros(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 定义y与x之间的映射关系</span></span><br><span class="line"><span class="comment"># y1 = x1**2+3*x2</span></span><br><span class="line"><span class="comment"># y2 = x2**2+2*x1</span></span><br><span class="line">y[<span class="number">0</span>,<span class="number">0</span>]=x[<span class="number">0</span>,<span class="number">0</span>]**<span class="number">2</span>+<span class="number">3</span>*x[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">y[<span class="number">0</span>,<span class="number">1</span>]=x[<span class="number">0</span>,<span class="number">1</span>]**<span class="number">2</span>+<span class="number">2</span>*x[<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><pre><code>tensor([[2., 3.]], requires_grad=True)tensor([0., 0.])tensor([[13., 13.]], grad_fn=&lt;CopySlices&gt;)</code></pre><h3 id="2-调用backward-获取y对x的梯度"><a href="#2-调用backward-获取y对x的梯度" class="headerlink" title="2.调用backward()获取y对x的梯度"></a>2.调用backward()获取y对x的梯度</h3><blockquote><p>需要重复使用backward()时,retain_graph=True</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成y1对x的梯度</span></span><br><span class="line">y.backward(torch.Tensor([[<span class="number">1</span>,<span class="number">0</span>]]),retain_graph=<span class="literal">True</span>)</span><br><span class="line">J[<span class="number">0</span>]=x.grad</span><br><span class="line"><span class="comment"># 因为梯度是累加的，所以需要清除对x的梯度</span></span><br><span class="line">x.grad = torch.zeros_like(x.grad)</span><br><span class="line"><span class="comment"># 生成y2对x的梯度</span></span><br><span class="line">y.backward(torch.Tensor([[<span class="number">0</span>,<span class="number">1</span>]]))</span><br><span class="line">J[<span class="number">1</span>]=x.grad</span><br><span class="line"><span class="comment"># 雅可比矩阵的值</span></span><br><span class="line"><span class="built_in">print</span>(J)</span><br></pre></td></tr></table></figure><pre><code>tensor([[4., 3.],        [2., 6.]])</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习&amp;深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TransE</title>
      <link href="/2020/10/29/TransE/"/>
      <url>/2020/10/29/TransE/</url>
      
        <content type="html"><![CDATA[<h1 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h1><blockquote><p> 《Translating Embeddings for Modeling Multi-relational Data》</p></blockquote><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><ul><li><strong>在低维向量空间中，将多种关系的图谱中的实体和关系在一个低维空间中进行表示，获得每个实体的表征结果。</strong></li><li><strong>提出一种易于训练的规范模型，该模型包含数量较少的参数，并且可以扩展到非常大的知识库。</strong></li><li><strong>对知识图谱中的多元关系数据进行建模，在不引入额外知识的情况下，高效的实现知识补全，关系预测。</strong></li></ul><h2 id="方法（模型）"><a href="#方法（模型）" class="headerlink" title="方法（模型）"></a>方法（模型）</h2><p><strong>TransE：基于能量的模型，用于学习实体的低维嵌入。</strong></p><ol><li><p>关系作为向量空间转变的桥梁：如果三元组<code>(h,l,t)</code>成立，则头实体embedding和关系embedding相加约等于尾实体的embedding。</p><blockquote><p>$h+l ≈ t$</p></blockquote></li><li><p>利用空间传递不变形，找到一个实体和向量空间，使得整关系三元组之间的势能差值最小。</p><blockquote><p>$min(t − ( h + l ))$</p></blockquote></li><li><p>模型</p></li></ol><ul><li><p>给定一个训练集 S ，三元组表示为 $( h , l , t )$，其中 $h , t ∈ E ,l ∈ L$ ，实体和关系的嵌入维度设为 k，希望 $h + l$ 与 $t$能够尽可能的相似，因此定义一个能量函数：</p><p>$d ( h + l , t ) = [ ( h + l ) − t ]^2 = ∣∣h∣∣^2_2 + ∣∣ l ∣∣^2_2 + ∣ ∣ t ∣ ∣_2^2 − 2 ( h^T t + l^ T ( t − h ) ) $</p><blockquote><p>欧式距离</p></blockquote></li><li><p>为了训练实体embedding和关系embedding，需要引入负样本。目标是尽可能对正样本中最小化 $d ( h + l , t )$ ，负样本中则尽可能最大化$d ( h ′ + l , t ′ )$ $。h’,t’$ 表示不属于某个三元组的实体。因此可以得出基于间距排序标准目标优化函数（<strong>损失函数</strong>）：</p><p>$L=\sum<em>{(h,ℓ,t)∈S}\sum</em>{(h′,ℓ,t′)∈S<em>{(h,ℓ,t)}^′}[γ+d(h+ℓ,t)−d(h′+ℓ,t′)]</em>+$</p><blockquote><p>其中 $[x]_+$表示 $x$ 中正例的部分，$γ &gt; 0$ 表示距离因子。</p><p>通过最小化正样本的损失，最大化负样本的距离，达到优化嵌入表示的目的。</p></blockquote></li><li><p>错误三元组生成：将正确三元组的头或者尾替换成其他的（每次只能选择头或者尾进行替换，不同时替换），得到错误的三元组。</p><p>$S_{(h,l,t)}^′={(h′,l,t)∣h′∈E}∪{(h,l,t′)∣t′∈E}$</p></li></ul><h2 id="测试数据集"><a href="#测试数据集" class="headerlink" title="测试数据集"></a>测试数据集</h2><ul><li><p>FreeBase</p></li><li><p>WordNet</p><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201015110914232.png" alt="image-20201015110914232" style="zoom: 67%;" /></p></li></ul><h2 id="性能水平"><a href="#性能水平" class="headerlink" title="性能水平"></a>性能水平</h2><h3 id="链接预测"><a href="#链接预测" class="headerlink" title="链接预测"></a>链接预测</h3><h4 id="评价方法"><a href="#评价方法" class="headerlink" title="评价方法"></a>评价方法</h4><ul><li>对于每个三元组，都将头部移除并依次替换为字典中的任意一个实体。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/iNIU4QHVtgja9xs.png" alt="image-20201014211344062"></p><ul><li><p>raw：原始数据</p></li><li><p>filtered：移除错误三元组</p><blockquote><p>某些错误的三元组会变成有效的三元组。在测试中，可能会出现某些错误三元组排序比测试集三元组靠前的情况，但是这些三元组都是真实的。为了解决这个缺陷对评价指标带来的影响，从数据集中删除错误的三元组。</p></blockquote></li></ul><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>​    <strong>在原始数据集和去除错误的三元组之后的数据集上，TransE均具有较低的平均排名和较高的hits@10排名。</strong></p><h3 id="四种类型的实体预测-1-1-1-N-N-1-N-N"><a href="#四种类型的实体预测-1-1-1-N-N-1-N-N" class="headerlink" title="四种类型的实体预测[1-1,1-N,N-1,N-N]"></a>四种类型的实体预测<code>[1-1,1-N,N-1,N-N</code>]</h3><ul><li>根据头实体和尾实体的对应关系划分。</li><li>给定关系和实体预测另一个实体。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/erLSYdn6y9WxqPb.png" alt="image-20201014212035697"></p><h4 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h4><p>​    <strong>TransE在1-1的情况下预测效果较好。</strong></p><h3 id="TransE在FB15k测试集上的样例预测"><a href="#TransE在FB15k测试集上的样例预测" class="headerlink" title="TransE在FB15k测试集上的样例预测"></a>TransE在FB15k测试集上的样例预测</h3><ul><li>粗体是测试元组正确的尾部，斜体是训练集上其它正确的尾部。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/h58lkvSjyUdVc3s.png" alt="image-20201014212836465"></p><h4 id="结论-2"><a href="#结论-2" class="headerlink" title="结论"></a>结论</h4><p>​    <strong>给定一个头部和一个标签，排在最高位的尾部被预测出来。</strong></p><h3 id="不同模型在不同样本数量下的性能"><a href="#不同模型在不同样本数量下的性能" class="headerlink" title="不同模型在不同样本数量下的性能"></a>不同模型在不同样本数量下的性能</h3><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/image-20201014213239556.png" alt="image-20201014213239556"></p><ul><li>左图表示测试集中平均排名：当训练集越大，TransE的平均排名下降的最快。</li><li>右图表示hits@10中正确的比例：当训练集越大，hits@10占比上升的最快。</li><li>结果表明TransE对样本预测的性能最优。</li></ul><h2 id="结论-3"><a href="#结论-3" class="headerlink" title="结论"></a>结论</h2><p><strong>TransE模型可以使用最小的参数量得到知识图谱的实体和关系向量表示。</strong></p><p><strong>TransE模型的参数较少，计算的复杂度显著降低，并且在大规模稀疏知识库上也同样具有较好的性能与可扩展性。</strong></p><h2 id="不足和改进"><a href="#不足和改进" class="headerlink" title="不足和改进"></a>不足和改进</h2><h4 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h4><ul><li>在处理复杂关系<code>[1-N,N-1,N-N</code>]时，性能显著下降，比较适合处理<code>1-1</code>的关系。</li><li>不能够很好的处理更复杂的知识网络。</li></ul><h4 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h4><ul><li>TransH模型：为了解决TransE模型在处理一对多 、 多对一 、多对多复杂关系时的局限性，TransH模型提出让一个实体在不同的关系下拥有不同的表示。</li><li>TransR模型：一个实体是多种属性的综合体，不同关系关注实体的不同属性。不同的关系拥有不同的语义空间。</li><li>TransD模型：给定三元组(h, r, t) , TransD模型设置了2个分别将头实体和尾实体投影到关系空间的投影矩阵。</li><li>TranSparse模型：TranSparse是通过在投影矩阵上强化稀疏性来简化TransR的工作。通过引入稀疏投影矩阵，TransSparse模型减少了参数个数。</li><li>TransM模型：除了允许实体在涉及不同关系时具有不同的嵌入之外，提高TransE模型性能可以从降低h+r≈t的要求研究开始。TransM模型将为每个事实（h,r,t）分配特定的关系权重theta_r。</li><li>TransF模型：TransF只需要t与h+r位于同一个方向，同时h与t-r也位于同一个方向。</li><li>ManifoldE模型：ManifoldE模型对于每个事实三元组$（h,r,t）$将$h+r≈t$转换为(h+r-t)的L2范式约等于theta_r的平方。</li><li>TransA模型：TransA模型为每个关系r引入一个对称的非负矩阵Mr，并使用自适应马氏距离定义评分函数。通过学习距离度量Mr, TransA在处理复杂关系时更加灵活。</li></ul><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ol><li><strong>Mean Rank 和 hit@10</strong></li></ol><p>在测试过程中，对于一个三元组，我们将头实体或尾实体替换成任意一种其他的实体，得到（n-1）个新的关系三元组，然后对这些三元组计算实体关系距离，将这n-1个三元组按照距离从小到大排列。</p><ul><li><p>对Mean Rank的理解</p><p>在测试集里，求真实的实体在n-1个元素中的排名，得出平均到第多少个才能匹配到正确的结果。</p></li><li><p>对hit@10的理解</p><p>在这个排好序的n-1元素中，从第一个开始遍历，看从第一个到第十个是否能够遇到真实的实体，如果遇到了就将 $hit@10 +1$。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> KGE </tag>
            
            <tag> KG </tag>
            
            <tag> TransE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>东油教务APP使用说明</title>
      <link href="/2020/10/26/dyjw/"/>
      <url>/2020/10/26/dyjw/</url>
      
        <content type="html"><![CDATA[<h3 id="请大家务必升级到1-0（正式版）及以后版本"><a href="#请大家务必升级到1-0（正式版）及以后版本" class="headerlink" title="请大家务必升级到1.0（正式版）及以后版本"></a>请大家务必升级到1.0（正式版）及以后版本</h3><h3 id="下载地址汇总"><a href="#下载地址汇总" class="headerlink" title="下载地址汇总"></a>下载地址汇总</h3><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201027141834.png" alt="image-20201027141828935"></p><h2 id="问题汇总"><a href="#问题汇总" class="headerlink" title="问题汇总"></a>问题汇总</h2><ol><li>账号密码不正确<br>教务系统升级改版，初次登陆请登录教务管理系统网页版重置密码。</li><li>验证码刷新不出来<br>登录 <code>jwgl.nepu.edu.cn</code> 看看自己有没有因为访问次数过多禁止访问！等解禁就好啦！ （或者更换网络环境，更换ip）</li><li>绩点怎么变低了<br>教务处更新了绩点计算规则！（大家都低了没关系/狗头）<h2 id="更新日式"><a href="#更新日式" class="headerlink" title="更新日式"></a>更新日式</h2></li></ol><h3 id="v1-5正式版：2020-10-26中午"><a href="#v1-5正式版：2020-10-26中午" class="headerlink" title="v1.5正式版：2020.10.26中午"></a>v1.5正式版：2020.10.26中午</h3><ul><li>为方便大家计算综测，平均分计算中去除“公选”类型的课程。与智育成绩算法一致。<h3 id="v1-4正式版：2020-10-25晚上"><a href="#v1-4正式版：2020-10-25晚上" class="headerlink" title="v1.4正式版：2020.10.25晚上"></a>v1.4正式版：2020.10.25晚上</h3></li><li>优化页面交互逻辑</li><li>修改登录界面</li><li>修复已知bug<h3 id="v1-3正式版：2020-10-25早晨"><a href="#v1-3正式版：2020-10-25早晨" class="headerlink" title="v1.3正式版：2020.10.25早晨"></a>v1.3正式版：2020.10.25早晨</h3></li><li>新增官方课表</li><li>修改程序图标</li><li>修复其他已知bug<h3 id="v1-1正式版：2020-10-24下午"><a href="#v1-1正式版：2020-10-24下午" class="headerlink" title="v1.1正式版：2020.10.24下午"></a>v1.1正式版：2020.10.24下午</h3></li><li>修复部分同学 全部学期 成绩查询失败的问题</li><li><p>修复其他已知bug</p><h3 id="v1-1正式版：2020-10-24凌晨"><a href="#v1-1正式版：2020-10-24凌晨" class="headerlink" title="v1.1正式版：2020.10.24凌晨"></a>v1.1正式版：2020.10.24凌晨</h3></li><li><p><strong>应用内陆续推送更新，本次为强制更新，v1.0版本在应用内更新后方可正常使用。</strong> </p></li><li>修复部分机型成绩查询失败的问题。</li><li>修复其他已知bug</li></ul><h3 id="v1-0正式版：2020-10-23晚上"><a href="#v1-0正式版：2020-10-23晚上" class="headerlink" title="v1.0正式版：2020.10.23晚上"></a>v1.0正式版：2020.10.23晚上</h3><ul><li><strong>重大升级：</strong> 终于支持软件内更新了！！！不用去百度云下载新版了！后面有更新会自动推送（应用商店审核太慢了。）</li><li>适配几款手机屏幕比例</li><li>修复其他已知bug<h3 id="beta5版本：2020-10-23中午"><a href="#beta5版本：2020-10-23中午" class="headerlink" title="beta5版本：2020.10.23中午"></a>beta5版本：2020.10.23中午</h3></li><li><strong>重大更新</strong>：修复部分机型闪退bug</li><li>修复历年平均绩点显示错误的问题</li><li>修复app内打开csdn之后无法返回的问题</li><li>修复其他已知bug<h3 id="beta5版本：2020-10-22深夜"><a href="#beta5版本：2020-10-22深夜" class="headerlink" title="beta5版本：2020.10.22深夜"></a>beta5版本：2020.10.22深夜</h3></li><li>新增登录页面输入验证码之后回车键登录。</li><li>修复了首页学科数显示的问题。</li><li>修复部分进行闪退的问题。</li><li><p>修复其他已知bug</p><h3 id="beta4版本：2020-10-22晚上"><a href="#beta4版本：2020-10-22晚上" class="headerlink" title="beta4版本：2020.10.22晚上"></a>beta4版本：2020.10.22晚上</h3></li><li><p>新增成绩分析</p></li><li>新增首页智育成绩展示</li><li>修复网页内无法跳转APP</li><li><p>修复其他已知bug</p><h3 id="beta3版本：2020-10-22下午"><a href="#beta3版本：2020-10-22下午" class="headerlink" title="beta3版本：2020.10.22下午"></a>beta3版本：2020.10.22下午</h3></li><li><p>新增绩点查询</p></li><li><p>修复了已知bug</p><h3 id="beta2版本：2020-10-22早晨"><a href="#beta2版本：2020-10-22早晨" class="headerlink" title="beta2版本：2020.10.22早晨"></a>beta2版本：2020.10.22早晨</h3></li><li><p>修复了当前学期成绩无法查询的问题</p></li></ul><h2 id="功能介绍"><a href="#功能介绍" class="headerlink" title="功能介绍"></a>功能介绍</h2><h3 id="成绩查询"><a href="#成绩查询" class="headerlink" title="成绩查询"></a>成绩查询</h3><ul><li>默认显示当前学期成绩</li><li>不同颜色代表不同的分数段<blockquote><p> <60分：红色 60-70分：橙色 70-90分：绿色  \>90分：蓝色</p><h3 id="成绩分析"><a href="#成绩分析" class="headerlink" title="成绩分析"></a>成绩分析</h3><p><img src="https://raw.githubusercontent.com/Asimok/picgo/main/picgo/img/MacBookPro/20201112142338.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5ODI3Njc3,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p></blockquote></li><li>纵坐标：课程数量</li><li>横坐标：分数段<blockquote><p>6：小于60分的课程数<br>7：60-70分<br>以此类推</p></blockquote></li></ul><h3 id="绩点"><a href="#绩点" class="headerlink" title="绩点"></a>绩点</h3><ul><li>绩点计算使用新算法，与教务处显示结果一致。<h3 id="通知公告"><a href="#通知公告" class="headerlink" title="通知公告"></a>通知公告</h3></li><li>为了方便大家查看教务处的通知公告，将它单独拿到App里。</li></ul><h4 id="用户需知"><a href="#用户需知" class="headerlink" title="用户需知"></a>用户需知</h4><p><strong>为得到用户注册量，会收集登录成功的学号！！！仅收集学号！</strong></p>]]></content>
      
      
      <categories>
          
          <category> 软件开发&amp;模型复现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>知识图谱嵌入(KGE)：方法和应用的综述</title>
      <link href="/2020/10/14/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B5%8C%E5%85%A5%EF%BC%9A%E6%96%B9%E6%B3%95%E5%92%8C%E5%BA%94%E7%94%A8%E7%9A%84%E7%BB%BC%E8%BF%B0/"/>
      <url>/2020/10/14/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%B5%8C%E5%85%A5%EF%BC%9A%E6%96%B9%E6%B3%95%E5%92%8C%E5%BA%94%E7%94%A8%E7%9A%84%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="1-知识图谱-KG"><a href="#1-知识图谱-KG" class="headerlink" title="1. 知识图谱(KG)"></a>1. 知识图谱(KG)</h2><ul><li>由实体(节点)和关系(不同类型的边)组成的多关系图。</li><li>每条边都表示为形式(头实体、关系、尾实体)的三个部分，也称为事实</li></ul><h3 id="1-1-问题"><a href="#1-1-问题" class="headerlink" title="1.1 问题"></a>1.1 问题</h3><ul><li>这类三元组的底层符号特性通常使KGs很难操作</li></ul><h3 id="1-2-解决："><a href="#1-2-解决：" class="headerlink" title="1.2 解决："></a>1.2 解决：</h3><ul><li>提出了一种新的研究方向——知识图谱嵌入。</li></ul><h3 id="1-3-关键思想"><a href="#1-3-关键思想" class="headerlink" title="1.3 关键思想"></a>1.3 关键思想</h3><ul><li>嵌入KG的组件，包括将实体和关系转化为连续的向量空间，从而简化操作，同时保留KG的原有的结构。</li></ul><h2 id="2-融合事实信息"><a href="#2-融合事实信息" class="headerlink" title="2. 融合事实信息"></a>2. 融合事实信息</h2><h3 id="2-1-平移距离模型"><a href="#2-1-平移距离模型" class="headerlink" title="2.1 平移距离模型"></a>2.1 平移距离模型</h3><ul><li>平移距离模型利用了基于距离的评分函数，通过两个实体之间的距离对事实的合理性进行度量。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163514.png" alt="img" style="zoom:67%;" /></p><h4 id="2-1-1-TransE模型"><a href="#2-1-1-TransE模型" class="headerlink" title="2.1.1 TransE模型"></a>2.1.1 TransE模型</h4><ul><li>平移不变现象</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163506.png" alt=""></p><ul><li><p><strong>TransE模型：</strong>将知识库中的关系看作实体间的某种平移向量。</p></li><li><p>对于每个事实三元组(h,r,t)，TransE模型将实体和关系表示为同一空间中，把关系向量r看作为头实体向量h和尾实体向量t之间的平移即 $h+r≈t$。</p></li><li><p>可以将r,看作从h到t的翻译</p></li><li><p>知识库中的实体关系类型可分为 一对一 、一对多 、 多对一 、多对多4 种类型，而复杂关系主要指的是 一对多 、 多对一 、多对多的 3 种关系类型。</p><h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><ul><li>TransE模型的参数较少，计算的复杂度显著降低，并且在大规模稀疏知识库上也同样具有较好的性能与可扩展性。</li></ul><h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul><li>TransE模型不能用在处理复杂关系上。</li></ul></li></ul><h4 id="2-1-2-TransH模型"><a href="#2-1-2-TransH模型" class="headerlink" title="2.1.2 TransH模型"></a>2.1.2 TransH模型</h4><ul><li>为了解决TransE模型在处理一对多 、 多对一 、多对多复杂关系时的局限性。</li><li>TransH模型提出让一个实体在不同的关系下拥有不同的表示。</li><li>对于关系r，TransH模型同时使用平移向量r和超平面的法向量w_r来表示它。对于一个三元组(h, r, t) , TransH首先将头实体向量h和尾实体向量r，沿法线wr，影到关系r对应的超平面上，用h⊥和t⊥表示如下：</li></ul><p><img src="https://i.loli.net/2020/10/14/rXvZCSqBY8EhcMV.png" alt=""></p><ul><li><p>TransH 使不同的实体在不同的关系下拥有了不同的表示形式，但由于实体向量被投影到了关系的语义空间中，故它们具有相同的维度</p><h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><ul><li>虽然TransH模型使每个实体在不同关系下拥有了不同的表示，它仍然假设实体和关系处于相同的语义空间中，这一定程度上限制了TransH的表示能力。</li></ul></li></ul><h4 id="2-1-3-TransR模型"><a href="#2-1-3-TransR模型" class="headerlink" title="2.1.3 TransR模型"></a>2.1.3 TransR模型</h4><ul><li>TransR模型认为，一个实体是多种属性的综合体，不同关系关注实体的不同属性。</li><li>不同的关系拥有不同的语义空间。</li><li>对于每一个关系r，TransR定义投影矩阵Mr，将实体向量从实体空间投影到关系r的子空间，用h⊥和t⊥表示如下：</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163454.png" alt=""></p><ul><li><p>然后使 $h⊥+r≈t⊥$</p><h5 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h5><ul><li><p>在同一个关系下：头、尾实体共享相同的投影矩阵。然而，一个关系的头、尾实体的类型或属性可能差异巨大。例如，对于三元组(美国，总统，奥巴马)，美国和奥巴马的类型完全不同，一个是国家，一个是人物。</p></li><li><p>从实体空间到关系空间的投影是实体和关系之间的交互过程，因此TransR让投影矩阵仅与关系有关是不合理的。</p></li><li>与TransE和TransH相比，TransR由于引入了空间投影，使得TransR模型参数急剧增加，计算复杂度大大提高。</li></ul></li></ul><h4 id="2-1-4-TransD模型"><a href="#2-1-4-TransD模型" class="headerlink" title="2.1.4 TransD模型"></a>2.1.4 TransD模型</h4><ul><li>给定三元组(h, r, t) , TransD模型设置了2个分别将头实体和尾实体投影到关系空间的投影矩阵Mr1和Mr2。具体定义如下:</li></ul><p><img src="https://i.loli.net/2020/10/14/kcstuVaQUAvE97y.png" alt="img"></p><ul><li>尾实体用h⊥和t⊥表示如下：</li></ul><p><img src="https://i.loli.net/2020/10/14/ERAcGWmow7drZ9x.png" alt="img"></p><h4 id="2-1-5-TranSparse模型"><a href="#2-1-5-TranSparse模型" class="headerlink" title="2.1.5 TranSparse模型"></a>2.1.5 TranSparse模型</h4><ul><li>TranSparse是通过在投影矩阵上强化稀疏性来简化TransR的工作。它有两个版本：TranSparse (共享)和TranSparse (单独)。</li><li>TranSparse (共享)对每个关系r使用相同的稀疏投影矩阵$M_r(theta_r)$ 即：</li></ul><p><img src="https://i.loli.net/2020/10/14/FSqw6I5lgOH7rsc.png" alt="img"></p><ul><li>TranSparse (单独)对于头实体和尾实体分别使用2个不同的投影矩阵$M_r1(theta_r1$)和$M_r2(theta_r2)$。</li></ul><p><img src="https://i.loli.net/2020/10/14/LcQ2gVtk7HBiaJN.png" alt="img"></p><ul><li><p>这里的$theta_r$、$theta_r1$和$theta_r2$表示这些投影矩阵的稀疏度。</p><h5 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h5><ul><li>TransSparse模型通过引入稀疏投影矩阵，TransSparse模型减少了参数个数。</li></ul></li></ul><h4 id="2-1-6-TransM模型"><a href="#2-1-6-TransM模型" class="headerlink" title="2.1.6 TransM模型"></a>2.1.6 TransM模型</h4><ul><li>除了允许实体在涉及不同关系时具有不同的嵌入之外，提高TransE模型性能可以从降低h+r≈t的要求研究开始。TransM模型将为每个事实（h,r,t）分配特定的关系权重theta_r。</li><li>通过对一对多、多对一和多对多分配较小的权重，TransM模型使得t在上述的复杂关系中离h+r更远。</li></ul><h4 id="2-1-7-ManifoldE模型"><a href="#2-1-7-ManifoldE模型" class="headerlink" title="2.1.7 ManifoldE模型"></a>2.1.7 ManifoldE模型</h4><ul><li>ManifoldE模型对于每个事实三元组$（h,r,t）$将$h+r≈t$转换为(h+r-t)的L2范式约等于theta_r的平方。</li><li>ManifoldE把t近似地位于流形体上，即一个以h+r为中心半径为theta_r的超球体，而不是接近h+r的精确点。</li></ul><h4 id="2-1-8-TransF模型"><a href="#2-1-8-TransF模型" class="headerlink" title="2.1.8 TransF模型"></a>2.1.8 TransF模型</h4><ul><li>TransF只需要t与h+r位于同一个方向，同时h与t-r也位于同一个方向。</li></ul><h4 id="2-1-9-TransA模型"><a href="#2-1-9-TransA模型" class="headerlink" title="2.1.9 TransA模型"></a>2.1.9 TransA模型</h4><ul><li><p>TransA模型为每个关系r引入一个对称的非负矩阵Mr，并使用自适应马氏距离定义评分函数。</p></li><li><p>通过学习距离度量Mr, TransA在处理复杂关系时更加灵活。</p><h5 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h5><ul><li>评分函数只采用L1或L2距离，灵活性不够。</li><li>评分函数过于简单，实体和关系向量的每一维等同考虑。</li></ul><h5 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h5><ul><li>提出TransA模型，将评分函数中的距离度量改用马氏距离，并为每一维学习不同的权重。</li></ul><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><ul><li>如下图所示，$( h_1, r_1, t_1)$和$(h_2,r_2,t_2)$两个合法的事实三元组，t3是错误的尾实体。如果使用欧氏距离，如图(a)所示，错误的实体t3会被预测出来。而如图(b)所示，TransA模型通过对向量不同维度进行加权，正确的实体由于在x轴或者y轴上距离较近，从而能够被正确预测。</li></ul><p><img src="https://i.loli.net/2020/10/14/R5O6apo914qAnYG.png" alt="img"></p></li></ul><h3 id="2-2-高斯嵌入模型"><a href="#2-2-高斯嵌入模型" class="headerlink" title="2.2 高斯嵌入模型"></a>2.2 高斯嵌入模型</h3><h4 id="2-2-1-KG2E模型"><a href="#2-2-1-KG2E模型" class="headerlink" title="2.2.1 KG2E模型"></a>2.2.1 KG2E模型</h4><ul><li>知识库中的关系和实体的语义本身具有不确定性，而过去模型中都忽略这个因素。</li><li>KG2E使用高斯分布来表示实体和关系。</li><li>其中高斯分布的均值表示的是实体或关系在语义空间中的中心位置，而高斯分布的协方差则表示该实体或关系的不确定度。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022101036.png" alt="img"></p><blockquote><p>每个圆圈代表不同实体与关系的表示，它们分别与”比尔·克林顿”构成三元组，其中圆圈大小表示的是不同实体或关系的不确定度，可以看到”国籍”的不确定度远远大于其他关系。</p></blockquote><h4 id="TransG模型"><a href="#TransG模型" class="headerlink" title="TransG模型"></a>TransG模型</h4><ul><li>TransG也是对高斯分布的实体进行了建模。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/640.png" alt="img"></p><ul><li>TransG提出使用高斯混合模型描述头、尾实体之间的关系。该模型认为，一个关系会对应多种语义，每种语义用一个高斯分布来刻画。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022101508.png" alt="img"></p><ul><li>传统模型和TransG模型比较</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022101740.png" alt="img"></p><blockquote><p>其中三角形表示正确的尾实体，圆形表示错误的尾实体。图(a)中为传统模型示例，由于将关系r的所有语义混为一谈，导致错误的实体无法被区分开。而图(b)所示，TransG模型通过考虑关系r的不同语义，形成多个高斯分布，就能够区分出正确和错误实体。</p></blockquote><h2 id="3-语义匹配模型"><a href="#3-语义匹配模型" class="headerlink" title="3 语义匹配模型"></a>3 语义匹配模型</h2><ul><li>使用基于相似度的评分函数。</li><li>通过匹配实体的潜在语义和向量空间表示中包含的关系来度量事实的可信性。</li></ul><h3 id="3-1-RESCAL模型及其扩展"><a href="#3-1-RESCAL模型及其扩展" class="headerlink" title="3.1 RESCAL模型及其扩展"></a>3.1 RESCAL模型及其扩展</h3><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163554.png" alt="img" style="zoom: 67%;" /></p><h4 id="3-1-1-RESCAL模型"><a href="#3-1-1-RESCAL模型" class="headerlink" title="3.1.1 RESCAL模型"></a>3.1.1 RESCAL模型</h4><ul><li>RESCAL(又称双线性模型)通过使用一个向量表示每个实体来获得它的潜在语义。</li><li>每个关系都表示为一个矩阵，该矩阵对潜在因素之间的成对交互作用进行了建模。它把事实$（h,r,t）$评分函数定义为一个双线性函数。</li></ul><h4 id="3-1-2-DistMult模型"><a href="#3-1-2-DistMult模型" class="headerlink" title="3.1.2 DistMult模型"></a>3.1.2 DistMult模型</h4><ul><li>DistMult通过将Mr限制为对角矩阵来简化RESCAL。(Mr关系矩阵)</li><li>评分函数只捕获沿同一维度的h和t分量之间的成对交互作用(参阅图5 b)，并将每一个关系的参数数量减少至O(d)。</li><li>然而，因为对于任意的h和t，$h^Tdiag(r)t = t^Tdiag(r)h$都是成立的，这种过度简化的模型<strong>只能处理对称的关系</strong>，这显然对于一般的KGs是不能完全适用的。</li></ul><h4 id="3-1-3-HolE模型"><a href="#3-1-3-HolE模型" class="headerlink" title="3.1.3 HolE模型"></a>3.1.3 HolE模型</h4><ul><li>HolE将RESCAL的表达能力与DistMult的效率和简单性相结合。</li><li>把实体和关系都表示为$R_d$中的向量。给定一个事实$(h,r,t)$，首先使用循环相关操作将实体表示形式组成$h*t∈R$。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022104059.png" alt="img"></p><ul><li>然后将组合向量与关系表示形式匹配，以对事实进行评分。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/640-20201022104132055.png" alt="img"></p><ul><li>循环相关对成对的相互作用进行压缩。因此，HolE对每个关系只需要$O(d)$参数，这比RESCAL更有效。与此同时，因为循环相关是不符合交换律的，即$h<em>t$不等于$t</em>h$。所以HolE能够像RESCAL那样<strong>对不对称关系进行建模</strong>。</li></ul><h4 id="3-1-4-ComplEx模型"><a href="#3-1-4-ComplEx模型" class="headerlink" title="3.1.4 ComplEx模型"></a>3.1.4 ComplEx模型</h4><ul><li>ComplEx通过引入复值嵌入来扩展DistMult，以便更好地对非对称关系进行建模。</li><li>在ComplEx中，实体和关系嵌入h，r, t不再存在于实空间中，而是存在于复空间中。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163603.png" alt="img" style="zoom:150%;" /></p><blockquote><p> 评分函数</p><p>这个评分函数不再是对称的，来自非对称关系的事实可以根据涉及实体的顺序得到不同的分数。</p></blockquote><h4 id="3-1-5-ANALOGY模型"><a href="#3-1-5-ANALOGY模型" class="headerlink" title="3.1.5 ANALOGY模型"></a>3.1.5 ANALOGY模型</h4><ul><li>ANALOGY 扩展了RESCAL，从而进一步对实体和关系的类比属性进行建模。</li><li>它遵循RESCAL并使用双线性评分函数。</li><li>尽管ANALOGY表示关系为矩阵，这些矩阵可以同时对角化成一组稀疏的准对角矩阵，由每个只有$O(d)$自由参数。</li></ul><h3 id="3-2-基于神经网络匹配"><a href="#3-2-基于神经网络匹配" class="headerlink" title="3.2 基于神经网络匹配"></a>3.2 基于神经网络匹配</h3><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022110857.png" style="zoom:80%;" /></p><h4 id="3-2-1-语义匹配能量模型-SME"><a href="#3-2-1-语义匹配能量模型-SME" class="headerlink" title="3.2.1 语义匹配能量模型(SME)"></a>3.2.1 语义匹配能量模型(SME)</h4><ul><li>SME采用神经网络结构进行语义匹配。</li><li>给定一个事实三元组$（h,r,t）$，它首先将实体和关系投影到输入层中的嵌入向量。然后，将关系r与头实体h组合得到$g_u(h,r)$，并与尾实体t组合，得到隐藏层中的$g_v(t,r)$。则该事实的分数最终由它们的点积定义为匹配的$g_u$和$g_v$。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022104846.png" style="zoom:150%;" /></p><ul><li>SME有两个版本：线性版本和双线性版本。</li></ul><h4 id="3-2-2-神经张量网络模型-NTN"><a href="#3-2-2-神经张量网络模型-NTN" class="headerlink" title="3.2.2 神经张量网络模型(NTN)"></a>3.2.2 神经张量网络模型(NTN)</h4><ul><li>NTN是另外一种神经网络结构，给定一个事实，它首先将实体投影到输入层中的嵌入向量。然后，将这两个实体h,t由关系特有的张量$M_r$(以及其他参数)组合，并映射到一个非线性隐藏层。最后，一个特定于关系的线性输出层给出了评分。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022110255.png" alt="img"></p><ul><li>尽管NTN是迄今为止最具表达能力的模型，但是，由于它的每个关系的需要O(d^2*k)个参数，并且不能简单有效地处理大型的KGs。</li></ul><h4 id="3-2-3-多层感知机-MLP"><a href="#3-2-3-多层感知机-MLP" class="headerlink" title="3.2.3 多层感知机(MLP)"></a>3.2.3 多层感知机(MLP)</h4><ul><li>MLP是一种更简单的方法，在这种方法中，每个关系(以及实体)都是由一个向量组合而成的。</li><li>给定一个事实$（h,r,t）$将嵌入向量h、r和t连接在输入层中，并映射到非线性的隐藏层。然后由线性输出层生成分数。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201102163615.png" alt="img"></p><blockquote><p>其中$M_1、M_2、M_3$是第一层的权重，w是第二层的权重，这些都是在不同的关系中共享的。</p></blockquote><h4 id="3-2-4-神经关联模型-NAM"><a href="#3-2-4-神经关联模型-NAM" class="headerlink" title="3.2.4 神经关联模型(NAM)"></a>3.2.4 神经关联模型(NAM)</h4><ul><li>NAM使用“深度”架构进行语义匹配，给定一个事实，它首先将头实体的嵌入向量和输入层中的关系连接起来，从而给出$z_0=[h,r]$。然后输入$z_0$输入到一个由L个线性隐层组成的深神经网络中。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022110719.png" alt="img"></p><blockquote><p>其中$M<em>(l)$和b</em>(l)分别表示第l层的权重矩阵和偏差。</p></blockquote><ul><li>在前馈过程之后，通过匹配最后一个隐藏层的输出和尾实体的嵌入向量来给出分数。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022110834.png" alt="img"></p><h2 id="4-融合附加信息"><a href="#4-融合附加信息" class="headerlink" title="4 融合附加信息"></a>4 融合附加信息</h2><ul><li>目前介绍的方法仅使用KG中观察到的事实来执行嵌入任务。事实上，可以合并许多附加信息来进一步改进任务，例如实体类型、关系路径、文本描述以及逻辑规则。</li></ul><h3 id="4-1-实体类型"><a href="#4-1-实体类型" class="headerlink" title="4.1 实体类型"></a>4.1 实体类型</h3><ul><li>即实体所属的语义类别。</li><li>实体类型也可以作为不同关系的头部和尾部位置的约束，例如关系DirectorOf的头实体的类型应该是人，尾实体的类型应该是电影作品。</li></ul><h4 id="4-1-1语义平滑嵌入-SSE-模型"><a href="#4-1-1语义平滑嵌入-SSE-模型" class="headerlink" title="4.1.1语义平滑嵌入(SSE)模型"></a>4.1.1语义平滑嵌入(SSE)模型</h4><ul><li><p>它要求相同类型的实体在嵌入空间中彼此邻近。</p></li><li><p>SSE采用两种流形学习算法，即拉普拉斯特征映射和局部线性嵌入来对这种光滑性假设进行建模。</p><blockquote><p>拉普拉斯特征映射：要求一个实体和同一类别中的每一个其他实体邻近。</p><p>局部线性嵌入：一个实体视为其最近邻居的线性组合，即同一类别内的实体。</p></blockquote></li><li><p>SSE的一个主要限制是它假设实体的语义范畴是无层次的，每个实体完全属于一个类别。显然，在典型的现实世界中，情况并非如此。</p></li></ul><h4 id="4-1-2-TKRL模型"><a href="#4-1-2-TKRL模型" class="headerlink" title="4.1.2 TKRL模型"></a>4.1.2 TKRL模型</h4><ul><li>它可以处理分层实体类别和多个类别标签。</li><li>TKRL是一个具有特定类型实体投影的平移距离模型。给定一个事实$(h,r,t)$，它首先用特定类型的投影矩阵预测h和t，然后将r建模为两个投影实体之间的平移。</li></ul><p><img src="https://asimov-1258043582.cos.ap-nanjing.myqcloud.com/img/20201022112809.png" alt="img"></p><blockquote><p>评分函数</p><p>其中$M_rh$和$M_rt$是h和t的投影矩阵，为了处理多个类别标签，$M_r$h表示为所有可能的类型矩阵的加权和。</p></blockquote><ul><li>虽然TKRL在链路预测和三元组分类等下游任务中取得了较好的性能，但由于它将每个类别与特定的投影矩阵相关联，因此具有较高的空间复杂度。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> KG </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
